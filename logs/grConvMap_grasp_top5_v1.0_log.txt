grConvMap_grasp_top5_v1.0 Training Log at 2024-06-09 15:38:50.676564

train-epoch-step: 1-1 -- Loss: 1.595199465751648
train-epoch-step: 1-2 -- Loss: 1.5268789529800415
train-epoch-step: 1-3 -- Loss: 1.5613930225372314
train-epoch-step: 1-4 -- Loss: 1.539506196975708
train-epoch-step: 1-5 -- Loss: 1.49886155128479
train-epoch-step: 1-6 -- Loss: 1.4655671119689941
train-epoch-step: 1-7 -- Loss: 1.5394113063812256
train-epoch-step: 1-8 -- Loss: 1.363990068435669
train-epoch-step: 1-9 -- Loss: 1.434786081314087
train-epoch-step: 1-10 -- Loss: 1.5964992046356201
train-epoch-step: 1-11 -- Loss: 1.1494441032409668
train-epoch-step: 1-12 -- Loss: 1.1534507274627686
train-epoch-step: 1-13 -- Loss: 1.261556625366211
train-epoch-step: 1-14 -- Loss: 1.0256776809692383
train-epoch-step: 1-15 -- Loss: 1.1212629079818726
train-epoch-step: 1-16 -- Loss: 0.9023910760879517
train-epoch-step: 1-17 -- Loss: 0.9419530630111694
train-epoch-step: 1-18 -- Loss: 1.100250244140625
train-epoch-step: 1-19 -- Loss: 0.8030786514282227
train-epoch-step: 1-20 -- Loss: 0.6763174533843994
train-epoch-step: 1-21 -- Loss: 0.6975471377372742
train-epoch-step: 1-22 -- Loss: 0.7225506901741028
train-epoch-step: 1-23 -- Loss: 0.5986825227737427
train-epoch-step: 1-24 -- Loss: 0.491082102060318
train-epoch-step: 1-25 -- Loss: 0.5569665431976318
train-epoch-step: 1-26 -- Loss: 0.7310935258865356
train-epoch-step: 1-27 -- Loss: 0.44884732365608215
train-epoch-step: 1-28 -- Loss: 0.4001684784889221
train-epoch-step: 1-29 -- Loss: 0.3900470733642578
train-epoch-step: 1-30 -- Loss: 0.34950751066207886
train-epoch-step: 1-31 -- Loss: 0.4377593398094177
train-epoch-step: 1-32 -- Loss: 1.038088321685791
train-epoch-step: 1-33 -- Loss: 0.4250866770744324
train-epoch-step: 1-34 -- Loss: 0.5219846963882446
train-epoch-step: 1-35 -- Loss: 0.329206645488739
train-epoch-step: 1-36 -- Loss: 0.33185696601867676
train-epoch-step: 1-37 -- Loss: 0.3365039825439453
train-epoch-step: 1-38 -- Loss: 0.6083450317382812
train-epoch-step: 1-39 -- Loss: 0.5525946617126465
train-epoch-step: 1-40 -- Loss: 0.31267938017845154
train-epoch-step: 1-41 -- Loss: 0.5257220268249512
train-epoch-step: 1-42 -- Loss: 0.2783384323120117
train-epoch-step: 1-43 -- Loss: 0.8697724342346191
train-epoch-step: 1-44 -- Loss: 0.6703683733940125
train-epoch-step: 1-45 -- Loss: 0.31235265731811523
train-epoch-step: 1-46 -- Loss: 0.3550815284252167
train-epoch-step: 1-47 -- Loss: 0.2905831038951874
train-epoch-step: 1-48 -- Loss: 0.30739519000053406
train-epoch-step: 1-49 -- Loss: 0.5591939091682434
train-epoch-step: 1-50 -- Loss: 0.2746065855026245
train-epoch-step: 1-51 -- Loss: 0.22326427698135376
train-epoch-step: 1-52 -- Loss: 0.2798433303833008
train-epoch-step: 1-53 -- Loss: 0.44935762882232666
train-epoch-step: 1-54 -- Loss: 0.40748071670532227
train-epoch-step: 1-55 -- Loss: 0.6734066009521484
train-epoch-step: 1-56 -- Loss: 0.24870117008686066
train-epoch-step: 1-57 -- Loss: 0.3397946357727051
train-epoch-step: 1-58 -- Loss: 0.3248310685157776
train-epoch-step: 1-59 -- Loss: 0.2694418728351593
train-epoch-step: 1-60 -- Loss: 0.336199551820755
train-epoch-step: 1-61 -- Loss: 0.2444855272769928
train-epoch-step: 1-62 -- Loss: 0.564342737197876
train-epoch-step: 1-63 -- Loss: 0.3308927118778229
train-epoch-step: 1-64 -- Loss: 0.3525412380695343
train-epoch-step: 1-65 -- Loss: 0.23688794672489166
train-epoch-step: 1-66 -- Loss: 0.26623523235321045
train-epoch-step: 1-67 -- Loss: 0.475366473197937