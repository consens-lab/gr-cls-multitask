grConvMap_grasp_top5_v1.0 Training Log at 2024-06-10 01:15:49.002243

train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100688934326172
train-epoch-step: 1-4 -- Loss: 1.544996738433838
train-epoch-step: 1-5 -- Loss: 1.4992728233337402
train-epoch-step: 1-6 -- Loss: 1.6029884815216064
train-epoch-step: 1-7 -- Loss: 1.444686770439148
train-epoch-step: 1-8 -- Loss: 1.4407882690429688
train-epoch-step: 1-9 -- Loss: 1.463073968887329
train-epoch-step: 1-10 -- Loss: 1.4210102558135986
train-epoch-step: 1-11 -- Loss: 1.2645952701568604
train-epoch-step: 1-12 -- Loss: 1.1825666427612305
train-epoch-step: 1-13 -- Loss: 1.2163021564483643
train-epoch-step: 1-14 -- Loss: 1.0300198793411255
train-epoch-step: 1-15 -- Loss: 0.9768151640892029
train-epoch-step: 1-16 -- Loss: 0.9234623312950134
train-epoch-step: 1-17 -- Loss: 0.9746809005737305
train-epoch-step: 1-18 -- Loss: 0.8348144292831421
train-epoch-step: 1-19 -- Loss: 0.6831537485122681
train-epoch-step: 1-20 -- Loss: 0.7804584503173828
train-epoch-step: 1-21 -- Loss: 0.8410978317260742
train-epoch-step: 1-22 -- Loss: 0.5577207803726196
train-epoch-step: 1-23 -- Loss: 0.564280092716217
train-epoch-step: 1-24 -- Loss: 0.4784613251686096
train-epoch-step: 1-25 -- Loss: 0.6167767643928528
train-epoch-step: 1-26 -- Loss: 0.5280846357345581
train-epoch-step: 1-27 -- Loss: 0.772271990776062
train-epoch-step: 1-28 -- Loss: 0.37471550703048706
train-epoch-step: 1-29 -- Loss: 0.5496460199356079
train-epoch-step: 1-30 -- Loss: 0.29081130027770996
train-epoch-step: 1-31 -- Loss: 0.3573148250579834
train-epoch-step: 1-32 -- Loss: 0.41269516944885254
train-epoch-step: 1-33 -- Loss: 0.6395256519317627
train-epoch-step: 1-34 -- Loss: 0.4050391912460327
train-epoch-step: 1-35 -- Loss: 0.5428979396820068
train-epoch-step: 1-36 -- Loss: 0.3633080720901489
train-epoch-step: 1-37 -- Loss: 0.35656964778900146
train-epoch-step: 1-38 -- Loss: 0.40450048446655273
train-epoch-step: 1-39 -- Loss: 0.5125441551208496
train-epoch-step: 1-40 -- Loss: 0.45617812871932983
train-epoch-step: 1-41 -- Loss: 0.487174391746521
train-epoch-step: 1-42 -- Loss: 0.358848512172699
train-epoch-step: 1-43 -- Loss: 0.6821423768997192
train-epoch-step: 1-44 -- Loss: 0.2957196831703186
train-epoch-step: 1-45 -- Loss: 0.272967129945755
train-epoch-step: 1-46 -- Loss: 0.39593690633773804
train-epoch-step: 1-47 -- Loss: 0.4344080686569214
train-epoch-step: 1-48 -- Loss: 0.3409571647644043
train-epoch-step: 1-49 -- Loss: 0.4226786494255066
train-epoch-step: 1-50 -- Loss: 0.28157222270965576
train-epoch-step: 1-51 -- Loss: 0.39722806215286255
train-epoch-step: 1-52 -- Loss: 0.3115120232105255
train-epoch-step: 1-53 -- Loss: 0.47353583574295044
train-epoch-step: 1-54 -- Loss: 0.5787376761436462
train-epoch-step: 1-55 -- Loss: 0.3621901273727417
train-epoch-step: 1-56 -- Loss: 0.40684545040130615
train-epoch-step: 1-57 -- Loss: 0.5251545906066895
train-epoch-step: 1-58 -- Loss: 0.520315945148468
train-epoch-step: 1-59 -- Loss: 0.5195196866989136
train-epoch-step: 1-60 -- Loss: 0.26066046953201294
train-epoch-step: 1-61 -- Loss: 0.40495795011520386
train-epoch-step: 1-62 -- Loss: 0.3583361506462097
train-epoch-step: 1-63 -- Loss: 0.2788715362548828
train-epoch-step: 1-64 -- Loss: 0.3362191319465637
train-epoch-step: 1-65 -- Loss: 0.3767580986022949
train-epoch-step: 1-66 -- Loss: 0.2147228866815567
train-epoch-step: 1-67 -- Loss: 0.2514243423938751
train-epoch-step: 1-68 -- Loss: 0.44013985991477966
train-epoch-step: 1-69 -- Loss: 0.25880685448646545
train-epoch-step: 1-70 -- Loss: 0.48983821272850037
train-epoch-step: 1-71 -- Loss: 0.570470929145813
train-epoch-step: 1-72 -- Loss: 0.3411130905151367
train-epoch-step: 1-73 -- Loss: 0.4110679626464844
train-epoch-step: 1-74 -- Loss: 0.19834765791893005
train-epoch-step: 1-75 -- Loss: 0.280025839805603
train-epoch-step: 1-76 -- Loss: 0.2840118706226349
train-epoch-step: 1-77 -- Loss: 0.39324426651000977
train-epoch-step: 1-78 -- Loss: 0.5092369318008423
train-epoch-step: 1-79 -- Loss: 0.3700944781303406
train-epoch-step: 1-80 -- Loss: 0.4488173723220825
train-epoch-step: 1-81 -- Loss: 0.2777833342552185
train-epoch-step: 1-82 -- Loss: 0.45877036452293396
train-epoch-step: 1-83 -- Loss: 0.3509339392185211
train-epoch-step: 1-84 -- Loss: 0.38693565130233765
train-epoch-step: 1-85 -- Loss: 0.33521580696105957
train-epoch-step: 1-86 -- Loss: 0.21837064623832703
train-epoch-step: 1-87 -- Loss: 0.399923712015152
train-epoch-step: 1-88 -- Loss: 0.26468193531036377
train-epoch-step: 1-89 -- Loss: 0.3283102512359619
train-epoch-step: 1-90 -- Loss: 0.3477069139480591
train-epoch-step: 1-91 -- Loss: 0.43541011214256287
train-epoch-step: 1-92 -- Loss: 0.302340567111969
train-epoch-step: 1-93 -- Loss: 0.3334745764732361
train-epoch-step: 1-94 -- Loss: 0.45690470933914185
train-epoch-step: 1-95 -- Loss: 0.36632615327835083
train-epoch-step: 1-96 -- Loss: 0.3854231834411621
train-epoch-step: 1-97 -- Loss: 0.35118913650512695
train-epoch-step: 1-98 -- Loss: 0.29531848430633545
train-epoch-step: 1-99 -- Loss: 0.3140128552913666
train-epoch-step: 1-100 -- Loss: 0.34969520568847656
train-epoch-step: 1-101 -- Loss: 0.4423777759075165
train-epoch-step: 1-102 -- Loss: 0.47795742750167847
train-epoch-step: 1-103 -- Loss: 0.369263231754303
train-epoch-step: 1-104 -- Loss: 0.28707069158554077
train-epoch-step: 1-105 -- Loss: 0.6589292287826538
train-epoch-step: 1-106 -- Loss: 0.3227101266384125
train-epoch-step: 1-107 -- Loss: 0.3731309473514557
train-epoch-step: 1-108 -- Loss: 0.328974187374115
train-epoch-step: 1-109 -- Loss: 0.27686452865600586
train-epoch-step: 1-110 -- Loss: 0.3271573781967163
train-epoch-step: 1-111 -- Loss: 0.34456363320350647
train-epoch-step: 1-112 -- Loss: 0.2739216685295105
train-epoch-step: 1-113 -- Loss: 0.3666471838951111
train-epoch-step: 1-114 -- Loss: 0.3909231722354889
train-epoch-step: 1-115 -- Loss: 0.27817749977111816
train-epoch-step: 1-116 -- Loss: 0.25152289867401123
train-epoch-step: 1-117 -- Loss: 0.2387610226869583
train-epoch-step: 1-118 -- Loss: 0.3554132580757141
train-epoch-step: 1-119 -- Loss: 0.2580104470252991
train-epoch-step: 1-120 -- Loss: 0.4401533007621765
train-epoch-step: 1-121 -- Loss: 0.40588271617889404
train-epoch-step: 1-122 -- Loss: 0.38463252782821655
train-epoch-step: 1-123 -- Loss: 0.3778296113014221
train-epoch-step: 1-124 -- Loss: 0.22262446582317352
train-epoch-step: 1-125 -- Loss: 0.2478744387626648
train-epoch-step: 1-126 -- Loss: 0.39565804600715637
train-epoch-step: 1-127 -- Loss: 0.28113436698913574
train-epoch-step: 1-128 -- Loss: 0.3290814161300659
train-epoch-step: 1-129 -- Loss: 0.23532389104366302
train-epoch-step: 1-130 -- Loss: 0.3173660337924957
train-epoch-step: 1-131 -- Loss: 0.2395210862159729
train-epoch-step: 1-132 -- Loss: 0.3278788924217224
train-epoch-step: 1-133 -- Loss: 0.20323920249938965
train-epoch-step: 1-134 -- Loss: 0.34590694308280945
train-epoch-step: 1-135 -- Loss: 0.21691834926605225
train-epoch-step: 1-136 -- Loss: 0.2046484649181366
train-epoch-step: 1-137 -- Loss: 0.43335601687431335
train-epoch-step: 1-138 -- Loss: 0.4957461357116699
train-epoch-step: 1-139 -- Loss: 0.23977848887443542
train-epoch-step: 1-140 -- Loss: 0.39690423011779785
train-epoch-step: 1-141 -- Loss: 0.4107478857040405
train-epoch-step: 1-142 -- Loss: 0.3609066307544708
train-epoch-step: 1-143 -- Loss: 0.3181382715702057
train-epoch-step: 1-144 -- Loss: 0.33661574125289917
train-epoch-step: 1-145 -- Loss: 0.2532355785369873
train-epoch-step: 1-146 -- Loss: 0.31726107001304626
train-epoch-step: 1-147 -- Loss: 0.3394773006439209
train-epoch-step: 1-148 -- Loss: 0.28684455156326294
train-epoch-step: 1-149 -- Loss: 0.20385679602622986
train-epoch-step: 1-150 -- Loss: 0.34084203839302063
train-epoch-step: 1-151 -- Loss: 0.3585386872291565
train-epoch-step: 1-152 -- Loss: 0.3345654010772705
train-epoch-step: 1-153 -- Loss: 0.49252501130104065
train-epoch-step: 1-154 -- Loss: 0.2495637834072113
train-epoch-step: 1-155 -- Loss: 0.24994149804115295
train-epoch-step: 1-156 -- Loss: 0.21173995733261108
train-epoch-step: 1-157 -- Loss: 0.28391292691230774
train-epoch-step: 1-158 -- Loss: 0.3097599148750305
train-epoch-step: 1-159 -- Loss: 0.3026924133300781
train-epoch-step: 1-160 -- Loss: 0.3590131998062134
train-epoch-step: 1-161 -- Loss: 0.3566049039363861
train-epoch-step: 1-162 -- Loss: 0.3975328207015991
train-epoch-step: 1-163 -- Loss: 0.3340751528739929
train-epoch-step: 1-164 -- Loss: 0.3139628767967224
train-epoch-step: 1-165 -- Loss: 0.275151789188385
train-epoch-step: 1-166 -- Loss: 0.21253368258476257
train-epoch-step: 1-167 -- Loss: 0.20286892354488373
train-epoch-step: 1-168 -- Loss: 0.3408060669898987
train-epoch-step: 1-169 -- Loss: 0.23705539107322693
train-epoch-step: 1-170 -- Loss: 0.36720412969589233
train-epoch-step: 1-171 -- Loss: 0.2947213649749756
train-epoch-step: 1-172 -- Loss: 0.4377664625644684
train-epoch-step: 1-173 -- Loss: 0.23004572093486786
train-epoch-step: 1-174 -- Loss: 0.4615405797958374
train-epoch-step: 1-175 -- Loss: 0.3427654802799225
train-epoch-step: 1-176 -- Loss: 0.2346367985010147
train-epoch-step: 1-177 -- Loss: 0.3083178699016571
train-epoch-step: 1-178 -- Loss: 0.3066769242286682
train-epoch-step: 1-179 -- Loss: 0.23421935737133026
train-epoch-step: 1-180 -- Loss: 0.2490624189376831
train-epoch-step: 1-181 -- Loss: 0.318930059671402
train-epoch-step: 1-182 -- Loss: 0.33099669218063354
train-epoch-step: 1-183 -- Loss: 0.7128309011459351
train-epoch-step: 1-184 -- Loss: 0.25891685485839844
train-epoch-step: 1-185 -- Loss: 0.24387776851654053
train-epoch-step: 1-186 -- Loss: 0.33381831645965576
train-epoch-step: 1-187 -- Loss: 0.38095954060554504
train-epoch-step: 1-188 -- Loss: 0.3397122025489807
train-epoch-step: 1-189 -- Loss: 0.24032706022262573
train-epoch-step: 1-190 -- Loss: 0.2845924496650696
train-epoch-step: 1-191 -- Loss: 0.2911085784435272
train-epoch-step: 1-192 -- Loss: 0.41226130723953247
train-epoch-step: 1-193 -- Loss: 0.4170800745487213
train-epoch-step: 1-194 -- Loss: 0.33893364667892456
train-epoch-step: 1-195 -- Loss: 0.33280596137046814
train-epoch-step: 1-196 -- Loss: 0.29734277725219727
train-epoch-step: 1-197 -- Loss: 0.2184947282075882
train-epoch-step: 1-198 -- Loss: 0.20954471826553345
train-epoch-step: 1-199 -- Loss: 0.2735116183757782
train-epoch-step: 1-200 -- Loss: 0.20540021359920502
train-epoch-step: 1-201 -- Loss: 0.3363708257675171
train-epoch-step: 1-202 -- Loss: 0.2232738882303238
train-epoch-step: 1-203 -- Loss: 0.3035964369773865
train-epoch-step: 1-204 -- Loss: 0.2639006972312927
train-epoch-step: 1-205 -- Loss: 0.29659339785575867
train-epoch-step: 1-206 -- Loss: 0.35787272453308105
train-epoch-step: 1-207 -- Loss: 0.2309211641550064
train-epoch-step: 1-208 -- Loss: 0.29489797353744507
train-epoch-step: 1-209 -- Loss: 0.2341824620962143
train-epoch-step: 1-210 -- Loss: 0.230238139629364
train-epoch-step: 1-211 -- Loss: 0.3583657145500183
train-epoch-step: 1-212 -- Loss: 0.32894790172576904
train-epoch-step: 1-213 -- Loss: 0.22589226067066193
train-epoch-step: 1-214 -- Loss: 0.25369465351104736
train-epoch-step: 1-215 -- Loss: 0.22389578819274902
train-epoch-step: 1-216 -- Loss: 0.30768248438835144
train-epoch-step: 1-217 -- Loss: 0.3829650282859802
train-epoch-step: 1-218 -- Loss: 0.2641264796257019
train-epoch-step: 1-219 -- Loss: 0.34167391061782837
train-epoch-step: 1-220 -- Loss: 0.21735355257987976
train-epoch-step: 1-221 -- Loss: 0.3824186325073242
train-epoch-step: 1-222 -- Loss: 0.21474643051624298
train-epoch-step: 1-223 -- Loss: 0.288916677236557
train-epoch-step: 1-224 -- Loss: 0.2962521016597748
train-epoch-step: 1-225 -- Loss: 0.475703626871109
train-epoch-step: 1-226 -- Loss: 0.34353670477867126
train-epoch-step: 1-227 -- Loss: 0.3770061731338501
train-epoch-step: 1-228 -- Loss: 0.29123109579086304
train-epoch-step: 1-229 -- Loss: 0.35709428787231445
train-epoch-step: 1-230 -- Loss: 0.2777200937271118
train-epoch-step: 1-231 -- Loss: 0.3021240234375
train-epoch-step: 1-232 -- Loss: 0.3052143454551697
train-epoch-step: 1-233 -- Loss: 0.15848752856254578
train-epoch-step: 1-234 -- Loss: 0.29114124178886414
train-epoch-step: 1-235 -- Loss: 0.2615046501159668
train-epoch-step: 1-236 -- Loss: 0.30438756942749023
train-epoch-step: 1-237 -- Loss: 0.4099043011665344
train-epoch-step: 1-238 -- Loss: 0.27030932903289795
train-epoch-step: 1-239 -- Loss: 0.23526562750339508
train-epoch-step: 1-240 -- Loss: 0.3677414655685425
train-epoch-step: 1-241 -- Loss: 0.2624799311161041
train-epoch-step: 1-242 -- Loss: 0.3631768524646759
train-epoch-step: 1-243 -- Loss: 0.4126244783401489
train-epoch-step: 1-244 -- Loss: 0.354462206363678
train-epoch-step: 1-245 -- Loss: 0.39459025859832764
train-epoch-step: 1-246 -- Loss: 0.4479750692844391
train-epoch-step: 1-247 -- Loss: 0.3994957208633423
train-epoch-step: 1-248 -- Loss: 0.280184805393219
train-epoch-step: 1-249 -- Loss: 0.2300751805305481
train-epoch-step: 1-250 -- Loss: 0.4079834222793579
train-epoch-step: 1-251 -- Loss: 0.1932351440191269
train-epoch-step: 1-252 -- Loss: 0.28318220376968384
train-epoch-step: 1-253 -- Loss: 0.21381503343582153
train-epoch-step: 1-254 -- Loss: 0.38720911741256714
train-epoch-step: 1-255 -- Loss: 0.22437389194965363
train-epoch-step: 1-256 -- Loss: 0.2333018183708191
train-epoch-step: 1-257 -- Loss: 0.2885749936103821
train-epoch-step: 1-258 -- Loss: 0.27846500277519226
train-epoch-step: 1-259 -- Loss: 0.1753973662853241
train-epoch-step: 1-260 -- Loss: 0.3431412875652313
train-epoch-step: 1-261 -- Loss: 0.2641509771347046
train-epoch-step: 1-262 -- Loss: 0.4840523898601532
train-epoch-step: 1-263 -- Loss: 0.39074403047561646
train-epoch-step: 1-264 -- Loss: 0.26906728744506836
train-epoch-step: 1-265 -- Loss: 0.18495553731918335
train-epoch-step: 1-266 -- Loss: 0.24118763208389282
train-epoch-step: 1-267 -- Loss: 0.22763708233833313
train-epoch-step: 1-268 -- Loss: 0.19923904538154602
train-epoch-step: 1-269 -- Loss: 0.26927030086517334
train-epoch-step: 1-270 -- Loss: 0.174363911151886
train-epoch-step: 1-271 -- Loss: 0.2625495195388794
train-epoch-step: 1-272 -- Loss: 0.19812160730361938
train-epoch-step: 1-273 -- Loss: 0.20433315634727478
train-epoch-step: 1-274 -- Loss: 0.3414446711540222
train-epoch-step: 1-275 -- Loss: 0.31566932797431946
train-epoch-step: 1-276 -- Loss: 0.23940737545490265
train-epoch-step: 1-277 -- Loss: 0.23363569378852844
train-epoch-step: 1-278 -- Loss: 0.24537517130374908
train-epoch-step: 1-279 -- Loss: 0.21715404093265533
train-epoch-step: 1-280 -- Loss: 0.3226969242095947
train-epoch-step: 1-281 -- Loss: 0.27399742603302
train-epoch-step: 1-282 -- Loss: 0.23682869970798492
train-epoch-step: 1-283 -- Loss: 0.1725464165210724
train-epoch-step: 1-284 -- Loss: 0.296495258808136
train-epoch-step: 1-285 -- Loss: 0.3196015954017639
train-epoch-step: 1-286 -- Loss: 0.24537119269371033
train-epoch-step: 1-287 -- Loss: 0.3419262170791626
train-epoch-step: 1-288 -- Loss: 0.165664404630661
train-epoch-step: 1-289 -- Loss: 0.20768395066261292
train-epoch-step: 1-290 -- Loss: 0.2900107502937317
train-epoch-step: 1-291 -- Loss: 0.1953202784061432
train-epoch-step: 1-292 -- Loss: 0.245755136013031
train-epoch-step: 1-293 -- Loss: 0.24216656386852264
train-epoch-step: 1-294 -- Loss: 0.28252241015434265
train-epoch-step: 1-295 -- Loss: 0.5188519954681396
train-epoch-step: 1-296 -- Loss: 0.3023747205734253
train-epoch-step: 1-297 -- Loss: 0.2830488085746765
train-epoch-step: 1-298 -- Loss: 0.38584184646606445
train-epoch-step: 1-299 -- Loss: 0.27799707651138306
train-epoch-step: 1-300 -- Loss: 0.2664371728897095
train-epoch-step: 1-301 -- Loss: 0.27796632051467896
train-epoch-step: 1-302 -- Loss: 0.3792799711227417
train-epoch-step: 1-303 -- Loss: 0.3518449068069458
train-epoch-step: 1-304 -- Loss: 0.2320549190044403
train-epoch-step: 1-305 -- Loss: 0.24278631806373596
train-epoch-step: 1-306 -- Loss: 0.4195833206176758
train-epoch-step: 1-307 -- Loss: 0.2651253342628479
train-epoch-step: 1-308 -- Loss: 0.42920154333114624
train-epoch-step: 1-309 -- Loss: 0.2674754559993744
train-epoch-step: 1-310 -- Loss: 0.23779171705245972
train-epoch-step: 1-311 -- Loss: 0.24967017769813538
train-epoch-step: 1-312 -- Loss: 0.32523906230926514
train-epoch-step: 1-313 -- Loss: 0.1575896441936493
train-epoch-step: 1-314 -- Loss: 0.3199208378791809
train-epoch-step: 1-315 -- Loss: 0.29689446091651917
train-epoch-step: 1-316 -- Loss: 0.2403266429901123
train-epoch-step: 1-317 -- Loss: 0.21387845277786255
train-epoch-step: 1-318 -- Loss: 0.2689601182937622
train-epoch-step: 1-319 -- Loss: 0.2726769745349884
train-epoch-step: 1-320 -- Loss: 0.18456199765205383
train-epoch-step: 1-321 -- Loss: 0.22172455489635468
train-epoch-step: 1-322 -- Loss: 0.3287675976753235
train-epoch-step: 1-323 -- Loss: 0.2462460696697235
train-epoch-step: 1-324 -- Loss: 0.41000479459762573
train-epoch-step: 1-325 -- Loss: 0.26213985681533813
train-epoch-step: 1-326 -- Loss: 0.3127388060092926
train-epoch-step: 1-327 -- Loss: 0.31152766942977905
train-epoch-step: 1-328 -- Loss: 0.33647745847702026
train-epoch-step: 1-329 -- Loss: 0.5235856771469116
train-epoch-step: 1-330 -- Loss: 0.5566213130950928
train-epoch-step: 1-331 -- Loss: 0.3490563631057739
train-epoch-step: 1-332 -- Loss: 0.1696995347738266
train-epoch-step: 1-333 -- Loss: 0.3072587549686432
train-epoch-step: 1-334 -- Loss: 0.2457529455423355
train-epoch-step: 1-335 -- Loss: 0.26677244901657104
train-epoch-step: 1-336 -- Loss: 0.2589036226272583
train-epoch-step: 1-337 -- Loss: 0.32040274143218994
train-epoch-step: 1-338 -- Loss: 0.2642391324043274
train-epoch-step: 1-339 -- Loss: 0.2312374860048294
train-epoch-step: 1-340 -- Loss: 0.3504977226257324
train-epoch-step: 1-341 -- Loss: 0.19998754560947418
train-epoch-step: 1-342 -- Loss: 0.24958372116088867
train-epoch-step: 1-343 -- Loss: 0.22691331803798676
train-epoch-step: 1-344 -- Loss: 0.2691401243209839
train-epoch-step: 1-345 -- Loss: 0.20823456346988678
train-epoch-step: 1-346 -- Loss: 0.31418994069099426
train-epoch-step: 1-347 -- Loss: 0.2689380347728729
train-epoch-step: 1-348 -- Loss: 0.33295243978500366
train-epoch-step: 1-349 -- Loss: 0.3397725820541382
train-epoch-step: 1-350 -- Loss: 0.4347810745239258
train-epoch-step: 1-351 -- Loss: 0.31527650356292725
train-epoch-step: 1-352 -- Loss: 0.23655086755752563
train-epoch-step: 1-353 -- Loss: 0.3372112512588501
train-epoch-step: 1-354 -- Loss: 0.43185657262802124
train-epoch-step: 1-355 -- Loss: 0.1789332628250122
train-epoch-step: 1-356 -- Loss: 0.18589945137500763
train-epoch-step: 1-357 -- Loss: 0.29983043670654297
train-epoch-step: 1-358 -- Loss: 0.27692845463752747
train-epoch-step: 1-359 -- Loss: 0.21097449958324432
train-epoch-step: 1-360 -- Loss: 0.21673583984375
train-epoch-step: 1-361 -- Loss: 0.43550246953964233
train-epoch-step: 1-362 -- Loss: 0.2489672303199768
train-epoch-step: 1-363 -- Loss: 0.18742845952510834
train-epoch-step: 1-364 -- Loss: 0.26953402161598206
train-epoch-step: 1-365 -- Loss: 0.2596778869628906
train-epoch-step: 1-366 -- Loss: 0.2978683114051819
train-epoch-step: 1-367 -- Loss: 0.3958910405635834
train-epoch-step: 1-368 -- Loss: 0.32702213525772095
train-epoch-step: 1-369 -- Loss: 0.4547143578529358
train-epoch-step: 1-370 -- Loss: 0.23033978044986725
train-epoch-step: 1-371 -- Loss: 0.19142155349254608
train-epoch-step: 1-372 -- Loss: 0.22182461619377136
train-epoch-step: 1-373 -- Loss: 0.3092912435531616
train-epoch-step: 1-374 -- Loss: 0.2452666461467743
train-epoch-step: 1-375 -- Loss: 0.4415815472602844
train-epoch-step: 1-376 -- Loss: 0.32215145230293274
train-epoch-step: 1-377 -- Loss: 0.4159270226955414
train-epoch-step: 1-378 -- Loss: 0.32730746269226074
train-epoch-step: 1-379 -- Loss: 0.17518913745880127
train-epoch-step: 1-380 -- Loss: 0.17775338888168335
train-epoch-step: 1-381 -- Loss: 0.3764139413833618
train-epoch-step: 1-382 -- Loss: 0.4348770081996918
train-epoch-step: 1-383 -- Loss: 0.36887121200561523
train-epoch-step: 1-384 -- Loss: 0.33438289165496826
train-epoch-step: 1-385 -- Loss: 0.2915211021900177
train-epoch-step: 1-386 -- Loss: 0.389778196811676
train-epoch-step: 1-387 -- Loss: 0.31891608238220215
train-epoch-step: 1-388 -- Loss: 0.31008514761924744
train-epoch-step: 1-389 -- Loss: 0.2929544746875763
train-epoch-step: 1-390 -- Loss: 0.23743483424186707
train-epoch-step: 1-391 -- Loss: 0.2386123687028885
train-epoch-step: 1-392 -- Loss: 0.2753902077674866
train-epoch-step: 1-393 -- Loss: 0.22696810960769653
train-epoch-step: 1-394 -- Loss: 0.34087759256362915
train-epoch-step: 1-395 -- Loss: 0.24374966323375702
train-epoch-step: 1-396 -- Loss: 0.1969096064567566
train-epoch-step: 1-397 -- Loss: 0.1826651394367218
train-epoch-step: 1-398 -- Loss: 0.2854682207107544
train-epoch-step: 1-399 -- Loss: 0.3255017101764679
train-epoch-step: 1-400 -- Loss: 0.4340997338294983
train-epoch-step: 1-401 -- Loss: 0.1791895031929016
train-epoch-step: 1-402 -- Loss: 0.4224034547805786
train-epoch-step: 1-403 -- Loss: 0.2630503475666046
train-epoch-step: 1-404 -- Loss: 0.22462019324302673
train-epoch-step: 1-405 -- Loss: 0.211405411362648
train-epoch-step: 1-406 -- Loss: 0.2410242259502411
train-epoch-step: 1-407 -- Loss: 0.16966570913791656
train-epoch-step: 1-408 -- Loss: 0.23284178972244263
train-epoch-step: 1-409 -- Loss: 0.27286431193351746
train-epoch-step: 1-410 -- Loss: 0.2949165999889374
train-epoch-step: 1-411 -- Loss: 0.32886505126953125
train-epoch-step: 1-412 -- Loss: 0.20134896039962769
train-epoch-step: 1-413 -- Loss: 0.22422368824481964
train-epoch-step: 1-414 -- Loss: 0.21966148912906647
train-epoch-step: 1-415 -- Loss: 0.19329553842544556
train-epoch-step: 1-416 -- Loss: 0.4753555655479431
train-epoch-step: 1-417 -- Loss: 0.31783801317214966
train-epoch-step: 1-418 -- Loss: 0.4315447211265564
train-epoch-step: 1-419 -- Loss: 0.27247118949890137
train-epoch-step: 1-420 -- Loss: 0.22177274525165558
train-epoch-step: 1-421 -- Loss: 0.25934672355651855
train-epoch-step: 1-422 -- Loss: 0.24565628170967102
train-epoch-step: 1-423 -- Loss: 0.27694642543792725
train-epoch-step: 1-424 -- Loss: 0.2154964655637741
train-epoch-step: 1-425 -- Loss: 0.27530646324157715
train-epoch-step: 1-426 -- Loss: 0.24656283855438232
train-epoch-step: 1-427 -- Loss: 0.20189538598060608
train-epoch-step: 1-428 -- Loss: 0.33044248819351196
train-epoch-step: 1-429 -- Loss: 0.29350268840789795
train-epoch-step: 1-430 -- Loss: 0.20161621272563934
train-epoch-step: 1-431 -- Loss: 0.26012715697288513
train-epoch-step: 1-432 -- Loss: 0.43612831830978394
train-epoch-step: 1-433 -- Loss: 0.23005832731723785
train-epoch-step: 1-434 -- Loss: 0.25037461519241333
train-epoch-step: 1-435 -- Loss: 0.25729578733444214
train-epoch-step: 1-436 -- Loss: 0.23494230210781097
train-epoch-step: 1-437 -- Loss: 0.19881311058998108
train-epoch-step: 1-438 -- Loss: 0.2830676734447479
train-epoch-step: 1-439 -- Loss: 0.5258079767227173
train-epoch-step: 1-440 -- Loss: 0.22992029786109924
train-epoch-step: 1-441 -- Loss: 0.34425437450408936
train-epoch-step: 1-442 -- Loss: 0.2806415557861328
train-epoch-step: 1-443 -- Loss: 0.24079377949237823
train-epoch-step: 1-444 -- Loss: 0.37141168117523193
train-epoch-step: 1-445 -- Loss: 0.32209834456443787
train-epoch-step: 1-446 -- Loss: 0.22384671866893768
train-epoch-step: 1-447 -- Loss: 0.32008856534957886
train-epoch-step: 1-448 -- Loss: 0.38338008522987366
train-epoch-step: 1-449 -- Loss: 0.2689782977104187
train-epoch-step: 1-450 -- Loss: 0.29392507672309875
train-epoch-step: 1-451 -- Loss: 0.22265006601810455
train-epoch-step: 1-452 -- Loss: 0.20567463338375092
train-epoch-step: 1-453 -- Loss: 0.1517810970544815
train-epoch-step: 1-454 -- Loss: 0.3643728494644165
train-epoch-step: 1-455 -- Loss: 0.21638941764831543
train-epoch-step: 1-456 -- Loss: 0.18531978130340576
train-epoch-step: 1-457 -- Loss: 0.34001287817955017
train-epoch-step: 1-458 -- Loss: 0.2542872428894043
train-epoch-step: 1-459 -- Loss: 0.3545452952384949
train-epoch-step: 1-460 -- Loss: 0.19992417097091675
train-epoch-step: 1-461 -- Loss: 0.22390398383140564
train-epoch-step: 1-462 -- Loss: 0.23480454087257385
train-epoch-step: 1-463 -- Loss: 0.21593761444091797
train-epoch-step: 1-464 -- Loss: 0.31825876235961914
train-epoch-step: 1-465 -- Loss: 0.6043437123298645
train-epoch-step: 1-466 -- Loss: 0.30694258213043213
train-epoch-step: 1-467 -- Loss: 0.17191675305366516
train-epoch-step: 1-468 -- Loss: 0.3013797998428345
train-epoch-step: 1-469 -- Loss: 0.394000768661499
train-epoch-step: 1-470 -- Loss: 0.2606523931026459
train-epoch-step: 1-471 -- Loss: 0.24407677352428436
train-epoch-step: 1-472 -- Loss: 0.23811861872673035
train-epoch-step: 1-473 -- Loss: 0.24884924292564392
train-epoch-step: 1-474 -- Loss: 0.17996713519096375
train-epoch-step: 1-475 -- Loss: 0.172176331281662
train-epoch-step: 1-476 -- Loss: 0.318273663520813
train-epoch-step: 1-477 -- Loss: 0.3433534801006317
train-epoch-step: 1-478 -- Loss: 0.2909393310546875
train-epoch-step: 1-479 -- Loss: 0.20361065864562988
train-epoch-step: 1-480 -- Loss: 0.3562363386154175
train-epoch-step: 1-481 -- Loss: 0.4383886456489563
train-epoch-step: 1-482 -- Loss: 0.37367796897888184
train-epoch-step: 1-483 -- Loss: 0.29318881034851074
train-epoch-step: 1-484 -- Loss: 0.31166473031044006
train-epoch-step: 1-485 -- Loss: 0.20469927787780762
train-epoch-step: 1-486 -- Loss: 0.3668229579925537
train-epoch-step: 1-487 -- Loss: 0.3746125102043152
train-epoch-step: 1-488 -- Loss: 0.2858690619468689
train-epoch-step: 1-489 -- Loss: 0.32041025161743164
train-epoch-step: 1-490 -- Loss: 0.21534019708633423
train-epoch-step: 1-491 -- Loss: 0.20163440704345703
train-epoch-step: 1-492 -- Loss: 0.19053679704666138
train-epoch-step: 1-493 -- Loss: 0.3303634524345398
train-epoch-step: 1-494 -- Loss: 0.30859673023223877
train-epoch-step: 1-495 -- Loss: 0.3413911759853363
train-epoch-step: 1-496 -- Loss: 0.1917857974767685
train-epoch-step: 1-497 -- Loss: 0.34154409170150757
train-epoch-step: 1-498 -- Loss: 0.2217904031276703
train-epoch-step: 1-499 -- Loss: 0.2543282210826874
train-epoch-step: 1-500 -- Loss: 0.23348994553089142
train-epoch-step: 1-501 -- Loss: 0.30632519721984863
train-epoch-step: 1-502 -- Loss: 0.2929394543170929
train-epoch-step: 1-503 -- Loss: 0.3438549041748047
train-epoch-step: 1-504 -- Loss: 0.16998820006847382
train-epoch-step: 1-505 -- Loss: 0.2704553008079529
train-epoch-step: 1-506 -- Loss: 0.17980113625526428
train-epoch-step: 1-507 -- Loss: 0.30397462844848633
train-epoch-step: 1-508 -- Loss: 0.26735252141952515
train-epoch-step: 1-509 -- Loss: 0.25982409715652466
train-epoch-step: 1-510 -- Loss: 0.22081664204597473
train-epoch-step: 1-511 -- Loss: 0.3167976140975952
train-epoch-step: 1-512 -- Loss: 0.3326696753501892
train-epoch-step: 1-513 -- Loss: 0.2899131774902344
train-epoch-step: 1-514 -- Loss: 0.2325761616230011
train-epoch-step: 1-515 -- Loss: 0.25647586584091187
train-epoch-step: 1-516 -- Loss: 0.2504279911518097
train-epoch-step: 1-517 -- Loss: 0.288850873708725
train-epoch-step: 1-518 -- Loss: 0.21262574195861816
train-epoch-step: 1-519 -- Loss: 0.21623127162456512
train-epoch-step: 1-520 -- Loss: 0.2757021486759186
train-epoch-step: 1-521 -- Loss: 0.3663877248764038
train-epoch-step: 1-522 -- Loss: 0.31387099623680115
train-epoch-step: 1-523 -- Loss: 0.2510029673576355
train-epoch-step: 1-524 -- Loss: 0.2541327476501465
train-epoch-step: 1-525 -- Loss: 0.3524310886859894
train-epoch-step: 1-526 -- Loss: 0.1962539404630661
train-epoch-step: 1-527 -- Loss: 0.2493351697921753
train-epoch-step: 1-528 -- Loss: 0.24260643124580383
train-epoch-step: 1-529 -- Loss: 0.272494375705719
train-epoch-step: 1-530 -- Loss: 0.26186585426330566
train-epoch-step: 1-531 -- Loss: 0.32781174778938293
train-epoch-step: 1-532 -- Loss: 0.2716194987297058
train-epoch-step: 1-533 -- Loss: 0.2562250792980194
train-epoch-step: 1-534 -- Loss: 0.1909053474664688
train-epoch-step: 1-535 -- Loss: 0.5092736482620239
train-epoch-step: 1-536 -- Loss: 0.2357131540775299
train-epoch-step: 1-537 -- Loss: 0.22936740517616272
train-epoch-step: 1-538 -- Loss: 0.163117915391922
train-epoch-step: 1-539 -- Loss: 0.28272807598114014
train-epoch-step: 1-540 -- Loss: 0.18758702278137207
train-epoch-step: 1-541 -- Loss: 0.33582183718681335
train-epoch-step: 1-542 -- Loss: 0.36518368124961853
train-epoch-step: 1-543 -- Loss: 0.2651274502277374
train-epoch-step: 1-544 -- Loss: 0.33314353227615356
train-epoch-step: 1-545 -- Loss: 0.2922501862049103
train-epoch-step: 1-546 -- Loss: 0.37514954805374146
train-epoch-step: 1-547 -- Loss: 0.2716226875782013
train-epoch-step: 1-548 -- Loss: 0.14183309674263
train-epoch-step: 1-549 -- Loss: 0.2489849478006363
train-epoch-step: 1-550 -- Loss: 0.29119056463241577
train-epoch-step: 1-551 -- Loss: 0.24911198019981384
train-epoch-step: 1-552 -- Loss: 0.18399187922477722
train-epoch-step: 1-553 -- Loss: 0.3016453981399536
train-epoch-step: 1-554 -- Loss: 0.28397315740585327
train-epoch-step: 1-555 -- Loss: 0.5460926294326782
train-epoch-step: 1-556 -- Loss: 0.25672242045402527
train-epoch-step: 1-557 -- Loss: 0.38336870074272156
train-epoch-step: 1-558 -- Loss: 0.41679221391677856
train-epoch-step: 1-559 -- Loss: 0.2226186990737915
train-epoch-step: 1-560 -- Loss: 0.3107756972312927
train-epoch-step: 1-561 -- Loss: 0.36600738763809204
train-epoch-step: 1-562 -- Loss: 0.3051128685474396
train-epoch-step: 1-563 -- Loss: 0.2813781499862671
train-epoch-step: 1-564 -- Loss: 0.1649411916732788
train-epoch-step: 1-565 -- Loss: 0.28353798389434814
train-epoch-step: 1-566 -- Loss: 0.2399872988462448
train-epoch-step: 1-567 -- Loss: 0.2973291873931885
train-epoch-step: 1-568 -- Loss: 0.2585969865322113
train-epoch-step: 1-569 -- Loss: 0.32421374320983887
train-epoch-step: 1-570 -- Loss: 0.2562963366508484
train-epoch-step: 1-571 -- Loss: 0.3054482042789459
train-epoch-step: 1-572 -- Loss: 0.35254207253456116
train-epoch-step: 1-573 -- Loss: 0.3076169490814209
train-epoch-step: 1-574 -- Loss: 0.39638879895210266
train-epoch-step: 1-575 -- Loss: 0.46370887756347656
train-epoch-step: 1-576 -- Loss: 0.1935240924358368
train-epoch-step: 1-577 -- Loss: 0.23991386592388153
train-epoch-step: 1-578 -- Loss: 0.3421001136302948
train-epoch-step: 1-579 -- Loss: 0.2447449117898941
train-epoch-step: 1-580 -- Loss: 0.29186925292015076
train-epoch-step: 1-581 -- Loss: 0.20020700991153717
train-epoch-step: 1-582 -- Loss: 0.3555925488471985
train-epoch-step: 1-583 -- Loss: 0.3337269127368927
train-epoch-step: 1-584 -- Loss: 0.2873477339744568
train-epoch-step: 1-585 -- Loss: 0.27836835384368896
train-epoch-step: 1-586 -- Loss: 0.39090031385421753
train-epoch-step: 1-587 -- Loss: 0.2565624415874481
train-epoch-step: 1-588 -- Loss: 0.1995393931865692
val-epoch-step: 1-589 -- Loss: 0.35400256514549255
val-epoch-step: 1-590 -- Loss: 0.21296709775924683
val-epoch-step: 1-591 -- Loss: 0.32415467500686646
val-epoch-step: 1-592 -- Loss: 0.2557699680328369
val-epoch-step: 1-593 -- Loss: 0.2116495966911316
val-epoch-step: 1-594 -- Loss: 0.4487566649913788
val-epoch-step: 1-595 -- Loss: 0.2488449513912201
val-epoch-step: 1-596 -- Loss: 0.2937051057815552
val-epoch-step: 1-597 -- Loss: 0.2809476852416992
val-epoch-step: 1-598 -- Loss: 0.23347975313663483
val-epoch-step: 1-599 -- Loss: 0.2665311098098755
val-epoch-step: 1-600 -- Loss: 0.2582562565803528
val-epoch-step: 1-601 -- Loss: 0.2091422826051712
val-epoch-step: 1-602 -- Loss: 0.2155551314353943
val-epoch-step: 1-603 -- Loss: 0.31573134660720825
val-epoch-step: 1-604 -- Loss: 0.19505810737609863
val-epoch-step: 1-605 -- Loss: 0.21410709619522095
val-epoch-step: 1-606 -- Loss: 0.44222426414489746
val-epoch-step: 1-607 -- Loss: 0.2167908251285553
val-epoch-step: 1-608 -- Loss: 0.3611159920692444
val-epoch-step: 1-609 -- Loss: 0.25985652208328247
val-epoch-step: 1-610 -- Loss: 0.30301013588905334
val-epoch-step: 1-611 -- Loss: 0.23692116141319275
val-epoch-step: 1-612 -- Loss: 0.4051674008369446
val-epoch-step: 1-613 -- Loss: 0.25610464811325073
val-epoch-step: 1-614 -- Loss: 0.21628180146217346
val-epoch-step: 1-615 -- Loss: 0.2766400873661041
val-epoch-step: 1-616 -- Loss: 0.20336776971817017
val-epoch-step: 1-617 -- Loss: 0.3293811082839966
val-epoch-step: 1-618 -- Loss: 0.27391141653060913
val-epoch-step: 1-619 -- Loss: 0.3076443076133728
val-epoch-step: 1-620 -- Loss: 0.20693561434745789
val-epoch-step: 1-621 -- Loss: 0.20299388468265533
val-epoch-step: 1-622 -- Loss: 0.20724280178546906
val-epoch-step: 1-623 -- Loss: 0.22522373497486115
val-epoch-step: 1-624 -- Loss: 0.24052020907402039
val-epoch-step: 1-625 -- Loss: 0.21824797987937927
val-epoch-step: 1-626 -- Loss: 0.23166215419769287
val-epoch-step: 1-627 -- Loss: 0.2810344099998474
val-epoch-step: 1-628 -- Loss: 0.5204634666442871
val-epoch-step: 1-629 -- Loss: 0.2903839945793152
val-epoch-step: 1-630 -- Loss: 0.4974520206451416
val-epoch-step: 1-631 -- Loss: 0.21826171875
val-epoch-step: 1-632 -- Loss: 0.2753017544746399
val-epoch-step: 1-633 -- Loss: 0.22411134839057922
val-epoch-step: 1-634 -- Loss: 0.20425155758857727
val-epoch-step: 1-635 -- Loss: 0.15683406591415405
val-epoch-step: 1-636 -- Loss: 0.23327986896038055
val-epoch-step: 1-637 -- Loss: 0.2713063061237335
val-epoch-step: 1-638 -- Loss: 0.22145625948905945
val-epoch-step: 1-639 -- Loss: 0.35619235038757324
val-epoch-step: 1-640 -- Loss: 0.37358665466308594
val-epoch-step: 1-641 -- Loss: 0.18441151082515717
val-epoch-step: 1-642 -- Loss: 0.2829311490058899
val-epoch-step: 1-643 -- Loss: 0.28406763076782227
val-epoch-step: 1-644 -- Loss: 0.25238460302352905
val-epoch-step: 1-645 -- Loss: 0.32246267795562744
val-epoch-step: 1-646 -- Loss: 0.2154422104358673
val-epoch-step: 1-647 -- Loss: 0.1984611451625824
val-epoch-step: 1-648 -- Loss: 0.23988589644432068
val-epoch-step: 1-649 -- Loss: 0.4988090991973877
val-epoch-step: 1-650 -- Loss: 0.3575856685638428
val-epoch-step: 1-651 -- Loss: 0.19510065019130707
val-epoch-step: 1-652 -- Loss: 0.2237483710050583
val-epoch-step: 1-653 -- Loss: 0.27702978253364563
val-epoch-step: 1-654 -- Loss: 0.15933245420455933
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100690126419067
train-epoch-step: 1-4 -- Loss: 1.5449962615966797
train-epoch-step: 1-5 -- Loss: 1.499272108078003
train-epoch-step: 1-6 -- Loss: 1.6029880046844482
train-epoch-step: 1-7 -- Loss: 1.4446882009506226
train-epoch-step: 1-8 -- Loss: 1.4407985210418701
train-epoch-step: 1-9 -- Loss: 1.4630786180496216
train-epoch-step: 1-10 -- Loss: 1.4210119247436523
train-epoch-step: 1-11 -- Loss: 1.2646315097808838
train-epoch-step: 1-12 -- Loss: 1.18257737159729
train-epoch-step: 1-13 -- Loss: 1.216294765472412
train-epoch-step: 1-14 -- Loss: 1.0300441980361938
train-epoch-step: 1-15 -- Loss: 0.9768474102020264
train-epoch-step: 1-16 -- Loss: 0.9235150814056396
train-epoch-step: 1-17 -- Loss: 0.9747445583343506
train-epoch-step: 1-18 -- Loss: 0.834835410118103
train-epoch-step: 1-19 -- Loss: 0.6831591129302979
train-epoch-step: 1-20 -- Loss: 0.780398964881897
train-epoch-step: 1-21 -- Loss: 0.840986430644989
train-epoch-step: 1-22 -- Loss: 0.5576072931289673
train-epoch-step: 1-23 -- Loss: 0.5641975402832031
train-epoch-step: 1-24 -- Loss: 0.4786152243614197
train-epoch-step: 1-25 -- Loss: 0.6166308522224426
train-epoch-step: 1-26 -- Loss: 0.5281051397323608
train-epoch-step: 1-27 -- Loss: 0.7720872163772583
train-epoch-step: 1-28 -- Loss: 0.3746895492076874
train-epoch-step: 1-29 -- Loss: 0.5497219562530518
train-epoch-step: 1-30 -- Loss: 0.2907765507698059
train-epoch-step: 1-31 -- Loss: 0.3573285937309265
train-epoch-step: 1-32 -- Loss: 0.41262707114219666
train-epoch-step: 1-33 -- Loss: 0.6394543051719666
train-epoch-step: 1-34 -- Loss: 0.40493839979171753
train-epoch-step: 1-35 -- Loss: 0.54270339012146
train-epoch-step: 1-36 -- Loss: 0.36314111948013306
train-epoch-step: 1-37 -- Loss: 0.3562553822994232
train-epoch-step: 1-38 -- Loss: 0.40436622500419617
train-epoch-step: 1-39 -- Loss: 0.5126458406448364
train-epoch-step: 1-40 -- Loss: 0.455963134765625
train-epoch-step: 1-41 -- Loss: 0.48735231161117554
train-epoch-step: 1-42 -- Loss: 0.3589908480644226
train-epoch-step: 1-43 -- Loss: 0.6815117597579956
train-epoch-step: 1-44 -- Loss: 0.2953871488571167
train-epoch-step: 1-45 -- Loss: 0.27350518107414246
train-epoch-step: 1-46 -- Loss: 0.3961295485496521
train-epoch-step: 1-47 -- Loss: 0.4332439601421356
train-epoch-step: 1-48 -- Loss: 0.34063488245010376
train-epoch-step: 1-49 -- Loss: 0.42341509461402893
train-epoch-step: 1-50 -- Loss: 0.28172627091407776
train-epoch-step: 1-51 -- Loss: 0.3977012038230896
train-epoch-step: 1-52 -- Loss: 0.31133463978767395
train-epoch-step: 1-53 -- Loss: 0.4747486710548401
train-epoch-step: 1-54 -- Loss: 0.5794345140457153
train-epoch-step: 1-55 -- Loss: 0.36206650733947754
train-epoch-step: 1-56 -- Loss: 0.40710723400115967
train-epoch-step: 1-57 -- Loss: 0.5258665084838867
train-epoch-step: 1-58 -- Loss: 0.52080899477005
train-epoch-step: 1-59 -- Loss: 0.519692599773407
train-epoch-step: 1-60 -- Loss: 0.26057636737823486
train-epoch-step: 1-61 -- Loss: 0.40518873929977417
train-epoch-step: 1-62 -- Loss: 0.35873928666114807
train-epoch-step: 1-63 -- Loss: 0.2789250612258911
train-epoch-step: 1-64 -- Loss: 0.3360220789909363
train-epoch-step: 1-65 -- Loss: 0.37686988711357117
train-epoch-step: 1-66 -- Loss: 0.21497265994548798
train-epoch-step: 1-67 -- Loss: 0.25164902210235596
train-epoch-step: 1-68 -- Loss: 0.4406765103340149
train-epoch-step: 1-69 -- Loss: 0.25871315598487854
train-epoch-step: 1-70 -- Loss: 0.48906269669532776
train-epoch-step: 1-71 -- Loss: 0.5695140361785889
train-epoch-step: 1-72 -- Loss: 0.3418917655944824
train-epoch-step: 1-73 -- Loss: 0.41121888160705566
train-epoch-step: 1-74 -- Loss: 0.1984509974718094
train-epoch-step: 1-75 -- Loss: 0.2803128957748413
train-epoch-step: 1-76 -- Loss: 0.28450655937194824
train-epoch-step: 1-77 -- Loss: 0.3935283422470093
train-epoch-step: 1-78 -- Loss: 0.5095970630645752
train-epoch-step: 1-79 -- Loss: 0.36971357464790344
train-epoch-step: 1-80 -- Loss: 0.44924142956733704
train-epoch-step: 1-81 -- Loss: 0.27833282947540283
train-epoch-step: 1-82 -- Loss: 0.4586225748062134
train-epoch-step: 1-83 -- Loss: 0.3513871133327484
train-epoch-step: 1-84 -- Loss: 0.38743409514427185
train-epoch-step: 1-85 -- Loss: 0.33559006452560425
train-epoch-step: 1-86 -- Loss: 0.21885818243026733
train-epoch-step: 1-87 -- Loss: 0.40017950534820557
train-epoch-step: 1-88 -- Loss: 0.264741986989975
train-epoch-step: 1-89 -- Loss: 0.32841411232948303
train-epoch-step: 1-90 -- Loss: 0.34777307510375977
train-epoch-step: 1-91 -- Loss: 0.4359191060066223
train-epoch-step: 1-92 -- Loss: 0.3022615611553192
train-epoch-step: 1-93 -- Loss: 0.33389538526535034
train-epoch-step: 1-94 -- Loss: 0.45617493987083435
train-epoch-step: 1-95 -- Loss: 0.36699771881103516
train-epoch-step: 1-96 -- Loss: 0.3857916593551636
train-epoch-step: 1-97 -- Loss: 0.35083067417144775
train-epoch-step: 1-98 -- Loss: 0.2951169013977051
train-epoch-step: 1-99 -- Loss: 0.31446373462677
train-epoch-step: 1-100 -- Loss: 0.35022681951522827
train-epoch-step: 1-101 -- Loss: 0.4423534870147705
train-epoch-step: 1-102 -- Loss: 0.478071391582489
train-epoch-step: 1-103 -- Loss: 0.36932530999183655
train-epoch-step: 1-104 -- Loss: 0.2868741750717163
train-epoch-step: 1-105 -- Loss: 0.6599268913269043
train-epoch-step: 1-106 -- Loss: 0.32287582755088806
train-epoch-step: 1-107 -- Loss: 0.373005747795105
train-epoch-step: 1-108 -- Loss: 0.3292408883571625
train-epoch-step: 1-109 -- Loss: 0.2770187556743622
train-epoch-step: 1-110 -- Loss: 0.32699012756347656
train-epoch-step: 1-111 -- Loss: 0.3445613980293274
train-epoch-step: 1-112 -- Loss: 0.2739231288433075
train-epoch-step: 1-113 -- Loss: 0.366394579410553
train-epoch-step: 1-114 -- Loss: 0.39212262630462646
train-epoch-step: 1-115 -- Loss: 0.27791261672973633
train-epoch-step: 1-116 -- Loss: 0.2515617907047272
train-epoch-step: 1-117 -- Loss: 0.2387426495552063
train-epoch-step: 1-118 -- Loss: 0.3557126522064209
train-epoch-step: 1-119 -- Loss: 0.25794023275375366
train-epoch-step: 1-120 -- Loss: 0.439728319644928
train-epoch-step: 1-121 -- Loss: 0.4069685637950897
train-epoch-step: 1-122 -- Loss: 0.38437533378601074
train-epoch-step: 1-123 -- Loss: 0.37773001194000244
train-epoch-step: 1-124 -- Loss: 0.22312526404857635
train-epoch-step: 1-125 -- Loss: 0.24814832210540771
train-epoch-step: 1-126 -- Loss: 0.3953840732574463
train-epoch-step: 1-127 -- Loss: 0.28109097480773926
train-epoch-step: 1-128 -- Loss: 0.329668790102005
train-epoch-step: 1-129 -- Loss: 0.23548054695129395
train-epoch-step: 1-130 -- Loss: 0.3172680735588074
train-epoch-step: 1-131 -- Loss: 0.2395612895488739
train-epoch-step: 1-132 -- Loss: 0.32845935225486755
train-epoch-step: 1-133 -- Loss: 0.20353452861309052
train-epoch-step: 1-134 -- Loss: 0.3451274335384369
train-epoch-step: 1-135 -- Loss: 0.2169715017080307
train-epoch-step: 1-136 -- Loss: 0.2048228681087494
train-epoch-step: 1-137 -- Loss: 0.4333662688732147
train-epoch-step: 1-138 -- Loss: 0.49531567096710205
train-epoch-step: 1-139 -- Loss: 0.23960360884666443
train-epoch-step: 1-140 -- Loss: 0.39616236090660095
train-epoch-step: 1-141 -- Loss: 0.41024893522262573
train-epoch-step: 1-142 -- Loss: 0.3612675964832306
train-epoch-step: 1-143 -- Loss: 0.31828251481056213
train-epoch-step: 1-144 -- Loss: 0.33755266666412354
train-epoch-step: 1-145 -- Loss: 0.25384852290153503
train-epoch-step: 1-146 -- Loss: 0.3177417516708374
train-epoch-step: 1-147 -- Loss: 0.33994361758232117
train-epoch-step: 1-148 -- Loss: 0.28709858655929565
train-epoch-step: 1-149 -- Loss: 0.20410999655723572
train-epoch-step: 1-150 -- Loss: 0.34134113788604736
train-epoch-step: 1-151 -- Loss: 0.35870856046676636
train-epoch-step: 1-152 -- Loss: 0.3349071741104126
train-epoch-step: 1-153 -- Loss: 0.4921466112136841
train-epoch-step: 1-154 -- Loss: 0.24945728480815887
train-epoch-step: 1-155 -- Loss: 0.2501351237297058
train-epoch-step: 1-156 -- Loss: 0.2118891477584839
train-epoch-step: 1-157 -- Loss: 0.284054696559906
train-epoch-step: 1-158 -- Loss: 0.30978429317474365
train-epoch-step: 1-159 -- Loss: 0.30266374349594116
train-epoch-step: 1-160 -- Loss: 0.3591887950897217
train-epoch-step: 1-161 -- Loss: 0.3569917678833008
train-epoch-step: 1-162 -- Loss: 0.39783912897109985
train-epoch-step: 1-163 -- Loss: 0.3341082036495209
train-epoch-step: 1-164 -- Loss: 0.314158171415329
train-epoch-step: 1-165 -- Loss: 0.27534642815589905
train-epoch-step: 1-166 -- Loss: 0.2125261425971985
train-epoch-step: 1-167 -- Loss: 0.2030649483203888
train-epoch-step: 1-168 -- Loss: 0.3409343957901001
train-epoch-step: 1-169 -- Loss: 0.2370852828025818
train-epoch-step: 1-170 -- Loss: 0.36710214614868164
train-epoch-step: 1-171 -- Loss: 0.29432499408721924
train-epoch-step: 1-172 -- Loss: 0.4376782476902008
train-epoch-step: 1-173 -- Loss: 0.22998952865600586
train-epoch-step: 1-174 -- Loss: 0.46249645948410034
train-epoch-step: 1-175 -- Loss: 0.34259307384490967
train-epoch-step: 1-176 -- Loss: 0.23474138975143433
train-epoch-step: 1-177 -- Loss: 0.3084680736064911
train-epoch-step: 1-178 -- Loss: 0.3069736659526825
train-epoch-step: 1-179 -- Loss: 0.23429182171821594
train-epoch-step: 1-180 -- Loss: 0.2492377758026123
train-epoch-step: 1-181 -- Loss: 0.3189253509044647
train-epoch-step: 1-182 -- Loss: 0.3303077816963196
train-epoch-step: 1-183 -- Loss: 0.7102672457695007
train-epoch-step: 1-184 -- Loss: 0.25875550508499146
train-epoch-step: 1-185 -- Loss: 0.24390533566474915
train-epoch-step: 1-186 -- Loss: 0.3342580795288086
train-epoch-step: 1-187 -- Loss: 0.38065066933631897
train-epoch-step: 1-188 -- Loss: 0.3403598368167877
train-epoch-step: 1-189 -- Loss: 0.2405647337436676
train-epoch-step: 1-190 -- Loss: 0.28522348403930664
train-epoch-step: 1-191 -- Loss: 0.29108262062072754
train-epoch-step: 1-192 -- Loss: 0.41190004348754883
train-epoch-step: 1-193 -- Loss: 0.4181916117668152
train-epoch-step: 1-194 -- Loss: 0.33865004777908325
train-epoch-step: 1-195 -- Loss: 0.33281201124191284
train-epoch-step: 1-196 -- Loss: 0.29755836725234985
train-epoch-step: 1-197 -- Loss: 0.21841961145401
train-epoch-step: 1-198 -- Loss: 0.20993861556053162
train-epoch-step: 1-199 -- Loss: 0.27391737699508667
train-epoch-step: 1-200 -- Loss: 0.20535235106945038
train-epoch-step: 1-201 -- Loss: 0.33648642897605896
train-epoch-step: 1-202 -- Loss: 0.22354651987552643
train-epoch-step: 1-203 -- Loss: 0.30412358045578003
train-epoch-step: 1-204 -- Loss: 0.26364168524742126
train-epoch-step: 1-205 -- Loss: 0.2963632345199585
train-epoch-step: 1-206 -- Loss: 0.3582689166069031
train-epoch-step: 1-207 -- Loss: 0.23106765747070312
train-epoch-step: 1-208 -- Loss: 0.2942918539047241
train-epoch-step: 1-209 -- Loss: 0.2343427687883377
train-epoch-step: 1-210 -- Loss: 0.23021334409713745
train-epoch-step: 1-211 -- Loss: 0.35767701268196106
train-epoch-step: 1-212 -- Loss: 0.32792049646377563
train-epoch-step: 1-213 -- Loss: 0.2258864939212799
train-epoch-step: 1-214 -- Loss: 0.2546980381011963
train-epoch-step: 1-215 -- Loss: 0.22391033172607422
train-epoch-step: 1-216 -- Loss: 0.3073895275592804
train-epoch-step: 1-217 -- Loss: 0.38213446736335754
train-epoch-step: 1-218 -- Loss: 0.2637585997581482
train-epoch-step: 1-219 -- Loss: 0.34237903356552124
train-epoch-step: 1-220 -- Loss: 0.21731004118919373
train-epoch-step: 1-221 -- Loss: 0.3812805414199829
train-epoch-step: 1-222 -- Loss: 0.2139437347650528
train-epoch-step: 1-223 -- Loss: 0.288288414478302
train-epoch-step: 1-224 -- Loss: 0.29607558250427246
train-epoch-step: 1-225 -- Loss: 0.4767065644264221
train-epoch-step: 1-226 -- Loss: 0.3438093066215515
train-epoch-step: 1-227 -- Loss: 0.3770471215248108
train-epoch-step: 1-228 -- Loss: 0.29128924012184143
train-epoch-step: 1-229 -- Loss: 0.35636061429977417
train-epoch-step: 1-230 -- Loss: 0.27713948488235474
train-epoch-step: 1-231 -- Loss: 0.3018820881843567
train-epoch-step: 1-232 -- Loss: 0.30489906668663025
train-epoch-step: 1-233 -- Loss: 0.1587626039981842
train-epoch-step: 1-234 -- Loss: 0.29077720642089844
train-epoch-step: 1-235 -- Loss: 0.26120951771736145
train-epoch-step: 1-236 -- Loss: 0.3050772249698639
train-epoch-step: 1-237 -- Loss: 0.40938806533813477
train-epoch-step: 1-238 -- Loss: 0.2705235183238983
train-epoch-step: 1-239 -- Loss: 0.23505862057209015
train-epoch-step: 1-240 -- Loss: 0.3684965968132019
train-epoch-step: 1-241 -- Loss: 0.2628232538700104
train-epoch-step: 1-242 -- Loss: 0.36360836029052734
train-epoch-step: 1-243 -- Loss: 0.4125421345233917
train-epoch-step: 1-244 -- Loss: 0.35322052240371704
train-epoch-step: 1-245 -- Loss: 0.3950028121471405
train-epoch-step: 1-246 -- Loss: 0.44730478525161743
train-epoch-step: 1-247 -- Loss: 0.3995700478553772
train-epoch-step: 1-248 -- Loss: 0.28028643131256104
train-epoch-step: 1-249 -- Loss: 0.23025831580162048
train-epoch-step: 1-250 -- Loss: 0.4072979688644409
train-epoch-step: 1-251 -- Loss: 0.1930725872516632
train-epoch-step: 1-252 -- Loss: 0.2837449014186859
train-epoch-step: 1-253 -- Loss: 0.21442240476608276
train-epoch-step: 1-254 -- Loss: 0.386690229177475
train-epoch-step: 1-255 -- Loss: 0.22425733506679535
train-epoch-step: 1-256 -- Loss: 0.2331424504518509
train-epoch-step: 1-257 -- Loss: 0.2882785201072693
train-epoch-step: 1-258 -- Loss: 0.2779936194419861
train-epoch-step: 1-259 -- Loss: 0.17573168873786926
train-epoch-step: 1-260 -- Loss: 0.343575119972229
train-epoch-step: 1-261 -- Loss: 0.26420316100120544
train-epoch-step: 1-262 -- Loss: 0.48394644260406494
train-epoch-step: 1-263 -- Loss: 0.3909781575202942
train-epoch-step: 1-264 -- Loss: 0.2686275541782379
train-epoch-step: 1-265 -- Loss: 0.184921532869339
train-epoch-step: 1-266 -- Loss: 0.24105429649353027
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100691318511963
train-epoch-step: 1-4 -- Loss: 1.544996738433838
train-epoch-step: 1-5 -- Loss: 1.4992706775665283
train-epoch-step: 1-6 -- Loss: 1.6029870510101318
train-epoch-step: 1-7 -- Loss: 1.4446864128112793
train-epoch-step: 1-8 -- Loss: 1.4407906532287598
train-epoch-step: 1-9 -- Loss: 1.4630968570709229
train-epoch-step: 1-10 -- Loss: 1.4210761785507202
train-epoch-step: 1-11 -- Loss: 1.2647422552108765
train-epoch-step: 1-12 -- Loss: 1.182734489440918
train-epoch-step: 1-13 -- Loss: 1.2165231704711914
train-epoch-step: 1-14 -- Loss: 1.0303232669830322
train-epoch-step: 1-15 -- Loss: 0.9770612716674805
train-epoch-step: 1-16 -- Loss: 0.9239329099655151
train-epoch-step: 1-17 -- Loss: 0.9749822616577148
train-epoch-step: 1-18 -- Loss: 0.8356625437736511
train-epoch-step: 1-19 -- Loss: 0.684181809425354
train-epoch-step: 1-20 -- Loss: 0.7814659476280212
train-epoch-step: 1-21 -- Loss: 0.8423659801483154
train-epoch-step: 1-22 -- Loss: 0.5589580535888672
train-epoch-step: 1-23 -- Loss: 0.5649972558021545
train-epoch-step: 1-24 -- Loss: 0.47949522733688354
train-epoch-step: 1-25 -- Loss: 0.6177389621734619
train-epoch-step: 1-26 -- Loss: 0.5284720659255981
train-epoch-step: 1-27 -- Loss: 0.7723042368888855
train-epoch-step: 1-28 -- Loss: 0.3750719428062439
train-epoch-step: 1-29 -- Loss: 0.5500078797340393
train-epoch-step: 1-30 -- Loss: 0.2908482253551483
train-epoch-step: 1-31 -- Loss: 0.35750600695610046
train-epoch-step: 1-32 -- Loss: 0.4130726754665375
train-epoch-step: 1-33 -- Loss: 0.6394143104553223
train-epoch-step: 1-34 -- Loss: 0.4051802456378937
train-epoch-step: 1-35 -- Loss: 0.5426152348518372
train-epoch-step: 1-36 -- Loss: 0.3630913496017456
train-epoch-step: 1-37 -- Loss: 0.3555752635002136
train-epoch-step: 1-38 -- Loss: 0.4044644832611084
train-epoch-step: 1-39 -- Loss: 0.5127242803573608
train-epoch-step: 1-40 -- Loss: 0.45474278926849365
train-epoch-step: 1-41 -- Loss: 0.4875727593898773
train-epoch-step: 1-42 -- Loss: 0.35899773240089417
train-epoch-step: 1-43 -- Loss: 0.6819794178009033
train-epoch-step: 1-44 -- Loss: 0.29555702209472656
train-epoch-step: 1-45 -- Loss: 0.2738953232765198
train-epoch-step: 1-46 -- Loss: 0.3953123092651367
train-epoch-step: 1-47 -- Loss: 0.43114492297172546
train-epoch-step: 1-48 -- Loss: 0.3405560851097107
train-epoch-step: 1-49 -- Loss: 0.42360252141952515
train-epoch-step: 1-50 -- Loss: 0.28071656823158264
train-epoch-step: 1-51 -- Loss: 0.396498441696167
train-epoch-step: 1-52 -- Loss: 0.31107592582702637
train-epoch-step: 1-53 -- Loss: 0.47394469380378723
train-epoch-step: 1-54 -- Loss: 0.5804078578948975
train-epoch-step: 1-55 -- Loss: 0.36230674386024475
train-epoch-step: 1-56 -- Loss: 0.4075593054294586
train-epoch-step: 1-57 -- Loss: 0.5254369974136353
train-epoch-step: 1-58 -- Loss: 0.5209078788757324
train-epoch-step: 1-59 -- Loss: 0.519668459892273
train-epoch-step: 1-60 -- Loss: 0.26055005192756653
train-epoch-step: 1-61 -- Loss: 0.4050051271915436
train-epoch-step: 1-62 -- Loss: 0.35858044028282166
train-epoch-step: 1-63 -- Loss: 0.2793692350387573
train-epoch-step: 1-64 -- Loss: 0.3354165554046631
train-epoch-step: 1-65 -- Loss: 0.37756162881851196
train-epoch-step: 1-66 -- Loss: 0.21484920382499695
train-epoch-step: 1-67 -- Loss: 0.2520172595977783
train-epoch-step: 1-68 -- Loss: 0.44108471274375916
train-epoch-step: 1-69 -- Loss: 0.25895509123802185
train-epoch-step: 1-70 -- Loss: 0.4889569580554962
train-epoch-step: 1-71 -- Loss: 0.5712121725082397
train-epoch-step: 1-72 -- Loss: 0.3407135605812073
train-epoch-step: 1-73 -- Loss: 0.4111400842666626
train-epoch-step: 1-74 -- Loss: 0.1980740875005722
train-epoch-step: 1-75 -- Loss: 0.27982455492019653
train-epoch-step: 1-76 -- Loss: 0.2832041382789612
train-epoch-step: 1-77 -- Loss: 0.39316242933273315
train-epoch-step: 1-78 -- Loss: 0.508563756942749
train-epoch-step: 1-79 -- Loss: 0.36969542503356934
train-epoch-step: 1-80 -- Loss: 0.4486249089241028
train-epoch-step: 1-81 -- Loss: 0.27767038345336914
train-epoch-step: 1-82 -- Loss: 0.4588732123374939
train-epoch-step: 1-83 -- Loss: 0.35089895129203796
train-epoch-step: 1-84 -- Loss: 0.38713231682777405
train-epoch-step: 1-85 -- Loss: 0.33445388078689575
train-epoch-step: 1-86 -- Loss: 0.21821901202201843
train-epoch-step: 1-87 -- Loss: 0.3999558091163635
train-epoch-step: 1-88 -- Loss: 0.2649323642253876
train-epoch-step: 1-89 -- Loss: 0.32782840728759766
train-epoch-step: 1-90 -- Loss: 0.34787508845329285
train-epoch-step: 1-91 -- Loss: 0.43491536378860474
train-epoch-step: 1-92 -- Loss: 0.3025363087654114
train-epoch-step: 1-93 -- Loss: 0.3336673378944397
train-epoch-step: 1-94 -- Loss: 0.457477331161499
train-epoch-step: 1-95 -- Loss: 0.36651259660720825
train-epoch-step: 1-96 -- Loss: 0.38584446907043457
train-epoch-step: 1-97 -- Loss: 0.35175156593322754
train-epoch-step: 1-98 -- Loss: 0.2960861027240753
train-epoch-step: 1-99 -- Loss: 0.31418514251708984
train-epoch-step: 1-100 -- Loss: 0.3498368263244629
train-epoch-step: 1-101 -- Loss: 0.4429510235786438
train-epoch-step: 1-102 -- Loss: 0.47781509160995483
train-epoch-step: 1-103 -- Loss: 0.3700346350669861
train-epoch-step: 1-104 -- Loss: 0.2874552011489868
train-epoch-step: 1-105 -- Loss: 0.6610594987869263
train-epoch-step: 1-106 -- Loss: 0.32413607835769653
train-epoch-step: 1-107 -- Loss: 0.3736864924430847
train-epoch-step: 1-108 -- Loss: 0.3290291726589203
train-epoch-step: 1-109 -- Loss: 0.27720654010772705
train-epoch-step: 1-110 -- Loss: 0.32692375779151917
train-epoch-step: 1-111 -- Loss: 0.3447597026824951
train-epoch-step: 1-112 -- Loss: 0.27452409267425537
train-epoch-step: 1-113 -- Loss: 0.3677644431591034
train-epoch-step: 1-114 -- Loss: 0.3925396502017975
train-epoch-step: 1-115 -- Loss: 0.2785550355911255
train-epoch-step: 1-116 -- Loss: 0.25194376707077026
train-epoch-step: 1-117 -- Loss: 0.2390926331281662
train-epoch-step: 1-118 -- Loss: 0.35641562938690186
train-epoch-step: 1-119 -- Loss: 0.25808843970298767
train-epoch-step: 1-120 -- Loss: 0.4404445290565491
train-epoch-step: 1-121 -- Loss: 0.40665608644485474
train-epoch-step: 1-122 -- Loss: 0.38317441940307617
train-epoch-step: 1-123 -- Loss: 0.3785868287086487
train-epoch-step: 1-124 -- Loss: 0.2230183482170105
train-epoch-step: 1-125 -- Loss: 0.24805229902267456
train-epoch-step: 1-126 -- Loss: 0.3950394093990326
train-epoch-step: 1-127 -- Loss: 0.28125065565109253
train-epoch-step: 1-128 -- Loss: 0.33103474974632263
train-epoch-step: 1-129 -- Loss: 0.23507246375083923
train-epoch-step: 1-130 -- Loss: 0.31778663396835327
train-epoch-step: 1-131 -- Loss: 0.23969654738903046
train-epoch-step: 1-132 -- Loss: 0.32937926054000854
train-epoch-step: 1-133 -- Loss: 0.2037712037563324
train-epoch-step: 1-134 -- Loss: 0.34453636407852173
train-epoch-step: 1-135 -- Loss: 0.21742796897888184
train-epoch-step: 1-136 -- Loss: 0.2051788568496704
train-epoch-step: 1-137 -- Loss: 0.4328557848930359
train-epoch-step: 1-138 -- Loss: 0.503287136554718
train-epoch-step: 1-139 -- Loss: 0.23981299996376038
train-epoch-step: 1-140 -- Loss: 0.3967534899711609
train-epoch-step: 1-141 -- Loss: 0.4106462299823761
train-epoch-step: 1-142 -- Loss: 0.36087989807128906
train-epoch-step: 1-143 -- Loss: 0.3178481459617615
train-epoch-step: 1-144 -- Loss: 0.3366236090660095
train-epoch-step: 1-145 -- Loss: 0.25301989912986755
train-epoch-step: 1-146 -- Loss: 0.31713008880615234
train-epoch-step: 1-147 -- Loss: 0.3401459753513336
train-epoch-step: 1-148 -- Loss: 0.2862403690814972
train-epoch-step: 1-149 -- Loss: 0.20399421453475952
train-epoch-step: 1-150 -- Loss: 0.3387637436389923
train-epoch-step: 1-151 -- Loss: 0.35933399200439453
train-epoch-step: 1-152 -- Loss: 0.33569473028182983
train-epoch-step: 1-153 -- Loss: 0.48974502086639404
train-epoch-step: 1-154 -- Loss: 0.24957415461540222
train-epoch-step: 1-155 -- Loss: 0.24992205202579498
train-epoch-step: 1-156 -- Loss: 0.2119581699371338
train-epoch-step: 1-157 -- Loss: 0.28377819061279297
train-epoch-step: 1-158 -- Loss: 0.3105490505695343
train-epoch-step: 1-159 -- Loss: 0.3028838634490967
train-epoch-step: 1-160 -- Loss: 0.3592611253261566
train-epoch-step: 1-161 -- Loss: 0.3566007614135742
train-epoch-step: 1-162 -- Loss: 0.39738667011260986
train-epoch-step: 1-163 -- Loss: 0.335456907749176
train-epoch-step: 1-164 -- Loss: 0.31351739168167114
train-epoch-step: 1-165 -- Loss: 0.2756146788597107
train-epoch-step: 1-166 -- Loss: 0.212607279419899
train-epoch-step: 1-167 -- Loss: 0.20297092199325562
train-epoch-step: 1-168 -- Loss: 0.3427218198776245
train-epoch-step: 1-169 -- Loss: 0.237444207072258
train-epoch-step: 1-170 -- Loss: 0.36584389209747314
train-epoch-step: 1-171 -- Loss: 0.2952163517475128
train-epoch-step: 1-172 -- Loss: 0.4382486045360565
train-epoch-step: 1-173 -- Loss: 0.23069101572036743
train-epoch-step: 1-174 -- Loss: 0.4609536826610565
train-epoch-step: 1-175 -- Loss: 0.3426511883735657
train-epoch-step: 1-176 -- Loss: 0.23470592498779297
train-epoch-step: 1-177 -- Loss: 0.30835258960723877
train-epoch-step: 1-178 -- Loss: 0.3067423403263092
train-epoch-step: 1-179 -- Loss: 0.23383453488349915
train-epoch-step: 1-180 -- Loss: 0.24914145469665527
train-epoch-step: 1-181 -- Loss: 0.31846779584884644
train-epoch-step: 1-182 -- Loss: 0.3318014144897461
train-epoch-step: 1-183 -- Loss: 0.7135943174362183
train-epoch-step: 1-184 -- Loss: 0.25963130593299866
train-epoch-step: 1-185 -- Loss: 0.24402017891407013
train-epoch-step: 1-186 -- Loss: 0.3347204327583313
train-epoch-step: 1-187 -- Loss: 0.3814276158809662
train-epoch-step: 1-188 -- Loss: 0.3398646116256714
train-epoch-step: 1-189 -- Loss: 0.240940123796463
train-epoch-step: 1-190 -- Loss: 0.28465819358825684
train-epoch-step: 1-191 -- Loss: 0.291016548871994
train-epoch-step: 1-192 -- Loss: 0.41119956970214844
train-epoch-step: 1-193 -- Loss: 0.4172920286655426
train-epoch-step: 1-194 -- Loss: 0.33718761801719666
train-epoch-step: 1-195 -- Loss: 0.332450270652771
train-epoch-step: 1-196 -- Loss: 0.2990027666091919
train-epoch-step: 1-197 -- Loss: 0.21888472139835358
train-epoch-step: 1-198 -- Loss: 0.20939575135707855
train-epoch-step: 1-199 -- Loss: 0.27351218461990356
train-epoch-step: 1-200 -- Loss: 0.20543095469474792
train-epoch-step: 1-201 -- Loss: 0.3376752734184265
train-epoch-step: 1-202 -- Loss: 0.22402513027191162
train-epoch-step: 1-203 -- Loss: 0.3039295971393585
train-epoch-step: 1-204 -- Loss: 0.2633229196071625
train-epoch-step: 1-205 -- Loss: 0.2965134382247925
train-epoch-step: 1-206 -- Loss: 0.3571399450302124
train-epoch-step: 1-207 -- Loss: 0.23043662309646606
train-epoch-step: 1-208 -- Loss: 0.2949661314487457
train-epoch-step: 1-209 -- Loss: 0.2345169186592102
train-epoch-step: 1-210 -- Loss: 0.22977063059806824
train-epoch-step: 1-211 -- Loss: 0.3575121760368347
train-epoch-step: 1-212 -- Loss: 0.3280602693557739
train-epoch-step: 1-213 -- Loss: 0.22661219537258148
train-epoch-step: 1-214 -- Loss: 0.25459885597229004
train-epoch-step: 1-215 -- Loss: 0.2242273986339569
train-epoch-step: 1-216 -- Loss: 0.3067507743835449
train-epoch-step: 1-217 -- Loss: 0.38252025842666626
train-epoch-step: 1-218 -- Loss: 0.26366981863975525
train-epoch-step: 1-219 -- Loss: 0.34118372201919556
train-epoch-step: 1-220 -- Loss: 0.217841237783432
train-epoch-step: 1-221 -- Loss: 0.3822155296802521
train-epoch-step: 1-222 -- Loss: 0.214739590883255
train-epoch-step: 1-223 -- Loss: 0.2889316976070404
train-epoch-step: 1-224 -- Loss: 0.29663658142089844
train-epoch-step: 1-225 -- Loss: 0.47569307684898376
train-epoch-step: 1-226 -- Loss: 0.3443620204925537
train-epoch-step: 1-227 -- Loss: 0.37635815143585205
train-epoch-step: 1-228 -- Loss: 0.29135647416114807
train-epoch-step: 1-229 -- Loss: 0.35563144087791443
train-epoch-step: 1-230 -- Loss: 0.27627497911453247
train-epoch-step: 1-231 -- Loss: 0.30217245221138
train-epoch-step: 1-232 -- Loss: 0.3056432008743286
train-epoch-step: 1-233 -- Loss: 0.15862399339675903
train-epoch-step: 1-234 -- Loss: 0.29053807258605957
train-epoch-step: 1-235 -- Loss: 0.2614002227783203
train-epoch-step: 1-236 -- Loss: 0.30450010299682617
train-epoch-step: 1-237 -- Loss: 0.40995365381240845
train-epoch-step: 1-238 -- Loss: 0.2708352208137512
train-epoch-step: 1-239 -- Loss: 0.23512022197246552
train-epoch-step: 1-240 -- Loss: 0.3675614595413208
train-epoch-step: 1-241 -- Loss: 0.26233816146850586
train-epoch-step: 1-242 -- Loss: 0.36295801401138306
train-epoch-step: 1-243 -- Loss: 0.4131515324115753
train-epoch-step: 1-244 -- Loss: 0.35367947816848755
train-epoch-step: 1-245 -- Loss: 0.39313265681266785
train-epoch-step: 1-246 -- Loss: 0.4474567770957947
train-epoch-step: 1-247 -- Loss: 0.4004082679748535
train-epoch-step: 1-248 -- Loss: 0.2802419662475586
train-epoch-step: 1-249 -- Loss: 0.2299920618534088
train-epoch-step: 1-250 -- Loss: 0.4081059694290161
train-epoch-step: 1-251 -- Loss: 0.19287152588367462
train-epoch-step: 1-252 -- Loss: 0.2834915816783905
train-epoch-step: 1-253 -- Loss: 0.21358221769332886
train-epoch-step: 1-254 -- Loss: 0.3860955238342285
train-epoch-step: 1-255 -- Loss: 0.22448939085006714
train-epoch-step: 1-256 -- Loss: 0.23358476161956787
train-epoch-step: 1-257 -- Loss: 0.28867632150650024
train-epoch-step: 1-258 -- Loss: 0.278715044260025
train-epoch-step: 1-259 -- Loss: 0.17557373642921448
train-epoch-step: 1-260 -- Loss: 0.34350335597991943
train-epoch-step: 1-261 -- Loss: 0.2654080092906952
train-epoch-step: 1-262 -- Loss: 0.48395997285842896
train-epoch-step: 1-263 -- Loss: 0.39019331336021423
train-epoch-step: 1-264 -- Loss: 0.26883700489997864
train-epoch-step: 1-265 -- Loss: 0.18511146306991577
train-epoch-step: 1-266 -- Loss: 0.24122804403305054
train-epoch-step: 1-267 -- Loss: 0.22712558507919312
train-epoch-step: 1-268 -- Loss: 0.20034921169281006
train-epoch-step: 1-269 -- Loss: 0.26968637108802795
train-epoch-step: 1-270 -- Loss: 0.17464420199394226
train-epoch-step: 1-271 -- Loss: 0.26282253861427307
train-epoch-step: 1-272 -- Loss: 0.19881898164749146
train-epoch-step: 1-273 -- Loss: 0.20446453988552094
train-epoch-step: 1-274 -- Loss: 0.3438425660133362
train-epoch-step: 1-275 -- Loss: 0.31556111574172974
train-epoch-step: 1-276 -- Loss: 0.2391318529844284
train-epoch-step: 1-277 -- Loss: 0.2322821319103241
train-epoch-step: 1-278 -- Loss: 0.24582146108150482
train-epoch-step: 1-279 -- Loss: 0.2174491584300995
train-epoch-step: 1-280 -- Loss: 0.32256820797920227
train-epoch-step: 1-281 -- Loss: 0.27348092198371887
train-epoch-step: 1-282 -- Loss: 0.23579831421375275
train-epoch-step: 1-283 -- Loss: 0.17321765422821045
train-epoch-step: 1-284 -- Loss: 0.2979850471019745
train-epoch-step: 1-285 -- Loss: 0.31952306628227234
train-epoch-step: 1-286 -- Loss: 0.24449701607227325
train-epoch-step: 1-287 -- Loss: 0.3433261513710022
train-epoch-step: 1-288 -- Loss: 0.16532695293426514
train-epoch-step: 1-289 -- Loss: 0.20663177967071533
train-epoch-step: 1-290 -- Loss: 0.28922587633132935
train-epoch-step: 1-291 -- Loss: 0.1960919052362442
train-epoch-step: 1-292 -- Loss: 0.24545574188232422
train-epoch-step: 1-293 -- Loss: 0.241947740316391
train-epoch-step: 1-294 -- Loss: 0.28320273756980896
train-epoch-step: 1-295 -- Loss: 0.51910001039505
train-epoch-step: 1-296 -- Loss: 0.3017163872718811
train-epoch-step: 1-297 -- Loss: 0.28358015418052673
train-epoch-step: 1-298 -- Loss: 0.3873113989830017
train-epoch-step: 1-299 -- Loss: 0.2779505252838135
train-epoch-step: 1-300 -- Loss: 0.2654392719268799
train-epoch-step: 1-301 -- Loss: 0.2763292193412781
train-epoch-step: 1-302 -- Loss: 0.37909844517707825
train-epoch-step: 1-303 -- Loss: 0.35276901721954346
train-epoch-step: 1-304 -- Loss: 0.23201021552085876
train-epoch-step: 1-305 -- Loss: 0.24222174286842346
train-epoch-step: 1-306 -- Loss: 0.4209264814853668
train-epoch-step: 1-307 -- Loss: 0.26721739768981934
train-epoch-step: 1-308 -- Loss: 0.43099337816238403
train-epoch-step: 1-309 -- Loss: 0.26712772250175476
train-epoch-step: 1-310 -- Loss: 0.2368057668209076
train-epoch-step: 1-311 -- Loss: 0.2493388056755066
train-epoch-step: 1-312 -- Loss: 0.3273107409477234
train-epoch-step: 1-313 -- Loss: 0.16014786064624786
train-epoch-step: 1-314 -- Loss: 0.3197144865989685
train-epoch-step: 1-315 -- Loss: 0.29850178956985474
train-epoch-step: 1-316 -- Loss: 0.24399809539318085
train-epoch-step: 1-317 -- Loss: 0.21763116121292114
train-epoch-step: 1-318 -- Loss: 0.2710568904876709
train-epoch-step: 1-319 -- Loss: 0.2720358073711395
train-epoch-step: 1-320 -- Loss: 0.18693041801452637
train-epoch-step: 1-321 -- Loss: 0.2209370732307434
train-epoch-step: 1-322 -- Loss: 0.32922959327697754
train-epoch-step: 1-323 -- Loss: 0.24718084931373596
train-epoch-step: 1-324 -- Loss: 0.4103267192840576
train-epoch-step: 1-325 -- Loss: 0.2622215151786804
train-epoch-step: 1-326 -- Loss: 0.3118675947189331
train-epoch-step: 1-327 -- Loss: 0.31205570697784424
train-epoch-step: 1-328 -- Loss: 0.33764663338661194
train-epoch-step: 1-329 -- Loss: 0.5247305631637573
train-epoch-step: 1-330 -- Loss: 0.5561001300811768
train-epoch-step: 1-331 -- Loss: 0.3493579030036926
train-epoch-step: 1-332 -- Loss: 0.17012450098991394
train-epoch-step: 1-333 -- Loss: 0.30587854981422424
train-epoch-step: 1-334 -- Loss: 0.24555209279060364
train-epoch-step: 1-335 -- Loss: 0.26769813895225525
train-epoch-step: 1-336 -- Loss: 0.2594882845878601
train-epoch-step: 1-337 -- Loss: 0.3210773766040802
train-epoch-step: 1-338 -- Loss: 0.26488280296325684
train-epoch-step: 1-339 -- Loss: 0.2313750982284546
train-epoch-step: 1-340 -- Loss: 0.35205626487731934
train-epoch-step: 1-341 -- Loss: 0.20027661323547363
train-epoch-step: 1-342 -- Loss: 0.24983850121498108
train-epoch-step: 1-343 -- Loss: 0.2274312674999237
train-epoch-step: 1-344 -- Loss: 0.2700701355934143
train-epoch-step: 1-345 -- Loss: 0.20949453115463257
train-epoch-step: 1-346 -- Loss: 0.3160068392753601
train-epoch-step: 1-347 -- Loss: 0.26841893792152405
train-epoch-step: 1-348 -- Loss: 0.3337697982788086
train-epoch-step: 1-349 -- Loss: 0.342412531375885
train-epoch-step: 1-350 -- Loss: 0.4352428615093231
train-epoch-step: 1-351 -- Loss: 0.31424710154533386
train-epoch-step: 1-352 -- Loss: 0.23810714483261108
train-epoch-step: 1-353 -- Loss: 0.33901840448379517
train-epoch-step: 1-354 -- Loss: 0.43328940868377686
train-epoch-step: 1-355 -- Loss: 0.17904028296470642
train-epoch-step: 1-356 -- Loss: 0.18643617630004883
train-epoch-step: 1-357 -- Loss: 0.30058884620666504
train-epoch-step: 1-358 -- Loss: 0.2770236134529114
train-epoch-step: 1-359 -- Loss: 0.21116997301578522
train-epoch-step: 1-360 -- Loss: 0.21751569211483002
train-epoch-step: 1-361 -- Loss: 0.4385099411010742
train-epoch-step: 1-362 -- Loss: 0.2498212307691574
train-epoch-step: 1-363 -- Loss: 0.18836882710456848
train-epoch-step: 1-364 -- Loss: 0.2697334289550781
train-epoch-step: 1-365 -- Loss: 0.2595062255859375
train-epoch-step: 1-366 -- Loss: 0.29829490184783936
train-epoch-step: 1-367 -- Loss: 0.39623913168907166
train-epoch-step: 1-368 -- Loss: 0.32773104310035706
train-epoch-step: 1-369 -- Loss: 0.4524794816970825
train-epoch-step: 1-370 -- Loss: 0.2308221012353897
train-epoch-step: 1-371 -- Loss: 0.19140160083770752
train-epoch-step: 1-372 -- Loss: 0.2225756049156189
train-epoch-step: 1-373 -- Loss: 0.31057870388031006
train-epoch-step: 1-374 -- Loss: 0.24579447507858276
train-epoch-step: 1-375 -- Loss: 0.44090256094932556
train-epoch-step: 1-376 -- Loss: 0.32280388474464417
train-epoch-step: 1-377 -- Loss: 0.4163031578063965
train-epoch-step: 1-378 -- Loss: 0.3285638689994812
train-epoch-step: 1-379 -- Loss: 0.17609764635562897
train-epoch-step: 1-380 -- Loss: 0.17779992520809174
train-epoch-step: 1-381 -- Loss: 0.37741705775260925
train-epoch-step: 1-382 -- Loss: 0.4372880458831787
train-epoch-step: 1-383 -- Loss: 0.37186479568481445
train-epoch-step: 1-384 -- Loss: 0.33510956168174744
train-epoch-step: 1-385 -- Loss: 0.2900640070438385
train-epoch-step: 1-386 -- Loss: 0.3893680274486542
train-epoch-step: 1-387 -- Loss: 0.32006916403770447
train-epoch-step: 1-388 -- Loss: 0.3091937303543091
train-epoch-step: 1-389 -- Loss: 0.29319703578948975
train-epoch-step: 1-390 -- Loss: 0.23743844032287598
train-epoch-step: 1-391 -- Loss: 0.23957622051239014
train-epoch-step: 1-392 -- Loss: 0.27615535259246826
train-epoch-step: 1-393 -- Loss: 0.22710032761096954
train-epoch-step: 1-394 -- Loss: 0.3407098352909088
train-epoch-step: 1-395 -- Loss: 0.24395817518234253
train-epoch-step: 1-396 -- Loss: 0.1981929987668991
train-epoch-step: 1-397 -- Loss: 0.18273350596427917
train-epoch-step: 1-398 -- Loss: 0.2856687307357788
train-epoch-step: 1-399 -- Loss: 0.3258283734321594
train-epoch-step: 1-400 -- Loss: 0.4350335896015167
train-epoch-step: 1-401 -- Loss: 0.17945390939712524
train-epoch-step: 1-402 -- Loss: 0.42293959856033325
train-epoch-step: 1-403 -- Loss: 0.26325440406799316
train-epoch-step: 1-404 -- Loss: 0.22437988221645355
train-epoch-step: 1-405 -- Loss: 0.2120380401611328
train-epoch-step: 1-406 -- Loss: 0.24153068661689758
train-epoch-step: 1-407 -- Loss: 0.16961929202079773
train-epoch-step: 1-408 -- Loss: 0.23250949382781982
train-epoch-step: 1-409 -- Loss: 0.27260833978652954
train-epoch-step: 1-410 -- Loss: 0.2967742681503296
train-epoch-step: 1-411 -- Loss: 0.3295215368270874
train-epoch-step: 1-412 -- Loss: 0.2015272080898285
train-epoch-step: 1-413 -- Loss: 0.22379127144813538
train-epoch-step: 1-414 -- Loss: 0.21997809410095215
train-epoch-step: 1-415 -- Loss: 0.19341573119163513
train-epoch-step: 1-416 -- Loss: 0.4759391248226166
train-epoch-step: 1-417 -- Loss: 0.3182368576526642
train-epoch-step: 1-418 -- Loss: 0.43240803480148315
train-epoch-step: 1-419 -- Loss: 0.27302658557891846
train-epoch-step: 1-420 -- Loss: 0.2218092978000641
train-epoch-step: 1-421 -- Loss: 0.2598682940006256
train-epoch-step: 1-422 -- Loss: 0.2457241714000702
train-epoch-step: 1-423 -- Loss: 0.2762937843799591
train-epoch-step: 1-424 -- Loss: 0.21623234450817108
train-epoch-step: 1-425 -- Loss: 0.2758711278438568
train-epoch-step: 1-426 -- Loss: 0.24690216779708862
train-epoch-step: 1-427 -- Loss: 0.20183154940605164
train-epoch-step: 1-428 -- Loss: 0.33021876215934753
train-epoch-step: 1-429 -- Loss: 0.29361677169799805
train-epoch-step: 1-430 -- Loss: 0.20157384872436523
train-epoch-step: 1-431 -- Loss: 0.2598612308502197
train-epoch-step: 1-432 -- Loss: 0.437042772769928
train-epoch-step: 1-433 -- Loss: 0.22949548065662384
train-epoch-step: 1-434 -- Loss: 0.2516629695892334
train-epoch-step: 1-435 -- Loss: 0.25696802139282227
train-epoch-step: 1-436 -- Loss: 0.23396709561347961
train-epoch-step: 1-437 -- Loss: 0.19913190603256226
train-epoch-step: 1-438 -- Loss: 0.2810284197330475
train-epoch-step: 1-439 -- Loss: 0.5243693590164185
train-epoch-step: 1-440 -- Loss: 0.22992634773254395
train-epoch-step: 1-441 -- Loss: 0.345259428024292
train-epoch-step: 1-442 -- Loss: 0.28072643280029297
train-epoch-step: 1-443 -- Loss: 0.23920395970344543
train-epoch-step: 1-444 -- Loss: 0.3729693591594696
train-epoch-step: 1-445 -- Loss: 0.3291345238685608
train-epoch-step: 1-446 -- Loss: 0.22298771142959595
train-epoch-step: 1-447 -- Loss: 0.31956812739372253
train-epoch-step: 1-448 -- Loss: 0.38133504986763
train-epoch-step: 1-449 -- Loss: 0.2696949243545532
train-epoch-step: 1-450 -- Loss: 0.29483529925346375
train-epoch-step: 1-451 -- Loss: 0.22312761843204498
train-epoch-step: 1-452 -- Loss: 0.20579002797603607
train-epoch-step: 1-453 -- Loss: 0.15218155086040497
train-epoch-step: 1-454 -- Loss: 0.36406686902046204
train-epoch-step: 1-455 -- Loss: 0.21761269867420197
train-epoch-step: 1-456 -- Loss: 0.1859106719493866
train-epoch-step: 1-457 -- Loss: 0.3381567895412445
train-epoch-step: 1-458 -- Loss: 0.2533903121948242
train-epoch-step: 1-459 -- Loss: 0.35491442680358887
train-epoch-step: 1-460 -- Loss: 0.19994854927062988
train-epoch-step: 1-461 -- Loss: 0.22410818934440613
train-epoch-step: 1-462 -- Loss: 0.23524199426174164
train-epoch-step: 1-463 -- Loss: 0.2163296341896057
train-epoch-step: 1-464 -- Loss: 0.3182312846183777
train-epoch-step: 1-465 -- Loss: 0.6014200448989868
train-epoch-step: 1-466 -- Loss: 0.3091757297515869
train-epoch-step: 1-467 -- Loss: 0.17210498452186584
train-epoch-step: 1-468 -- Loss: 0.30221104621887207
train-epoch-step: 1-469 -- Loss: 0.39345717430114746
train-epoch-step: 1-470 -- Loss: 0.2593372166156769
train-epoch-step: 1-471 -- Loss: 0.2452518343925476
train-epoch-step: 1-472 -- Loss: 0.23822057247161865
train-epoch-step: 1-473 -- Loss: 0.2490001618862152
train-epoch-step: 1-474 -- Loss: 0.18012866377830505
train-epoch-step: 1-475 -- Loss: 0.1723799705505371
train-epoch-step: 1-476 -- Loss: 0.3182724118232727
train-epoch-step: 1-477 -- Loss: 0.3423713445663452
train-epoch-step: 1-478 -- Loss: 0.29166293144226074
train-epoch-step: 1-479 -- Loss: 0.20478932559490204
train-epoch-step: 1-480 -- Loss: 0.35473549365997314
train-epoch-step: 1-481 -- Loss: 0.4393298327922821
train-epoch-step: 1-482 -- Loss: 0.3744279444217682
train-epoch-step: 1-483 -- Loss: 0.29410722851753235
train-epoch-step: 1-484 -- Loss: 0.30974581837654114
train-epoch-step: 1-485 -- Loss: 0.2041792869567871
train-epoch-step: 1-486 -- Loss: 0.365384966135025
train-epoch-step: 1-487 -- Loss: 0.3747466802597046
train-epoch-step: 1-488 -- Loss: 0.28493091464042664
train-epoch-step: 1-489 -- Loss: 0.3198055922985077
train-epoch-step: 1-490 -- Loss: 0.2159452736377716
train-epoch-step: 1-491 -- Loss: 0.20166677236557007
train-epoch-step: 1-492 -- Loss: 0.1900930553674698
train-epoch-step: 1-493 -- Loss: 0.33038726449012756
train-epoch-step: 1-494 -- Loss: 0.3094775080680847
train-epoch-step: 1-495 -- Loss: 0.33934837579727173
train-epoch-step: 1-496 -- Loss: 0.19097280502319336
train-epoch-step: 1-497 -- Loss: 0.34103140234947205
train-epoch-step: 1-498 -- Loss: 0.22107885777950287
train-epoch-step: 1-499 -- Loss: 0.252816379070282
train-epoch-step: 1-500 -- Loss: 0.23298519849777222
train-epoch-step: 1-501 -- Loss: 0.30593958497047424
train-epoch-step: 1-502 -- Loss: 0.29262351989746094
train-epoch-step: 1-503 -- Loss: 0.3434297442436218
train-epoch-step: 1-504 -- Loss: 0.17002654075622559
train-epoch-step: 1-505 -- Loss: 0.27089768648147583
train-epoch-step: 1-506 -- Loss: 0.18008781969547272
train-epoch-step: 1-507 -- Loss: 0.3031401038169861
train-epoch-step: 1-508 -- Loss: 0.2671564221382141
train-epoch-step: 1-509 -- Loss: 0.2596684396266937
train-epoch-step: 1-510 -- Loss: 0.22102421522140503
train-epoch-step: 1-511 -- Loss: 0.31699299812316895
train-epoch-step: 1-512 -- Loss: 0.3323157727718353
train-epoch-step: 1-513 -- Loss: 0.2901450991630554
train-epoch-step: 1-514 -- Loss: 0.23475989699363708
train-epoch-step: 1-515 -- Loss: 0.2562733292579651
train-epoch-step: 1-516 -- Loss: 0.2506403923034668
train-epoch-step: 1-517 -- Loss: 0.28844010829925537
train-epoch-step: 1-518 -- Loss: 0.21230003237724304
train-epoch-step: 1-519 -- Loss: 0.21640366315841675
train-epoch-step: 1-520 -- Loss: 0.27527379989624023
train-epoch-step: 1-521 -- Loss: 0.36807239055633545
train-epoch-step: 1-522 -- Loss: 0.31513386964797974
train-epoch-step: 1-523 -- Loss: 0.25053122639656067
train-epoch-step: 1-524 -- Loss: 0.25424253940582275
train-epoch-step: 1-525 -- Loss: 0.3551115095615387
train-epoch-step: 1-526 -- Loss: 0.19646716117858887
train-epoch-step: 1-527 -- Loss: 0.2481006234884262
train-epoch-step: 1-528 -- Loss: 0.24170657992362976
train-epoch-step: 1-529 -- Loss: 0.2718433141708374
train-epoch-step: 1-530 -- Loss: 0.2622014880180359
train-epoch-step: 1-531 -- Loss: 0.32720792293548584
train-epoch-step: 1-532 -- Loss: 0.2706769108772278
train-epoch-step: 1-533 -- Loss: 0.2559894621372223
train-epoch-step: 1-534 -- Loss: 0.19096556305885315
train-epoch-step: 1-535 -- Loss: 0.5106037855148315
train-epoch-step: 1-536 -- Loss: 0.23566597700119019
train-epoch-step: 1-537 -- Loss: 0.22890311479568481
train-epoch-step: 1-538 -- Loss: 0.16252979636192322
train-epoch-step: 1-539 -- Loss: 0.2829289436340332
train-epoch-step: 1-540 -- Loss: 0.18747837841510773
train-epoch-step: 1-541 -- Loss: 0.3351344168186188
train-epoch-step: 1-542 -- Loss: 0.3653872311115265
train-epoch-step: 1-543 -- Loss: 0.26534610986709595
train-epoch-step: 1-544 -- Loss: 0.3322262763977051
train-epoch-step: 1-545 -- Loss: 0.291795939207077
train-epoch-step: 1-546 -- Loss: 0.37433552742004395
train-epoch-step: 1-547 -- Loss: 0.26973944902420044
train-epoch-step: 1-548 -- Loss: 0.1415923535823822
train-epoch-step: 1-549 -- Loss: 0.24814368784427643
train-epoch-step: 1-550 -- Loss: 0.29067283868789673
train-epoch-step: 1-551 -- Loss: 0.24874725937843323
train-epoch-step: 1-552 -- Loss: 0.18470486998558044
train-epoch-step: 1-553 -- Loss: 0.30217310786247253
train-epoch-step: 1-554 -- Loss: 0.28505563735961914
train-epoch-step: 1-555 -- Loss: 0.5443235635757446
train-epoch-step: 1-556 -- Loss: 0.25714200735092163
train-epoch-step: 1-557 -- Loss: 0.38594114780426025
train-epoch-step: 1-558 -- Loss: 0.4203791320323944
train-epoch-step: 1-559 -- Loss: 0.22267304360866547
train-epoch-step: 1-560 -- Loss: 0.3111804127693176
train-epoch-step: 1-561 -- Loss: 0.36306798458099365
train-epoch-step: 1-562 -- Loss: 0.30653345584869385
train-epoch-step: 1-563 -- Loss: 0.2818549871444702
train-epoch-step: 1-564 -- Loss: 0.16515116393566132
train-epoch-step: 1-565 -- Loss: 0.28414660692214966
train-epoch-step: 1-566 -- Loss: 0.24069708585739136
train-epoch-step: 1-567 -- Loss: 0.29667505621910095
train-epoch-step: 1-568 -- Loss: 0.25755614042282104
train-epoch-step: 1-569 -- Loss: 0.3250756859779358
train-epoch-step: 1-570 -- Loss: 0.2574335038661957
train-epoch-step: 1-571 -- Loss: 0.3052825629711151
train-epoch-step: 1-572 -- Loss: 0.3518637418746948
train-epoch-step: 1-573 -- Loss: 0.30789849162101746
train-epoch-step: 1-574 -- Loss: 0.3975658118724823
train-epoch-step: 1-575 -- Loss: 0.4640137255191803
train-epoch-step: 1-576 -- Loss: 0.19331292808055878
train-epoch-step: 1-577 -- Loss: 0.23997795581817627
train-epoch-step: 1-578 -- Loss: 0.3429017663002014
train-epoch-step: 1-579 -- Loss: 0.24399204552173615
train-epoch-step: 1-580 -- Loss: 0.29175758361816406
train-epoch-step: 1-581 -- Loss: 0.1985352486371994
train-epoch-step: 1-582 -- Loss: 0.3556429445743561
train-epoch-step: 1-583 -- Loss: 0.33322063088417053
train-epoch-step: 1-584 -- Loss: 0.2860792577266693
train-epoch-step: 1-585 -- Loss: 0.2772976756095886
train-epoch-step: 1-586 -- Loss: 0.39018890261650085
train-epoch-step: 1-587 -- Loss: 0.25582289695739746
train-epoch-step: 1-588 -- Loss: 0.19862870872020721
val-epoch-step: 1-589 -- Loss: 0.35488632321357727
val-epoch-step: 1-590 -- Loss: 0.21292108297348022
val-epoch-step: 1-591 -- Loss: 0.32677507400512695
val-epoch-step: 1-592 -- Loss: 0.2562294602394104
val-epoch-step: 1-593 -- Loss: 0.2104940116405487
val-epoch-step: 1-594 -- Loss: 0.4499308466911316
val-epoch-step: 1-595 -- Loss: 0.24774952232837677
val-epoch-step: 1-596 -- Loss: 0.2937137484550476
val-epoch-step: 1-597 -- Loss: 0.2811437249183655
val-epoch-step: 1-598 -- Loss: 0.23260244727134705
val-epoch-step: 1-599 -- Loss: 0.2664104402065277
val-epoch-step: 1-600 -- Loss: 0.25841397047042847
val-epoch-step: 1-601 -- Loss: 0.2083718627691269
val-epoch-step: 1-602 -- Loss: 0.21576905250549316
val-epoch-step: 1-603 -- Loss: 0.31002938747406006
val-epoch-step: 1-604 -- Loss: 0.1951630860567093
val-epoch-step: 1-605 -- Loss: 0.21324589848518372
val-epoch-step: 1-606 -- Loss: 0.4405370354652405
val-epoch-step: 1-607 -- Loss: 0.21622563898563385
val-epoch-step: 1-608 -- Loss: 0.3596229553222656
val-epoch-step: 1-609 -- Loss: 0.2592897415161133
val-epoch-step: 1-610 -- Loss: 0.3017351031303406
val-epoch-step: 1-611 -- Loss: 0.2361714243888855
val-epoch-step: 1-612 -- Loss: 0.40493351221084595
val-epoch-step: 1-613 -- Loss: 0.25567296147346497
val-epoch-step: 1-614 -- Loss: 0.2163064181804657
val-epoch-step: 1-615 -- Loss: 0.2762105464935303
val-epoch-step: 1-616 -- Loss: 0.20330648124217987
val-epoch-step: 1-617 -- Loss: 0.327847421169281
val-epoch-step: 1-618 -- Loss: 0.2744133770465851
val-epoch-step: 1-619 -- Loss: 0.3073756694793701
val-epoch-step: 1-620 -- Loss: 0.20653098821640015
val-epoch-step: 1-621 -- Loss: 0.20279362797737122
val-epoch-step: 1-622 -- Loss: 0.2072003334760666
val-epoch-step: 1-623 -- Loss: 0.22431209683418274
val-epoch-step: 1-624 -- Loss: 0.240091010928154
val-epoch-step: 1-625 -- Loss: 0.21647171676158905
val-epoch-step: 1-626 -- Loss: 0.23148810863494873
val-epoch-step: 1-627 -- Loss: 0.27994418144226074
val-epoch-step: 1-628 -- Loss: 0.5229969024658203
val-epoch-step: 1-629 -- Loss: 0.2903273105621338
val-epoch-step: 1-630 -- Loss: 0.4983442425727844
val-epoch-step: 1-631 -- Loss: 0.21830032765865326
val-epoch-step: 1-632 -- Loss: 0.2752746343612671
val-epoch-step: 1-633 -- Loss: 0.22418484091758728
val-epoch-step: 1-634 -- Loss: 0.2035633772611618
val-epoch-step: 1-635 -- Loss: 0.15693238377571106
val-epoch-step: 1-636 -- Loss: 0.23221677541732788
val-epoch-step: 1-637 -- Loss: 0.2707475423812866
val-epoch-step: 1-638 -- Loss: 0.22162047028541565
val-epoch-step: 1-639 -- Loss: 0.35870420932769775
val-epoch-step: 1-640 -- Loss: 0.3743147850036621
val-epoch-step: 1-641 -- Loss: 0.1836196482181549
val-epoch-step: 1-642 -- Loss: 0.2818809449672699
val-epoch-step: 1-643 -- Loss: 0.2838805615901947
val-epoch-step: 1-644 -- Loss: 0.2518065273761749
val-epoch-step: 1-645 -- Loss: 0.32137441635131836
val-epoch-step: 1-646 -- Loss: 0.21483324468135834
val-epoch-step: 1-647 -- Loss: 0.19820889830589294
val-epoch-step: 1-648 -- Loss: 0.24012762308120728
val-epoch-step: 1-649 -- Loss: 0.4932412803173065
val-epoch-step: 1-650 -- Loss: 0.35476207733154297
val-epoch-step: 1-651 -- Loss: 0.1951635330915451
val-epoch-step: 1-652 -- Loss: 0.22353655099868774
val-epoch-step: 1-653 -- Loss: 0.27649810910224915
val-epoch-step: 1-654 -- Loss: 0.15907566249370575
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100688934326172
train-epoch-step: 1-4 -- Loss: 1.5449962615966797
train-epoch-step: 1-5 -- Loss: 1.4992713928222656
train-epoch-step: 1-6 -- Loss: 1.6029877662658691
train-epoch-step: 1-7 -- Loss: 1.4446911811828613
train-epoch-step: 1-8 -- Loss: 1.4408009052276611
train-epoch-step: 1-9 -- Loss: 1.4630820751190186
train-epoch-step: 1-10 -- Loss: 1.421022891998291
train-epoch-step: 1-11 -- Loss: 1.2646312713623047
train-epoch-step: 1-12 -- Loss: 1.1825796365737915
train-epoch-step: 1-13 -- Loss: 1.2163407802581787
train-epoch-step: 1-14 -- Loss: 1.030070424079895
train-epoch-step: 1-15 -- Loss: 0.9769066572189331
train-epoch-step: 1-16 -- Loss: 0.9235671758651733
train-epoch-step: 1-17 -- Loss: 0.9747381210327148
train-epoch-step: 1-18 -- Loss: 0.8349165916442871
train-epoch-step: 1-19 -- Loss: 0.6832812428474426
train-epoch-step: 1-20 -- Loss: 0.7804485559463501
train-epoch-step: 1-21 -- Loss: 0.8410714268684387
train-epoch-step: 1-22 -- Loss: 0.5577394366264343
train-epoch-step: 1-23 -- Loss: 0.5642870664596558
train-epoch-step: 1-24 -- Loss: 0.47858187556266785
train-epoch-step: 1-25 -- Loss: 0.6166514754295349
train-epoch-step: 1-26 -- Loss: 0.5280101895332336
train-epoch-step: 1-27 -- Loss: 0.7721532583236694
train-epoch-step: 1-28 -- Loss: 0.374655157327652
train-epoch-step: 1-29 -- Loss: 0.5496691465377808
train-epoch-step: 1-30 -- Loss: 0.2907133102416992
train-epoch-step: 1-31 -- Loss: 0.35729825496673584
train-epoch-step: 1-32 -- Loss: 0.4125489294528961
train-epoch-step: 1-33 -- Loss: 0.6394206285476685
train-epoch-step: 1-34 -- Loss: 0.4049876928329468
train-epoch-step: 1-35 -- Loss: 0.5427305102348328
train-epoch-step: 1-36 -- Loss: 0.36331117153167725
train-epoch-step: 1-37 -- Loss: 0.3562780022621155
train-epoch-step: 1-38 -- Loss: 0.4042630195617676
train-epoch-step: 1-39 -- Loss: 0.5130159854888916
train-epoch-step: 1-40 -- Loss: 0.4561139941215515
train-epoch-step: 1-41 -- Loss: 0.4873802363872528
train-epoch-step: 1-42 -- Loss: 0.3593267500400543
train-epoch-step: 1-43 -- Loss: 0.6819314956665039
train-epoch-step: 1-44 -- Loss: 0.29573285579681396
train-epoch-step: 1-45 -- Loss: 0.27351656556129456
train-epoch-step: 1-46 -- Loss: 0.39654919505119324
train-epoch-step: 1-47 -- Loss: 0.4339115023612976
train-epoch-step: 1-48 -- Loss: 0.3409966826438904
train-epoch-step: 1-49 -- Loss: 0.4226539731025696
train-epoch-step: 1-50 -- Loss: 0.2819727957248688
train-epoch-step: 1-51 -- Loss: 0.3979267477989197
train-epoch-step: 1-52 -- Loss: 0.3116946518421173
train-epoch-step: 1-53 -- Loss: 0.4736926555633545
train-epoch-step: 1-54 -- Loss: 0.5793053507804871
train-epoch-step: 1-55 -- Loss: 0.3623185455799103
train-epoch-step: 1-56 -- Loss: 0.406849205493927
train-epoch-step: 1-57 -- Loss: 0.5253306031227112
train-epoch-step: 1-58 -- Loss: 0.5204702615737915
train-epoch-step: 1-59 -- Loss: 0.5193597078323364
train-epoch-step: 1-60 -- Loss: 0.2604919672012329
train-epoch-step: 1-61 -- Loss: 0.40476077795028687
train-epoch-step: 1-62 -- Loss: 0.35808396339416504
train-epoch-step: 1-63 -- Loss: 0.2785888910293579
train-epoch-step: 1-64 -- Loss: 0.3358421325683594
train-epoch-step: 1-65 -- Loss: 0.37670478224754333
train-epoch-step: 1-66 -- Loss: 0.21449658274650574
train-epoch-step: 1-67 -- Loss: 0.2513777017593384
train-epoch-step: 1-68 -- Loss: 0.4405553936958313
train-epoch-step: 1-69 -- Loss: 0.25849559903144836
train-epoch-step: 1-70 -- Loss: 0.4890936315059662
train-epoch-step: 1-71 -- Loss: 0.5685181617736816
train-epoch-step: 1-72 -- Loss: 0.34129780530929565
train-epoch-step: 1-73 -- Loss: 0.41116607189178467
train-epoch-step: 1-74 -- Loss: 0.1984458863735199
train-epoch-step: 1-75 -- Loss: 0.28008896112442017
train-epoch-step: 1-76 -- Loss: 0.2834654748439789
train-epoch-step: 1-77 -- Loss: 0.39295363426208496
train-epoch-step: 1-78 -- Loss: 0.509661078453064
train-epoch-step: 1-79 -- Loss: 0.3703058362007141
train-epoch-step: 1-80 -- Loss: 0.44899728894233704
train-epoch-step: 1-81 -- Loss: 0.2771814167499542
train-epoch-step: 1-82 -- Loss: 0.4574091136455536
train-epoch-step: 1-83 -- Loss: 0.351040244102478
train-epoch-step: 1-84 -- Loss: 0.38688790798187256
train-epoch-step: 1-85 -- Loss: 0.3352525234222412
train-epoch-step: 1-86 -- Loss: 0.21818235516548157
train-epoch-step: 1-87 -- Loss: 0.39958101511001587
train-epoch-step: 1-88 -- Loss: 0.26488733291625977
train-epoch-step: 1-89 -- Loss: 0.3283592462539673
train-epoch-step: 1-90 -- Loss: 0.34772855043411255
train-epoch-step: 1-91 -- Loss: 0.43501365184783936
train-epoch-step: 1-92 -- Loss: 0.3026573657989502
train-epoch-step: 1-93 -- Loss: 0.33389684557914734
train-epoch-step: 1-94 -- Loss: 0.45723462104797363
train-epoch-step: 1-95 -- Loss: 0.36639708280563354
train-epoch-step: 1-96 -- Loss: 0.38547343015670776
train-epoch-step: 1-97 -- Loss: 0.3512236177921295
train-epoch-step: 1-98 -- Loss: 0.2953888177871704
train-epoch-step: 1-99 -- Loss: 0.3145468235015869
train-epoch-step: 1-100 -- Loss: 0.34947115182876587
train-epoch-step: 1-101 -- Loss: 0.44236037135124207
train-epoch-step: 1-102 -- Loss: 0.47831279039382935
train-epoch-step: 1-103 -- Loss: 0.36921578645706177
train-epoch-step: 1-104 -- Loss: 0.2869955897331238
train-epoch-step: 1-105 -- Loss: 0.6594983339309692
train-epoch-step: 1-106 -- Loss: 0.32306647300720215
train-epoch-step: 1-107 -- Loss: 0.37325868010520935
train-epoch-step: 1-108 -- Loss: 0.3289755582809448
train-epoch-step: 1-109 -- Loss: 0.27703484892845154
train-epoch-step: 1-110 -- Loss: 0.3275338411331177
train-epoch-step: 1-111 -- Loss: 0.3448200225830078
train-epoch-step: 1-112 -- Loss: 0.2740288972854614
train-epoch-step: 1-113 -- Loss: 0.3667427599430084
train-epoch-step: 1-114 -- Loss: 0.3914513885974884
train-epoch-step: 1-115 -- Loss: 0.2782992422580719
train-epoch-step: 1-116 -- Loss: 0.2515706717967987
train-epoch-step: 1-117 -- Loss: 0.23901677131652832
train-epoch-step: 1-118 -- Loss: 0.355506956577301
train-epoch-step: 1-119 -- Loss: 0.25778478384017944
train-epoch-step: 1-120 -- Loss: 0.44021928310394287
train-epoch-step: 1-121 -- Loss: 0.40587812662124634
train-epoch-step: 1-122 -- Loss: 0.38437986373901367
train-epoch-step: 1-123 -- Loss: 0.37808239459991455
train-epoch-step: 1-124 -- Loss: 0.2227492779493332
train-epoch-step: 1-125 -- Loss: 0.24793770909309387
train-epoch-step: 1-126 -- Loss: 0.39596837759017944
train-epoch-step: 1-127 -- Loss: 0.2812647819519043
train-epoch-step: 1-128 -- Loss: 0.3291405737400055
train-epoch-step: 1-129 -- Loss: 0.23532208800315857
train-epoch-step: 1-130 -- Loss: 0.31738004088401794
train-epoch-step: 1-131 -- Loss: 0.23953458666801453
train-epoch-step: 1-132 -- Loss: 0.3282191753387451
train-epoch-step: 1-133 -- Loss: 0.20366710424423218
train-epoch-step: 1-134 -- Loss: 0.3457610011100769
train-epoch-step: 1-135 -- Loss: 0.21694417297840118
train-epoch-step: 1-136 -- Loss: 0.20454472303390503
train-epoch-step: 1-137 -- Loss: 0.4333120286464691
train-epoch-step: 1-138 -- Loss: 0.4964710474014282
train-epoch-step: 1-139 -- Loss: 0.2398884892463684
train-epoch-step: 1-140 -- Loss: 0.396288126707077
train-epoch-step: 1-141 -- Loss: 0.4105418920516968
train-epoch-step: 1-142 -- Loss: 0.36098775267601013
train-epoch-step: 1-143 -- Loss: 0.3179130554199219
train-epoch-step: 1-144 -- Loss: 0.3370055556297302
train-epoch-step: 1-145 -- Loss: 0.2531658113002777
train-epoch-step: 1-146 -- Loss: 0.31744086742401123
train-epoch-step: 1-147 -- Loss: 0.3394807279109955
train-epoch-step: 1-148 -- Loss: 0.2868109345436096
train-epoch-step: 1-149 -- Loss: 0.2039288580417633
train-epoch-step: 1-150 -- Loss: 0.3412718176841736
train-epoch-step: 1-151 -- Loss: 0.35861364006996155
train-epoch-step: 1-152 -- Loss: 0.3348923921585083
train-epoch-step: 1-153 -- Loss: 0.4938666820526123
train-epoch-step: 1-154 -- Loss: 0.2498924881219864
train-epoch-step: 1-155 -- Loss: 0.24985724687576294
train-epoch-step: 1-156 -- Loss: 0.2118382453918457
train-epoch-step: 1-157 -- Loss: 0.28413429856300354
train-epoch-step: 1-158 -- Loss: 0.30992990732192993
train-epoch-step: 1-159 -- Loss: 0.3026387095451355
train-epoch-step: 1-160 -- Loss: 0.3594578802585602
train-epoch-step: 1-161 -- Loss: 0.3567875325679779
train-epoch-step: 1-162 -- Loss: 0.3974299430847168
train-epoch-step: 1-163 -- Loss: 0.33388257026672363
train-epoch-step: 1-164 -- Loss: 0.3139795958995819
train-epoch-step: 1-165 -- Loss: 0.27514225244522095
train-epoch-step: 1-166 -- Loss: 0.2124253809452057
train-epoch-step: 1-167 -- Loss: 0.2030312716960907
train-epoch-step: 1-168 -- Loss: 0.34065505862236023
train-epoch-step: 1-169 -- Loss: 0.23725394904613495
train-epoch-step: 1-170 -- Loss: 0.36739498376846313
train-epoch-step: 1-171 -- Loss: 0.2945497930049896
train-epoch-step: 1-172 -- Loss: 0.4373922049999237
train-epoch-step: 1-173 -- Loss: 0.23036165535449982
train-epoch-step: 1-174 -- Loss: 0.4601469039916992
train-epoch-step: 1-175 -- Loss: 0.34225714206695557
train-epoch-step: 1-176 -- Loss: 0.23478402197360992
train-epoch-step: 1-177 -- Loss: 0.30872777104377747
train-epoch-step: 1-178 -- Loss: 0.3069057762622833
train-epoch-step: 1-179 -- Loss: 0.23463834822177887
train-epoch-step: 1-180 -- Loss: 0.2493981420993805
train-epoch-step: 1-181 -- Loss: 0.31910938024520874
train-epoch-step: 1-182 -- Loss: 0.33095377683639526
train-epoch-step: 1-183 -- Loss: 0.7139486074447632
train-epoch-step: 1-184 -- Loss: 0.2591743767261505
train-epoch-step: 1-185 -- Loss: 0.2443642020225525
train-epoch-step: 1-186 -- Loss: 0.33410748839378357
train-epoch-step: 1-187 -- Loss: 0.3813716769218445
train-epoch-step: 1-188 -- Loss: 0.3399779200553894
train-epoch-step: 1-189 -- Loss: 0.241369366645813
train-epoch-step: 1-190 -- Loss: 0.28488683700561523
train-epoch-step: 1-191 -- Loss: 0.29140591621398926
train-epoch-step: 1-192 -- Loss: 0.413127601146698
train-epoch-step: 1-193 -- Loss: 0.41744738817214966
train-epoch-step: 1-194 -- Loss: 0.339305579662323
train-epoch-step: 1-195 -- Loss: 0.332599937915802
train-epoch-step: 1-196 -- Loss: 0.2975316643714905
train-epoch-step: 1-197 -- Loss: 0.2184477150440216
train-epoch-step: 1-198 -- Loss: 0.20952671766281128
train-epoch-step: 1-199 -- Loss: 0.2734140455722809
train-epoch-step: 1-200 -- Loss: 0.20546066761016846
train-epoch-step: 1-201 -- Loss: 0.3363884389400482
train-epoch-step: 1-202 -- Loss: 0.22353151440620422
train-epoch-step: 1-203 -- Loss: 0.3031565546989441
train-epoch-step: 1-204 -- Loss: 0.2639576494693756
train-epoch-step: 1-205 -- Loss: 0.2963472008705139
train-epoch-step: 1-206 -- Loss: 0.35806161165237427
train-epoch-step: 1-207 -- Loss: 0.231088325381279
train-epoch-step: 1-208 -- Loss: 0.2946687340736389
train-epoch-step: 1-209 -- Loss: 0.23479703068733215
train-epoch-step: 1-210 -- Loss: 0.2294377088546753
train-epoch-step: 1-211 -- Loss: 0.35954758524894714
train-epoch-step: 1-212 -- Loss: 0.3286188244819641
train-epoch-step: 1-213 -- Loss: 0.22593270242214203
train-epoch-step: 1-214 -- Loss: 0.2549138367176056
train-epoch-step: 1-215 -- Loss: 0.2241005301475525
train-epoch-step: 1-216 -- Loss: 0.3080953359603882
train-epoch-step: 1-217 -- Loss: 0.3828306198120117
train-epoch-step: 1-218 -- Loss: 0.263731449842453
train-epoch-step: 1-219 -- Loss: 0.34230542182922363
train-epoch-step: 1-220 -- Loss: 0.21758103370666504
train-epoch-step: 1-221 -- Loss: 0.38199466466903687
train-epoch-step: 1-222 -- Loss: 0.21447208523750305
train-epoch-step: 1-223 -- Loss: 0.2885087728500366
train-epoch-step: 1-224 -- Loss: 0.29634636640548706
train-epoch-step: 1-225 -- Loss: 0.47572532296180725
train-epoch-step: 1-226 -- Loss: 0.3424808382987976
train-epoch-step: 1-227 -- Loss: 0.37677961587905884
train-epoch-step: 1-228 -- Loss: 0.29095858335494995
train-epoch-step: 1-229 -- Loss: 0.35677337646484375
train-epoch-step: 1-230 -- Loss: 0.27723240852355957
train-epoch-step: 1-231 -- Loss: 0.3014523386955261
train-epoch-step: 1-232 -- Loss: 0.3047672212123871
train-epoch-step: 1-233 -- Loss: 0.15868732333183289
train-epoch-step: 1-234 -- Loss: 0.29027628898620605
train-epoch-step: 1-235 -- Loss: 0.2616947889328003
train-epoch-step: 1-236 -- Loss: 0.3043600022792816
train-epoch-step: 1-237 -- Loss: 0.4095713496208191
train-epoch-step: 1-238 -- Loss: 0.27061399817466736
train-epoch-step: 1-239 -- Loss: 0.23550276458263397
train-epoch-step: 1-240 -- Loss: 0.3681398034095764
train-epoch-step: 1-241 -- Loss: 0.26306021213531494
train-epoch-step: 1-242 -- Loss: 0.3630039393901825
train-epoch-step: 1-243 -- Loss: 0.412885844707489
train-epoch-step: 1-244 -- Loss: 0.35373741388320923
train-epoch-step: 1-245 -- Loss: 0.3951973021030426
train-epoch-step: 1-246 -- Loss: 0.44764190912246704
train-epoch-step: 1-247 -- Loss: 0.39918678998947144
train-epoch-step: 1-248 -- Loss: 0.2802012860774994
train-epoch-step: 1-249 -- Loss: 0.23010872304439545
train-epoch-step: 1-250 -- Loss: 0.4074484407901764
train-epoch-step: 1-251 -- Loss: 0.19331279397010803
train-epoch-step: 1-252 -- Loss: 0.2832925319671631
train-epoch-step: 1-253 -- Loss: 0.21385669708251953
train-epoch-step: 1-254 -- Loss: 0.3868533968925476
train-epoch-step: 1-255 -- Loss: 0.22439336776733398
train-epoch-step: 1-256 -- Loss: 0.23331402242183685
train-epoch-step: 1-257 -- Loss: 0.288926362991333
train-epoch-step: 1-258 -- Loss: 0.27858689427375793
train-epoch-step: 1-259 -- Loss: 0.17539849877357483
train-epoch-step: 1-260 -- Loss: 0.34400707483291626
train-epoch-step: 1-261 -- Loss: 0.2643638253211975
train-epoch-step: 1-262 -- Loss: 0.48400425910949707
train-epoch-step: 1-263 -- Loss: 0.3912990987300873
train-epoch-step: 1-264 -- Loss: 0.26881760358810425
train-epoch-step: 1-265 -- Loss: 0.18510779738426208
train-epoch-step: 1-266 -- Loss: 0.24100668728351593
train-epoch-step: 1-267 -- Loss: 0.22728487849235535
train-epoch-step: 1-268 -- Loss: 0.19973081350326538
train-epoch-step: 1-269 -- Loss: 0.269548624753952
train-epoch-step: 1-270 -- Loss: 0.17427629232406616
train-epoch-step: 1-271 -- Loss: 0.2625175416469574
train-epoch-step: 1-272 -- Loss: 0.19822567701339722
train-epoch-step: 1-273 -- Loss: 0.20432910323143005
train-epoch-step: 1-274 -- Loss: 0.3426608443260193
train-epoch-step: 1-275 -- Loss: 0.3158515989780426
train-epoch-step: 1-276 -- Loss: 0.23939403891563416
train-epoch-step: 1-277 -- Loss: 0.2336401343345642
train-epoch-step: 1-278 -- Loss: 0.2457987368106842
train-epoch-step: 1-279 -- Loss: 0.21698570251464844
train-epoch-step: 1-280 -- Loss: 0.32288646697998047
train-epoch-step: 1-281 -- Loss: 0.27384519577026367
train-epoch-step: 1-282 -- Loss: 0.23702415823936462
train-epoch-step: 1-283 -- Loss: 0.17251120507717133
train-epoch-step: 1-284 -- Loss: 0.2972140312194824
train-epoch-step: 1-285 -- Loss: 0.3200092911720276
train-epoch-step: 1-286 -- Loss: 0.24508324265480042
train-epoch-step: 1-287 -- Loss: 0.34288257360458374
train-epoch-step: 1-288 -- Loss: 0.1650189459323883
train-epoch-step: 1-289 -- Loss: 0.2076413333415985
train-epoch-step: 1-290 -- Loss: 0.2904132306575775
train-epoch-step: 1-291 -- Loss: 0.19565370678901672
train-epoch-step: 1-292 -- Loss: 0.24588961899280548
train-epoch-step: 1-293 -- Loss: 0.24195754528045654
train-epoch-step: 1-294 -- Loss: 0.2824935019016266
train-epoch-step: 1-295 -- Loss: 0.5189366340637207
train-epoch-step: 1-296 -- Loss: 0.3018988370895386
train-epoch-step: 1-297 -- Loss: 0.28331369161605835
train-epoch-step: 1-298 -- Loss: 0.385629802942276
train-epoch-step: 1-299 -- Loss: 0.27787816524505615
train-epoch-step: 1-300 -- Loss: 0.2666998505592346
train-epoch-step: 1-301 -- Loss: 0.2787782549858093
train-epoch-step: 1-302 -- Loss: 0.37823402881622314
train-epoch-step: 1-303 -- Loss: 0.3515510559082031
train-epoch-step: 1-304 -- Loss: 0.23239123821258545
train-epoch-step: 1-305 -- Loss: 0.2433721423149109
train-epoch-step: 1-306 -- Loss: 0.419782817363739
train-epoch-step: 1-307 -- Loss: 0.2650172710418701
train-epoch-step: 1-308 -- Loss: 0.42922431230545044
train-epoch-step: 1-309 -- Loss: 0.26797187328338623
train-epoch-step: 1-310 -- Loss: 0.23834504187107086
train-epoch-step: 1-311 -- Loss: 0.24986818432807922
train-epoch-step: 1-312 -- Loss: 0.32581162452697754
train-epoch-step: 1-313 -- Loss: 0.1584029644727707
train-epoch-step: 1-314 -- Loss: 0.3222388029098511
train-epoch-step: 1-315 -- Loss: 0.29809385538101196
train-epoch-step: 1-316 -- Loss: 0.24119038879871368
train-epoch-step: 1-317 -- Loss: 0.21495716273784637
train-epoch-step: 1-318 -- Loss: 0.2698400318622589
train-epoch-step: 1-319 -- Loss: 0.2725270390510559
train-epoch-step: 1-320 -- Loss: 0.18505236506462097
train-epoch-step: 1-321 -- Loss: 0.22152528166770935
train-epoch-step: 1-322 -- Loss: 0.32924532890319824
train-epoch-step: 1-323 -- Loss: 0.24709805846214294
train-epoch-step: 1-324 -- Loss: 0.41071557998657227
train-epoch-step: 1-325 -- Loss: 0.26214975118637085
train-epoch-step: 1-326 -- Loss: 0.31304341554641724
train-epoch-step: 1-327 -- Loss: 0.3120359778404236
train-epoch-step: 1-328 -- Loss: 0.3370722532272339
train-epoch-step: 1-329 -- Loss: 0.5249805450439453
train-epoch-step: 1-330 -- Loss: 0.5569416284561157
train-epoch-step: 1-331 -- Loss: 0.3490413427352905
train-epoch-step: 1-332 -- Loss: 0.17007501423358917
train-epoch-step: 1-333 -- Loss: 0.30844658613204956
train-epoch-step: 1-334 -- Loss: 0.24639156460762024
train-epoch-step: 1-335 -- Loss: 0.2670974135398865
train-epoch-step: 1-336 -- Loss: 0.2590605914592743
train-epoch-step: 1-337 -- Loss: 0.3205961585044861
train-epoch-step: 1-338 -- Loss: 0.2649672031402588
train-epoch-step: 1-339 -- Loss: 0.2313654124736786
train-epoch-step: 1-340 -- Loss: 0.3529151380062103
train-epoch-step: 1-341 -- Loss: 0.20044249296188354
train-epoch-step: 1-342 -- Loss: 0.2504400610923767
train-epoch-step: 1-343 -- Loss: 0.22738425433635712
train-epoch-step: 1-344 -- Loss: 0.26954570412635803
train-epoch-step: 1-345 -- Loss: 0.20906314253807068
train-epoch-step: 1-346 -- Loss: 0.31510087847709656
train-epoch-step: 1-347 -- Loss: 0.2693544626235962
train-epoch-step: 1-348 -- Loss: 0.3340204656124115
train-epoch-step: 1-349 -- Loss: 0.3401276469230652
train-epoch-step: 1-350 -- Loss: 0.4349098205566406
train-epoch-step: 1-351 -- Loss: 0.31489527225494385
train-epoch-step: 1-352 -- Loss: 0.236859530210495
train-epoch-step: 1-353 -- Loss: 0.33831697702407837
train-epoch-step: 1-354 -- Loss: 0.43257248401641846
train-epoch-step: 1-355 -- Loss: 0.17912915349006653
train-epoch-step: 1-356 -- Loss: 0.18602204322814941
train-epoch-step: 1-357 -- Loss: 0.30059587955474854
train-epoch-step: 1-358 -- Loss: 0.27730464935302734
train-epoch-step: 1-359 -- Loss: 0.2112131118774414
train-epoch-step: 1-360 -- Loss: 0.21707288920879364
train-epoch-step: 1-361 -- Loss: 0.4375319480895996
train-epoch-step: 1-362 -- Loss: 0.24956545233726501
train-epoch-step: 1-363 -- Loss: 0.187761127948761
train-epoch-step: 1-364 -- Loss: 0.26962989568710327
train-epoch-step: 1-365 -- Loss: 0.2597886919975281
train-epoch-step: 1-366 -- Loss: 0.29811254143714905
train-epoch-step: 1-367 -- Loss: 0.396087646484375
train-epoch-step: 1-368 -- Loss: 0.3278804421424866
train-epoch-step: 1-369 -- Loss: 0.4540259838104248
train-epoch-step: 1-370 -- Loss: 0.2307058572769165
train-epoch-step: 1-371 -- Loss: 0.19150486588478088
train-epoch-step: 1-372 -- Loss: 0.22225579619407654
train-epoch-step: 1-373 -- Loss: 0.31004583835601807
train-epoch-step: 1-374 -- Loss: 0.24576155841350555
train-epoch-step: 1-375 -- Loss: 0.44170331954956055
train-epoch-step: 1-376 -- Loss: 0.3226303160190582
train-epoch-step: 1-377 -- Loss: 0.4166070222854614
train-epoch-step: 1-378 -- Loss: 0.327683687210083
train-epoch-step: 1-379 -- Loss: 0.17524686455726624
train-epoch-step: 1-380 -- Loss: 0.1779598742723465
train-epoch-step: 1-381 -- Loss: 0.37657907605171204
train-epoch-step: 1-382 -- Loss: 0.4359498620033264
train-epoch-step: 1-383 -- Loss: 0.3699588179588318
train-epoch-step: 1-384 -- Loss: 0.33467525243759155
train-epoch-step: 1-385 -- Loss: 0.29166853427886963
train-epoch-step: 1-386 -- Loss: 0.3902585506439209
train-epoch-step: 1-387 -- Loss: 0.320083349943161
train-epoch-step: 1-388 -- Loss: 0.3106977939605713
train-epoch-step: 1-389 -- Loss: 0.2930395007133484
train-epoch-step: 1-390 -- Loss: 0.23825514316558838
train-epoch-step: 1-391 -- Loss: 0.23952649533748627
train-epoch-step: 1-392 -- Loss: 0.27648743987083435
train-epoch-step: 1-393 -- Loss: 0.2269757241010666
train-epoch-step: 1-394 -- Loss: 0.34165334701538086
train-epoch-step: 1-395 -- Loss: 0.2449178397655487
train-epoch-step: 1-396 -- Loss: 0.19765950739383698
train-epoch-step: 1-397 -- Loss: 0.18271954357624054
train-epoch-step: 1-398 -- Loss: 0.28550198674201965
train-epoch-step: 1-399 -- Loss: 0.3266769051551819
train-epoch-step: 1-400 -- Loss: 0.4352926015853882
train-epoch-step: 1-401 -- Loss: 0.17964963614940643
train-epoch-step: 1-402 -- Loss: 0.4212990403175354
train-epoch-step: 1-403 -- Loss: 0.26272058486938477
train-epoch-step: 1-404 -- Loss: 0.2254202514886856
train-epoch-step: 1-405 -- Loss: 0.2122642695903778
train-epoch-step: 1-406 -- Loss: 0.24077481031417847
train-epoch-step: 1-407 -- Loss: 0.16960766911506653
train-epoch-step: 1-408 -- Loss: 0.2323315441608429
train-epoch-step: 1-409 -- Loss: 0.2735210061073303
train-epoch-step: 1-410 -- Loss: 0.2980555295944214
train-epoch-step: 1-411 -- Loss: 0.3299969434738159
train-epoch-step: 1-412 -- Loss: 0.20122729241847992
train-epoch-step: 1-413 -- Loss: 0.2239932119846344
train-epoch-step: 1-414 -- Loss: 0.21980980038642883
train-epoch-step: 1-415 -- Loss: 0.19388915598392487
train-epoch-step: 1-416 -- Loss: 0.4768955707550049
train-epoch-step: 1-417 -- Loss: 0.3176427483558655
train-epoch-step: 1-418 -- Loss: 0.43496954441070557
train-epoch-step: 1-419 -- Loss: 0.27244648337364197
train-epoch-step: 1-420 -- Loss: 0.22212041914463043
train-epoch-step: 1-421 -- Loss: 0.25958162546157837
train-epoch-step: 1-422 -- Loss: 0.2458021193742752
train-epoch-step: 1-423 -- Loss: 0.2759511470794678
train-epoch-step: 1-424 -- Loss: 0.21661370992660522
train-epoch-step: 1-425 -- Loss: 0.2759878933429718
train-epoch-step: 1-426 -- Loss: 0.2470419555902481
train-epoch-step: 1-427 -- Loss: 0.20223797857761383
train-epoch-step: 1-428 -- Loss: 0.3309594988822937
train-epoch-step: 1-429 -- Loss: 0.29339516162872314
train-epoch-step: 1-430 -- Loss: 0.20223069190979004
train-epoch-step: 1-431 -- Loss: 0.2597826421260834
train-epoch-step: 1-432 -- Loss: 0.4358122646808624
train-epoch-step: 1-433 -- Loss: 0.23056745529174805
train-epoch-step: 1-434 -- Loss: 0.24967463314533234
train-epoch-step: 1-435 -- Loss: 0.2574145495891571
train-epoch-step: 1-436 -- Loss: 0.23428237438201904
train-epoch-step: 1-437 -- Loss: 0.19938631355762482
train-epoch-step: 1-438 -- Loss: 0.2825769782066345
train-epoch-step: 1-439 -- Loss: 0.5266045331954956
train-epoch-step: 1-440 -- Loss: 0.23045670986175537
train-epoch-step: 1-441 -- Loss: 0.3457188308238983
train-epoch-step: 1-442 -- Loss: 0.2814306616783142
train-epoch-step: 1-443 -- Loss: 0.24098262190818787
train-epoch-step: 1-444 -- Loss: 0.37180542945861816
train-epoch-step: 1-445 -- Loss: 0.32711905241012573
train-epoch-step: 1-446 -- Loss: 0.2236519306898117
train-epoch-step: 1-447 -- Loss: 0.3208622932434082
train-epoch-step: 1-448 -- Loss: 0.3829011917114258
train-epoch-step: 1-449 -- Loss: 0.26862820982933044
train-epoch-step: 1-450 -- Loss: 0.29291194677352905
train-epoch-step: 1-451 -- Loss: 0.22404207289218903
train-epoch-step: 1-452 -- Loss: 0.20551753044128418
train-epoch-step: 1-453 -- Loss: 0.1524025797843933
train-epoch-step: 1-454 -- Loss: 0.3633950352668762
train-epoch-step: 1-455 -- Loss: 0.21691438555717468
train-epoch-step: 1-456 -- Loss: 0.18650034070014954
train-epoch-step: 1-457 -- Loss: 0.33849477767944336
train-epoch-step: 1-458 -- Loss: 0.2539082169532776
train-epoch-step: 1-459 -- Loss: 0.3547256886959076
train-epoch-step: 1-460 -- Loss: 0.19962629675865173
train-epoch-step: 1-461 -- Loss: 0.22488164901733398
train-epoch-step: 1-462 -- Loss: 0.23512987792491913
train-epoch-step: 1-463 -- Loss: 0.21622788906097412
train-epoch-step: 1-464 -- Loss: 0.31679046154022217
train-epoch-step: 1-465 -- Loss: 0.6046795845031738
train-epoch-step: 1-466 -- Loss: 0.30829519033432007
train-epoch-step: 1-467 -- Loss: 0.1740076094865799
train-epoch-step: 1-468 -- Loss: 0.30173617601394653
train-epoch-step: 1-469 -- Loss: 0.394502192735672
train-epoch-step: 1-470 -- Loss: 0.26019659638404846
train-epoch-step: 1-471 -- Loss: 0.2452860176563263
train-epoch-step: 1-472 -- Loss: 0.23977616429328918
train-epoch-step: 1-473 -- Loss: 0.24940602481365204
train-epoch-step: 1-474 -- Loss: 0.18011274933815002
train-epoch-step: 1-475 -- Loss: 0.17274557054042816
train-epoch-step: 1-476 -- Loss: 0.31989264488220215
train-epoch-step: 1-477 -- Loss: 0.34479236602783203
train-epoch-step: 1-478 -- Loss: 0.2932322025299072
train-epoch-step: 1-479 -- Loss: 0.2050248384475708
train-epoch-step: 1-480 -- Loss: 0.3576369881629944
train-epoch-step: 1-481 -- Loss: 0.43776804208755493
train-epoch-step: 1-482 -- Loss: 0.37607860565185547
train-epoch-step: 1-483 -- Loss: 0.2944568991661072
train-epoch-step: 1-484 -- Loss: 0.3126070201396942
train-epoch-step: 1-485 -- Loss: 0.2051963210105896
train-epoch-step: 1-486 -- Loss: 0.3660131096839905
train-epoch-step: 1-487 -- Loss: 0.37546753883361816
train-epoch-step: 1-488 -- Loss: 0.28487589955329895
train-epoch-step: 1-489 -- Loss: 0.3214656114578247
train-epoch-step: 1-490 -- Loss: 0.21629932522773743
train-epoch-step: 1-491 -- Loss: 0.2019474059343338
train-epoch-step: 1-492 -- Loss: 0.19141462445259094
train-epoch-step: 1-493 -- Loss: 0.3303733468055725
train-epoch-step: 1-494 -- Loss: 0.31013238430023193
train-epoch-step: 1-495 -- Loss: 0.3418159782886505
train-epoch-step: 1-496 -- Loss: 0.191258043050766
train-epoch-step: 1-497 -- Loss: 0.34187695384025574
train-epoch-step: 1-498 -- Loss: 0.2220343053340912
train-epoch-step: 1-499 -- Loss: 0.2544119954109192
train-epoch-step: 1-500 -- Loss: 0.2330108880996704
train-epoch-step: 1-501 -- Loss: 0.30579331517219543
train-epoch-step: 1-502 -- Loss: 0.29285454750061035
train-epoch-step: 1-503 -- Loss: 0.3426341712474823
train-epoch-step: 1-504 -- Loss: 0.1700998693704605
train-epoch-step: 1-505 -- Loss: 0.2708891034126282
train-epoch-step: 1-506 -- Loss: 0.18088428676128387
train-epoch-step: 1-507 -- Loss: 0.3043077290058136
train-epoch-step: 1-508 -- Loss: 0.2670024037361145
train-epoch-step: 1-509 -- Loss: 0.2601360082626343
train-epoch-step: 1-510 -- Loss: 0.22178873419761658
train-epoch-step: 1-511 -- Loss: 0.31775474548339844
train-epoch-step: 1-512 -- Loss: 0.3327779173851013
train-epoch-step: 1-513 -- Loss: 0.28994178771972656
train-epoch-step: 1-514 -- Loss: 0.23338399827480316
train-epoch-step: 1-515 -- Loss: 0.2573879361152649
train-epoch-step: 1-516 -- Loss: 0.25027260184288025
train-epoch-step: 1-517 -- Loss: 0.2898039221763611
train-epoch-step: 1-518 -- Loss: 0.2126401662826538
train-epoch-step: 1-519 -- Loss: 0.21704448759555817
train-epoch-step: 1-520 -- Loss: 0.27660539746284485
train-epoch-step: 1-521 -- Loss: 0.3691026270389557
train-epoch-step: 1-522 -- Loss: 0.31382840871810913
train-epoch-step: 1-523 -- Loss: 0.25085726380348206
train-epoch-step: 1-524 -- Loss: 0.25412607192993164
train-epoch-step: 1-525 -- Loss: 0.35448500514030457
train-epoch-step: 1-526 -- Loss: 0.19695952534675598
train-epoch-step: 1-527 -- Loss: 0.24917571246623993
train-epoch-step: 1-528 -- Loss: 0.24248452484607697
train-epoch-step: 1-529 -- Loss: 0.272262841463089
train-epoch-step: 1-530 -- Loss: 0.2624688148498535
train-epoch-step: 1-531 -- Loss: 0.3290480077266693
train-epoch-step: 1-532 -- Loss: 0.2707613706588745
train-epoch-step: 1-533 -- Loss: 0.2553532123565674
train-epoch-step: 1-534 -- Loss: 0.1917276680469513
train-epoch-step: 1-535 -- Loss: 0.5089259147644043
train-epoch-step: 1-536 -- Loss: 0.23537449538707733
train-epoch-step: 1-537 -- Loss: 0.22863689064979553
train-epoch-step: 1-538 -- Loss: 0.16294880211353302
train-epoch-step: 1-539 -- Loss: 0.2831462323665619
train-epoch-step: 1-540 -- Loss: 0.1877869963645935
train-epoch-step: 1-541 -- Loss: 0.336966335773468
train-epoch-step: 1-542 -- Loss: 0.36637094616889954
train-epoch-step: 1-543 -- Loss: 0.26364123821258545
train-epoch-step: 1-544 -- Loss: 0.33277660608291626
train-epoch-step: 1-545 -- Loss: 0.2911183536052704
train-epoch-step: 1-546 -- Loss: 0.37542974948883057
train-epoch-step: 1-547 -- Loss: 0.2708696722984314
train-epoch-step: 1-548 -- Loss: 0.14138388633728027
train-epoch-step: 1-549 -- Loss: 0.24836459755897522
train-epoch-step: 1-550 -- Loss: 0.291792094707489
train-epoch-step: 1-551 -- Loss: 0.24851582944393158
train-epoch-step: 1-552 -- Loss: 0.18391115963459015
train-epoch-step: 1-553 -- Loss: 0.301931232213974
train-epoch-step: 1-554 -- Loss: 0.28336358070373535
train-epoch-step: 1-555 -- Loss: 0.5428255796432495
train-epoch-step: 1-556 -- Loss: 0.25642144680023193
train-epoch-step: 1-557 -- Loss: 0.38365739583969116
train-epoch-step: 1-558 -- Loss: 0.41879957914352417
train-epoch-step: 1-559 -- Loss: 0.22281548380851746
train-epoch-step: 1-560 -- Loss: 0.3122139871120453
train-epoch-step: 1-561 -- Loss: 0.36081838607788086
train-epoch-step: 1-562 -- Loss: 0.30650776624679565
train-epoch-step: 1-563 -- Loss: 0.28217077255249023
train-epoch-step: 1-564 -- Loss: 0.16458553075790405
train-epoch-step: 1-565 -- Loss: 0.2836650311946869
train-epoch-step: 1-566 -- Loss: 0.24017652869224548
train-epoch-step: 1-567 -- Loss: 0.2976973056793213
train-epoch-step: 1-568 -- Loss: 0.2592375874519348
train-epoch-step: 1-569 -- Loss: 0.32463234663009644
train-epoch-step: 1-570 -- Loss: 0.25684839487075806
train-epoch-step: 1-571 -- Loss: 0.3060307502746582
train-epoch-step: 1-572 -- Loss: 0.35127949714660645
train-epoch-step: 1-573 -- Loss: 0.30885761976242065
train-epoch-step: 1-574 -- Loss: 0.3958996534347534
train-epoch-step: 1-575 -- Loss: 0.4652538299560547
train-epoch-step: 1-576 -- Loss: 0.19330599904060364
train-epoch-step: 1-577 -- Loss: 0.24021685123443604
train-epoch-step: 1-578 -- Loss: 0.34364956617355347
train-epoch-step: 1-579 -- Loss: 0.2446453869342804
train-epoch-step: 1-580 -- Loss: 0.292835533618927
train-epoch-step: 1-581 -- Loss: 0.19963431358337402
train-epoch-step: 1-582 -- Loss: 0.3563516139984131
train-epoch-step: 1-583 -- Loss: 0.3343356251716614
train-epoch-step: 1-584 -- Loss: 0.2869569659233093
train-epoch-step: 1-585 -- Loss: 0.2783876061439514
train-epoch-step: 1-586 -- Loss: 0.3940649926662445
train-epoch-step: 1-587 -- Loss: 0.256475567817688
train-epoch-step: 1-588 -- Loss: 0.19832341372966766
val-epoch-step: 1-589 -- Loss: 0.3529558777809143
val-epoch-step: 1-590 -- Loss: 0.21299880743026733
val-epoch-step: 1-591 -- Loss: 0.32719534635543823
val-epoch-step: 1-592 -- Loss: 0.2562043070793152
val-epoch-step: 1-593 -- Loss: 0.21116971969604492
val-epoch-step: 1-594 -- Loss: 0.45034271478652954
val-epoch-step: 1-595 -- Loss: 0.24746978282928467
val-epoch-step: 1-596 -- Loss: 0.2942543625831604
val-epoch-step: 1-597 -- Loss: 0.27997440099716187
val-epoch-step: 1-598 -- Loss: 0.23286685347557068
val-epoch-step: 1-599 -- Loss: 0.26694247126579285
val-epoch-step: 1-600 -- Loss: 0.25917914509773254
val-epoch-step: 1-601 -- Loss: 0.2081839144229889
val-epoch-step: 1-602 -- Loss: 0.2160394787788391
val-epoch-step: 1-603 -- Loss: 0.31249845027923584
val-epoch-step: 1-604 -- Loss: 0.19463123381137848
val-epoch-step: 1-605 -- Loss: 0.2138407975435257
val-epoch-step: 1-606 -- Loss: 0.44157665967941284
val-epoch-step: 1-607 -- Loss: 0.21640758216381073
val-epoch-step: 1-608 -- Loss: 0.3590581715106964
val-epoch-step: 1-609 -- Loss: 0.2594020366668701
val-epoch-step: 1-610 -- Loss: 0.30224132537841797
val-epoch-step: 1-611 -- Loss: 0.23478177189826965
val-epoch-step: 1-612 -- Loss: 0.4057164490222931
val-epoch-step: 1-613 -- Loss: 0.2563754916191101
val-epoch-step: 1-614 -- Loss: 0.21662846207618713
val-epoch-step: 1-615 -- Loss: 0.2758358120918274
val-epoch-step: 1-616 -- Loss: 0.20300158858299255
val-epoch-step: 1-617 -- Loss: 0.3291859030723572
val-epoch-step: 1-618 -- Loss: 0.27496111392974854
val-epoch-step: 1-619 -- Loss: 0.3078308701515198
val-epoch-step: 1-620 -- Loss: 0.20721150934696198
val-epoch-step: 1-621 -- Loss: 0.20316532254219055
val-epoch-step: 1-622 -- Loss: 0.2072877436876297
val-epoch-step: 1-623 -- Loss: 0.22569355368614197
val-epoch-step: 1-624 -- Loss: 0.24012914299964905
val-epoch-step: 1-625 -- Loss: 0.21762561798095703
val-epoch-step: 1-626 -- Loss: 0.23156042397022247
val-epoch-step: 1-627 -- Loss: 0.2803446054458618
val-epoch-step: 1-628 -- Loss: 0.5240730047225952
val-epoch-step: 1-629 -- Loss: 0.29031872749328613
val-epoch-step: 1-630 -- Loss: 0.4963299632072449
val-epoch-step: 1-631 -- Loss: 0.21864727139472961
val-epoch-step: 1-632 -- Loss: 0.27536648511886597
val-epoch-step: 1-633 -- Loss: 0.22382816672325134
val-epoch-step: 1-634 -- Loss: 0.2041110247373581
val-epoch-step: 1-635 -- Loss: 0.15716707706451416
val-epoch-step: 1-636 -- Loss: 0.23285967111587524
val-epoch-step: 1-637 -- Loss: 0.27070778608322144
val-epoch-step: 1-638 -- Loss: 0.2212401032447815
val-epoch-step: 1-639 -- Loss: 0.3586254119873047
val-epoch-step: 1-640 -- Loss: 0.3727346658706665
val-epoch-step: 1-641 -- Loss: 0.18386447429656982
val-epoch-step: 1-642 -- Loss: 0.2820605933666229
val-epoch-step: 1-643 -- Loss: 0.2862433195114136
val-epoch-step: 1-644 -- Loss: 0.2511897385120392
val-epoch-step: 1-645 -- Loss: 0.3217591643333435
val-epoch-step: 1-646 -- Loss: 0.21530574560165405
val-epoch-step: 1-647 -- Loss: 0.19816821813583374
val-epoch-step: 1-648 -- Loss: 0.240231454372406
val-epoch-step: 1-649 -- Loss: 0.4991995394229889
val-epoch-step: 1-650 -- Loss: 0.3570612072944641
val-epoch-step: 1-651 -- Loss: 0.19530045986175537
val-epoch-step: 1-652 -- Loss: 0.2242095023393631
val-epoch-step: 1-653 -- Loss: 0.27698373794555664
val-epoch-step: 1-654 -- Loss: 0.15973936021327972
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100688934326172
train-epoch-step: 1-4 -- Loss: 1.5449960231781006
train-epoch-step: 1-5 -- Loss: 1.4992728233337402
train-epoch-step: 1-6 -- Loss: 1.602989673614502
train-epoch-step: 1-7 -- Loss: 1.4446908235549927
train-epoch-step: 1-8 -- Loss: 1.4407986402511597
train-epoch-step: 1-9 -- Loss: 1.4630992412567139
train-epoch-step: 1-10 -- Loss: 1.4210798740386963
train-epoch-step: 1-11 -- Loss: 1.2647467851638794
train-epoch-step: 1-12 -- Loss: 1.1827374696731567
train-epoch-step: 1-13 -- Loss: 1.216467261314392
train-epoch-step: 1-14 -- Loss: 1.0302917957305908
train-epoch-step: 1-15 -- Loss: 0.9770121574401855
train-epoch-step: 1-16 -- Loss: 0.9237378835678101
train-epoch-step: 1-17 -- Loss: 0.9749886393547058
train-epoch-step: 1-18 -- Loss: 0.8352214097976685
train-epoch-step: 1-19 -- Loss: 0.6835276484489441
train-epoch-step: 1-20 -- Loss: 0.7809185981750488
train-epoch-step: 1-21 -- Loss: 0.8414639234542847
train-epoch-step: 1-22 -- Loss: 0.5579992532730103
train-epoch-step: 1-23 -- Loss: 0.5644631385803223
train-epoch-step: 1-24 -- Loss: 0.47869810461997986
train-epoch-step: 1-25 -- Loss: 0.6165966987609863
train-epoch-step: 1-26 -- Loss: 0.5283864736557007
train-epoch-step: 1-27 -- Loss: 0.7722481489181519
train-epoch-step: 1-28 -- Loss: 0.3749021589756012
train-epoch-step: 1-29 -- Loss: 0.5498186349868774
train-epoch-step: 1-30 -- Loss: 0.2908301055431366
train-epoch-step: 1-31 -- Loss: 0.35737526416778564
train-epoch-step: 1-32 -- Loss: 0.41259753704071045
train-epoch-step: 1-33 -- Loss: 0.6393531560897827
train-epoch-step: 1-34 -- Loss: 0.40499061346054077
train-epoch-step: 1-35 -- Loss: 0.5428617000579834
train-epoch-step: 1-36 -- Loss: 0.3633141815662384
train-epoch-step: 1-37 -- Loss: 0.3564086854457855
train-epoch-step: 1-38 -- Loss: 0.4042130708694458
train-epoch-step: 1-39 -- Loss: 0.5129039287567139
train-epoch-step: 1-40 -- Loss: 0.45598316192626953
train-epoch-step: 1-41 -- Loss: 0.48715832829475403
train-epoch-step: 1-42 -- Loss: 0.3590236306190491
train-epoch-step: 1-43 -- Loss: 0.6816826462745667
train-epoch-step: 1-44 -- Loss: 0.29550114274024963
train-epoch-step: 1-45 -- Loss: 0.2732400894165039
train-epoch-step: 1-46 -- Loss: 0.3959929943084717
train-epoch-step: 1-47 -- Loss: 0.43391597270965576
train-epoch-step: 1-48 -- Loss: 0.34073179960250854
train-epoch-step: 1-49 -- Loss: 0.42424046993255615
train-epoch-step: 1-50 -- Loss: 0.2817537188529968
train-epoch-step: 1-51 -- Loss: 0.3968772888183594
train-epoch-step: 1-52 -- Loss: 0.31048429012298584
train-epoch-step: 1-53 -- Loss: 0.4749893248081207
train-epoch-step: 1-54 -- Loss: 0.5797153115272522
train-epoch-step: 1-55 -- Loss: 0.3617650270462036
train-epoch-step: 1-56 -- Loss: 0.40748751163482666
train-epoch-step: 1-57 -- Loss: 0.526416540145874
train-epoch-step: 1-58 -- Loss: 0.5216407775878906
train-epoch-step: 1-59 -- Loss: 0.5200030207633972
train-epoch-step: 1-60 -- Loss: 0.26079100370407104
train-epoch-step: 1-61 -- Loss: 0.4056040644645691
train-epoch-step: 1-62 -- Loss: 0.35939013957977295
train-epoch-step: 1-63 -- Loss: 0.27935153245925903
train-epoch-step: 1-64 -- Loss: 0.33600547909736633
train-epoch-step: 1-65 -- Loss: 0.37707799673080444
train-epoch-step: 1-66 -- Loss: 0.21532392501831055
train-epoch-step: 1-67 -- Loss: 0.25218191742897034
train-epoch-step: 1-68 -- Loss: 0.44071316719055176
train-epoch-step: 1-69 -- Loss: 0.2590921223163605
train-epoch-step: 1-70 -- Loss: 0.48935961723327637
train-epoch-step: 1-71 -- Loss: 0.5710887908935547
train-epoch-step: 1-72 -- Loss: 0.34158438444137573
train-epoch-step: 1-73 -- Loss: 0.41108155250549316
train-epoch-step: 1-74 -- Loss: 0.19844752550125122
train-epoch-step: 1-75 -- Loss: 0.2803974151611328
train-epoch-step: 1-76 -- Loss: 0.2847900092601776
train-epoch-step: 1-77 -- Loss: 0.3934432864189148
train-epoch-step: 1-78 -- Loss: 0.5099208354949951
train-epoch-step: 1-79 -- Loss: 0.36984503269195557
train-epoch-step: 1-80 -- Loss: 0.4491811692714691
train-epoch-step: 1-81 -- Loss: 0.2776852250099182
train-epoch-step: 1-82 -- Loss: 0.459501177072525
train-epoch-step: 1-83 -- Loss: 0.350800096988678
train-epoch-step: 1-84 -- Loss: 0.38661980628967285
train-epoch-step: 1-85 -- Loss: 0.3349054157733917
train-epoch-step: 1-86 -- Loss: 0.21848756074905396
train-epoch-step: 1-87 -- Loss: 0.4000515341758728
train-epoch-step: 1-88 -- Loss: 0.26446229219436646
train-epoch-step: 1-89 -- Loss: 0.3281857371330261
train-epoch-step: 1-90 -- Loss: 0.3476887345314026
train-epoch-step: 1-91 -- Loss: 0.4357019364833832
train-epoch-step: 1-92 -- Loss: 0.3021279275417328
train-epoch-step: 1-93 -- Loss: 0.3336118757724762
train-epoch-step: 1-94 -- Loss: 0.4572864770889282
train-epoch-step: 1-95 -- Loss: 0.366536021232605
train-epoch-step: 1-96 -- Loss: 0.3855537176132202
train-epoch-step: 1-97 -- Loss: 0.35156890749931335
train-epoch-step: 1-98 -- Loss: 0.2954016923904419
train-epoch-step: 1-99 -- Loss: 0.3141632080078125
train-epoch-step: 1-100 -- Loss: 0.3497096002101898
train-epoch-step: 1-101 -- Loss: 0.4426141679286957
train-epoch-step: 1-102 -- Loss: 0.4777122139930725
train-epoch-step: 1-103 -- Loss: 0.3694913983345032
train-epoch-step: 1-104 -- Loss: 0.2868516147136688
train-epoch-step: 1-105 -- Loss: 0.6602672934532166
train-epoch-step: 1-106 -- Loss: 0.32299235463142395
train-epoch-step: 1-107 -- Loss: 0.37328040599823
train-epoch-step: 1-108 -- Loss: 0.32801342010498047
train-epoch-step: 1-109 -- Loss: 0.2767921984195709
train-epoch-step: 1-110 -- Loss: 0.3273780345916748
train-epoch-step: 1-111 -- Loss: 0.3442104756832123
train-epoch-step: 1-112 -- Loss: 0.2741691470146179
train-epoch-step: 1-113 -- Loss: 0.36702072620391846
train-epoch-step: 1-114 -- Loss: 0.3907706141471863
train-epoch-step: 1-115 -- Loss: 0.2782326340675354
train-epoch-step: 1-116 -- Loss: 0.2517942786216736
train-epoch-step: 1-117 -- Loss: 0.23919349908828735
train-epoch-step: 1-118 -- Loss: 0.3554297089576721
train-epoch-step: 1-119 -- Loss: 0.2579813301563263
train-epoch-step: 1-120 -- Loss: 0.43987536430358887
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.551900029182434
train-epoch-step: 1-3 -- Loss: 1.5100688934326172
train-epoch-step: 1-4 -- Loss: 1.5449965000152588
train-epoch-step: 1-5 -- Loss: 1.4992716312408447
train-epoch-step: 1-6 -- Loss: 1.6029868125915527
train-epoch-step: 1-7 -- Loss: 1.4446837902069092
train-epoch-step: 1-8 -- Loss: 1.4407813549041748
train-epoch-step: 1-9 -- Loss: 1.463067889213562
train-epoch-step: 1-10 -- Loss: 1.4209847450256348
train-epoch-step: 1-11 -- Loss: 1.2645618915557861
train-epoch-step: 1-12 -- Loss: 1.1824958324432373
train-epoch-step: 1-13 -- Loss: 1.2163231372833252
train-epoch-step: 1-14 -- Loss: 1.0299651622772217
train-epoch-step: 1-15 -- Loss: 0.9768190383911133
train-epoch-step: 1-16 -- Loss: 0.9235489368438721
train-epoch-step: 1-17 -- Loss: 0.9746268391609192
train-epoch-step: 1-18 -- Loss: 0.8350878953933716
train-epoch-step: 1-19 -- Loss: 0.6835058927536011
train-epoch-step: 1-20 -- Loss: 0.7807660102844238
train-epoch-step: 1-21 -- Loss: 0.8416168093681335
train-epoch-step: 1-22 -- Loss: 0.5581621527671814
train-epoch-step: 1-23 -- Loss: 0.564447820186615
train-epoch-step: 1-24 -- Loss: 0.4789573848247528
train-epoch-step: 1-25 -- Loss: 0.6171254515647888
train-epoch-step: 1-26 -- Loss: 0.5281469821929932
train-epoch-step: 1-27 -- Loss: 0.7724593877792358
train-epoch-step: 1-28 -- Loss: 0.3747904300689697
train-epoch-step: 1-29 -- Loss: 0.5498295426368713
train-epoch-step: 1-30 -- Loss: 0.29067063331604004
train-epoch-step: 1-31 -- Loss: 0.3574838638305664
train-epoch-step: 1-32 -- Loss: 0.41265493631362915
train-epoch-step: 1-33 -- Loss: 0.6395672559738159
train-epoch-step: 1-34 -- Loss: 0.40490370988845825
train-epoch-step: 1-35 -- Loss: 0.5425829887390137
train-epoch-step: 1-36 -- Loss: 0.36308348178863525
train-epoch-step: 1-37 -- Loss: 0.35587161779403687
train-epoch-step: 1-38 -- Loss: 0.4039872884750366
train-epoch-step: 1-39 -- Loss: 0.5120490789413452
train-epoch-step: 1-40 -- Loss: 0.45567139983177185
train-epoch-step: 1-41 -- Loss: 0.48696550726890564
train-epoch-step: 1-42 -- Loss: 0.35895228385925293
train-epoch-step: 1-43 -- Loss: 0.6817208528518677
train-epoch-step: 1-44 -- Loss: 0.29500502347946167
train-epoch-step: 1-45 -- Loss: 0.27326688170433044
train-epoch-step: 1-46 -- Loss: 0.3951832056045532
train-epoch-step: 1-47 -- Loss: 0.4319193363189697
train-epoch-step: 1-48 -- Loss: 0.3403790295124054
train-epoch-step: 1-49 -- Loss: 0.4237639307975769
train-epoch-step: 1-50 -- Loss: 0.2809447646141052
train-epoch-step: 1-51 -- Loss: 0.39634567499160767
train-epoch-step: 1-52 -- Loss: 0.3106550872325897
train-epoch-step: 1-53 -- Loss: 0.47362446784973145
train-epoch-step: 1-54 -- Loss: 0.5819069147109985
train-epoch-step: 1-55 -- Loss: 0.36184847354888916
train-epoch-step: 1-56 -- Loss: 0.4077475368976593
train-epoch-step: 1-57 -- Loss: 0.5262535214424133
train-epoch-step: 1-58 -- Loss: 0.5213613510131836
train-epoch-step: 1-59 -- Loss: 0.5196607708930969
train-epoch-step: 1-60 -- Loss: 0.26063865423202515
train-epoch-step: 1-61 -- Loss: 0.40565359592437744
train-epoch-step: 1-62 -- Loss: 0.3590131998062134
train-epoch-step: 1-63 -- Loss: 0.2792341709136963
train-epoch-step: 1-64 -- Loss: 0.33557015657424927
train-epoch-step: 1-65 -- Loss: 0.3774036467075348
train-epoch-step: 1-66 -- Loss: 0.215215265750885
train-epoch-step: 1-67 -- Loss: 0.2520662546157837
train-epoch-step: 1-68 -- Loss: 0.44105100631713867
train-epoch-step: 1-69 -- Loss: 0.25900739431381226
train-epoch-step: 1-70 -- Loss: 0.48873817920684814
train-epoch-step: 1-71 -- Loss: 0.5705363750457764
train-epoch-step: 1-72 -- Loss: 0.3410640358924866
train-epoch-step: 1-73 -- Loss: 0.4110948145389557
train-epoch-step: 1-74 -- Loss: 0.19815361499786377
train-epoch-step: 1-75 -- Loss: 0.28008025884628296
train-epoch-step: 1-76 -- Loss: 0.28356969356536865
train-epoch-step: 1-77 -- Loss: 0.393574059009552
train-epoch-step: 1-78 -- Loss: 0.509287416934967
train-epoch-step: 1-79 -- Loss: 0.3699324131011963
train-epoch-step: 1-80 -- Loss: 0.448906809091568
train-epoch-step: 1-81 -- Loss: 0.27840539813041687
train-epoch-step: 1-82 -- Loss: 0.4596969485282898
train-epoch-step: 1-83 -- Loss: 0.35128504037857056
train-epoch-step: 1-84 -- Loss: 0.38772064447402954
train-epoch-step: 1-85 -- Loss: 0.3348766565322876
train-epoch-step: 1-86 -- Loss: 0.21890875697135925
train-epoch-step: 1-87 -- Loss: 0.4004252851009369
train-epoch-step: 1-88 -- Loss: 0.2649857997894287
train-epoch-step: 1-89 -- Loss: 0.32756099104881287
train-epoch-step: 1-90 -- Loss: 0.34777379035949707
train-epoch-step: 1-91 -- Loss: 0.4358031451702118
train-epoch-step: 1-92 -- Loss: 0.3024502396583557
train-epoch-step: 1-93 -- Loss: 0.3339933753013611
train-epoch-step: 1-94 -- Loss: 0.4556642770767212
train-epoch-step: 1-95 -- Loss: 0.3663804531097412
train-epoch-step: 1-96 -- Loss: 0.3855414390563965
train-epoch-step: 1-97 -- Loss: 0.3512910008430481
train-epoch-step: 1-98 -- Loss: 0.2957637310028076
train-epoch-step: 1-99 -- Loss: 0.31444597244262695
train-epoch-step: 1-100 -- Loss: 0.34953105449676514
train-epoch-step: 1-101 -- Loss: 0.44278573989868164
train-epoch-step: 1-102 -- Loss: 0.47788524627685547
train-epoch-step: 1-103 -- Loss: 0.3697296679019928
train-epoch-step: 1-104 -- Loss: 0.2872637212276459
train-epoch-step: 1-105 -- Loss: 0.6598649621009827
train-epoch-step: 1-106 -- Loss: 0.322865754365921
train-epoch-step: 1-107 -- Loss: 0.3733361065387726
train-epoch-step: 1-108 -- Loss: 0.328502893447876
train-epoch-step: 1-109 -- Loss: 0.2769487500190735
train-epoch-step: 1-110 -- Loss: 0.32661697268486023
train-epoch-step: 1-111 -- Loss: 0.3439052104949951
train-epoch-step: 1-112 -- Loss: 0.27480050921440125
train-epoch-step: 1-113 -- Loss: 0.36761441826820374
train-epoch-step: 1-114 -- Loss: 0.3923846483230591
train-epoch-step: 1-115 -- Loss: 0.2783322036266327
train-epoch-step: 1-116 -- Loss: 0.2519809603691101
train-epoch-step: 1-117 -- Loss: 0.23922684788703918
train-epoch-step: 1-118 -- Loss: 0.3556348383426666
train-epoch-step: 1-119 -- Loss: 0.2583039402961731
train-epoch-step: 1-120 -- Loss: 0.4388597905635834
train-epoch-step: 1-121 -- Loss: 0.40754175186157227
train-epoch-step: 1-122 -- Loss: 0.3843037784099579
train-epoch-step: 1-123 -- Loss: 0.37836432456970215
train-epoch-step: 1-124 -- Loss: 0.22324809432029724
train-epoch-step: 1-125 -- Loss: 0.24836483597755432
train-epoch-step: 1-126 -- Loss: 0.39554256200790405
train-epoch-step: 1-127 -- Loss: 0.2808482348918915
train-epoch-step: 1-128 -- Loss: 0.3314135670661926
train-epoch-step: 1-129 -- Loss: 0.23530100286006927
train-epoch-step: 1-130 -- Loss: 0.317130982875824
train-epoch-step: 1-131 -- Loss: 0.23956476151943207
train-epoch-step: 1-132 -- Loss: 0.32914626598358154
train-epoch-step: 1-133 -- Loss: 0.20366787910461426
train-epoch-step: 1-134 -- Loss: 0.3451133966445923
train-epoch-step: 1-135 -- Loss: 0.21741202473640442
train-epoch-step: 1-136 -- Loss: 0.20509254932403564
train-epoch-step: 1-137 -- Loss: 0.4330637454986572
train-epoch-step: 1-138 -- Loss: 0.5006160736083984
train-epoch-step: 1-139 -- Loss: 0.23992997407913208
train-epoch-step: 1-140 -- Loss: 0.395304799079895
train-epoch-step: 1-141 -- Loss: 0.41014426946640015
train-epoch-step: 1-142 -- Loss: 0.3610718846321106
train-epoch-step: 1-143 -- Loss: 0.31783291697502136
train-epoch-step: 1-144 -- Loss: 0.33742284774780273
train-epoch-step: 1-145 -- Loss: 0.2540997266769409
train-epoch-step: 1-146 -- Loss: 0.3176323473453522
train-epoch-step: 1-147 -- Loss: 0.33977505564689636
train-epoch-step: 1-148 -- Loss: 0.28676480054855347
train-epoch-step: 1-149 -- Loss: 0.2036287933588028
train-epoch-step: 1-150 -- Loss: 0.3413304388523102
train-epoch-step: 1-151 -- Loss: 0.3584301471710205
train-epoch-step: 1-152 -- Loss: 0.33555030822753906
train-epoch-step: 1-153 -- Loss: 0.4934249222278595
train-epoch-step: 1-154 -- Loss: 0.2502986192703247
train-epoch-step: 1-155 -- Loss: 0.25004738569259644
train-epoch-step: 1-156 -- Loss: 0.21201886236667633
train-epoch-step: 1-157 -- Loss: 0.2838437855243683
train-epoch-step: 1-158 -- Loss: 0.3109547197818756
train-epoch-step: 1-159 -- Loss: 0.30186939239501953
train-epoch-step: 1-160 -- Loss: 0.35890352725982666
train-epoch-step: 1-161 -- Loss: 0.3562808334827423
train-epoch-step: 1-162 -- Loss: 0.3974078893661499
train-epoch-step: 1-163 -- Loss: 0.33420315384864807
train-epoch-step: 1-164 -- Loss: 0.31353893876075745
train-epoch-step: 1-165 -- Loss: 0.2758415937423706
train-epoch-step: 1-166 -- Loss: 0.2124597728252411
train-epoch-step: 1-167 -- Loss: 0.20330335199832916
train-epoch-step: 1-168 -- Loss: 0.34159380197525024
train-epoch-step: 1-169 -- Loss: 0.2367607057094574
train-epoch-step: 1-170 -- Loss: 0.3670003414154053
train-epoch-step: 1-171 -- Loss: 0.29469841718673706
train-epoch-step: 1-172 -- Loss: 0.43759390711784363
train-epoch-step: 1-173 -- Loss: 0.23037704825401306
train-epoch-step: 1-174 -- Loss: 0.4599835276603699
train-epoch-step: 1-175 -- Loss: 0.3429437279701233
train-epoch-step: 1-176 -- Loss: 0.2347203940153122
train-epoch-step: 1-177 -- Loss: 0.30811598896980286
train-epoch-step: 1-178 -- Loss: 0.30688372254371643
train-epoch-step: 1-179 -- Loss: 0.23402762413024902
train-epoch-step: 1-180 -- Loss: 0.24872563779354095
train-epoch-step: 1-181 -- Loss: 0.3182521462440491
train-epoch-step: 1-182 -- Loss: 0.3313697576522827
train-epoch-step: 1-183 -- Loss: 0.7135069370269775
train-epoch-step: 1-184 -- Loss: 0.2592403292655945
train-epoch-step: 1-185 -- Loss: 0.24407866597175598
train-epoch-step: 1-186 -- Loss: 0.33457234501838684
train-epoch-step: 1-187 -- Loss: 0.3814149796962738
train-epoch-step: 1-188 -- Loss: 0.33936843276023865
train-epoch-step: 1-189 -- Loss: 0.2405037134885788
train-epoch-step: 1-190 -- Loss: 0.28449296951293945
train-epoch-step: 1-191 -- Loss: 0.2908945679664612
train-epoch-step: 1-192 -- Loss: 0.41108980774879456
train-epoch-step: 1-193 -- Loss: 0.41628217697143555
train-epoch-step: 1-194 -- Loss: 0.337719202041626
train-epoch-step: 1-195 -- Loss: 0.3321664035320282
train-epoch-step: 1-196 -- Loss: 0.2982203960418701
train-epoch-step: 1-197 -- Loss: 0.21888408064842224
train-epoch-step: 1-198 -- Loss: 0.20927512645721436
train-epoch-step: 1-199 -- Loss: 0.27388495206832886
train-epoch-step: 1-200 -- Loss: 0.20535056293010712
train-epoch-step: 1-201 -- Loss: 0.3366406559944153
train-epoch-step: 1-202 -- Loss: 0.22357672452926636
train-epoch-step: 1-203 -- Loss: 0.3035925328731537
train-epoch-step: 1-204 -- Loss: 0.26262569427490234
train-epoch-step: 1-205 -- Loss: 0.2956748604774475
train-epoch-step: 1-206 -- Loss: 0.3569437861442566
train-epoch-step: 1-207 -- Loss: 0.23072977364063263
train-epoch-step: 1-208 -- Loss: 0.29397088289260864
train-epoch-step: 1-209 -- Loss: 0.23378995060920715
train-epoch-step: 1-210 -- Loss: 0.22957953810691833
train-epoch-step: 1-211 -- Loss: 0.3564121127128601
train-epoch-step: 1-212 -- Loss: 0.32649701833724976
train-epoch-step: 1-213 -- Loss: 0.22642895579338074
train-epoch-step: 1-214 -- Loss: 0.25551122426986694
train-epoch-step: 1-215 -- Loss: 0.2239983081817627
train-epoch-step: 1-216 -- Loss: 0.3065118193626404
train-epoch-step: 1-217 -- Loss: 0.3820486068725586
train-epoch-step: 1-218 -- Loss: 0.26469850540161133
train-epoch-step: 1-219 -- Loss: 0.3409552574157715
train-epoch-step: 1-220 -- Loss: 0.21723079681396484
train-epoch-step: 1-221 -- Loss: 0.38146618008613586
train-epoch-step: 1-222 -- Loss: 0.2140992283821106
train-epoch-step: 1-223 -- Loss: 0.2878330945968628
train-epoch-step: 1-224 -- Loss: 0.2969006896018982
train-epoch-step: 1-225 -- Loss: 0.47587573528289795
train-epoch-step: 1-226 -- Loss: 0.3435327708721161
train-epoch-step: 1-227 -- Loss: 0.37654995918273926
train-epoch-step: 1-228 -- Loss: 0.2914905846118927
train-epoch-step: 1-229 -- Loss: 0.35691702365875244
train-epoch-step: 1-230 -- Loss: 0.275728702545166
train-epoch-step: 1-231 -- Loss: 0.3017710745334625
train-epoch-step: 1-232 -- Loss: 0.3057333827018738
train-epoch-step: 1-233 -- Loss: 0.15884247422218323
train-epoch-step: 1-234 -- Loss: 0.2912479639053345
train-epoch-step: 1-235 -- Loss: 0.26072391867637634
train-epoch-step: 1-236 -- Loss: 0.3045652210712433
train-epoch-step: 1-237 -- Loss: 0.4099063277244568
train-epoch-step: 1-238 -- Loss: 0.2706022560596466
train-epoch-step: 1-239 -- Loss: 0.23480738699436188
train-epoch-step: 1-240 -- Loss: 0.3673824071884155
train-epoch-step: 1-241 -- Loss: 0.2624136507511139
train-epoch-step: 1-242 -- Loss: 0.3631955683231354
train-epoch-step: 1-243 -- Loss: 0.41289985179901123
train-epoch-step: 1-244 -- Loss: 0.3529684543609619
train-epoch-step: 1-245 -- Loss: 0.3923540413379669
train-epoch-step: 1-246 -- Loss: 0.44771450757980347
train-epoch-step: 1-247 -- Loss: 0.40138673782348633
train-epoch-step: 1-248 -- Loss: 0.28027382493019104
train-epoch-step: 1-249 -- Loss: 0.2297249436378479
train-epoch-step: 1-250 -- Loss: 0.4075165390968323
train-epoch-step: 1-251 -- Loss: 0.19277118146419525
train-epoch-step: 1-252 -- Loss: 0.2836225628852844
train-epoch-step: 1-253 -- Loss: 0.2136853188276291
train-epoch-step: 1-254 -- Loss: 0.3866790533065796
train-epoch-step: 1-255 -- Loss: 0.22478848695755005
train-epoch-step: 1-256 -- Loss: 0.23389820754528046
train-epoch-step: 1-257 -- Loss: 0.2890792489051819
train-epoch-step: 1-258 -- Loss: 0.2787323296070099
train-epoch-step: 1-259 -- Loss: 0.17562836408615112
train-epoch-step: 1-260 -- Loss: 0.3432270288467407
train-epoch-step: 1-261 -- Loss: 0.26534363627433777
train-epoch-step: 1-262 -- Loss: 0.4835549294948578
train-epoch-step: 1-263 -- Loss: 0.3894326686859131
train-epoch-step: 1-264 -- Loss: 0.2685166001319885
train-epoch-step: 1-265 -- Loss: 0.18514080345630646
train-epoch-step: 1-266 -- Loss: 0.24119436740875244
train-epoch-step: 1-267 -- Loss: 0.22710123658180237
train-epoch-step: 1-268 -- Loss: 0.20052577555179596
train-epoch-step: 1-269 -- Loss: 0.27033597230911255
train-epoch-step: 1-270 -- Loss: 0.17468594014644623
train-epoch-step: 1-271 -- Loss: 0.26281189918518066
train-epoch-step: 1-272 -- Loss: 0.19919060170650482
train-epoch-step: 1-273 -- Loss: 0.2049875557422638
train-epoch-step: 1-274 -- Loss: 0.34318435192108154
train-epoch-step: 1-275 -- Loss: 0.3157905042171478
train-epoch-step: 1-276 -- Loss: 0.24005544185638428
train-epoch-step: 1-277 -- Loss: 0.23327501118183136
train-epoch-step: 1-278 -- Loss: 0.24575771391391754
train-epoch-step: 1-279 -- Loss: 0.2175285518169403
train-epoch-step: 1-280 -- Loss: 0.32322958111763
train-epoch-step: 1-281 -- Loss: 0.2742993235588074
train-epoch-step: 1-282 -- Loss: 0.23664867877960205
train-epoch-step: 1-283 -- Loss: 0.17334704101085663
train-epoch-step: 1-284 -- Loss: 0.2990715801715851
train-epoch-step: 1-285 -- Loss: 0.3204779326915741
train-epoch-step: 1-286 -- Loss: 0.24527627229690552
train-epoch-step: 1-287 -- Loss: 0.34327325224876404
train-epoch-step: 1-288 -- Loss: 0.16664549708366394
train-epoch-step: 1-289 -- Loss: 0.20836281776428223
train-epoch-step: 1-290 -- Loss: 0.2901516556739807
train-epoch-step: 1-291 -- Loss: 0.19602617621421814
train-epoch-step: 1-292 -- Loss: 0.245945006608963
train-epoch-step: 1-293 -- Loss: 0.2425777018070221
train-epoch-step: 1-294 -- Loss: 0.28298914432525635
train-epoch-step: 1-295 -- Loss: 0.5192975401878357
train-epoch-step: 1-296 -- Loss: 0.3022826015949249
train-epoch-step: 1-297 -- Loss: 0.2844546437263489
train-epoch-step: 1-298 -- Loss: 0.3862053155899048
train-epoch-step: 1-299 -- Loss: 0.2785089612007141
train-epoch-step: 1-300 -- Loss: 0.2667677700519562
train-epoch-step: 1-301 -- Loss: 0.2775112986564636
train-epoch-step: 1-302 -- Loss: 0.3781473636627197
train-epoch-step: 1-303 -- Loss: 0.3513980805873871
train-epoch-step: 1-304 -- Loss: 0.23323102295398712
train-epoch-step: 1-305 -- Loss: 0.24336719512939453
train-epoch-step: 1-306 -- Loss: 0.4214208126068115
train-epoch-step: 1-307 -- Loss: 0.26592904329299927
train-epoch-step: 1-308 -- Loss: 0.43380749225616455
train-epoch-step: 1-309 -- Loss: 0.26846927404403687
train-epoch-step: 1-310 -- Loss: 0.23813150823116302
train-epoch-step: 1-311 -- Loss: 0.24988222122192383
train-epoch-step: 1-312 -- Loss: 0.3265925943851471
train-epoch-step: 1-313 -- Loss: 0.16010840237140656
train-epoch-step: 1-314 -- Loss: 0.32121115922927856
train-epoch-step: 1-315 -- Loss: 0.2979834973812103
train-epoch-step: 1-316 -- Loss: 0.2422189861536026
train-epoch-step: 1-317 -- Loss: 0.21603530645370483
train-epoch-step: 1-318 -- Loss: 0.27115458250045776
train-epoch-step: 1-319 -- Loss: 0.2724123001098633
train-epoch-step: 1-320 -- Loss: 0.18540449440479279
train-epoch-step: 1-321 -- Loss: 0.22101357579231262
train-epoch-step: 1-322 -- Loss: 0.32923436164855957
train-epoch-step: 1-323 -- Loss: 0.2478356510400772
train-epoch-step: 1-324 -- Loss: 0.4112135171890259
train-epoch-step: 1-325 -- Loss: 0.26231637597084045
train-epoch-step: 1-326 -- Loss: 0.3135719895362854
train-epoch-step: 1-327 -- Loss: 0.31262579560279846
train-epoch-step: 1-328 -- Loss: 0.3385305404663086
train-epoch-step: 1-329 -- Loss: 0.5258117914199829
train-epoch-step: 1-330 -- Loss: 0.5574874877929688
train-epoch-step: 1-331 -- Loss: 0.34942057728767395
train-epoch-step: 1-332 -- Loss: 0.1700269877910614
train-epoch-step: 1-333 -- Loss: 0.30714282393455505
train-epoch-step: 1-334 -- Loss: 0.24611394107341766
train-epoch-step: 1-335 -- Loss: 0.2673690915107727
train-epoch-step: 1-336 -- Loss: 0.2596955895423889
train-epoch-step: 1-337 -- Loss: 0.32163551449775696
train-epoch-step: 1-338 -- Loss: 0.2646794319152832
train-epoch-step: 1-339 -- Loss: 0.2312619984149933
train-epoch-step: 1-340 -- Loss: 0.352115660905838
train-epoch-step: 1-341 -- Loss: 0.20038630068302155
train-epoch-step: 1-342 -- Loss: 0.25039517879486084
train-epoch-step: 1-343 -- Loss: 0.2276747226715088
train-epoch-step: 1-344 -- Loss: 0.27012521028518677
train-epoch-step: 1-345 -- Loss: 0.20973065495491028
train-epoch-step: 1-346 -- Loss: 0.3158937692642212
train-epoch-step: 1-347 -- Loss: 0.2686035633087158
train-epoch-step: 1-348 -- Loss: 0.3336867094039917
train-epoch-step: 1-349 -- Loss: 0.3421809673309326
train-epoch-step: 1-350 -- Loss: 0.4350857138633728
train-epoch-step: 1-351 -- Loss: 0.31525981426239014
train-epoch-step: 1-352 -- Loss: 0.2375086098909378
train-epoch-step: 1-353 -- Loss: 0.3381893038749695
train-epoch-step: 1-354 -- Loss: 0.43310195207595825
train-epoch-step: 1-355 -- Loss: 0.1794392168521881
train-epoch-step: 1-356 -- Loss: 0.18650096654891968
train-epoch-step: 1-357 -- Loss: 0.3001866936683655
train-epoch-step: 1-358 -- Loss: 0.27736544609069824
train-epoch-step: 1-359 -- Loss: 0.21140837669372559
train-epoch-step: 1-360 -- Loss: 0.2181948721408844
train-epoch-step: 1-361 -- Loss: 0.4386110305786133
train-epoch-step: 1-362 -- Loss: 0.24980320036411285
train-epoch-step: 1-363 -- Loss: 0.18891048431396484
train-epoch-step: 1-364 -- Loss: 0.27004697918891907
train-epoch-step: 1-365 -- Loss: 0.25938746333122253
train-epoch-step: 1-366 -- Loss: 0.29843682050704956
train-epoch-step: 1-367 -- Loss: 0.3958314061164856
train-epoch-step: 1-368 -- Loss: 0.32720834016799927
train-epoch-step: 1-369 -- Loss: 0.45391416549682617
train-epoch-step: 1-370 -- Loss: 0.2320200800895691
train-epoch-step: 1-371 -- Loss: 0.19152888655662537
train-epoch-step: 1-372 -- Loss: 0.22274968028068542
train-epoch-step: 1-373 -- Loss: 0.3113406002521515
train-epoch-step: 1-374 -- Loss: 0.2475346326828003
train-epoch-step: 1-375 -- Loss: 0.44287797808647156
train-epoch-step: 1-376 -- Loss: 0.3235998749732971
train-epoch-step: 1-377 -- Loss: 0.41576188802719116
train-epoch-step: 1-378 -- Loss: 0.3280791640281677
train-epoch-step: 1-379 -- Loss: 0.17730490863323212
train-epoch-step: 1-380 -- Loss: 0.17850355803966522
train-epoch-step: 1-381 -- Loss: 0.37600839138031006
train-epoch-step: 1-382 -- Loss: 0.436023473739624
train-epoch-step: 1-383 -- Loss: 0.3717363476753235
train-epoch-step: 1-384 -- Loss: 0.33500897884368896
train-epoch-step: 1-385 -- Loss: 0.2899237871170044
train-epoch-step: 1-386 -- Loss: 0.3886472284793854
train-epoch-step: 1-387 -- Loss: 0.3195018768310547
train-epoch-step: 1-388 -- Loss: 0.30950361490249634
train-epoch-step: 1-389 -- Loss: 0.2925085127353668
train-epoch-step: 1-390 -- Loss: 0.23684440553188324
train-epoch-step: 1-391 -- Loss: 0.2393653392791748
train-epoch-step: 1-392 -- Loss: 0.27585354447364807
train-epoch-step: 1-393 -- Loss: 0.22734448313713074
train-epoch-step: 1-394 -- Loss: 0.3403802514076233
train-epoch-step: 1-395 -- Loss: 0.24304604530334473
train-epoch-step: 1-396 -- Loss: 0.19764289259910583
train-epoch-step: 1-397 -- Loss: 0.18281033635139465
train-epoch-step: 1-398 -- Loss: 0.28571975231170654
train-epoch-step: 1-399 -- Loss: 0.32571548223495483
train-epoch-step: 1-400 -- Loss: 0.43396061658859253
train-epoch-step: 1-401 -- Loss: 0.17911803722381592
train-epoch-step: 1-402 -- Loss: 0.42091304063796997
train-epoch-step: 1-403 -- Loss: 0.2626287341117859
train-epoch-step: 1-404 -- Loss: 0.2238095998764038
train-epoch-step: 1-405 -- Loss: 0.2115904986858368
train-epoch-step: 1-406 -- Loss: 0.24119041860103607
train-epoch-step: 1-407 -- Loss: 0.16947013139724731
train-epoch-step: 1-408 -- Loss: 0.23249772191047668
train-epoch-step: 1-409 -- Loss: 0.27292945981025696
train-epoch-step: 1-410 -- Loss: 0.29740703105926514
train-epoch-step: 1-411 -- Loss: 0.32934847474098206
train-epoch-step: 1-412 -- Loss: 0.2014906406402588
train-epoch-step: 1-413 -- Loss: 0.22400598227977753
train-epoch-step: 1-414 -- Loss: 0.22048501670360565
train-epoch-step: 1-415 -- Loss: 0.19380418956279755
train-epoch-step: 1-416 -- Loss: 0.4802822172641754
train-epoch-step: 1-417 -- Loss: 0.3177661597728729
train-epoch-step: 1-418 -- Loss: 0.42905157804489136
train-epoch-step: 1-419 -- Loss: 0.27287834882736206
train-epoch-step: 1-420 -- Loss: 0.2220345139503479
train-epoch-step: 1-421 -- Loss: 0.26010191440582275
train-epoch-step: 1-422 -- Loss: 0.24576187133789062
train-epoch-step: 1-423 -- Loss: 0.2766519784927368
train-epoch-step: 1-424 -- Loss: 0.21666893362998962
train-epoch-step: 1-425 -- Loss: 0.2761683166027069
train-epoch-step: 1-426 -- Loss: 0.24701525270938873
train-epoch-step: 1-427 -- Loss: 0.20179864764213562
train-epoch-step: 1-428 -- Loss: 0.3300163149833679
train-epoch-step: 1-429 -- Loss: 0.2940874993801117
train-epoch-step: 1-430 -- Loss: 0.20167572796344757
train-epoch-step: 1-431 -- Loss: 0.2594776153564453
train-epoch-step: 1-432 -- Loss: 0.4362010955810547
train-epoch-step: 1-433 -- Loss: 0.22960112988948822
train-epoch-step: 1-434 -- Loss: 0.25013667345046997
train-epoch-step: 1-435 -- Loss: 0.25669053196907043
train-epoch-step: 1-436 -- Loss: 0.23430639505386353
train-epoch-step: 1-437 -- Loss: 0.19919529557228088
train-epoch-step: 1-438 -- Loss: 0.28141558170318604
train-epoch-step: 1-439 -- Loss: 0.5269047617912292
train-epoch-step: 1-440 -- Loss: 0.22977979481220245
train-epoch-step: 1-441 -- Loss: 0.3449893593788147
train-epoch-step: 1-442 -- Loss: 0.2818743586540222
train-epoch-step: 1-443 -- Loss: 0.23923853039741516
train-epoch-step: 1-444 -- Loss: 0.3733140528202057
train-epoch-step: 1-445 -- Loss: 0.3333142101764679
train-epoch-step: 1-446 -- Loss: 0.22334833443164825
train-epoch-step: 1-447 -- Loss: 0.32080721855163574
train-epoch-step: 1-448 -- Loss: 0.38184016942977905
train-epoch-step: 1-449 -- Loss: 0.2696109712123871
train-epoch-step: 1-450 -- Loss: 0.2950223982334137
train-epoch-step: 1-451 -- Loss: 0.22500140964984894
train-epoch-step: 1-452 -- Loss: 0.20662009716033936
train-epoch-step: 1-453 -- Loss: 0.15193027257919312
train-epoch-step: 1-454 -- Loss: 0.3649604022502899
train-epoch-step: 1-455 -- Loss: 0.21822622418403625
train-epoch-step: 1-456 -- Loss: 0.18684284389019012
train-epoch-step: 1-457 -- Loss: 0.3387254476547241
train-epoch-step: 1-458 -- Loss: 0.2534807324409485
train-epoch-step: 1-459 -- Loss: 0.3550035357475281
train-epoch-step: 1-460 -- Loss: 0.19971105456352234
train-epoch-step: 1-461 -- Loss: 0.2249900847673416
train-epoch-step: 1-462 -- Loss: 0.23553255200386047
train-epoch-step: 1-463 -- Loss: 0.21658319234848022
train-epoch-step: 1-464 -- Loss: 0.31974148750305176
train-epoch-step: 1-465 -- Loss: 0.5937032699584961
train-epoch-step: 1-466 -- Loss: 0.31020742654800415
train-epoch-step: 1-467 -- Loss: 0.1721562147140503
train-epoch-step: 1-468 -- Loss: 0.3009955883026123
train-epoch-step: 1-469 -- Loss: 0.3929107189178467
train-epoch-step: 1-470 -- Loss: 0.259886771440506
train-epoch-step: 1-471 -- Loss: 0.24470117688179016
train-epoch-step: 1-472 -- Loss: 0.2380187213420868
train-epoch-step: 1-473 -- Loss: 0.24899882078170776
train-epoch-step: 1-474 -- Loss: 0.1795942187309265
train-epoch-step: 1-475 -- Loss: 0.1724313348531723
train-epoch-step: 1-476 -- Loss: 0.3182642459869385
train-epoch-step: 1-477 -- Loss: 0.34319645166397095
train-epoch-step: 1-478 -- Loss: 0.2917971611022949
train-epoch-step: 1-479 -- Loss: 0.2043294906616211
train-epoch-step: 1-480 -- Loss: 0.35472121834754944
train-epoch-step: 1-481 -- Loss: 0.439042329788208
train-epoch-step: 1-482 -- Loss: 0.3756137192249298
train-epoch-step: 1-483 -- Loss: 0.2936582863330841
train-epoch-step: 1-484 -- Loss: 0.3113443851470947
train-epoch-step: 1-485 -- Loss: 0.20507825911045074
train-epoch-step: 1-486 -- Loss: 0.3656846880912781
train-epoch-step: 1-487 -- Loss: 0.3754544258117676
train-epoch-step: 1-488 -- Loss: 0.2865462005138397
train-epoch-step: 1-489 -- Loss: 0.3198152184486389
train-epoch-step: 1-490 -- Loss: 0.2165227085351944
train-epoch-step: 1-491 -- Loss: 0.20240482687950134
train-epoch-step: 1-492 -- Loss: 0.19090257585048676
train-epoch-step: 1-493 -- Loss: 0.3298356533050537
train-epoch-step: 1-494 -- Loss: 0.3094199597835541
train-epoch-step: 1-495 -- Loss: 0.3405637741088867
train-epoch-step: 1-496 -- Loss: 0.19125370681285858
train-epoch-step: 1-497 -- Loss: 0.3412739634513855
train-epoch-step: 1-498 -- Loss: 0.22126254439353943
train-epoch-step: 1-499 -- Loss: 0.2540920376777649
train-epoch-step: 1-500 -- Loss: 0.23284733295440674
train-epoch-step: 1-501 -- Loss: 0.3047447204589844
train-epoch-step: 1-502 -- Loss: 0.29193755984306335
train-epoch-step: 1-503 -- Loss: 0.3450104296207428
train-epoch-step: 1-504 -- Loss: 0.16992390155792236
train-epoch-step: 1-505 -- Loss: 0.2705935835838318
train-epoch-step: 1-506 -- Loss: 0.1806100308895111
train-epoch-step: 1-507 -- Loss: 0.3029598295688629
train-epoch-step: 1-508 -- Loss: 0.2668538987636566
train-epoch-step: 1-509 -- Loss: 0.2590083181858063
train-epoch-step: 1-510 -- Loss: 0.22165663540363312
train-epoch-step: 1-511 -- Loss: 0.31675803661346436
train-epoch-step: 1-512 -- Loss: 0.3320133090019226
train-epoch-step: 1-513 -- Loss: 0.2902158498764038
train-epoch-step: 1-514 -- Loss: 0.23402313888072968
train-epoch-step: 1-515 -- Loss: 0.2567692995071411
train-epoch-step: 1-516 -- Loss: 0.25036847591400146
train-epoch-step: 1-517 -- Loss: 0.2893245220184326
train-epoch-step: 1-518 -- Loss: 0.21220353245735168
train-epoch-step: 1-519 -- Loss: 0.21652115881443024
train-epoch-step: 1-520 -- Loss: 0.2756780982017517
train-epoch-step: 1-521 -- Loss: 0.368380606174469
train-epoch-step: 1-522 -- Loss: 0.31465959548950195
train-epoch-step: 1-523 -- Loss: 0.25065040588378906
train-epoch-step: 1-524 -- Loss: 0.25455623865127563
train-epoch-step: 1-525 -- Loss: 0.3535026013851166
train-epoch-step: 1-526 -- Loss: 0.19686591625213623
train-epoch-step: 1-527 -- Loss: 0.24817121028900146
train-epoch-step: 1-528 -- Loss: 0.2419780194759369
train-epoch-step: 1-529 -- Loss: 0.27217286825180054
train-epoch-step: 1-530 -- Loss: 0.2619783878326416
train-epoch-step: 1-531 -- Loss: 0.3282288908958435
train-epoch-step: 1-532 -- Loss: 0.2708028554916382
train-epoch-step: 1-533 -- Loss: 0.2556658983230591
train-epoch-step: 1-534 -- Loss: 0.1907016485929489
train-epoch-step: 1-535 -- Loss: 0.5084207653999329
train-epoch-step: 1-536 -- Loss: 0.2357088029384613
train-epoch-step: 1-537 -- Loss: 0.22947506606578827
train-epoch-step: 1-538 -- Loss: 0.16252833604812622
train-epoch-step: 1-539 -- Loss: 0.28303539752960205
train-epoch-step: 1-540 -- Loss: 0.18709155917167664
train-epoch-step: 1-541 -- Loss: 0.33537378907203674
train-epoch-step: 1-542 -- Loss: 0.36403441429138184
train-epoch-step: 1-543 -- Loss: 0.26513296365737915
train-epoch-step: 1-544 -- Loss: 0.33331480622291565
train-epoch-step: 1-545 -- Loss: 0.2913321554660797
train-epoch-step: 1-546 -- Loss: 0.3750140070915222
train-epoch-step: 1-547 -- Loss: 0.27069365978240967
train-epoch-step: 1-548 -- Loss: 0.14201676845550537
train-epoch-step: 1-549 -- Loss: 0.2492116391658783
train-epoch-step: 1-550 -- Loss: 0.290988564491272
train-epoch-step: 1-551 -- Loss: 0.24919772148132324
train-epoch-step: 1-552 -- Loss: 0.1848379671573639
train-epoch-step: 1-553 -- Loss: 0.30299684405326843
train-epoch-step: 1-554 -- Loss: 0.28415995836257935
train-epoch-step: 1-555 -- Loss: 0.5406058430671692
train-epoch-step: 1-556 -- Loss: 0.25648170709609985
train-epoch-step: 1-557 -- Loss: 0.3853265941143036
train-epoch-step: 1-558 -- Loss: 0.4195898175239563
train-epoch-step: 1-559 -- Loss: 0.22226738929748535
train-epoch-step: 1-560 -- Loss: 0.3112385869026184
train-epoch-step: 1-561 -- Loss: 0.3621099591255188
train-epoch-step: 1-562 -- Loss: 0.30612897872924805
train-epoch-step: 1-563 -- Loss: 0.28215491771698
train-epoch-step: 1-564 -- Loss: 0.16540516912937164
train-epoch-step: 1-565 -- Loss: 0.2842659652233124
train-epoch-step: 1-566 -- Loss: 0.24063415825366974
train-epoch-step: 1-567 -- Loss: 0.2974739074707031
train-epoch-step: 1-568 -- Loss: 0.25827446579933167
train-epoch-step: 1-569 -- Loss: 0.32454484701156616
train-epoch-step: 1-570 -- Loss: 0.256710410118103
train-epoch-step: 1-571 -- Loss: 0.30504685640335083
train-epoch-step: 1-572 -- Loss: 0.3517961800098419
train-epoch-step: 1-573 -- Loss: 0.3083478808403015
train-epoch-step: 1-574 -- Loss: 0.39632707834243774
train-epoch-step: 1-575 -- Loss: 0.4638465940952301
train-epoch-step: 1-576 -- Loss: 0.19356617331504822
train-epoch-step: 1-577 -- Loss: 0.24003948271274567
train-epoch-step: 1-578 -- Loss: 0.3417356014251709
train-epoch-step: 1-579 -- Loss: 0.2431451380252838
train-epoch-step: 1-580 -- Loss: 0.29287293553352356
train-epoch-step: 1-581 -- Loss: 0.1986500322818756
train-epoch-step: 1-582 -- Loss: 0.35610073804855347
train-epoch-step: 1-583 -- Loss: 0.33353736996650696
train-epoch-step: 1-584 -- Loss: 0.2856629490852356
train-epoch-step: 1-585 -- Loss: 0.2782481908798218
train-epoch-step: 1-586 -- Loss: 0.3906139135360718
train-epoch-step: 1-587 -- Loss: 0.2566665709018707
train-epoch-step: 1-588 -- Loss: 0.19828912615776062
val-epoch-step: 1-589 -- Loss: 0.3550458550453186
val-epoch-step: 1-590 -- Loss: 0.2127898782491684
val-epoch-step: 1-591 -- Loss: 0.32749900221824646
val-epoch-step: 1-592 -- Loss: 0.2560289800167084
val-epoch-step: 1-593 -- Loss: 0.21037620306015015
val-epoch-step: 1-594 -- Loss: 0.4459138512611389
val-epoch-step: 1-595 -- Loss: 0.2477678805589676
val-epoch-step: 1-596 -- Loss: 0.2943423390388489
val-epoch-step: 1-597 -- Loss: 0.2799364924430847
val-epoch-step: 1-598 -- Loss: 0.23319579660892487
val-epoch-step: 1-599 -- Loss: 0.26623794436454773
val-epoch-step: 1-600 -- Loss: 0.25755172967910767
val-epoch-step: 1-601 -- Loss: 0.20804017782211304
val-epoch-step: 1-602 -- Loss: 0.21617615222930908
val-epoch-step: 1-603 -- Loss: 0.310596764087677
val-epoch-step: 1-604 -- Loss: 0.1948680281639099
val-epoch-step: 1-605 -- Loss: 0.21325993537902832
val-epoch-step: 1-606 -- Loss: 0.4412044584751129
val-epoch-step: 1-607 -- Loss: 0.21576938033103943
val-epoch-step: 1-608 -- Loss: 0.35936370491981506
val-epoch-step: 1-609 -- Loss: 0.25806725025177
val-epoch-step: 1-610 -- Loss: 0.3024570345878601
val-epoch-step: 1-611 -- Loss: 0.23628167808055878
val-epoch-step: 1-612 -- Loss: 0.4055907130241394
val-epoch-step: 1-613 -- Loss: 0.2553466558456421
val-epoch-step: 1-614 -- Loss: 0.2163514941930771
val-epoch-step: 1-615 -- Loss: 0.2761799991130829
val-epoch-step: 1-616 -- Loss: 0.20302540063858032
val-epoch-step: 1-617 -- Loss: 0.3295283913612366
val-epoch-step: 1-618 -- Loss: 0.2747265696525574
val-epoch-step: 1-619 -- Loss: 0.30741190910339355
val-epoch-step: 1-620 -- Loss: 0.20688241720199585
val-epoch-step: 1-621 -- Loss: 0.20351043343544006
val-epoch-step: 1-622 -- Loss: 0.20733213424682617
val-epoch-step: 1-623 -- Loss: 0.22463998198509216
val-epoch-step: 1-624 -- Loss: 0.23955929279327393
val-epoch-step: 1-625 -- Loss: 0.21689856052398682
val-epoch-step: 1-626 -- Loss: 0.23115700483322144
val-epoch-step: 1-627 -- Loss: 0.27897560596466064
val-epoch-step: 1-628 -- Loss: 0.5218716263771057
val-epoch-step: 1-629 -- Loss: 0.29032236337661743
val-epoch-step: 1-630 -- Loss: 0.4992403984069824
val-epoch-step: 1-631 -- Loss: 0.21725039184093475
val-epoch-step: 1-632 -- Loss: 0.27532270550727844
val-epoch-step: 1-633 -- Loss: 0.22388166189193726
val-epoch-step: 1-634 -- Loss: 0.20331916213035583
val-epoch-step: 1-635 -- Loss: 0.15725389122962952
val-epoch-step: 1-636 -- Loss: 0.2325844168663025
val-epoch-step: 1-637 -- Loss: 0.27028053998947144
val-epoch-step: 1-638 -- Loss: 0.2212657630443573
val-epoch-step: 1-639 -- Loss: 0.3589496612548828
val-epoch-step: 1-640 -- Loss: 0.3733493387699127
val-epoch-step: 1-641 -- Loss: 0.18382513523101807
val-epoch-step: 1-642 -- Loss: 0.2815505266189575
val-epoch-step: 1-643 -- Loss: 0.28450465202331543
val-epoch-step: 1-644 -- Loss: 0.25134095549583435
val-epoch-step: 1-645 -- Loss: 0.32101970911026
val-epoch-step: 1-646 -- Loss: 0.2147943377494812
val-epoch-step: 1-647 -- Loss: 0.19804087281227112
val-epoch-step: 1-648 -- Loss: 0.23945993185043335
val-epoch-step: 1-649 -- Loss: 0.4939393401145935
val-epoch-step: 1-650 -- Loss: 0.3545351028442383
val-epoch-step: 1-651 -- Loss: 0.1950300931930542
val-epoch-step: 1-652 -- Loss: 0.2235163003206253
val-epoch-step: 1-653 -- Loss: 0.2766643166542053
val-epoch-step: 1-654 -- Loss: 0.15950801968574524
train-epoch-step: 1-0 -- Loss: 1.574275255203247
train-epoch-step: 1-1 -- Loss: 1.5172159671783447
train-epoch-step: 1-2 -- Loss: 1.5519001483917236
train-epoch-step: 1-3 -- Loss: 1.5100691318511963
train-epoch-step: 1-4 -- Loss: 1.5449965000152588
train-epoch-step: 1-5 -- Loss: 1.4992704391479492
train-epoch-step: 1-6 -- Loss: 1.6029870510101318
train-epoch-step: 1-7 -- Loss: 1.44468355178833
train-epoch-step: 1-8 -- Loss: 1.4407868385314941
train-epoch-step: 1-9 -- Loss: 1.4630680084228516
train-epoch-step: 1-10 -- Loss: 1.4209949970245361
train-epoch-step: 1-11 -- Loss: 1.2645725011825562
train-epoch-step: 1-12 -- Loss: 1.182519555091858
train-epoch-step: 1-13 -- Loss: 1.2162916660308838
train-epoch-step: 1-14 -- Loss: 1.0299882888793945
train-epoch-step: 1-15 -- Loss: 0.9768030643463135
train-epoch-step: 1-16 -- Loss: 0.9235737323760986
train-epoch-step: 1-17 -- Loss: 0.9746153950691223
train-epoch-step: 1-18 -- Loss: 0.8348737955093384
train-epoch-step: 1-19 -- Loss: 0.6833313703536987
train-epoch-step: 1-20 -- Loss: 0.7804833650588989
train-epoch-step: 1-21 -- Loss: 0.8414084315299988
train-epoch-step: 1-22 -- Loss: 0.5579832196235657
train-epoch-step: 1-23 -- Loss: 0.5647529363632202
train-epoch-step: 1-24 -- Loss: 0.4789709448814392
train-epoch-step: 1-25 -- Loss: 0.6160589456558228
train-epoch-step: 1-26 -- Loss: 0.527961790561676
train-epoch-step: 1-27 -- Loss: 0.7715479731559753
train-epoch-step: 1-28 -- Loss: 0.37470483779907227
train-epoch-step: 1-29 -- Loss: 0.5498247146606445
train-epoch-step: 1-30 -- Loss: 0.29072892665863037
train-epoch-step: 1-31 -- Loss: 0.3574969172477722
train-epoch-step: 1-32 -- Loss: 0.4121030867099762
train-epoch-step: 1-33 -- Loss: 0.639301061630249
train-epoch-step: 1-34 -- Loss: 0.40573447942733765
train-epoch-step: 1-35 -- Loss: 0.5431245565414429
train-epoch-step: 1-36 -- Loss: 0.3647949695587158
train-epoch-step: 1-37 -- Loss: 0.35670989751815796
train-epoch-step: 1-38 -- Loss: 0.40429478883743286
train-epoch-step: 1-39 -- Loss: 0.5149688124656677
train-epoch-step: 1-40 -- Loss: 0.4567890763282776
train-epoch-step: 1-41 -- Loss: 0.4894210994243622
train-epoch-step: 1-42 -- Loss: 0.36164504289627075
train-epoch-step: 1-43 -- Loss: 0.6832675933837891
train-epoch-step: 1-44 -- Loss: 0.2978496551513672
train-epoch-step: 1-45 -- Loss: 0.2742968797683716
train-epoch-step: 1-46 -- Loss: 0.39687055349349976
train-epoch-step: 1-47 -- Loss: 0.4343588948249817
train-epoch-step: 1-48 -- Loss: 0.3423183858394623
train-epoch-step: 1-49 -- Loss: 0.4212118983268738
train-epoch-step: 1-50 -- Loss: 0.2817057967185974
train-epoch-step: 1-51 -- Loss: 0.39856189489364624
train-epoch-step: 1-52 -- Loss: 0.31308263540267944
train-epoch-step: 1-53 -- Loss: 0.47593051195144653
train-epoch-step: 1-54 -- Loss: 0.5753699541091919
train-epoch-step: 1-55 -- Loss: 0.3628688454627991
train-epoch-step: 1-56 -- Loss: 0.40687650442123413
train-epoch-step: 1-57 -- Loss: 0.5264190435409546
train-epoch-step: 1-58 -- Loss: 0.5210257768630981
train-epoch-step: 1-59 -- Loss: 0.5203441977500916
train-epoch-step: 1-60 -- Loss: 0.2611326575279236
train-epoch-step: 1-61 -- Loss: 0.4044681191444397
train-epoch-step: 1-62 -- Loss: 0.3588312268257141
train-epoch-step: 1-63 -- Loss: 0.2789747416973114
train-epoch-step: 1-64 -- Loss: 0.33678680658340454
train-epoch-step: 1-65 -- Loss: 0.37757784128189087
train-epoch-step: 1-66 -- Loss: 0.21466121077537537
train-epoch-step: 1-67 -- Loss: 0.2518653869628906
train-epoch-step: 1-68 -- Loss: 0.4404755234718323
train-epoch-step: 1-69 -- Loss: 0.25879842042922974
train-epoch-step: 1-70 -- Loss: 0.48920097947120667
train-epoch-step: 1-71 -- Loss: 0.5714839696884155
train-epoch-step: 1-72 -- Loss: 0.34249746799468994
train-epoch-step: 1-73 -- Loss: 0.4113944172859192
train-epoch-step: 1-74 -- Loss: 0.19874784350395203
train-epoch-step: 1-75 -- Loss: 0.2797752022743225
train-epoch-step: 1-76 -- Loss: 0.2848190665245056
train-epoch-step: 1-77 -- Loss: 0.39336809515953064
train-epoch-step: 1-78 -- Loss: 0.5099203586578369
train-epoch-step: 1-79 -- Loss: 0.3701198101043701
train-epoch-step: 1-80 -- Loss: 0.44965875148773193
train-epoch-step: 1-81 -- Loss: 0.27721983194351196
train-epoch-step: 1-82 -- Loss: 0.45875808596611023
train-epoch-step: 1-83 -- Loss: 0.3493863046169281
train-epoch-step: 1-84 -- Loss: 0.3853791356086731
train-epoch-step: 1-85 -- Loss: 0.3353358209133148
train-epoch-step: 1-86 -- Loss: 0.2183687537908554
train-epoch-step: 1-87 -- Loss: 0.3999674320220947
train-epoch-step: 1-88 -- Loss: 0.26490750908851624
train-epoch-step: 1-89 -- Loss: 0.32932233810424805
train-epoch-step: 1-90 -- Loss: 0.3484821915626526
train-epoch-step: 1-91 -- Loss: 0.4346866011619568
train-epoch-step: 1-92 -- Loss: 0.30243241786956787
train-epoch-step: 1-93 -- Loss: 0.3335663378238678
train-epoch-step: 1-94 -- Loss: 0.45813947916030884
train-epoch-step: 1-95 -- Loss: 0.36667436361312866
train-epoch-step: 1-96 -- Loss: 0.3862936794757843
train-epoch-step: 1-97 -- Loss: 0.35183948278427124
train-epoch-step: 1-98 -- Loss: 0.29539352655410767
train-epoch-step: 1-99 -- Loss: 0.31438764929771423
train-epoch-step: 1-100 -- Loss: 0.3492124676704407
train-epoch-step: 1-101 -- Loss: 0.44275230169296265
train-epoch-step: 1-102 -- Loss: 0.48072129487991333
train-epoch-step: 1-103 -- Loss: 0.3687060475349426
train-epoch-step: 1-104 -- Loss: 0.2877546548843384
train-epoch-step: 1-105 -- Loss: 0.6575613021850586
train-epoch-step: 1-106 -- Loss: 0.3224347233772278
train-epoch-step: 1-107 -- Loss: 0.37291860580444336
train-epoch-step: 1-108 -- Loss: 0.3297843337059021
train-epoch-step: 1-109 -- Loss: 0.2772934138774872
train-epoch-step: 1-110 -- Loss: 0.32871827483177185
train-epoch-step: 1-111 -- Loss: 0.3448992967605591
train-epoch-step: 1-112 -- Loss: 0.27409660816192627
train-epoch-step: 1-113 -- Loss: 0.3663681745529175
train-epoch-step: 1-114 -- Loss: 0.3902973532676697
train-epoch-step: 1-115 -- Loss: 0.278449147939682
train-epoch-step: 1-116 -- Loss: 0.25106164813041687
train-epoch-step: 1-117 -- Loss: 0.23882824182510376
train-epoch-step: 1-118 -- Loss: 0.35651424527168274
train-epoch-step: 1-119 -- Loss: 0.2572081983089447
train-epoch-step: 1-120 -- Loss: 0.44273921847343445
train-epoch-step: 1-121 -- Loss: 0.4061073958873749
train-epoch-step: 1-122 -- Loss: 0.3837544322013855
train-epoch-step: 1-123 -- Loss: 0.3786658048629761
train-epoch-step: 1-124 -- Loss: 0.22234860062599182
train-epoch-step: 1-125 -- Loss: 0.24862736463546753
train-epoch-step: 1-126 -- Loss: 0.3960382342338562
train-epoch-step: 1-127 -- Loss: 0.28047141432762146
train-epoch-step: 1-128 -- Loss: 0.32762032747268677
train-epoch-step: 1-129 -- Loss: 0.2354951798915863
train-epoch-step: 1-130 -- Loss: 0.31661102175712585
train-epoch-step: 1-131 -- Loss: 0.24006465077400208
train-epoch-step: 1-132 -- Loss: 0.3278927206993103
train-epoch-step: 1-133 -- Loss: 0.20347309112548828
train-epoch-step: 1-134 -- Loss: 0.3435615301132202
train-epoch-step: 1-135 -- Loss: 0.21697735786437988
train-epoch-step: 1-136 -- Loss: 0.2046467810869217
train-epoch-step: 1-137 -- Loss: 0.43433064222335815
train-epoch-step: 1-138 -- Loss: 0.4921080768108368
train-epoch-step: 1-139 -- Loss: 0.23993879556655884
train-epoch-step: 1-140 -- Loss: 0.39656227827072144
train-epoch-step: 1-141 -- Loss: 0.41102129220962524
train-epoch-step: 1-142 -- Loss: 0.36121460795402527
train-epoch-step: 1-143 -- Loss: 0.3194862902164459
train-epoch-step: 1-144 -- Loss: 0.3371679186820984
train-epoch-step: 1-145 -- Loss: 0.25455862283706665
train-epoch-step: 1-146 -- Loss: 0.3170827031135559
train-epoch-step: 1-147 -- Loss: 0.3391641676425934
train-epoch-step: 1-148 -- Loss: 0.28687673807144165
train-epoch-step: 1-149 -- Loss: 0.20398131012916565
train-epoch-step: 1-150 -- Loss: 0.34218311309814453
train-epoch-step: 1-151 -- Loss: 0.3590352535247803
train-epoch-step: 1-152 -- Loss: 0.334675133228302
train-epoch-step: 1-153 -- Loss: 0.49437835812568665
train-epoch-step: 1-154 -- Loss: 0.2501550018787384
train-epoch-step: 1-155 -- Loss: 0.24973025918006897
train-epoch-step: 1-156 -- Loss: 0.21212515234947205
train-epoch-step: 1-157 -- Loss: 0.2836434543132782
train-epoch-step: 1-158 -- Loss: 0.3102310001850128
train-epoch-step: 1-159 -- Loss: 0.30243030190467834
train-epoch-step: 1-160 -- Loss: 0.35943859815597534
train-epoch-step: 1-161 -- Loss: 0.35537588596343994
train-epoch-step: 1-162 -- Loss: 0.3983178436756134
train-epoch-step: 1-163 -- Loss: 0.33302927017211914
train-epoch-step: 1-164 -- Loss: 0.313128262758255
train-epoch-step: 1-165 -- Loss: 0.2754627466201782
train-epoch-step: 1-166 -- Loss: 0.2128412127494812
train-epoch-step: 1-167 -- Loss: 0.20256999135017395
train-epoch-step: 1-168 -- Loss: 0.3412861227989197
train-epoch-step: 1-169 -- Loss: 0.2364414632320404
train-epoch-step: 1-170 -- Loss: 0.3661856949329376
train-epoch-step: 1-171 -- Loss: 0.2937859296798706
train-epoch-step: 1-172 -- Loss: 0.43746721744537354
train-epoch-step: 1-173 -- Loss: 0.22965532541275024
train-epoch-step: 1-174 -- Loss: 0.45896559953689575
train-epoch-step: 1-175 -- Loss: 0.34371334314346313
train-epoch-step: 1-176 -- Loss: 0.23476718366146088
train-epoch-step: 1-177 -- Loss: 0.3089892566204071
train-epoch-step: 1-178 -- Loss: 0.30584660172462463
train-epoch-step: 1-179 -- Loss: 0.23454587161540985
train-epoch-step: 1-180 -- Loss: 0.24881824851036072
train-epoch-step: 1-181 -- Loss: 0.31938502192497253
train-epoch-step: 1-182 -- Loss: 0.3305967450141907
train-epoch-step: 1-183 -- Loss: 0.7189579010009766
train-epoch-step: 1-184 -- Loss: 0.2588287889957428
train-epoch-step: 1-185 -- Loss: 0.2441367506980896
train-epoch-step: 1-186 -- Loss: 0.3346884250640869
train-epoch-step: 1-187 -- Loss: 0.38328397274017334
train-epoch-step: 1-188 -- Loss: 0.34067487716674805
train-epoch-step: 1-189 -- Loss: 0.2423102855682373
train-epoch-step: 1-190 -- Loss: 0.28547918796539307
train-epoch-step: 1-191 -- Loss: 0.2914436459541321
train-epoch-step: 1-192 -- Loss: 0.4138640761375427
train-epoch-step: 1-193 -- Loss: 0.41770216822624207
train-epoch-step: 1-194 -- Loss: 0.33833611011505127
train-epoch-step: 1-195 -- Loss: 0.33248090744018555
train-epoch-step: 1-196 -- Loss: 0.2985028624534607
train-epoch-step: 1-197 -- Loss: 0.21854615211486816
train-epoch-step: 1-198 -- Loss: 0.2090338170528412
train-epoch-step: 1-199 -- Loss: 0.27417755126953125
train-epoch-step: 1-200 -- Loss: 0.2060653418302536
train-epoch-step: 1-201 -- Loss: 0.33693426847457886
train-epoch-step: 1-202 -- Loss: 0.2234179973602295
train-epoch-step: 1-203 -- Loss: 0.3039567172527313
train-epoch-step: 1-204 -- Loss: 0.2640463709831238
train-epoch-step: 1-205 -- Loss: 0.2957003116607666
train-epoch-step: 1-206 -- Loss: 0.3572183847427368
train-epoch-step: 1-207 -- Loss: 0.23088398575782776
train-epoch-step: 1-208 -- Loss: 0.29518163204193115
train-epoch-step: 1-209 -- Loss: 0.2342175543308258
train-epoch-step: 1-210 -- Loss: 0.22788332402706146
train-epoch-step: 1-211 -- Loss: 0.3586963713169098
train-epoch-step: 1-212 -- Loss: 0.32923829555511475
train-epoch-step: 1-213 -- Loss: 0.22548748552799225
train-epoch-step: 1-214 -- Loss: 0.25577405095100403
train-epoch-step: 1-215 -- Loss: 0.22495156526565552
train-epoch-step: 1-216 -- Loss: 0.30787193775177
train-epoch-step: 1-217 -- Loss: 0.3847191631793976
train-epoch-step: 1-218 -- Loss: 0.26477059721946716
train-epoch-step: 1-219 -- Loss: 0.34157735109329224
train-epoch-step: 1-220 -- Loss: 0.21826663613319397
train-epoch-step: 1-221 -- Loss: 0.38377684354782104
train-epoch-step: 1-222 -- Loss: 0.21375234425067902
train-epoch-step: 1-223 -- Loss: 0.2880150377750397
train-epoch-step: 1-224 -- Loss: 0.29745179414749146
train-epoch-step: 1-225 -- Loss: 0.4777938723564148
train-epoch-step: 1-226 -- Loss: 0.34443819522857666
train-epoch-step: 1-227 -- Loss: 0.37662869691848755
train-epoch-step: 1-228 -- Loss: 0.29199230670928955
train-epoch-step: 1-229 -- Loss: 0.3579268455505371
train-epoch-step: 1-230 -- Loss: 0.27744314074516296
train-epoch-step: 1-231 -- Loss: 0.30201011896133423
train-epoch-step: 1-232 -- Loss: 0.3056991696357727
train-epoch-step: 1-233 -- Loss: 0.15869921445846558
train-epoch-step: 1-234 -- Loss: 0.29169636964797974
train-epoch-step: 1-235 -- Loss: 0.2615413963794708
train-epoch-step: 1-236 -- Loss: 0.30349040031433105
train-epoch-step: 1-237 -- Loss: 0.40889260172843933
train-epoch-step: 1-238 -- Loss: 0.2706538438796997
train-epoch-step: 1-239 -- Loss: 0.2348351776599884
train-epoch-step: 1-240 -- Loss: 0.36716485023498535
train-epoch-step: 1-241 -- Loss: 0.26244401931762695
train-epoch-step: 1-242 -- Loss: 0.3646315038204193
train-epoch-step: 1-243 -- Loss: 0.41387444734573364
train-epoch-step: 1-244 -- Loss: 0.35349345207214355
train-epoch-step: 1-245 -- Loss: 0.3948709964752197
train-epoch-step: 1-246 -- Loss: 0.44830965995788574
train-epoch-step: 1-247 -- Loss: 0.4017248749732971
train-epoch-step: 1-248 -- Loss: 0.28060540556907654
train-epoch-step: 1-249 -- Loss: 0.23009151220321655
train-epoch-step: 1-250 -- Loss: 0.4068170189857483
train-epoch-step: 1-251 -- Loss: 0.19221442937850952
train-epoch-step: 1-252 -- Loss: 0.28324204683303833
train-epoch-step: 1-253 -- Loss: 0.21429845690727234
train-epoch-step: 1-254 -- Loss: 0.38535767793655396
train-epoch-step: 1-255 -- Loss: 0.2246321439743042
train-epoch-step: 1-256 -- Loss: 0.23398979008197784
train-epoch-step: 1-257 -- Loss: 0.28879639506340027
train-epoch-step: 1-258 -- Loss: 0.27964168787002563
train-epoch-step: 1-259 -- Loss: 0.17552050948143005
train-epoch-step: 1-260 -- Loss: 0.34367936849594116
train-epoch-step: 1-261 -- Loss: 0.2646237015724182
train-epoch-step: 1-262 -- Loss: 0.4811614155769348
train-epoch-step: 1-263 -- Loss: 0.3913450241088867
train-epoch-step: 1-264 -- Loss: 0.2691482603549957
train-epoch-step: 1-265 -- Loss: 0.18496140837669373
train-epoch-step: 1-266 -- Loss: 0.24180245399475098
train-epoch-step: 1-267 -- Loss: 0.2273697406053543
train-epoch-step: 1-268 -- Loss: 0.20051267743110657
train-epoch-step: 1-269 -- Loss: 0.26956844329833984
train-epoch-step: 1-270 -- Loss: 0.17434817552566528
train-epoch-step: 1-271 -- Loss: 0.26346355676651
train-epoch-step: 1-272 -- Loss: 0.19831658899784088
train-epoch-step: 1-273 -- Loss: 0.20447209477424622
train-epoch-step: 1-274 -- Loss: 0.34366375207901
train-epoch-step: 1-275 -- Loss: 0.3148522675037384
train-epoch-step: 1-276 -- Loss: 0.23907873034477234
train-epoch-step: 1-277 -- Loss: 0.2332238256931305
train-epoch-step: 1-278 -- Loss: 0.2458730936050415
train-epoch-step: 1-279 -- Loss: 0.21676942706108093
train-epoch-step: 1-280 -- Loss: 0.32294708490371704
train-epoch-step: 1-281 -- Loss: 0.27405357360839844
train-epoch-step: 1-282 -- Loss: 0.23717504739761353
train-epoch-step: 1-283 -- Loss: 0.17291483283042908
train-epoch-step: 1-284 -- Loss: 0.2963797152042389
train-epoch-step: 1-285 -- Loss: 0.3196256160736084
train-epoch-step: 1-286 -- Loss: 0.24355663359165192
train-epoch-step: 1-287 -- Loss: 0.34230655431747437
train-epoch-step: 1-288 -- Loss: 0.16513597965240479
train-epoch-step: 1-289 -- Loss: 0.20649877190589905
train-epoch-step: 1-290 -- Loss: 0.2891114056110382
train-epoch-step: 1-291 -- Loss: 0.19571278989315033
train-epoch-step: 1-292 -- Loss: 0.24697910249233246
train-epoch-step: 1-293 -- Loss: 0.2403481900691986
train-epoch-step: 1-294 -- Loss: 0.28308019042015076
train-epoch-step: 1-295 -- Loss: 0.5182815790176392
train-epoch-step: 1-296 -- Loss: 0.30235424637794495
train-epoch-step: 1-297 -- Loss: 0.2837390899658203
train-epoch-step: 1-298 -- Loss: 0.3857992887496948
train-epoch-step: 1-299 -- Loss: 0.27748021483421326
train-epoch-step: 1-300 -- Loss: 0.2657657861709595
train-epoch-step: 1-301 -- Loss: 0.27765756845474243
train-epoch-step: 1-302 -- Loss: 0.3788225054740906
train-epoch-step: 1-303 -- Loss: 0.3511549234390259
train-epoch-step: 1-304 -- Loss: 0.23120008409023285
train-epoch-step: 1-305 -- Loss: 0.24243947863578796
train-epoch-step: 1-306 -- Loss: 0.42403644323349
train-epoch-step: 1-307 -- Loss: 0.265602171421051
train-epoch-step: 1-308 -- Loss: 0.4289129972457886
train-epoch-step: 1-309 -- Loss: 0.2676049768924713
train-epoch-step: 1-310 -- Loss: 0.23689648509025574
train-epoch-step: 1-311 -- Loss: 0.2496604025363922
train-epoch-step: 1-312 -- Loss: 0.3272918462753296
train-epoch-step: 1-313 -- Loss: 0.1591080129146576
train-epoch-step: 1-314 -- Loss: 0.3174510598182678
train-epoch-step: 1-315 -- Loss: 0.29793843626976013
train-epoch-step: 1-316 -- Loss: 0.24215289950370789
train-epoch-step: 1-317 -- Loss: 0.21550635993480682
train-epoch-step: 1-318 -- Loss: 0.26916438341140747
train-epoch-step: 1-319 -- Loss: 0.27283698320388794
train-epoch-step: 1-320 -- Loss: 0.1850123256444931
train-epoch-step: 1-321 -- Loss: 0.2213338315486908
train-epoch-step: 1-322 -- Loss: 0.328762412071228
train-epoch-step: 1-323 -- Loss: 0.2468152940273285
train-epoch-step: 1-324 -- Loss: 0.4100756049156189
train-epoch-step: 1-325 -- Loss: 0.2620214819908142
train-epoch-step: 1-326 -- Loss: 0.3124433159828186
train-epoch-step: 1-327 -- Loss: 0.31194519996643066
train-epoch-step: 1-328 -- Loss: 0.3369753360748291
train-epoch-step: 1-329 -- Loss: 0.5232003927230835
train-epoch-step: 1-330 -- Loss: 0.5556438565254211
train-epoch-step: 1-331 -- Loss: 0.34888792037963867
train-epoch-step: 1-332 -- Loss: 0.16936972737312317
train-epoch-step: 1-333 -- Loss: 0.3062380254268646
train-epoch-step: 1-334 -- Loss: 0.24525198340415955
train-epoch-step: 1-335 -- Loss: 0.2673635482788086
train-epoch-step: 1-336 -- Loss: 0.25893598794937134
train-epoch-step: 1-337 -- Loss: 0.3194563090801239
train-epoch-step: 1-338 -- Loss: 0.26420414447784424
train-epoch-step: 1-339 -- Loss: 0.23059329390525818
train-epoch-step: 1-340 -- Loss: 0.3524979054927826
train-epoch-step: 1-341 -- Loss: 0.20075784623622894
train-epoch-step: 1-342 -- Loss: 0.2501816749572754
train-epoch-step: 1-343 -- Loss: 0.22734910249710083
train-epoch-step: 1-344 -- Loss: 0.2694595456123352
train-epoch-step: 1-345 -- Loss: 0.20941641926765442
train-epoch-step: 1-346 -- Loss: 0.3148193657398224
train-epoch-step: 1-347 -- Loss: 0.2694352865219116
train-epoch-step: 1-348 -- Loss: 0.33424484729766846
train-epoch-step: 1-349 -- Loss: 0.33974671363830566
train-epoch-step: 1-350 -- Loss: 0.43468528985977173
train-epoch-step: 1-351 -- Loss: 0.31534308195114136
train-epoch-step: 1-352 -- Loss: 0.23788297176361084
train-epoch-step: 1-353 -- Loss: 0.3391796350479126
train-epoch-step: 1-354 -- Loss: 0.43370646238327026
train-epoch-step: 1-355 -- Loss: 0.17915937304496765
train-epoch-step: 1-356 -- Loss: 0.18637168407440186
train-epoch-step: 1-357 -- Loss: 0.30067285895347595
train-epoch-step: 1-358 -- Loss: 0.2771427631378174
train-epoch-step: 1-359 -- Loss: 0.2104688137769699
train-epoch-step: 1-360 -- Loss: 0.21838700771331787
train-epoch-step: 1-361 -- Loss: 0.4375174641609192
train-epoch-step: 1-362 -- Loss: 0.249914288520813
train-epoch-step: 1-363 -- Loss: 0.18747574090957642
train-epoch-step: 1-364 -- Loss: 0.26908010244369507
train-epoch-step: 1-365 -- Loss: 0.26037657260894775
train-epoch-step: 1-366 -- Loss: 0.29832297563552856
train-epoch-step: 1-367 -- Loss: 0.3972131311893463
train-epoch-step: 1-368 -- Loss: 0.32677900791168213
train-epoch-step: 1-369 -- Loss: 0.45456695556640625
train-epoch-step: 1-370 -- Loss: 0.22914767265319824
train-epoch-step: 1-371 -- Loss: 0.19146424531936646
train-epoch-step: 1-372 -- Loss: 0.22142678499221802
train-epoch-step: 1-373 -- Loss: 0.30943045020103455
train-epoch-step: 1-374 -- Loss: 0.2449311912059784
train-epoch-step: 1-375 -- Loss: 0.4410276710987091
train-epoch-step: 1-376 -- Loss: 0.3225940465927124
train-epoch-step: 1-377 -- Loss: 0.4154263734817505
train-epoch-step: 1-378 -- Loss: 0.32735955715179443
train-epoch-step: 1-379 -- Loss: 0.1757555603981018
train-epoch-step: 1-380 -- Loss: 0.17705568671226501
train-epoch-step: 1-381 -- Loss: 0.37849271297454834
train-epoch-step: 1-382 -- Loss: 0.4354039430618286
train-epoch-step: 1-383 -- Loss: 0.3733115792274475
train-epoch-step: 1-384 -- Loss: 0.33440470695495605
train-epoch-step: 1-385 -- Loss: 0.2929855287075043
train-epoch-step: 1-386 -- Loss: 0.3925953209400177
train-epoch-step: 1-387 -- Loss: 0.32045629620552063
train-epoch-step: 1-388 -- Loss: 0.31080442667007446
train-epoch-step: 1-389 -- Loss: 0.29312863945961
train-epoch-step: 1-390 -- Loss: 0.2388356477022171
train-epoch-step: 1-391 -- Loss: 0.23983842134475708
train-epoch-step: 1-392 -- Loss: 0.275896281003952
train-epoch-step: 1-393 -- Loss: 0.22724896669387817
train-epoch-step: 1-394 -- Loss: 0.3410182595252991
train-epoch-step: 1-395 -- Loss: 0.24509993195533752
train-epoch-step: 1-396 -- Loss: 0.19760145246982574
train-epoch-step: 1-397 -- Loss: 0.1826585978269577
train-epoch-step: 1-398 -- Loss: 0.28702840209007263
train-epoch-step: 1-399 -- Loss: 0.32559269666671753
train-epoch-step: 1-400 -- Loss: 0.4351136088371277
train-epoch-step: 1-401 -- Loss: 0.17938153445720673
train-epoch-step: 1-402 -- Loss: 0.4224998354911804
train-epoch-step: 1-403 -- Loss: 0.26288527250289917
train-epoch-step: 1-404 -- Loss: 0.22575363516807556
train-epoch-step: 1-405 -- Loss: 0.21189738810062408
train-epoch-step: 1-406 -- Loss: 0.24087731540203094
train-epoch-step: 1-407 -- Loss: 0.17039436101913452
train-epoch-step: 1-408 -- Loss: 0.23301909863948822
train-epoch-step: 1-409 -- Loss: 0.2734781503677368
train-epoch-step: 1-410 -- Loss: 0.2948485016822815
train-epoch-step: 1-411 -- Loss: 0.32979917526245117
train-epoch-step: 1-412 -- Loss: 0.20104795694351196
train-epoch-step: 1-413 -- Loss: 0.22376015782356262
train-epoch-step: 1-414 -- Loss: 0.22047147154808044
train-epoch-step: 1-415 -- Loss: 0.19365307688713074
train-epoch-step: 1-416 -- Loss: 0.47574496269226074
train-epoch-step: 1-417 -- Loss: 0.31783199310302734
train-epoch-step: 1-418 -- Loss: 0.4306199550628662
train-epoch-step: 1-419 -- Loss: 0.2728593945503235
train-epoch-step: 1-420 -- Loss: 0.22181302309036255
train-epoch-step: 1-421 -- Loss: 0.25894895195961
train-epoch-step: 1-422 -- Loss: 0.24544529616832733
train-epoch-step: 1-423 -- Loss: 0.2757338285446167
train-epoch-step: 1-424 -- Loss: 0.2158779501914978
train-epoch-step: 1-425 -- Loss: 0.27685362100601196
train-epoch-step: 1-426 -- Loss: 0.2460426241159439
train-epoch-step: 1-427 -- Loss: 0.2024681270122528
train-epoch-step: 1-428 -- Loss: 0.33011776208877563
train-epoch-step: 1-429 -- Loss: 0.2935459315776825
train-epoch-step: 1-430 -- Loss: 0.20238308608531952
train-epoch-step: 1-431 -- Loss: 0.25923576951026917
train-epoch-step: 1-432 -- Loss: 0.4354172945022583
train-epoch-step: 1-433 -- Loss: 0.23104199767112732
train-epoch-step: 1-434 -- Loss: 0.24819229543209076
train-epoch-step: 1-435 -- Loss: 0.257512629032135
train-epoch-step: 1-436 -- Loss: 0.23378145694732666
train-epoch-step: 1-437 -- Loss: 0.19828787446022034
train-epoch-step: 1-438 -- Loss: 0.28115952014923096
train-epoch-step: 1-439 -- Loss: 0.5276095867156982
train-epoch-step: 1-440 -- Loss: 0.2306370735168457
train-epoch-step: 1-441 -- Loss: 0.3449581563472748
train-epoch-step: 1-442 -- Loss: 0.2817828357219696
train-epoch-step: 1-443 -- Loss: 0.24003338813781738
train-epoch-step: 1-444 -- Loss: 0.37234461307525635
train-epoch-step: 1-445 -- Loss: 0.3331836462020874
train-epoch-step: 1-446 -- Loss: 0.22359682619571686
train-epoch-step: 1-447 -- Loss: 0.3191066384315491
train-epoch-step: 1-448 -- Loss: 0.3826150894165039
train-epoch-step: 1-449 -- Loss: 0.2687852084636688
train-epoch-step: 1-450 -- Loss: 0.2945348620414734
train-epoch-step: 1-451 -- Loss: 0.2243756651878357
train-epoch-step: 1-452 -- Loss: 0.20586737990379333
train-epoch-step: 1-453 -- Loss: 0.15217581391334534
train-epoch-step: 1-454 -- Loss: 0.36677616834640503
train-epoch-step: 1-455 -- Loss: 0.21884803473949432
train-epoch-step: 1-456 -- Loss: 0.1865392029285431
train-epoch-step: 1-457 -- Loss: 0.33789148926734924
train-epoch-step: 1-458 -- Loss: 0.2518952786922455
train-epoch-step: 1-459 -- Loss: 0.355005145072937
train-epoch-step: 1-460 -- Loss: 0.19943177700042725
train-epoch-step: 1-461 -- Loss: 0.22488033771514893
train-epoch-step: 1-462 -- Loss: 0.2346782088279724
train-epoch-step: 1-463 -- Loss: 0.21683767437934875
train-epoch-step: 1-464 -- Loss: 0.31756529211997986
train-epoch-step: 1-465 -- Loss: 0.6040251851081848
train-epoch-step: 1-466 -- Loss: 0.3073956072330475
train-epoch-step: 1-467 -- Loss: 0.17241138219833374
train-epoch-step: 1-468 -- Loss: 0.30042701959609985
train-epoch-step: 1-469 -- Loss: 0.39243030548095703
train-epoch-step: 1-470 -- Loss: 0.260358601808548
train-epoch-step: 1-471 -- Loss: 0.2433437705039978
train-epoch-step: 1-472 -- Loss: 0.23926211893558502
train-epoch-step: 1-473 -- Loss: 0.24899369478225708
train-epoch-step: 1-474 -- Loss: 0.17986540496349335
train-epoch-step: 1-475 -- Loss: 0.17250558733940125
train-epoch-step: 1-476 -- Loss: 0.3188473582267761
train-epoch-step: 1-477 -- Loss: 0.34238937497138977
train-epoch-step: 1-478 -- Loss: 0.2926722466945648
train-epoch-step: 1-479 -- Loss: 0.20476338267326355
train-epoch-step: 1-480 -- Loss: 0.35659050941467285
train-epoch-step: 1-481 -- Loss: 0.4403121769428253
train-epoch-step: 1-482 -- Loss: 0.37333565950393677
train-epoch-step: 1-483 -- Loss: 0.293956458568573
train-epoch-step: 1-484 -- Loss: 0.31226611137390137
train-epoch-step: 1-485 -- Loss: 0.20497822761535645
train-epoch-step: 1-486 -- Loss: 0.3681545853614807
train-epoch-step: 1-487 -- Loss: 0.3783397674560547
train-epoch-step: 1-488 -- Loss: 0.2872793972492218
train-epoch-step: 1-489 -- Loss: 0.32280969619750977
train-epoch-step: 1-490 -- Loss: 0.21775507926940918
train-epoch-step: 1-491 -- Loss: 0.20247694849967957
train-epoch-step: 1-492 -- Loss: 0.19103722274303436
train-epoch-step: 1-493 -- Loss: 0.3277955651283264
train-epoch-step: 1-494 -- Loss: 0.3108583390712738
train-epoch-step: 1-495 -- Loss: 0.3401752710342407
train-epoch-step: 1-496 -- Loss: 0.19135624170303345
train-epoch-step: 1-497 -- Loss: 0.3435586988925934
train-epoch-step: 1-498 -- Loss: 0.22200964391231537
train-epoch-step: 1-499 -- Loss: 0.2532501816749573
train-epoch-step: 1-500 -- Loss: 0.23429489135742188
train-epoch-step: 1-501 -- Loss: 0.3060173988342285
train-epoch-step: 1-502 -- Loss: 0.29277363419532776
train-epoch-step: 1-503 -- Loss: 0.3462492823600769
train-epoch-step: 1-504 -- Loss: 0.17011256515979767
train-epoch-step: 1-505 -- Loss: 0.2706703841686249
train-epoch-step: 1-506 -- Loss: 0.18060779571533203
train-epoch-step: 1-507 -- Loss: 0.3045804798603058
train-epoch-step: 1-508 -- Loss: 0.26822179555892944
train-epoch-step: 1-509 -- Loss: 0.2585287094116211
train-epoch-step: 1-510 -- Loss: 0.22111350297927856
train-epoch-step: 1-511 -- Loss: 0.3176853656768799
train-epoch-step: 1-512 -- Loss: 0.333000510931015
train-epoch-step: 1-513 -- Loss: 0.2900415360927582
train-epoch-step: 1-514 -- Loss: 0.2333344966173172
train-epoch-step: 1-515 -- Loss: 0.25749993324279785
train-epoch-step: 1-516 -- Loss: 0.24930760264396667
train-epoch-step: 1-517 -- Loss: 0.2900104820728302
train-epoch-step: 1-518 -- Loss: 0.21225973963737488
train-epoch-step: 1-519 -- Loss: 0.21658097207546234
train-epoch-step: 1-520 -- Loss: 0.276262104511261
train-epoch-step: 1-521 -- Loss: 0.36733394861221313
train-epoch-step: 1-522 -- Loss: 0.3150899410247803
train-epoch-step: 1-523 -- Loss: 0.2501690983772278
train-epoch-step: 1-524 -- Loss: 0.2535251975059509
train-epoch-step: 1-525 -- Loss: 0.35697662830352783
train-epoch-step: 1-526 -- Loss: 0.196975976228714
train-epoch-step: 1-527 -- Loss: 0.2493746280670166
train-epoch-step: 1-528 -- Loss: 0.24308177828788757
train-epoch-step: 1-529 -- Loss: 0.27246055006980896
train-epoch-step: 1-530 -- Loss: 0.2622254192829132
train-epoch-step: 1-531 -- Loss: 0.3277457356452942
train-epoch-step: 1-532 -- Loss: 0.27064961194992065
train-epoch-step: 1-533 -- Loss: 0.2558785676956177
train-epoch-step: 1-534 -- Loss: 0.1915661096572876
train-epoch-step: 1-535 -- Loss: 0.5081278085708618
train-epoch-step: 1-536 -- Loss: 0.23562604188919067
train-epoch-step: 1-537 -- Loss: 0.2294108271598816
train-epoch-step: 1-538 -- Loss: 0.1630677729845047
train-epoch-step: 1-539 -- Loss: 0.2841053605079651
train-epoch-step: 1-540 -- Loss: 0.1874692142009735
train-epoch-step: 1-541 -- Loss: 0.3362484574317932
train-epoch-step: 1-542 -- Loss: 0.36617833375930786
train-epoch-step: 1-543 -- Loss: 0.2653142213821411
train-epoch-step: 1-544 -- Loss: 0.3304508328437805
train-epoch-step: 1-545 -- Loss: 0.2900596857070923
train-epoch-step: 1-546 -- Loss: 0.3773878216743469
train-epoch-step: 1-547 -- Loss: 0.26983892917633057
train-epoch-step: 1-548 -- Loss: 0.14155708253383636
train-epoch-step: 1-549 -- Loss: 0.24804145097732544
train-epoch-step: 1-550 -- Loss: 0.2910330295562744
train-epoch-step: 1-551 -- Loss: 0.2489032745361328
train-epoch-step: 1-552 -- Loss: 0.18458694219589233
train-epoch-step: 1-553 -- Loss: 0.3022654354572296
train-epoch-step: 1-554 -- Loss: 0.2829596698284149
train-epoch-step: 1-555 -- Loss: 0.5508724451065063
train-epoch-step: 1-556 -- Loss: 0.25752121210098267
train-epoch-step: 1-557 -- Loss: 0.3841702938079834
train-epoch-step: 1-558 -- Loss: 0.42099660634994507
train-epoch-step: 1-559 -- Loss: 0.2231079638004303
train-epoch-step: 1-560 -- Loss: 0.31100520491600037
train-epoch-step: 1-561 -- Loss: 0.355061799287796
train-epoch-step: 1-562 -- Loss: 0.30725395679473877
train-epoch-step: 1-563 -- Loss: 0.2819690704345703
train-epoch-step: 1-564 -- Loss: 0.16522307693958282
train-epoch-step: 1-565 -- Loss: 0.2839016914367676
train-epoch-step: 1-566 -- Loss: 0.23919926583766937
train-epoch-step: 1-567 -- Loss: 0.29779696464538574
train-epoch-step: 1-568 -- Loss: 0.2604338824748993
train-epoch-step: 1-569 -- Loss: 0.32343006134033203
train-epoch-step: 1-570 -- Loss: 0.25700753927230835
train-epoch-step: 1-571 -- Loss: 0.3055880069732666
train-epoch-step: 1-572 -- Loss: 0.35069841146469116
train-epoch-step: 1-573 -- Loss: 0.3082650303840637
train-epoch-step: 1-574 -- Loss: 0.3960566520690918
train-epoch-step: 1-575 -- Loss: 0.46620112657546997
train-epoch-step: 1-576 -- Loss: 0.1932574212551117
train-epoch-step: 1-577 -- Loss: 0.23989060521125793
train-epoch-step: 1-578 -- Loss: 0.34341180324554443
train-epoch-step: 1-579 -- Loss: 0.24524396657943726
train-epoch-step: 1-580 -- Loss: 0.29091691970825195
train-epoch-step: 1-581 -- Loss: 0.19971983134746552
train-epoch-step: 1-582 -- Loss: 0.35544347763061523
train-epoch-step: 1-583 -- Loss: 0.3332761228084564
train-epoch-step: 1-584 -- Loss: 0.28673532605171204
train-epoch-step: 1-585 -- Loss: 0.2788141965866089
train-epoch-step: 1-586 -- Loss: 0.38918912410736084
train-epoch-step: 1-587 -- Loss: 0.2551965117454529
train-epoch-step: 1-588 -- Loss: 0.19938164949417114
val-epoch-step: 1-589 -- Loss: 0.3545411229133606
val-epoch-step: 1-590 -- Loss: 0.21217729151248932
val-epoch-step: 1-591 -- Loss: 0.3218558430671692
val-epoch-step: 1-592 -- Loss: 0.2575109302997589
val-epoch-step: 1-593 -- Loss: 0.21268653869628906
val-epoch-step: 1-594 -- Loss: 0.4467066526412964
val-epoch-step: 1-595 -- Loss: 0.2471814900636673
val-epoch-step: 1-596 -- Loss: 0.2943826913833618
val-epoch-step: 1-597 -- Loss: 0.28145831823349
val-epoch-step: 1-598 -- Loss: 0.23377996683120728
val-epoch-step: 1-599 -- Loss: 0.2668231129646301
val-epoch-step: 1-600 -- Loss: 0.26072973012924194
val-epoch-step: 1-601 -- Loss: 0.20822137594223022
val-epoch-step: 1-602 -- Loss: 0.21571706235408783
val-epoch-step: 1-603 -- Loss: 0.3162768483161926
val-epoch-step: 1-604 -- Loss: 0.19572389125823975
val-epoch-step: 1-605 -- Loss: 0.21467766165733337
val-epoch-step: 1-606 -- Loss: 0.440670371055603
val-epoch-step: 1-607 -- Loss: 0.21711796522140503
val-epoch-step: 1-608 -- Loss: 0.35946646332740784
val-epoch-step: 1-609 -- Loss: 0.26024454832077026
val-epoch-step: 1-610 -- Loss: 0.3032582402229309
val-epoch-step: 1-611 -- Loss: 0.2365415394306183
val-epoch-step: 1-612 -- Loss: 0.4051218330860138
val-epoch-step: 1-613 -- Loss: 0.2564704418182373
val-epoch-step: 1-614 -- Loss: 0.21780015528202057
val-epoch-step: 1-615 -- Loss: 0.275964617729187
val-epoch-step: 1-616 -- Loss: 0.20319348573684692
val-epoch-step: 1-617 -- Loss: 0.32875072956085205
val-epoch-step: 1-618 -- Loss: 0.2747187316417694
val-epoch-step: 1-619 -- Loss: 0.3073585629463196
val-epoch-step: 1-620 -- Loss: 0.20791639387607574
val-epoch-step: 1-621 -- Loss: 0.2020418643951416
val-epoch-step: 1-622 -- Loss: 0.20682880282402039
val-epoch-step: 1-623 -- Loss: 0.2251494824886322
val-epoch-step: 1-624 -- Loss: 0.240439772605896
val-epoch-step: 1-625 -- Loss: 0.21685411036014557
val-epoch-step: 1-626 -- Loss: 0.23273558914661407
val-epoch-step: 1-627 -- Loss: 0.28155654668807983
val-epoch-step: 1-628 -- Loss: 0.5228347182273865
val-epoch-step: 1-629 -- Loss: 0.2908017635345459
val-epoch-step: 1-630 -- Loss: 0.5013389587402344
val-epoch-step: 1-631 -- Loss: 0.2183508276939392
val-epoch-step: 1-632 -- Loss: 0.27662602066993713
val-epoch-step: 1-633 -- Loss: 0.22386132180690765
val-epoch-step: 1-634 -- Loss: 0.20424579083919525
val-epoch-step: 1-635 -- Loss: 0.15671253204345703
val-epoch-step: 1-636 -- Loss: 0.23230300843715668
val-epoch-step: 1-637 -- Loss: 0.2707841992378235
val-epoch-step: 1-638 -- Loss: 0.220721036195755
val-epoch-step: 1-639 -- Loss: 0.3571164906024933
val-epoch-step: 1-640 -- Loss: 0.37243711948394775
val-epoch-step: 1-641 -- Loss: 0.18307670950889587
val-epoch-step: 1-642 -- Loss: 0.28467869758605957
val-epoch-step: 1-643 -- Loss: 0.28461724519729614
val-epoch-step: 1-644 -- Loss: 0.25349265336990356
val-epoch-step: 1-645 -- Loss: 0.32080069184303284
val-epoch-step: 1-646 -- Loss: 0.217298686504364
val-epoch-step: 1-647 -- Loss: 0.19756802916526794
val-epoch-step: 1-648 -- Loss: 0.24121153354644775
val-epoch-step: 1-649 -- Loss: 0.5020381808280945
val-epoch-step: 1-650 -- Loss: 0.35811930894851685
val-epoch-step: 1-651 -- Loss: 0.1954079270362854
val-epoch-step: 1-652 -- Loss: 0.2235727161169052
val-epoch-step: 1-653 -- Loss: 0.27706456184387207
val-epoch-step: 1-654 -- Loss: 0.15982156991958618
Epoch: 1 -- Train Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1719, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 2-0 -- Loss: 0.323069304227829
train-epoch-step: 2-1 -- Loss: 0.21014651656150818
train-epoch-step: 2-2 -- Loss: 0.2909030318260193
train-epoch-step: 2-3 -- Loss: 0.2140115350484848
train-epoch-step: 2-4 -- Loss: 0.28758326172828674
train-epoch-step: 2-5 -- Loss: 0.2658647894859314
train-epoch-step: 2-6 -- Loss: 0.4870211184024811
train-epoch-step: 2-7 -- Loss: 0.2522450089454651
train-epoch-step: 2-8 -- Loss: 0.2766667306423187
train-epoch-step: 2-9 -- Loss: 0.4063571095466614
train-epoch-step: 2-10 -- Loss: 0.3987460732460022
train-epoch-step: 2-11 -- Loss: 0.24796225130558014
train-epoch-step: 2-12 -- Loss: 0.2283806949853897
train-epoch-step: 2-13 -- Loss: 0.2996242046356201
train-epoch-step: 2-14 -- Loss: 0.2313491702079773
train-epoch-step: 2-15 -- Loss: 0.23866648972034454
train-epoch-step: 2-16 -- Loss: 0.2658448815345764
train-epoch-step: 2-17 -- Loss: 0.32193177938461304
train-epoch-step: 2-18 -- Loss: 0.29963013529777527
train-epoch-step: 2-19 -- Loss: 0.20202726125717163
train-epoch-step: 2-20 -- Loss: 0.3207181692123413
train-epoch-step: 2-21 -- Loss: 0.4210273027420044
train-epoch-step: 2-22 -- Loss: 0.23097965121269226
train-epoch-step: 2-23 -- Loss: 0.2651990056037903
train-epoch-step: 2-24 -- Loss: 0.20539332926273346
train-epoch-step: 2-25 -- Loss: 0.3235422968864441
train-epoch-step: 2-26 -- Loss: 0.2932281792163849
train-epoch-step: 2-27 -- Loss: 0.5246720910072327
train-epoch-step: 2-28 -- Loss: 0.19161616265773773
train-epoch-step: 2-29 -- Loss: 0.3376561403274536
train-epoch-step: 2-30 -- Loss: 0.16057462990283966
train-epoch-step: 2-31 -- Loss: 0.2145891785621643
train-epoch-step: 2-32 -- Loss: 0.2566918730735779
train-epoch-step: 2-33 -- Loss: 0.42885279655456543
train-epoch-step: 2-34 -- Loss: 0.2586497664451599
train-epoch-step: 2-35 -- Loss: 0.3654208779335022
train-epoch-step: 2-36 -- Loss: 0.2353721559047699
train-epoch-step: 2-37 -- Loss: 0.22553205490112305
train-epoch-step: 2-38 -- Loss: 0.29185283184051514
train-epoch-step: 2-39 -- Loss: 0.36885565519332886
train-epoch-step: 2-40 -- Loss: 0.29737797379493713
train-epoch-step: 2-41 -- Loss: 0.3295445442199707
train-epoch-step: 2-42 -- Loss: 0.2269403636455536
train-epoch-step: 2-43 -- Loss: 0.5108048915863037
train-epoch-step: 2-44 -- Loss: 0.20096346735954285
train-epoch-step: 2-45 -- Loss: 0.18271654844284058
train-epoch-step: 2-46 -- Loss: 0.2511875331401825
train-epoch-step: 2-47 -- Loss: 0.3269311189651489
train-epoch-step: 2-48 -- Loss: 0.23263949155807495
train-epoch-step: 2-49 -- Loss: 0.30993807315826416
train-epoch-step: 2-50 -- Loss: 0.18336047232151031
train-epoch-step: 2-51 -- Loss: 0.285822331905365
train-epoch-step: 2-52 -- Loss: 0.22360441088676453
train-epoch-step: 2-53 -- Loss: 0.3394506871700287
train-epoch-step: 2-54 -- Loss: 0.43243706226348877
train-epoch-step: 2-55 -- Loss: 0.25250938534736633
train-epoch-step: 2-56 -- Loss: 0.3088405728340149
train-epoch-step: 2-57 -- Loss: 0.3797474503517151
train-epoch-step: 2-58 -- Loss: 0.39320623874664307
train-epoch-step: 2-59 -- Loss: 0.38285577297210693
train-epoch-step: 2-60 -- Loss: 0.20114709436893463
train-epoch-step: 2-61 -- Loss: 0.315822958946228
train-epoch-step: 2-62 -- Loss: 0.26667192578315735
train-epoch-step: 2-63 -- Loss: 0.20462918281555176
train-epoch-step: 2-64 -- Loss: 0.2615076005458832
train-epoch-step: 2-65 -- Loss: 0.28874632716178894
train-epoch-step: 2-66 -- Loss: 0.16171759366989136
train-epoch-step: 2-67 -- Loss: 0.19076845049858093
train-epoch-step: 2-68 -- Loss: 0.3464188873767853
train-epoch-step: 2-69 -- Loss: 0.2022264301776886
train-epoch-step: 2-70 -- Loss: 0.395788311958313
train-epoch-step: 2-71 -- Loss: 0.40734755992889404
train-epoch-step: 2-72 -- Loss: 0.2572288513183594
train-epoch-step: 2-73 -- Loss: 0.32159119844436646
train-epoch-step: 2-74 -- Loss: 0.1474066525697708
train-epoch-step: 2-75 -- Loss: 0.21128572523593903
train-epoch-step: 2-76 -- Loss: 0.21339938044548035
train-epoch-step: 2-77 -- Loss: 0.3206941485404968
train-epoch-step: 2-78 -- Loss: 0.4054538309574127
train-epoch-step: 2-79 -- Loss: 0.2959196865558624
train-epoch-step: 2-80 -- Loss: 0.38071393966674805
train-epoch-step: 2-81 -- Loss: 0.2127176821231842
train-epoch-step: 2-82 -- Loss: 0.36158111691474915
train-epoch-step: 2-83 -- Loss: 0.2759406566619873
train-epoch-step: 2-84 -- Loss: 0.3055887818336487
train-epoch-step: 2-85 -- Loss: 0.2588675022125244
train-epoch-step: 2-86 -- Loss: 0.17719323933124542
train-epoch-step: 2-87 -- Loss: 0.32746434211730957
train-epoch-step: 2-88 -- Loss: 0.20930734276771545
train-epoch-step: 2-89 -- Loss: 0.2660564184188843
train-epoch-step: 2-90 -- Loss: 0.2830919325351715
train-epoch-step: 2-91 -- Loss: 0.3530374765396118
train-epoch-step: 2-92 -- Loss: 0.2500034272670746
train-epoch-step: 2-93 -- Loss: 0.2743828296661377
train-epoch-step: 2-94 -- Loss: 0.3697972893714905
train-epoch-step: 2-95 -- Loss: 0.2886951267719269
train-epoch-step: 2-96 -- Loss: 0.32458072900772095
train-epoch-step: 2-97 -- Loss: 0.279141366481781
train-epoch-step: 2-98 -- Loss: 0.23794128000736237
train-epoch-step: 2-99 -- Loss: 0.25800126791000366
train-epoch-step: 2-100 -- Loss: 0.27444106340408325
train-epoch-step: 2-101 -- Loss: 0.3751157820224762
train-epoch-step: 2-102 -- Loss: 0.39946267008781433
train-epoch-step: 2-103 -- Loss: 0.300094336271286
train-epoch-step: 2-104 -- Loss: 0.23245060443878174
train-epoch-step: 2-105 -- Loss: 0.5342458486557007
train-epoch-step: 2-106 -- Loss: 0.26687756180763245
train-epoch-step: 2-107 -- Loss: 0.3007720112800598
train-epoch-step: 2-108 -- Loss: 0.2661513090133667
train-epoch-step: 2-109 -- Loss: 0.23178258538246155
train-epoch-step: 2-110 -- Loss: 0.2734212279319763
train-epoch-step: 2-111 -- Loss: 0.2882347106933594
train-epoch-step: 2-112 -- Loss: 0.2385045439004898
train-epoch-step: 2-113 -- Loss: 0.3090188503265381
train-epoch-step: 2-114 -- Loss: 0.3312702775001526
train-epoch-step: 2-115 -- Loss: 0.23837634921073914
train-epoch-step: 2-116 -- Loss: 0.21725642681121826
train-epoch-step: 2-117 -- Loss: 0.2007748782634735
train-epoch-step: 2-118 -- Loss: 0.29911941289901733
train-epoch-step: 2-119 -- Loss: 0.21668139100074768
train-epoch-step: 2-120 -- Loss: 0.3708801865577698
train-epoch-step: 2-121 -- Loss: 0.3663761019706726
train-epoch-step: 2-122 -- Loss: 0.3334541916847229
train-epoch-step: 2-123 -- Loss: 0.310805082321167
train-epoch-step: 2-124 -- Loss: 0.1807478666305542
train-epoch-step: 2-125 -- Loss: 0.21684324741363525
train-epoch-step: 2-126 -- Loss: 0.3553311824798584
train-epoch-step: 2-127 -- Loss: 0.24497556686401367
train-epoch-step: 2-128 -- Loss: 0.2694059908390045
train-epoch-step: 2-129 -- Loss: 0.20458050072193146
train-epoch-step: 2-130 -- Loss: 0.26818621158599854
train-epoch-step: 2-131 -- Loss: 0.20050767064094543
train-epoch-step: 2-132 -- Loss: 0.2741842269897461
train-epoch-step: 2-133 -- Loss: 0.16917848587036133
train-epoch-step: 2-134 -- Loss: 0.2931073307991028
train-epoch-step: 2-135 -- Loss: 0.1908719539642334
train-epoch-step: 2-136 -- Loss: 0.17561084032058716
train-epoch-step: 2-137 -- Loss: 0.3660646975040436
train-epoch-step: 2-138 -- Loss: 0.42388129234313965
train-epoch-step: 2-139 -- Loss: 0.1948453187942505
train-epoch-step: 2-140 -- Loss: 0.3349432945251465
train-epoch-step: 2-141 -- Loss: 0.3462342619895935
train-epoch-step: 2-142 -- Loss: 0.2961527109146118
train-epoch-step: 2-143 -- Loss: 0.27359139919281006
train-epoch-step: 2-144 -- Loss: 0.2868436574935913
train-epoch-step: 2-145 -- Loss: 0.2022060602903366
train-epoch-step: 2-146 -- Loss: 0.27045172452926636
train-epoch-step: 2-147 -- Loss: 0.28623172640800476
train-epoch-step: 2-148 -- Loss: 0.24516057968139648
train-epoch-step: 2-149 -- Loss: 0.17533151805400848
train-epoch-step: 2-150 -- Loss: 0.27498966455459595
train-epoch-step: 2-151 -- Loss: 0.28964871168136597
train-epoch-step: 2-152 -- Loss: 0.2823909521102905
train-epoch-step: 2-153 -- Loss: 0.4137711822986603
train-epoch-step: 2-154 -- Loss: 0.20549920201301575
train-epoch-step: 2-155 -- Loss: 0.19915255904197693
train-epoch-step: 2-156 -- Loss: 0.17516036331653595
train-epoch-step: 2-157 -- Loss: 0.24453023076057434
train-epoch-step: 2-158 -- Loss: 0.26253366470336914
train-epoch-step: 2-159 -- Loss: 0.2590997517108917
train-epoch-step: 2-160 -- Loss: 0.30648529529571533
train-epoch-step: 2-161 -- Loss: 0.31768184900283813
train-epoch-step: 2-162 -- Loss: 0.32919543981552124
train-epoch-step: 2-163 -- Loss: 0.28707805275917053
train-epoch-step: 2-164 -- Loss: 0.2676761746406555
train-epoch-step: 2-165 -- Loss: 0.2361426204442978
train-epoch-step: 2-166 -- Loss: 0.18482625484466553
train-epoch-step: 2-167 -- Loss: 0.17483952641487122
train-epoch-step: 2-168 -- Loss: 0.29082369804382324
train-epoch-step: 2-169 -- Loss: 0.19625110924243927
train-epoch-step: 2-170 -- Loss: 0.30612415075302124
train-epoch-step: 2-171 -- Loss: 0.2532631456851959
train-epoch-step: 2-172 -- Loss: 0.3780389428138733
train-epoch-step: 2-173 -- Loss: 0.18978606164455414
train-epoch-step: 2-174 -- Loss: 0.3715362846851349
train-epoch-step: 2-175 -- Loss: 0.2859322726726532
train-epoch-step: 2-176 -- Loss: 0.19582220911979675
train-epoch-step: 2-177 -- Loss: 0.2635262608528137
train-epoch-step: 2-178 -- Loss: 0.2651887536048889
train-epoch-step: 2-179 -- Loss: 0.19807562232017517
train-epoch-step: 2-180 -- Loss: 0.21399635076522827
train-epoch-step: 2-181 -- Loss: 0.2682337164878845
train-epoch-step: 2-182 -- Loss: 0.28295233845710754
train-epoch-step: 2-183 -- Loss: 0.5555700063705444
train-epoch-step: 2-184 -- Loss: 0.216128408908844
train-epoch-step: 2-185 -- Loss: 0.21174167096614838
train-epoch-step: 2-186 -- Loss: 0.28282684087753296
train-epoch-step: 2-187 -- Loss: 0.32453906536102295
train-epoch-step: 2-188 -- Loss: 0.29155197739601135
train-epoch-step: 2-189 -- Loss: 0.19545093178749084
train-epoch-step: 2-190 -- Loss: 0.24305622279644012
train-epoch-step: 2-191 -- Loss: 0.25346362590789795
train-epoch-step: 2-192 -- Loss: 0.36178743839263916
train-epoch-step: 2-193 -- Loss: 0.35280609130859375
train-epoch-step: 2-194 -- Loss: 0.28709420561790466
train-epoch-step: 2-195 -- Loss: 0.270770788192749
train-epoch-step: 2-196 -- Loss: 0.25744307041168213
train-epoch-step: 2-197 -- Loss: 0.18568545579910278
train-epoch-step: 2-198 -- Loss: 0.18267670273780823
train-epoch-step: 2-199 -- Loss: 0.22286438941955566
train-epoch-step: 2-200 -- Loss: 0.18028932809829712
train-epoch-step: 2-201 -- Loss: 0.2880652844905853
train-epoch-step: 2-202 -- Loss: 0.19515371322631836
train-epoch-step: 2-203 -- Loss: 0.25919151306152344
train-epoch-step: 2-204 -- Loss: 0.2267468273639679
train-epoch-step: 2-205 -- Loss: 0.2631533741950989
train-epoch-step: 2-206 -- Loss: 0.29698115587234497
train-epoch-step: 2-207 -- Loss: 0.19518369436264038
train-epoch-step: 2-208 -- Loss: 0.27235886454582214
train-epoch-step: 2-209 -- Loss: 0.1996636539697647
train-epoch-step: 2-210 -- Loss: 0.19401028752326965
train-epoch-step: 2-211 -- Loss: 0.327498197555542
train-epoch-step: 2-212 -- Loss: 0.2963067293167114
train-epoch-step: 2-213 -- Loss: 0.19800996780395508
train-epoch-step: 2-214 -- Loss: 0.21865078806877136
train-epoch-step: 2-215 -- Loss: 0.19549275934696198
train-epoch-step: 2-216 -- Loss: 0.27207836508750916
train-epoch-step: 2-217 -- Loss: 0.3249478340148926
train-epoch-step: 2-218 -- Loss: 0.22513394057750702
train-epoch-step: 2-219 -- Loss: 0.2956711947917938
train-epoch-step: 2-220 -- Loss: 0.18430712819099426
train-epoch-step: 2-221 -- Loss: 0.3206128776073456
train-epoch-step: 2-222 -- Loss: 0.19039586186408997
train-epoch-step: 2-223 -- Loss: 0.24563677608966827
train-epoch-step: 2-224 -- Loss: 0.2598578929901123
train-epoch-step: 2-225 -- Loss: 0.42609483003616333
train-epoch-step: 2-226 -- Loss: 0.3216058909893036
train-epoch-step: 2-227 -- Loss: 0.33642369508743286
train-epoch-step: 2-228 -- Loss: 0.2565847635269165
train-epoch-step: 2-229 -- Loss: 0.2939503788948059
train-epoch-step: 2-230 -- Loss: 0.24427416920661926
train-epoch-step: 2-231 -- Loss: 0.2654385566711426
train-epoch-step: 2-232 -- Loss: 0.278552383184433
train-epoch-step: 2-233 -- Loss: 0.14006084203720093
train-epoch-step: 2-234 -- Loss: 0.2584734857082367
train-epoch-step: 2-235 -- Loss: 0.227805495262146
train-epoch-step: 2-236 -- Loss: 0.27462655305862427
train-epoch-step: 2-237 -- Loss: 0.35283520817756653
train-epoch-step: 2-238 -- Loss: 0.23763203620910645
train-epoch-step: 2-239 -- Loss: 0.20163249969482422
train-epoch-step: 2-240 -- Loss: 0.32192713022232056
train-epoch-step: 2-241 -- Loss: 0.23668614029884338
train-epoch-step: 2-242 -- Loss: 0.3341221809387207
train-epoch-step: 2-243 -- Loss: 0.35384178161621094
train-epoch-step: 2-244 -- Loss: 0.3069819211959839
train-epoch-step: 2-245 -- Loss: 0.3505208492279053
train-epoch-step: 2-246 -- Loss: 0.4123615622520447
train-epoch-step: 2-247 -- Loss: 0.3411175012588501
train-epoch-step: 2-248 -- Loss: 0.25351592898368835
train-epoch-step: 2-249 -- Loss: 0.20425009727478027
train-epoch-step: 2-250 -- Loss: 0.3422020673751831
train-epoch-step: 2-251 -- Loss: 0.17609761655330658
train-epoch-step: 2-252 -- Loss: 0.26549509167671204
train-epoch-step: 2-253 -- Loss: 0.19295892119407654
train-epoch-step: 2-254 -- Loss: 0.3392014801502228
train-epoch-step: 2-255 -- Loss: 0.19940665364265442
train-epoch-step: 2-256 -- Loss: 0.20533478260040283
train-epoch-step: 2-257 -- Loss: 0.2698705196380615
train-epoch-step: 2-258 -- Loss: 0.23967161774635315
train-epoch-step: 2-259 -- Loss: 0.16014759242534637
train-epoch-step: 2-260 -- Loss: 0.30418938398361206
train-epoch-step: 2-261 -- Loss: 0.24336102604866028
train-epoch-step: 2-262 -- Loss: 0.4252626299858093
train-epoch-step: 2-263 -- Loss: 0.35482141375541687
train-epoch-step: 2-264 -- Loss: 0.2376943975687027
train-epoch-step: 2-265 -- Loss: 0.1601729691028595
train-epoch-step: 2-266 -- Loss: 0.21676580607891083
train-epoch-step: 2-267 -- Loss: 0.20445473492145538
train-epoch-step: 2-268 -- Loss: 0.17364057898521423
train-epoch-step: 2-269 -- Loss: 0.23690277338027954
train-epoch-step: 2-270 -- Loss: 0.15296635031700134
train-epoch-step: 2-271 -- Loss: 0.23466110229492188
train-epoch-step: 2-272 -- Loss: 0.17553125321865082
train-epoch-step: 2-273 -- Loss: 0.1813550591468811
train-epoch-step: 2-274 -- Loss: 0.2894883155822754
train-epoch-step: 2-275 -- Loss: 0.2984526753425598
train-epoch-step: 2-276 -- Loss: 0.22192835807800293
train-epoch-step: 2-277 -- Loss: 0.21081894636154175
train-epoch-step: 2-278 -- Loss: 0.21319489181041718
train-epoch-step: 2-279 -- Loss: 0.19966727495193481
train-epoch-step: 2-280 -- Loss: 0.2894626259803772
train-epoch-step: 2-281 -- Loss: 0.246745765209198
train-epoch-step: 2-282 -- Loss: 0.21209031343460083
train-epoch-step: 2-283 -- Loss: 0.1564617156982422
train-epoch-step: 2-284 -- Loss: 0.2612362205982208
train-epoch-step: 2-285 -- Loss: 0.2818185091018677
train-epoch-step: 2-286 -- Loss: 0.22042934596538544
train-epoch-step: 2-287 -- Loss: 0.30362606048583984
train-epoch-step: 2-288 -- Loss: 0.14861592650413513
train-epoch-step: 2-289 -- Loss: 0.18095549941062927
train-epoch-step: 2-290 -- Loss: 0.2550303339958191
train-epoch-step: 2-291 -- Loss: 0.17311610281467438
train-epoch-step: 2-292 -- Loss: 0.21376937627792358
train-epoch-step: 2-293 -- Loss: 0.21002164483070374
train-epoch-step: 2-294 -- Loss: 0.24628473818302155
train-epoch-step: 2-295 -- Loss: 0.44930005073547363
train-epoch-step: 2-296 -- Loss: 0.26970601081848145
train-epoch-step: 2-297 -- Loss: 0.25863468647003174
train-epoch-step: 2-298 -- Loss: 0.3448921740055084
train-epoch-step: 2-299 -- Loss: 0.24786436557769775
train-epoch-step: 2-300 -- Loss: 0.24926206469535828
train-epoch-step: 2-301 -- Loss: 0.2527395486831665
train-epoch-step: 2-302 -- Loss: 0.3389124274253845
train-epoch-step: 2-303 -- Loss: 0.3109012842178345
train-epoch-step: 2-304 -- Loss: 0.2100445032119751
train-epoch-step: 2-305 -- Loss: 0.2216314822435379
train-epoch-step: 2-306 -- Loss: 0.41907811164855957
train-epoch-step: 2-307 -- Loss: 0.23897133767604828
train-epoch-step: 2-308 -- Loss: 0.39229506254196167
train-epoch-step: 2-309 -- Loss: 0.24443355202674866
train-epoch-step: 2-310 -- Loss: 0.22899317741394043
train-epoch-step: 2-311 -- Loss: 0.23795610666275024
train-epoch-step: 2-312 -- Loss: 0.2996980547904968
train-epoch-step: 2-313 -- Loss: 0.14817777276039124
train-epoch-step: 2-314 -- Loss: 0.28970545530319214
train-epoch-step: 2-315 -- Loss: 0.2596457302570343
train-epoch-step: 2-316 -- Loss: 0.21716663241386414
train-epoch-step: 2-317 -- Loss: 0.19156229496002197
train-epoch-step: 2-318 -- Loss: 0.24182385206222534
train-epoch-step: 2-319 -- Loss: 0.2583446502685547
train-epoch-step: 2-320 -- Loss: 0.17103156447410583
train-epoch-step: 2-321 -- Loss: 0.20108045637607574
train-epoch-step: 2-322 -- Loss: 0.30137932300567627
train-epoch-step: 2-323 -- Loss: 0.2243286371231079
train-epoch-step: 2-324 -- Loss: 0.3754068613052368
train-epoch-step: 2-325 -- Loss: 0.24301768839359283
train-epoch-step: 2-326 -- Loss: 0.2891472280025482
train-epoch-step: 2-327 -- Loss: 0.2921786308288574
train-epoch-step: 2-328 -- Loss: 0.3048733174800873
train-epoch-step: 2-329 -- Loss: 0.4831899106502533
train-epoch-step: 2-330 -- Loss: 0.5112773180007935
train-epoch-step: 2-331 -- Loss: 0.32327431440353394
train-epoch-step: 2-332 -- Loss: 0.14908188581466675
train-epoch-step: 2-333 -- Loss: 0.2743279039859772
train-epoch-step: 2-334 -- Loss: 0.22337853908538818
train-epoch-step: 2-335 -- Loss: 0.24864238500595093
train-epoch-step: 2-336 -- Loss: 0.23692774772644043
train-epoch-step: 2-337 -- Loss: 0.2976941466331482
train-epoch-step: 2-338 -- Loss: 0.24585683643817902
train-epoch-step: 2-339 -- Loss: 0.2131277620792389
train-epoch-step: 2-340 -- Loss: 0.3091334402561188
train-epoch-step: 2-341 -- Loss: 0.18955738842487335
train-epoch-step: 2-342 -- Loss: 0.23093602061271667
train-epoch-step: 2-343 -- Loss: 0.21441683173179626
train-epoch-step: 2-344 -- Loss: 0.25054365396499634
train-epoch-step: 2-345 -- Loss: 0.18701523542404175
train-epoch-step: 2-346 -- Loss: 0.284460186958313
train-epoch-step: 2-347 -- Loss: 0.24447856843471527
train-epoch-step: 2-348 -- Loss: 0.3059278726577759
train-epoch-step: 2-349 -- Loss: 0.3097255825996399
train-epoch-step: 2-350 -- Loss: 0.39924919605255127
train-epoch-step: 2-351 -- Loss: 0.2917158603668213
train-epoch-step: 2-352 -- Loss: 0.2085568606853485
train-epoch-step: 2-353 -- Loss: 0.29677289724349976
train-epoch-step: 2-354 -- Loss: 0.3975456953048706
train-epoch-step: 2-355 -- Loss: 0.1661868393421173
train-epoch-step: 2-356 -- Loss: 0.16994476318359375
train-epoch-step: 2-357 -- Loss: 0.26964208483695984
train-epoch-step: 2-358 -- Loss: 0.2512640058994293
train-epoch-step: 2-359 -- Loss: 0.19815632700920105
train-epoch-step: 2-360 -- Loss: 0.19604705274105072
train-epoch-step: 2-361 -- Loss: 0.39717990159988403
train-epoch-step: 2-362 -- Loss: 0.23563164472579956
train-epoch-step: 2-363 -- Loss: 0.16332624852657318
train-epoch-step: 2-364 -- Loss: 0.24951854348182678
train-epoch-step: 2-365 -- Loss: 0.23668617010116577
train-epoch-step: 2-366 -- Loss: 0.27738964557647705
train-epoch-step: 2-367 -- Loss: 0.3718879818916321
train-epoch-step: 2-368 -- Loss: 0.30010199546813965
train-epoch-step: 2-369 -- Loss: 0.4083884358406067
train-epoch-step: 2-370 -- Loss: 0.20106615126132965
train-epoch-step: 2-371 -- Loss: 0.17409339547157288
train-epoch-step: 2-372 -- Loss: 0.20043987035751343
train-epoch-step: 2-373 -- Loss: 0.2747347950935364
train-epoch-step: 2-374 -- Loss: 0.22088149189949036
train-epoch-step: 2-375 -- Loss: 0.4099181890487671
train-epoch-step: 2-376 -- Loss: 0.2875599265098572
train-epoch-step: 2-377 -- Loss: 0.3687237501144409
train-epoch-step: 2-378 -- Loss: 0.2998783588409424
train-epoch-step: 2-379 -- Loss: 0.15778662264347076
train-epoch-step: 2-380 -- Loss: 0.1591496765613556
train-epoch-step: 2-381 -- Loss: 0.35889530181884766
train-epoch-step: 2-382 -- Loss: 0.38343629240989685
train-epoch-step: 2-383 -- Loss: 0.3237743675708771
train-epoch-step: 2-384 -- Loss: 0.3124361038208008
train-epoch-step: 2-385 -- Loss: 0.27479445934295654
train-epoch-step: 2-386 -- Loss: 0.3592004179954529
train-epoch-step: 2-387 -- Loss: 0.29722511768341064
train-epoch-step: 2-388 -- Loss: 0.2922474145889282
train-epoch-step: 2-389 -- Loss: 0.27205705642700195
train-epoch-step: 2-390 -- Loss: 0.21519263088703156
train-epoch-step: 2-391 -- Loss: 0.22150853276252747
train-epoch-step: 2-392 -- Loss: 0.2611026167869568
train-epoch-step: 2-393 -- Loss: 0.2150546759366989
train-epoch-step: 2-394 -- Loss: 0.31456679105758667
train-epoch-step: 2-395 -- Loss: 0.22308249771595
train-epoch-step: 2-396 -- Loss: 0.18612068891525269
train-epoch-step: 2-397 -- Loss: 0.1706169843673706
train-epoch-step: 2-398 -- Loss: 0.2631985545158386
train-epoch-step: 2-399 -- Loss: 0.30017030239105225
train-epoch-step: 2-400 -- Loss: 0.40531328320503235
train-epoch-step: 2-401 -- Loss: 0.16493673622608185
train-epoch-step: 2-402 -- Loss: 0.39134645462036133
train-epoch-step: 2-403 -- Loss: 0.24251137673854828
train-epoch-step: 2-404 -- Loss: 0.20925135910511017
train-epoch-step: 2-405 -- Loss: 0.20199298858642578
train-epoch-step: 2-406 -- Loss: 0.2294902801513672
train-epoch-step: 2-407 -- Loss: 0.1606559157371521
train-epoch-step: 2-408 -- Loss: 0.21951787173748016
train-epoch-step: 2-409 -- Loss: 0.25071775913238525
train-epoch-step: 2-410 -- Loss: 0.26975005865097046
train-epoch-step: 2-411 -- Loss: 0.30082571506500244
train-epoch-step: 2-412 -- Loss: 0.18644672632217407
train-epoch-step: 2-413 -- Loss: 0.20812085270881653
train-epoch-step: 2-414 -- Loss: 0.20658433437347412
train-epoch-step: 2-415 -- Loss: 0.18044590950012207
train-epoch-step: 2-416 -- Loss: 0.4294905662536621
train-epoch-step: 2-417 -- Loss: 0.28716960549354553
train-epoch-step: 2-418 -- Loss: 0.392794668674469
train-epoch-step: 2-419 -- Loss: 0.2402665913105011
train-epoch-step: 2-420 -- Loss: 0.20731332898139954
train-epoch-step: 2-421 -- Loss: 0.2469385862350464
train-epoch-step: 2-422 -- Loss: 0.22438302636146545
train-epoch-step: 2-423 -- Loss: 0.25729185342788696
train-epoch-step: 2-424 -- Loss: 0.2017800360918045
train-epoch-step: 2-425 -- Loss: 0.26174676418304443
train-epoch-step: 2-426 -- Loss: 0.23111359775066376
train-epoch-step: 2-427 -- Loss: 0.18975219130516052
train-epoch-step: 2-428 -- Loss: 0.30441367626190186
train-epoch-step: 2-429 -- Loss: 0.2706793546676636
train-epoch-step: 2-430 -- Loss: 0.1910969316959381
train-epoch-step: 2-431 -- Loss: 0.2424456626176834
train-epoch-step: 2-432 -- Loss: 0.3880263566970825
train-epoch-step: 2-433 -- Loss: 0.2159614861011505
train-epoch-step: 2-434 -- Loss: 0.21709366142749786
train-epoch-step: 2-435 -- Loss: 0.23867611587047577
train-epoch-step: 2-436 -- Loss: 0.21835312247276306
train-epoch-step: 2-437 -- Loss: 0.18700005114078522
train-epoch-step: 2-438 -- Loss: 0.25771790742874146
train-epoch-step: 2-439 -- Loss: 0.4671039879322052
train-epoch-step: 2-440 -- Loss: 0.2112860083580017
train-epoch-step: 2-441 -- Loss: 0.3150659501552582
train-epoch-step: 2-442 -- Loss: 0.2627277672290802
train-epoch-step: 2-443 -- Loss: 0.23429664969444275
train-epoch-step: 2-444 -- Loss: 0.32968613505363464
train-epoch-step: 2-445 -- Loss: 0.294453889131546
train-epoch-step: 2-446 -- Loss: 0.21484772861003876
train-epoch-step: 2-447 -- Loss: 0.3019854724407196
train-epoch-step: 2-448 -- Loss: 0.3526607155799866
train-epoch-step: 2-449 -- Loss: 0.25951576232910156
train-epoch-step: 2-450 -- Loss: 0.2710915207862854
train-epoch-step: 2-451 -- Loss: 0.2079046219587326
train-epoch-step: 2-452 -- Loss: 0.19346091151237488
train-epoch-step: 2-453 -- Loss: 0.13723407685756683
train-epoch-step: 2-454 -- Loss: 0.33947786688804626
train-epoch-step: 2-455 -- Loss: 0.19886937737464905
train-epoch-step: 2-456 -- Loss: 0.1738959550857544
train-epoch-step: 2-457 -- Loss: 0.308173269033432
train-epoch-step: 2-458 -- Loss: 0.23220080137252808
train-epoch-step: 2-459 -- Loss: 0.3308374285697937
train-epoch-step: 2-460 -- Loss: 0.18776646256446838
train-epoch-step: 2-461 -- Loss: 0.21004992723464966
train-epoch-step: 2-462 -- Loss: 0.2161664068698883
train-epoch-step: 2-463 -- Loss: 0.20188561081886292
train-epoch-step: 2-464 -- Loss: 0.2893117666244507
train-epoch-step: 2-465 -- Loss: 0.47911912202835083
train-epoch-step: 2-466 -- Loss: 0.29524460434913635
train-epoch-step: 2-467 -- Loss: 0.1604931354522705
train-epoch-step: 2-468 -- Loss: 0.2925795316696167
train-epoch-step: 2-469 -- Loss: 0.3652566075325012
train-epoch-step: 2-470 -- Loss: 0.24837122857570648
train-epoch-step: 2-471 -- Loss: 0.23537284135818481
train-epoch-step: 2-472 -- Loss: 0.22675244510173798
train-epoch-step: 2-473 -- Loss: 0.2319106161594391
train-epoch-step: 2-474 -- Loss: 0.16780421137809753
train-epoch-step: 2-475 -- Loss: 0.16210296750068665
train-epoch-step: 2-476 -- Loss: 0.2842511832714081
train-epoch-step: 2-477 -- Loss: 0.31560999155044556
train-epoch-step: 2-478 -- Loss: 0.26790034770965576
train-epoch-step: 2-479 -- Loss: 0.1872638761997223
train-epoch-step: 2-480 -- Loss: 0.34353107213974
train-epoch-step: 2-481 -- Loss: 0.4066754877567291
train-epoch-step: 2-482 -- Loss: 0.3475053310394287
train-epoch-step: 2-483 -- Loss: 0.2792660892009735
train-epoch-step: 2-484 -- Loss: 0.2952940762042999
train-epoch-step: 2-485 -- Loss: 0.19415424764156342
train-epoch-step: 2-486 -- Loss: 0.35359033942222595
train-epoch-step: 2-487 -- Loss: 0.32954514026641846
train-epoch-step: 2-488 -- Loss: 0.27133673429489136
train-epoch-step: 2-489 -- Loss: 0.29791849851608276
train-epoch-step: 2-490 -- Loss: 0.2000899314880371
train-epoch-step: 2-491 -- Loss: 0.1910255253314972
train-epoch-step: 2-492 -- Loss: 0.17746539413928986
train-epoch-step: 2-493 -- Loss: 0.3051755428314209
train-epoch-step: 2-494 -- Loss: 0.28992605209350586
train-epoch-step: 2-495 -- Loss: 0.30948173999786377
train-epoch-step: 2-496 -- Loss: 0.1877644807100296
train-epoch-step: 2-497 -- Loss: 0.3100779056549072
train-epoch-step: 2-498 -- Loss: 0.2079477310180664
train-epoch-step: 2-499 -- Loss: 0.24490110576152802
train-epoch-step: 2-500 -- Loss: 0.22123396396636963
train-epoch-step: 2-501 -- Loss: 0.2948589026927948
train-epoch-step: 2-502 -- Loss: 0.2646872401237488
train-epoch-step: 2-503 -- Loss: 0.3212258219718933
train-epoch-step: 2-504 -- Loss: 0.1606760174036026
train-epoch-step: 2-505 -- Loss: 0.26087772846221924
train-epoch-step: 2-506 -- Loss: 0.16987645626068115
train-epoch-step: 2-507 -- Loss: 0.2756316661834717
train-epoch-step: 2-508 -- Loss: 0.25611281394958496
train-epoch-step: 2-509 -- Loss: 0.24315941333770752
train-epoch-step: 2-510 -- Loss: 0.206932932138443
train-epoch-step: 2-511 -- Loss: 0.3074621260166168
train-epoch-step: 2-512 -- Loss: 0.30648094415664673
train-epoch-step: 2-513 -- Loss: 0.2830592691898346
train-epoch-step: 2-514 -- Loss: 0.21304470300674438
train-epoch-step: 2-515 -- Loss: 0.24542230367660522
train-epoch-step: 2-516 -- Loss: 0.2413462996482849
train-epoch-step: 2-517 -- Loss: 0.273110032081604
train-epoch-step: 2-518 -- Loss: 0.20103177428245544
train-epoch-step: 2-519 -- Loss: 0.20214003324508667
train-epoch-step: 2-520 -- Loss: 0.27195098996162415
train-epoch-step: 2-521 -- Loss: 0.34131962060928345
train-epoch-step: 2-522 -- Loss: 0.3000278174877167
train-epoch-step: 2-523 -- Loss: 0.23115572333335876
train-epoch-step: 2-524 -- Loss: 0.23445799946784973
train-epoch-step: 2-525 -- Loss: 0.29403355717658997
train-epoch-step: 2-526 -- Loss: 0.1842910498380661
train-epoch-step: 2-527 -- Loss: 0.23390239477157593
train-epoch-step: 2-528 -- Loss: 0.229777991771698
train-epoch-step: 2-529 -- Loss: 0.2531300485134125
train-epoch-step: 2-530 -- Loss: 0.2510814666748047
train-epoch-step: 2-531 -- Loss: 0.3106171786785126
train-epoch-step: 2-532 -- Loss: 0.24288654327392578
train-epoch-step: 2-533 -- Loss: 0.23949846625328064
train-epoch-step: 2-534 -- Loss: 0.1818099319934845
train-epoch-step: 2-535 -- Loss: 0.4694238603115082
train-epoch-step: 2-536 -- Loss: 0.22205424308776855
train-epoch-step: 2-537 -- Loss: 0.2076382040977478
train-epoch-step: 2-538 -- Loss: 0.1509861946105957
train-epoch-step: 2-539 -- Loss: 0.28072988986968994
train-epoch-step: 2-540 -- Loss: 0.18066586554050446
train-epoch-step: 2-541 -- Loss: 0.31448203325271606
train-epoch-step: 2-542 -- Loss: 0.34522882103919983
train-epoch-step: 2-543 -- Loss: 0.24570025503635406
train-epoch-step: 2-544 -- Loss: 0.31474393606185913
train-epoch-step: 2-545 -- Loss: 0.2797067165374756
train-epoch-step: 2-546 -- Loss: 0.34317442774772644
train-epoch-step: 2-547 -- Loss: 0.2530764937400818
train-epoch-step: 2-548 -- Loss: 0.13519693911075592
train-epoch-step: 2-549 -- Loss: 0.23256278038024902
train-epoch-step: 2-550 -- Loss: 0.2771660387516022
train-epoch-step: 2-551 -- Loss: 0.24147164821624756
train-epoch-step: 2-552 -- Loss: 0.17655298113822937
train-epoch-step: 2-553 -- Loss: 0.2831345200538635
train-epoch-step: 2-554 -- Loss: 0.2561395764350891
train-epoch-step: 2-555 -- Loss: 0.41367942094802856
train-epoch-step: 2-556 -- Loss: 0.24136243760585785
train-epoch-step: 2-557 -- Loss: 0.35851967334747314
train-epoch-step: 2-558 -- Loss: 0.3831028342247009
train-epoch-step: 2-559 -- Loss: 0.20929266512393951
train-epoch-step: 2-560 -- Loss: 0.2890077233314514
train-epoch-step: 2-561 -- Loss: 0.3016059398651123
train-epoch-step: 2-562 -- Loss: 0.2867506146430969
train-epoch-step: 2-563 -- Loss: 0.2708459794521332
train-epoch-step: 2-564 -- Loss: 0.15448322892189026
train-epoch-step: 2-565 -- Loss: 0.2590828537940979
train-epoch-step: 2-566 -- Loss: 0.22915227711200714
train-epoch-step: 2-567 -- Loss: 0.2846628427505493
train-epoch-step: 2-568 -- Loss: 0.23423245549201965
train-epoch-step: 2-569 -- Loss: 0.3137509524822235
train-epoch-step: 2-570 -- Loss: 0.23920032382011414
train-epoch-step: 2-571 -- Loss: 0.2893224060535431
train-epoch-step: 2-572 -- Loss: 0.34213027358055115
train-epoch-step: 2-573 -- Loss: 0.2979206442832947
train-epoch-step: 2-574 -- Loss: 0.36370229721069336
train-epoch-step: 2-575 -- Loss: 0.44539567828178406
train-epoch-step: 2-576 -- Loss: 0.17968039214611053
train-epoch-step: 2-577 -- Loss: 0.2290026992559433
train-epoch-step: 2-578 -- Loss: 0.3219029903411865
train-epoch-step: 2-579 -- Loss: 0.22710686922073364
train-epoch-step: 2-580 -- Loss: 0.27599358558654785
train-epoch-step: 2-581 -- Loss: 0.18828904628753662
train-epoch-step: 2-582 -- Loss: 0.3248904049396515
train-epoch-step: 2-583 -- Loss: 0.31450748443603516
train-epoch-step: 2-584 -- Loss: 0.2704637944698334
train-epoch-step: 2-585 -- Loss: 0.26131534576416016
train-epoch-step: 2-586 -- Loss: 0.3715038001537323
train-epoch-step: 2-587 -- Loss: 0.23643669486045837
train-epoch-step: 2-588 -- Loss: 0.18714606761932373
val-epoch-step: 2-589 -- Loss: 0.32955828309059143
val-epoch-step: 2-590 -- Loss: 0.20439642667770386
val-epoch-step: 2-591 -- Loss: 0.30141493678092957
val-epoch-step: 2-592 -- Loss: 0.2354593276977539
val-epoch-step: 2-593 -- Loss: 0.20093496143817902
val-epoch-step: 2-594 -- Loss: 0.4144101142883301
val-epoch-step: 2-595 -- Loss: 0.23686370253562927
val-epoch-step: 2-596 -- Loss: 0.27930203080177307
val-epoch-step: 2-597 -- Loss: 0.2612778842449188
val-epoch-step: 2-598 -- Loss: 0.2165791094303131
val-epoch-step: 2-599 -- Loss: 0.25534677505493164
val-epoch-step: 2-600 -- Loss: 0.2473832368850708
val-epoch-step: 2-601 -- Loss: 0.19719555974006653
val-epoch-step: 2-602 -- Loss: 0.20044559240341187
val-epoch-step: 2-603 -- Loss: 0.298958957195282
val-epoch-step: 2-604 -- Loss: 0.18820354342460632
val-epoch-step: 2-605 -- Loss: 0.20054730772972107
val-epoch-step: 2-606 -- Loss: 0.406819611787796
val-epoch-step: 2-607 -- Loss: 0.199515700340271
val-epoch-step: 2-608 -- Loss: 0.3347019553184509
val-epoch-step: 2-609 -- Loss: 0.24384036660194397
val-epoch-step: 2-610 -- Loss: 0.27542227506637573
val-epoch-step: 2-611 -- Loss: 0.221176415681839
val-epoch-step: 2-612 -- Loss: 0.38876259326934814
val-epoch-step: 2-613 -- Loss: 0.24457816779613495
val-epoch-step: 2-614 -- Loss: 0.21003013849258423
val-epoch-step: 2-615 -- Loss: 0.26152002811431885
val-epoch-step: 2-616 -- Loss: 0.1931149810552597
val-epoch-step: 2-617 -- Loss: 0.30069610476493835
val-epoch-step: 2-618 -- Loss: 0.26560020446777344
val-epoch-step: 2-619 -- Loss: 0.29323500394821167
val-epoch-step: 2-620 -- Loss: 0.19490200281143188
val-epoch-step: 2-621 -- Loss: 0.1919475644826889
val-epoch-step: 2-622 -- Loss: 0.19710227847099304
val-epoch-step: 2-623 -- Loss: 0.21199020743370056
val-epoch-step: 2-624 -- Loss: 0.22547805309295654
val-epoch-step: 2-625 -- Loss: 0.20700867474079132
val-epoch-step: 2-626 -- Loss: 0.22034500539302826
val-epoch-step: 2-627 -- Loss: 0.2665502429008484
val-epoch-step: 2-628 -- Loss: 0.48459285497665405
val-epoch-step: 2-629 -- Loss: 0.2772585153579712
val-epoch-step: 2-630 -- Loss: 0.4707915186882019
val-epoch-step: 2-631 -- Loss: 0.2011534720659256
val-epoch-step: 2-632 -- Loss: 0.2626853585243225
val-epoch-step: 2-633 -- Loss: 0.20773212611675262
val-epoch-step: 2-634 -- Loss: 0.19138388335704803
val-epoch-step: 2-635 -- Loss: 0.14993028342723846
val-epoch-step: 2-636 -- Loss: 0.22238266468048096
val-epoch-step: 2-637 -- Loss: 0.25295642018318176
val-epoch-step: 2-638 -- Loss: 0.20919013023376465
val-epoch-step: 2-639 -- Loss: 0.34746041893959045
val-epoch-step: 2-640 -- Loss: 0.3523982763290405
val-epoch-step: 2-641 -- Loss: 0.17225030064582825
val-epoch-step: 2-642 -- Loss: 0.2699267268180847
val-epoch-step: 2-643 -- Loss: 0.27250218391418457
val-epoch-step: 2-644 -- Loss: 0.23349879682064056
val-epoch-step: 2-645 -- Loss: 0.2963888943195343
val-epoch-step: 2-646 -- Loss: 0.2040499448776245
val-epoch-step: 2-647 -- Loss: 0.1837276965379715
val-epoch-step: 2-648 -- Loss: 0.22370967268943787
val-epoch-step: 2-649 -- Loss: 0.3844448924064636
val-epoch-step: 2-650 -- Loss: 0.3416944146156311
val-epoch-step: 2-651 -- Loss: 0.19036146998405457
val-epoch-step: 2-652 -- Loss: 0.21223792433738708
val-epoch-step: 2-653 -- Loss: 0.26607394218444824
val-epoch-step: 2-654 -- Loss: 0.15316040813922882
Epoch: 2 -- Train Loss: tensor(0.1708, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 3-0 -- Loss: 0.30990880727767944
train-epoch-step: 3-1 -- Loss: 0.20193728804588318
train-epoch-step: 3-2 -- Loss: 0.2734629213809967
train-epoch-step: 3-3 -- Loss: 0.20034921169281006
train-epoch-step: 3-4 -- Loss: 0.26760709285736084
train-epoch-step: 3-5 -- Loss: 0.2573448419570923
train-epoch-step: 3-6 -- Loss: 0.40286993980407715
train-epoch-step: 3-7 -- Loss: 0.23381318151950836
train-epoch-step: 3-8 -- Loss: 0.2613604962825775
train-epoch-step: 3-9 -- Loss: 0.3772454857826233
train-epoch-step: 3-10 -- Loss: 0.36366191506385803
train-epoch-step: 3-11 -- Loss: 0.24302679300308228
train-epoch-step: 3-12 -- Loss: 0.21187543869018555
train-epoch-step: 3-13 -- Loss: 0.2769226133823395
train-epoch-step: 3-14 -- Loss: 0.22099553048610687
train-epoch-step: 3-15 -- Loss: 0.22474926710128784
train-epoch-step: 3-16 -- Loss: 0.24900928139686584
train-epoch-step: 3-17 -- Loss: 0.30858495831489563
train-epoch-step: 3-18 -- Loss: 0.2798740267753601
train-epoch-step: 3-19 -- Loss: 0.19284705817699432
train-epoch-step: 3-20 -- Loss: 0.30315452814102173
train-epoch-step: 3-21 -- Loss: 0.39401325583457947
train-epoch-step: 3-22 -- Loss: 0.21645112335681915
train-epoch-step: 3-23 -- Loss: 0.2550358176231384
train-epoch-step: 3-24 -- Loss: 0.18869858980178833
train-epoch-step: 3-25 -- Loss: 0.30721527338027954
train-epoch-step: 3-26 -- Loss: 0.27964797616004944
train-epoch-step: 3-27 -- Loss: 0.46348267793655396
train-epoch-step: 3-28 -- Loss: 0.18133249878883362
train-epoch-step: 3-29 -- Loss: 0.3258347511291504
train-epoch-step: 3-30 -- Loss: 0.15654399991035461
train-epoch-step: 3-31 -- Loss: 0.2042202353477478
train-epoch-step: 3-32 -- Loss: 0.24627730250358582
train-epoch-step: 3-33 -- Loss: 0.3861052393913269
train-epoch-step: 3-34 -- Loss: 0.2473471313714981
train-epoch-step: 3-35 -- Loss: 0.3463423252105713
train-epoch-step: 3-36 -- Loss: 0.21874549984931946
train-epoch-step: 3-37 -- Loss: 0.21709418296813965
train-epoch-step: 3-38 -- Loss: 0.26960688829421997
train-epoch-step: 3-39 -- Loss: 0.34495192766189575
train-epoch-step: 3-40 -- Loss: 0.2915789484977722
train-epoch-step: 3-41 -- Loss: 0.3023095726966858
train-epoch-step: 3-42 -- Loss: 0.20974010229110718
train-epoch-step: 3-43 -- Loss: 0.4379394054412842
train-epoch-step: 3-44 -- Loss: 0.1837429702281952
train-epoch-step: 3-45 -- Loss: 0.17788410186767578
train-epoch-step: 3-46 -- Loss: 0.24154327809810638
train-epoch-step: 3-47 -- Loss: 0.31331735849380493
train-epoch-step: 3-48 -- Loss: 0.21726153790950775
train-epoch-step: 3-49 -- Loss: 0.2937370538711548
train-epoch-step: 3-50 -- Loss: 0.1699419468641281
train-epoch-step: 3-51 -- Loss: 0.2695133686065674
train-epoch-step: 3-52 -- Loss: 0.21206852793693542
train-epoch-step: 3-53 -- Loss: 0.3233039975166321
train-epoch-step: 3-54 -- Loss: 0.393837034702301
train-epoch-step: 3-55 -- Loss: 0.23327144980430603
train-epoch-step: 3-56 -- Loss: 0.28621309995651245
train-epoch-step: 3-57 -- Loss: 0.3512105345726013
train-epoch-step: 3-58 -- Loss: 0.3715476989746094
train-epoch-step: 3-59 -- Loss: 0.36181527376174927
train-epoch-step: 3-60 -- Loss: 0.18183119595050812
train-epoch-step: 3-61 -- Loss: 0.30363449454307556
train-epoch-step: 3-62 -- Loss: 0.26139283180236816
train-epoch-step: 3-63 -- Loss: 0.19377192854881287
train-epoch-step: 3-64 -- Loss: 0.23129479587078094
train-epoch-step: 3-65 -- Loss: 0.27512428164482117
train-epoch-step: 3-66 -- Loss: 0.153096541762352
train-epoch-step: 3-67 -- Loss: 0.178384929895401
train-epoch-step: 3-68 -- Loss: 0.3254154324531555
train-epoch-step: 3-69 -- Loss: 0.19257357716560364
train-epoch-step: 3-70 -- Loss: 0.3347605764865875
train-epoch-step: 3-71 -- Loss: 0.36412855982780457
train-epoch-step: 3-72 -- Loss: 0.25072193145751953
train-epoch-step: 3-73 -- Loss: 0.29905128479003906
train-epoch-step: 3-74 -- Loss: 0.13555684685707092
train-epoch-step: 3-75 -- Loss: 0.1965470016002655
train-epoch-step: 3-76 -- Loss: 0.20402580499649048
train-epoch-step: 3-77 -- Loss: 0.31110450625419617
train-epoch-step: 3-78 -- Loss: 0.38691848516464233
train-epoch-step: 3-79 -- Loss: 0.2756871283054352
train-epoch-step: 3-80 -- Loss: 0.3776474595069885
train-epoch-step: 3-81 -- Loss: 0.19546571373939514
train-epoch-step: 3-82 -- Loss: 0.3399077355861664
train-epoch-step: 3-83 -- Loss: 0.26541197299957275
train-epoch-step: 3-84 -- Loss: 0.2892027199268341
train-epoch-step: 3-85 -- Loss: 0.2504923641681671
train-epoch-step: 3-86 -- Loss: 0.16991063952445984
train-epoch-step: 3-87 -- Loss: 0.31380778551101685
train-epoch-step: 3-88 -- Loss: 0.19794104993343353
train-epoch-step: 3-89 -- Loss: 0.2643895149230957
train-epoch-step: 3-90 -- Loss: 0.2722511887550354
train-epoch-step: 3-91 -- Loss: 0.3378455638885498
train-epoch-step: 3-92 -- Loss: 0.23281970620155334
train-epoch-step: 3-93 -- Loss: 0.27276811003685
train-epoch-step: 3-94 -- Loss: 0.34032586216926575
train-epoch-step: 3-95 -- Loss: 0.2760424315929413
train-epoch-step: 3-96 -- Loss: 0.3121581971645355
train-epoch-step: 3-97 -- Loss: 0.2658041715621948
train-epoch-step: 3-98 -- Loss: 0.22645241022109985
train-epoch-step: 3-99 -- Loss: 0.24925093352794647
train-epoch-step: 3-100 -- Loss: 0.2619171738624573
train-epoch-step: 3-101 -- Loss: 0.3615027070045471
train-epoch-step: 3-102 -- Loss: 0.36262089014053345
train-epoch-step: 3-103 -- Loss: 0.2881184220314026
train-epoch-step: 3-104 -- Loss: 0.21402694284915924
train-epoch-step: 3-105 -- Loss: 0.47260603308677673
train-epoch-step: 3-106 -- Loss: 0.25300848484039307
train-epoch-step: 3-107 -- Loss: 0.2865169942378998
train-epoch-step: 3-108 -- Loss: 0.2537674307823181
train-epoch-step: 3-109 -- Loss: 0.22322818636894226
train-epoch-step: 3-110 -- Loss: 0.2676578760147095
train-epoch-step: 3-111 -- Loss: 0.25866061449050903
train-epoch-step: 3-112 -- Loss: 0.22931599617004395
train-epoch-step: 3-113 -- Loss: 0.2728169858455658
train-epoch-step: 3-114 -- Loss: 0.32404443621635437
train-epoch-step: 3-115 -- Loss: 0.22827863693237305
train-epoch-step: 3-116 -- Loss: 0.2086777687072754
train-epoch-step: 3-117 -- Loss: 0.1813495010137558
train-epoch-step: 3-118 -- Loss: 0.28058797121047974
train-epoch-step: 3-119 -- Loss: 0.2051319181919098
train-epoch-step: 3-120 -- Loss: 0.3597564399242401
train-epoch-step: 3-121 -- Loss: 0.348402202129364
train-epoch-step: 3-122 -- Loss: 0.3121385872364044
train-epoch-step: 3-123 -- Loss: 0.29525333642959595
train-epoch-step: 3-124 -- Loss: 0.1701839566230774
train-epoch-step: 3-125 -- Loss: 0.21194040775299072
train-epoch-step: 3-126 -- Loss: 0.3410147428512573
train-epoch-step: 3-127 -- Loss: 0.23301851749420166
train-epoch-step: 3-128 -- Loss: 0.25226151943206787
train-epoch-step: 3-129 -- Loss: 0.19523605704307556
train-epoch-step: 3-130 -- Loss: 0.2592858076095581
train-epoch-step: 3-131 -- Loss: 0.18931247293949127
train-epoch-step: 3-132 -- Loss: 0.26694393157958984
train-epoch-step: 3-133 -- Loss: 0.1587696075439453
train-epoch-step: 3-134 -- Loss: 0.272153377532959
train-epoch-step: 3-135 -- Loss: 0.18462777137756348
train-epoch-step: 3-136 -- Loss: 0.1717667281627655
train-epoch-step: 3-137 -- Loss: 0.3566807210445404
train-epoch-step: 3-138 -- Loss: 0.393974244594574
train-epoch-step: 3-139 -- Loss: 0.1855999082326889
train-epoch-step: 3-140 -- Loss: 0.3124958872795105
train-epoch-step: 3-141 -- Loss: 0.33388614654541016
train-epoch-step: 3-142 -- Loss: 0.2817913591861725
train-epoch-step: 3-143 -- Loss: 0.255165159702301
train-epoch-step: 3-144 -- Loss: 0.2681523859500885
train-epoch-step: 3-145 -- Loss: 0.19496868550777435
train-epoch-step: 3-146 -- Loss: 0.2507578134536743
train-epoch-step: 3-147 -- Loss: 0.25902289152145386
train-epoch-step: 3-148 -- Loss: 0.241472989320755
train-epoch-step: 3-149 -- Loss: 0.16283878684043884
train-epoch-step: 3-150 -- Loss: 0.26002687215805054
train-epoch-step: 3-151 -- Loss: 0.26663297414779663
train-epoch-step: 3-152 -- Loss: 0.2696133255958557
train-epoch-step: 3-153 -- Loss: 0.41524365544319153
train-epoch-step: 3-154 -- Loss: 0.19977876543998718
train-epoch-step: 3-155 -- Loss: 0.19372200965881348
train-epoch-step: 3-156 -- Loss: 0.1682756543159485
train-epoch-step: 3-157 -- Loss: 0.2344481647014618
train-epoch-step: 3-158 -- Loss: 0.24452199041843414
train-epoch-step: 3-159 -- Loss: 0.2356262505054474
train-epoch-step: 3-160 -- Loss: 0.29709479212760925
train-epoch-step: 3-161 -- Loss: 0.3018953502178192
train-epoch-step: 3-162 -- Loss: 0.30243223905563354
train-epoch-step: 3-163 -- Loss: 0.27157124876976013
train-epoch-step: 3-164 -- Loss: 0.2548609972000122
train-epoch-step: 3-165 -- Loss: 0.22409497201442719
train-epoch-step: 3-166 -- Loss: 0.1750604659318924
train-epoch-step: 3-167 -- Loss: 0.16914969682693481
train-epoch-step: 3-168 -- Loss: 0.2849937677383423
train-epoch-step: 3-169 -- Loss: 0.19078806042671204
train-epoch-step: 3-170 -- Loss: 0.29190242290496826
train-epoch-step: 3-171 -- Loss: 0.2298450767993927
train-epoch-step: 3-172 -- Loss: 0.36113929748535156
train-epoch-step: 3-173 -- Loss: 0.17895756661891937
train-epoch-step: 3-174 -- Loss: 0.3443433344364166
train-epoch-step: 3-175 -- Loss: 0.2721081078052521
train-epoch-step: 3-176 -- Loss: 0.18499520421028137
train-epoch-step: 3-177 -- Loss: 0.2521112561225891
train-epoch-step: 3-178 -- Loss: 0.2598778009414673
train-epoch-step: 3-179 -- Loss: 0.1918671727180481
train-epoch-step: 3-180 -- Loss: 0.20305003225803375
train-epoch-step: 3-181 -- Loss: 0.2557651400566101
train-epoch-step: 3-182 -- Loss: 0.27338531613349915
train-epoch-step: 3-183 -- Loss: 0.4642046093940735
train-epoch-step: 3-184 -- Loss: 0.20692400634288788
train-epoch-step: 3-185 -- Loss: 0.2020299732685089
train-epoch-step: 3-186 -- Loss: 0.2667224407196045
train-epoch-step: 3-187 -- Loss: 0.31351494789123535
train-epoch-step: 3-188 -- Loss: 0.2689509093761444
train-epoch-step: 3-189 -- Loss: 0.18579861521720886
train-epoch-step: 3-190 -- Loss: 0.23992012441158295
train-epoch-step: 3-191 -- Loss: 0.24173644185066223
train-epoch-step: 3-192 -- Loss: 0.3491125702857971
train-epoch-step: 3-193 -- Loss: 0.3365911841392517
train-epoch-step: 3-194 -- Loss: 0.2593381702899933
train-epoch-step: 3-195 -- Loss: 0.24991539120674133
train-epoch-step: 3-196 -- Loss: 0.25025129318237305
train-epoch-step: 3-197 -- Loss: 0.17483669519424438
train-epoch-step: 3-198 -- Loss: 0.17689140141010284
train-epoch-step: 3-199 -- Loss: 0.21056890487670898
train-epoch-step: 3-200 -- Loss: 0.17208820581436157
train-epoch-step: 3-201 -- Loss: 0.27408263087272644
train-epoch-step: 3-202 -- Loss: 0.18940123915672302
train-epoch-step: 3-203 -- Loss: 0.24871625006198883
train-epoch-step: 3-204 -- Loss: 0.20573650300502777
train-epoch-step: 3-205 -- Loss: 0.2509530186653137
train-epoch-step: 3-206 -- Loss: 0.2842743694782257
train-epoch-step: 3-207 -- Loss: 0.1862398087978363
train-epoch-step: 3-208 -- Loss: 0.24648647010326385
train-epoch-step: 3-209 -- Loss: 0.1971818208694458
train-epoch-step: 3-210 -- Loss: 0.18556948006153107
train-epoch-step: 3-211 -- Loss: 0.28951990604400635
train-epoch-step: 3-212 -- Loss: 0.2738114893436432
train-epoch-step: 3-213 -- Loss: 0.18363049626350403
train-epoch-step: 3-214 -- Loss: 0.20242615044116974
train-epoch-step: 3-215 -- Loss: 0.19044461846351624
train-epoch-step: 3-216 -- Loss: 0.2705560624599457
train-epoch-step: 3-217 -- Loss: 0.3023938834667206
train-epoch-step: 3-218 -- Loss: 0.21165280044078827
train-epoch-step: 3-219 -- Loss: 0.28535544872283936
train-epoch-step: 3-220 -- Loss: 0.17594143748283386
train-epoch-step: 3-221 -- Loss: 0.28791719675064087
train-epoch-step: 3-222 -- Loss: 0.17448167502880096
train-epoch-step: 3-223 -- Loss: 0.2329346239566803
train-epoch-step: 3-224 -- Loss: 0.24756836891174316
train-epoch-step: 3-225 -- Loss: 0.42895686626434326
train-epoch-step: 3-226 -- Loss: 0.31159651279449463
train-epoch-step: 3-227 -- Loss: 0.32226163148880005
train-epoch-step: 3-228 -- Loss: 0.2470107227563858
train-epoch-step: 3-229 -- Loss: 0.27609503269195557
train-epoch-step: 3-230 -- Loss: 0.22541172802448273
train-epoch-step: 3-231 -- Loss: 0.2462635338306427
train-epoch-step: 3-232 -- Loss: 0.26801663637161255
train-epoch-step: 3-233 -- Loss: 0.12348823994398117
train-epoch-step: 3-234 -- Loss: 0.24438771605491638
train-epoch-step: 3-235 -- Loss: 0.21938760578632355
train-epoch-step: 3-236 -- Loss: 0.2488783895969391
train-epoch-step: 3-237 -- Loss: 0.34533804655075073
train-epoch-step: 3-238 -- Loss: 0.22138196229934692
train-epoch-step: 3-239 -- Loss: 0.19356995820999146
train-epoch-step: 3-240 -- Loss: 0.3038508892059326
train-epoch-step: 3-241 -- Loss: 0.21933506429195404
train-epoch-step: 3-242 -- Loss: 0.31038179993629456
train-epoch-step: 3-243 -- Loss: 0.32202112674713135
train-epoch-step: 3-244 -- Loss: 0.2919934391975403
train-epoch-step: 3-245 -- Loss: 0.33015286922454834
train-epoch-step: 3-246 -- Loss: 0.38855451345443726
train-epoch-step: 3-247 -- Loss: 0.33097589015960693
train-epoch-step: 3-248 -- Loss: 0.24468326568603516
train-epoch-step: 3-249 -- Loss: 0.19558754563331604
train-epoch-step: 3-250 -- Loss: 0.314582884311676
train-epoch-step: 3-251 -- Loss: 0.16711607575416565
train-epoch-step: 3-252 -- Loss: 0.2579900026321411
train-epoch-step: 3-253 -- Loss: 0.18320053815841675
train-epoch-step: 3-254 -- Loss: 0.3269844949245453
train-epoch-step: 3-255 -- Loss: 0.19315847754478455
train-epoch-step: 3-256 -- Loss: 0.20179542899131775
train-epoch-step: 3-257 -- Loss: 0.25572168827056885
train-epoch-step: 3-258 -- Loss: 0.228355273604393
train-epoch-step: 3-259 -- Loss: 0.15585297346115112
train-epoch-step: 3-260 -- Loss: 0.294355571269989
train-epoch-step: 3-261 -- Loss: 0.23866435885429382
train-epoch-step: 3-262 -- Loss: 0.4127981960773468
train-epoch-step: 3-263 -- Loss: 0.3287668526172638
train-epoch-step: 3-264 -- Loss: 0.2312658727169037
train-epoch-step: 3-265 -- Loss: 0.15329721570014954
train-epoch-step: 3-266 -- Loss: 0.20938590168952942
train-epoch-step: 3-267 -- Loss: 0.19876988232135773
train-epoch-step: 3-268 -- Loss: 0.16536137461662292
train-epoch-step: 3-269 -- Loss: 0.23321771621704102
train-epoch-step: 3-270 -- Loss: 0.1464693695306778
train-epoch-step: 3-271 -- Loss: 0.2152296006679535
train-epoch-step: 3-272 -- Loss: 0.16531942784786224
train-epoch-step: 3-273 -- Loss: 0.17346468567848206
train-epoch-step: 3-274 -- Loss: 0.2646283209323883
train-epoch-step: 3-275 -- Loss: 0.28292858600616455
train-epoch-step: 3-276 -- Loss: 0.20964902639389038
train-epoch-step: 3-277 -- Loss: 0.20488475263118744
train-epoch-step: 3-278 -- Loss: 0.2026708424091339
train-epoch-step: 3-279 -- Loss: 0.19384372234344482
train-epoch-step: 3-280 -- Loss: 0.27500319480895996
train-epoch-step: 3-281 -- Loss: 0.24003207683563232
train-epoch-step: 3-282 -- Loss: 0.1975599229335785
train-epoch-step: 3-283 -- Loss: 0.14908650517463684
train-epoch-step: 3-284 -- Loss: 0.24148443341255188
train-epoch-step: 3-285 -- Loss: 0.27070730924606323
train-epoch-step: 3-286 -- Loss: 0.21387667953968048
train-epoch-step: 3-287 -- Loss: 0.2870035469532013
train-epoch-step: 3-288 -- Loss: 0.1342860609292984
train-epoch-step: 3-289 -- Loss: 0.1691029965877533
train-epoch-step: 3-290 -- Loss: 0.24434131383895874
train-epoch-step: 3-291 -- Loss: 0.16563157737255096
train-epoch-step: 3-292 -- Loss: 0.2055024951696396
train-epoch-step: 3-293 -- Loss: 0.19896292686462402
train-epoch-step: 3-294 -- Loss: 0.23900488018989563
train-epoch-step: 3-295 -- Loss: 0.4037330448627472
train-epoch-step: 3-296 -- Loss: 0.2408038079738617
train-epoch-step: 3-297 -- Loss: 0.24110989272594452
train-epoch-step: 3-298 -- Loss: 0.33012571930885315
train-epoch-step: 3-299 -- Loss: 0.2303798943758011
train-epoch-step: 3-300 -- Loss: 0.23686493933200836
train-epoch-step: 3-301 -- Loss: 0.22903631627559662
train-epoch-step: 3-302 -- Loss: 0.30784285068511963
train-epoch-step: 3-303 -- Loss: 0.281477689743042
train-epoch-step: 3-304 -- Loss: 0.19564467668533325
train-epoch-step: 3-305 -- Loss: 0.20402412116527557
train-epoch-step: 3-306 -- Loss: 0.33035987615585327
train-epoch-step: 3-307 -- Loss: 0.23762020468711853
train-epoch-step: 3-308 -- Loss: 0.3434089422225952
train-epoch-step: 3-309 -- Loss: 0.2141646295785904
train-epoch-step: 3-310 -- Loss: 0.21478280425071716
train-epoch-step: 3-311 -- Loss: 0.22603096067905426
train-epoch-step: 3-312 -- Loss: 0.2923703193664551
train-epoch-step: 3-313 -- Loss: 0.13315187394618988
train-epoch-step: 3-314 -- Loss: 0.2700510025024414
train-epoch-step: 3-315 -- Loss: 0.23397332429885864
train-epoch-step: 3-316 -- Loss: 0.21228405833244324
train-epoch-step: 3-317 -- Loss: 0.18553005158901215
train-epoch-step: 3-318 -- Loss: 0.22903907299041748
train-epoch-step: 3-319 -- Loss: 0.24706530570983887
train-epoch-step: 3-320 -- Loss: 0.16382364928722382
train-epoch-step: 3-321 -- Loss: 0.1934461146593094
train-epoch-step: 3-322 -- Loss: 0.29183340072631836
train-epoch-step: 3-323 -- Loss: 0.2121170461177826
train-epoch-step: 3-324 -- Loss: 0.37678056955337524
train-epoch-step: 3-325 -- Loss: 0.2172567993402481
train-epoch-step: 3-326 -- Loss: 0.2557034194469452
train-epoch-step: 3-327 -- Loss: 0.2780371308326721
train-epoch-step: 3-328 -- Loss: 0.2754589915275574
train-epoch-step: 3-329 -- Loss: 0.45269232988357544
train-epoch-step: 3-330 -- Loss: 0.5058003664016724
train-epoch-step: 3-331 -- Loss: 0.3093894422054291
train-epoch-step: 3-332 -- Loss: 0.1428554356098175
train-epoch-step: 3-333 -- Loss: 0.25752848386764526
train-epoch-step: 3-334 -- Loss: 0.21533775329589844
train-epoch-step: 3-335 -- Loss: 0.23939268290996552
train-epoch-step: 3-336 -- Loss: 0.23279942572116852
train-epoch-step: 3-337 -- Loss: 0.28767985105514526
train-epoch-step: 3-338 -- Loss: 0.22792686522006989
train-epoch-step: 3-339 -- Loss: 0.2008540779352188
train-epoch-step: 3-340 -- Loss: 0.28762754797935486
train-epoch-step: 3-341 -- Loss: 0.18448495864868164
train-epoch-step: 3-342 -- Loss: 0.21945306658744812
train-epoch-step: 3-343 -- Loss: 0.21436065435409546
train-epoch-step: 3-344 -- Loss: 0.23465043306350708
train-epoch-step: 3-345 -- Loss: 0.17905625700950623
train-epoch-step: 3-346 -- Loss: 0.2647574543952942
train-epoch-step: 3-347 -- Loss: 0.23325106501579285
train-epoch-step: 3-348 -- Loss: 0.283012717962265
train-epoch-step: 3-349 -- Loss: 0.3058585524559021
train-epoch-step: 3-350 -- Loss: 0.37587082386016846
train-epoch-step: 3-351 -- Loss: 0.28385353088378906
train-epoch-step: 3-352 -- Loss: 0.1961413025856018
train-epoch-step: 3-353 -- Loss: 0.2731614112854004
train-epoch-step: 3-354 -- Loss: 0.3733797073364258
train-epoch-step: 3-355 -- Loss: 0.16128234565258026
train-epoch-step: 3-356 -- Loss: 0.16025689244270325
train-epoch-step: 3-357 -- Loss: 0.25313740968704224
train-epoch-step: 3-358 -- Loss: 0.24509219825267792
train-epoch-step: 3-359 -- Loss: 0.19268620014190674
train-epoch-step: 3-360 -- Loss: 0.18048778176307678
train-epoch-step: 3-361 -- Loss: 0.3654435873031616
train-epoch-step: 3-362 -- Loss: 0.23083320260047913
train-epoch-step: 3-363 -- Loss: 0.15583327412605286
train-epoch-step: 3-364 -- Loss: 0.24112766981124878
train-epoch-step: 3-365 -- Loss: 0.225211501121521
train-epoch-step: 3-366 -- Loss: 0.26336920261383057
train-epoch-step: 3-367 -- Loss: 0.3886159658432007
train-epoch-step: 3-368 -- Loss: 0.29066795110702515
train-epoch-step: 3-369 -- Loss: 0.37772607803344727
train-epoch-step: 3-370 -- Loss: 0.18863749504089355
train-epoch-step: 3-371 -- Loss: 0.16724619269371033
train-epoch-step: 3-372 -- Loss: 0.19319391250610352
train-epoch-step: 3-373 -- Loss: 0.2621358335018158
train-epoch-step: 3-374 -- Loss: 0.21516749262809753
train-epoch-step: 3-375 -- Loss: 0.40334558486938477
train-epoch-step: 3-376 -- Loss: 0.27796614170074463
train-epoch-step: 3-377 -- Loss: 0.34053561091423035
train-epoch-step: 3-378 -- Loss: 0.2858758270740509
train-epoch-step: 3-379 -- Loss: 0.1508398950099945
train-epoch-step: 3-380 -- Loss: 0.1463015377521515
train-epoch-step: 3-381 -- Loss: 0.3390381336212158
train-epoch-step: 3-382 -- Loss: 0.3519270420074463
train-epoch-step: 3-383 -- Loss: 0.2869381308555603
train-epoch-step: 3-384 -- Loss: 0.3019140660762787
train-epoch-step: 3-385 -- Loss: 0.2683240473270416
train-epoch-step: 3-386 -- Loss: 0.3220862150192261
train-epoch-step: 3-387 -- Loss: 0.2874525189399719
train-epoch-step: 3-388 -- Loss: 0.2908638119697571
train-epoch-step: 3-389 -- Loss: 0.25686943531036377
train-epoch-step: 3-390 -- Loss: 0.2005765289068222
train-epoch-step: 3-391 -- Loss: 0.20914044976234436
train-epoch-step: 3-392 -- Loss: 0.2507253587245941
train-epoch-step: 3-393 -- Loss: 0.20606327056884766
train-epoch-step: 3-394 -- Loss: 0.30812740325927734
train-epoch-step: 3-395 -- Loss: 0.21280907094478607
train-epoch-step: 3-396 -- Loss: 0.1815480887889862
train-epoch-step: 3-397 -- Loss: 0.1701349914073944
train-epoch-step: 3-398 -- Loss: 0.2630258798599243
train-epoch-step: 3-399 -- Loss: 0.28113001585006714
train-epoch-step: 3-400 -- Loss: 0.39503568410873413
train-epoch-step: 3-401 -- Loss: 0.1583845615386963
train-epoch-step: 3-402 -- Loss: 0.3541281521320343
train-epoch-step: 3-403 -- Loss: 0.23195931315422058
train-epoch-step: 3-404 -- Loss: 0.1991291344165802
train-epoch-step: 3-405 -- Loss: 0.1992982178926468
train-epoch-step: 3-406 -- Loss: 0.21610434353351593
train-epoch-step: 3-407 -- Loss: 0.1609565168619156
train-epoch-step: 3-408 -- Loss: 0.21565952897071838
train-epoch-step: 3-409 -- Loss: 0.24335625767707825
train-epoch-step: 3-410 -- Loss: 0.26187241077423096
train-epoch-step: 3-411 -- Loss: 0.26783257722854614
train-epoch-step: 3-412 -- Loss: 0.1725279688835144
train-epoch-step: 3-413 -- Loss: 0.19695299863815308
train-epoch-step: 3-414 -- Loss: 0.1907205730676651
train-epoch-step: 3-415 -- Loss: 0.18291717767715454
train-epoch-step: 3-416 -- Loss: 0.38909971714019775
train-epoch-step: 3-417 -- Loss: 0.2826540470123291
train-epoch-step: 3-418 -- Loss: 0.3429287075996399
train-epoch-step: 3-419 -- Loss: 0.2363632619380951
train-epoch-step: 3-420 -- Loss: 0.20505303144454956
train-epoch-step: 3-421 -- Loss: 0.24159032106399536
train-epoch-step: 3-422 -- Loss: 0.21098214387893677
train-epoch-step: 3-423 -- Loss: 0.2377721071243286
train-epoch-step: 3-424 -- Loss: 0.18779629468917847
train-epoch-step: 3-425 -- Loss: 0.2520471513271332
train-epoch-step: 3-426 -- Loss: 0.22607257962226868
train-epoch-step: 3-427 -- Loss: 0.18149229884147644
train-epoch-step: 3-428 -- Loss: 0.283067911863327
train-epoch-step: 3-429 -- Loss: 0.26174476742744446
train-epoch-step: 3-430 -- Loss: 0.18772009015083313
train-epoch-step: 3-431 -- Loss: 0.23319439589977264
train-epoch-step: 3-432 -- Loss: 0.3431175649166107
train-epoch-step: 3-433 -- Loss: 0.2055116593837738
train-epoch-step: 3-434 -- Loss: 0.1985548585653305
train-epoch-step: 3-435 -- Loss: 0.226729154586792
train-epoch-step: 3-436 -- Loss: 0.20576629042625427
train-epoch-step: 3-437 -- Loss: 0.17954015731811523
train-epoch-step: 3-438 -- Loss: 0.2384261190891266
train-epoch-step: 3-439 -- Loss: 0.40361833572387695
train-epoch-step: 3-440 -- Loss: 0.19655293226242065
train-epoch-step: 3-441 -- Loss: 0.31693869829177856
train-epoch-step: 3-442 -- Loss: 0.26646727323532104
train-epoch-step: 3-443 -- Loss: 0.21584098041057587
train-epoch-step: 3-444 -- Loss: 0.3198101222515106
train-epoch-step: 3-445 -- Loss: 0.2553946077823639
train-epoch-step: 3-446 -- Loss: 0.2127726674079895
train-epoch-step: 3-447 -- Loss: 0.28450876474380493
train-epoch-step: 3-448 -- Loss: 0.33997926115989685
train-epoch-step: 3-449 -- Loss: 0.25960657000541687
train-epoch-step: 3-450 -- Loss: 0.25787925720214844
train-epoch-step: 3-451 -- Loss: 0.1889767050743103
train-epoch-step: 3-452 -- Loss: 0.18432939052581787
train-epoch-step: 3-453 -- Loss: 0.1316884160041809
train-epoch-step: 3-454 -- Loss: 0.3340274691581726
train-epoch-step: 3-455 -- Loss: 0.1932956576347351
train-epoch-step: 3-456 -- Loss: 0.16547568142414093
train-epoch-step: 3-457 -- Loss: 0.2910483479499817
train-epoch-step: 3-458 -- Loss: 0.2361031174659729
train-epoch-step: 3-459 -- Loss: 0.30989086627960205
train-epoch-step: 3-460 -- Loss: 0.16575023531913757
train-epoch-step: 3-461 -- Loss: 0.2012222409248352
train-epoch-step: 3-462 -- Loss: 0.21101529896259308
train-epoch-step: 3-463 -- Loss: 0.19103264808654785
train-epoch-step: 3-464 -- Loss: 0.263408899307251
train-epoch-step: 3-465 -- Loss: 0.38652366399765015
train-epoch-step: 3-466 -- Loss: 0.271274596452713
train-epoch-step: 3-467 -- Loss: 0.1549888700246811
train-epoch-step: 3-468 -- Loss: 0.27166613936424255
train-epoch-step: 3-469 -- Loss: 0.3590579032897949
train-epoch-step: 3-470 -- Loss: 0.24377860128879547
train-epoch-step: 3-471 -- Loss: 0.21438902616500854
train-epoch-step: 3-472 -- Loss: 0.21372568607330322
train-epoch-step: 3-473 -- Loss: 0.22572587430477142
train-epoch-step: 3-474 -- Loss: 0.16241148114204407
train-epoch-step: 3-475 -- Loss: 0.1504138708114624
train-epoch-step: 3-476 -- Loss: 0.2669064700603485
train-epoch-step: 3-477 -- Loss: 0.30243462324142456
train-epoch-step: 3-478 -- Loss: 0.25122737884521484
train-epoch-step: 3-479 -- Loss: 0.19143915176391602
train-epoch-step: 3-480 -- Loss: 0.3063982129096985
train-epoch-step: 3-481 -- Loss: 0.37721145153045654
train-epoch-step: 3-482 -- Loss: 0.32850024104118347
train-epoch-step: 3-483 -- Loss: 0.2762884497642517
train-epoch-step: 3-484 -- Loss: 0.27190178632736206
train-epoch-step: 3-485 -- Loss: 0.18295589089393616
train-epoch-step: 3-486 -- Loss: 0.37435758113861084
train-epoch-step: 3-487 -- Loss: 0.31002843379974365
train-epoch-step: 3-488 -- Loss: 0.2584870457649231
train-epoch-step: 3-489 -- Loss: 0.2900603115558624
train-epoch-step: 3-490 -- Loss: 0.19456090033054352
train-epoch-step: 3-491 -- Loss: 0.1868438869714737
train-epoch-step: 3-492 -- Loss: 0.16669784486293793
train-epoch-step: 3-493 -- Loss: 0.29518648982048035
train-epoch-step: 3-494 -- Loss: 0.2824024558067322
train-epoch-step: 3-495 -- Loss: 0.2908172607421875
train-epoch-step: 3-496 -- Loss: 0.18459263443946838
train-epoch-step: 3-497 -- Loss: 0.283386766910553
train-epoch-step: 3-498 -- Loss: 0.19754600524902344
train-epoch-step: 3-499 -- Loss: 0.23302508890628815
train-epoch-step: 3-500 -- Loss: 0.21680612862110138
train-epoch-step: 3-501 -- Loss: 0.29707399010658264
train-epoch-step: 3-502 -- Loss: 0.24192549288272858
train-epoch-step: 3-503 -- Loss: 0.3014138340950012
train-epoch-step: 3-504 -- Loss: 0.15499098598957062
train-epoch-step: 3-505 -- Loss: 0.24298325181007385
train-epoch-step: 3-506 -- Loss: 0.16223788261413574
train-epoch-step: 3-507 -- Loss: 0.2543841600418091
train-epoch-step: 3-508 -- Loss: 0.23572935163974762
train-epoch-step: 3-509 -- Loss: 0.22999252378940582
train-epoch-step: 3-510 -- Loss: 0.20141887664794922
train-epoch-step: 3-511 -- Loss: 0.2910694479942322
train-epoch-step: 3-512 -- Loss: 0.2765037715435028
train-epoch-step: 3-513 -- Loss: 0.2763528525829315
train-epoch-step: 3-514 -- Loss: 0.20227310061454773
train-epoch-step: 3-515 -- Loss: 0.2300366461277008
train-epoch-step: 3-516 -- Loss: 0.2283879518508911
train-epoch-step: 3-517 -- Loss: 0.2592387795448303
train-epoch-step: 3-518 -- Loss: 0.19858992099761963
train-epoch-step: 3-519 -- Loss: 0.1889934241771698
train-epoch-step: 3-520 -- Loss: 0.2611692547798157
train-epoch-step: 3-521 -- Loss: 0.30750370025634766
train-epoch-step: 3-522 -- Loss: 0.27628618478775024
train-epoch-step: 3-523 -- Loss: 0.2222190499305725
train-epoch-step: 3-524 -- Loss: 0.22747689485549927
train-epoch-step: 3-525 -- Loss: 0.2597419321537018
train-epoch-step: 3-526 -- Loss: 0.17198507487773895
train-epoch-step: 3-527 -- Loss: 0.24414536356925964
train-epoch-step: 3-528 -- Loss: 0.2292194664478302
train-epoch-step: 3-529 -- Loss: 0.24255093932151794
train-epoch-step: 3-530 -- Loss: 0.24419334530830383
train-epoch-step: 3-531 -- Loss: 0.27953460812568665
train-epoch-step: 3-532 -- Loss: 0.23727938532829285
train-epoch-step: 3-533 -- Loss: 0.2329796850681305
train-epoch-step: 3-534 -- Loss: 0.17837631702423096
train-epoch-step: 3-535 -- Loss: 0.4101153016090393
train-epoch-step: 3-536 -- Loss: 0.2126496434211731
train-epoch-step: 3-537 -- Loss: 0.2048693150281906
train-epoch-step: 3-538 -- Loss: 0.14197787642478943
train-epoch-step: 3-539 -- Loss: 0.2716716527938843
train-epoch-step: 3-540 -- Loss: 0.1793219894170761
train-epoch-step: 3-541 -- Loss: 0.3004610538482666
train-epoch-step: 3-542 -- Loss: 0.31943273544311523
train-epoch-step: 3-543 -- Loss: 0.22369584441184998
train-epoch-step: 3-544 -- Loss: 0.2868834137916565
train-epoch-step: 3-545 -- Loss: 0.2648068964481354
train-epoch-step: 3-546 -- Loss: 0.3292652368545532
train-epoch-step: 3-547 -- Loss: 0.23005113005638123
train-epoch-step: 3-548 -- Loss: 0.12398393452167511
train-epoch-step: 3-549 -- Loss: 0.21586064994335175
train-epoch-step: 3-550 -- Loss: 0.2685622572898865
train-epoch-step: 3-551 -- Loss: 0.2215961515903473
train-epoch-step: 3-552 -- Loss: 0.17124149203300476
train-epoch-step: 3-553 -- Loss: 0.26543760299682617
train-epoch-step: 3-554 -- Loss: 0.24925978481769562
train-epoch-step: 3-555 -- Loss: 0.3399127721786499
train-epoch-step: 3-556 -- Loss: 0.23363202810287476
train-epoch-step: 3-557 -- Loss: 0.33151501417160034
train-epoch-step: 3-558 -- Loss: 0.34367305040359497
train-epoch-step: 3-559 -- Loss: 0.2017516791820526
train-epoch-step: 3-560 -- Loss: 0.2710408568382263
train-epoch-step: 3-561 -- Loss: 0.2713712751865387
train-epoch-step: 3-562 -- Loss: 0.2682139277458191
train-epoch-step: 3-563 -- Loss: 0.2566910982131958
train-epoch-step: 3-564 -- Loss: 0.14384421706199646
train-epoch-step: 3-565 -- Loss: 0.24507935345172882
train-epoch-step: 3-566 -- Loss: 0.22141656279563904
train-epoch-step: 3-567 -- Loss: 0.27329209446907043
train-epoch-step: 3-568 -- Loss: 0.2109525501728058
train-epoch-step: 3-569 -- Loss: 0.3035823702812195
train-epoch-step: 3-570 -- Loss: 0.23117013275623322
train-epoch-step: 3-571 -- Loss: 0.282748818397522
train-epoch-step: 3-572 -- Loss: 0.3263571858406067
train-epoch-step: 3-573 -- Loss: 0.28536489605903625
train-epoch-step: 3-574 -- Loss: 0.34936195611953735
train-epoch-step: 3-575 -- Loss: 0.433699369430542
train-epoch-step: 3-576 -- Loss: 0.16813579201698303
train-epoch-step: 3-577 -- Loss: 0.22317372262477875
train-epoch-step: 3-578 -- Loss: 0.3075215816497803
train-epoch-step: 3-579 -- Loss: 0.22592179477214813
train-epoch-step: 3-580 -- Loss: 0.26344603300094604
train-epoch-step: 3-581 -- Loss: 0.1853879988193512
train-epoch-step: 3-582 -- Loss: 0.29766973853111267
train-epoch-step: 3-583 -- Loss: 0.30874523520469666
train-epoch-step: 3-584 -- Loss: 0.2636526823043823
train-epoch-step: 3-585 -- Loss: 0.2535993456840515
train-epoch-step: 3-586 -- Loss: 0.3649093508720398
train-epoch-step: 3-587 -- Loss: 0.2243330180644989
train-epoch-step: 3-588 -- Loss: 0.17647415399551392
val-epoch-step: 3-589 -- Loss: 0.30940163135528564
val-epoch-step: 3-590 -- Loss: 0.19412708282470703
val-epoch-step: 3-591 -- Loss: 0.2781890630722046
val-epoch-step: 3-592 -- Loss: 0.2304140329360962
val-epoch-step: 3-593 -- Loss: 0.1894899606704712
val-epoch-step: 3-594 -- Loss: 0.4119759500026703
val-epoch-step: 3-595 -- Loss: 0.23164355754852295
val-epoch-step: 3-596 -- Loss: 0.273068368434906
val-epoch-step: 3-597 -- Loss: 0.24457906186580658
val-epoch-step: 3-598 -- Loss: 0.20433031022548676
val-epoch-step: 3-599 -- Loss: 0.23860663175582886
val-epoch-step: 3-600 -- Loss: 0.23617330193519592
val-epoch-step: 3-601 -- Loss: 0.19165241718292236
val-epoch-step: 3-602 -- Loss: 0.19113919138908386
val-epoch-step: 3-603 -- Loss: 0.27080023288726807
val-epoch-step: 3-604 -- Loss: 0.18305841088294983
val-epoch-step: 3-605 -- Loss: 0.19539755582809448
val-epoch-step: 3-606 -- Loss: 0.3741855025291443
val-epoch-step: 3-607 -- Loss: 0.1905922144651413
val-epoch-step: 3-608 -- Loss: 0.3173564076423645
val-epoch-step: 3-609 -- Loss: 0.23746678233146667
val-epoch-step: 3-610 -- Loss: 0.26520922780036926
val-epoch-step: 3-611 -- Loss: 0.21303845942020416
val-epoch-step: 3-612 -- Loss: 0.38772955536842346
val-epoch-step: 3-613 -- Loss: 0.237594872713089
val-epoch-step: 3-614 -- Loss: 0.2028789520263672
val-epoch-step: 3-615 -- Loss: 0.2516736388206482
val-epoch-step: 3-616 -- Loss: 0.1870235651731491
val-epoch-step: 3-617 -- Loss: 0.2694876492023468
val-epoch-step: 3-618 -- Loss: 0.2574109137058258
val-epoch-step: 3-619 -- Loss: 0.28319603204727173
val-epoch-step: 3-620 -- Loss: 0.18799078464508057
val-epoch-step: 3-621 -- Loss: 0.18351492285728455
val-epoch-step: 3-622 -- Loss: 0.19110457599163055
val-epoch-step: 3-623 -- Loss: 0.19874393939971924
val-epoch-step: 3-624 -- Loss: 0.2212757170200348
val-epoch-step: 3-625 -- Loss: 0.20073944330215454
val-epoch-step: 3-626 -- Loss: 0.20561100542545319
val-epoch-step: 3-627 -- Loss: 0.257143497467041
val-epoch-step: 3-628 -- Loss: 0.4854319989681244
val-epoch-step: 3-629 -- Loss: 0.26966190338134766
val-epoch-step: 3-630 -- Loss: 0.43365538120269775
val-epoch-step: 3-631 -- Loss: 0.19345149397850037
val-epoch-step: 3-632 -- Loss: 0.24847091734409332
val-epoch-step: 3-633 -- Loss: 0.20117005705833435
val-epoch-step: 3-634 -- Loss: 0.18533483147621155
val-epoch-step: 3-635 -- Loss: 0.1463737040758133
val-epoch-step: 3-636 -- Loss: 0.21622441709041595
val-epoch-step: 3-637 -- Loss: 0.24441863596439362
val-epoch-step: 3-638 -- Loss: 0.20604053139686584
val-epoch-step: 3-639 -- Loss: 0.32997891306877136
val-epoch-step: 3-640 -- Loss: 0.32085445523262024
val-epoch-step: 3-641 -- Loss: 0.16434255242347717
val-epoch-step: 3-642 -- Loss: 0.2666488289833069
val-epoch-step: 3-643 -- Loss: 0.2568581700325012
val-epoch-step: 3-644 -- Loss: 0.2209128588438034
val-epoch-step: 3-645 -- Loss: 0.29082560539245605
val-epoch-step: 3-646 -- Loss: 0.19861085712909698
val-epoch-step: 3-647 -- Loss: 0.17564111948013306
val-epoch-step: 3-648 -- Loss: 0.2162320464849472
val-epoch-step: 3-649 -- Loss: 0.338811457157135
val-epoch-step: 3-650 -- Loss: 0.32848021388053894
val-epoch-step: 3-651 -- Loss: 0.18110136687755585
val-epoch-step: 3-652 -- Loss: 0.20324546098709106
val-epoch-step: 3-653 -- Loss: 0.2559913992881775
val-epoch-step: 3-654 -- Loss: 0.14854349195957184
Epoch: 3 -- Train Loss: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 4-0 -- Loss: 0.29597198963165283
train-epoch-step: 4-1 -- Loss: 0.18879875540733337
train-epoch-step: 4-2 -- Loss: 0.2620713710784912
train-epoch-step: 4-3 -- Loss: 0.19614946842193604
train-epoch-step: 4-4 -- Loss: 0.25703728199005127
train-epoch-step: 4-5 -- Loss: 0.25806179642677307
train-epoch-step: 4-6 -- Loss: 0.3555459976196289
train-epoch-step: 4-7 -- Loss: 0.23033469915390015
train-epoch-step: 4-8 -- Loss: 0.2532547414302826
train-epoch-step: 4-9 -- Loss: 0.35839951038360596
train-epoch-step: 4-10 -- Loss: 0.3434712588787079
train-epoch-step: 4-11 -- Loss: 0.2373443990945816
train-epoch-step: 4-12 -- Loss: 0.20491047203540802
train-epoch-step: 4-13 -- Loss: 0.2548459768295288
train-epoch-step: 4-14 -- Loss: 0.20700927078723907
train-epoch-step: 4-15 -- Loss: 0.2129378467798233
train-epoch-step: 4-16 -- Loss: 0.23299849033355713
train-epoch-step: 4-17 -- Loss: 0.2882031202316284
train-epoch-step: 4-18 -- Loss: 0.24703200161457062
train-epoch-step: 4-19 -- Loss: 0.17904677987098694
train-epoch-step: 4-20 -- Loss: 0.29706957936286926
train-epoch-step: 4-21 -- Loss: 0.39163756370544434
train-epoch-step: 4-22 -- Loss: 0.20348580181598663
train-epoch-step: 4-23 -- Loss: 0.24872758984565735
train-epoch-step: 4-24 -- Loss: 0.17790521681308746
train-epoch-step: 4-25 -- Loss: 0.29835402965545654
train-epoch-step: 4-26 -- Loss: 0.26691707968711853
train-epoch-step: 4-27 -- Loss: 0.3828556537628174
train-epoch-step: 4-28 -- Loss: 0.16791731119155884
train-epoch-step: 4-29 -- Loss: 0.31151044368743896
train-epoch-step: 4-30 -- Loss: 0.14455737173557281
train-epoch-step: 4-31 -- Loss: 0.19502317905426025
train-epoch-step: 4-32 -- Loss: 0.2318345606327057
train-epoch-step: 4-33 -- Loss: 0.350231409072876
train-epoch-step: 4-34 -- Loss: 0.229880690574646
train-epoch-step: 4-35 -- Loss: 0.31940215826034546
train-epoch-step: 4-36 -- Loss: 0.198716402053833
train-epoch-step: 4-37 -- Loss: 0.19633089005947113
train-epoch-step: 4-38 -- Loss: 0.25906240940093994
train-epoch-step: 4-39 -- Loss: 0.3185803294181824
train-epoch-step: 4-40 -- Loss: 0.2716182470321655
train-epoch-step: 4-41 -- Loss: 0.2796735167503357
train-epoch-step: 4-42 -- Loss: 0.20003995299339294
train-epoch-step: 4-43 -- Loss: 0.38073593378067017
train-epoch-step: 4-44 -- Loss: 0.17531275749206543
train-epoch-step: 4-45 -- Loss: 0.17221221327781677
train-epoch-step: 4-46 -- Loss: 0.2285347282886505
train-epoch-step: 4-47 -- Loss: 0.30037033557891846
train-epoch-step: 4-48 -- Loss: 0.20096592605113983
train-epoch-step: 4-49 -- Loss: 0.28233039379119873
train-epoch-step: 4-50 -- Loss: 0.16062572598457336
train-epoch-step: 4-51 -- Loss: 0.25485730171203613
train-epoch-step: 4-52 -- Loss: 0.20511016249656677
train-epoch-step: 4-53 -- Loss: 0.3038659393787384
train-epoch-step: 4-54 -- Loss: 0.380685031414032
train-epoch-step: 4-55 -- Loss: 0.2274114340543747
train-epoch-step: 4-56 -- Loss: 0.2648470103740692
train-epoch-step: 4-57 -- Loss: 0.3097197115421295
train-epoch-step: 4-58 -- Loss: 0.36048465967178345
train-epoch-step: 4-59 -- Loss: 0.3450363874435425
train-epoch-step: 4-60 -- Loss: 0.18516778945922852
train-epoch-step: 4-61 -- Loss: 0.3103112578392029
train-epoch-step: 4-62 -- Loss: 0.2535060942173004
train-epoch-step: 4-63 -- Loss: 0.18772214651107788
train-epoch-step: 4-64 -- Loss: 0.21903738379478455
train-epoch-step: 4-65 -- Loss: 0.25631511211395264
train-epoch-step: 4-66 -- Loss: 0.14343173801898956
train-epoch-step: 4-67 -- Loss: 0.16696934401988983
train-epoch-step: 4-68 -- Loss: 0.32824426889419556
train-epoch-step: 4-69 -- Loss: 0.18582895398139954
train-epoch-step: 4-70 -- Loss: 0.3030394911766052
train-epoch-step: 4-71 -- Loss: 0.3393481373786926
train-epoch-step: 4-72 -- Loss: 0.23834894597530365
train-epoch-step: 4-73 -- Loss: 0.28235602378845215
train-epoch-step: 4-74 -- Loss: 0.13013955950737
train-epoch-step: 4-75 -- Loss: 0.18802186846733093
train-epoch-step: 4-76 -- Loss: 0.19217437505722046
train-epoch-step: 4-77 -- Loss: 0.30045565962791443
train-epoch-step: 4-78 -- Loss: 0.40738046169281006
train-epoch-step: 4-79 -- Loss: 0.26487985253334045
train-epoch-step: 4-80 -- Loss: 0.40836912393569946
train-epoch-step: 4-81 -- Loss: 0.18959340453147888
train-epoch-step: 4-82 -- Loss: 0.3237931728363037
train-epoch-step: 4-83 -- Loss: 0.25553035736083984
train-epoch-step: 4-84 -- Loss: 0.2820202112197876
train-epoch-step: 4-85 -- Loss: 0.24581554532051086
train-epoch-step: 4-86 -- Loss: 0.1715594381093979
train-epoch-step: 4-87 -- Loss: 0.3082225024700165
train-epoch-step: 4-88 -- Loss: 0.1922846883535385
train-epoch-step: 4-89 -- Loss: 0.25790828466415405
train-epoch-step: 4-90 -- Loss: 0.2595813572406769
train-epoch-step: 4-91 -- Loss: 0.32924893498420715
train-epoch-step: 4-92 -- Loss: 0.2214180827140808
train-epoch-step: 4-93 -- Loss: 0.2538706064224243
train-epoch-step: 4-94 -- Loss: 0.33283358812332153
train-epoch-step: 4-95 -- Loss: 0.26241010427474976
train-epoch-step: 4-96 -- Loss: 0.3013342320919037
train-epoch-step: 4-97 -- Loss: 0.2565419673919678
train-epoch-step: 4-98 -- Loss: 0.22307440638542175
train-epoch-step: 4-99 -- Loss: 0.24222615361213684
train-epoch-step: 4-100 -- Loss: 0.2542378008365631
train-epoch-step: 4-101 -- Loss: 0.34572991728782654
train-epoch-step: 4-102 -- Loss: 0.34013843536376953
train-epoch-step: 4-103 -- Loss: 0.28477251529693604
train-epoch-step: 4-104 -- Loss: 0.2083895206451416
train-epoch-step: 4-105 -- Loss: 0.4349866807460785
train-epoch-step: 4-106 -- Loss: 0.24531018733978271
train-epoch-step: 4-107 -- Loss: 0.2812889814376831
train-epoch-step: 4-108 -- Loss: 0.24642795324325562
train-epoch-step: 4-109 -- Loss: 0.2114802598953247
train-epoch-step: 4-110 -- Loss: 0.2512613534927368
train-epoch-step: 4-111 -- Loss: 0.24370893836021423
train-epoch-step: 4-112 -- Loss: 0.22050505876541138
train-epoch-step: 4-113 -- Loss: 0.2534187436103821
train-epoch-step: 4-114 -- Loss: 0.30659013986587524
train-epoch-step: 4-115 -- Loss: 0.21955326199531555
train-epoch-step: 4-116 -- Loss: 0.20192503929138184
train-epoch-step: 4-117 -- Loss: 0.17419004440307617
train-epoch-step: 4-118 -- Loss: 0.26996082067489624
train-epoch-step: 4-119 -- Loss: 0.19895225763320923
train-epoch-step: 4-120 -- Loss: 0.354790598154068
train-epoch-step: 4-121 -- Loss: 0.35029304027557373
train-epoch-step: 4-122 -- Loss: 0.2995489835739136
train-epoch-step: 4-123 -- Loss: 0.2839571237564087
train-epoch-step: 4-124 -- Loss: 0.1645132601261139
train-epoch-step: 4-125 -- Loss: 0.2044774740934372
train-epoch-step: 4-126 -- Loss: 0.3214550018310547
train-epoch-step: 4-127 -- Loss: 0.22855716943740845
train-epoch-step: 4-128 -- Loss: 0.24023818969726562
train-epoch-step: 4-129 -- Loss: 0.18934497237205505
train-epoch-step: 4-130 -- Loss: 0.24547894299030304
train-epoch-step: 4-131 -- Loss: 0.18084247410297394
train-epoch-step: 4-132 -- Loss: 0.2632478177547455
train-epoch-step: 4-133 -- Loss: 0.15401840209960938
train-epoch-step: 4-134 -- Loss: 0.2699747681617737
train-epoch-step: 4-135 -- Loss: 0.1763056218624115
train-epoch-step: 4-136 -- Loss: 0.16495487093925476
train-epoch-step: 4-137 -- Loss: 0.34191301465034485
train-epoch-step: 4-138 -- Loss: 0.36973845958709717
train-epoch-step: 4-139 -- Loss: 0.1772841364145279
train-epoch-step: 4-140 -- Loss: 0.2851031422615051
train-epoch-step: 4-141 -- Loss: 0.3195626139640808
train-epoch-step: 4-142 -- Loss: 0.2666916847229004
train-epoch-step: 4-143 -- Loss: 0.2371111959218979
train-epoch-step: 4-144 -- Loss: 0.2659764289855957
train-epoch-step: 4-145 -- Loss: 0.18364739418029785
train-epoch-step: 4-146 -- Loss: 0.23682162165641785
train-epoch-step: 4-147 -- Loss: 0.24298247694969177
train-epoch-step: 4-148 -- Loss: 0.23712597787380219
train-epoch-step: 4-149 -- Loss: 0.15331757068634033
train-epoch-step: 4-150 -- Loss: 0.25213342905044556
train-epoch-step: 4-151 -- Loss: 0.25378620624542236
train-epoch-step: 4-152 -- Loss: 0.25651222467422485
train-epoch-step: 4-153 -- Loss: 0.41096407175064087
train-epoch-step: 4-154 -- Loss: 0.18543821573257446
train-epoch-step: 4-155 -- Loss: 0.19094815850257874
train-epoch-step: 4-156 -- Loss: 0.16606725752353668
train-epoch-step: 4-157 -- Loss: 0.22436746954917908
train-epoch-step: 4-158 -- Loss: 0.23215344548225403
train-epoch-step: 4-159 -- Loss: 0.22867169976234436
train-epoch-step: 4-160 -- Loss: 0.28754591941833496
train-epoch-step: 4-161 -- Loss: 0.2862674593925476
train-epoch-step: 4-162 -- Loss: 0.2795182764530182
train-epoch-step: 4-163 -- Loss: 0.26051416993141174
train-epoch-step: 4-164 -- Loss: 0.24422231316566467
train-epoch-step: 4-165 -- Loss: 0.2159348726272583
train-epoch-step: 4-166 -- Loss: 0.16655726730823517
train-epoch-step: 4-167 -- Loss: 0.16275599598884583
train-epoch-step: 4-168 -- Loss: 0.2781243622303009
train-epoch-step: 4-169 -- Loss: 0.18305113911628723
train-epoch-step: 4-170 -- Loss: 0.28778019547462463
train-epoch-step: 4-171 -- Loss: 0.2029365748167038
train-epoch-step: 4-172 -- Loss: 0.3428317606449127
train-epoch-step: 4-173 -- Loss: 0.17383511364459991
train-epoch-step: 4-174 -- Loss: 0.3118929862976074
train-epoch-step: 4-175 -- Loss: 0.24771523475646973
train-epoch-step: 4-176 -- Loss: 0.17754007875919342
train-epoch-step: 4-177 -- Loss: 0.24480801820755005
train-epoch-step: 4-178 -- Loss: 0.2544083297252655
train-epoch-step: 4-179 -- Loss: 0.1864757537841797
train-epoch-step: 4-180 -- Loss: 0.1916278600692749
train-epoch-step: 4-181 -- Loss: 0.2351720631122589
train-epoch-step: 4-182 -- Loss: 0.2670789659023285
train-epoch-step: 4-183 -- Loss: 0.3895919919013977
train-epoch-step: 4-184 -- Loss: 0.196371927857399
train-epoch-step: 4-185 -- Loss: 0.19546830654144287
train-epoch-step: 4-186 -- Loss: 0.2525795102119446
train-epoch-step: 4-187 -- Loss: 0.296237051486969
train-epoch-step: 4-188 -- Loss: 0.2534047067165375
train-epoch-step: 4-189 -- Loss: 0.1830938309431076
train-epoch-step: 4-190 -- Loss: 0.228547602891922
train-epoch-step: 4-191 -- Loss: 0.24000312387943268
train-epoch-step: 4-192 -- Loss: 0.33630722761154175
train-epoch-step: 4-193 -- Loss: 0.3189690411090851
train-epoch-step: 4-194 -- Loss: 0.24398429691791534
train-epoch-step: 4-195 -- Loss: 0.2190568596124649
train-epoch-step: 4-196 -- Loss: 0.24262237548828125
train-epoch-step: 4-197 -- Loss: 0.1678071916103363
train-epoch-step: 4-198 -- Loss: 0.17654559016227722
train-epoch-step: 4-199 -- Loss: 0.20357942581176758
train-epoch-step: 4-200 -- Loss: 0.16324979066848755
train-epoch-step: 4-201 -- Loss: 0.2623332738876343
train-epoch-step: 4-202 -- Loss: 0.18403594195842743
train-epoch-step: 4-203 -- Loss: 0.23721849918365479
train-epoch-step: 4-204 -- Loss: 0.20226307213306427
train-epoch-step: 4-205 -- Loss: 0.24381324648857117
train-epoch-step: 4-206 -- Loss: 0.27113956212997437
train-epoch-step: 4-207 -- Loss: 0.18162105977535248
train-epoch-step: 4-208 -- Loss: 0.23950491845607758
train-epoch-step: 4-209 -- Loss: 0.18503504991531372
train-epoch-step: 4-210 -- Loss: 0.18407082557678223
train-epoch-step: 4-211 -- Loss: 0.27835819125175476
train-epoch-step: 4-212 -- Loss: 0.2639548182487488
train-epoch-step: 4-213 -- Loss: 0.17737090587615967
train-epoch-step: 4-214 -- Loss: 0.1966245472431183
train-epoch-step: 4-215 -- Loss: 0.18742838501930237
train-epoch-step: 4-216 -- Loss: 0.261737585067749
train-epoch-step: 4-217 -- Loss: 0.2842004895210266
train-epoch-step: 4-218 -- Loss: 0.21082282066345215
train-epoch-step: 4-219 -- Loss: 0.27228641510009766
train-epoch-step: 4-220 -- Loss: 0.17090606689453125
train-epoch-step: 4-221 -- Loss: 0.2755395770072937
train-epoch-step: 4-222 -- Loss: 0.16917729377746582
train-epoch-step: 4-223 -- Loss: 0.22644716501235962
train-epoch-step: 4-224 -- Loss: 0.24186331033706665
train-epoch-step: 4-225 -- Loss: 0.4168475866317749
train-epoch-step: 4-226 -- Loss: 0.29445749521255493
train-epoch-step: 4-227 -- Loss: 0.31473442912101746
train-epoch-step: 4-228 -- Loss: 0.23802700638771057
train-epoch-step: 4-229 -- Loss: 0.25559288263320923
train-epoch-step: 4-230 -- Loss: 0.21656903624534607
train-epoch-step: 4-231 -- Loss: 0.2394738346338272
train-epoch-step: 4-232 -- Loss: 0.26017868518829346
train-epoch-step: 4-233 -- Loss: 0.12036960572004318
train-epoch-step: 4-234 -- Loss: 0.23779922723770142
train-epoch-step: 4-235 -- Loss: 0.21336573362350464
train-epoch-step: 4-236 -- Loss: 0.23990564048290253
train-epoch-step: 4-237 -- Loss: 0.33174681663513184
train-epoch-step: 4-238 -- Loss: 0.2098034918308258
train-epoch-step: 4-239 -- Loss: 0.1809244453907013
train-epoch-step: 4-240 -- Loss: 0.28818604350090027
train-epoch-step: 4-241 -- Loss: 0.21401047706604004
train-epoch-step: 4-242 -- Loss: 0.3014768362045288
train-epoch-step: 4-243 -- Loss: 0.3022027611732483
train-epoch-step: 4-244 -- Loss: 0.27571457624435425
train-epoch-step: 4-245 -- Loss: 0.32106050848960876
train-epoch-step: 4-246 -- Loss: 0.3753441572189331
train-epoch-step: 4-247 -- Loss: 0.3234917223453522
train-epoch-step: 4-248 -- Loss: 0.24007242918014526
train-epoch-step: 4-249 -- Loss: 0.18901070952415466
train-epoch-step: 4-250 -- Loss: 0.2794869840145111
train-epoch-step: 4-251 -- Loss: 0.1549588143825531
train-epoch-step: 4-252 -- Loss: 0.25170841813087463
train-epoch-step: 4-253 -- Loss: 0.17717352509498596
train-epoch-step: 4-254 -- Loss: 0.31624549627304077
train-epoch-step: 4-255 -- Loss: 0.18927261233329773
train-epoch-step: 4-256 -- Loss: 0.20100462436676025
train-epoch-step: 4-257 -- Loss: 0.2486554980278015
train-epoch-step: 4-258 -- Loss: 0.21582476794719696
train-epoch-step: 4-259 -- Loss: 0.1563478708267212
train-epoch-step: 4-260 -- Loss: 0.2785552740097046
train-epoch-step: 4-261 -- Loss: 0.22526530921459198
train-epoch-step: 4-262 -- Loss: 0.41285091638565063
train-epoch-step: 4-263 -- Loss: 0.3030528426170349
train-epoch-step: 4-264 -- Loss: 0.21995477378368378
train-epoch-step: 4-265 -- Loss: 0.1450221836566925
train-epoch-step: 4-266 -- Loss: 0.19891239702701569
train-epoch-step: 4-267 -- Loss: 0.18996146321296692
train-epoch-step: 4-268 -- Loss: 0.15858465433120728
train-epoch-step: 4-269 -- Loss: 0.2279704213142395
train-epoch-step: 4-270 -- Loss: 0.14205436408519745
train-epoch-step: 4-271 -- Loss: 0.20941132307052612
train-epoch-step: 4-272 -- Loss: 0.1596323549747467
train-epoch-step: 4-273 -- Loss: 0.16818049550056458
train-epoch-step: 4-274 -- Loss: 0.2507994771003723
train-epoch-step: 4-275 -- Loss: 0.2731531858444214
train-epoch-step: 4-276 -- Loss: 0.2103494107723236
train-epoch-step: 4-277 -- Loss: 0.20136383175849915
train-epoch-step: 4-278 -- Loss: 0.20223259925842285
train-epoch-step: 4-279 -- Loss: 0.1909472644329071
train-epoch-step: 4-280 -- Loss: 0.27073875069618225
train-epoch-step: 4-281 -- Loss: 0.234572172164917
train-epoch-step: 4-282 -- Loss: 0.1882385015487671
train-epoch-step: 4-283 -- Loss: 0.14647556841373444
train-epoch-step: 4-284 -- Loss: 0.2406328022480011
train-epoch-step: 4-285 -- Loss: 0.2640537917613983
train-epoch-step: 4-286 -- Loss: 0.2076900601387024
train-epoch-step: 4-287 -- Loss: 0.2739185690879822
train-epoch-step: 4-288 -- Loss: 0.1317637711763382
train-epoch-step: 4-289 -- Loss: 0.16370105743408203
train-epoch-step: 4-290 -- Loss: 0.23716525733470917
train-epoch-step: 4-291 -- Loss: 0.15600799024105072
train-epoch-step: 4-292 -- Loss: 0.19792841374874115
train-epoch-step: 4-293 -- Loss: 0.18962998688220978
train-epoch-step: 4-294 -- Loss: 0.22596222162246704
train-epoch-step: 4-295 -- Loss: 0.38084322214126587
train-epoch-step: 4-296 -- Loss: 0.22802646458148956
train-epoch-step: 4-297 -- Loss: 0.23020672798156738
train-epoch-step: 4-298 -- Loss: 0.3173114061355591
train-epoch-step: 4-299 -- Loss: 0.22592280805110931
train-epoch-step: 4-300 -- Loss: 0.23613379895687103
train-epoch-step: 4-301 -- Loss: 0.2234201729297638
train-epoch-step: 4-302 -- Loss: 0.2888370454311371
train-epoch-step: 4-303 -- Loss: 0.2681753933429718
train-epoch-step: 4-304 -- Loss: 0.19084720313549042
train-epoch-step: 4-305 -- Loss: 0.1987680196762085
train-epoch-step: 4-306 -- Loss: 0.3120362162590027
train-epoch-step: 4-307 -- Loss: 0.23152956366539001
train-epoch-step: 4-308 -- Loss: 0.32057851552963257
train-epoch-step: 4-309 -- Loss: 0.2102854698896408
train-epoch-step: 4-310 -- Loss: 0.21034249663352966
train-epoch-step: 4-311 -- Loss: 0.2137715369462967
train-epoch-step: 4-312 -- Loss: 0.2837528586387634
train-epoch-step: 4-313 -- Loss: 0.1299913376569748
train-epoch-step: 4-314 -- Loss: 0.26499128341674805
train-epoch-step: 4-315 -- Loss: 0.21706512570381165
train-epoch-step: 4-316 -- Loss: 0.20781733095645905
train-epoch-step: 4-317 -- Loss: 0.18378451466560364
train-epoch-step: 4-318 -- Loss: 0.21670891344547272
train-epoch-step: 4-319 -- Loss: 0.23918813467025757
train-epoch-step: 4-320 -- Loss: 0.15606988966464996
train-epoch-step: 4-321 -- Loss: 0.18932653963565826
train-epoch-step: 4-322 -- Loss: 0.27850010991096497
train-epoch-step: 4-323 -- Loss: 0.20611971616744995
train-epoch-step: 4-324 -- Loss: 0.36110201478004456
train-epoch-step: 4-325 -- Loss: 0.20570838451385498
train-epoch-step: 4-326 -- Loss: 0.24921032786369324
train-epoch-step: 4-327 -- Loss: 0.2719622850418091
train-epoch-step: 4-328 -- Loss: 0.2677619159221649
train-epoch-step: 4-329 -- Loss: 0.43628042936325073
train-epoch-step: 4-330 -- Loss: 0.47936904430389404
train-epoch-step: 4-331 -- Loss: 0.29489436745643616
train-epoch-step: 4-332 -- Loss: 0.14400522410869598
train-epoch-step: 4-333 -- Loss: 0.24923937022686005
train-epoch-step: 4-334 -- Loss: 0.20333236455917358
train-epoch-step: 4-335 -- Loss: 0.23080004751682281
train-epoch-step: 4-336 -- Loss: 0.2208208590745926
train-epoch-step: 4-337 -- Loss: 0.27390676736831665
train-epoch-step: 4-338 -- Loss: 0.21893489360809326
train-epoch-step: 4-339 -- Loss: 0.19553840160369873
train-epoch-step: 4-340 -- Loss: 0.2729150056838989
train-epoch-step: 4-341 -- Loss: 0.17938357591629028
train-epoch-step: 4-342 -- Loss: 0.21566560864448547
train-epoch-step: 4-343 -- Loss: 0.2072077840566635
train-epoch-step: 4-344 -- Loss: 0.22515755891799927
train-epoch-step: 4-345 -- Loss: 0.1690855473279953
train-epoch-step: 4-346 -- Loss: 0.2552430331707001
train-epoch-step: 4-347 -- Loss: 0.2232668697834015
train-epoch-step: 4-348 -- Loss: 0.2740355134010315
train-epoch-step: 4-349 -- Loss: 0.29079553484916687
train-epoch-step: 4-350 -- Loss: 0.3533530831336975
train-epoch-step: 4-351 -- Loss: 0.27235639095306396
train-epoch-step: 4-352 -- Loss: 0.1928395926952362
train-epoch-step: 4-353 -- Loss: 0.26652881503105164
train-epoch-step: 4-354 -- Loss: 0.3709646463394165
train-epoch-step: 4-355 -- Loss: 0.1588846892118454
train-epoch-step: 4-356 -- Loss: 0.15743237733840942
train-epoch-step: 4-357 -- Loss: 0.24622738361358643
train-epoch-step: 4-358 -- Loss: 0.2379070371389389
train-epoch-step: 4-359 -- Loss: 0.18664982914924622
train-epoch-step: 4-360 -- Loss: 0.17862673103809357
train-epoch-step: 4-361 -- Loss: 0.34852564334869385
train-epoch-step: 4-362 -- Loss: 0.22725878655910492
train-epoch-step: 4-363 -- Loss: 0.15090522170066833
train-epoch-step: 4-364 -- Loss: 0.23439708352088928
train-epoch-step: 4-365 -- Loss: 0.2181425839662552
train-epoch-step: 4-366 -- Loss: 0.25324052572250366
train-epoch-step: 4-367 -- Loss: 0.3690550923347473
train-epoch-step: 4-368 -- Loss: 0.271623432636261
train-epoch-step: 4-369 -- Loss: 0.35249966382980347
train-epoch-step: 4-370 -- Loss: 0.1777699738740921
train-epoch-step: 4-371 -- Loss: 0.1580079346895218
train-epoch-step: 4-372 -- Loss: 0.1873558759689331
train-epoch-step: 4-373 -- Loss: 0.2584925591945648
train-epoch-step: 4-374 -- Loss: 0.21195068955421448
train-epoch-step: 4-375 -- Loss: 0.3935788869857788
train-epoch-step: 4-376 -- Loss: 0.2732614278793335
train-epoch-step: 4-377 -- Loss: 0.335540771484375
train-epoch-step: 4-378 -- Loss: 0.2806408405303955
train-epoch-step: 4-379 -- Loss: 0.1501820683479309
train-epoch-step: 4-380 -- Loss: 0.13762590289115906
train-epoch-step: 4-381 -- Loss: 0.32351571321487427
train-epoch-step: 4-382 -- Loss: 0.3195328712463379
train-epoch-step: 4-383 -- Loss: 0.2536924183368683
train-epoch-step: 4-384 -- Loss: 0.2919691205024719
train-epoch-step: 4-385 -- Loss: 0.2661711573600769
train-epoch-step: 4-386 -- Loss: 0.28939133882522583
train-epoch-step: 4-387 -- Loss: 0.27424705028533936
train-epoch-step: 4-388 -- Loss: 0.2984248399734497
train-epoch-step: 4-389 -- Loss: 0.2459409087896347
train-epoch-step: 4-390 -- Loss: 0.19756187498569489
train-epoch-step: 4-391 -- Loss: 0.1956859827041626
train-epoch-step: 4-392 -- Loss: 0.25042402744293213
train-epoch-step: 4-393 -- Loss: 0.20863868296146393
train-epoch-step: 4-394 -- Loss: 0.3026275634765625
train-epoch-step: 4-395 -- Loss: 0.20836135745048523
train-epoch-step: 4-396 -- Loss: 0.1773792803287506
train-epoch-step: 4-397 -- Loss: 0.16864527761936188
train-epoch-step: 4-398 -- Loss: 0.2519279420375824
train-epoch-step: 4-399 -- Loss: 0.2559542953968048
train-epoch-step: 4-400 -- Loss: 0.3765324056148529
train-epoch-step: 4-401 -- Loss: 0.15857349336147308
train-epoch-step: 4-402 -- Loss: 0.3442321717739105
train-epoch-step: 4-403 -- Loss: 0.22786584496498108
train-epoch-step: 4-404 -- Loss: 0.19334833323955536
train-epoch-step: 4-405 -- Loss: 0.20329347252845764
train-epoch-step: 4-406 -- Loss: 0.2186674028635025
train-epoch-step: 4-407 -- Loss: 0.15075872838497162
train-epoch-step: 4-408 -- Loss: 0.20615044236183167
train-epoch-step: 4-409 -- Loss: 0.23339107632637024
train-epoch-step: 4-410 -- Loss: 0.24806468188762665
train-epoch-step: 4-411 -- Loss: 0.26468539237976074
train-epoch-step: 4-412 -- Loss: 0.16573145985603333
train-epoch-step: 4-413 -- Loss: 0.19010302424430847
train-epoch-step: 4-414 -- Loss: 0.18487787246704102
train-epoch-step: 4-415 -- Loss: 0.18374113738536835
train-epoch-step: 4-416 -- Loss: 0.36358433961868286
train-epoch-step: 4-417 -- Loss: 0.26581937074661255
train-epoch-step: 4-418 -- Loss: 0.32517796754837036
train-epoch-step: 4-419 -- Loss: 0.22384412586688995
train-epoch-step: 4-420 -- Loss: 0.20096231997013092
train-epoch-step: 4-421 -- Loss: 0.2381969690322876
train-epoch-step: 4-422 -- Loss: 0.198015034198761
train-epoch-step: 4-423 -- Loss: 0.22028762102127075
train-epoch-step: 4-424 -- Loss: 0.17808282375335693
train-epoch-step: 4-425 -- Loss: 0.24611908197402954
train-epoch-step: 4-426 -- Loss: 0.2359948754310608
train-epoch-step: 4-427 -- Loss: 0.1782904863357544
train-epoch-step: 4-428 -- Loss: 0.26450884342193604
train-epoch-step: 4-429 -- Loss: 0.2464488297700882
train-epoch-step: 4-430 -- Loss: 0.18204107880592346
train-epoch-step: 4-431 -- Loss: 0.2215302437543869
train-epoch-step: 4-432 -- Loss: 0.3238976001739502
train-epoch-step: 4-433 -- Loss: 0.19402983784675598
train-epoch-step: 4-434 -- Loss: 0.1848176121711731
train-epoch-step: 4-435 -- Loss: 0.21467578411102295
train-epoch-step: 4-436 -- Loss: 0.2066073715686798
train-epoch-step: 4-437 -- Loss: 0.18260571360588074
train-epoch-step: 4-438 -- Loss: 0.23617559671401978
train-epoch-step: 4-439 -- Loss: 0.378755122423172
train-epoch-step: 4-440 -- Loss: 0.18847525119781494
train-epoch-step: 4-441 -- Loss: 0.2992304563522339
train-epoch-step: 4-442 -- Loss: 0.2559390068054199
train-epoch-step: 4-443 -- Loss: 0.20623502135276794
train-epoch-step: 4-444 -- Loss: 0.3167051672935486
train-epoch-step: 4-445 -- Loss: 0.24267232418060303
train-epoch-step: 4-446 -- Loss: 0.20464974641799927
train-epoch-step: 4-447 -- Loss: 0.27120906114578247
train-epoch-step: 4-448 -- Loss: 0.32690268754959106
train-epoch-step: 4-449 -- Loss: 0.2521243691444397
train-epoch-step: 4-450 -- Loss: 0.24957340955734253
train-epoch-step: 4-451 -- Loss: 0.18595705926418304
train-epoch-step: 4-452 -- Loss: 0.1783170998096466
train-epoch-step: 4-453 -- Loss: 0.1288260966539383
train-epoch-step: 4-454 -- Loss: 0.32482630014419556
train-epoch-step: 4-455 -- Loss: 0.1862853765487671
train-epoch-step: 4-456 -- Loss: 0.16002798080444336
train-epoch-step: 4-457 -- Loss: 0.2837553322315216
train-epoch-step: 4-458 -- Loss: 0.1990949809551239
train-epoch-step: 4-459 -- Loss: 0.28340423107147217
train-epoch-step: 4-460 -- Loss: 0.16365182399749756
train-epoch-step: 4-461 -- Loss: 0.19463331997394562
train-epoch-step: 4-462 -- Loss: 0.20206931233406067
train-epoch-step: 4-463 -- Loss: 0.18518564105033875
train-epoch-step: 4-464 -- Loss: 0.2449469417333603
train-epoch-step: 4-465 -- Loss: 0.3522118330001831
train-epoch-step: 4-466 -- Loss: 0.260120689868927
train-epoch-step: 4-467 -- Loss: 0.1493447721004486
train-epoch-step: 4-468 -- Loss: 0.2661207914352417
train-epoch-step: 4-469 -- Loss: 0.3497505784034729
train-epoch-step: 4-470 -- Loss: 0.23838219046592712
train-epoch-step: 4-471 -- Loss: 0.20983590185642242
train-epoch-step: 4-472 -- Loss: 0.20949162542819977
train-epoch-step: 4-473 -- Loss: 0.22252658009529114
train-epoch-step: 4-474 -- Loss: 0.1569317877292633
train-epoch-step: 4-475 -- Loss: 0.14730754494667053
train-epoch-step: 4-476 -- Loss: 0.2609112858772278
train-epoch-step: 4-477 -- Loss: 0.3054071068763733
train-epoch-step: 4-478 -- Loss: 0.24534417688846588
train-epoch-step: 4-479 -- Loss: 0.1850263476371765
train-epoch-step: 4-480 -- Loss: 0.27431267499923706
train-epoch-step: 4-481 -- Loss: 0.35816794633865356
train-epoch-step: 4-482 -- Loss: 0.3395160138607025
train-epoch-step: 4-483 -- Loss: 0.2612917721271515
train-epoch-step: 4-484 -- Loss: 0.2827419340610504
train-epoch-step: 4-485 -- Loss: 0.17611943185329437
train-epoch-step: 4-486 -- Loss: 0.35978245735168457
train-epoch-step: 4-487 -- Loss: 0.2985815703868866
train-epoch-step: 4-488 -- Loss: 0.24589625000953674
train-epoch-step: 4-489 -- Loss: 0.28029847145080566
train-epoch-step: 4-490 -- Loss: 0.18348336219787598
train-epoch-step: 4-491 -- Loss: 0.18007498979568481
train-epoch-step: 4-492 -- Loss: 0.16184768080711365
train-epoch-step: 4-493 -- Loss: 0.2851478159427643
train-epoch-step: 4-494 -- Loss: 0.2751620411872864
train-epoch-step: 4-495 -- Loss: 0.2808229327201843
train-epoch-step: 4-496 -- Loss: 0.17954781651496887
train-epoch-step: 4-497 -- Loss: 0.27415356040000916
train-epoch-step: 4-498 -- Loss: 0.1925891637802124
train-epoch-step: 4-499 -- Loss: 0.223913311958313
train-epoch-step: 4-500 -- Loss: 0.20821510255336761
train-epoch-step: 4-501 -- Loss: 0.28900793194770813
train-epoch-step: 4-502 -- Loss: 0.22579090297222137
train-epoch-step: 4-503 -- Loss: 0.28440994024276733
train-epoch-step: 4-504 -- Loss: 0.15657192468643188
train-epoch-step: 4-505 -- Loss: 0.23463408648967743
train-epoch-step: 4-506 -- Loss: 0.15596503019332886
train-epoch-step: 4-507 -- Loss: 0.23612254858016968
train-epoch-step: 4-508 -- Loss: 0.2256072461605072
train-epoch-step: 4-509 -- Loss: 0.22153151035308838
train-epoch-step: 4-510 -- Loss: 0.18329961597919464
train-epoch-step: 4-511 -- Loss: 0.2790798544883728
train-epoch-step: 4-512 -- Loss: 0.24965262413024902
train-epoch-step: 4-513 -- Loss: 0.26545044779777527
train-epoch-step: 4-514 -- Loss: 0.19407308101654053
train-epoch-step: 4-515 -- Loss: 0.2224527895450592
train-epoch-step: 4-516 -- Loss: 0.22154875099658966
train-epoch-step: 4-517 -- Loss: 0.24673277139663696
train-epoch-step: 4-518 -- Loss: 0.18729127943515778
train-epoch-step: 4-519 -- Loss: 0.18111905455589294
train-epoch-step: 4-520 -- Loss: 0.25188249349594116
train-epoch-step: 4-521 -- Loss: 0.29091447591781616
train-epoch-step: 4-522 -- Loss: 0.23503327369689941
train-epoch-step: 4-523 -- Loss: 0.20995087921619415
train-epoch-step: 4-524 -- Loss: 0.22032159566879272
train-epoch-step: 4-525 -- Loss: 0.24298596382141113
train-epoch-step: 4-526 -- Loss: 0.16669771075248718
train-epoch-step: 4-527 -- Loss: 0.22387506067752838
train-epoch-step: 4-528 -- Loss: 0.21392080187797546
train-epoch-step: 4-529 -- Loss: 0.23625841736793518
train-epoch-step: 4-530 -- Loss: 0.25545406341552734
train-epoch-step: 4-531 -- Loss: 0.2591228485107422
train-epoch-step: 4-532 -- Loss: 0.2277674376964569
train-epoch-step: 4-533 -- Loss: 0.21912461519241333
train-epoch-step: 4-534 -- Loss: 0.174644336104393
train-epoch-step: 4-535 -- Loss: 0.38603338599205017
train-epoch-step: 4-536 -- Loss: 0.20802253484725952
train-epoch-step: 4-537 -- Loss: 0.20073610544204712
train-epoch-step: 4-538 -- Loss: 0.1365952491760254
train-epoch-step: 4-539 -- Loss: 0.25305742025375366
train-epoch-step: 4-540 -- Loss: 0.17155328392982483
train-epoch-step: 4-541 -- Loss: 0.2780793607234955
train-epoch-step: 4-542 -- Loss: 0.31498444080352783
train-epoch-step: 4-543 -- Loss: 0.22104328870773315
train-epoch-step: 4-544 -- Loss: 0.2855166792869568
train-epoch-step: 4-545 -- Loss: 0.25248992443084717
train-epoch-step: 4-546 -- Loss: 0.2994652986526489
train-epoch-step: 4-547 -- Loss: 0.22670915722846985
train-epoch-step: 4-548 -- Loss: 0.11940962821245193
train-epoch-step: 4-549 -- Loss: 0.20833531022071838
train-epoch-step: 4-550 -- Loss: 0.25736314058303833
train-epoch-step: 4-551 -- Loss: 0.21419012546539307
train-epoch-step: 4-552 -- Loss: 0.166515052318573
train-epoch-step: 4-553 -- Loss: 0.2462879717350006
train-epoch-step: 4-554 -- Loss: 0.23974868655204773
train-epoch-step: 4-555 -- Loss: 0.3114333152770996
train-epoch-step: 4-556 -- Loss: 0.22683796286582947
train-epoch-step: 4-557 -- Loss: 0.32050439715385437
train-epoch-step: 4-558 -- Loss: 0.31647923588752747
train-epoch-step: 4-559 -- Loss: 0.19572991132736206
train-epoch-step: 4-560 -- Loss: 0.2552439272403717
train-epoch-step: 4-561 -- Loss: 0.25493693351745605
train-epoch-step: 4-562 -- Loss: 0.2668614387512207
train-epoch-step: 4-563 -- Loss: 0.2515142858028412
train-epoch-step: 4-564 -- Loss: 0.1368354856967926
train-epoch-step: 4-565 -- Loss: 0.2372526079416275
train-epoch-step: 4-566 -- Loss: 0.21295519173145294
train-epoch-step: 4-567 -- Loss: 0.2658081650733948
train-epoch-step: 4-568 -- Loss: 0.20345941185951233
train-epoch-step: 4-569 -- Loss: 0.2924025058746338
train-epoch-step: 4-570 -- Loss: 0.22658251225948334
train-epoch-step: 4-571 -- Loss: 0.2757924795150757
train-epoch-step: 4-572 -- Loss: 0.315841943025589
train-epoch-step: 4-573 -- Loss: 0.27674248814582825
train-epoch-step: 4-574 -- Loss: 0.3428072929382324
train-epoch-step: 4-575 -- Loss: 0.41537874937057495
train-epoch-step: 4-576 -- Loss: 0.16308149695396423
train-epoch-step: 4-577 -- Loss: 0.21799078583717346
train-epoch-step: 4-578 -- Loss: 0.2990264892578125
train-epoch-step: 4-579 -- Loss: 0.22144772112369537
train-epoch-step: 4-580 -- Loss: 0.2565004825592041
train-epoch-step: 4-581 -- Loss: 0.18150222301483154
train-epoch-step: 4-582 -- Loss: 0.2838897705078125
train-epoch-step: 4-583 -- Loss: 0.2982783913612366
train-epoch-step: 4-584 -- Loss: 0.26059573888778687
train-epoch-step: 4-585 -- Loss: 0.24656392633914948
train-epoch-step: 4-586 -- Loss: 0.35411423444747925
train-epoch-step: 4-587 -- Loss: 0.21040931344032288
train-epoch-step: 4-588 -- Loss: 0.16953042149543762
val-epoch-step: 4-589 -- Loss: 0.2913321852684021
val-epoch-step: 4-590 -- Loss: 0.19161325693130493
val-epoch-step: 4-591 -- Loss: 0.26206672191619873
val-epoch-step: 4-592 -- Loss: 0.22548919916152954
val-epoch-step: 4-593 -- Loss: 0.17949245870113373
val-epoch-step: 4-594 -- Loss: 0.3948785662651062
val-epoch-step: 4-595 -- Loss: 0.22171735763549805
val-epoch-step: 4-596 -- Loss: 0.26848363876342773
val-epoch-step: 4-597 -- Loss: 0.22749561071395874
val-epoch-step: 4-598 -- Loss: 0.19295327365398407
val-epoch-step: 4-599 -- Loss: 0.23097176849842072
val-epoch-step: 4-600 -- Loss: 0.22945401072502136
val-epoch-step: 4-601 -- Loss: 0.18980735540390015
val-epoch-step: 4-602 -- Loss: 0.17921195924282074
val-epoch-step: 4-603 -- Loss: 0.2292933166027069
val-epoch-step: 4-604 -- Loss: 0.18110516667366028
val-epoch-step: 4-605 -- Loss: 0.1874236911535263
val-epoch-step: 4-606 -- Loss: 0.35426777601242065
val-epoch-step: 4-607 -- Loss: 0.1770191490650177
val-epoch-step: 4-608 -- Loss: 0.30955979228019714
val-epoch-step: 4-609 -- Loss: 0.22411292791366577
val-epoch-step: 4-610 -- Loss: 0.2500401437282562
val-epoch-step: 4-611 -- Loss: 0.208382710814476
val-epoch-step: 4-612 -- Loss: 0.37736275792121887
val-epoch-step: 4-613 -- Loss: 0.22811557352542877
val-epoch-step: 4-614 -- Loss: 0.19857442378997803
val-epoch-step: 4-615 -- Loss: 0.24423404037952423
val-epoch-step: 4-616 -- Loss: 0.18497879803180695
val-epoch-step: 4-617 -- Loss: 0.2523714303970337
val-epoch-step: 4-618 -- Loss: 0.24534860253334045
val-epoch-step: 4-619 -- Loss: 0.27098363637924194
val-epoch-step: 4-620 -- Loss: 0.18166014552116394
val-epoch-step: 4-621 -- Loss: 0.1788208782672882
val-epoch-step: 4-622 -- Loss: 0.18625332415103912
val-epoch-step: 4-623 -- Loss: 0.19324299693107605
val-epoch-step: 4-624 -- Loss: 0.2125864177942276
val-epoch-step: 4-625 -- Loss: 0.1955958604812622
val-epoch-step: 4-626 -- Loss: 0.195101797580719
val-epoch-step: 4-627 -- Loss: 0.2494189441204071
val-epoch-step: 4-628 -- Loss: 0.5095058679580688
val-epoch-step: 4-629 -- Loss: 0.2645156979560852
val-epoch-step: 4-630 -- Loss: 0.4249313771724701
val-epoch-step: 4-631 -- Loss: 0.1811794936656952
val-epoch-step: 4-632 -- Loss: 0.24933721125125885
val-epoch-step: 4-633 -- Loss: 0.20047524571418762
val-epoch-step: 4-634 -- Loss: 0.17930954694747925
val-epoch-step: 4-635 -- Loss: 0.14153055846691132
val-epoch-step: 4-636 -- Loss: 0.21040655672550201
val-epoch-step: 4-637 -- Loss: 0.23286357522010803
val-epoch-step: 4-638 -- Loss: 0.19517947733402252
val-epoch-step: 4-639 -- Loss: 0.3259885907173157
val-epoch-step: 4-640 -- Loss: 0.3063833713531494
val-epoch-step: 4-641 -- Loss: 0.15676699578762054
val-epoch-step: 4-642 -- Loss: 0.2540697157382965
val-epoch-step: 4-643 -- Loss: 0.24579526484012604
val-epoch-step: 4-644 -- Loss: 0.2071039378643036
val-epoch-step: 4-645 -- Loss: 0.28080838918685913
val-epoch-step: 4-646 -- Loss: 0.1863347887992859
val-epoch-step: 4-647 -- Loss: 0.1729365587234497
val-epoch-step: 4-648 -- Loss: 0.2074820101261139
val-epoch-step: 4-649 -- Loss: 0.29513055086135864
val-epoch-step: 4-650 -- Loss: 0.3187514543533325
val-epoch-step: 4-651 -- Loss: 0.17809954285621643
val-epoch-step: 4-652 -- Loss: 0.19682323932647705
val-epoch-step: 4-653 -- Loss: 0.24957305192947388
val-epoch-step: 4-654 -- Loss: 0.1409703642129898
Epoch: 4 -- Train Loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1612, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 5-0 -- Loss: 0.2860162854194641
train-epoch-step: 5-1 -- Loss: 0.18487973511219025
train-epoch-step: 5-2 -- Loss: 0.2560432255268097
train-epoch-step: 5-3 -- Loss: 0.1919853389263153
train-epoch-step: 5-4 -- Loss: 0.2505141496658325
train-epoch-step: 5-5 -- Loss: 0.24842315912246704
train-epoch-step: 5-6 -- Loss: 0.3142026662826538
train-epoch-step: 5-7 -- Loss: 0.22356556355953217
train-epoch-step: 5-8 -- Loss: 0.24688157439231873
train-epoch-step: 5-9 -- Loss: 0.34677696228027344
train-epoch-step: 5-10 -- Loss: 0.3187468647956848
train-epoch-step: 5-11 -- Loss: 0.23215703666210175
train-epoch-step: 5-12 -- Loss: 0.19803833961486816
train-epoch-step: 5-13 -- Loss: 0.2502315044403076
train-epoch-step: 5-14 -- Loss: 0.20253607630729675
train-epoch-step: 5-15 -- Loss: 0.20818883180618286
train-epoch-step: 5-16 -- Loss: 0.22110438346862793
train-epoch-step: 5-17 -- Loss: 0.2865435481071472
train-epoch-step: 5-18 -- Loss: 0.24814005196094513
train-epoch-step: 5-19 -- Loss: 0.1756700873374939
train-epoch-step: 5-20 -- Loss: 0.2925642728805542
train-epoch-step: 5-21 -- Loss: 0.3953728675842285
train-epoch-step: 5-22 -- Loss: 0.20081965625286102
train-epoch-step: 5-23 -- Loss: 0.2386729121208191
train-epoch-step: 5-24 -- Loss: 0.17169851064682007
train-epoch-step: 5-25 -- Loss: 0.28290438652038574
train-epoch-step: 5-26 -- Loss: 0.25381752848625183
train-epoch-step: 5-27 -- Loss: 0.34558621048927307
train-epoch-step: 5-28 -- Loss: 0.16462013125419617
train-epoch-step: 5-29 -- Loss: 0.3070233464241028
train-epoch-step: 5-30 -- Loss: 0.1414044201374054
train-epoch-step: 5-31 -- Loss: 0.1897842288017273
train-epoch-step: 5-32 -- Loss: 0.22532682120800018
train-epoch-step: 5-33 -- Loss: 0.35151511430740356
train-epoch-step: 5-34 -- Loss: 0.2174454778432846
train-epoch-step: 5-35 -- Loss: 0.3139338493347168
train-epoch-step: 5-36 -- Loss: 0.19023722410202026
train-epoch-step: 5-37 -- Loss: 0.19423213601112366
train-epoch-step: 5-38 -- Loss: 0.2555561661720276
train-epoch-step: 5-39 -- Loss: 0.3054744601249695
train-epoch-step: 5-40 -- Loss: 0.2694374918937683
train-epoch-step: 5-41 -- Loss: 0.2776215672492981
train-epoch-step: 5-42 -- Loss: 0.19216425716876984
train-epoch-step: 5-43 -- Loss: 0.37454521656036377
train-epoch-step: 5-44 -- Loss: 0.17200587689876556
train-epoch-step: 5-45 -- Loss: 0.16733673214912415
train-epoch-step: 5-46 -- Loss: 0.23044157028198242
train-epoch-step: 5-47 -- Loss: 0.29431626200675964
train-epoch-step: 5-48 -- Loss: 0.19653263688087463
train-epoch-step: 5-49 -- Loss: 0.2828700840473175
train-epoch-step: 5-50 -- Loss: 0.15769422054290771
train-epoch-step: 5-51 -- Loss: 0.24818119406700134
train-epoch-step: 5-52 -- Loss: 0.20331592857837677
train-epoch-step: 5-53 -- Loss: 0.290194571018219
train-epoch-step: 5-54 -- Loss: 0.36670470237731934
train-epoch-step: 5-55 -- Loss: 0.22020748257637024
train-epoch-step: 5-56 -- Loss: 0.2604084014892578
train-epoch-step: 5-57 -- Loss: 0.29874762892723083
train-epoch-step: 5-58 -- Loss: 0.3482167422771454
train-epoch-step: 5-59 -- Loss: 0.345760703086853
train-epoch-step: 5-60 -- Loss: 0.17186200618743896
train-epoch-step: 5-61 -- Loss: 0.29473525285720825
train-epoch-step: 5-62 -- Loss: 0.24023771286010742
train-epoch-step: 5-63 -- Loss: 0.17752963304519653
train-epoch-step: 5-64 -- Loss: 0.21421945095062256
train-epoch-step: 5-65 -- Loss: 0.25049957633018494
train-epoch-step: 5-66 -- Loss: 0.14074067771434784
train-epoch-step: 5-67 -- Loss: 0.1601170301437378
train-epoch-step: 5-68 -- Loss: 0.3156037926673889
train-epoch-step: 5-69 -- Loss: 0.18036021292209625
train-epoch-step: 5-70 -- Loss: 0.2773953676223755
train-epoch-step: 5-71 -- Loss: 0.324361115694046
train-epoch-step: 5-72 -- Loss: 0.24287426471710205
train-epoch-step: 5-73 -- Loss: 0.2707940936088562
train-epoch-step: 5-74 -- Loss: 0.12915393710136414
train-epoch-step: 5-75 -- Loss: 0.1838081181049347
train-epoch-step: 5-76 -- Loss: 0.18783530592918396
train-epoch-step: 5-77 -- Loss: 0.289834588766098
train-epoch-step: 5-78 -- Loss: 0.36751601099967957
train-epoch-step: 5-79 -- Loss: 0.2587709128856659
train-epoch-step: 5-80 -- Loss: 0.37242746353149414
train-epoch-step: 5-81 -- Loss: 0.17092077434062958
train-epoch-step: 5-82 -- Loss: 0.3197426199913025
train-epoch-step: 5-83 -- Loss: 0.24504438042640686
train-epoch-step: 5-84 -- Loss: 0.2725524306297302
train-epoch-step: 5-85 -- Loss: 0.24032354354858398
train-epoch-step: 5-86 -- Loss: 0.16439135372638702
train-epoch-step: 5-87 -- Loss: 0.30851423740386963
train-epoch-step: 5-88 -- Loss: 0.1856689751148224
train-epoch-step: 5-89 -- Loss: 0.24975767731666565
train-epoch-step: 5-90 -- Loss: 0.253298819065094
train-epoch-step: 5-91 -- Loss: 0.31792575120925903
train-epoch-step: 5-92 -- Loss: 0.21693527698516846
train-epoch-step: 5-93 -- Loss: 0.25302958488464355
train-epoch-step: 5-94 -- Loss: 0.322706013917923
train-epoch-step: 5-95 -- Loss: 0.26251959800720215
train-epoch-step: 5-96 -- Loss: 0.29343706369400024
train-epoch-step: 5-97 -- Loss: 0.25434303283691406
train-epoch-step: 5-98 -- Loss: 0.21246767044067383
train-epoch-step: 5-99 -- Loss: 0.23840180039405823
train-epoch-step: 5-100 -- Loss: 0.2516031265258789
train-epoch-step: 5-101 -- Loss: 0.3458021581172943
train-epoch-step: 5-102 -- Loss: 0.32629725337028503
train-epoch-step: 5-103 -- Loss: 0.2624557614326477
train-epoch-step: 5-104 -- Loss: 0.19920557737350464
train-epoch-step: 5-105 -- Loss: 0.40562766790390015
train-epoch-step: 5-106 -- Loss: 0.23680412769317627
train-epoch-step: 5-107 -- Loss: 0.2583746314048767
train-epoch-step: 5-108 -- Loss: 0.23836129903793335
train-epoch-step: 5-109 -- Loss: 0.20103713870048523
train-epoch-step: 5-110 -- Loss: 0.24957489967346191
train-epoch-step: 5-111 -- Loss: 0.2379356324672699
train-epoch-step: 5-112 -- Loss: 0.22510714828968048
train-epoch-step: 5-113 -- Loss: 0.2316669225692749
train-epoch-step: 5-114 -- Loss: 0.340944766998291
train-epoch-step: 5-115 -- Loss: 0.21315640211105347
train-epoch-step: 5-116 -- Loss: 0.20039518177509308
train-epoch-step: 5-117 -- Loss: 0.17251522839069366
train-epoch-step: 5-118 -- Loss: 0.26788657903671265
train-epoch-step: 5-119 -- Loss: 0.20454709231853485
train-epoch-step: 5-120 -- Loss: 0.35671210289001465
train-epoch-step: 5-121 -- Loss: 0.3423718214035034
train-epoch-step: 5-122 -- Loss: 0.2819729447364807
train-epoch-step: 5-123 -- Loss: 0.2733636796474457
train-epoch-step: 5-124 -- Loss: 0.15831992030143738
train-epoch-step: 5-125 -- Loss: 0.19645743072032928
train-epoch-step: 5-126 -- Loss: 0.3263871967792511
train-epoch-step: 5-127 -- Loss: 0.22361856698989868
train-epoch-step: 5-128 -- Loss: 0.23473003506660461
train-epoch-step: 5-129 -- Loss: 0.18734468519687653
train-epoch-step: 5-130 -- Loss: 0.2451440840959549
train-epoch-step: 5-131 -- Loss: 0.17809835076332092
train-epoch-step: 5-132 -- Loss: 0.2542223334312439
train-epoch-step: 5-133 -- Loss: 0.1509416699409485
train-epoch-step: 5-134 -- Loss: 0.2625448703765869
train-epoch-step: 5-135 -- Loss: 0.17243078351020813
train-epoch-step: 5-136 -- Loss: 0.1631314903497696
train-epoch-step: 5-137 -- Loss: 0.3360280394554138
train-epoch-step: 5-138 -- Loss: 0.35292163491249084
train-epoch-step: 5-139 -- Loss: 0.17432336509227753
train-epoch-step: 5-140 -- Loss: 0.277043879032135
train-epoch-step: 5-141 -- Loss: 0.3092816472053528
train-epoch-step: 5-142 -- Loss: 0.2658725380897522
train-epoch-step: 5-143 -- Loss: 0.22788560390472412
train-epoch-step: 5-144 -- Loss: 0.2513992488384247
train-epoch-step: 5-145 -- Loss: 0.182069793343544
train-epoch-step: 5-146 -- Loss: 0.23028279840946198
train-epoch-step: 5-147 -- Loss: 0.23881560564041138
train-epoch-step: 5-148 -- Loss: 0.23040395975112915
train-epoch-step: 5-149 -- Loss: 0.15575706958770752
train-epoch-step: 5-150 -- Loss: 0.24678143858909607
train-epoch-step: 5-151 -- Loss: 0.2402018904685974
train-epoch-step: 5-152 -- Loss: 0.2503023147583008
train-epoch-step: 5-153 -- Loss: 0.4177948832511902
train-epoch-step: 5-154 -- Loss: 0.18156464397907257
train-epoch-step: 5-155 -- Loss: 0.19390252232551575
train-epoch-step: 5-156 -- Loss: 0.16185562312602997
train-epoch-step: 5-157 -- Loss: 0.22838792204856873
train-epoch-step: 5-158 -- Loss: 0.22560259699821472
train-epoch-step: 5-159 -- Loss: 0.22755977511405945
train-epoch-step: 5-160 -- Loss: 0.28938913345336914
train-epoch-step: 5-161 -- Loss: 0.2861570119857788
train-epoch-step: 5-162 -- Loss: 0.27762866020202637
train-epoch-step: 5-163 -- Loss: 0.25026586651802063
train-epoch-step: 5-164 -- Loss: 0.24212178587913513
train-epoch-step: 5-165 -- Loss: 0.21410100162029266
train-epoch-step: 5-166 -- Loss: 0.160223588347435
train-epoch-step: 5-167 -- Loss: 0.15896514058113098
train-epoch-step: 5-168 -- Loss: 0.2714073061943054
train-epoch-step: 5-169 -- Loss: 0.1805068850517273
train-epoch-step: 5-170 -- Loss: 0.277416467666626
train-epoch-step: 5-171 -- Loss: 0.19044196605682373
train-epoch-step: 5-172 -- Loss: 0.3345232307910919
train-epoch-step: 5-173 -- Loss: 0.16742569208145142
train-epoch-step: 5-174 -- Loss: 0.3089362680912018
train-epoch-step: 5-175 -- Loss: 0.252139151096344
train-epoch-step: 5-176 -- Loss: 0.17173698544502258
train-epoch-step: 5-177 -- Loss: 0.24077093601226807
train-epoch-step: 5-178 -- Loss: 0.25095033645629883
train-epoch-step: 5-179 -- Loss: 0.18231186270713806
train-epoch-step: 5-180 -- Loss: 0.1941516101360321
train-epoch-step: 5-181 -- Loss: 0.2301638424396515
train-epoch-step: 5-182 -- Loss: 0.25128889083862305
train-epoch-step: 5-183 -- Loss: 0.3520076274871826
train-epoch-step: 5-184 -- Loss: 0.18763691186904907
train-epoch-step: 5-185 -- Loss: 0.19132326543331146
train-epoch-step: 5-186 -- Loss: 0.25380343198776245
train-epoch-step: 5-187 -- Loss: 0.2917520999908447
train-epoch-step: 5-188 -- Loss: 0.23956307768821716
train-epoch-step: 5-189 -- Loss: 0.17839288711547852
train-epoch-step: 5-190 -- Loss: 0.23102571070194244
train-epoch-step: 5-191 -- Loss: 0.23591335117816925
train-epoch-step: 5-192 -- Loss: 0.3181878328323364
train-epoch-step: 5-193 -- Loss: 0.3001817464828491
train-epoch-step: 5-194 -- Loss: 0.2295941710472107
train-epoch-step: 5-195 -- Loss: 0.21464960277080536
train-epoch-step: 5-196 -- Loss: 0.22907844185829163
train-epoch-step: 5-197 -- Loss: 0.1646440029144287
train-epoch-step: 5-198 -- Loss: 0.17126494646072388
train-epoch-step: 5-199 -- Loss: 0.20042872428894043
train-epoch-step: 5-200 -- Loss: 0.16007615625858307
train-epoch-step: 5-201 -- Loss: 0.25857535004615784
train-epoch-step: 5-202 -- Loss: 0.1765972077846527
train-epoch-step: 5-203 -- Loss: 0.23621538281440735
train-epoch-step: 5-204 -- Loss: 0.1974835842847824
train-epoch-step: 5-205 -- Loss: 0.236485093832016
train-epoch-step: 5-206 -- Loss: 0.2668202519416809
train-epoch-step: 5-207 -- Loss: 0.17670290172100067
train-epoch-step: 5-208 -- Loss: 0.2276395559310913
train-epoch-step: 5-209 -- Loss: 0.18593421578407288
train-epoch-step: 5-210 -- Loss: 0.1763559877872467
train-epoch-step: 5-211 -- Loss: 0.27597397565841675
train-epoch-step: 5-212 -- Loss: 0.2572926878929138
train-epoch-step: 5-213 -- Loss: 0.17072606086730957
train-epoch-step: 5-214 -- Loss: 0.1933152675628662
train-epoch-step: 5-215 -- Loss: 0.1796313226222992
train-epoch-step: 5-216 -- Loss: 0.2616267800331116
train-epoch-step: 5-217 -- Loss: 0.28110048174858093
train-epoch-step: 5-218 -- Loss: 0.2149926722049713
train-epoch-step: 5-219 -- Loss: 0.2603384852409363
train-epoch-step: 5-220 -- Loss: 0.1659957468509674
train-epoch-step: 5-221 -- Loss: 0.2591705024242401
train-epoch-step: 5-222 -- Loss: 0.16298122704029083
train-epoch-step: 5-223 -- Loss: 0.21963286399841309
train-epoch-step: 5-224 -- Loss: 0.23336251080036163
train-epoch-step: 5-225 -- Loss: 0.40692609548568726
train-epoch-step: 5-226 -- Loss: 0.27973657846450806
train-epoch-step: 5-227 -- Loss: 0.3064979612827301
train-epoch-step: 5-228 -- Loss: 0.2311779260635376
train-epoch-step: 5-229 -- Loss: 0.2439495325088501
train-epoch-step: 5-230 -- Loss: 0.20490902662277222
train-epoch-step: 5-231 -- Loss: 0.2330600619316101
train-epoch-step: 5-232 -- Loss: 0.25562116503715515
train-epoch-step: 5-233 -- Loss: 0.11423073709011078
train-epoch-step: 5-234 -- Loss: 0.22803840041160583
train-epoch-step: 5-235 -- Loss: 0.2082979679107666
train-epoch-step: 5-236 -- Loss: 0.2305089682340622
train-epoch-step: 5-237 -- Loss: 0.32099539041519165
train-epoch-step: 5-238 -- Loss: 0.20492389798164368
train-epoch-step: 5-239 -- Loss: 0.17753866314888
train-epoch-step: 5-240 -- Loss: 0.27619361877441406
train-epoch-step: 5-241 -- Loss: 0.20463915169239044
train-epoch-step: 5-242 -- Loss: 0.28886112570762634
train-epoch-step: 5-243 -- Loss: 0.2974012494087219
train-epoch-step: 5-244 -- Loss: 0.2581717371940613
train-epoch-step: 5-245 -- Loss: 0.3112972378730774
train-epoch-step: 5-246 -- Loss: 0.36930689215660095
train-epoch-step: 5-247 -- Loss: 0.314043790102005
train-epoch-step: 5-248 -- Loss: 0.23985642194747925
train-epoch-step: 5-249 -- Loss: 0.18341469764709473
train-epoch-step: 5-250 -- Loss: 0.2678130269050598
train-epoch-step: 5-251 -- Loss: 0.14962005615234375
train-epoch-step: 5-252 -- Loss: 0.24755413830280304
train-epoch-step: 5-253 -- Loss: 0.17616695165634155
train-epoch-step: 5-254 -- Loss: 0.30866602063179016
train-epoch-step: 5-255 -- Loss: 0.18590711057186127
train-epoch-step: 5-256 -- Loss: 0.20020759105682373
train-epoch-step: 5-257 -- Loss: 0.24661658704280853
train-epoch-step: 5-258 -- Loss: 0.20545148849487305
train-epoch-step: 5-259 -- Loss: 0.15328527987003326
train-epoch-step: 5-260 -- Loss: 0.27017301321029663
train-epoch-step: 5-261 -- Loss: 0.22271430492401123
train-epoch-step: 5-262 -- Loss: 0.40446922183036804
train-epoch-step: 5-263 -- Loss: 0.2870784401893616
train-epoch-step: 5-264 -- Loss: 0.21562540531158447
train-epoch-step: 5-265 -- Loss: 0.14490076899528503
train-epoch-step: 5-266 -- Loss: 0.19429317116737366
train-epoch-step: 5-267 -- Loss: 0.186822310090065
train-epoch-step: 5-268 -- Loss: 0.15594878792762756
train-epoch-step: 5-269 -- Loss: 0.22265644371509552
train-epoch-step: 5-270 -- Loss: 0.13754738867282867
train-epoch-step: 5-271 -- Loss: 0.1944570243358612
train-epoch-step: 5-272 -- Loss: 0.1558268964290619
train-epoch-step: 5-273 -- Loss: 0.1622547060251236
train-epoch-step: 5-274 -- Loss: 0.23810794949531555
train-epoch-step: 5-275 -- Loss: 0.26672154664993286
train-epoch-step: 5-276 -- Loss: 0.19798195362091064
train-epoch-step: 5-277 -- Loss: 0.19621187448501587
train-epoch-step: 5-278 -- Loss: 0.1883709728717804
train-epoch-step: 5-279 -- Loss: 0.1891198307275772
train-epoch-step: 5-280 -- Loss: 0.2672939896583557
train-epoch-step: 5-281 -- Loss: 0.2284594178199768
train-epoch-step: 5-282 -- Loss: 0.1784014105796814
train-epoch-step: 5-283 -- Loss: 0.1436615139245987
train-epoch-step: 5-284 -- Loss: 0.2714766263961792
train-epoch-step: 5-285 -- Loss: 0.25212588906288147
train-epoch-step: 5-286 -- Loss: 0.20513524115085602
train-epoch-step: 5-287 -- Loss: 0.2652769088745117
train-epoch-step: 5-288 -- Loss: 0.12620091438293457
train-epoch-step: 5-289 -- Loss: 0.16046570241451263
train-epoch-step: 5-290 -- Loss: 0.2365921586751938
train-epoch-step: 5-291 -- Loss: 0.15044432878494263
train-epoch-step: 5-292 -- Loss: 0.19820886850357056
train-epoch-step: 5-293 -- Loss: 0.18227434158325195
train-epoch-step: 5-294 -- Loss: 0.21918541193008423
train-epoch-step: 5-295 -- Loss: 0.3803349733352661
train-epoch-step: 5-296 -- Loss: 0.21900737285614014
train-epoch-step: 5-297 -- Loss: 0.22458189725875854
train-epoch-step: 5-298 -- Loss: 0.3147309124469757
train-epoch-step: 5-299 -- Loss: 0.21241098642349243
train-epoch-step: 5-300 -- Loss: 0.23019981384277344
train-epoch-step: 5-301 -- Loss: 0.2181396186351776
train-epoch-step: 5-302 -- Loss: 0.2876872420310974
train-epoch-step: 5-303 -- Loss: 0.2646279036998749
train-epoch-step: 5-304 -- Loss: 0.1830456554889679
train-epoch-step: 5-305 -- Loss: 0.18924351036548615
train-epoch-step: 5-306 -- Loss: 0.3018563389778137
train-epoch-step: 5-307 -- Loss: 0.2174042910337448
train-epoch-step: 5-308 -- Loss: 0.32135385274887085
train-epoch-step: 5-309 -- Loss: 0.2017545849084854
train-epoch-step: 5-310 -- Loss: 0.2090970277786255
train-epoch-step: 5-311 -- Loss: 0.21313150227069855
train-epoch-step: 5-312 -- Loss: 0.27717411518096924
train-epoch-step: 5-313 -- Loss: 0.12812462449073792
train-epoch-step: 5-314 -- Loss: 0.2589910626411438
train-epoch-step: 5-315 -- Loss: 0.22076217830181122
train-epoch-step: 5-316 -- Loss: 0.19364486634731293
train-epoch-step: 5-317 -- Loss: 0.18503201007843018
train-epoch-step: 5-318 -- Loss: 0.2144167274236679
train-epoch-step: 5-319 -- Loss: 0.23292578756809235
train-epoch-step: 5-320 -- Loss: 0.1538516879081726
train-epoch-step: 5-321 -- Loss: 0.1843378245830536
train-epoch-step: 5-322 -- Loss: 0.2717965245246887
train-epoch-step: 5-323 -- Loss: 0.19854846596717834
train-epoch-step: 5-324 -- Loss: 0.34493276476860046
train-epoch-step: 5-325 -- Loss: 0.19346527755260468
train-epoch-step: 5-326 -- Loss: 0.24105097353458405
train-epoch-step: 5-327 -- Loss: 0.26979002356529236
train-epoch-step: 5-328 -- Loss: 0.254548579454422
train-epoch-step: 5-329 -- Loss: 0.435619592666626
train-epoch-step: 5-330 -- Loss: 0.47508537769317627
train-epoch-step: 5-331 -- Loss: 0.2919559180736542
train-epoch-step: 5-332 -- Loss: 0.1344858705997467
train-epoch-step: 5-333 -- Loss: 0.23788711428642273
train-epoch-step: 5-334 -- Loss: 0.19680872559547424
train-epoch-step: 5-335 -- Loss: 0.22984258830547333
train-epoch-step: 5-336 -- Loss: 0.21425139904022217
train-epoch-step: 5-337 -- Loss: 0.27618637681007385
train-epoch-step: 5-338 -- Loss: 0.21586298942565918
train-epoch-step: 5-339 -- Loss: 0.18549972772598267
train-epoch-step: 5-340 -- Loss: 0.2577472925186157
train-epoch-step: 5-341 -- Loss: 0.17597179114818573
train-epoch-step: 5-342 -- Loss: 0.21051166951656342
train-epoch-step: 5-343 -- Loss: 0.20148009061813354
train-epoch-step: 5-344 -- Loss: 0.21700389683246613
train-epoch-step: 5-345 -- Loss: 0.16447407007217407
train-epoch-step: 5-346 -- Loss: 0.24307286739349365
train-epoch-step: 5-347 -- Loss: 0.20930907130241394
train-epoch-step: 5-348 -- Loss: 0.26114189624786377
train-epoch-step: 5-349 -- Loss: 0.27559274435043335
train-epoch-step: 5-350 -- Loss: 0.3449224829673767
train-epoch-step: 5-351 -- Loss: 0.26622968912124634
train-epoch-step: 5-352 -- Loss: 0.1810101717710495
train-epoch-step: 5-353 -- Loss: 0.2506452202796936
train-epoch-step: 5-354 -- Loss: 0.3504214286804199
train-epoch-step: 5-355 -- Loss: 0.1546485722064972
train-epoch-step: 5-356 -- Loss: 0.15253625810146332
train-epoch-step: 5-357 -- Loss: 0.24040061235427856
train-epoch-step: 5-358 -- Loss: 0.233084574341774
train-epoch-step: 5-359 -- Loss: 0.18470919132232666
train-epoch-step: 5-360 -- Loss: 0.16873380541801453
train-epoch-step: 5-361 -- Loss: 0.32630664110183716
train-epoch-step: 5-362 -- Loss: 0.21510049700737
train-epoch-step: 5-363 -- Loss: 0.14991964399814606
train-epoch-step: 5-364 -- Loss: 0.2292557656764984
train-epoch-step: 5-365 -- Loss: 0.21635288000106812
train-epoch-step: 5-366 -- Loss: 0.2507965564727783
train-epoch-step: 5-367 -- Loss: 0.3578500747680664
train-epoch-step: 5-368 -- Loss: 0.26965129375457764
train-epoch-step: 5-369 -- Loss: 0.35402458906173706
train-epoch-step: 5-370 -- Loss: 0.17090263962745667
train-epoch-step: 5-371 -- Loss: 0.155495747923851
train-epoch-step: 5-372 -- Loss: 0.18565118312835693
train-epoch-step: 5-373 -- Loss: 0.2503669261932373
train-epoch-step: 5-374 -- Loss: 0.20563942193984985
train-epoch-step: 5-375 -- Loss: 0.3862268030643463
train-epoch-step: 5-376 -- Loss: 0.2727894186973572
train-epoch-step: 5-377 -- Loss: 0.3316529095172882
train-epoch-step: 5-378 -- Loss: 0.2763977348804474
train-epoch-step: 5-379 -- Loss: 0.15005192160606384
train-epoch-step: 5-380 -- Loss: 0.13249537348747253
train-epoch-step: 5-381 -- Loss: 0.32876890897750854
train-epoch-step: 5-382 -- Loss: 0.3082277178764343
train-epoch-step: 5-383 -- Loss: 0.24478138983249664
train-epoch-step: 5-384 -- Loss: 0.28662824630737305
train-epoch-step: 5-385 -- Loss: 0.2624779939651489
train-epoch-step: 5-386 -- Loss: 0.2695942521095276
train-epoch-step: 5-387 -- Loss: 0.2666609287261963
train-epoch-step: 5-388 -- Loss: 0.28920432925224304
train-epoch-step: 5-389 -- Loss: 0.2372322976589203
train-epoch-step: 5-390 -- Loss: 0.1854938119649887
train-epoch-step: 5-391 -- Loss: 0.18805968761444092
train-epoch-step: 5-392 -- Loss: 0.2377559244632721
train-epoch-step: 5-393 -- Loss: 0.20508641004562378
train-epoch-step: 5-394 -- Loss: 0.2979476749897003
train-epoch-step: 5-395 -- Loss: 0.20682206749916077
train-epoch-step: 5-396 -- Loss: 0.17057964205741882
train-epoch-step: 5-397 -- Loss: 0.1651647537946701
train-epoch-step: 5-398 -- Loss: 0.24646002054214478
train-epoch-step: 5-399 -- Loss: 0.23292699456214905
train-epoch-step: 5-400 -- Loss: 0.3648105263710022
train-epoch-step: 5-401 -- Loss: 0.15292587876319885
train-epoch-step: 5-402 -- Loss: 0.3287273347377777
train-epoch-step: 5-403 -- Loss: 0.2218203842639923
train-epoch-step: 5-404 -- Loss: 0.18596690893173218
train-epoch-step: 5-405 -- Loss: 0.1888500154018402
train-epoch-step: 5-406 -- Loss: 0.20771998167037964
train-epoch-step: 5-407 -- Loss: 0.14469245076179504
train-epoch-step: 5-408 -- Loss: 0.2045166790485382
train-epoch-step: 5-409 -- Loss: 0.22920024394989014
train-epoch-step: 5-410 -- Loss: 0.24040307104587555
train-epoch-step: 5-411 -- Loss: 0.25475722551345825
train-epoch-step: 5-412 -- Loss: 0.15999963879585266
train-epoch-step: 5-413 -- Loss: 0.18451620638370514
train-epoch-step: 5-414 -- Loss: 0.17737257480621338
train-epoch-step: 5-415 -- Loss: 0.17511527240276337
train-epoch-step: 5-416 -- Loss: 0.33787092566490173
train-epoch-step: 5-417 -- Loss: 0.25696107745170593
train-epoch-step: 5-418 -- Loss: 0.3014657199382782
train-epoch-step: 5-419 -- Loss: 0.22018170356750488
train-epoch-step: 5-420 -- Loss: 0.20013639330863953
train-epoch-step: 5-421 -- Loss: 0.24065259099006653
train-epoch-step: 5-422 -- Loss: 0.18972517549991608
train-epoch-step: 5-423 -- Loss: 0.2218729853630066
train-epoch-step: 5-424 -- Loss: 0.1721997708082199
train-epoch-step: 5-425 -- Loss: 0.2395927757024765
train-epoch-step: 5-426 -- Loss: 0.21517238020896912
train-epoch-step: 5-427 -- Loss: 0.19013184309005737
train-epoch-step: 5-428 -- Loss: 0.27779287099838257
train-epoch-step: 5-429 -- Loss: 0.23522675037384033
train-epoch-step: 5-430 -- Loss: 0.1792343556880951
train-epoch-step: 5-431 -- Loss: 0.22012972831726074
train-epoch-step: 5-432 -- Loss: 0.3036835193634033
train-epoch-step: 5-433 -- Loss: 0.1828172355890274
train-epoch-step: 5-434 -- Loss: 0.1727096140384674
train-epoch-step: 5-435 -- Loss: 0.20340612530708313
train-epoch-step: 5-436 -- Loss: 0.1961716264486313
train-epoch-step: 5-437 -- Loss: 0.17682938277721405
train-epoch-step: 5-438 -- Loss: 0.22866441309452057
train-epoch-step: 5-439 -- Loss: 0.37957531213760376
train-epoch-step: 5-440 -- Loss: 0.17638316750526428
train-epoch-step: 5-441 -- Loss: 0.2859392762184143
train-epoch-step: 5-442 -- Loss: 0.24664458632469177
train-epoch-step: 5-443 -- Loss: 0.20291391015052795
train-epoch-step: 5-444 -- Loss: 0.31483566761016846
train-epoch-step: 5-445 -- Loss: 0.2329019010066986
train-epoch-step: 5-446 -- Loss: 0.20280218124389648
train-epoch-step: 5-447 -- Loss: 0.2696731686592102
train-epoch-step: 5-448 -- Loss: 0.3242480158805847
train-epoch-step: 5-449 -- Loss: 0.25130972266197205
train-epoch-step: 5-450 -- Loss: 0.24488401412963867
train-epoch-step: 5-451 -- Loss: 0.18375526368618011
train-epoch-step: 5-452 -- Loss: 0.1702566146850586
train-epoch-step: 5-453 -- Loss: 0.126141756772995
train-epoch-step: 5-454 -- Loss: 0.31053781509399414
train-epoch-step: 5-455 -- Loss: 0.1752200424671173
train-epoch-step: 5-456 -- Loss: 0.15894252061843872
train-epoch-step: 5-457 -- Loss: 0.2805302143096924
train-epoch-step: 5-458 -- Loss: 0.20586010813713074
train-epoch-step: 5-459 -- Loss: 0.281438410282135
train-epoch-step: 5-460 -- Loss: 0.15842612087726593
train-epoch-step: 5-461 -- Loss: 0.18666216731071472
train-epoch-step: 5-462 -- Loss: 0.19413317739963531
train-epoch-step: 5-463 -- Loss: 0.1811196506023407
train-epoch-step: 5-464 -- Loss: 0.23825787007808685
train-epoch-step: 5-465 -- Loss: 0.33532053232192993
train-epoch-step: 5-466 -- Loss: 0.25072962045669556
train-epoch-step: 5-467 -- Loss: 0.14604917168617249
train-epoch-step: 5-468 -- Loss: 0.2561788558959961
train-epoch-step: 5-469 -- Loss: 0.3397144079208374
train-epoch-step: 5-470 -- Loss: 0.23035813868045807
train-epoch-step: 5-471 -- Loss: 0.20291757583618164
train-epoch-step: 5-472 -- Loss: 0.2036670744419098
train-epoch-step: 5-473 -- Loss: 0.21548902988433838
train-epoch-step: 5-474 -- Loss: 0.15717560052871704
train-epoch-step: 5-475 -- Loss: 0.14006534218788147
train-epoch-step: 5-476 -- Loss: 0.2489852011203766
train-epoch-step: 5-477 -- Loss: 0.2882992625236511
train-epoch-step: 5-478 -- Loss: 0.24099045991897583
train-epoch-step: 5-479 -- Loss: 0.18156841397285461
train-epoch-step: 5-480 -- Loss: 0.2458311915397644
train-epoch-step: 5-481 -- Loss: 0.3539555072784424
train-epoch-step: 5-482 -- Loss: 0.33358675241470337
train-epoch-step: 5-483 -- Loss: 0.2553119361400604
train-epoch-step: 5-484 -- Loss: 0.266415536403656
train-epoch-step: 5-485 -- Loss: 0.16719910502433777
train-epoch-step: 5-486 -- Loss: 0.3473445177078247
train-epoch-step: 5-487 -- Loss: 0.2835724651813507
train-epoch-step: 5-488 -- Loss: 0.2402595430612564
train-epoch-step: 5-489 -- Loss: 0.27250927686691284
train-epoch-step: 5-490 -- Loss: 0.17912273108959198
train-epoch-step: 5-491 -- Loss: 0.1727273166179657
train-epoch-step: 5-492 -- Loss: 0.1607922911643982
train-epoch-step: 5-493 -- Loss: 0.2826522886753082
train-epoch-step: 5-494 -- Loss: 0.27531862258911133
train-epoch-step: 5-495 -- Loss: 0.25969165563583374
train-epoch-step: 5-496 -- Loss: 0.1745605170726776
train-epoch-step: 5-497 -- Loss: 0.24672862887382507
train-epoch-step: 5-498 -- Loss: 0.1865052580833435
train-epoch-step: 5-499 -- Loss: 0.2128223180770874
train-epoch-step: 5-500 -- Loss: 0.19954761862754822
train-epoch-step: 5-501 -- Loss: 0.28048649430274963
train-epoch-step: 5-502 -- Loss: 0.21009844541549683
train-epoch-step: 5-503 -- Loss: 0.2779187858104706
train-epoch-step: 5-504 -- Loss: 0.1513015180826187
train-epoch-step: 5-505 -- Loss: 0.22819939255714417
train-epoch-step: 5-506 -- Loss: 0.15023493766784668
train-epoch-step: 5-507 -- Loss: 0.22661074995994568
train-epoch-step: 5-508 -- Loss: 0.21883660554885864
train-epoch-step: 5-509 -- Loss: 0.21586981415748596
train-epoch-step: 5-510 -- Loss: 0.17604674398899078
train-epoch-step: 5-511 -- Loss: 0.26867496967315674
train-epoch-step: 5-512 -- Loss: 0.233597069978714
train-epoch-step: 5-513 -- Loss: 0.25682443380355835
train-epoch-step: 5-514 -- Loss: 0.19235514104366302
train-epoch-step: 5-515 -- Loss: 0.21015805006027222
train-epoch-step: 5-516 -- Loss: 0.21585425734519958
train-epoch-step: 5-517 -- Loss: 0.2377660572528839
train-epoch-step: 5-518 -- Loss: 0.17303982377052307
train-epoch-step: 5-519 -- Loss: 0.17035794258117676
train-epoch-step: 5-520 -- Loss: 0.23971593379974365
train-epoch-step: 5-521 -- Loss: 0.28842151165008545
train-epoch-step: 5-522 -- Loss: 0.2245454639196396
train-epoch-step: 5-523 -- Loss: 0.20526042580604553
train-epoch-step: 5-524 -- Loss: 0.20912641286849976
train-epoch-step: 5-525 -- Loss: 0.2396293431520462
train-epoch-step: 5-526 -- Loss: 0.16452474892139435
train-epoch-step: 5-527 -- Loss: 0.21460387110710144
train-epoch-step: 5-528 -- Loss: 0.2063697874546051
train-epoch-step: 5-529 -- Loss: 0.2264798879623413
train-epoch-step: 5-530 -- Loss: 0.21886283159255981
train-epoch-step: 5-531 -- Loss: 0.2567635774612427
train-epoch-step: 5-532 -- Loss: 0.21841168403625488
train-epoch-step: 5-533 -- Loss: 0.2105010449886322
train-epoch-step: 5-534 -- Loss: 0.16811275482177734
train-epoch-step: 5-535 -- Loss: 0.360198050737381
train-epoch-step: 5-536 -- Loss: 0.20038717985153198
train-epoch-step: 5-537 -- Loss: 0.19205430150032043
train-epoch-step: 5-538 -- Loss: 0.13139896094799042
train-epoch-step: 5-539 -- Loss: 0.24804481863975525
train-epoch-step: 5-540 -- Loss: 0.16883967816829681
train-epoch-step: 5-541 -- Loss: 0.2667437791824341
train-epoch-step: 5-542 -- Loss: 0.3037923574447632
train-epoch-step: 5-543 -- Loss: 0.2079666256904602
train-epoch-step: 5-544 -- Loss: 0.277680903673172
train-epoch-step: 5-545 -- Loss: 0.24246391654014587
train-epoch-step: 5-546 -- Loss: 0.284376323223114
train-epoch-step: 5-547 -- Loss: 0.22154420614242554
train-epoch-step: 5-548 -- Loss: 0.11522728949785233
train-epoch-step: 5-549 -- Loss: 0.20215024054050446
train-epoch-step: 5-550 -- Loss: 0.25435754656791687
train-epoch-step: 5-551 -- Loss: 0.20562872290611267
train-epoch-step: 5-552 -- Loss: 0.1620340198278427
train-epoch-step: 5-553 -- Loss: 0.2383594512939453
train-epoch-step: 5-554 -- Loss: 0.23266208171844482
train-epoch-step: 5-555 -- Loss: 0.27184224128723145
train-epoch-step: 5-556 -- Loss: 0.22221894562244415
train-epoch-step: 5-557 -- Loss: 0.29818493127822876
train-epoch-step: 5-558 -- Loss: 0.29119402170181274
train-epoch-step: 5-559 -- Loss: 0.18798916041851044
train-epoch-step: 5-560 -- Loss: 0.2563020884990692
train-epoch-step: 5-561 -- Loss: 0.24357621371746063
train-epoch-step: 5-562 -- Loss: 0.25079604983329773
train-epoch-step: 5-563 -- Loss: 0.24344153702259064
train-epoch-step: 5-564 -- Loss: 0.13380196690559387
train-epoch-step: 5-565 -- Loss: 0.22909745573997498
train-epoch-step: 5-566 -- Loss: 0.20358417928218842
train-epoch-step: 5-567 -- Loss: 0.25845205783843994
train-epoch-step: 5-568 -- Loss: 0.19204360246658325
train-epoch-step: 5-569 -- Loss: 0.2931625545024872
train-epoch-step: 5-570 -- Loss: 0.2287139743566513
train-epoch-step: 5-571 -- Loss: 0.271043986082077
train-epoch-step: 5-572 -- Loss: 0.3088100850582123
train-epoch-step: 5-573 -- Loss: 0.2677565813064575
train-epoch-step: 5-574 -- Loss: 0.328925758600235
train-epoch-step: 5-575 -- Loss: 0.4041154980659485
train-epoch-step: 5-576 -- Loss: 0.1596418172121048
train-epoch-step: 5-577 -- Loss: 0.21487373113632202
train-epoch-step: 5-578 -- Loss: 0.29528844356536865
train-epoch-step: 5-579 -- Loss: 0.21752360463142395
train-epoch-step: 5-580 -- Loss: 0.25353795289993286
train-epoch-step: 5-581 -- Loss: 0.1776362657546997
train-epoch-step: 5-582 -- Loss: 0.2769591808319092
train-epoch-step: 5-583 -- Loss: 0.2990434169769287
train-epoch-step: 5-584 -- Loss: 0.25339046120643616
train-epoch-step: 5-585 -- Loss: 0.241560161113739
train-epoch-step: 5-586 -- Loss: 0.3437134027481079
train-epoch-step: 5-587 -- Loss: 0.20101076364517212
train-epoch-step: 5-588 -- Loss: 0.1615385264158249
val-epoch-step: 5-589 -- Loss: 0.282157301902771
val-epoch-step: 5-590 -- Loss: 0.18447448313236237
val-epoch-step: 5-591 -- Loss: 0.26850321888923645
val-epoch-step: 5-592 -- Loss: 0.21999922394752502
val-epoch-step: 5-593 -- Loss: 0.17991074919700623
val-epoch-step: 5-594 -- Loss: 0.3869823217391968
val-epoch-step: 5-595 -- Loss: 0.21761232614517212
val-epoch-step: 5-596 -- Loss: 0.2537260353565216
val-epoch-step: 5-597 -- Loss: 0.2220556139945984
val-epoch-step: 5-598 -- Loss: 0.19104090332984924
val-epoch-step: 5-599 -- Loss: 0.22589504718780518
val-epoch-step: 5-600 -- Loss: 0.22064073383808136
val-epoch-step: 5-601 -- Loss: 0.18481215834617615
val-epoch-step: 5-602 -- Loss: 0.17359837889671326
val-epoch-step: 5-603 -- Loss: 0.22049474716186523
val-epoch-step: 5-604 -- Loss: 0.1791439950466156
val-epoch-step: 5-605 -- Loss: 0.1841837465763092
val-epoch-step: 5-606 -- Loss: 0.35061854124069214
val-epoch-step: 5-607 -- Loss: 0.16766010224819183
val-epoch-step: 5-608 -- Loss: 0.3023189902305603
val-epoch-step: 5-609 -- Loss: 0.21757830679416656
val-epoch-step: 5-610 -- Loss: 0.23838278651237488
val-epoch-step: 5-611 -- Loss: 0.20171239972114563
val-epoch-step: 5-612 -- Loss: 0.3745456337928772
val-epoch-step: 5-613 -- Loss: 0.22475959360599518
val-epoch-step: 5-614 -- Loss: 0.19697563350200653
val-epoch-step: 5-615 -- Loss: 0.23731976747512817
val-epoch-step: 5-616 -- Loss: 0.18227940797805786
val-epoch-step: 5-617 -- Loss: 0.24778103828430176
val-epoch-step: 5-618 -- Loss: 0.24127496778964996
val-epoch-step: 5-619 -- Loss: 0.2644140124320984
val-epoch-step: 5-620 -- Loss: 0.177140474319458
val-epoch-step: 5-621 -- Loss: 0.17484652996063232
val-epoch-step: 5-622 -- Loss: 0.1778622269630432
val-epoch-step: 5-623 -- Loss: 0.18450121581554413
val-epoch-step: 5-624 -- Loss: 0.20972052216529846
val-epoch-step: 5-625 -- Loss: 0.1905435472726822
val-epoch-step: 5-626 -- Loss: 0.1866401582956314
val-epoch-step: 5-627 -- Loss: 0.242935448884964
val-epoch-step: 5-628 -- Loss: 0.4969302713871002
val-epoch-step: 5-629 -- Loss: 0.25278693437576294
val-epoch-step: 5-630 -- Loss: 0.4109622538089752
val-epoch-step: 5-631 -- Loss: 0.17744168639183044
val-epoch-step: 5-632 -- Loss: 0.2479848861694336
val-epoch-step: 5-633 -- Loss: 0.19346417486667633
val-epoch-step: 5-634 -- Loss: 0.17594553530216217
val-epoch-step: 5-635 -- Loss: 0.14190399646759033
val-epoch-step: 5-636 -- Loss: 0.2088315486907959
val-epoch-step: 5-637 -- Loss: 0.224422425031662
val-epoch-step: 5-638 -- Loss: 0.1905170977115631
val-epoch-step: 5-639 -- Loss: 0.32256338000297546
val-epoch-step: 5-640 -- Loss: 0.30646631121635437
val-epoch-step: 5-641 -- Loss: 0.15283018350601196
val-epoch-step: 5-642 -- Loss: 0.2485833317041397
val-epoch-step: 5-643 -- Loss: 0.2452334761619568
val-epoch-step: 5-644 -- Loss: 0.19705578684806824
val-epoch-step: 5-645 -- Loss: 0.27074381709098816
val-epoch-step: 5-646 -- Loss: 0.17916998267173767
val-epoch-step: 5-647 -- Loss: 0.17029714584350586
val-epoch-step: 5-648 -- Loss: 0.1978933960199356
val-epoch-step: 5-649 -- Loss: 0.27565842866897583
val-epoch-step: 5-650 -- Loss: 0.31192803382873535
val-epoch-step: 5-651 -- Loss: 0.17335715889930725
val-epoch-step: 5-652 -- Loss: 0.19483941793441772
val-epoch-step: 5-653 -- Loss: 0.246498242020607
val-epoch-step: 5-654 -- Loss: 0.13717854022979736
Epoch: 5 -- Train Loss: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1592, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 6-0 -- Loss: 0.2786642909049988
train-epoch-step: 6-1 -- Loss: 0.18072819709777832
train-epoch-step: 6-2 -- Loss: 0.2482834756374359
train-epoch-step: 6-3 -- Loss: 0.18663689494132996
train-epoch-step: 6-4 -- Loss: 0.24953033030033112
train-epoch-step: 6-5 -- Loss: 0.24092893302440643
train-epoch-step: 6-6 -- Loss: 0.3029116988182068
train-epoch-step: 6-7 -- Loss: 0.2204718440771103
train-epoch-step: 6-8 -- Loss: 0.24043238162994385
train-epoch-step: 6-9 -- Loss: 0.3472197651863098
train-epoch-step: 6-10 -- Loss: 0.309888631105423
train-epoch-step: 6-11 -- Loss: 0.23150399327278137
train-epoch-step: 6-12 -- Loss: 0.19630831480026245
train-epoch-step: 6-13 -- Loss: 0.24213480949401855
train-epoch-step: 6-14 -- Loss: 0.19871026277542114
train-epoch-step: 6-15 -- Loss: 0.20084378123283386
train-epoch-step: 6-16 -- Loss: 0.21809935569763184
train-epoch-step: 6-17 -- Loss: 0.27985087037086487
train-epoch-step: 6-18 -- Loss: 0.2351711094379425
train-epoch-step: 6-19 -- Loss: 0.16943484544754028
train-epoch-step: 6-20 -- Loss: 0.2869020700454712
train-epoch-step: 6-21 -- Loss: 0.4224105477333069
train-epoch-step: 6-22 -- Loss: 0.19316136837005615
train-epoch-step: 6-23 -- Loss: 0.23593677580356598
train-epoch-step: 6-24 -- Loss: 0.1630309671163559
train-epoch-step: 6-25 -- Loss: 0.27796101570129395
train-epoch-step: 6-26 -- Loss: 0.2522204518318176
train-epoch-step: 6-27 -- Loss: 0.3178812265396118
train-epoch-step: 6-28 -- Loss: 0.1582653969526291
train-epoch-step: 6-29 -- Loss: 0.3016982972621918
train-epoch-step: 6-30 -- Loss: 0.1394454836845398
train-epoch-step: 6-31 -- Loss: 0.18500816822052002
train-epoch-step: 6-32 -- Loss: 0.2188769280910492
train-epoch-step: 6-33 -- Loss: 0.3403056859970093
train-epoch-step: 6-34 -- Loss: 0.2140800654888153
train-epoch-step: 6-35 -- Loss: 0.3106960952281952
train-epoch-step: 6-36 -- Loss: 0.17646266520023346
train-epoch-step: 6-37 -- Loss: 0.1908484697341919
train-epoch-step: 6-38 -- Loss: 0.2547299861907959
train-epoch-step: 6-39 -- Loss: 0.29831159114837646
train-epoch-step: 6-40 -- Loss: 0.2686512768268585
train-epoch-step: 6-41 -- Loss: 0.26295366883277893
train-epoch-step: 6-42 -- Loss: 0.1905338168144226
train-epoch-step: 6-43 -- Loss: 0.3565172255039215
train-epoch-step: 6-44 -- Loss: 0.16345307230949402
train-epoch-step: 6-45 -- Loss: 0.15786081552505493
train-epoch-step: 6-46 -- Loss: 0.2184397429227829
train-epoch-step: 6-47 -- Loss: 0.29374876618385315
train-epoch-step: 6-48 -- Loss: 0.19031642377376556
train-epoch-step: 6-49 -- Loss: 0.271756112575531
train-epoch-step: 6-50 -- Loss: 0.15061673521995544
train-epoch-step: 6-51 -- Loss: 0.23664721846580505
train-epoch-step: 6-52 -- Loss: 0.1975715607404709
train-epoch-step: 6-53 -- Loss: 0.2818526029586792
train-epoch-step: 6-54 -- Loss: 0.3585691452026367
train-epoch-step: 6-55 -- Loss: 0.21084947884082794
train-epoch-step: 6-56 -- Loss: 0.24041607975959778
train-epoch-step: 6-57 -- Loss: 0.28389033675193787
train-epoch-step: 6-58 -- Loss: 0.3450309932231903
train-epoch-step: 6-59 -- Loss: 0.32711464166641235
train-epoch-step: 6-60 -- Loss: 0.16242791712284088
train-epoch-step: 6-61 -- Loss: 0.2773025929927826
train-epoch-step: 6-62 -- Loss: 0.2348598688840866
train-epoch-step: 6-63 -- Loss: 0.1736065149307251
train-epoch-step: 6-64 -- Loss: 0.20050708949565887
train-epoch-step: 6-65 -- Loss: 0.23854589462280273
train-epoch-step: 6-66 -- Loss: 0.14013594388961792
train-epoch-step: 6-67 -- Loss: 0.15929938852787018
train-epoch-step: 6-68 -- Loss: 0.2960621118545532
train-epoch-step: 6-69 -- Loss: 0.17357034981250763
train-epoch-step: 6-70 -- Loss: 0.27275165915489197
train-epoch-step: 6-71 -- Loss: 0.31210875511169434
train-epoch-step: 6-72 -- Loss: 0.2273920476436615
train-epoch-step: 6-73 -- Loss: 0.2635071873664856
train-epoch-step: 6-74 -- Loss: 0.12304919958114624
train-epoch-step: 6-75 -- Loss: 0.17692814767360687
train-epoch-step: 6-76 -- Loss: 0.1873738169670105
train-epoch-step: 6-77 -- Loss: 0.28073030710220337
train-epoch-step: 6-78 -- Loss: 0.3642734885215759
train-epoch-step: 6-79 -- Loss: 0.24535326659679413
train-epoch-step: 6-80 -- Loss: 0.38057941198349
train-epoch-step: 6-81 -- Loss: 0.16301082074642181
train-epoch-step: 6-82 -- Loss: 0.3063335418701172
train-epoch-step: 6-83 -- Loss: 0.23222990334033966
train-epoch-step: 6-84 -- Loss: 0.2609959542751312
train-epoch-step: 6-85 -- Loss: 0.22900424897670746
train-epoch-step: 6-86 -- Loss: 0.15919256210327148
train-epoch-step: 6-87 -- Loss: 0.301910936832428
train-epoch-step: 6-88 -- Loss: 0.1785372793674469
train-epoch-step: 6-89 -- Loss: 0.24745336174964905
train-epoch-step: 6-90 -- Loss: 0.24456025660037994
train-epoch-step: 6-91 -- Loss: 0.30694305896759033
train-epoch-step: 6-92 -- Loss: 0.2041124701499939
train-epoch-step: 6-93 -- Loss: 0.26056885719299316
train-epoch-step: 6-94 -- Loss: 0.30681467056274414
train-epoch-step: 6-95 -- Loss: 0.24887730181217194
train-epoch-step: 6-96 -- Loss: 0.29654932022094727
train-epoch-step: 6-97 -- Loss: 0.24686077237129211
train-epoch-step: 6-98 -- Loss: 0.2088511735200882
train-epoch-step: 6-99 -- Loss: 0.23602740466594696
train-epoch-step: 6-100 -- Loss: 0.24338199198246002
train-epoch-step: 6-101 -- Loss: 0.3268130421638489
train-epoch-step: 6-102 -- Loss: 0.29834863543510437
train-epoch-step: 6-103 -- Loss: 0.2558920383453369
train-epoch-step: 6-104 -- Loss: 0.19394421577453613
train-epoch-step: 6-105 -- Loss: 0.35794132947921753
train-epoch-step: 6-106 -- Loss: 0.2338346391916275
train-epoch-step: 6-107 -- Loss: 0.2434084117412567
train-epoch-step: 6-108 -- Loss: 0.23467038571834564
train-epoch-step: 6-109 -- Loss: 0.18965114653110504
train-epoch-step: 6-110 -- Loss: 0.23047885298728943
train-epoch-step: 6-111 -- Loss: 0.23208414018154144
train-epoch-step: 6-112 -- Loss: 0.21825836598873138
train-epoch-step: 6-113 -- Loss: 0.21898473799228668
train-epoch-step: 6-114 -- Loss: 0.3131496012210846
train-epoch-step: 6-115 -- Loss: 0.21309725940227509
train-epoch-step: 6-116 -- Loss: 0.19423744082450867
train-epoch-step: 6-117 -- Loss: 0.16448929905891418
train-epoch-step: 6-118 -- Loss: 0.2561282515525818
train-epoch-step: 6-119 -- Loss: 0.19521136581897736
train-epoch-step: 6-120 -- Loss: 0.34448912739753723
train-epoch-step: 6-121 -- Loss: 0.34664350748062134
train-epoch-step: 6-122 -- Loss: 0.27108198404312134
train-epoch-step: 6-123 -- Loss: 0.26729536056518555
train-epoch-step: 6-124 -- Loss: 0.15376392006874084
train-epoch-step: 6-125 -- Loss: 0.19774794578552246
train-epoch-step: 6-126 -- Loss: 0.31202125549316406
train-epoch-step: 6-127 -- Loss: 0.21907971799373627
train-epoch-step: 6-128 -- Loss: 0.22203247249126434
train-epoch-step: 6-129 -- Loss: 0.17755940556526184
train-epoch-step: 6-130 -- Loss: 0.24423927068710327
train-epoch-step: 6-131 -- Loss: 0.1757911890745163
train-epoch-step: 6-132 -- Loss: 0.25449803471565247
train-epoch-step: 6-133 -- Loss: 0.14841577410697937
train-epoch-step: 6-134 -- Loss: 0.25210994482040405
train-epoch-step: 6-135 -- Loss: 0.17010627686977386
train-epoch-step: 6-136 -- Loss: 0.1614341139793396
train-epoch-step: 6-137 -- Loss: 0.3271384835243225
train-epoch-step: 6-138 -- Loss: 0.33452287316322327
train-epoch-step: 6-139 -- Loss: 0.16721202433109283
train-epoch-step: 6-140 -- Loss: 0.2586975395679474
train-epoch-step: 6-141 -- Loss: 0.3009180426597595
train-epoch-step: 6-142 -- Loss: 0.2611308693885803
train-epoch-step: 6-143 -- Loss: 0.20991405844688416
train-epoch-step: 6-144 -- Loss: 0.24802984297275543
train-epoch-step: 6-145 -- Loss: 0.17351330816745758
train-epoch-step: 6-146 -- Loss: 0.22756806015968323
train-epoch-step: 6-147 -- Loss: 0.2341570407152176
train-epoch-step: 6-148 -- Loss: 0.22195804119110107
train-epoch-step: 6-149 -- Loss: 0.1495373398065567
train-epoch-step: 6-150 -- Loss: 0.24113604426383972
train-epoch-step: 6-151 -- Loss: 0.23199127614498138
train-epoch-step: 6-152 -- Loss: 0.24368339776992798
train-epoch-step: 6-153 -- Loss: 0.3878791332244873
train-epoch-step: 6-154 -- Loss: 0.16943661868572235
train-epoch-step: 6-155 -- Loss: 0.18238095939159393
train-epoch-step: 6-156 -- Loss: 0.1604594588279724
train-epoch-step: 6-157 -- Loss: 0.21248796582221985
train-epoch-step: 6-158 -- Loss: 0.21291719377040863
train-epoch-step: 6-159 -- Loss: 0.2163282036781311
train-epoch-step: 6-160 -- Loss: 0.28029537200927734
train-epoch-step: 6-161 -- Loss: 0.26954638957977295
train-epoch-step: 6-162 -- Loss: 0.26805582642555237
train-epoch-step: 6-163 -- Loss: 0.23499968647956848
train-epoch-step: 6-164 -- Loss: 0.2362678200006485
train-epoch-step: 6-165 -- Loss: 0.21295210719108582
train-epoch-step: 6-166 -- Loss: 0.15144169330596924
train-epoch-step: 6-167 -- Loss: 0.15294867753982544
train-epoch-step: 6-168 -- Loss: 0.26510512828826904
train-epoch-step: 6-169 -- Loss: 0.1790115088224411
train-epoch-step: 6-170 -- Loss: 0.2690236568450928
train-epoch-step: 6-171 -- Loss: 0.17958350479602814
train-epoch-step: 6-172 -- Loss: 0.3264593183994293
train-epoch-step: 6-173 -- Loss: 0.16313661634922028
train-epoch-step: 6-174 -- Loss: 0.29961955547332764
train-epoch-step: 6-175 -- Loss: 0.23458029329776764
train-epoch-step: 6-176 -- Loss: 0.16865983605384827
train-epoch-step: 6-177 -- Loss: 0.233609139919281
train-epoch-step: 6-178 -- Loss: 0.24160447716712952
train-epoch-step: 6-179 -- Loss: 0.17722025513648987
train-epoch-step: 6-180 -- Loss: 0.18553906679153442
train-epoch-step: 6-181 -- Loss: 0.2220415472984314
train-epoch-step: 6-182 -- Loss: 0.24495075643062592
train-epoch-step: 6-183 -- Loss: 0.3455085754394531
train-epoch-step: 6-184 -- Loss: 0.17631876468658447
train-epoch-step: 6-185 -- Loss: 0.18327146768569946
train-epoch-step: 6-186 -- Loss: 0.2491738647222519
train-epoch-step: 6-187 -- Loss: 0.2757682204246521
train-epoch-step: 6-188 -- Loss: 0.2235429286956787
train-epoch-step: 6-189 -- Loss: 0.17102877795696259
train-epoch-step: 6-190 -- Loss: 0.22409993410110474
train-epoch-step: 6-191 -- Loss: 0.22663986682891846
train-epoch-step: 6-192 -- Loss: 0.3024923503398895
train-epoch-step: 6-193 -- Loss: 0.28767603635787964
train-epoch-step: 6-194 -- Loss: 0.2323078066110611
train-epoch-step: 6-195 -- Loss: 0.20441189408302307
train-epoch-step: 6-196 -- Loss: 0.22267712652683258
train-epoch-step: 6-197 -- Loss: 0.16204477846622467
train-epoch-step: 6-198 -- Loss: 0.1669125109910965
train-epoch-step: 6-199 -- Loss: 0.19279740750789642
train-epoch-step: 6-200 -- Loss: 0.16017001867294312
train-epoch-step: 6-201 -- Loss: 0.24933676421642303
train-epoch-step: 6-202 -- Loss: 0.1732570081949234
train-epoch-step: 6-203 -- Loss: 0.22859126329421997
train-epoch-step: 6-204 -- Loss: 0.18832258880138397
train-epoch-step: 6-205 -- Loss: 0.2296636998653412
train-epoch-step: 6-206 -- Loss: 0.2514268159866333
train-epoch-step: 6-207 -- Loss: 0.1741546094417572
train-epoch-step: 6-208 -- Loss: 0.2195451855659485
train-epoch-step: 6-209 -- Loss: 0.18093933165073395
train-epoch-step: 6-210 -- Loss: 0.17030282318592072
train-epoch-step: 6-211 -- Loss: 0.2593165636062622
train-epoch-step: 6-212 -- Loss: 0.25165045261383057
train-epoch-step: 6-213 -- Loss: 0.16317203640937805
train-epoch-step: 6-214 -- Loss: 0.1934533417224884
train-epoch-step: 6-215 -- Loss: 0.1748703122138977
train-epoch-step: 6-216 -- Loss: 0.24893316626548767
train-epoch-step: 6-217 -- Loss: 0.26900404691696167
train-epoch-step: 6-218 -- Loss: 0.19993558526039124
train-epoch-step: 6-219 -- Loss: 0.2586982548236847
train-epoch-step: 6-220 -- Loss: 0.16569934785366058
train-epoch-step: 6-221 -- Loss: 0.26862087845802307
train-epoch-step: 6-222 -- Loss: 0.1575690656900406
train-epoch-step: 6-223 -- Loss: 0.21786537766456604
train-epoch-step: 6-224 -- Loss: 0.2334006279706955
train-epoch-step: 6-225 -- Loss: 0.38756465911865234
train-epoch-step: 6-226 -- Loss: 0.2763737440109253
train-epoch-step: 6-227 -- Loss: 0.30259138345718384
train-epoch-step: 6-228 -- Loss: 0.22401589155197144
train-epoch-step: 6-229 -- Loss: 0.24732929468154907
train-epoch-step: 6-230 -- Loss: 0.2050572633743286
train-epoch-step: 6-231 -- Loss: 0.23334935307502747
train-epoch-step: 6-232 -- Loss: 0.2520190477371216
train-epoch-step: 6-233 -- Loss: 0.1107492446899414
train-epoch-step: 6-234 -- Loss: 0.22497817873954773
train-epoch-step: 6-235 -- Loss: 0.20260807871818542
train-epoch-step: 6-236 -- Loss: 0.2148532271385193
train-epoch-step: 6-237 -- Loss: 0.3150154650211334
train-epoch-step: 6-238 -- Loss: 0.19921964406967163
train-epoch-step: 6-239 -- Loss: 0.17179125547409058
train-epoch-step: 6-240 -- Loss: 0.27321934700012207
train-epoch-step: 6-241 -- Loss: 0.19683793187141418
train-epoch-step: 6-242 -- Loss: 0.28512081503868103
train-epoch-step: 6-243 -- Loss: 0.2909072935581207
train-epoch-step: 6-244 -- Loss: 0.26068997383117676
train-epoch-step: 6-245 -- Loss: 0.301586389541626
train-epoch-step: 6-246 -- Loss: 0.362138956785202
train-epoch-step: 6-247 -- Loss: 0.2950143814086914
train-epoch-step: 6-248 -- Loss: 0.23405827581882477
train-epoch-step: 6-249 -- Loss: 0.18195867538452148
train-epoch-step: 6-250 -- Loss: 0.26701730489730835
train-epoch-step: 6-251 -- Loss: 0.14172221720218658
train-epoch-step: 6-252 -- Loss: 0.24993562698364258
train-epoch-step: 6-253 -- Loss: 0.17488640546798706
train-epoch-step: 6-254 -- Loss: 0.30130255222320557
train-epoch-step: 6-255 -- Loss: 0.1832663118839264
train-epoch-step: 6-256 -- Loss: 0.19572100043296814
train-epoch-step: 6-257 -- Loss: 0.24054458737373352
train-epoch-step: 6-258 -- Loss: 0.20469944179058075
train-epoch-step: 6-259 -- Loss: 0.15463364124298096
train-epoch-step: 6-260 -- Loss: 0.26875731348991394
train-epoch-step: 6-261 -- Loss: 0.2208675742149353
train-epoch-step: 6-262 -- Loss: 0.3902830183506012
train-epoch-step: 6-263 -- Loss: 0.27601003646850586
train-epoch-step: 6-264 -- Loss: 0.21323922276496887
train-epoch-step: 6-265 -- Loss: 0.1401764154434204
train-epoch-step: 6-266 -- Loss: 0.19005686044692993
train-epoch-step: 6-267 -- Loss: 0.18314749002456665
train-epoch-step: 6-268 -- Loss: 0.15282173454761505
train-epoch-step: 6-269 -- Loss: 0.2214180827140808
train-epoch-step: 6-270 -- Loss: 0.13747937977313995
train-epoch-step: 6-271 -- Loss: 0.18871521949768066
train-epoch-step: 6-272 -- Loss: 0.15147250890731812
train-epoch-step: 6-273 -- Loss: 0.16325391829013824
train-epoch-step: 6-274 -- Loss: 0.23576532304286957
train-epoch-step: 6-275 -- Loss: 0.2555919289588928
train-epoch-step: 6-276 -- Loss: 0.19534356892108917
train-epoch-step: 6-277 -- Loss: 0.19375869631767273
train-epoch-step: 6-278 -- Loss: 0.18544334173202515
train-epoch-step: 6-279 -- Loss: 0.1837625652551651
train-epoch-step: 6-280 -- Loss: 0.2699902653694153
train-epoch-step: 6-281 -- Loss: 0.2284873127937317
train-epoch-step: 6-282 -- Loss: 0.1738343983888626
train-epoch-step: 6-283 -- Loss: 0.14213579893112183
train-epoch-step: 6-284 -- Loss: 0.3041989803314209
train-epoch-step: 6-285 -- Loss: 0.24222567677497864
train-epoch-step: 6-286 -- Loss: 0.19957703351974487
train-epoch-step: 6-287 -- Loss: 0.2566564977169037
train-epoch-step: 6-288 -- Loss: 0.117266446352005
train-epoch-step: 6-289 -- Loss: 0.15964040160179138
train-epoch-step: 6-290 -- Loss: 0.23064002394676208
train-epoch-step: 6-291 -- Loss: 0.15070247650146484
train-epoch-step: 6-292 -- Loss: 0.1880660206079483
train-epoch-step: 6-293 -- Loss: 0.1753731667995453
train-epoch-step: 6-294 -- Loss: 0.20741695165634155
train-epoch-step: 6-295 -- Loss: 0.377652108669281
train-epoch-step: 6-296 -- Loss: 0.21112294495105743
train-epoch-step: 6-297 -- Loss: 0.2203187793493271
train-epoch-step: 6-298 -- Loss: 0.30250558257102966
train-epoch-step: 6-299 -- Loss: 0.21345944702625275
train-epoch-step: 6-300 -- Loss: 0.22824403643608093
train-epoch-step: 6-301 -- Loss: 0.20834727585315704
train-epoch-step: 6-302 -- Loss: 0.27770620584487915
train-epoch-step: 6-303 -- Loss: 0.2595558762550354
train-epoch-step: 6-304 -- Loss: 0.1838337779045105
train-epoch-step: 6-305 -- Loss: 0.1854187548160553
train-epoch-step: 6-306 -- Loss: 0.2865775525569916
train-epoch-step: 6-307 -- Loss: 0.20822623372077942
train-epoch-step: 6-308 -- Loss: 0.3171137571334839
train-epoch-step: 6-309 -- Loss: 0.19795550405979156
train-epoch-step: 6-310 -- Loss: 0.20548903942108154
train-epoch-step: 6-311 -- Loss: 0.205924391746521
train-epoch-step: 6-312 -- Loss: 0.2732512354850769
train-epoch-step: 6-313 -- Loss: 0.12342317402362823
train-epoch-step: 6-314 -- Loss: 0.2538539171218872
train-epoch-step: 6-315 -- Loss: 0.20758697390556335
train-epoch-step: 6-316 -- Loss: 0.19423426687717438
train-epoch-step: 6-317 -- Loss: 0.17923462390899658
train-epoch-step: 6-318 -- Loss: 0.20578980445861816
train-epoch-step: 6-319 -- Loss: 0.2328343689441681
train-epoch-step: 6-320 -- Loss: 0.14891204237937927
train-epoch-step: 6-321 -- Loss: 0.18059983849525452
train-epoch-step: 6-322 -- Loss: 0.2690788805484772
train-epoch-step: 6-323 -- Loss: 0.19555795192718506
train-epoch-step: 6-324 -- Loss: 0.3387647867202759
train-epoch-step: 6-325 -- Loss: 0.19018524885177612
train-epoch-step: 6-326 -- Loss: 0.23103360831737518
train-epoch-step: 6-327 -- Loss: 0.2680220901966095
train-epoch-step: 6-328 -- Loss: 0.2546347379684448
train-epoch-step: 6-329 -- Loss: 0.42590972781181335
train-epoch-step: 6-330 -- Loss: 0.46224936842918396
train-epoch-step: 6-331 -- Loss: 0.28204113245010376
train-epoch-step: 6-332 -- Loss: 0.13435284793376923
train-epoch-step: 6-333 -- Loss: 0.23654097318649292
train-epoch-step: 6-334 -- Loss: 0.192576065659523
train-epoch-step: 6-335 -- Loss: 0.21938884258270264
train-epoch-step: 6-336 -- Loss: 0.20963139832019806
train-epoch-step: 6-337 -- Loss: 0.26632851362228394
train-epoch-step: 6-338 -- Loss: 0.21292638778686523
train-epoch-step: 6-339 -- Loss: 0.18131589889526367
train-epoch-step: 6-340 -- Loss: 0.24932435154914856
train-epoch-step: 6-341 -- Loss: 0.17472493648529053
train-epoch-step: 6-342 -- Loss: 0.2094491422176361
train-epoch-step: 6-343 -- Loss: 0.19746245443820953
train-epoch-step: 6-344 -- Loss: 0.2126057744026184
train-epoch-step: 6-345 -- Loss: 0.1586354374885559
train-epoch-step: 6-346 -- Loss: 0.24085870385169983
train-epoch-step: 6-347 -- Loss: 0.20514719188213348
train-epoch-step: 6-348 -- Loss: 0.2591102123260498
train-epoch-step: 6-349 -- Loss: 0.27736347913742065
train-epoch-step: 6-350 -- Loss: 0.3386429250240326
train-epoch-step: 6-351 -- Loss: 0.2566298544406891
train-epoch-step: 6-352 -- Loss: 0.17979227006435394
train-epoch-step: 6-353 -- Loss: 0.24724826216697693
train-epoch-step: 6-354 -- Loss: 0.34469062089920044
train-epoch-step: 6-355 -- Loss: 0.15388834476470947
train-epoch-step: 6-356 -- Loss: 0.1483640819787979
train-epoch-step: 6-357 -- Loss: 0.2398567497730255
train-epoch-step: 6-358 -- Loss: 0.22888000309467316
train-epoch-step: 6-359 -- Loss: 0.184352308511734
train-epoch-step: 6-360 -- Loss: 0.15946568548679352
train-epoch-step: 6-361 -- Loss: 0.32109004259109497
train-epoch-step: 6-362 -- Loss: 0.21426528692245483
train-epoch-step: 6-363 -- Loss: 0.15326812863349915
train-epoch-step: 6-364 -- Loss: 0.2271198034286499
train-epoch-step: 6-365 -- Loss: 0.2154604196548462
train-epoch-step: 6-366 -- Loss: 0.2471330761909485
train-epoch-step: 6-367 -- Loss: 0.3426703214645386
train-epoch-step: 6-368 -- Loss: 0.25743401050567627
train-epoch-step: 6-369 -- Loss: 0.339310884475708
train-epoch-step: 6-370 -- Loss: 0.15896853804588318
train-epoch-step: 6-371 -- Loss: 0.1498253345489502
train-epoch-step: 6-372 -- Loss: 0.18021336197853088
train-epoch-step: 6-373 -- Loss: 0.24779510498046875
train-epoch-step: 6-374 -- Loss: 0.19108489155769348
train-epoch-step: 6-375 -- Loss: 0.3671572208404541
train-epoch-step: 6-376 -- Loss: 0.2602546811103821
train-epoch-step: 6-377 -- Loss: 0.2997227907180786
train-epoch-step: 6-378 -- Loss: 0.26678720116615295
train-epoch-step: 6-379 -- Loss: 0.1462087631225586
train-epoch-step: 6-380 -- Loss: 0.11423172056674957
train-epoch-step: 6-381 -- Loss: 0.3038364350795746
train-epoch-step: 6-382 -- Loss: 0.29947710037231445
train-epoch-step: 6-383 -- Loss: 0.2247897982597351
train-epoch-step: 6-384 -- Loss: 0.2738609313964844
train-epoch-step: 6-385 -- Loss: 0.25300395488739014
train-epoch-step: 6-386 -- Loss: 0.24929356575012207
train-epoch-step: 6-387 -- Loss: 0.2512517273426056
train-epoch-step: 6-388 -- Loss: 0.2976948618888855
train-epoch-step: 6-389 -- Loss: 0.22716912627220154
train-epoch-step: 6-390 -- Loss: 0.18012602627277374
train-epoch-step: 6-391 -- Loss: 0.17925801873207092
train-epoch-step: 6-392 -- Loss: 0.22855144739151
train-epoch-step: 6-393 -- Loss: 0.19665580987930298
train-epoch-step: 6-394 -- Loss: 0.28802162408828735
train-epoch-step: 6-395 -- Loss: 0.19723495841026306
train-epoch-step: 6-396 -- Loss: 0.16506105661392212
train-epoch-step: 6-397 -- Loss: 0.15902595221996307
train-epoch-step: 6-398 -- Loss: 0.23742246627807617
train-epoch-step: 6-399 -- Loss: 0.23042628169059753
train-epoch-step: 6-400 -- Loss: 0.3529609143733978
train-epoch-step: 6-401 -- Loss: 0.14884231984615326
train-epoch-step: 6-402 -- Loss: 0.323537141084671
train-epoch-step: 6-403 -- Loss: 0.21092525124549866
train-epoch-step: 6-404 -- Loss: 0.18018248677253723
train-epoch-step: 6-405 -- Loss: 0.19616176187992096
train-epoch-step: 6-406 -- Loss: 0.20779269933700562
train-epoch-step: 6-407 -- Loss: 0.14298750460147858
train-epoch-step: 6-408 -- Loss: 0.1976773887872696
train-epoch-step: 6-409 -- Loss: 0.22196826338768005
train-epoch-step: 6-410 -- Loss: 0.22681483626365662
train-epoch-step: 6-411 -- Loss: 0.24775996804237366
train-epoch-step: 6-412 -- Loss: 0.16048331558704376
train-epoch-step: 6-413 -- Loss: 0.18241481482982635
train-epoch-step: 6-414 -- Loss: 0.1769682765007019
train-epoch-step: 6-415 -- Loss: 0.1782083809375763
train-epoch-step: 6-416 -- Loss: 0.32749468088150024
train-epoch-step: 6-417 -- Loss: 0.24497491121292114
train-epoch-step: 6-418 -- Loss: 0.2930052876472473
train-epoch-step: 6-419 -- Loss: 0.2132648378610611
train-epoch-step: 6-420 -- Loss: 0.19310438632965088
train-epoch-step: 6-421 -- Loss: 0.2274591028690338
train-epoch-step: 6-422 -- Loss: 0.18613272905349731
train-epoch-step: 6-423 -- Loss: 0.2304505556821823
train-epoch-step: 6-424 -- Loss: 0.17352351546287537
train-epoch-step: 6-425 -- Loss: 0.22892701625823975
train-epoch-step: 6-426 -- Loss: 0.20760929584503174
train-epoch-step: 6-427 -- Loss: 0.17696315050125122
train-epoch-step: 6-428 -- Loss: 0.252125084400177
train-epoch-step: 6-429 -- Loss: 0.22489799559116364
train-epoch-step: 6-430 -- Loss: 0.18561822175979614
train-epoch-step: 6-431 -- Loss: 0.20521080493927002
train-epoch-step: 6-432 -- Loss: 0.29159897565841675
train-epoch-step: 6-433 -- Loss: 0.1752120554447174
train-epoch-step: 6-434 -- Loss: 0.16476961970329285
train-epoch-step: 6-435 -- Loss: 0.19959485530853271
train-epoch-step: 6-436 -- Loss: 0.19349750876426697
train-epoch-step: 6-437 -- Loss: 0.17328886687755585
train-epoch-step: 6-438 -- Loss: 0.21590308845043182
train-epoch-step: 6-439 -- Loss: 0.35542425513267517
train-epoch-step: 6-440 -- Loss: 0.17140233516693115
train-epoch-step: 6-441 -- Loss: 0.2758432924747467
train-epoch-step: 6-442 -- Loss: 0.24344809353351593
train-epoch-step: 6-443 -- Loss: 0.1986602246761322
train-epoch-step: 6-444 -- Loss: 0.3156276345252991
train-epoch-step: 6-445 -- Loss: 0.2298397570848465
train-epoch-step: 6-446 -- Loss: 0.2001153528690338
train-epoch-step: 6-447 -- Loss: 0.2554883658885956
train-epoch-step: 6-448 -- Loss: 0.3168855905532837
train-epoch-step: 6-449 -- Loss: 0.24547022581100464
train-epoch-step: 6-450 -- Loss: 0.2397506833076477
train-epoch-step: 6-451 -- Loss: 0.17974510788917542
train-epoch-step: 6-452 -- Loss: 0.16469162702560425
train-epoch-step: 6-453 -- Loss: 0.1224513053894043
train-epoch-step: 6-454 -- Loss: 0.3022233545780182
train-epoch-step: 6-455 -- Loss: 0.17453798651695251
train-epoch-step: 6-456 -- Loss: 0.15250365436077118
train-epoch-step: 6-457 -- Loss: 0.27301129698753357
train-epoch-step: 6-458 -- Loss: 0.1898035705089569
train-epoch-step: 6-459 -- Loss: 0.26039618253707886
train-epoch-step: 6-460 -- Loss: 0.1570943295955658
train-epoch-step: 6-461 -- Loss: 0.17957372963428497
train-epoch-step: 6-462 -- Loss: 0.19521857798099518
train-epoch-step: 6-463 -- Loss: 0.17322327196598053
train-epoch-step: 6-464 -- Loss: 0.22533279657363892
train-epoch-step: 6-465 -- Loss: 0.3205466866493225
train-epoch-step: 6-466 -- Loss: 0.244361013174057
train-epoch-step: 6-467 -- Loss: 0.14540262520313263
train-epoch-step: 6-468 -- Loss: 0.2472895234823227
train-epoch-step: 6-469 -- Loss: 0.33539167046546936
train-epoch-step: 6-470 -- Loss: 0.22187983989715576
train-epoch-step: 6-471 -- Loss: 0.19368022680282593
train-epoch-step: 6-472 -- Loss: 0.1992148458957672
train-epoch-step: 6-473 -- Loss: 0.2122296690940857
train-epoch-step: 6-474 -- Loss: 0.15139320492744446
train-epoch-step: 6-475 -- Loss: 0.13928723335266113
train-epoch-step: 6-476 -- Loss: 0.24750511348247528
train-epoch-step: 6-477 -- Loss: 0.28658902645111084
train-epoch-step: 6-478 -- Loss: 0.23660455644130707
train-epoch-step: 6-479 -- Loss: 0.17631548643112183
train-epoch-step: 6-480 -- Loss: 0.2412201315164566
train-epoch-step: 6-481 -- Loss: 0.3420461118221283
train-epoch-step: 6-482 -- Loss: 0.32221513986587524
train-epoch-step: 6-483 -- Loss: 0.2520780861377716
train-epoch-step: 6-484 -- Loss: 0.25813671946525574
train-epoch-step: 6-485 -- Loss: 0.16611605882644653
train-epoch-step: 6-486 -- Loss: 0.3356633484363556
train-epoch-step: 6-487 -- Loss: 0.2787751257419586
train-epoch-step: 6-488 -- Loss: 0.23492887616157532
train-epoch-step: 6-489 -- Loss: 0.27289074659347534
train-epoch-step: 6-490 -- Loss: 0.17751500010490417
train-epoch-step: 6-491 -- Loss: 0.1754947155714035
train-epoch-step: 6-492 -- Loss: 0.1580510139465332
train-epoch-step: 6-493 -- Loss: 0.26561492681503296
train-epoch-step: 6-494 -- Loss: 0.26432397961616516
train-epoch-step: 6-495 -- Loss: 0.2686147689819336
train-epoch-step: 6-496 -- Loss: 0.16831454634666443
train-epoch-step: 6-497 -- Loss: 0.24448320269584656
train-epoch-step: 6-498 -- Loss: 0.18594613671302795
train-epoch-step: 6-499 -- Loss: 0.2065259963274002
train-epoch-step: 6-500 -- Loss: 0.19230905175209045
train-epoch-step: 6-501 -- Loss: 0.2749587595462799
train-epoch-step: 6-502 -- Loss: 0.20406952500343323
train-epoch-step: 6-503 -- Loss: 0.2717464566230774
train-epoch-step: 6-504 -- Loss: 0.14889222383499146
train-epoch-step: 6-505 -- Loss: 0.22228755056858063
train-epoch-step: 6-506 -- Loss: 0.15165495872497559
train-epoch-step: 6-507 -- Loss: 0.22314327955245972
train-epoch-step: 6-508 -- Loss: 0.21635545790195465
train-epoch-step: 6-509 -- Loss: 0.2127714604139328
train-epoch-step: 6-510 -- Loss: 0.16896837949752808
train-epoch-step: 6-511 -- Loss: 0.2648417055606842
train-epoch-step: 6-512 -- Loss: 0.22499872744083405
train-epoch-step: 6-513 -- Loss: 0.25339949131011963
train-epoch-step: 6-514 -- Loss: 0.18498492240905762
train-epoch-step: 6-515 -- Loss: 0.20272740721702576
train-epoch-step: 6-516 -- Loss: 0.2069036215543747
train-epoch-step: 6-517 -- Loss: 0.23076969385147095
train-epoch-step: 6-518 -- Loss: 0.1692025363445282
train-epoch-step: 6-519 -- Loss: 0.16724151372909546
train-epoch-step: 6-520 -- Loss: 0.23577140271663666
train-epoch-step: 6-521 -- Loss: 0.28041955828666687
train-epoch-step: 6-522 -- Loss: 0.21251778304576874
train-epoch-step: 6-523 -- Loss: 0.2022746354341507
train-epoch-step: 6-524 -- Loss: 0.2086448073387146
train-epoch-step: 6-525 -- Loss: 0.23342184722423553
train-epoch-step: 6-526 -- Loss: 0.15925002098083496
train-epoch-step: 6-527 -- Loss: 0.20982271432876587
train-epoch-step: 6-528 -- Loss: 0.19857868552207947
train-epoch-step: 6-529 -- Loss: 0.22397524118423462
train-epoch-step: 6-530 -- Loss: 0.2218131124973297
train-epoch-step: 6-531 -- Loss: 0.2489813268184662
train-epoch-step: 6-532 -- Loss: 0.21510890126228333
train-epoch-step: 6-533 -- Loss: 0.20689606666564941
train-epoch-step: 6-534 -- Loss: 0.16664384305477142
train-epoch-step: 6-535 -- Loss: 0.3512321710586548
train-epoch-step: 6-536 -- Loss: 0.20232605934143066
train-epoch-step: 6-537 -- Loss: 0.18759626150131226
train-epoch-step: 6-538 -- Loss: 0.12661652266979218
train-epoch-step: 6-539 -- Loss: 0.24621817469596863
train-epoch-step: 6-540 -- Loss: 0.16241365671157837
train-epoch-step: 6-541 -- Loss: 0.26940399408340454
train-epoch-step: 6-542 -- Loss: 0.2969292402267456
train-epoch-step: 6-543 -- Loss: 0.20203819870948792
train-epoch-step: 6-544 -- Loss: 0.2765403985977173
train-epoch-step: 6-545 -- Loss: 0.2435404658317566
train-epoch-step: 6-546 -- Loss: 0.2677970230579376
train-epoch-step: 6-547 -- Loss: 0.22318045794963837
train-epoch-step: 6-548 -- Loss: 0.11525239050388336
train-epoch-step: 6-549 -- Loss: 0.19068334996700287
train-epoch-step: 6-550 -- Loss: 0.24829110503196716
train-epoch-step: 6-551 -- Loss: 0.20418165624141693
train-epoch-step: 6-552 -- Loss: 0.15984943509101868
train-epoch-step: 6-553 -- Loss: 0.229016974568367
train-epoch-step: 6-554 -- Loss: 0.22014914453029633
train-epoch-step: 6-555 -- Loss: 0.27246350049972534
train-epoch-step: 6-556 -- Loss: 0.2210242748260498
train-epoch-step: 6-557 -- Loss: 0.29166001081466675
train-epoch-step: 6-558 -- Loss: 0.281166672706604
train-epoch-step: 6-559 -- Loss: 0.1859273910522461
train-epoch-step: 6-560 -- Loss: 0.25101175904273987
train-epoch-step: 6-561 -- Loss: 0.24863004684448242
train-epoch-step: 6-562 -- Loss: 0.24318870902061462
train-epoch-step: 6-563 -- Loss: 0.2386290580034256
train-epoch-step: 6-564 -- Loss: 0.13115723431110382
train-epoch-step: 6-565 -- Loss: 0.22257952392101288
train-epoch-step: 6-566 -- Loss: 0.20450209081172943
train-epoch-step: 6-567 -- Loss: 0.2591136395931244
train-epoch-step: 6-568 -- Loss: 0.19403038918972015
train-epoch-step: 6-569 -- Loss: 0.2870370149612427
train-epoch-step: 6-570 -- Loss: 0.22805289924144745
train-epoch-step: 6-571 -- Loss: 0.2647000551223755
train-epoch-step: 6-572 -- Loss: 0.30341053009033203
train-epoch-step: 6-573 -- Loss: 0.264342337846756
train-epoch-step: 6-574 -- Loss: 0.3137871026992798
train-epoch-step: 6-575 -- Loss: 0.3906184434890747
train-epoch-step: 6-576 -- Loss: 0.1535964012145996
train-epoch-step: 6-577 -- Loss: 0.2111743986606598
train-epoch-step: 6-578 -- Loss: 0.2823219895362854
train-epoch-step: 6-579 -- Loss: 0.20896406471729279
train-epoch-step: 6-580 -- Loss: 0.24744224548339844
train-epoch-step: 6-581 -- Loss: 0.1734025776386261
train-epoch-step: 6-582 -- Loss: 0.27375704050064087
train-epoch-step: 6-583 -- Loss: 0.2975064218044281
train-epoch-step: 6-584 -- Loss: 0.24731750786304474
train-epoch-step: 6-585 -- Loss: 0.24000102281570435
train-epoch-step: 6-586 -- Loss: 0.3346007466316223
train-epoch-step: 6-587 -- Loss: 0.20518973469734192
train-epoch-step: 6-588 -- Loss: 0.15902957320213318
val-epoch-step: 6-589 -- Loss: 0.270280659198761
val-epoch-step: 6-590 -- Loss: 0.18050450086593628
val-epoch-step: 6-591 -- Loss: 0.2561757266521454
val-epoch-step: 6-592 -- Loss: 0.21665862202644348
val-epoch-step: 6-593 -- Loss: 0.17392607033252716
val-epoch-step: 6-594 -- Loss: 0.4308002293109894
val-epoch-step: 6-595 -- Loss: 0.20846039056777954
val-epoch-step: 6-596 -- Loss: 0.24711212515830994
val-epoch-step: 6-597 -- Loss: 0.2183244228363037
val-epoch-step: 6-598 -- Loss: 0.18428540229797363
val-epoch-step: 6-599 -- Loss: 0.221760094165802
val-epoch-step: 6-600 -- Loss: 0.22640976309776306
val-epoch-step: 6-601 -- Loss: 0.18437477946281433
val-epoch-step: 6-602 -- Loss: 0.16761845350265503
val-epoch-step: 6-603 -- Loss: 0.21225324273109436
val-epoch-step: 6-604 -- Loss: 0.17513075470924377
val-epoch-step: 6-605 -- Loss: 0.18122106790542603
val-epoch-step: 6-606 -- Loss: 0.3325812816619873
val-epoch-step: 6-607 -- Loss: 0.16183599829673767
val-epoch-step: 6-608 -- Loss: 0.304826557636261
val-epoch-step: 6-609 -- Loss: 0.21613597869873047
val-epoch-step: 6-610 -- Loss: 0.2333957701921463
val-epoch-step: 6-611 -- Loss: 0.1994248628616333
val-epoch-step: 6-612 -- Loss: 0.3832135796546936
val-epoch-step: 6-613 -- Loss: 0.21598154306411743
val-epoch-step: 6-614 -- Loss: 0.19113977253437042
val-epoch-step: 6-615 -- Loss: 0.23266394436359406
val-epoch-step: 6-616 -- Loss: 0.1776747703552246
val-epoch-step: 6-617 -- Loss: 0.23429745435714722
val-epoch-step: 6-618 -- Loss: 0.24616126716136932
val-epoch-step: 6-619 -- Loss: 0.2657870352268219
val-epoch-step: 6-620 -- Loss: 0.17329511046409607
val-epoch-step: 6-621 -- Loss: 0.1737672984600067
val-epoch-step: 6-622 -- Loss: 0.17426073551177979
val-epoch-step: 6-623 -- Loss: 0.18230363726615906
val-epoch-step: 6-624 -- Loss: 0.21225208044052124
val-epoch-step: 6-625 -- Loss: 0.18888059258460999
val-epoch-step: 6-626 -- Loss: 0.1810418665409088
val-epoch-step: 6-627 -- Loss: 0.23976311087608337
val-epoch-step: 6-628 -- Loss: 0.6427084803581238
val-epoch-step: 6-629 -- Loss: 0.24464786052703857
val-epoch-step: 6-630 -- Loss: 0.40481579303741455
val-epoch-step: 6-631 -- Loss: 0.1737552136182785
val-epoch-step: 6-632 -- Loss: 0.2556758522987366
val-epoch-step: 6-633 -- Loss: 0.19287598133087158
val-epoch-step: 6-634 -- Loss: 0.16976088285446167
val-epoch-step: 6-635 -- Loss: 0.13689342141151428
val-epoch-step: 6-636 -- Loss: 0.19900481402873993
val-epoch-step: 6-637 -- Loss: 0.22025510668754578
val-epoch-step: 6-638 -- Loss: 0.18821661174297333
val-epoch-step: 6-639 -- Loss: 0.3155595064163208
val-epoch-step: 6-640 -- Loss: 0.2986670732498169
val-epoch-step: 6-641 -- Loss: 0.1475900113582611
val-epoch-step: 6-642 -- Loss: 0.24162396788597107
val-epoch-step: 6-643 -- Loss: 0.23417925834655762
val-epoch-step: 6-644 -- Loss: 0.19077321887016296
val-epoch-step: 6-645 -- Loss: 0.2694331705570221
val-epoch-step: 6-646 -- Loss: 0.1787695288658142
val-epoch-step: 6-647 -- Loss: 0.16244366765022278
val-epoch-step: 6-648 -- Loss: 0.1954568773508072
val-epoch-step: 6-649 -- Loss: 0.26894494891166687
val-epoch-step: 6-650 -- Loss: 0.3033272624015808
val-epoch-step: 6-651 -- Loss: 0.17162320017814636
val-epoch-step: 6-652 -- Loss: 0.1973828673362732
val-epoch-step: 6-653 -- Loss: 0.23764748871326447
val-epoch-step: 6-654 -- Loss: 0.1356339454650879
Epoch: 6 -- Train Loss: tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 7-0 -- Loss: 0.276256263256073
train-epoch-step: 7-1 -- Loss: 0.1752507984638214
train-epoch-step: 7-2 -- Loss: 0.2582787275314331
train-epoch-step: 7-3 -- Loss: 0.18156415224075317
train-epoch-step: 7-4 -- Loss: 0.2454291582107544
train-epoch-step: 7-5 -- Loss: 0.24019989371299744
train-epoch-step: 7-6 -- Loss: 0.3024172782897949
train-epoch-step: 7-7 -- Loss: 0.22073619067668915
train-epoch-step: 7-8 -- Loss: 0.2452990561723709
train-epoch-step: 7-9 -- Loss: 0.34057676792144775
train-epoch-step: 7-10 -- Loss: 0.3095398545265198
train-epoch-step: 7-11 -- Loss: 0.22897060215473175
train-epoch-step: 7-12 -- Loss: 0.19302958250045776
train-epoch-step: 7-13 -- Loss: 0.24686293303966522
train-epoch-step: 7-14 -- Loss: 0.20370909571647644
train-epoch-step: 7-15 -- Loss: 0.19892066717147827
train-epoch-step: 7-16 -- Loss: 0.2094516009092331
train-epoch-step: 7-17 -- Loss: 0.2770325839519501
train-epoch-step: 7-18 -- Loss: 0.24128906428813934
train-epoch-step: 7-19 -- Loss: 0.1681700348854065
train-epoch-step: 7-20 -- Loss: 0.28608036041259766
train-epoch-step: 7-21 -- Loss: 0.4273987412452698
train-epoch-step: 7-22 -- Loss: 0.19863764941692352
train-epoch-step: 7-23 -- Loss: 0.23475168645381927
train-epoch-step: 7-24 -- Loss: 0.1639280766248703
train-epoch-step: 7-25 -- Loss: 0.28436553478240967
train-epoch-step: 7-26 -- Loss: 0.24576233327388763
train-epoch-step: 7-27 -- Loss: 0.32307690382003784
train-epoch-step: 7-28 -- Loss: 0.1543356329202652
train-epoch-step: 7-29 -- Loss: 0.29392579197883606
train-epoch-step: 7-30 -- Loss: 0.1372586041688919
train-epoch-step: 7-31 -- Loss: 0.1804620325565338
train-epoch-step: 7-32 -- Loss: 0.21533429622650146
train-epoch-step: 7-33 -- Loss: 0.3317745327949524
train-epoch-step: 7-34 -- Loss: 0.20571014285087585
train-epoch-step: 7-35 -- Loss: 0.30569544434547424
train-epoch-step: 7-36 -- Loss: 0.1715603768825531
train-epoch-step: 7-37 -- Loss: 0.18695484101772308
train-epoch-step: 7-38 -- Loss: 0.2464362531900406
train-epoch-step: 7-39 -- Loss: 0.29810869693756104
train-epoch-step: 7-40 -- Loss: 0.25886866450309753
train-epoch-step: 7-41 -- Loss: 0.2561384439468384
train-epoch-step: 7-42 -- Loss: 0.18593832850456238
train-epoch-step: 7-43 -- Loss: 0.3521202802658081
train-epoch-step: 7-44 -- Loss: 0.15922126173973083
train-epoch-step: 7-45 -- Loss: 0.15764525532722473
train-epoch-step: 7-46 -- Loss: 0.21721994876861572
train-epoch-step: 7-47 -- Loss: 0.29191717505455017
train-epoch-step: 7-48 -- Loss: 0.18569472432136536
train-epoch-step: 7-49 -- Loss: 0.2740018963813782
train-epoch-step: 7-50 -- Loss: 0.14924702048301697
train-epoch-step: 7-51 -- Loss: 0.2357170283794403
train-epoch-step: 7-52 -- Loss: 0.19684892892837524
train-epoch-step: 7-53 -- Loss: 0.2687852382659912
train-epoch-step: 7-54 -- Loss: 0.3553527295589447
train-epoch-step: 7-55 -- Loss: 0.21262283623218536
train-epoch-step: 7-56 -- Loss: 0.25096553564071655
train-epoch-step: 7-57 -- Loss: 0.2819114625453949
train-epoch-step: 7-58 -- Loss: 0.3407459557056427
train-epoch-step: 7-59 -- Loss: 0.32912737131118774
train-epoch-step: 7-60 -- Loss: 0.16361026465892792
train-epoch-step: 7-61 -- Loss: 0.27934104204177856
train-epoch-step: 7-62 -- Loss: 0.23619893193244934
train-epoch-step: 7-63 -- Loss: 0.17023888230323792
train-epoch-step: 7-64 -- Loss: 0.19383816421031952
train-epoch-step: 7-65 -- Loss: 0.24149252474308014
train-epoch-step: 7-66 -- Loss: 0.13817980885505676
train-epoch-step: 7-67 -- Loss: 0.1548740118741989
train-epoch-step: 7-68 -- Loss: 0.290735125541687
train-epoch-step: 7-69 -- Loss: 0.16767190396785736
train-epoch-step: 7-70 -- Loss: 0.2651105523109436
train-epoch-step: 7-71 -- Loss: 0.3123264014720917
train-epoch-step: 7-72 -- Loss: 0.22568562626838684
train-epoch-step: 7-73 -- Loss: 0.25739943981170654
train-epoch-step: 7-74 -- Loss: 0.12058844417333603
train-epoch-step: 7-75 -- Loss: 0.16390490531921387
train-epoch-step: 7-76 -- Loss: 0.17966610193252563
train-epoch-step: 7-77 -- Loss: 0.27904289960861206
train-epoch-step: 7-78 -- Loss: 0.3348349630832672
train-epoch-step: 7-79 -- Loss: 0.24009805917739868
train-epoch-step: 7-80 -- Loss: 0.3836539387702942
train-epoch-step: 7-81 -- Loss: 0.15949340164661407
train-epoch-step: 7-82 -- Loss: 0.304686576128006
train-epoch-step: 7-83 -- Loss: 0.23255309462547302
train-epoch-step: 7-84 -- Loss: 0.2519306242465973
train-epoch-step: 7-85 -- Loss: 0.22130367159843445
train-epoch-step: 7-86 -- Loss: 0.15785159170627594
train-epoch-step: 7-87 -- Loss: 0.29924294352531433
train-epoch-step: 7-88 -- Loss: 0.17601320147514343
train-epoch-step: 7-89 -- Loss: 0.24370884895324707
train-epoch-step: 7-90 -- Loss: 0.2399645894765854
train-epoch-step: 7-91 -- Loss: 0.30336132645606995
train-epoch-step: 7-92 -- Loss: 0.1960095912218094
train-epoch-step: 7-93 -- Loss: 0.23003479838371277
train-epoch-step: 7-94 -- Loss: 0.30672961473464966
train-epoch-step: 7-95 -- Loss: 0.24213576316833496
train-epoch-step: 7-96 -- Loss: 0.28607606887817383
train-epoch-step: 7-97 -- Loss: 0.23352426290512085
train-epoch-step: 7-98 -- Loss: 0.19631525874137878
train-epoch-step: 7-99 -- Loss: 0.2382379174232483
train-epoch-step: 7-100 -- Loss: 0.23857919871807098
train-epoch-step: 7-101 -- Loss: 0.32563596963882446
train-epoch-step: 7-102 -- Loss: 0.29443037509918213
train-epoch-step: 7-103 -- Loss: 0.24629870057106018
train-epoch-step: 7-104 -- Loss: 0.18547660112380981
train-epoch-step: 7-105 -- Loss: 0.34582898020744324
train-epoch-step: 7-106 -- Loss: 0.22535759210586548
train-epoch-step: 7-107 -- Loss: 0.23834511637687683
train-epoch-step: 7-108 -- Loss: 0.23071058094501495
train-epoch-step: 7-109 -- Loss: 0.18901923298835754
train-epoch-step: 7-110 -- Loss: 0.22670717537403107
train-epoch-step: 7-111 -- Loss: 0.22468458116054535
train-epoch-step: 7-112 -- Loss: 0.211991548538208
train-epoch-step: 7-113 -- Loss: 0.21165820956230164
train-epoch-step: 7-114 -- Loss: 0.3077748119831085
train-epoch-step: 7-115 -- Loss: 0.21033185720443726
train-epoch-step: 7-116 -- Loss: 0.19160497188568115
train-epoch-step: 7-117 -- Loss: 0.16038334369659424
train-epoch-step: 7-118 -- Loss: 0.24789145588874817
train-epoch-step: 7-119 -- Loss: 0.19091153144836426
train-epoch-step: 7-120 -- Loss: 0.3329997658729553
train-epoch-step: 7-121 -- Loss: 0.3326655626296997
train-epoch-step: 7-122 -- Loss: 0.2666824758052826
train-epoch-step: 7-123 -- Loss: 0.2654925584793091
train-epoch-step: 7-124 -- Loss: 0.14759840071201324
train-epoch-step: 7-125 -- Loss: 0.19168177247047424
train-epoch-step: 7-126 -- Loss: 0.3048837184906006
train-epoch-step: 7-127 -- Loss: 0.2176678478717804
train-epoch-step: 7-128 -- Loss: 0.2173486351966858
train-epoch-step: 7-129 -- Loss: 0.17606128752231598
train-epoch-step: 7-130 -- Loss: 0.24357634782791138
train-epoch-step: 7-131 -- Loss: 0.1667618453502655
train-epoch-step: 7-132 -- Loss: 0.25754401087760925
train-epoch-step: 7-133 -- Loss: 0.14386992156505585
train-epoch-step: 7-134 -- Loss: 0.2508179545402527
train-epoch-step: 7-135 -- Loss: 0.1666695773601532
train-epoch-step: 7-136 -- Loss: 0.1596510410308838
train-epoch-step: 7-137 -- Loss: 0.3250125050544739
train-epoch-step: 7-138 -- Loss: 0.327520489692688
train-epoch-step: 7-139 -- Loss: 0.16552779078483582
train-epoch-step: 7-140 -- Loss: 0.25610750913619995
train-epoch-step: 7-141 -- Loss: 0.296254962682724
train-epoch-step: 7-142 -- Loss: 0.25515544414520264
train-epoch-step: 7-143 -- Loss: 0.21189413964748383
train-epoch-step: 7-144 -- Loss: 0.2382259964942932
train-epoch-step: 7-145 -- Loss: 0.17218628525733948
train-epoch-step: 7-146 -- Loss: 0.22264930605888367
train-epoch-step: 7-147 -- Loss: 0.22435936331748962
train-epoch-step: 7-148 -- Loss: 0.22033798694610596
train-epoch-step: 7-149 -- Loss: 0.15004029870033264
train-epoch-step: 7-150 -- Loss: 0.23833447694778442
train-epoch-step: 7-151 -- Loss: 0.23101016879081726
train-epoch-step: 7-152 -- Loss: 0.23900920152664185
train-epoch-step: 7-153 -- Loss: 0.3825061321258545
train-epoch-step: 7-154 -- Loss: 0.16828827559947968
train-epoch-step: 7-155 -- Loss: 0.18173286318778992
train-epoch-step: 7-156 -- Loss: 0.15817135572433472
train-epoch-step: 7-157 -- Loss: 0.20569360256195068
train-epoch-step: 7-158 -- Loss: 0.20949691534042358
train-epoch-step: 7-159 -- Loss: 0.21342980861663818
train-epoch-step: 7-160 -- Loss: 0.2746536135673523
train-epoch-step: 7-161 -- Loss: 0.2628099322319031
train-epoch-step: 7-162 -- Loss: 0.2528456449508667
train-epoch-step: 7-163 -- Loss: 0.23159709572792053
train-epoch-step: 7-164 -- Loss: 0.2268105447292328
train-epoch-step: 7-165 -- Loss: 0.20465226471424103
train-epoch-step: 7-166 -- Loss: 0.14879371225833893
train-epoch-step: 7-167 -- Loss: 0.14888308942317963
train-epoch-step: 7-168 -- Loss: 0.25677981972694397
train-epoch-step: 7-169 -- Loss: 0.18069185316562653
train-epoch-step: 7-170 -- Loss: 0.2579568028450012
train-epoch-step: 7-171 -- Loss: 0.1712859719991684
train-epoch-step: 7-172 -- Loss: 0.31672513484954834
train-epoch-step: 7-173 -- Loss: 0.1561998426914215
train-epoch-step: 7-174 -- Loss: 0.2946319580078125
train-epoch-step: 7-175 -- Loss: 0.22539255023002625
train-epoch-step: 7-176 -- Loss: 0.1643848717212677
train-epoch-step: 7-177 -- Loss: 0.23309363424777985
train-epoch-step: 7-178 -- Loss: 0.24073520302772522
train-epoch-step: 7-179 -- Loss: 0.17488734424114227
train-epoch-step: 7-180 -- Loss: 0.18317830562591553
train-epoch-step: 7-181 -- Loss: 0.22069384157657623
train-epoch-step: 7-182 -- Loss: 0.23920008540153503
train-epoch-step: 7-183 -- Loss: 0.34874671697616577
train-epoch-step: 7-184 -- Loss: 0.17533493041992188
train-epoch-step: 7-185 -- Loss: 0.17937585711479187
train-epoch-step: 7-186 -- Loss: 0.2417052537202835
train-epoch-step: 7-187 -- Loss: 0.2689201831817627
train-epoch-step: 7-188 -- Loss: 0.21174204349517822
train-epoch-step: 7-189 -- Loss: 0.16370722651481628
train-epoch-step: 7-190 -- Loss: 0.21891233325004578
train-epoch-step: 7-191 -- Loss: 0.22279483079910278
train-epoch-step: 7-192 -- Loss: 0.303104966878891
train-epoch-step: 7-193 -- Loss: 0.27962246537208557
train-epoch-step: 7-194 -- Loss: 0.22261114418506622
train-epoch-step: 7-195 -- Loss: 0.20024248957633972
train-epoch-step: 7-196 -- Loss: 0.21776726841926575
train-epoch-step: 7-197 -- Loss: 0.15947335958480835
train-epoch-step: 7-198 -- Loss: 0.16664451360702515
train-epoch-step: 7-199 -- Loss: 0.18607640266418457
train-epoch-step: 7-200 -- Loss: 0.153196319937706
train-epoch-step: 7-201 -- Loss: 0.2450525164604187
train-epoch-step: 7-202 -- Loss: 0.16952413320541382
train-epoch-step: 7-203 -- Loss: 0.21748103201389313
train-epoch-step: 7-204 -- Loss: 0.18287254869937897
train-epoch-step: 7-205 -- Loss: 0.2296738624572754
train-epoch-step: 7-206 -- Loss: 0.25291404128074646
train-epoch-step: 7-207 -- Loss: 0.17573346197605133
train-epoch-step: 7-208 -- Loss: 0.2186255156993866
train-epoch-step: 7-209 -- Loss: 0.18026486039161682
train-epoch-step: 7-210 -- Loss: 0.16756820678710938
train-epoch-step: 7-211 -- Loss: 0.2580394446849823
train-epoch-step: 7-212 -- Loss: 0.24582645297050476
train-epoch-step: 7-213 -- Loss: 0.16213494539260864
train-epoch-step: 7-214 -- Loss: 0.1893540620803833
train-epoch-step: 7-215 -- Loss: 0.1697220504283905
train-epoch-step: 7-216 -- Loss: 0.24438804388046265
train-epoch-step: 7-217 -- Loss: 0.26141422986984253
train-epoch-step: 7-218 -- Loss: 0.19436043500900269
train-epoch-step: 7-219 -- Loss: 0.2564184069633484
train-epoch-step: 7-220 -- Loss: 0.16290003061294556
train-epoch-step: 7-221 -- Loss: 0.25251057744026184
train-epoch-step: 7-222 -- Loss: 0.15555991232395172
train-epoch-step: 7-223 -- Loss: 0.21195264160633087
train-epoch-step: 7-224 -- Loss: 0.2279350310564041
train-epoch-step: 7-225 -- Loss: 0.38437706232070923
train-epoch-step: 7-226 -- Loss: 0.27380314469337463
train-epoch-step: 7-227 -- Loss: 0.2883005738258362
train-epoch-step: 7-228 -- Loss: 0.22151543200016022
train-epoch-step: 7-229 -- Loss: 0.2371433526277542
train-epoch-step: 7-230 -- Loss: 0.19373241066932678
train-epoch-step: 7-231 -- Loss: 0.2233903855085373
train-epoch-step: 7-232 -- Loss: 0.2498960793018341
train-epoch-step: 7-233 -- Loss: 0.1083817183971405
train-epoch-step: 7-234 -- Loss: 0.2265656590461731
train-epoch-step: 7-235 -- Loss: 0.2023855447769165
train-epoch-step: 7-236 -- Loss: 0.21460849046707153
train-epoch-step: 7-237 -- Loss: 0.3011069893836975
train-epoch-step: 7-238 -- Loss: 0.1910828948020935
train-epoch-step: 7-239 -- Loss: 0.16730275750160217
train-epoch-step: 7-240 -- Loss: 0.2707027792930603
train-epoch-step: 7-241 -- Loss: 0.18889227509498596
train-epoch-step: 7-242 -- Loss: 0.27524062991142273
train-epoch-step: 7-243 -- Loss: 0.28070372343063354
train-epoch-step: 7-244 -- Loss: 0.2520623207092285
train-epoch-step: 7-245 -- Loss: 0.29570311307907104
train-epoch-step: 7-246 -- Loss: 0.3545887768268585
train-epoch-step: 7-247 -- Loss: 0.2900986075401306
train-epoch-step: 7-248 -- Loss: 0.2296532392501831
train-epoch-step: 7-249 -- Loss: 0.18056392669677734
train-epoch-step: 7-250 -- Loss: 0.2501383125782013
train-epoch-step: 7-251 -- Loss: 0.1359374225139618
train-epoch-step: 7-252 -- Loss: 0.24178260564804077
train-epoch-step: 7-253 -- Loss: 0.17170661687850952
train-epoch-step: 7-254 -- Loss: 0.29145267605781555
train-epoch-step: 7-255 -- Loss: 0.18091650307178497
train-epoch-step: 7-256 -- Loss: 0.1940615475177765
train-epoch-step: 7-257 -- Loss: 0.23403975367546082
train-epoch-step: 7-258 -- Loss: 0.194665789604187
train-epoch-step: 7-259 -- Loss: 0.15595224499702454
train-epoch-step: 7-260 -- Loss: 0.2571941018104553
train-epoch-step: 7-261 -- Loss: 0.21456047892570496
train-epoch-step: 7-262 -- Loss: 0.3875386416912079
train-epoch-step: 7-263 -- Loss: 0.26552098989486694
train-epoch-step: 7-264 -- Loss: 0.207219660282135
train-epoch-step: 7-265 -- Loss: 0.13779118657112122
train-epoch-step: 7-266 -- Loss: 0.18153050541877747
train-epoch-step: 7-267 -- Loss: 0.18199440836906433
train-epoch-step: 7-268 -- Loss: 0.14664813876152039
train-epoch-step: 7-269 -- Loss: 0.21754544973373413
train-epoch-step: 7-270 -- Loss: 0.13554254174232483
train-epoch-step: 7-271 -- Loss: 0.1889716386795044
train-epoch-step: 7-272 -- Loss: 0.14767062664031982
train-epoch-step: 7-273 -- Loss: 0.15964704751968384
train-epoch-step: 7-274 -- Loss: 0.22859975695610046
train-epoch-step: 7-275 -- Loss: 0.2514854669570923
train-epoch-step: 7-276 -- Loss: 0.1894991099834442
train-epoch-step: 7-277 -- Loss: 0.1929558366537094
train-epoch-step: 7-278 -- Loss: 0.1798393577337265
train-epoch-step: 7-279 -- Loss: 0.18163712322711945
train-epoch-step: 7-280 -- Loss: 0.26208192110061646
train-epoch-step: 7-281 -- Loss: 0.22334907948970795
train-epoch-step: 7-282 -- Loss: 0.1726224571466446
train-epoch-step: 7-283 -- Loss: 0.1411244124174118
train-epoch-step: 7-284 -- Loss: 0.29131534695625305
train-epoch-step: 7-285 -- Loss: 0.2414473295211792
train-epoch-step: 7-286 -- Loss: 0.19668298959732056
train-epoch-step: 7-287 -- Loss: 0.2565014958381653
train-epoch-step: 7-288 -- Loss: 0.11437860131263733
train-epoch-step: 7-289 -- Loss: 0.1562633514404297
train-epoch-step: 7-290 -- Loss: 0.22466149926185608
train-epoch-step: 7-291 -- Loss: 0.14227546751499176
train-epoch-step: 7-292 -- Loss: 0.19031035900115967
train-epoch-step: 7-293 -- Loss: 0.16987963020801544
train-epoch-step: 7-294 -- Loss: 0.21423503756523132
train-epoch-step: 7-295 -- Loss: 0.3551349639892578
train-epoch-step: 7-296 -- Loss: 0.20985016226768494
train-epoch-step: 7-297 -- Loss: 0.2179289311170578
train-epoch-step: 7-298 -- Loss: 0.2977079153060913
train-epoch-step: 7-299 -- Loss: 0.20863832533359528
train-epoch-step: 7-300 -- Loss: 0.21659839153289795
train-epoch-step: 7-301 -- Loss: 0.20377382636070251
train-epoch-step: 7-302 -- Loss: 0.26985281705856323
train-epoch-step: 7-303 -- Loss: 0.2559763789176941
train-epoch-step: 7-304 -- Loss: 0.17709209024906158
train-epoch-step: 7-305 -- Loss: 0.18123868107795715
train-epoch-step: 7-306 -- Loss: 0.28107213973999023
train-epoch-step: 7-307 -- Loss: 0.20618155598640442
train-epoch-step: 7-308 -- Loss: 0.29752281308174133
train-epoch-step: 7-309 -- Loss: 0.19224567711353302
train-epoch-step: 7-310 -- Loss: 0.20143674314022064
train-epoch-step: 7-311 -- Loss: 0.20149432122707367
train-epoch-step: 7-312 -- Loss: 0.2631821632385254
train-epoch-step: 7-313 -- Loss: 0.12415780127048492
train-epoch-step: 7-314 -- Loss: 0.2500302791595459
train-epoch-step: 7-315 -- Loss: 0.20452046394348145
train-epoch-step: 7-316 -- Loss: 0.1884937435388565
train-epoch-step: 7-317 -- Loss: 0.17359569668769836
train-epoch-step: 7-318 -- Loss: 0.20321734249591827
train-epoch-step: 7-319 -- Loss: 0.22695103287696838
train-epoch-step: 7-320 -- Loss: 0.14695876836776733
train-epoch-step: 7-321 -- Loss: 0.1737383008003235
train-epoch-step: 7-322 -- Loss: 0.2580500841140747
train-epoch-step: 7-323 -- Loss: 0.19205433130264282
train-epoch-step: 7-324 -- Loss: 0.3215177655220032
train-epoch-step: 7-325 -- Loss: 0.18279027938842773
train-epoch-step: 7-326 -- Loss: 0.2292269766330719
train-epoch-step: 7-327 -- Loss: 0.2612030804157257
train-epoch-step: 7-328 -- Loss: 0.24592959880828857
train-epoch-step: 7-329 -- Loss: 0.40351563692092896
train-epoch-step: 7-330 -- Loss: 0.4421995282173157
train-epoch-step: 7-331 -- Loss: 0.2751726508140564
train-epoch-step: 7-332 -- Loss: 0.13155263662338257
train-epoch-step: 7-333 -- Loss: 0.23141586780548096
train-epoch-step: 7-334 -- Loss: 0.18857111036777496
train-epoch-step: 7-335 -- Loss: 0.21870821714401245
train-epoch-step: 7-336 -- Loss: 0.2029489278793335
train-epoch-step: 7-337 -- Loss: 0.26403307914733887
train-epoch-step: 7-338 -- Loss: 0.20158329606056213
train-epoch-step: 7-339 -- Loss: 0.17948253452777863
train-epoch-step: 7-340 -- Loss: 0.2429676502943039
train-epoch-step: 7-341 -- Loss: 0.1758827269077301
train-epoch-step: 7-342 -- Loss: 0.21060439944267273
train-epoch-step: 7-343 -- Loss: 0.1922224760055542
train-epoch-step: 7-344 -- Loss: 0.21325886249542236
train-epoch-step: 7-345 -- Loss: 0.15895316004753113
train-epoch-step: 7-346 -- Loss: 0.24649783968925476
train-epoch-step: 7-347 -- Loss: 0.20017343759536743
train-epoch-step: 7-348 -- Loss: 0.24889925122261047
train-epoch-step: 7-349 -- Loss: 0.27561119198799133
train-epoch-step: 7-350 -- Loss: 0.332300066947937
train-epoch-step: 7-351 -- Loss: 0.2569817900657654
train-epoch-step: 7-352 -- Loss: 0.17255640029907227
train-epoch-step: 7-353 -- Loss: 0.2362900674343109
train-epoch-step: 7-354 -- Loss: 0.3337298035621643
train-epoch-step: 7-355 -- Loss: 0.15412694215774536
train-epoch-step: 7-356 -- Loss: 0.14810700714588165
train-epoch-step: 7-357 -- Loss: 0.23210036754608154
train-epoch-step: 7-358 -- Loss: 0.2286132425069809
train-epoch-step: 7-359 -- Loss: 0.17826318740844727
train-epoch-step: 7-360 -- Loss: 0.15453581511974335
train-epoch-step: 7-361 -- Loss: 0.3133625388145447
train-epoch-step: 7-362 -- Loss: 0.21021762490272522
train-epoch-step: 7-363 -- Loss: 0.1443081796169281
train-epoch-step: 7-364 -- Loss: 0.22452619671821594
train-epoch-step: 7-365 -- Loss: 0.2089795619249344
train-epoch-step: 7-366 -- Loss: 0.24196210503578186
train-epoch-step: 7-367 -- Loss: 0.3398580551147461
train-epoch-step: 7-368 -- Loss: 0.25213760137557983
train-epoch-step: 7-369 -- Loss: 0.33496177196502686
train-epoch-step: 7-370 -- Loss: 0.15775682032108307
train-epoch-step: 7-371 -- Loss: 0.14876632392406464
train-epoch-step: 7-372 -- Loss: 0.1766822338104248
train-epoch-step: 7-373 -- Loss: 0.2414710521697998
train-epoch-step: 7-374 -- Loss: 0.18434719741344452
train-epoch-step: 7-375 -- Loss: 0.3607826828956604
train-epoch-step: 7-376 -- Loss: 0.25974106788635254
train-epoch-step: 7-377 -- Loss: 0.3004089593887329
train-epoch-step: 7-378 -- Loss: 0.26507848501205444
train-epoch-step: 7-379 -- Loss: 0.14327524602413177
train-epoch-step: 7-380 -- Loss: 0.11255565285682678
train-epoch-step: 7-381 -- Loss: 0.2963404655456543
train-epoch-step: 7-382 -- Loss: 0.2902000844478607
train-epoch-step: 7-383 -- Loss: 0.22034777700901031
train-epoch-step: 7-384 -- Loss: 0.26699501276016235
train-epoch-step: 7-385 -- Loss: 0.24916470050811768
train-epoch-step: 7-386 -- Loss: 0.24937084317207336
train-epoch-step: 7-387 -- Loss: 0.25151875615119934
train-epoch-step: 7-388 -- Loss: 0.28312206268310547
train-epoch-step: 7-389 -- Loss: 0.22156928479671478
train-epoch-step: 7-390 -- Loss: 0.17084191739559174
train-epoch-step: 7-391 -- Loss: 0.17822803556919098
train-epoch-step: 7-392 -- Loss: 0.2217675894498825
train-epoch-step: 7-393 -- Loss: 0.19361191987991333
train-epoch-step: 7-394 -- Loss: 0.277452290058136
train-epoch-step: 7-395 -- Loss: 0.1981566846370697
train-epoch-step: 7-396 -- Loss: 0.16016845405101776
train-epoch-step: 7-397 -- Loss: 0.15809586644172668
train-epoch-step: 7-398 -- Loss: 0.233135387301445
train-epoch-step: 7-399 -- Loss: 0.22416070103645325
train-epoch-step: 7-400 -- Loss: 0.3532564342021942
train-epoch-step: 7-401 -- Loss: 0.144227534532547
train-epoch-step: 7-402 -- Loss: 0.3082631528377533
train-epoch-step: 7-403 -- Loss: 0.20172765851020813
train-epoch-step: 7-404 -- Loss: 0.1724131852388382
train-epoch-step: 7-405 -- Loss: 0.18437227606773376
train-epoch-step: 7-406 -- Loss: 0.20255690813064575
train-epoch-step: 7-407 -- Loss: 0.14226284623146057
train-epoch-step: 7-408 -- Loss: 0.19668462872505188
train-epoch-step: 7-409 -- Loss: 0.21705010533332825
train-epoch-step: 7-410 -- Loss: 0.22116225957870483
train-epoch-step: 7-411 -- Loss: 0.2476697862148285
train-epoch-step: 7-412 -- Loss: 0.1599273979663849
train-epoch-step: 7-413 -- Loss: 0.1797875612974167
train-epoch-step: 7-414 -- Loss: 0.16953185200691223
train-epoch-step: 7-415 -- Loss: 0.17333097755908966
train-epoch-step: 7-416 -- Loss: 0.3218187987804413
train-epoch-step: 7-417 -- Loss: 0.2411954253911972
train-epoch-step: 7-418 -- Loss: 0.2940841019153595
train-epoch-step: 7-419 -- Loss: 0.2164025604724884
train-epoch-step: 7-420 -- Loss: 0.191831573843956
train-epoch-step: 7-421 -- Loss: 0.22395500540733337
train-epoch-step: 7-422 -- Loss: 0.17838063836097717
train-epoch-step: 7-423 -- Loss: 0.21437090635299683
train-epoch-step: 7-424 -- Loss: 0.16784551739692688
train-epoch-step: 7-425 -- Loss: 0.2221846878528595
train-epoch-step: 7-426 -- Loss: 0.19800758361816406
train-epoch-step: 7-427 -- Loss: 0.1713070273399353
train-epoch-step: 7-428 -- Loss: 0.24469302594661713
train-epoch-step: 7-429 -- Loss: 0.2106497436761856
train-epoch-step: 7-430 -- Loss: 0.1900048851966858
train-epoch-step: 7-431 -- Loss: 0.20399580895900726
train-epoch-step: 7-432 -- Loss: 0.29109108448028564
train-epoch-step: 7-433 -- Loss: 0.16985385119915009
train-epoch-step: 7-434 -- Loss: 0.16341368854045868
train-epoch-step: 7-435 -- Loss: 0.19500118494033813
train-epoch-step: 7-436 -- Loss: 0.19055376946926117
train-epoch-step: 7-437 -- Loss: 0.17368018627166748
train-epoch-step: 7-438 -- Loss: 0.21421602368354797
train-epoch-step: 7-439 -- Loss: 0.3384435474872589
train-epoch-step: 7-440 -- Loss: 0.16362980008125305
train-epoch-step: 7-441 -- Loss: 0.27253735065460205
train-epoch-step: 7-442 -- Loss: 0.23382309079170227
train-epoch-step: 7-443 -- Loss: 0.18882742524147034
train-epoch-step: 7-444 -- Loss: 0.3176499605178833
train-epoch-step: 7-445 -- Loss: 0.21841008961200714
train-epoch-step: 7-446 -- Loss: 0.1916499137878418
train-epoch-step: 7-447 -- Loss: 0.24701239168643951
train-epoch-step: 7-448 -- Loss: 0.3140246868133545
train-epoch-step: 7-449 -- Loss: 0.2302180826663971
train-epoch-step: 7-450 -- Loss: 0.22854655981063843
train-epoch-step: 7-451 -- Loss: 0.17952515184879303
train-epoch-step: 7-452 -- Loss: 0.16465237736701965
train-epoch-step: 7-453 -- Loss: 0.12454560399055481
train-epoch-step: 7-454 -- Loss: 0.29613548517227173
train-epoch-step: 7-455 -- Loss: 0.16728709638118744
train-epoch-step: 7-456 -- Loss: 0.14963185787200928
train-epoch-step: 7-457 -- Loss: 0.2755512297153473
train-epoch-step: 7-458 -- Loss: 0.19157743453979492
train-epoch-step: 7-459 -- Loss: 0.2633349299430847
train-epoch-step: 7-460 -- Loss: 0.15549615025520325
train-epoch-step: 7-461 -- Loss: 0.1787574291229248
train-epoch-step: 7-462 -- Loss: 0.1868487298488617
train-epoch-step: 7-463 -- Loss: 0.1667712926864624
train-epoch-step: 7-464 -- Loss: 0.21728959679603577
train-epoch-step: 7-465 -- Loss: 0.31161564588546753
train-epoch-step: 7-466 -- Loss: 0.24451559782028198
train-epoch-step: 7-467 -- Loss: 0.1446298211812973
train-epoch-step: 7-468 -- Loss: 0.252435564994812
train-epoch-step: 7-469 -- Loss: 0.3313554525375366
train-epoch-step: 7-470 -- Loss: 0.22451604902744293
train-epoch-step: 7-471 -- Loss: 0.1933896541595459
train-epoch-step: 7-472 -- Loss: 0.19774213433265686
train-epoch-step: 7-473 -- Loss: 0.21291571855545044
train-epoch-step: 7-474 -- Loss: 0.15363706648349762
train-epoch-step: 7-475 -- Loss: 0.1363365352153778
train-epoch-step: 7-476 -- Loss: 0.24113520979881287
train-epoch-step: 7-477 -- Loss: 0.2739018499851227
train-epoch-step: 7-478 -- Loss: 0.22979675233364105
train-epoch-step: 7-479 -- Loss: 0.17759618163108826
train-epoch-step: 7-480 -- Loss: 0.23415310680866241
train-epoch-step: 7-481 -- Loss: 0.3430716395378113
train-epoch-step: 7-482 -- Loss: 0.32471543550491333
train-epoch-step: 7-483 -- Loss: 0.24937893450260162
train-epoch-step: 7-484 -- Loss: 0.2546025216579437
train-epoch-step: 7-485 -- Loss: 0.16063833236694336
train-epoch-step: 7-486 -- Loss: 0.3256586194038391
train-epoch-step: 7-487 -- Loss: 0.27155762910842896
train-epoch-step: 7-488 -- Loss: 0.23152481019496918
train-epoch-step: 7-489 -- Loss: 0.2612806558609009
train-epoch-step: 7-490 -- Loss: 0.17262385785579681
train-epoch-step: 7-491 -- Loss: 0.17100505530834198
train-epoch-step: 7-492 -- Loss: 0.1551448106765747
train-epoch-step: 7-493 -- Loss: 0.2654361426830292
train-epoch-step: 7-494 -- Loss: 0.2644517123699188
train-epoch-step: 7-495 -- Loss: 0.2511637806892395
train-epoch-step: 7-496 -- Loss: 0.16796988248825073
train-epoch-step: 7-497 -- Loss: 0.23149484395980835
train-epoch-step: 7-498 -- Loss: 0.18319499492645264
train-epoch-step: 7-499 -- Loss: 0.20163246989250183
train-epoch-step: 7-500 -- Loss: 0.18971814215183258
train-epoch-step: 7-501 -- Loss: 0.26043248176574707
train-epoch-step: 7-502 -- Loss: 0.19897888600826263
train-epoch-step: 7-503 -- Loss: 0.2733348608016968
train-epoch-step: 7-504 -- Loss: 0.14750301837921143
train-epoch-step: 7-505 -- Loss: 0.21389886736869812
train-epoch-step: 7-506 -- Loss: 0.15153269469738007
train-epoch-step: 7-507 -- Loss: 0.21945811808109283
train-epoch-step: 7-508 -- Loss: 0.21128302812576294
train-epoch-step: 7-509 -- Loss: 0.2074052095413208
train-epoch-step: 7-510 -- Loss: 0.16198505461215973
train-epoch-step: 7-511 -- Loss: 0.2609848082065582
train-epoch-step: 7-512 -- Loss: 0.21948635578155518
train-epoch-step: 7-513 -- Loss: 0.24716755747795105
train-epoch-step: 7-514 -- Loss: 0.17796939611434937
train-epoch-step: 7-515 -- Loss: 0.1975819170475006
train-epoch-step: 7-516 -- Loss: 0.20081700384616852
train-epoch-step: 7-517 -- Loss: 0.2258775234222412
train-epoch-step: 7-518 -- Loss: 0.1679372489452362
train-epoch-step: 7-519 -- Loss: 0.16277648508548737
train-epoch-step: 7-520 -- Loss: 0.22497564554214478
train-epoch-step: 7-521 -- Loss: 0.28112488985061646
train-epoch-step: 7-522 -- Loss: 0.2107340395450592
train-epoch-step: 7-523 -- Loss: 0.19178448617458344
train-epoch-step: 7-524 -- Loss: 0.20256003737449646
train-epoch-step: 7-525 -- Loss: 0.2245156168937683
train-epoch-step: 7-526 -- Loss: 0.1569465547800064
train-epoch-step: 7-527 -- Loss: 0.19842500984668732
train-epoch-step: 7-528 -- Loss: 0.19254648685455322
train-epoch-step: 7-529 -- Loss: 0.21720120310783386
train-epoch-step: 7-530 -- Loss: 0.21712003648281097
train-epoch-step: 7-531 -- Loss: 0.2420022040605545
train-epoch-step: 7-532 -- Loss: 0.20755882561206818
train-epoch-step: 7-533 -- Loss: 0.2010287642478943
train-epoch-step: 7-534 -- Loss: 0.16790544986724854
train-epoch-step: 7-535 -- Loss: 0.3456330895423889
train-epoch-step: 7-536 -- Loss: 0.19204974174499512
train-epoch-step: 7-537 -- Loss: 0.18684139847755432
train-epoch-step: 7-538 -- Loss: 0.1230507642030716
train-epoch-step: 7-539 -- Loss: 0.23675766587257385
train-epoch-step: 7-540 -- Loss: 0.16275134682655334
train-epoch-step: 7-541 -- Loss: 0.25451236963272095
train-epoch-step: 7-542 -- Loss: 0.28995946049690247
train-epoch-step: 7-543 -- Loss: 0.19900844991207123
train-epoch-step: 7-544 -- Loss: 0.2645905613899231
train-epoch-step: 7-545 -- Loss: 0.23501400649547577
train-epoch-step: 7-546 -- Loss: 0.27978670597076416
train-epoch-step: 7-547 -- Loss: 0.21020127832889557
train-epoch-step: 7-548 -- Loss: 0.109877809882164
train-epoch-step: 7-549 -- Loss: 0.18125545978546143
train-epoch-step: 7-550 -- Loss: 0.24181431531906128
train-epoch-step: 7-551 -- Loss: 0.19451908767223358
train-epoch-step: 7-552 -- Loss: 0.15347275137901306
train-epoch-step: 7-553 -- Loss: 0.2257382869720459
train-epoch-step: 7-554 -- Loss: 0.21789106726646423
train-epoch-step: 7-555 -- Loss: 0.26911216974258423
train-epoch-step: 7-556 -- Loss: 0.21962668001651764
train-epoch-step: 7-557 -- Loss: 0.2825663089752197
train-epoch-step: 7-558 -- Loss: 0.2736593186855316
train-epoch-step: 7-559 -- Loss: 0.17563873529434204
train-epoch-step: 7-560 -- Loss: 0.24196401238441467
train-epoch-step: 7-561 -- Loss: 0.23293063044548035
train-epoch-step: 7-562 -- Loss: 0.2419561892747879
train-epoch-step: 7-563 -- Loss: 0.23502784967422485
train-epoch-step: 7-564 -- Loss: 0.13128024339675903
train-epoch-step: 7-565 -- Loss: 0.2246977537870407
train-epoch-step: 7-566 -- Loss: 0.19944755733013153
train-epoch-step: 7-567 -- Loss: 0.2545737624168396
train-epoch-step: 7-568 -- Loss: 0.19012796878814697
train-epoch-step: 7-569 -- Loss: 0.27581995725631714
train-epoch-step: 7-570 -- Loss: 0.22019417583942413
train-epoch-step: 7-571 -- Loss: 0.26147958636283875
train-epoch-step: 7-572 -- Loss: 0.2952668368816376
train-epoch-step: 7-573 -- Loss: 0.2584298253059387
train-epoch-step: 7-574 -- Loss: 0.3075867295265198
train-epoch-step: 7-575 -- Loss: 0.38198429346084595
train-epoch-step: 7-576 -- Loss: 0.1481812596321106
train-epoch-step: 7-577 -- Loss: 0.20690086483955383
train-epoch-step: 7-578 -- Loss: 0.2757185697555542
train-epoch-step: 7-579 -- Loss: 0.20567993819713593
train-epoch-step: 7-580 -- Loss: 0.2429782599210739
train-epoch-step: 7-581 -- Loss: 0.17248331010341644
train-epoch-step: 7-582 -- Loss: 0.26770663261413574
train-epoch-step: 7-583 -- Loss: 0.29308927059173584
train-epoch-step: 7-584 -- Loss: 0.24374839663505554
train-epoch-step: 7-585 -- Loss: 0.23163047432899475
train-epoch-step: 7-586 -- Loss: 0.32494425773620605
train-epoch-step: 7-587 -- Loss: 0.19079121947288513
train-epoch-step: 7-588 -- Loss: 0.15314297378063202
val-epoch-step: 7-589 -- Loss: 0.25883030891418457
val-epoch-step: 7-590 -- Loss: 0.18136100471019745
val-epoch-step: 7-591 -- Loss: 0.24716371297836304
val-epoch-step: 7-592 -- Loss: 0.21718481183052063
val-epoch-step: 7-593 -- Loss: 0.17501966655254364
val-epoch-step: 7-594 -- Loss: 0.38741862773895264
val-epoch-step: 7-595 -- Loss: 0.20672255754470825
val-epoch-step: 7-596 -- Loss: 0.2501506507396698
val-epoch-step: 7-597 -- Loss: 0.21426965296268463
val-epoch-step: 7-598 -- Loss: 0.17781148850917816
val-epoch-step: 7-599 -- Loss: 0.21246932446956635
val-epoch-step: 7-600 -- Loss: 0.22630488872528076
val-epoch-step: 7-601 -- Loss: 0.1861766278743744
val-epoch-step: 7-602 -- Loss: 0.162311851978302
val-epoch-step: 7-603 -- Loss: 0.20380333065986633
val-epoch-step: 7-604 -- Loss: 0.175874263048172
val-epoch-step: 7-605 -- Loss: 0.1738450527191162
val-epoch-step: 7-606 -- Loss: 0.31911593675613403
val-epoch-step: 7-607 -- Loss: 0.1581118106842041
val-epoch-step: 7-608 -- Loss: 0.2968570291996002
val-epoch-step: 7-609 -- Loss: 0.210252046585083
val-epoch-step: 7-610 -- Loss: 0.22409209609031677
val-epoch-step: 7-611 -- Loss: 0.1952427178621292
val-epoch-step: 7-612 -- Loss: 0.38095995783805847
val-epoch-step: 7-613 -- Loss: 0.21034978330135345
val-epoch-step: 7-614 -- Loss: 0.19233694672584534
val-epoch-step: 7-615 -- Loss: 0.2231089472770691
val-epoch-step: 7-616 -- Loss: 0.18037429451942444
val-epoch-step: 7-617 -- Loss: 0.2303207516670227
val-epoch-step: 7-618 -- Loss: 0.2395358681678772
val-epoch-step: 7-619 -- Loss: 0.26093387603759766
val-epoch-step: 7-620 -- Loss: 0.17078939080238342
val-epoch-step: 7-621 -- Loss: 0.1713089644908905
val-epoch-step: 7-622 -- Loss: 0.1720193475484848
val-epoch-step: 7-623 -- Loss: 0.17762446403503418
val-epoch-step: 7-624 -- Loss: 0.21400120854377747
val-epoch-step: 7-625 -- Loss: 0.19026800990104675
val-epoch-step: 7-626 -- Loss: 0.17816418409347534
val-epoch-step: 7-627 -- Loss: 0.2333977073431015
val-epoch-step: 7-628 -- Loss: 0.5834060311317444
val-epoch-step: 7-629 -- Loss: 0.24076113104820251
val-epoch-step: 7-630 -- Loss: 0.4056549668312073
val-epoch-step: 7-631 -- Loss: 0.1773073971271515
val-epoch-step: 7-632 -- Loss: 0.2346387505531311
val-epoch-step: 7-633 -- Loss: 0.1899724304676056
val-epoch-step: 7-634 -- Loss: 0.16500473022460938
val-epoch-step: 7-635 -- Loss: 0.1343059092760086
val-epoch-step: 7-636 -- Loss: 0.19748714566230774
val-epoch-step: 7-637 -- Loss: 0.21386030316352844
val-epoch-step: 7-638 -- Loss: 0.1842157244682312
val-epoch-step: 7-639 -- Loss: 0.3177757263183594
val-epoch-step: 7-640 -- Loss: 0.29280778765678406
val-epoch-step: 7-641 -- Loss: 0.14646470546722412
val-epoch-step: 7-642 -- Loss: 0.23201708495616913
val-epoch-step: 7-643 -- Loss: 0.24233508110046387
val-epoch-step: 7-644 -- Loss: 0.191144198179245
val-epoch-step: 7-645 -- Loss: 0.2639693319797516
val-epoch-step: 7-646 -- Loss: 0.17469371855258942
val-epoch-step: 7-647 -- Loss: 0.1582731008529663
val-epoch-step: 7-648 -- Loss: 0.19250671565532684
val-epoch-step: 7-649 -- Loss: 0.26637762784957886
val-epoch-step: 7-650 -- Loss: 0.29799753427505493
val-epoch-step: 7-651 -- Loss: 0.16662713885307312
val-epoch-step: 7-652 -- Loss: 0.19411954283714294
val-epoch-step: 7-653 -- Loss: 0.24102789163589478
val-epoch-step: 7-654 -- Loss: 0.13495196402072906
Epoch: 7 -- Train Loss: tensor(0.1579, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1559, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 8-0 -- Loss: 0.2725778818130493
train-epoch-step: 8-1 -- Loss: 0.17497754096984863
train-epoch-step: 8-2 -- Loss: 0.24118325114250183
train-epoch-step: 8-3 -- Loss: 0.1832636296749115
train-epoch-step: 8-4 -- Loss: 0.25391826033592224
train-epoch-step: 8-5 -- Loss: 0.2295188009738922
train-epoch-step: 8-6 -- Loss: 0.27480292320251465
train-epoch-step: 8-7 -- Loss: 0.20583374798297882
train-epoch-step: 8-8 -- Loss: 0.23221486806869507
train-epoch-step: 8-9 -- Loss: 0.32685932517051697
train-epoch-step: 8-10 -- Loss: 0.2968846559524536
train-epoch-step: 8-11 -- Loss: 0.2156059294939041
train-epoch-step: 8-12 -- Loss: 0.193098783493042
train-epoch-step: 8-13 -- Loss: 0.22925156354904175
train-epoch-step: 8-14 -- Loss: 0.19169607758522034
train-epoch-step: 8-15 -- Loss: 0.19129633903503418
train-epoch-step: 8-16 -- Loss: 0.20810054242610931
train-epoch-step: 8-17 -- Loss: 0.2673378586769104
train-epoch-step: 8-18 -- Loss: 0.2299494743347168
train-epoch-step: 8-19 -- Loss: 0.16147632896900177
train-epoch-step: 8-20 -- Loss: 0.27583709359169006
train-epoch-step: 8-21 -- Loss: 0.4257863163948059
train-epoch-step: 8-22 -- Loss: 0.18960034847259521
train-epoch-step: 8-23 -- Loss: 0.22461417317390442
train-epoch-step: 8-24 -- Loss: 0.159121572971344
train-epoch-step: 8-25 -- Loss: 0.26693543791770935
train-epoch-step: 8-26 -- Loss: 0.2419288009405136
train-epoch-step: 8-27 -- Loss: 0.30459722876548767
train-epoch-step: 8-28 -- Loss: 0.15180866420269012
train-epoch-step: 8-29 -- Loss: 0.2848473787307739
train-epoch-step: 8-30 -- Loss: 0.13366244733333588
train-epoch-step: 8-31 -- Loss: 0.17656372487545013
train-epoch-step: 8-32 -- Loss: 0.2092134952545166
train-epoch-step: 8-33 -- Loss: 0.31352800130844116
train-epoch-step: 8-34 -- Loss: 0.20194736123085022
train-epoch-step: 8-35 -- Loss: 0.29392510652542114
train-epoch-step: 8-36 -- Loss: 0.16721677780151367
train-epoch-step: 8-37 -- Loss: 0.1734820306301117
train-epoch-step: 8-38 -- Loss: 0.24170461297035217
train-epoch-step: 8-39 -- Loss: 0.2873503267765045
train-epoch-step: 8-40 -- Loss: 0.2545678913593292
train-epoch-step: 8-41 -- Loss: 0.2538819909095764
train-epoch-step: 8-42 -- Loss: 0.18323157727718353
train-epoch-step: 8-43 -- Loss: 0.33595049381256104
train-epoch-step: 8-44 -- Loss: 0.1531010866165161
train-epoch-step: 8-45 -- Loss: 0.1555565893650055
train-epoch-step: 8-46 -- Loss: 0.2177484631538391
train-epoch-step: 8-47 -- Loss: 0.2966112494468689
train-epoch-step: 8-48 -- Loss: 0.18504445254802704
train-epoch-step: 8-49 -- Loss: 0.26416537165641785
train-epoch-step: 8-50 -- Loss: 0.14682698249816895
train-epoch-step: 8-51 -- Loss: 0.23384803533554077
train-epoch-step: 8-52 -- Loss: 0.18914882838726044
train-epoch-step: 8-53 -- Loss: 0.26495832204818726
train-epoch-step: 8-54 -- Loss: 0.33685341477394104
train-epoch-step: 8-55 -- Loss: 0.21117670834064484
train-epoch-step: 8-56 -- Loss: 0.22659176588058472
train-epoch-step: 8-57 -- Loss: 0.28556644916534424
train-epoch-step: 8-58 -- Loss: 0.3317045569419861
train-epoch-step: 8-59 -- Loss: 0.31313008069992065
train-epoch-step: 8-60 -- Loss: 0.1539967656135559
train-epoch-step: 8-61 -- Loss: 0.2648543119430542
train-epoch-step: 8-62 -- Loss: 0.22355200350284576
train-epoch-step: 8-63 -- Loss: 0.16720177233219147
train-epoch-step: 8-64 -- Loss: 0.18791285157203674
train-epoch-step: 8-65 -- Loss: 0.23171934485435486
train-epoch-step: 8-66 -- Loss: 0.13487191498279572
train-epoch-step: 8-67 -- Loss: 0.1522088199853897
train-epoch-step: 8-68 -- Loss: 0.2767832279205322
train-epoch-step: 8-69 -- Loss: 0.163360595703125
train-epoch-step: 8-70 -- Loss: 0.2584892213344574
train-epoch-step: 8-71 -- Loss: 0.30341455340385437
train-epoch-step: 8-72 -- Loss: 0.22285932302474976
train-epoch-step: 8-73 -- Loss: 0.25403454899787903
train-epoch-step: 8-74 -- Loss: 0.11865773797035217
train-epoch-step: 8-75 -- Loss: 0.16736839711666107
train-epoch-step: 8-76 -- Loss: 0.1781659871339798
train-epoch-step: 8-77 -- Loss: 0.26890188455581665
train-epoch-step: 8-78 -- Loss: 0.3244544267654419
train-epoch-step: 8-79 -- Loss: 0.23075252771377563
train-epoch-step: 8-80 -- Loss: 0.3712742328643799
train-epoch-step: 8-81 -- Loss: 0.15284301340579987
train-epoch-step: 8-82 -- Loss: 0.2999674677848816
train-epoch-step: 8-83 -- Loss: 0.22505789995193481
train-epoch-step: 8-84 -- Loss: 0.24374151229858398
train-epoch-step: 8-85 -- Loss: 0.21833595633506775
train-epoch-step: 8-86 -- Loss: 0.1532575786113739
train-epoch-step: 8-87 -- Loss: 0.29207292199134827
train-epoch-step: 8-88 -- Loss: 0.16667558252811432
train-epoch-step: 8-89 -- Loss: 0.23460504412651062
train-epoch-step: 8-90 -- Loss: 0.2352180778980255
train-epoch-step: 8-91 -- Loss: 0.29318398237228394
train-epoch-step: 8-92 -- Loss: 0.19114327430725098
train-epoch-step: 8-93 -- Loss: 0.22123388946056366
train-epoch-step: 8-94 -- Loss: 0.28096333146095276
train-epoch-step: 8-95 -- Loss: 0.24270634353160858
train-epoch-step: 8-96 -- Loss: 0.28391721844673157
train-epoch-step: 8-97 -- Loss: 0.21767425537109375
train-epoch-step: 8-98 -- Loss: 0.1841096431016922
train-epoch-step: 8-99 -- Loss: 0.22239606082439423
train-epoch-step: 8-100 -- Loss: 0.2343841940164566
train-epoch-step: 8-101 -- Loss: 0.3272552490234375
train-epoch-step: 8-102 -- Loss: 0.289678156375885
train-epoch-step: 8-103 -- Loss: 0.236124187707901
train-epoch-step: 8-104 -- Loss: 0.17722728848457336
train-epoch-step: 8-105 -- Loss: 0.33219555020332336
train-epoch-step: 8-106 -- Loss: 0.2218513786792755
train-epoch-step: 8-107 -- Loss: 0.225948303937912
train-epoch-step: 8-108 -- Loss: 0.22448448836803436
train-epoch-step: 8-109 -- Loss: 0.18388403952121735
train-epoch-step: 8-110 -- Loss: 0.22026635706424713
train-epoch-step: 8-111 -- Loss: 0.22652876377105713
train-epoch-step: 8-112 -- Loss: 0.2061486542224884
train-epoch-step: 8-113 -- Loss: 0.20688137412071228
train-epoch-step: 8-114 -- Loss: 0.2768990993499756
train-epoch-step: 8-115 -- Loss: 0.2025800198316574
train-epoch-step: 8-116 -- Loss: 0.18717417120933533
train-epoch-step: 8-117 -- Loss: 0.15449289977550507
train-epoch-step: 8-118 -- Loss: 0.2446555346250534
train-epoch-step: 8-119 -- Loss: 0.19160059094429016
train-epoch-step: 8-120 -- Loss: 0.33845996856689453
train-epoch-step: 8-121 -- Loss: 0.32494625449180603
train-epoch-step: 8-122 -- Loss: 0.26358357071876526
train-epoch-step: 8-123 -- Loss: 0.26063817739486694
train-epoch-step: 8-124 -- Loss: 0.14689549803733826
train-epoch-step: 8-125 -- Loss: 0.19084572792053223
train-epoch-step: 8-126 -- Loss: 0.29499030113220215
train-epoch-step: 8-127 -- Loss: 0.21711435914039612
train-epoch-step: 8-128 -- Loss: 0.2102580964565277
train-epoch-step: 8-129 -- Loss: 0.1758260577917099
train-epoch-step: 8-130 -- Loss: 0.22920826077461243
train-epoch-step: 8-131 -- Loss: 0.1673978865146637
train-epoch-step: 8-132 -- Loss: 0.24307185411453247
train-epoch-step: 8-133 -- Loss: 0.14161817729473114
train-epoch-step: 8-134 -- Loss: 0.24225598573684692
train-epoch-step: 8-135 -- Loss: 0.16464777290821075
train-epoch-step: 8-136 -- Loss: 0.15425296127796173
train-epoch-step: 8-137 -- Loss: 0.3145461678504944
train-epoch-step: 8-138 -- Loss: 0.3151453137397766
train-epoch-step: 8-139 -- Loss: 0.16067802906036377
train-epoch-step: 8-140 -- Loss: 0.24713373184204102
train-epoch-step: 8-141 -- Loss: 0.28444358706474304
train-epoch-step: 8-142 -- Loss: 0.24735088646411896
train-epoch-step: 8-143 -- Loss: 0.20521098375320435
train-epoch-step: 8-144 -- Loss: 0.22527550160884857
train-epoch-step: 8-145 -- Loss: 0.1655634194612503
train-epoch-step: 8-146 -- Loss: 0.21391037106513977
train-epoch-step: 8-147 -- Loss: 0.22953778505325317
train-epoch-step: 8-148 -- Loss: 0.21674564480781555
train-epoch-step: 8-149 -- Loss: 0.14465054869651794
train-epoch-step: 8-150 -- Loss: 0.22870197892189026
train-epoch-step: 8-151 -- Loss: 0.2270870953798294
train-epoch-step: 8-152 -- Loss: 0.2381230890750885
train-epoch-step: 8-153 -- Loss: 0.3791654706001282
train-epoch-step: 8-154 -- Loss: 0.16192558407783508
train-epoch-step: 8-155 -- Loss: 0.1733756810426712
train-epoch-step: 8-156 -- Loss: 0.154558464884758
train-epoch-step: 8-157 -- Loss: 0.20958945155143738
train-epoch-step: 8-158 -- Loss: 0.20103819668293
train-epoch-step: 8-159 -- Loss: 0.20963113009929657
train-epoch-step: 8-160 -- Loss: 0.28135597705841064
train-epoch-step: 8-161 -- Loss: 0.26331982016563416
train-epoch-step: 8-162 -- Loss: 0.2522670030593872
train-epoch-step: 8-163 -- Loss: 0.2214580923318863
train-epoch-step: 8-164 -- Loss: 0.22371414303779602
train-epoch-step: 8-165 -- Loss: 0.20314431190490723
train-epoch-step: 8-166 -- Loss: 0.14798788726329803
train-epoch-step: 8-167 -- Loss: 0.14334963262081146
train-epoch-step: 8-168 -- Loss: 0.2543071508407593
train-epoch-step: 8-169 -- Loss: 0.17054016888141632
train-epoch-step: 8-170 -- Loss: 0.2503682076931
train-epoch-step: 8-171 -- Loss: 0.16674849390983582
train-epoch-step: 8-172 -- Loss: 0.3109896779060364
train-epoch-step: 8-173 -- Loss: 0.15898245573043823
train-epoch-step: 8-174 -- Loss: 0.2890912890434265
train-epoch-step: 8-175 -- Loss: 0.21533513069152832
train-epoch-step: 8-176 -- Loss: 0.16026629507541656
train-epoch-step: 8-177 -- Loss: 0.22829535603523254
train-epoch-step: 8-178 -- Loss: 0.23200955986976624
train-epoch-step: 8-179 -- Loss: 0.17191511392593384
train-epoch-step: 8-180 -- Loss: 0.17902278900146484
train-epoch-step: 8-181 -- Loss: 0.22057746350765228
train-epoch-step: 8-182 -- Loss: 0.2374052256345749
train-epoch-step: 8-183 -- Loss: 0.3250073194503784
train-epoch-step: 8-184 -- Loss: 0.16353662312030792
train-epoch-step: 8-185 -- Loss: 0.17761076986789703
train-epoch-step: 8-186 -- Loss: 0.24288755655288696
train-epoch-step: 8-187 -- Loss: 0.2653353214263916
train-epoch-step: 8-188 -- Loss: 0.2104116976261139
train-epoch-step: 8-189 -- Loss: 0.16938117146492004
train-epoch-step: 8-190 -- Loss: 0.21990087628364563
train-epoch-step: 8-191 -- Loss: 0.22403272986412048
train-epoch-step: 8-192 -- Loss: 0.30319711565971375
train-epoch-step: 8-193 -- Loss: 0.27425041794776917
train-epoch-step: 8-194 -- Loss: 0.220413938164711
train-epoch-step: 8-195 -- Loss: 0.19022895395755768
train-epoch-step: 8-196 -- Loss: 0.22215956449508667
train-epoch-step: 8-197 -- Loss: 0.1714116632938385
train-epoch-step: 8-198 -- Loss: 0.1678367406129837
train-epoch-step: 8-199 -- Loss: 0.18596452474594116
train-epoch-step: 8-200 -- Loss: 0.1502053290605545
train-epoch-step: 8-201 -- Loss: 0.24344095587730408
train-epoch-step: 8-202 -- Loss: 0.16985604166984558
train-epoch-step: 8-203 -- Loss: 0.21521808207035065
train-epoch-step: 8-204 -- Loss: 0.1828828752040863
train-epoch-step: 8-205 -- Loss: 0.22325168550014496
train-epoch-step: 8-206 -- Loss: 0.24843749403953552
train-epoch-step: 8-207 -- Loss: 0.16150401532649994
train-epoch-step: 8-208 -- Loss: 0.2201499193906784
train-epoch-step: 8-209 -- Loss: 0.1667594015598297
train-epoch-step: 8-210 -- Loss: 0.17053720355033875
train-epoch-step: 8-211 -- Loss: 0.2526494860649109
train-epoch-step: 8-212 -- Loss: 0.2392868995666504
train-epoch-step: 8-213 -- Loss: 0.15298332273960114
train-epoch-step: 8-214 -- Loss: 0.1770794689655304
train-epoch-step: 8-215 -- Loss: 0.16706238687038422
train-epoch-step: 8-216 -- Loss: 0.2423628866672516
train-epoch-step: 8-217 -- Loss: 0.2585713863372803
train-epoch-step: 8-218 -- Loss: 0.19292640686035156
train-epoch-step: 8-219 -- Loss: 0.2624807357788086
train-epoch-step: 8-220 -- Loss: 0.1631670594215393
train-epoch-step: 8-221 -- Loss: 0.23843832314014435
train-epoch-step: 8-222 -- Loss: 0.1511787474155426
train-epoch-step: 8-223 -- Loss: 0.21300184726715088
train-epoch-step: 8-224 -- Loss: 0.22958557307720184
train-epoch-step: 8-225 -- Loss: 0.38248109817504883
train-epoch-step: 8-226 -- Loss: 0.262106716632843
train-epoch-step: 8-227 -- Loss: 0.2904748022556305
train-epoch-step: 8-228 -- Loss: 0.21725408732891083
train-epoch-step: 8-229 -- Loss: 0.22618429362773895
train-epoch-step: 8-230 -- Loss: 0.19475683569908142
train-epoch-step: 8-231 -- Loss: 0.22292864322662354
train-epoch-step: 8-232 -- Loss: 0.2470317929983139
train-epoch-step: 8-233 -- Loss: 0.10372543334960938
train-epoch-step: 8-234 -- Loss: 0.21868813037872314
train-epoch-step: 8-235 -- Loss: 0.19530577957630157
train-epoch-step: 8-236 -- Loss: 0.21653735637664795
train-epoch-step: 8-237 -- Loss: 0.29589566588401794
train-epoch-step: 8-238 -- Loss: 0.1884053349494934
train-epoch-step: 8-239 -- Loss: 0.1647597998380661
train-epoch-step: 8-240 -- Loss: 0.26070141792297363
train-epoch-step: 8-241 -- Loss: 0.18539196252822876
train-epoch-step: 8-242 -- Loss: 0.27255529165267944
train-epoch-step: 8-243 -- Loss: 0.27555549144744873
train-epoch-step: 8-244 -- Loss: 0.24852244555950165
train-epoch-step: 8-245 -- Loss: 0.30164772272109985
train-epoch-step: 8-246 -- Loss: 0.3365880846977234
train-epoch-step: 8-247 -- Loss: 0.2846542298793793
train-epoch-step: 8-248 -- Loss: 0.22965319454669952
train-epoch-step: 8-249 -- Loss: 0.1803913116455078
train-epoch-step: 8-250 -- Loss: 0.24110066890716553
train-epoch-step: 8-251 -- Loss: 0.135928213596344
train-epoch-step: 8-252 -- Loss: 0.2510109543800354
train-epoch-step: 8-253 -- Loss: 0.17489303648471832
train-epoch-step: 8-254 -- Loss: 0.30684152245521545
train-epoch-step: 8-255 -- Loss: 0.1815597414970398
train-epoch-step: 8-256 -- Loss: 0.19262981414794922
train-epoch-step: 8-257 -- Loss: 0.23500514030456543
train-epoch-step: 8-258 -- Loss: 0.1899196356534958
train-epoch-step: 8-259 -- Loss: 0.1553611308336258
train-epoch-step: 8-260 -- Loss: 0.2572871446609497
train-epoch-step: 8-261 -- Loss: 0.21611447632312775
train-epoch-step: 8-262 -- Loss: 0.37303704023361206
train-epoch-step: 8-263 -- Loss: 0.3518945872783661
train-epoch-step: 8-264 -- Loss: 0.20634222030639648
train-epoch-step: 8-265 -- Loss: 0.13877910375595093
train-epoch-step: 8-266 -- Loss: 0.19258487224578857
train-epoch-step: 8-267 -- Loss: 0.17809200286865234
train-epoch-step: 8-268 -- Loss: 0.14882218837738037
train-epoch-step: 8-269 -- Loss: 0.220689594745636
train-epoch-step: 8-270 -- Loss: 0.1368047595024109
train-epoch-step: 8-271 -- Loss: 0.18533341586589813
train-epoch-step: 8-272 -- Loss: 0.14486823976039886
train-epoch-step: 8-273 -- Loss: 0.1586424559354782
train-epoch-step: 8-274 -- Loss: 0.22849148511886597
train-epoch-step: 8-275 -- Loss: 0.2464267611503601
train-epoch-step: 8-276 -- Loss: 0.19110232591629028
train-epoch-step: 8-277 -- Loss: 0.18710947036743164
train-epoch-step: 8-278 -- Loss: 0.17986303567886353
train-epoch-step: 8-279 -- Loss: 0.18307384848594666
train-epoch-step: 8-280 -- Loss: 0.25777482986450195
train-epoch-step: 8-281 -- Loss: 0.21883775293827057
train-epoch-step: 8-282 -- Loss: 0.16689637303352356
train-epoch-step: 8-283 -- Loss: 0.14142245054244995
train-epoch-step: 8-284 -- Loss: 0.2600722312927246
train-epoch-step: 8-285 -- Loss: 0.24056938290596008
train-epoch-step: 8-286 -- Loss: 0.1931867152452469
train-epoch-step: 8-287 -- Loss: 0.2494952529668808
train-epoch-step: 8-288 -- Loss: 0.11402933299541473
train-epoch-step: 8-289 -- Loss: 0.15650531649589539
train-epoch-step: 8-290 -- Loss: 0.22801686823368073
train-epoch-step: 8-291 -- Loss: 0.142282173037529
train-epoch-step: 8-292 -- Loss: 0.19088368117809296
train-epoch-step: 8-293 -- Loss: 0.16772237420082092
train-epoch-step: 8-294 -- Loss: 0.21194206178188324
train-epoch-step: 8-295 -- Loss: 0.36321815848350525
train-epoch-step: 8-296 -- Loss: 0.2066907286643982
train-epoch-step: 8-297 -- Loss: 0.20906749367713928
train-epoch-step: 8-298 -- Loss: 0.2906286120414734
train-epoch-step: 8-299 -- Loss: 0.20155371725559235
train-epoch-step: 8-300 -- Loss: 0.2145403027534485
train-epoch-step: 8-301 -- Loss: 0.19638046622276306
train-epoch-step: 8-302 -- Loss: 0.26819223165512085
train-epoch-step: 8-303 -- Loss: 0.24873918294906616
train-epoch-step: 8-304 -- Loss: 0.1763536036014557
train-epoch-step: 8-305 -- Loss: 0.18075165152549744
train-epoch-step: 8-306 -- Loss: 0.27591565251350403
train-epoch-step: 8-307 -- Loss: 0.2004464864730835
train-epoch-step: 8-308 -- Loss: 0.2962624728679657
train-epoch-step: 8-309 -- Loss: 0.18484054505825043
train-epoch-step: 8-310 -- Loss: 0.19594980776309967
train-epoch-step: 8-311 -- Loss: 0.1993209719657898
train-epoch-step: 8-312 -- Loss: 0.26727890968322754
train-epoch-step: 8-313 -- Loss: 0.11993822455406189
train-epoch-step: 8-314 -- Loss: 0.247536763548851
train-epoch-step: 8-315 -- Loss: 0.20148873329162598
train-epoch-step: 8-316 -- Loss: 0.1853352040052414
train-epoch-step: 8-317 -- Loss: 0.17717066407203674
train-epoch-step: 8-318 -- Loss: 0.20183859765529633
train-epoch-step: 8-319 -- Loss: 0.22817213833332062
train-epoch-step: 8-320 -- Loss: 0.1452515423297882
train-epoch-step: 8-321 -- Loss: 0.16736042499542236
train-epoch-step: 8-322 -- Loss: 0.2558647692203522
train-epoch-step: 8-323 -- Loss: 0.18649759888648987
train-epoch-step: 8-324 -- Loss: 0.31953611969947815
train-epoch-step: 8-325 -- Loss: 0.18103164434432983
train-epoch-step: 8-326 -- Loss: 0.21324536204338074
train-epoch-step: 8-327 -- Loss: 0.262001097202301
train-epoch-step: 8-328 -- Loss: 0.24235416948795319
train-epoch-step: 8-329 -- Loss: 0.39097100496292114
train-epoch-step: 8-330 -- Loss: 0.4387797713279724
train-epoch-step: 8-331 -- Loss: 0.27272355556488037
train-epoch-step: 8-332 -- Loss: 0.12826719880104065
train-epoch-step: 8-333 -- Loss: 0.23050159215927124
train-epoch-step: 8-334 -- Loss: 0.1841275840997696
train-epoch-step: 8-335 -- Loss: 0.21498985588550568
train-epoch-step: 8-336 -- Loss: 0.20189279317855835
train-epoch-step: 8-337 -- Loss: 0.2588844299316406
train-epoch-step: 8-338 -- Loss: 0.2026563435792923
train-epoch-step: 8-339 -- Loss: 0.17492735385894775
train-epoch-step: 8-340 -- Loss: 0.24155868589878082
train-epoch-step: 8-341 -- Loss: 0.1771179884672165
train-epoch-step: 8-342 -- Loss: 0.20606070756912231
train-epoch-step: 8-343 -- Loss: 0.18854913115501404
train-epoch-step: 8-344 -- Loss: 0.20808261632919312
train-epoch-step: 8-345 -- Loss: 0.1590426117181778
train-epoch-step: 8-346 -- Loss: 0.23228204250335693
train-epoch-step: 8-347 -- Loss: 0.19098657369613647
train-epoch-step: 8-348 -- Loss: 0.2416113317012787
train-epoch-step: 8-349 -- Loss: 0.2721799910068512
train-epoch-step: 8-350 -- Loss: 0.3205738961696625
train-epoch-step: 8-351 -- Loss: 0.24680081009864807
train-epoch-step: 8-352 -- Loss: 0.16998714208602905
train-epoch-step: 8-353 -- Loss: 0.23292005062103271
train-epoch-step: 8-354 -- Loss: 0.32879018783569336
train-epoch-step: 8-355 -- Loss: 0.14779755473136902
train-epoch-step: 8-356 -- Loss: 0.1422746777534485
train-epoch-step: 8-357 -- Loss: 0.2269168198108673
train-epoch-step: 8-358 -- Loss: 0.23345160484313965
train-epoch-step: 8-359 -- Loss: 0.17757010459899902
train-epoch-step: 8-360 -- Loss: 0.15001046657562256
train-epoch-step: 8-361 -- Loss: 0.31179505586624146
train-epoch-step: 8-362 -- Loss: 0.20514053106307983
train-epoch-step: 8-363 -- Loss: 0.13781622052192688
train-epoch-step: 8-364 -- Loss: 0.21837392449378967
train-epoch-step: 8-365 -- Loss: 0.20642688870429993
train-epoch-step: 8-366 -- Loss: 0.23475587368011475
train-epoch-step: 8-367 -- Loss: 0.33555319905281067
train-epoch-step: 8-368 -- Loss: 0.2487342357635498
train-epoch-step: 8-369 -- Loss: 0.3266799747943878
train-epoch-step: 8-370 -- Loss: 0.15257441997528076
train-epoch-step: 8-371 -- Loss: 0.14388339221477509
train-epoch-step: 8-372 -- Loss: 0.1767045259475708
train-epoch-step: 8-373 -- Loss: 0.24189361929893494
train-epoch-step: 8-374 -- Loss: 0.18029026687145233
train-epoch-step: 8-375 -- Loss: 0.35669422149658203
train-epoch-step: 8-376 -- Loss: 0.2547168433666229
train-epoch-step: 8-377 -- Loss: 0.2892564535140991
train-epoch-step: 8-378 -- Loss: 0.26416218280792236
train-epoch-step: 8-379 -- Loss: 0.13879385590553284
train-epoch-step: 8-380 -- Loss: 0.10942745208740234
train-epoch-step: 8-381 -- Loss: 0.3025451898574829
train-epoch-step: 8-382 -- Loss: 0.28895992040634155
train-epoch-step: 8-383 -- Loss: 0.21512189507484436
train-epoch-step: 8-384 -- Loss: 0.26631999015808105
train-epoch-step: 8-385 -- Loss: 0.2431582510471344
train-epoch-step: 8-386 -- Loss: 0.24482060968875885
train-epoch-step: 8-387 -- Loss: 0.24427951872348785
train-epoch-step: 8-388 -- Loss: 0.26642102003097534
train-epoch-step: 8-389 -- Loss: 0.21777120232582092
train-epoch-step: 8-390 -- Loss: 0.16997812688350677
train-epoch-step: 8-391 -- Loss: 0.17128531634807587
train-epoch-step: 8-392 -- Loss: 0.21545490622520447
train-epoch-step: 8-393 -- Loss: 0.18803885579109192
train-epoch-step: 8-394 -- Loss: 0.26561591029167175
train-epoch-step: 8-395 -- Loss: 0.19008861482143402
train-epoch-step: 8-396 -- Loss: 0.15938527882099152
train-epoch-step: 8-397 -- Loss: 0.1563493013381958
train-epoch-step: 8-398 -- Loss: 0.229690819978714
train-epoch-step: 8-399 -- Loss: 0.21660539507865906
train-epoch-step: 8-400 -- Loss: 0.341802716255188
train-epoch-step: 8-401 -- Loss: 0.14198042452335358
train-epoch-step: 8-402 -- Loss: 0.302152156829834
train-epoch-step: 8-403 -- Loss: 0.1939149796962738
train-epoch-step: 8-404 -- Loss: 0.168864905834198
train-epoch-step: 8-405 -- Loss: 0.17757943272590637
train-epoch-step: 8-406 -- Loss: 0.1978388875722885
train-epoch-step: 8-407 -- Loss: 0.13951554894447327
train-epoch-step: 8-408 -- Loss: 0.1910872906446457
train-epoch-step: 8-409 -- Loss: 0.21437595784664154
train-epoch-step: 8-410 -- Loss: 0.21372359991073608
train-epoch-step: 8-411 -- Loss: 0.23973986506462097
train-epoch-step: 8-412 -- Loss: 0.15415632724761963
train-epoch-step: 8-413 -- Loss: 0.17714761197566986
train-epoch-step: 8-414 -- Loss: 0.16248328983783722
train-epoch-step: 8-415 -- Loss: 0.169059619307518
train-epoch-step: 8-416 -- Loss: 0.31701499223709106
train-epoch-step: 8-417 -- Loss: 0.2408818155527115
train-epoch-step: 8-418 -- Loss: 0.28599727153778076
train-epoch-step: 8-419 -- Loss: 0.20429429411888123
train-epoch-step: 8-420 -- Loss: 0.18878716230392456
train-epoch-step: 8-421 -- Loss: 0.22283396124839783
train-epoch-step: 8-422 -- Loss: 0.18047112226486206
train-epoch-step: 8-423 -- Loss: 0.21919845044612885
train-epoch-step: 8-424 -- Loss: 0.16517274081707
train-epoch-step: 8-425 -- Loss: 0.21877321600914001
train-epoch-step: 8-426 -- Loss: 0.19496048986911774
train-epoch-step: 8-427 -- Loss: 0.17044681310653687
train-epoch-step: 8-428 -- Loss: 0.23891638219356537
train-epoch-step: 8-429 -- Loss: 0.20473827421665192
train-epoch-step: 8-430 -- Loss: 0.1783439964056015
train-epoch-step: 8-431 -- Loss: 0.20151051878929138
train-epoch-step: 8-432 -- Loss: 0.2818688154220581
train-epoch-step: 8-433 -- Loss: 0.162682443857193
train-epoch-step: 8-434 -- Loss: 0.1497810035943985
train-epoch-step: 8-435 -- Loss: 0.19561150670051575
train-epoch-step: 8-436 -- Loss: 0.1931161880493164
train-epoch-step: 8-437 -- Loss: 0.16860359907150269
train-epoch-step: 8-438 -- Loss: 0.2108611762523651
train-epoch-step: 8-439 -- Loss: 0.31422463059425354
train-epoch-step: 8-440 -- Loss: 0.16289976239204407
train-epoch-step: 8-441 -- Loss: 0.2680245041847229
train-epoch-step: 8-442 -- Loss: 0.23205721378326416
train-epoch-step: 8-443 -- Loss: 0.1914011538028717
train-epoch-step: 8-444 -- Loss: 0.3198727071285248
train-epoch-step: 8-445 -- Loss: 0.21232619881629944
train-epoch-step: 8-446 -- Loss: 0.18938703835010529
train-epoch-step: 8-447 -- Loss: 0.24162624776363373
train-epoch-step: 8-448 -- Loss: 0.31107258796691895
train-epoch-step: 8-449 -- Loss: 0.2351900041103363
train-epoch-step: 8-450 -- Loss: 0.22828075289726257
train-epoch-step: 8-451 -- Loss: 0.17748762667179108
train-epoch-step: 8-452 -- Loss: 0.15917068719863892
train-epoch-step: 8-453 -- Loss: 0.1266823410987854
train-epoch-step: 8-454 -- Loss: 0.29446008801460266
train-epoch-step: 8-455 -- Loss: 0.16026711463928223
train-epoch-step: 8-456 -- Loss: 0.14595583081245422
train-epoch-step: 8-457 -- Loss: 0.2633056044578552
train-epoch-step: 8-458 -- Loss: 0.17907458543777466
train-epoch-step: 8-459 -- Loss: 0.2628006935119629
train-epoch-step: 8-460 -- Loss: 0.1513957530260086
train-epoch-step: 8-461 -- Loss: 0.1726454794406891
train-epoch-step: 8-462 -- Loss: 0.1910754293203354
train-epoch-step: 8-463 -- Loss: 0.16781660914421082
train-epoch-step: 8-464 -- Loss: 0.22093921899795532
train-epoch-step: 8-465 -- Loss: 0.3009781241416931
train-epoch-step: 8-466 -- Loss: 0.241003155708313
train-epoch-step: 8-467 -- Loss: 0.1429869830608368
train-epoch-step: 8-468 -- Loss: 0.24214254319667816
train-epoch-step: 8-469 -- Loss: 0.3234083652496338
train-epoch-step: 8-470 -- Loss: 0.21678823232650757
train-epoch-step: 8-471 -- Loss: 0.17995503544807434
train-epoch-step: 8-472 -- Loss: 0.19287526607513428
train-epoch-step: 8-473 -- Loss: 0.2071402221918106
train-epoch-step: 8-474 -- Loss: 0.1491388976573944
train-epoch-step: 8-475 -- Loss: 0.13407938182353973
train-epoch-step: 8-476 -- Loss: 0.23558583855628967
train-epoch-step: 8-477 -- Loss: 0.27569758892059326
train-epoch-step: 8-478 -- Loss: 0.22829319536685944
train-epoch-step: 8-479 -- Loss: 0.17180493474006653
train-epoch-step: 8-480 -- Loss: 0.2312420904636383
train-epoch-step: 8-481 -- Loss: 0.33839911222457886
train-epoch-step: 8-482 -- Loss: 0.3236818313598633
train-epoch-step: 8-483 -- Loss: 0.24207504093647003
train-epoch-step: 8-484 -- Loss: 0.24710986018180847
train-epoch-step: 8-485 -- Loss: 0.15584126114845276
train-epoch-step: 8-486 -- Loss: 0.324827641248703
train-epoch-step: 8-487 -- Loss: 0.27139151096343994
train-epoch-step: 8-488 -- Loss: 0.22610673308372498
train-epoch-step: 8-489 -- Loss: 0.2570687532424927
train-epoch-step: 8-490 -- Loss: 0.17211326956748962
train-epoch-step: 8-491 -- Loss: 0.17142564058303833
train-epoch-step: 8-492 -- Loss: 0.1531044840812683
train-epoch-step: 8-493 -- Loss: 0.25988033413887024
train-epoch-step: 8-494 -- Loss: 0.2574453353881836
train-epoch-step: 8-495 -- Loss: 0.2468985915184021
train-epoch-step: 8-496 -- Loss: 0.16411203145980835
train-epoch-step: 8-497 -- Loss: 0.22537775337696075
train-epoch-step: 8-498 -- Loss: 0.17793306708335876
train-epoch-step: 8-499 -- Loss: 0.19637610018253326
train-epoch-step: 8-500 -- Loss: 0.18909920752048492
train-epoch-step: 8-501 -- Loss: 0.2560308575630188
train-epoch-step: 8-502 -- Loss: 0.1889406144618988
train-epoch-step: 8-503 -- Loss: 0.26740795373916626
train-epoch-step: 8-504 -- Loss: 0.14517712593078613
train-epoch-step: 8-505 -- Loss: 0.21224597096443176
train-epoch-step: 8-506 -- Loss: 0.14415767788887024
train-epoch-step: 8-507 -- Loss: 0.21562333405017853
train-epoch-step: 8-508 -- Loss: 0.20802780985832214
train-epoch-step: 8-509 -- Loss: 0.19889438152313232
train-epoch-step: 8-510 -- Loss: 0.15292613208293915
train-epoch-step: 8-511 -- Loss: 0.2545727491378784
train-epoch-step: 8-512 -- Loss: 0.21695660054683685
train-epoch-step: 8-513 -- Loss: 0.2496342808008194
train-epoch-step: 8-514 -- Loss: 0.18528170883655548
train-epoch-step: 8-515 -- Loss: 0.2002107799053192
train-epoch-step: 8-516 -- Loss: 0.1982318013906479
train-epoch-step: 8-517 -- Loss: 0.21780253946781158
train-epoch-step: 8-518 -- Loss: 0.1607271432876587
train-epoch-step: 8-519 -- Loss: 0.16038212180137634
train-epoch-step: 8-520 -- Loss: 0.2198880910873413
train-epoch-step: 8-521 -- Loss: 0.2725176513195038
train-epoch-step: 8-522 -- Loss: 0.2142890989780426
train-epoch-step: 8-523 -- Loss: 0.1890360563993454
train-epoch-step: 8-524 -- Loss: 0.19998489320278168
train-epoch-step: 8-525 -- Loss: 0.221452996134758
train-epoch-step: 8-526 -- Loss: 0.1533067524433136
train-epoch-step: 8-527 -- Loss: 0.19258221983909607
train-epoch-step: 8-528 -- Loss: 0.18741609156131744
train-epoch-step: 8-529 -- Loss: 0.20922166109085083
train-epoch-step: 8-530 -- Loss: 0.21446801722049713
train-epoch-step: 8-531 -- Loss: 0.24337346851825714
train-epoch-step: 8-532 -- Loss: 0.2029218226671219
train-epoch-step: 8-533 -- Loss: 0.19427940249443054
train-epoch-step: 8-534 -- Loss: 0.15832579135894775
train-epoch-step: 8-535 -- Loss: 0.33898109197616577
train-epoch-step: 8-536 -- Loss: 0.18720337748527527
train-epoch-step: 8-537 -- Loss: 0.17885328829288483
train-epoch-step: 8-538 -- Loss: 0.12060298025608063
train-epoch-step: 8-539 -- Loss: 0.2346043884754181
train-epoch-step: 8-540 -- Loss: 0.16065442562103271
train-epoch-step: 8-541 -- Loss: 0.249197319149971
train-epoch-step: 8-542 -- Loss: 0.2910650968551636
train-epoch-step: 8-543 -- Loss: 0.19834789633750916
train-epoch-step: 8-544 -- Loss: 0.26190394163131714
train-epoch-step: 8-545 -- Loss: 0.22976166009902954
train-epoch-step: 8-546 -- Loss: 0.25771909952163696
train-epoch-step: 8-547 -- Loss: 0.2125856876373291
train-epoch-step: 8-548 -- Loss: 0.11046961694955826
train-epoch-step: 8-549 -- Loss: 0.17858611047267914
train-epoch-step: 8-550 -- Loss: 0.2378205806016922
train-epoch-step: 8-551 -- Loss: 0.19195404648780823
train-epoch-step: 8-552 -- Loss: 0.1560966670513153
train-epoch-step: 8-553 -- Loss: 0.22398874163627625
train-epoch-step: 8-554 -- Loss: 0.21537676453590393
train-epoch-step: 8-555 -- Loss: 0.2524912357330322
train-epoch-step: 8-556 -- Loss: 0.2118557244539261
train-epoch-step: 8-557 -- Loss: 0.28389352560043335
train-epoch-step: 8-558 -- Loss: 0.27095088362693787
train-epoch-step: 8-559 -- Loss: 0.1732620745897293
train-epoch-step: 8-560 -- Loss: 0.24084994196891785
train-epoch-step: 8-561 -- Loss: 0.23188945651054382
train-epoch-step: 8-562 -- Loss: 0.23204128444194794
train-epoch-step: 8-563 -- Loss: 0.22925907373428345
train-epoch-step: 8-564 -- Loss: 0.12632843852043152
train-epoch-step: 8-565 -- Loss: 0.21942266821861267
train-epoch-step: 8-566 -- Loss: 0.19666436314582825
train-epoch-step: 8-567 -- Loss: 0.2547283172607422
train-epoch-step: 8-568 -- Loss: 0.19571205973625183
train-epoch-step: 8-569 -- Loss: 0.28124186396598816
train-epoch-step: 8-570 -- Loss: 0.2070704996585846
train-epoch-step: 8-571 -- Loss: 0.26494917273521423
train-epoch-step: 8-572 -- Loss: 0.2981172800064087
train-epoch-step: 8-573 -- Loss: 0.25001126527786255
train-epoch-step: 8-574 -- Loss: 0.30194687843322754
train-epoch-step: 8-575 -- Loss: 0.3843352794647217
train-epoch-step: 8-576 -- Loss: 0.15101616084575653
train-epoch-step: 8-577 -- Loss: 0.20459114015102386
train-epoch-step: 8-578 -- Loss: 0.2750835418701172
train-epoch-step: 8-579 -- Loss: 0.19524116814136505
train-epoch-step: 8-580 -- Loss: 0.238768070936203
train-epoch-step: 8-581 -- Loss: 0.16911198198795319
train-epoch-step: 8-582 -- Loss: 0.25462180376052856
train-epoch-step: 8-583 -- Loss: 0.2846471667289734
train-epoch-step: 8-584 -- Loss: 0.24033471941947937
train-epoch-step: 8-585 -- Loss: 0.23205718398094177
train-epoch-step: 8-586 -- Loss: 0.3251655101776123
train-epoch-step: 8-587 -- Loss: 0.18450865149497986
train-epoch-step: 8-588 -- Loss: 0.15284514427185059
val-epoch-step: 8-589 -- Loss: 0.2495255172252655
val-epoch-step: 8-590 -- Loss: 0.1769348829984665
val-epoch-step: 8-591 -- Loss: 0.24556344747543335
val-epoch-step: 8-592 -- Loss: 0.21072342991828918
val-epoch-step: 8-593 -- Loss: 0.1712455153465271
val-epoch-step: 8-594 -- Loss: 0.3820815086364746
val-epoch-step: 8-595 -- Loss: 0.21173222362995148
val-epoch-step: 8-596 -- Loss: 0.2433050125837326
val-epoch-step: 8-597 -- Loss: 0.2143050730228424
val-epoch-step: 8-598 -- Loss: 0.174047589302063
val-epoch-step: 8-599 -- Loss: 0.2112797349691391
val-epoch-step: 8-600 -- Loss: 0.21158191561698914
val-epoch-step: 8-601 -- Loss: 0.1821039915084839
val-epoch-step: 8-602 -- Loss: 0.15851199626922607
val-epoch-step: 8-603 -- Loss: 0.19954180717468262
val-epoch-step: 8-604 -- Loss: 0.1677095592021942
val-epoch-step: 8-605 -- Loss: 0.17521096765995026
val-epoch-step: 8-606 -- Loss: 0.3427483141422272
val-epoch-step: 8-607 -- Loss: 0.15441879630088806
val-epoch-step: 8-608 -- Loss: 0.29051852226257324
val-epoch-step: 8-609 -- Loss: 0.20133234560489655
val-epoch-step: 8-610 -- Loss: 0.2186557501554489
val-epoch-step: 8-611 -- Loss: 0.19016841053962708
val-epoch-step: 8-612 -- Loss: 0.3942231833934784
val-epoch-step: 8-613 -- Loss: 0.206380695104599
val-epoch-step: 8-614 -- Loss: 0.18676090240478516
val-epoch-step: 8-615 -- Loss: 0.2214786261320114
val-epoch-step: 8-616 -- Loss: 0.176083505153656
val-epoch-step: 8-617 -- Loss: 0.2208947241306305
val-epoch-step: 8-618 -- Loss: 0.22653019428253174
val-epoch-step: 8-619 -- Loss: 0.2537851929664612
val-epoch-step: 8-620 -- Loss: 0.1688065081834793
val-epoch-step: 8-621 -- Loss: 0.17058156430721283
val-epoch-step: 8-622 -- Loss: 0.1682860404253006
val-epoch-step: 8-623 -- Loss: 0.17551513016223907
val-epoch-step: 8-624 -- Loss: 0.2097921371459961
val-epoch-step: 8-625 -- Loss: 0.18483787775039673
val-epoch-step: 8-626 -- Loss: 0.17476722598075867
val-epoch-step: 8-627 -- Loss: 0.22936776280403137
val-epoch-step: 8-628 -- Loss: 0.5404067635536194
val-epoch-step: 8-629 -- Loss: 0.2350006103515625
val-epoch-step: 8-630 -- Loss: 0.39349937438964844
val-epoch-step: 8-631 -- Loss: 0.16979971528053284
val-epoch-step: 8-632 -- Loss: 0.22826573252677917
val-epoch-step: 8-633 -- Loss: 0.18548575043678284
val-epoch-step: 8-634 -- Loss: 0.16731388866901398
val-epoch-step: 8-635 -- Loss: 0.1386491358280182
val-epoch-step: 8-636 -- Loss: 0.1959160417318344
val-epoch-step: 8-637 -- Loss: 0.20822741091251373
val-epoch-step: 8-638 -- Loss: 0.18168672919273376
val-epoch-step: 8-639 -- Loss: 0.30513355135917664
val-epoch-step: 8-640 -- Loss: 0.2894534766674042
val-epoch-step: 8-641 -- Loss: 0.1454235315322876
val-epoch-step: 8-642 -- Loss: 0.22533467411994934
val-epoch-step: 8-643 -- Loss: 0.23201441764831543
val-epoch-step: 8-644 -- Loss: 0.19023820757865906
val-epoch-step: 8-645 -- Loss: 0.25333747267723083
val-epoch-step: 8-646 -- Loss: 0.1722795069217682
val-epoch-step: 8-647 -- Loss: 0.15703393518924713
val-epoch-step: 8-648 -- Loss: 0.19221815466880798
val-epoch-step: 8-649 -- Loss: 0.24870368838310242
val-epoch-step: 8-650 -- Loss: 0.29779788851737976
val-epoch-step: 8-651 -- Loss: 0.16662368178367615
val-epoch-step: 8-652 -- Loss: 0.1895325481891632
val-epoch-step: 8-653 -- Loss: 0.23684336245059967
val-epoch-step: 8-654 -- Loss: 0.13367214798927307
Epoch: 8 -- Train Loss: tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1533, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 9-0 -- Loss: 0.26951169967651367
train-epoch-step: 9-1 -- Loss: 0.16772979497909546
train-epoch-step: 9-2 -- Loss: 0.23484857380390167
train-epoch-step: 9-3 -- Loss: 0.17817038297653198
train-epoch-step: 9-4 -- Loss: 0.23439934849739075
train-epoch-step: 9-5 -- Loss: 0.2266063094139099
train-epoch-step: 9-6 -- Loss: 0.2654896676540375
train-epoch-step: 9-7 -- Loss: 0.19959664344787598
train-epoch-step: 9-8 -- Loss: 0.23138684034347534
train-epoch-step: 9-9 -- Loss: 0.3175159990787506
train-epoch-step: 9-10 -- Loss: 0.2985941767692566
train-epoch-step: 9-11 -- Loss: 0.21259619295597076
train-epoch-step: 9-12 -- Loss: 0.18988282978534698
train-epoch-step: 9-13 -- Loss: 0.2252732217311859
train-epoch-step: 9-14 -- Loss: 0.18834355473518372
train-epoch-step: 9-15 -- Loss: 0.1919645071029663
train-epoch-step: 9-16 -- Loss: 0.19887292385101318
train-epoch-step: 9-17 -- Loss: 0.25877687335014343
train-epoch-step: 9-18 -- Loss: 0.2291884422302246
train-epoch-step: 9-19 -- Loss: 0.15758153796195984
train-epoch-step: 9-20 -- Loss: 0.2656615972518921
train-epoch-step: 9-21 -- Loss: 0.37786775827407837
train-epoch-step: 9-22 -- Loss: 0.17980290949344635
train-epoch-step: 9-23 -- Loss: 0.2277696430683136
train-epoch-step: 9-24 -- Loss: 0.1535082459449768
train-epoch-step: 9-25 -- Loss: 0.26452159881591797
train-epoch-step: 9-26 -- Loss: 0.23987342417240143
train-epoch-step: 9-27 -- Loss: 0.30423229932785034
train-epoch-step: 9-28 -- Loss: 0.14977571368217468
train-epoch-step: 9-29 -- Loss: 0.28477632999420166
train-epoch-step: 9-30 -- Loss: 0.13123290240764618
train-epoch-step: 9-31 -- Loss: 0.17312392592430115
train-epoch-step: 9-32 -- Loss: 0.20468485355377197
train-epoch-step: 9-33 -- Loss: 0.3116682767868042
train-epoch-step: 9-34 -- Loss: 0.19830524921417236
train-epoch-step: 9-35 -- Loss: 0.2928152084350586
train-epoch-step: 9-36 -- Loss: 0.1648067981004715
train-epoch-step: 9-37 -- Loss: 0.1733701229095459
train-epoch-step: 9-38 -- Loss: 0.2361200451850891
train-epoch-step: 9-39 -- Loss: 0.28554171323776245
train-epoch-step: 9-40 -- Loss: 0.24708375334739685
train-epoch-step: 9-41 -- Loss: 0.2541584074497223
train-epoch-step: 9-42 -- Loss: 0.1755749136209488
train-epoch-step: 9-43 -- Loss: 0.3385332226753235
train-epoch-step: 9-44 -- Loss: 0.15297949314117432
train-epoch-step: 9-45 -- Loss: 0.15511415898799896
train-epoch-step: 9-46 -- Loss: 0.21528123319149017
train-epoch-step: 9-47 -- Loss: 0.3040192127227783
train-epoch-step: 9-48 -- Loss: 0.17915502190589905
train-epoch-step: 9-49 -- Loss: 0.25398269295692444
train-epoch-step: 9-50 -- Loss: 0.14345107972621918
train-epoch-step: 9-51 -- Loss: 0.23498162627220154
train-epoch-step: 9-52 -- Loss: 0.18743214011192322
train-epoch-step: 9-53 -- Loss: 0.2650364637374878
train-epoch-step: 9-54 -- Loss: 0.34091630578041077
train-epoch-step: 9-55 -- Loss: 0.2060583531856537
train-epoch-step: 9-56 -- Loss: 0.22335520386695862
train-epoch-step: 9-57 -- Loss: 0.2792939841747284
train-epoch-step: 9-58 -- Loss: 0.3264581561088562
train-epoch-step: 9-59 -- Loss: 0.3097582757472992
train-epoch-step: 9-60 -- Loss: 0.15360084176063538
train-epoch-step: 9-61 -- Loss: 0.25740984082221985
train-epoch-step: 9-62 -- Loss: 0.22058001160621643
train-epoch-step: 9-63 -- Loss: 0.16701120138168335
train-epoch-step: 9-64 -- Loss: 0.1835954636335373
train-epoch-step: 9-65 -- Loss: 0.2256060540676117
train-epoch-step: 9-66 -- Loss: 0.13121233880519867
train-epoch-step: 9-67 -- Loss: 0.14936569333076477
train-epoch-step: 9-68 -- Loss: 0.2769215703010559
train-epoch-step: 9-69 -- Loss: 0.15997296571731567
train-epoch-step: 9-70 -- Loss: 0.2515476644039154
train-epoch-step: 9-71 -- Loss: 0.29831162095069885
train-epoch-step: 9-72 -- Loss: 0.2207023799419403
train-epoch-step: 9-73 -- Loss: 0.24976025521755219
train-epoch-step: 9-74 -- Loss: 0.11685037612915039
train-epoch-step: 9-75 -- Loss: 0.15746022760868073
train-epoch-step: 9-76 -- Loss: 0.17329129576683044
train-epoch-step: 9-77 -- Loss: 0.2653661072254181
train-epoch-step: 9-78 -- Loss: 0.31919169425964355
train-epoch-step: 9-79 -- Loss: 0.23236440122127533
train-epoch-step: 9-80 -- Loss: 0.34816959500312805
train-epoch-step: 9-81 -- Loss: 0.14883552491664886
train-epoch-step: 9-82 -- Loss: 0.29671576619148254
train-epoch-step: 9-83 -- Loss: 0.22158154845237732
train-epoch-step: 9-84 -- Loss: 0.24594834446907043
train-epoch-step: 9-85 -- Loss: 0.21256482601165771
train-epoch-step: 9-86 -- Loss: 0.14992710947990417
train-epoch-step: 9-87 -- Loss: 0.2846410274505615
train-epoch-step: 9-88 -- Loss: 0.16645608842372894
train-epoch-step: 9-89 -- Loss: 0.2315273880958557
train-epoch-step: 9-90 -- Loss: 0.23595517873764038
train-epoch-step: 9-91 -- Loss: 0.2863377332687378
train-epoch-step: 9-92 -- Loss: 0.18983545899391174
train-epoch-step: 9-93 -- Loss: 0.21433451771736145
train-epoch-step: 9-94 -- Loss: 0.2802473306655884
train-epoch-step: 9-95 -- Loss: 0.23741210997104645
train-epoch-step: 9-96 -- Loss: 0.2716464102268219
train-epoch-step: 9-97 -- Loss: 0.21339191496372223
train-epoch-step: 9-98 -- Loss: 0.1774386316537857
train-epoch-step: 9-99 -- Loss: 0.2188575565814972
train-epoch-step: 9-100 -- Loss: 0.23001092672348022
train-epoch-step: 9-101 -- Loss: 0.330727756023407
train-epoch-step: 9-102 -- Loss: 0.2772012948989868
train-epoch-step: 9-103 -- Loss: 0.23500823974609375
train-epoch-step: 9-104 -- Loss: 0.17902517318725586
train-epoch-step: 9-105 -- Loss: 0.3322351574897766
train-epoch-step: 9-106 -- Loss: 0.21153339743614197
train-epoch-step: 9-107 -- Loss: 0.22900420427322388
train-epoch-step: 9-108 -- Loss: 0.2188969850540161
train-epoch-step: 9-109 -- Loss: 0.17806707322597504
train-epoch-step: 9-110 -- Loss: 0.21865232288837433
train-epoch-step: 9-111 -- Loss: 0.22170889377593994
train-epoch-step: 9-112 -- Loss: 0.201788529753685
train-epoch-step: 9-113 -- Loss: 0.20273804664611816
train-epoch-step: 9-114 -- Loss: 0.2618914842605591
train-epoch-step: 9-115 -- Loss: 0.19936086237430573
train-epoch-step: 9-116 -- Loss: 0.18285828828811646
train-epoch-step: 9-117 -- Loss: 0.15030188858509064
train-epoch-step: 9-118 -- Loss: 0.23934222757816315
train-epoch-step: 9-119 -- Loss: 0.18504077196121216
train-epoch-step: 9-120 -- Loss: 0.32406359910964966
train-epoch-step: 9-121 -- Loss: 0.33824384212493896
train-epoch-step: 9-122 -- Loss: 0.25012633204460144
train-epoch-step: 9-123 -- Loss: 0.2557336688041687
train-epoch-step: 9-124 -- Loss: 0.14416423439979553
train-epoch-step: 9-125 -- Loss: 0.18660280108451843
train-epoch-step: 9-126 -- Loss: 0.2925543785095215
train-epoch-step: 9-127 -- Loss: 0.20874229073524475
train-epoch-step: 9-128 -- Loss: 0.20359578728675842
train-epoch-step: 9-129 -- Loss: 0.17429083585739136
train-epoch-step: 9-130 -- Loss: 0.23329289257526398
train-epoch-step: 9-131 -- Loss: 0.16316774487495422
train-epoch-step: 9-132 -- Loss: 0.2408674657344818
train-epoch-step: 9-133 -- Loss: 0.1393081396818161
train-epoch-step: 9-134 -- Loss: 0.24188140034675598
train-epoch-step: 9-135 -- Loss: 0.16312339901924133
train-epoch-step: 9-136 -- Loss: 0.15386982262134552
train-epoch-step: 9-137 -- Loss: 0.3055848777294159
train-epoch-step: 9-138 -- Loss: 0.3214356303215027
train-epoch-step: 9-139 -- Loss: 0.15826037526130676
train-epoch-step: 9-140 -- Loss: 0.24339744448661804
train-epoch-step: 9-141 -- Loss: 0.28082820773124695
train-epoch-step: 9-142 -- Loss: 0.2440471053123474
train-epoch-step: 9-143 -- Loss: 0.20608316361904144
train-epoch-step: 9-144 -- Loss: 0.22930040955543518
train-epoch-step: 9-145 -- Loss: 0.1681457757949829
train-epoch-step: 9-146 -- Loss: 0.21459011733531952
train-epoch-step: 9-147 -- Loss: 0.22471527755260468
train-epoch-step: 9-148 -- Loss: 0.20825070142745972
train-epoch-step: 9-149 -- Loss: 0.14121508598327637
train-epoch-step: 9-150 -- Loss: 0.23062127828598022
train-epoch-step: 9-151 -- Loss: 0.22180315852165222
train-epoch-step: 9-152 -- Loss: 0.23434585332870483
train-epoch-step: 9-153 -- Loss: 0.3611026704311371
train-epoch-step: 9-154 -- Loss: 0.15834924578666687
train-epoch-step: 9-155 -- Loss: 0.1661178320646286
train-epoch-step: 9-156 -- Loss: 0.15354809165000916
train-epoch-step: 9-157 -- Loss: 0.2023220956325531
train-epoch-step: 9-158 -- Loss: 0.19678889214992523
train-epoch-step: 9-159 -- Loss: 0.2070770412683487
train-epoch-step: 9-160 -- Loss: 0.2844645082950592
train-epoch-step: 9-161 -- Loss: 0.2517213821411133
train-epoch-step: 9-162 -- Loss: 0.2526100277900696
train-epoch-step: 9-163 -- Loss: 0.21334786713123322
train-epoch-step: 9-164 -- Loss: 0.2213188260793686
train-epoch-step: 9-165 -- Loss: 0.1976929008960724
train-epoch-step: 9-166 -- Loss: 0.14384669065475464
train-epoch-step: 9-167 -- Loss: 0.14437460899353027
train-epoch-step: 9-168 -- Loss: 0.24806345999240875
train-epoch-step: 9-169 -- Loss: 0.17127178609371185
train-epoch-step: 9-170 -- Loss: 0.24799580872058868
train-epoch-step: 9-171 -- Loss: 0.1667758971452713
train-epoch-step: 9-172 -- Loss: 0.30556246638298035
train-epoch-step: 9-173 -- Loss: 0.15301580727100372
train-epoch-step: 9-174 -- Loss: 0.28369206190109253
train-epoch-step: 9-175 -- Loss: 0.2063407003879547
train-epoch-step: 9-176 -- Loss: 0.15911729633808136
train-epoch-step: 9-177 -- Loss: 0.22237735986709595
train-epoch-step: 9-178 -- Loss: 0.22708635032176971
train-epoch-step: 9-179 -- Loss: 0.17367754876613617
train-epoch-step: 9-180 -- Loss: 0.17680475115776062
train-epoch-step: 9-181 -- Loss: 0.21613575518131256
train-epoch-step: 9-182 -- Loss: 0.2357490360736847
train-epoch-step: 9-183 -- Loss: 0.3217011094093323
train-epoch-step: 9-184 -- Loss: 0.16782015562057495
train-epoch-step: 9-185 -- Loss: 0.17123158276081085
train-epoch-step: 9-186 -- Loss: 0.23139968514442444
train-epoch-step: 9-187 -- Loss: 0.2626829743385315
train-epoch-step: 9-188 -- Loss: 0.20462477207183838
train-epoch-step: 9-189 -- Loss: 0.1635591983795166
train-epoch-step: 9-190 -- Loss: 0.21130530536174774
train-epoch-step: 9-191 -- Loss: 0.22148708999156952
train-epoch-step: 9-192 -- Loss: 0.2833338975906372
train-epoch-step: 9-193 -- Loss: 0.26671522855758667
train-epoch-step: 9-194 -- Loss: 0.21753227710723877
train-epoch-step: 9-195 -- Loss: 0.18948079645633698
train-epoch-step: 9-196 -- Loss: 0.2109951674938202
train-epoch-step: 9-197 -- Loss: 0.15776444971561432
train-epoch-step: 9-198 -- Loss: 0.1644316017627716
train-epoch-step: 9-199 -- Loss: 0.18187551200389862
train-epoch-step: 9-200 -- Loss: 0.14621558785438538
train-epoch-step: 9-201 -- Loss: 0.2411826103925705
train-epoch-step: 9-202 -- Loss: 0.16435673832893372
train-epoch-step: 9-203 -- Loss: 0.2104140818119049
train-epoch-step: 9-204 -- Loss: 0.17764483392238617
train-epoch-step: 9-205 -- Loss: 0.2232404351234436
train-epoch-step: 9-206 -- Loss: 0.23784589767456055
train-epoch-step: 9-207 -- Loss: 0.16707514226436615
train-epoch-step: 9-208 -- Loss: 0.21391993761062622
train-epoch-step: 9-209 -- Loss: 0.16352775692939758
train-epoch-step: 9-210 -- Loss: 0.16127291321754456
train-epoch-step: 9-211 -- Loss: 0.247202068567276
train-epoch-step: 9-212 -- Loss: 0.23744940757751465
train-epoch-step: 9-213 -- Loss: 0.14743675291538239
train-epoch-step: 9-214 -- Loss: 0.1801816076040268
train-epoch-step: 9-215 -- Loss: 0.1613912731409073
train-epoch-step: 9-216 -- Loss: 0.23240363597869873
train-epoch-step: 9-217 -- Loss: 0.24816583096981049
train-epoch-step: 9-218 -- Loss: 0.180251806974411
train-epoch-step: 9-219 -- Loss: 0.24604421854019165
train-epoch-step: 9-220 -- Loss: 0.1583356112241745
train-epoch-step: 9-221 -- Loss: 0.23741663992404938
train-epoch-step: 9-222 -- Loss: 0.1484529674053192
train-epoch-step: 9-223 -- Loss: 0.2045346051454544
train-epoch-step: 9-224 -- Loss: 0.2253638207912445
train-epoch-step: 9-225 -- Loss: 0.3740813136100769
train-epoch-step: 9-226 -- Loss: 0.25935956835746765
train-epoch-step: 9-227 -- Loss: 0.27999380230903625
train-epoch-step: 9-228 -- Loss: 0.21441099047660828
train-epoch-step: 9-229 -- Loss: 0.21961967647075653
train-epoch-step: 9-230 -- Loss: 0.19031064212322235
train-epoch-step: 9-231 -- Loss: 0.2121039181947708
train-epoch-step: 9-232 -- Loss: 0.23821353912353516
train-epoch-step: 9-233 -- Loss: 0.103706493973732
train-epoch-step: 9-234 -- Loss: 0.22137704491615295
train-epoch-step: 9-235 -- Loss: 0.1980258822441101
train-epoch-step: 9-236 -- Loss: 0.20854197442531586
train-epoch-step: 9-237 -- Loss: 0.2906438112258911
train-epoch-step: 9-238 -- Loss: 0.18457932770252228
train-epoch-step: 9-239 -- Loss: 0.15925584733486176
train-epoch-step: 9-240 -- Loss: 0.2544727027416229
train-epoch-step: 9-241 -- Loss: 0.18815931677818298
train-epoch-step: 9-242 -- Loss: 0.2628878951072693
train-epoch-step: 9-243 -- Loss: 0.2644766569137573
train-epoch-step: 9-244 -- Loss: 0.24099352955818176
train-epoch-step: 9-245 -- Loss: 0.2846798896789551
train-epoch-step: 9-246 -- Loss: 0.331581175327301
train-epoch-step: 9-247 -- Loss: 0.28827109932899475
train-epoch-step: 9-248 -- Loss: 0.2203446924686432
train-epoch-step: 9-249 -- Loss: 0.17337960004806519
train-epoch-step: 9-250 -- Loss: 0.2369576245546341
train-epoch-step: 9-251 -- Loss: 0.13235951960086823
train-epoch-step: 9-252 -- Loss: 0.23052489757537842
train-epoch-step: 9-253 -- Loss: 0.16669127345085144
train-epoch-step: 9-254 -- Loss: 0.2781478762626648
train-epoch-step: 9-255 -- Loss: 0.17744873464107513
train-epoch-step: 9-256 -- Loss: 0.19084744155406952
train-epoch-step: 9-257 -- Loss: 0.2268974781036377
train-epoch-step: 9-258 -- Loss: 0.18466615676879883
train-epoch-step: 9-259 -- Loss: 0.14396239817142487
train-epoch-step: 9-260 -- Loss: 0.2521821856498718
train-epoch-step: 9-261 -- Loss: 0.20936369895935059
train-epoch-step: 9-262 -- Loss: 0.3726500868797302
train-epoch-step: 9-263 -- Loss: 0.24902816116809845
train-epoch-step: 9-264 -- Loss: 0.20687291026115417
train-epoch-step: 9-265 -- Loss: 0.13734760880470276
train-epoch-step: 9-266 -- Loss: 0.17609351873397827
train-epoch-step: 9-267 -- Loss: 0.17420679330825806
train-epoch-step: 9-268 -- Loss: 0.14235767722129822
train-epoch-step: 9-269 -- Loss: 0.2072000503540039
train-epoch-step: 9-270 -- Loss: 0.13378426432609558
train-epoch-step: 9-271 -- Loss: 0.17375043034553528
train-epoch-step: 9-272 -- Loss: 0.14034974575042725
train-epoch-step: 9-273 -- Loss: 0.1517055630683899
train-epoch-step: 9-274 -- Loss: 0.2245805859565735
train-epoch-step: 9-275 -- Loss: 0.2397734820842743
train-epoch-step: 9-276 -- Loss: 0.18644487857818604
train-epoch-step: 9-277 -- Loss: 0.18157893419265747
train-epoch-step: 9-278 -- Loss: 0.17468520998954773
train-epoch-step: 9-279 -- Loss: 0.17841744422912598
train-epoch-step: 9-280 -- Loss: 0.2546100616455078
train-epoch-step: 9-281 -- Loss: 0.21719348430633545
train-epoch-step: 9-282 -- Loss: 0.1652965545654297
train-epoch-step: 9-283 -- Loss: 0.13750731945037842
train-epoch-step: 9-284 -- Loss: 0.31311777234077454
train-epoch-step: 9-285 -- Loss: 0.22466981410980225
train-epoch-step: 9-286 -- Loss: 0.18976637721061707
train-epoch-step: 9-287 -- Loss: 0.24642369151115417
train-epoch-step: 9-288 -- Loss: 0.10952674597501755
train-epoch-step: 9-289 -- Loss: 0.15067511796951294
train-epoch-step: 9-290 -- Loss: 0.22123023867607117
train-epoch-step: 9-291 -- Loss: 0.13772368431091309
train-epoch-step: 9-292 -- Loss: 0.1848703920841217
train-epoch-step: 9-293 -- Loss: 0.16234788298606873
train-epoch-step: 9-294 -- Loss: 0.2083873748779297
train-epoch-step: 9-295 -- Loss: 0.35882768034935
train-epoch-step: 9-296 -- Loss: 0.19951596856117249
train-epoch-step: 9-297 -- Loss: 0.20672671496868134
train-epoch-step: 9-298 -- Loss: 0.2863014340400696
train-epoch-step: 9-299 -- Loss: 0.2028951644897461
train-epoch-step: 9-300 -- Loss: 0.21011973917484283
train-epoch-step: 9-301 -- Loss: 0.19765812158584595
train-epoch-step: 9-302 -- Loss: 0.26331931352615356
train-epoch-step: 9-303 -- Loss: 0.24919798970222473
train-epoch-step: 9-304 -- Loss: 0.17777714133262634
train-epoch-step: 9-305 -- Loss: 0.17438428103923798
train-epoch-step: 9-306 -- Loss: 0.28392869234085083
train-epoch-step: 9-307 -- Loss: 0.2037479132413864
train-epoch-step: 9-308 -- Loss: 0.28290703892707825
train-epoch-step: 9-309 -- Loss: 0.18510928750038147
train-epoch-step: 9-310 -- Loss: 0.19242243468761444
train-epoch-step: 9-311 -- Loss: 0.19454294443130493
train-epoch-step: 9-312 -- Loss: 0.2587665319442749
train-epoch-step: 9-313 -- Loss: 0.1214376837015152
train-epoch-step: 9-314 -- Loss: 0.2432188242673874
train-epoch-step: 9-315 -- Loss: 0.19546997547149658
train-epoch-step: 9-316 -- Loss: 0.18067006766796112
train-epoch-step: 9-317 -- Loss: 0.17499220371246338
train-epoch-step: 9-318 -- Loss: 0.19641350209712982
train-epoch-step: 9-319 -- Loss: 0.22107641398906708
train-epoch-step: 9-320 -- Loss: 0.14295311272144318
train-epoch-step: 9-321 -- Loss: 0.16485479474067688
train-epoch-step: 9-322 -- Loss: 0.25547558069229126
train-epoch-step: 9-323 -- Loss: 0.18837176263332367
train-epoch-step: 9-324 -- Loss: 0.31728920340538025
train-epoch-step: 9-325 -- Loss: 0.1797531247138977
train-epoch-step: 9-326 -- Loss: 0.21127170324325562
train-epoch-step: 9-327 -- Loss: 0.2597104609012604
train-epoch-step: 9-328 -- Loss: 0.23414191603660583
train-epoch-step: 9-329 -- Loss: 0.3826676905155182
train-epoch-step: 9-330 -- Loss: 0.428494393825531
train-epoch-step: 9-331 -- Loss: 0.2713683545589447
train-epoch-step: 9-332 -- Loss: 0.12846103310585022
train-epoch-step: 9-333 -- Loss: 0.22360524535179138
train-epoch-step: 9-334 -- Loss: 0.18734289705753326
train-epoch-step: 9-335 -- Loss: 0.2114500254392624
train-epoch-step: 9-336 -- Loss: 0.19799959659576416
train-epoch-step: 9-337 -- Loss: 0.2579779326915741
train-epoch-step: 9-338 -- Loss: 0.19808930158615112
train-epoch-step: 9-339 -- Loss: 0.17449747025966644
train-epoch-step: 9-340 -- Loss: 0.2347204089164734
train-epoch-step: 9-341 -- Loss: 0.16814740002155304
train-epoch-step: 9-342 -- Loss: 0.19938495755195618
train-epoch-step: 9-343 -- Loss: 0.18828809261322021
train-epoch-step: 9-344 -- Loss: 0.2085372507572174
train-epoch-step: 9-345 -- Loss: 0.14826492965221405
train-epoch-step: 9-346 -- Loss: 0.2309051752090454
train-epoch-step: 9-347 -- Loss: 0.1877167969942093
train-epoch-step: 9-348 -- Loss: 0.2420237511396408
train-epoch-step: 9-349 -- Loss: 0.27039510011672974
train-epoch-step: 9-350 -- Loss: 0.3129848837852478
train-epoch-step: 9-351 -- Loss: 0.2449793666601181
train-epoch-step: 9-352 -- Loss: 0.169394388794899
train-epoch-step: 9-353 -- Loss: 0.2346181571483612
train-epoch-step: 9-354 -- Loss: 0.32713985443115234
train-epoch-step: 9-355 -- Loss: 0.14630109071731567
train-epoch-step: 9-356 -- Loss: 0.14069686830043793
train-epoch-step: 9-357 -- Loss: 0.2280961275100708
train-epoch-step: 9-358 -- Loss: 0.22939570248126984
train-epoch-step: 9-359 -- Loss: 0.17451408505439758
train-epoch-step: 9-360 -- Loss: 0.14647486805915833
train-epoch-step: 9-361 -- Loss: 0.31071531772613525
train-epoch-step: 9-362 -- Loss: 0.20040060579776764
train-epoch-step: 9-363 -- Loss: 0.13949590921401978
train-epoch-step: 9-364 -- Loss: 0.21933172643184662
train-epoch-step: 9-365 -- Loss: 0.20152825117111206
train-epoch-step: 9-366 -- Loss: 0.2355537712574005
train-epoch-step: 9-367 -- Loss: 0.3325393795967102
train-epoch-step: 9-368 -- Loss: 0.24589478969573975
train-epoch-step: 9-369 -- Loss: 0.32586780190467834
train-epoch-step: 9-370 -- Loss: 0.1494700163602829
train-epoch-step: 9-371 -- Loss: 0.14200343191623688
train-epoch-step: 9-372 -- Loss: 0.17567598819732666
train-epoch-step: 9-373 -- Loss: 0.23894761502742767
train-epoch-step: 9-374 -- Loss: 0.17890891432762146
train-epoch-step: 9-375 -- Loss: 0.3475663959980011
train-epoch-step: 9-376 -- Loss: 0.25027236342430115
train-epoch-step: 9-377 -- Loss: 0.28703930974006653
train-epoch-step: 9-378 -- Loss: 0.2559581696987152
train-epoch-step: 9-379 -- Loss: 0.13903239369392395
train-epoch-step: 9-380 -- Loss: 0.1063428446650505
train-epoch-step: 9-381 -- Loss: 0.292121022939682
train-epoch-step: 9-382 -- Loss: 0.28165990114212036
train-epoch-step: 9-383 -- Loss: 0.2199465036392212
train-epoch-step: 9-384 -- Loss: 0.26146915555000305
train-epoch-step: 9-385 -- Loss: 0.24421784281730652
train-epoch-step: 9-386 -- Loss: 0.23327544331550598
train-epoch-step: 9-387 -- Loss: 0.24426987767219543
train-epoch-step: 9-388 -- Loss: 0.2706814408302307
train-epoch-step: 9-389 -- Loss: 0.21316272020339966
train-epoch-step: 9-390 -- Loss: 0.16502505540847778
train-epoch-step: 9-391 -- Loss: 0.17345675826072693
train-epoch-step: 9-392 -- Loss: 0.21359892189502716
train-epoch-step: 9-393 -- Loss: 0.18835416436195374
train-epoch-step: 9-394 -- Loss: 0.26674824953079224
train-epoch-step: 9-395 -- Loss: 0.19102582335472107
train-epoch-step: 9-396 -- Loss: 0.15584126114845276
train-epoch-step: 9-397 -- Loss: 0.15168240666389465
train-epoch-step: 9-398 -- Loss: 0.2323618233203888
train-epoch-step: 9-399 -- Loss: 0.2167842537164688
train-epoch-step: 9-400 -- Loss: 0.3388255834579468
train-epoch-step: 9-401 -- Loss: 0.14040862023830414
train-epoch-step: 9-402 -- Loss: 0.2988274097442627
train-epoch-step: 9-403 -- Loss: 0.19543752074241638
train-epoch-step: 9-404 -- Loss: 0.16835381090641022
train-epoch-step: 9-405 -- Loss: 0.17518776655197144
train-epoch-step: 9-406 -- Loss: 0.19836397469043732
train-epoch-step: 9-407 -- Loss: 0.13815230131149292
train-epoch-step: 9-408 -- Loss: 0.19275712966918945
train-epoch-step: 9-409 -- Loss: 0.2127925306558609
train-epoch-step: 9-410 -- Loss: 0.2107599675655365
train-epoch-step: 9-411 -- Loss: 0.2301885187625885
train-epoch-step: 9-412 -- Loss: 0.1501760184764862
train-epoch-step: 9-413 -- Loss: 0.17416006326675415
train-epoch-step: 9-414 -- Loss: 0.1623993217945099
train-epoch-step: 9-415 -- Loss: 0.16518855094909668
train-epoch-step: 9-416 -- Loss: 0.31083017587661743
train-epoch-step: 9-417 -- Loss: 0.24210822582244873
train-epoch-step: 9-418 -- Loss: 0.2833293080329895
train-epoch-step: 9-419 -- Loss: 0.20604974031448364
train-epoch-step: 9-420 -- Loss: 0.18887676298618317
train-epoch-step: 9-421 -- Loss: 0.21649236977100372
train-epoch-step: 9-422 -- Loss: 0.1771976500749588
train-epoch-step: 9-423 -- Loss: 0.21044984459877014
train-epoch-step: 9-424 -- Loss: 0.16110923886299133
train-epoch-step: 9-425 -- Loss: 0.2151423692703247
train-epoch-step: 9-426 -- Loss: 0.1899946928024292
train-epoch-step: 9-427 -- Loss: 0.1678331196308136
train-epoch-step: 9-428 -- Loss: 0.23858049511909485
train-epoch-step: 9-429 -- Loss: 0.20500868558883667
train-epoch-step: 9-430 -- Loss: 0.17625105381011963
train-epoch-step: 9-431 -- Loss: 0.19341476261615753
train-epoch-step: 9-432 -- Loss: 0.2815012037754059
train-epoch-step: 9-433 -- Loss: 0.16329124569892883
train-epoch-step: 9-434 -- Loss: 0.1508239209651947
train-epoch-step: 9-435 -- Loss: 0.18615847826004028
train-epoch-step: 9-436 -- Loss: 0.18210145831108093
train-epoch-step: 9-437 -- Loss: 0.1632431149482727
train-epoch-step: 9-438 -- Loss: 0.21618184447288513
train-epoch-step: 9-439 -- Loss: 0.31440526247024536
train-epoch-step: 9-440 -- Loss: 0.15559908747673035
train-epoch-step: 9-441 -- Loss: 0.26186683773994446
train-epoch-step: 9-442 -- Loss: 0.23327425122261047
train-epoch-step: 9-443 -- Loss: 0.18536606431007385
train-epoch-step: 9-444 -- Loss: 0.30219554901123047
train-epoch-step: 9-445 -- Loss: 0.22824373841285706
train-epoch-step: 9-446 -- Loss: 0.18750278651714325
train-epoch-step: 9-447 -- Loss: 0.2494317889213562
train-epoch-step: 9-448 -- Loss: 0.30347222089767456
train-epoch-step: 9-449 -- Loss: 0.23099398612976074
train-epoch-step: 9-450 -- Loss: 0.2235754132270813
train-epoch-step: 9-451 -- Loss: 0.17541508376598358
train-epoch-step: 9-452 -- Loss: 0.15886124968528748
train-epoch-step: 9-453 -- Loss: 0.11779917776584625
train-epoch-step: 9-454 -- Loss: 0.2853727340698242
train-epoch-step: 9-455 -- Loss: 0.1622602790594101
train-epoch-step: 9-456 -- Loss: 0.14571250975131989
train-epoch-step: 9-457 -- Loss: 0.25638508796691895
train-epoch-step: 9-458 -- Loss: 0.1756156086921692
train-epoch-step: 9-459 -- Loss: 0.2585088014602661
train-epoch-step: 9-460 -- Loss: 0.14244335889816284
train-epoch-step: 9-461 -- Loss: 0.16846415400505066
train-epoch-step: 9-462 -- Loss: 0.18613770604133606
train-epoch-step: 9-463 -- Loss: 0.1661090850830078
train-epoch-step: 9-464 -- Loss: 0.2074873447418213
train-epoch-step: 9-465 -- Loss: 0.3017575442790985
train-epoch-step: 9-466 -- Loss: 0.23424643278121948
train-epoch-step: 9-467 -- Loss: 0.14309221506118774
train-epoch-step: 9-468 -- Loss: 0.23316793143749237
train-epoch-step: 9-469 -- Loss: 0.3132167458534241
train-epoch-step: 9-470 -- Loss: 0.20882144570350647
train-epoch-step: 9-471 -- Loss: 0.18100358545780182
train-epoch-step: 9-472 -- Loss: 0.18907801806926727
train-epoch-step: 9-473 -- Loss: 0.21221080422401428
train-epoch-step: 9-474 -- Loss: 0.14913076162338257
train-epoch-step: 9-475 -- Loss: 0.13404612243175507
train-epoch-step: 9-476 -- Loss: 0.23232166469097137
train-epoch-step: 9-477 -- Loss: 0.2695865035057068
train-epoch-step: 9-478 -- Loss: 0.22687765955924988
train-epoch-step: 9-479 -- Loss: 0.16931135952472687
train-epoch-step: 9-480 -- Loss: 0.2229471504688263
train-epoch-step: 9-481 -- Loss: 0.32642120122909546
train-epoch-step: 9-482 -- Loss: 0.3113000988960266
train-epoch-step: 9-483 -- Loss: 0.23681065440177917
train-epoch-step: 9-484 -- Loss: 0.2524620592594147
train-epoch-step: 9-485 -- Loss: 0.1514917016029358
train-epoch-step: 9-486 -- Loss: 0.31552714109420776
train-epoch-step: 9-487 -- Loss: 0.2654682993888855
train-epoch-step: 9-488 -- Loss: 0.2218608409166336
train-epoch-step: 9-489 -- Loss: 0.25533100962638855
train-epoch-step: 9-490 -- Loss: 0.16640818119049072
train-epoch-step: 9-491 -- Loss: 0.16453921794891357
train-epoch-step: 9-492 -- Loss: 0.14742030203342438
train-epoch-step: 9-493 -- Loss: 0.25854867696762085
train-epoch-step: 9-494 -- Loss: 0.25692224502563477
train-epoch-step: 9-495 -- Loss: 0.24310436844825745
train-epoch-step: 9-496 -- Loss: 0.15977662801742554
train-epoch-step: 9-497 -- Loss: 0.21886058151721954
train-epoch-step: 9-498 -- Loss: 0.17380070686340332
train-epoch-step: 9-499 -- Loss: 0.19700491428375244
train-epoch-step: 9-500 -- Loss: 0.18354815244674683
train-epoch-step: 9-501 -- Loss: 0.2554008960723877
train-epoch-step: 9-502 -- Loss: 0.18913841247558594
train-epoch-step: 9-503 -- Loss: 0.25660648941993713
train-epoch-step: 9-504 -- Loss: 0.14789488911628723
train-epoch-step: 9-505 -- Loss: 0.20406612753868103
train-epoch-step: 9-506 -- Loss: 0.13945436477661133
train-epoch-step: 9-507 -- Loss: 0.21341121196746826
train-epoch-step: 9-508 -- Loss: 0.20404252409934998
train-epoch-step: 9-509 -- Loss: 0.19647426903247833
train-epoch-step: 9-510 -- Loss: 0.15279680490493774
train-epoch-step: 9-511 -- Loss: 0.25383612513542175
train-epoch-step: 9-512 -- Loss: 0.21249604225158691
train-epoch-step: 9-513 -- Loss: 0.24424004554748535
train-epoch-step: 9-514 -- Loss: 0.17954373359680176
train-epoch-step: 9-515 -- Loss: 0.19430512189865112
train-epoch-step: 9-516 -- Loss: 0.19691959023475647
train-epoch-step: 9-517 -- Loss: 0.2131975293159485
train-epoch-step: 9-518 -- Loss: 0.15795554220676422
train-epoch-step: 9-519 -- Loss: 0.15590986609458923
train-epoch-step: 9-520 -- Loss: 0.21722204983234406
train-epoch-step: 9-521 -- Loss: 0.2648409605026245
train-epoch-step: 9-522 -- Loss: 0.2019691914319992
train-epoch-step: 9-523 -- Loss: 0.18709224462509155
train-epoch-step: 9-524 -- Loss: 0.20887304842472076
train-epoch-step: 9-525 -- Loss: 0.22659388184547424
train-epoch-step: 9-526 -- Loss: 0.15678319334983826
train-epoch-step: 9-527 -- Loss: 0.2000320553779602
train-epoch-step: 9-528 -- Loss: 0.187058687210083
train-epoch-step: 9-529 -- Loss: 0.20579496026039124
train-epoch-step: 9-530 -- Loss: 0.21170099079608917
train-epoch-step: 9-531 -- Loss: 0.23403918743133545
train-epoch-step: 9-532 -- Loss: 0.2042340189218521
train-epoch-step: 9-533 -- Loss: 0.1954512596130371
train-epoch-step: 9-534 -- Loss: 0.1700102984905243
train-epoch-step: 9-535 -- Loss: 0.33451372385025024
train-epoch-step: 9-536 -- Loss: 0.1903555989265442
train-epoch-step: 9-537 -- Loss: 0.17909622192382812
train-epoch-step: 9-538 -- Loss: 0.11783061176538467
train-epoch-step: 9-539 -- Loss: 0.23330745100975037
train-epoch-step: 9-540 -- Loss: 0.1572907269001007
train-epoch-step: 9-541 -- Loss: 0.24169185757637024
train-epoch-step: 9-542 -- Loss: 0.28287258744239807
train-epoch-step: 9-543 -- Loss: 0.19259017705917358
train-epoch-step: 9-544 -- Loss: 0.2633303105831146
train-epoch-step: 9-545 -- Loss: 0.22668451070785522
train-epoch-step: 9-546 -- Loss: 0.259050577878952
train-epoch-step: 9-547 -- Loss: 0.21055150032043457
train-epoch-step: 9-548 -- Loss: 0.10954955220222473
train-epoch-step: 9-549 -- Loss: 0.17299091815948486
train-epoch-step: 9-550 -- Loss: 0.2371687889099121
train-epoch-step: 9-551 -- Loss: 0.19042855501174927
train-epoch-step: 9-552 -- Loss: 0.15259219706058502
train-epoch-step: 9-553 -- Loss: 0.22138729691505432
train-epoch-step: 9-554 -- Loss: 0.21207195520401
train-epoch-step: 9-555 -- Loss: 0.2466404289007187
train-epoch-step: 9-556 -- Loss: 0.21261093020439148
train-epoch-step: 9-557 -- Loss: 0.27981340885162354
train-epoch-step: 9-558 -- Loss: 0.2803129553794861
train-epoch-step: 9-559 -- Loss: 0.17033062875270844
train-epoch-step: 9-560 -- Loss: 0.24004045128822327
train-epoch-step: 9-561 -- Loss: 0.23284626007080078
train-epoch-step: 9-562 -- Loss: 0.23395009338855743
train-epoch-step: 9-563 -- Loss: 0.2239566445350647
train-epoch-step: 9-564 -- Loss: 0.1265399008989334
train-epoch-step: 9-565 -- Loss: 0.21677613258361816
train-epoch-step: 9-566 -- Loss: 0.19447061419487
train-epoch-step: 9-567 -- Loss: 0.25308215618133545
train-epoch-step: 9-568 -- Loss: 0.18950480222702026
train-epoch-step: 9-569 -- Loss: 0.26970669627189636
train-epoch-step: 9-570 -- Loss: 0.21139174699783325
train-epoch-step: 9-571 -- Loss: 0.2528685927391052
train-epoch-step: 9-572 -- Loss: 0.29790014028549194
train-epoch-step: 9-573 -- Loss: 0.24767059087753296
train-epoch-step: 9-574 -- Loss: 0.2994573712348938
train-epoch-step: 9-575 -- Loss: 0.3740677833557129
train-epoch-step: 9-576 -- Loss: 0.14720764756202698
train-epoch-step: 9-577 -- Loss: 0.20518767833709717
train-epoch-step: 9-578 -- Loss: 0.2696063816547394
train-epoch-step: 9-579 -- Loss: 0.19249600172042847
train-epoch-step: 9-580 -- Loss: 0.23116275668144226
train-epoch-step: 9-581 -- Loss: 0.1648772805929184
train-epoch-step: 9-582 -- Loss: 0.24749113619327545
train-epoch-step: 9-583 -- Loss: 0.2793676257133484
train-epoch-step: 9-584 -- Loss: 0.24011722207069397
train-epoch-step: 9-585 -- Loss: 0.23390164971351624
train-epoch-step: 9-586 -- Loss: 0.31784945726394653
train-epoch-step: 9-587 -- Loss: 0.19028452038764954
train-epoch-step: 9-588 -- Loss: 0.15158556401729584
val-epoch-step: 9-589 -- Loss: 0.25618526339530945
val-epoch-step: 9-590 -- Loss: 0.17052718997001648
val-epoch-step: 9-591 -- Loss: 0.2428731918334961
val-epoch-step: 9-592 -- Loss: 0.20599627494812012
val-epoch-step: 9-593 -- Loss: 0.168720081448555
val-epoch-step: 9-594 -- Loss: 0.35481691360473633
val-epoch-step: 9-595 -- Loss: 0.20685948431491852
val-epoch-step: 9-596 -- Loss: 0.23995760083198547
val-epoch-step: 9-597 -- Loss: 0.21539044380187988
val-epoch-step: 9-598 -- Loss: 0.17398032546043396
val-epoch-step: 9-599 -- Loss: 0.20780062675476074
val-epoch-step: 9-600 -- Loss: 0.20289179682731628
val-epoch-step: 9-601 -- Loss: 0.17400392889976501
val-epoch-step: 9-602 -- Loss: 0.15859383344650269
val-epoch-step: 9-603 -- Loss: 0.20804227888584137
val-epoch-step: 9-604 -- Loss: 0.17018289864063263
val-epoch-step: 9-605 -- Loss: 0.17236655950546265
val-epoch-step: 9-606 -- Loss: 0.3089970648288727
val-epoch-step: 9-607 -- Loss: 0.14891967177391052
val-epoch-step: 9-608 -- Loss: 0.28487491607666016
val-epoch-step: 9-609 -- Loss: 0.20570382475852966
val-epoch-step: 9-610 -- Loss: 0.2151021808385849
val-epoch-step: 9-611 -- Loss: 0.1867256760597229
val-epoch-step: 9-612 -- Loss: 0.35556331276893616
val-epoch-step: 9-613 -- Loss: 0.2118070423603058
val-epoch-step: 9-614 -- Loss: 0.17857375741004944
val-epoch-step: 9-615 -- Loss: 0.21521875262260437
val-epoch-step: 9-616 -- Loss: 0.17635640501976013
val-epoch-step: 9-617 -- Loss: 0.22179177403450012
val-epoch-step: 9-618 -- Loss: 0.22590774297714233
val-epoch-step: 9-619 -- Loss: 0.2584420442581177
val-epoch-step: 9-620 -- Loss: 0.16707544028759003
val-epoch-step: 9-621 -- Loss: 0.1596929132938385
val-epoch-step: 9-622 -- Loss: 0.16958433389663696
val-epoch-step: 9-623 -- Loss: 0.17223960161209106
val-epoch-step: 9-624 -- Loss: 0.1996767818927765
val-epoch-step: 9-625 -- Loss: 0.18034987151622772
val-epoch-step: 9-626 -- Loss: 0.1661546379327774
val-epoch-step: 9-627 -- Loss: 0.2290715128183365
val-epoch-step: 9-628 -- Loss: 0.5915402173995972
val-epoch-step: 9-629 -- Loss: 0.2304145246744156
val-epoch-step: 9-630 -- Loss: 0.39063790440559387
val-epoch-step: 9-631 -- Loss: 0.16823619604110718
val-epoch-step: 9-632 -- Loss: 0.22333267331123352
val-epoch-step: 9-633 -- Loss: 0.18202528357505798
val-epoch-step: 9-634 -- Loss: 0.16006237268447876
val-epoch-step: 9-635 -- Loss: 0.1366855502128601
val-epoch-step: 9-636 -- Loss: 0.19097024202346802
val-epoch-step: 9-637 -- Loss: 0.20431923866271973
val-epoch-step: 9-638 -- Loss: 0.1790667474269867
val-epoch-step: 9-639 -- Loss: 0.29919710755348206
val-epoch-step: 9-640 -- Loss: 0.2888241410255432
val-epoch-step: 9-641 -- Loss: 0.14024505019187927
val-epoch-step: 9-642 -- Loss: 0.21990081667900085
val-epoch-step: 9-643 -- Loss: 0.2307555079460144
val-epoch-step: 9-644 -- Loss: 0.1860053539276123
val-epoch-step: 9-645 -- Loss: 0.2544494867324829
val-epoch-step: 9-646 -- Loss: 0.16684846580028534
val-epoch-step: 9-647 -- Loss: 0.1554497927427292
val-epoch-step: 9-648 -- Loss: 0.19228670001029968
val-epoch-step: 9-649 -- Loss: 0.2464335560798645
val-epoch-step: 9-650 -- Loss: 0.2868962287902832
val-epoch-step: 9-651 -- Loss: 0.1644279509782791
val-epoch-step: 9-652 -- Loss: 0.1867561638355255
val-epoch-step: 9-653 -- Loss: 0.23353280127048492
val-epoch-step: 9-654 -- Loss: 0.13005521893501282
Epoch: 9 -- Train Loss: tensor(0.1550, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 10-0 -- Loss: 0.26057249307632446
train-epoch-step: 10-1 -- Loss: 0.16618680953979492
train-epoch-step: 10-2 -- Loss: 0.23000633716583252
train-epoch-step: 10-3 -- Loss: 0.1736847311258316
train-epoch-step: 10-4 -- Loss: 0.22160270810127258
train-epoch-step: 10-5 -- Loss: 0.22278249263763428
train-epoch-step: 10-6 -- Loss: 0.2736705243587494
train-epoch-step: 10-7 -- Loss: 0.2024286538362503
train-epoch-step: 10-8 -- Loss: 0.22201023995876312
train-epoch-step: 10-9 -- Loss: 0.3093968331813812
train-epoch-step: 10-10 -- Loss: 0.2837487757205963
train-epoch-step: 10-11 -- Loss: 0.20790480077266693
train-epoch-step: 10-12 -- Loss: 0.18561221659183502
train-epoch-step: 10-13 -- Loss: 0.21438828110694885
train-epoch-step: 10-14 -- Loss: 0.1830013245344162
train-epoch-step: 10-15 -- Loss: 0.1891792118549347
train-epoch-step: 10-16 -- Loss: 0.19630363583564758
train-epoch-step: 10-17 -- Loss: 0.259034663438797
train-epoch-step: 10-18 -- Loss: 0.22107531130313873
train-epoch-step: 10-19 -- Loss: 0.1547349989414215
train-epoch-step: 10-20 -- Loss: 0.26503676176071167
train-epoch-step: 10-21 -- Loss: 0.39805474877357483
train-epoch-step: 10-22 -- Loss: 0.17711490392684937
train-epoch-step: 10-23 -- Loss: 0.2173824906349182
train-epoch-step: 10-24 -- Loss: 0.1506168693304062
train-epoch-step: 10-25 -- Loss: 0.26236850023269653
train-epoch-step: 10-26 -- Loss: 0.22959861159324646
train-epoch-step: 10-27 -- Loss: 0.30084681510925293
train-epoch-step: 10-28 -- Loss: 0.14470836520195007
train-epoch-step: 10-29 -- Loss: 0.27904582023620605
train-epoch-step: 10-30 -- Loss: 0.1274414211511612
train-epoch-step: 10-31 -- Loss: 0.17043384909629822
train-epoch-step: 10-32 -- Loss: 0.2005312144756317
train-epoch-step: 10-33 -- Loss: 0.31481537222862244
train-epoch-step: 10-34 -- Loss: 0.19842004776000977
train-epoch-step: 10-35 -- Loss: 0.2967883050441742
train-epoch-step: 10-36 -- Loss: 0.16459842026233673
train-epoch-step: 10-37 -- Loss: 0.16675366461277008
train-epoch-step: 10-38 -- Loss: 0.22957172989845276
train-epoch-step: 10-39 -- Loss: 0.2821164131164551
train-epoch-step: 10-40 -- Loss: 0.24946735799312592
train-epoch-step: 10-41 -- Loss: 0.2513132393360138
train-epoch-step: 10-42 -- Loss: 0.17268207669258118
train-epoch-step: 10-43 -- Loss: 0.3254764676094055
train-epoch-step: 10-44 -- Loss: 0.14958398044109344
train-epoch-step: 10-45 -- Loss: 0.14728006720542908
train-epoch-step: 10-46 -- Loss: 0.2157078981399536
train-epoch-step: 10-47 -- Loss: 0.28421759605407715
train-epoch-step: 10-48 -- Loss: 0.17723342776298523
train-epoch-step: 10-49 -- Loss: 0.25326424837112427
train-epoch-step: 10-50 -- Loss: 0.14126965403556824
train-epoch-step: 10-51 -- Loss: 0.22616451978683472
train-epoch-step: 10-52 -- Loss: 0.18401309847831726
train-epoch-step: 10-53 -- Loss: 0.2599521279335022
train-epoch-step: 10-54 -- Loss: 0.33627498149871826
train-epoch-step: 10-55 -- Loss: 0.19901052117347717
train-epoch-step: 10-56 -- Loss: 0.21956174075603485
train-epoch-step: 10-57 -- Loss: 0.27467605471611023
train-epoch-step: 10-58 -- Loss: 0.32033970952033997
train-epoch-step: 10-59 -- Loss: 0.3087662160396576
train-epoch-step: 10-60 -- Loss: 0.15216416120529175
train-epoch-step: 10-61 -- Loss: 0.25262585282325745
train-epoch-step: 10-62 -- Loss: 0.21830832958221436
train-epoch-step: 10-63 -- Loss: 0.16606584191322327
train-epoch-step: 10-64 -- Loss: 0.17885619401931763
train-epoch-step: 10-65 -- Loss: 0.22817078232765198
train-epoch-step: 10-66 -- Loss: 0.13162770867347717
train-epoch-step: 10-67 -- Loss: 0.14868217706680298
train-epoch-step: 10-68 -- Loss: 0.26619812846183777
train-epoch-step: 10-69 -- Loss: 0.1573033183813095
train-epoch-step: 10-70 -- Loss: 0.2470252513885498
train-epoch-step: 10-71 -- Loss: 0.29492494463920593
train-epoch-step: 10-72 -- Loss: 0.2135544717311859
train-epoch-step: 10-73 -- Loss: 0.25329381227493286
train-epoch-step: 10-74 -- Loss: 0.11499368399381638
train-epoch-step: 10-75 -- Loss: 0.15402203798294067
train-epoch-step: 10-76 -- Loss: 0.1723395586013794
train-epoch-step: 10-77 -- Loss: 0.26202425360679626
train-epoch-step: 10-78 -- Loss: 0.3190920054912567
train-epoch-step: 10-79 -- Loss: 0.22996726632118225
train-epoch-step: 10-80 -- Loss: 0.32568442821502686
train-epoch-step: 10-81 -- Loss: 0.1446799635887146
train-epoch-step: 10-82 -- Loss: 0.2996305823326111
train-epoch-step: 10-83 -- Loss: 0.2270599752664566
train-epoch-step: 10-84 -- Loss: 0.23927070200443268
train-epoch-step: 10-85 -- Loss: 0.20791557431221008
train-epoch-step: 10-86 -- Loss: 0.151053786277771
train-epoch-step: 10-87 -- Loss: 0.2887519896030426
train-epoch-step: 10-88 -- Loss: 0.16449663043022156
train-epoch-step: 10-89 -- Loss: 0.22760555148124695
train-epoch-step: 10-90 -- Loss: 0.23158633708953857
train-epoch-step: 10-91 -- Loss: 0.28282630443573
train-epoch-step: 10-92 -- Loss: 0.1896919161081314
train-epoch-step: 10-93 -- Loss: 0.21326026320457458
train-epoch-step: 10-94 -- Loss: 0.2682058811187744
train-epoch-step: 10-95 -- Loss: 0.23441706597805023
train-epoch-step: 10-96 -- Loss: 0.26715052127838135
train-epoch-step: 10-97 -- Loss: 0.2089652568101883
train-epoch-step: 10-98 -- Loss: 0.18004678189754486
train-epoch-step: 10-99 -- Loss: 0.21536734700202942
train-epoch-step: 10-100 -- Loss: 0.22698017954826355
train-epoch-step: 10-101 -- Loss: 0.32403284311294556
train-epoch-step: 10-102 -- Loss: 0.26712873578071594
train-epoch-step: 10-103 -- Loss: 0.23483793437480927
train-epoch-step: 10-104 -- Loss: 0.1741686761379242
train-epoch-step: 10-105 -- Loss: 0.3147730231285095
train-epoch-step: 10-106 -- Loss: 0.20628634095191956
train-epoch-step: 10-107 -- Loss: 0.21962496638298035
train-epoch-step: 10-108 -- Loss: 0.2165156602859497
train-epoch-step: 10-109 -- Loss: 0.17158715426921844
train-epoch-step: 10-110 -- Loss: 0.2202540636062622
train-epoch-step: 10-111 -- Loss: 0.21422156691551208
train-epoch-step: 10-112 -- Loss: 0.19753623008728027
train-epoch-step: 10-113 -- Loss: 0.19570612907409668
train-epoch-step: 10-114 -- Loss: 0.2708379626274109
train-epoch-step: 10-115 -- Loss: 0.20292305946350098
train-epoch-step: 10-116 -- Loss: 0.18238770961761475
train-epoch-step: 10-117 -- Loss: 0.1508016586303711
train-epoch-step: 10-118 -- Loss: 0.2360333353281021
train-epoch-step: 10-119 -- Loss: 0.17808890342712402
train-epoch-step: 10-120 -- Loss: 0.32624632120132446
train-epoch-step: 10-121 -- Loss: 0.30676835775375366
train-epoch-step: 10-122 -- Loss: 0.24966835975646973
train-epoch-step: 10-123 -- Loss: 0.252626895904541
train-epoch-step: 10-124 -- Loss: 0.142952099442482
train-epoch-step: 10-125 -- Loss: 0.1802540123462677
train-epoch-step: 10-126 -- Loss: 0.27783894538879395
train-epoch-step: 10-127 -- Loss: 0.2149144858121872
train-epoch-step: 10-128 -- Loss: 0.20544415712356567
train-epoch-step: 10-129 -- Loss: 0.1716681867837906
train-epoch-step: 10-130 -- Loss: 0.21780413389205933
train-epoch-step: 10-131 -- Loss: 0.16239996254444122
train-epoch-step: 10-132 -- Loss: 0.23145973682403564
train-epoch-step: 10-133 -- Loss: 0.1400180459022522
train-epoch-step: 10-134 -- Loss: 0.23967111110687256
train-epoch-step: 10-135 -- Loss: 0.1605890393257141
train-epoch-step: 10-136 -- Loss: 0.15090271830558777
train-epoch-step: 10-137 -- Loss: 0.3016808331012726
train-epoch-step: 10-138 -- Loss: 0.3060652017593384
train-epoch-step: 10-139 -- Loss: 0.15355102717876434
train-epoch-step: 10-140 -- Loss: 0.2411474883556366
train-epoch-step: 10-141 -- Loss: 0.2825663387775421
train-epoch-step: 10-142 -- Loss: 0.24223795533180237
train-epoch-step: 10-143 -- Loss: 0.20053941011428833
train-epoch-step: 10-144 -- Loss: 0.219875305891037
train-epoch-step: 10-145 -- Loss: 0.16266955435276031
train-epoch-step: 10-146 -- Loss: 0.20681628584861755
train-epoch-step: 10-147 -- Loss: 0.21701902151107788
train-epoch-step: 10-148 -- Loss: 0.20788037776947021
train-epoch-step: 10-149 -- Loss: 0.13708144426345825
train-epoch-step: 10-150 -- Loss: 0.2205139845609665
train-epoch-step: 10-151 -- Loss: 0.223287895321846
train-epoch-step: 10-152 -- Loss: 0.2304631620645523
train-epoch-step: 10-153 -- Loss: 0.35788464546203613
train-epoch-step: 10-154 -- Loss: 0.15312838554382324
train-epoch-step: 10-155 -- Loss: 0.16456015408039093
train-epoch-step: 10-156 -- Loss: 0.14835450053215027
train-epoch-step: 10-157 -- Loss: 0.19351404905319214
train-epoch-step: 10-158 -- Loss: 0.19302353262901306
train-epoch-step: 10-159 -- Loss: 0.2096809446811676
train-epoch-step: 10-160 -- Loss: 0.2673235833644867
train-epoch-step: 10-161 -- Loss: 0.24649643898010254
train-epoch-step: 10-162 -- Loss: 0.25252604484558105
train-epoch-step: 10-163 -- Loss: 0.20849022269248962
train-epoch-step: 10-164 -- Loss: 0.21632950007915497
train-epoch-step: 10-165 -- Loss: 0.19215044379234314
train-epoch-step: 10-166 -- Loss: 0.14260928332805634
train-epoch-step: 10-167 -- Loss: 0.14582200348377228
train-epoch-step: 10-168 -- Loss: 0.24464786052703857
train-epoch-step: 10-169 -- Loss: 0.1665477752685547
train-epoch-step: 10-170 -- Loss: 0.23556101322174072
train-epoch-step: 10-171 -- Loss: 0.16330306231975555
train-epoch-step: 10-172 -- Loss: 0.3012785017490387
train-epoch-step: 10-173 -- Loss: 0.15314683318138123
train-epoch-step: 10-174 -- Loss: 0.2792355418205261
train-epoch-step: 10-175 -- Loss: 0.2095640003681183
train-epoch-step: 10-176 -- Loss: 0.15611810982227325
train-epoch-step: 10-177 -- Loss: 0.21957780420780182
train-epoch-step: 10-178 -- Loss: 0.22417034208774567
train-epoch-step: 10-179 -- Loss: 0.16939353942871094
train-epoch-step: 10-180 -- Loss: 0.1709844172000885
train-epoch-step: 10-181 -- Loss: 0.2035197615623474
train-epoch-step: 10-182 -- Loss: 0.23158425092697144
train-epoch-step: 10-183 -- Loss: 0.30619314312934875
train-epoch-step: 10-184 -- Loss: 0.16230499744415283
train-epoch-step: 10-185 -- Loss: 0.1705971360206604
train-epoch-step: 10-186 -- Loss: 0.22180864214897156
train-epoch-step: 10-187 -- Loss: 0.24594642221927643
train-epoch-step: 10-188 -- Loss: 0.20437347888946533
train-epoch-step: 10-189 -- Loss: 0.15494424104690552
train-epoch-step: 10-190 -- Loss: 0.20665059983730316
train-epoch-step: 10-191 -- Loss: 0.21039459109306335
train-epoch-step: 10-192 -- Loss: 0.2794792652130127
train-epoch-step: 10-193 -- Loss: 0.2622976303100586
train-epoch-step: 10-194 -- Loss: 0.20965394377708435
train-epoch-step: 10-195 -- Loss: 0.19583140313625336
train-epoch-step: 10-196 -- Loss: 0.22198408842086792
train-epoch-step: 10-197 -- Loss: 0.16015572845935822
train-epoch-step: 10-198 -- Loss: 0.15290077030658722
train-epoch-step: 10-199 -- Loss: 0.176762193441391
train-epoch-step: 10-200 -- Loss: 0.14725585281848907
train-epoch-step: 10-201 -- Loss: 0.23519396781921387
train-epoch-step: 10-202 -- Loss: 0.15854331851005554
train-epoch-step: 10-203 -- Loss: 0.20498239994049072
train-epoch-step: 10-204 -- Loss: 0.17007769644260406
train-epoch-step: 10-205 -- Loss: 0.22586610913276672
train-epoch-step: 10-206 -- Loss: 0.24389106035232544
train-epoch-step: 10-207 -- Loss: 0.16901038587093353
train-epoch-step: 10-208 -- Loss: 0.21230041980743408
train-epoch-step: 10-209 -- Loss: 0.15726248919963837
train-epoch-step: 10-210 -- Loss: 0.1574316918849945
train-epoch-step: 10-211 -- Loss: 0.24334102869033813
train-epoch-step: 10-212 -- Loss: 0.2296282798051834
train-epoch-step: 10-213 -- Loss: 0.147628054022789
train-epoch-step: 10-214 -- Loss: 0.17561385035514832
train-epoch-step: 10-215 -- Loss: 0.1604980230331421
train-epoch-step: 10-216 -- Loss: 0.2309992015361786
train-epoch-step: 10-217 -- Loss: 0.24422390758991241
train-epoch-step: 10-218 -- Loss: 0.1741102635860443
train-epoch-step: 10-219 -- Loss: 0.24028758704662323
train-epoch-step: 10-220 -- Loss: 0.15841202437877655
train-epoch-step: 10-221 -- Loss: 0.2337147742509842
train-epoch-step: 10-222 -- Loss: 0.14494328200817108
train-epoch-step: 10-223 -- Loss: 0.20874494314193726
train-epoch-step: 10-224 -- Loss: 0.22585658729076385
train-epoch-step: 10-225 -- Loss: 0.36350709199905396
train-epoch-step: 10-226 -- Loss: 0.2545897960662842
train-epoch-step: 10-227 -- Loss: 0.2833051085472107
train-epoch-step: 10-228 -- Loss: 0.20534932613372803
train-epoch-step: 10-229 -- Loss: 0.21546030044555664
train-epoch-step: 10-230 -- Loss: 0.18830373883247375
train-epoch-step: 10-231 -- Loss: 0.20704051852226257
train-epoch-step: 10-232 -- Loss: 0.24143517017364502
train-epoch-step: 10-233 -- Loss: 0.10056516528129578
train-epoch-step: 10-234 -- Loss: 0.21489162743091583
train-epoch-step: 10-235 -- Loss: 0.18897852301597595
train-epoch-step: 10-236 -- Loss: 0.21146097779273987
train-epoch-step: 10-237 -- Loss: 0.28755128383636475
train-epoch-step: 10-238 -- Loss: 0.1811387836933136
train-epoch-step: 10-239 -- Loss: 0.15899214148521423
train-epoch-step: 10-240 -- Loss: 0.2597582936286926
train-epoch-step: 10-241 -- Loss: 0.18553566932678223
train-epoch-step: 10-242 -- Loss: 0.25746631622314453
train-epoch-step: 10-243 -- Loss: 0.26763394474983215
train-epoch-step: 10-244 -- Loss: 0.24949100613594055
train-epoch-step: 10-245 -- Loss: 0.2752859592437744
train-epoch-step: 10-246 -- Loss: 0.3131636083126068
train-epoch-step: 10-247 -- Loss: 0.27587735652923584
train-epoch-step: 10-248 -- Loss: 0.22170604765415192
train-epoch-step: 10-249 -- Loss: 0.17342756688594818
train-epoch-step: 10-250 -- Loss: 0.2340574711561203
train-epoch-step: 10-251 -- Loss: 0.13375669717788696
train-epoch-step: 10-252 -- Loss: 0.24145856499671936
train-epoch-step: 10-253 -- Loss: 0.16886068880558014
train-epoch-step: 10-254 -- Loss: 0.27946048974990845
train-epoch-step: 10-255 -- Loss: 0.17795108258724213
train-epoch-step: 10-256 -- Loss: 0.1842348575592041
train-epoch-step: 10-257 -- Loss: 0.22795197367668152
train-epoch-step: 10-258 -- Loss: 0.18176454305648804
train-epoch-step: 10-259 -- Loss: 0.1445661187171936
train-epoch-step: 10-260 -- Loss: 0.24741718173027039
train-epoch-step: 10-261 -- Loss: 0.20879122614860535
train-epoch-step: 10-262 -- Loss: 0.3561558723449707
train-epoch-step: 10-263 -- Loss: 0.24512821435928345
train-epoch-step: 10-264 -- Loss: 0.1966274380683899
train-epoch-step: 10-265 -- Loss: 0.13835154473781586
train-epoch-step: 10-266 -- Loss: 0.17409533262252808
train-epoch-step: 10-267 -- Loss: 0.17024379968643188
train-epoch-step: 10-268 -- Loss: 0.14088721573352814
train-epoch-step: 10-269 -- Loss: 0.20471183955669403
train-epoch-step: 10-270 -- Loss: 0.1306122988462448
train-epoch-step: 10-271 -- Loss: 0.18258914351463318
train-epoch-step: 10-272 -- Loss: 0.13899314403533936
train-epoch-step: 10-273 -- Loss: 0.15256479382514954
train-epoch-step: 10-274 -- Loss: 0.22493988275527954
train-epoch-step: 10-275 -- Loss: 0.23301063477993011
train-epoch-step: 10-276 -- Loss: 0.18561968207359314
train-epoch-step: 10-277 -- Loss: 0.1767680048942566
train-epoch-step: 10-278 -- Loss: 0.1723182648420334
train-epoch-step: 10-279 -- Loss: 0.17678901553153992
train-epoch-step: 10-280 -- Loss: 0.2506411075592041
train-epoch-step: 10-281 -- Loss: 0.21511951088905334
train-epoch-step: 10-282 -- Loss: 0.16109874844551086
train-epoch-step: 10-283 -- Loss: 0.13788658380508423
train-epoch-step: 10-284 -- Loss: 0.28303220868110657
train-epoch-step: 10-285 -- Loss: 0.2269177883863449
train-epoch-step: 10-286 -- Loss: 0.18749675154685974
train-epoch-step: 10-287 -- Loss: 0.23958076536655426
train-epoch-step: 10-288 -- Loss: 0.10885167121887207
train-epoch-step: 10-289 -- Loss: 0.14739157259464264
train-epoch-step: 10-290 -- Loss: 0.21650007367134094
train-epoch-step: 10-291 -- Loss: 0.13626506924629211
train-epoch-step: 10-292 -- Loss: 0.18460696935653687
train-epoch-step: 10-293 -- Loss: 0.16364797949790955
train-epoch-step: 10-294 -- Loss: 0.20448404550552368
train-epoch-step: 10-295 -- Loss: 0.351457417011261
train-epoch-step: 10-296 -- Loss: 0.20120583474636078
train-epoch-step: 10-297 -- Loss: 0.20592734217643738
train-epoch-step: 10-298 -- Loss: 0.29074928164482117
train-epoch-step: 10-299 -- Loss: 0.19206739962100983
train-epoch-step: 10-300 -- Loss: 0.21711035072803497
train-epoch-step: 10-301 -- Loss: 0.19178369641304016
train-epoch-step: 10-302 -- Loss: 0.2592802047729492
train-epoch-step: 10-303 -- Loss: 0.2378753423690796
train-epoch-step: 10-304 -- Loss: 0.17108309268951416
train-epoch-step: 10-305 -- Loss: 0.17064307630062103
train-epoch-step: 10-306 -- Loss: 0.2827417254447937
train-epoch-step: 10-307 -- Loss: 0.1936493068933487
train-epoch-step: 10-308 -- Loss: 0.27789506316185
train-epoch-step: 10-309 -- Loss: 0.1793937087059021
train-epoch-step: 10-310 -- Loss: 0.18976156413555145
train-epoch-step: 10-311 -- Loss: 0.19481521844863892
train-epoch-step: 10-312 -- Loss: 0.255231112241745
train-epoch-step: 10-313 -- Loss: 0.11775928735733032
train-epoch-step: 10-314 -- Loss: 0.2452075481414795
train-epoch-step: 10-315 -- Loss: 0.21562808752059937
train-epoch-step: 10-316 -- Loss: 0.1799771785736084
train-epoch-step: 10-317 -- Loss: 0.17739632725715637
train-epoch-step: 10-318 -- Loss: 0.1923820972442627
train-epoch-step: 10-319 -- Loss: 0.2163635790348053
train-epoch-step: 10-320 -- Loss: 0.1432586908340454
train-epoch-step: 10-321 -- Loss: 0.17239339649677277
train-epoch-step: 10-322 -- Loss: 0.2533133029937744
train-epoch-step: 10-323 -- Loss: 0.18733881413936615
train-epoch-step: 10-324 -- Loss: 0.3135124742984772
train-epoch-step: 10-325 -- Loss: 0.1770731806755066
train-epoch-step: 10-326 -- Loss: 0.2089962512254715
train-epoch-step: 10-327 -- Loss: 0.25572288036346436
train-epoch-step: 10-328 -- Loss: 0.2290882170200348
train-epoch-step: 10-329 -- Loss: 0.3819490075111389
train-epoch-step: 10-330 -- Loss: 0.4252951741218567
train-epoch-step: 10-331 -- Loss: 0.26134124398231506
train-epoch-step: 10-332 -- Loss: 0.12582871317863464
train-epoch-step: 10-333 -- Loss: 0.22016696631908417
train-epoch-step: 10-334 -- Loss: 0.18568408489227295
train-epoch-step: 10-335 -- Loss: 0.20483659207820892
train-epoch-step: 10-336 -- Loss: 0.19607628881931305
train-epoch-step: 10-337 -- Loss: 0.25482475757598877
train-epoch-step: 10-338 -- Loss: 0.19352011382579803
train-epoch-step: 10-339 -- Loss: 0.17066152393817902
train-epoch-step: 10-340 -- Loss: 0.23155328631401062
train-epoch-step: 10-341 -- Loss: 0.16644534468650818
train-epoch-step: 10-342 -- Loss: 0.20168185234069824
train-epoch-step: 10-343 -- Loss: 0.1848895400762558
train-epoch-step: 10-344 -- Loss: 0.20077767968177795
train-epoch-step: 10-345 -- Loss: 0.1527080535888672
train-epoch-step: 10-346 -- Loss: 0.2229853719472885
train-epoch-step: 10-347 -- Loss: 0.1824718862771988
train-epoch-step: 10-348 -- Loss: 0.23699064552783966
train-epoch-step: 10-349 -- Loss: 0.261868417263031
train-epoch-step: 10-350 -- Loss: 0.31425419449806213
train-epoch-step: 10-351 -- Loss: 0.23374706506729126
train-epoch-step: 10-352 -- Loss: 0.16404768824577332
train-epoch-step: 10-353 -- Loss: 0.22754700481891632
train-epoch-step: 10-354 -- Loss: 0.32997357845306396
train-epoch-step: 10-355 -- Loss: 0.14301037788391113
train-epoch-step: 10-356 -- Loss: 0.13816888630390167
train-epoch-step: 10-357 -- Loss: 0.22541379928588867
train-epoch-step: 10-358 -- Loss: 0.22116069495677948
train-epoch-step: 10-359 -- Loss: 0.17155537009239197
train-epoch-step: 10-360 -- Loss: 0.1398678421974182
train-epoch-step: 10-361 -- Loss: 0.29964113235473633
train-epoch-step: 10-362 -- Loss: 0.200628399848938
train-epoch-step: 10-363 -- Loss: 0.13997505605220795
train-epoch-step: 10-364 -- Loss: 0.21442125737667084
train-epoch-step: 10-365 -- Loss: 0.20341703295707703
train-epoch-step: 10-366 -- Loss: 0.2326379418373108
train-epoch-step: 10-367 -- Loss: 0.32460999488830566
train-epoch-step: 10-368 -- Loss: 0.24492719769477844
train-epoch-step: 10-369 -- Loss: 0.31256359815597534
train-epoch-step: 10-370 -- Loss: 0.14384566247463226
train-epoch-step: 10-371 -- Loss: 0.1377357840538025
train-epoch-step: 10-372 -- Loss: 0.1736738681793213
train-epoch-step: 10-373 -- Loss: 0.23050051927566528
train-epoch-step: 10-374 -- Loss: 0.17548581957817078
train-epoch-step: 10-375 -- Loss: 0.3357853293418884
train-epoch-step: 10-376 -- Loss: 0.23923054337501526
train-epoch-step: 10-377 -- Loss: 0.28054100275039673
train-epoch-step: 10-378 -- Loss: 0.2585243582725525
train-epoch-step: 10-379 -- Loss: 0.14128485321998596
train-epoch-step: 10-380 -- Loss: 0.10404191166162491
train-epoch-step: 10-381 -- Loss: 0.28757786750793457
train-epoch-step: 10-382 -- Loss: 0.26892343163490295
train-epoch-step: 10-383 -- Loss: 0.2088448852300644
train-epoch-step: 10-384 -- Loss: 0.25756311416625977
train-epoch-step: 10-385 -- Loss: 0.23773439228534698
train-epoch-step: 10-386 -- Loss: 0.247281014919281
train-epoch-step: 10-387 -- Loss: 0.24202023446559906
train-epoch-step: 10-388 -- Loss: 0.31707727909088135
train-epoch-step: 10-389 -- Loss: 0.2239546775817871
train-epoch-step: 10-390 -- Loss: 0.16265884041786194
train-epoch-step: 10-391 -- Loss: 0.1670314073562622
train-epoch-step: 10-392 -- Loss: 0.21303413808345795
train-epoch-step: 10-393 -- Loss: 0.18848922848701477
train-epoch-step: 10-394 -- Loss: 0.25997909903526306
train-epoch-step: 10-395 -- Loss: 0.19433008134365082
train-epoch-step: 10-396 -- Loss: 0.15491241216659546
train-epoch-step: 10-397 -- Loss: 0.14837127923965454
train-epoch-step: 10-398 -- Loss: 0.2326415777206421
train-epoch-step: 10-399 -- Loss: 0.21987083554267883
train-epoch-step: 10-400 -- Loss: 0.3405655026435852
train-epoch-step: 10-401 -- Loss: 0.13978135585784912
train-epoch-step: 10-402 -- Loss: 0.3179757595062256
train-epoch-step: 10-403 -- Loss: 0.19019126892089844
train-epoch-step: 10-404 -- Loss: 0.16672663390636444
train-epoch-step: 10-405 -- Loss: 0.1819421499967575
train-epoch-step: 10-406 -- Loss: 0.19846764206886292
train-epoch-step: 10-407 -- Loss: 0.13816538453102112
train-epoch-step: 10-408 -- Loss: 0.1912880837917328
train-epoch-step: 10-409 -- Loss: 0.20333296060562134
train-epoch-step: 10-410 -- Loss: 0.22372934222221375
train-epoch-step: 10-411 -- Loss: 0.23108476400375366
train-epoch-step: 10-412 -- Loss: 0.1477331817150116
train-epoch-step: 10-413 -- Loss: 0.1712259203195572
train-epoch-step: 10-414 -- Loss: 0.16143798828125
train-epoch-step: 10-415 -- Loss: 0.1725187599658966
train-epoch-step: 10-416 -- Loss: 0.32126715779304504
train-epoch-step: 10-417 -- Loss: 0.2418804168701172
train-epoch-step: 10-418 -- Loss: 0.32053303718566895
train-epoch-step: 10-419 -- Loss: 0.20770993828773499
train-epoch-step: 10-420 -- Loss: 0.19099411368370056
train-epoch-step: 10-421 -- Loss: 0.2219049036502838
train-epoch-step: 10-422 -- Loss: 0.18116538226604462
train-epoch-step: 10-423 -- Loss: 0.21173971891403198
train-epoch-step: 10-424 -- Loss: 0.16288217902183533
train-epoch-step: 10-425 -- Loss: 0.22325153648853302
train-epoch-step: 10-426 -- Loss: 0.20967766642570496
train-epoch-step: 10-427 -- Loss: 0.16556954383850098
train-epoch-step: 10-428 -- Loss: 0.24040445685386658
train-epoch-step: 10-429 -- Loss: 0.20715981721878052
train-epoch-step: 10-430 -- Loss: 0.17806799709796906
train-epoch-step: 10-431 -- Loss: 0.20001891255378723
train-epoch-step: 10-432 -- Loss: 0.28247782588005066
train-epoch-step: 10-433 -- Loss: 0.16824157536029816
train-epoch-step: 10-434 -- Loss: 0.14858272671699524
train-epoch-step: 10-435 -- Loss: 0.18815690279006958
train-epoch-step: 10-436 -- Loss: 0.19170352816581726
train-epoch-step: 10-437 -- Loss: 0.16055506467819214
train-epoch-step: 10-438 -- Loss: 0.22056517004966736
train-epoch-step: 10-439 -- Loss: 0.3162775933742523
train-epoch-step: 10-440 -- Loss: 0.15859952569007874
train-epoch-step: 10-441 -- Loss: 0.25267454981803894
train-epoch-step: 10-442 -- Loss: 0.2210579663515091
train-epoch-step: 10-443 -- Loss: 0.18405413627624512
train-epoch-step: 10-444 -- Loss: 0.255634605884552
train-epoch-step: 10-445 -- Loss: 0.23357148468494415
train-epoch-step: 10-446 -- Loss: 0.1849302351474762
train-epoch-step: 10-447 -- Loss: 0.23561111092567444
train-epoch-step: 10-448 -- Loss: 0.3009381592273712
train-epoch-step: 10-449 -- Loss: 0.2287428379058838
train-epoch-step: 10-450 -- Loss: 0.2205452024936676
train-epoch-step: 10-451 -- Loss: 0.1691913902759552
train-epoch-step: 10-452 -- Loss: 0.15657612681388855
train-epoch-step: 10-453 -- Loss: 0.1122133806347847
train-epoch-step: 10-454 -- Loss: 0.292921245098114
train-epoch-step: 10-455 -- Loss: 0.1560765653848648
train-epoch-step: 10-456 -- Loss: 0.14175835251808167
train-epoch-step: 10-457 -- Loss: 0.25292494893074036
train-epoch-step: 10-458 -- Loss: 0.17390814423561096
train-epoch-step: 10-459 -- Loss: 0.2546667456626892
train-epoch-step: 10-460 -- Loss: 0.1425292193889618
train-epoch-step: 10-461 -- Loss: 0.1708725094795227
train-epoch-step: 10-462 -- Loss: 0.17838440835475922
train-epoch-step: 10-463 -- Loss: 0.16217301785945892
train-epoch-step: 10-464 -- Loss: 0.20729809999465942
train-epoch-step: 10-465 -- Loss: 0.29291072487831116
train-epoch-step: 10-466 -- Loss: 0.22515584528446198
train-epoch-step: 10-467 -- Loss: 0.14051929116249084
train-epoch-step: 10-468 -- Loss: 0.22761747241020203
train-epoch-step: 10-469 -- Loss: 0.29669055342674255
train-epoch-step: 10-470 -- Loss: 0.21146437525749207
train-epoch-step: 10-471 -- Loss: 0.17563317716121674
train-epoch-step: 10-472 -- Loss: 0.18031901121139526
train-epoch-step: 10-473 -- Loss: 0.1992417573928833
train-epoch-step: 10-474 -- Loss: 0.14378595352172852
train-epoch-step: 10-475 -- Loss: 0.13376781344413757
train-epoch-step: 10-476 -- Loss: 0.22897961735725403
train-epoch-step: 10-477 -- Loss: 0.2653921842575073
train-epoch-step: 10-478 -- Loss: 0.2230512946844101
train-epoch-step: 10-479 -- Loss: 0.1690710186958313
train-epoch-step: 10-480 -- Loss: 0.2283281534910202
train-epoch-step: 10-481 -- Loss: 0.32610246539115906
train-epoch-step: 10-482 -- Loss: 0.30777496099472046
train-epoch-step: 10-483 -- Loss: 0.22605057060718536
train-epoch-step: 10-484 -- Loss: 0.24627730250358582
train-epoch-step: 10-485 -- Loss: 0.15263324975967407
train-epoch-step: 10-486 -- Loss: 0.30501508712768555
train-epoch-step: 10-487 -- Loss: 0.257087379693985
train-epoch-step: 10-488 -- Loss: 0.22021876275539398
train-epoch-step: 10-489 -- Loss: 0.2529051899909973
train-epoch-step: 10-490 -- Loss: 0.16130882501602173
train-epoch-step: 10-491 -- Loss: 0.16357627511024475
train-epoch-step: 10-492 -- Loss: 0.14855307340621948
train-epoch-step: 10-493 -- Loss: 0.25285178422927856
train-epoch-step: 10-494 -- Loss: 0.25740909576416016
train-epoch-step: 10-495 -- Loss: 0.2401449829339981
train-epoch-step: 10-496 -- Loss: 0.15525071322917938
train-epoch-step: 10-497 -- Loss: 0.21467548608779907
train-epoch-step: 10-498 -- Loss: 0.1751062422990799
train-epoch-step: 10-499 -- Loss: 0.200199156999588
train-epoch-step: 10-500 -- Loss: 0.1808202862739563
train-epoch-step: 10-501 -- Loss: 0.24457016587257385
train-epoch-step: 10-502 -- Loss: 0.18285202980041504
train-epoch-step: 10-503 -- Loss: 0.2493913173675537
train-epoch-step: 10-504 -- Loss: 0.1400696337223053
train-epoch-step: 10-505 -- Loss: 0.199150949716568
train-epoch-step: 10-506 -- Loss: 0.13867586851119995
train-epoch-step: 10-507 -- Loss: 0.20920121669769287
train-epoch-step: 10-508 -- Loss: 0.20011639595031738
train-epoch-step: 10-509 -- Loss: 0.19459445774555206
train-epoch-step: 10-510 -- Loss: 0.14899136126041412
train-epoch-step: 10-511 -- Loss: 0.24848270416259766
train-epoch-step: 10-512 -- Loss: 0.2066953182220459
train-epoch-step: 10-513 -- Loss: 0.23949578404426575
train-epoch-step: 10-514 -- Loss: 0.17754170298576355
train-epoch-step: 10-515 -- Loss: 0.1882014274597168
train-epoch-step: 10-516 -- Loss: 0.20160236954689026
train-epoch-step: 10-517 -- Loss: 0.20890378952026367
train-epoch-step: 10-518 -- Loss: 0.15977881848812103
train-epoch-step: 10-519 -- Loss: 0.15052127838134766
train-epoch-step: 10-520 -- Loss: 0.21073627471923828
train-epoch-step: 10-521 -- Loss: 0.2529929280281067
train-epoch-step: 10-522 -- Loss: 0.2072352021932602
train-epoch-step: 10-523 -- Loss: 0.18445831537246704
train-epoch-step: 10-524 -- Loss: 0.202754944562912
train-epoch-step: 10-525 -- Loss: 0.21919132769107819
train-epoch-step: 10-526 -- Loss: 0.14906933903694153
train-epoch-step: 10-527 -- Loss: 0.18542718887329102
train-epoch-step: 10-528 -- Loss: 0.18175365030765533
train-epoch-step: 10-529 -- Loss: 0.20894020795822144
train-epoch-step: 10-530 -- Loss: 0.2044726312160492
train-epoch-step: 10-531 -- Loss: 0.23444126546382904
train-epoch-step: 10-532 -- Loss: 0.1944396197795868
train-epoch-step: 10-533 -- Loss: 0.1885841190814972
train-epoch-step: 10-534 -- Loss: 0.15659484267234802
train-epoch-step: 10-535 -- Loss: 0.32920747995376587
train-epoch-step: 10-536 -- Loss: 0.1832105666399002
train-epoch-step: 10-537 -- Loss: 0.17696882784366608
train-epoch-step: 10-538 -- Loss: 0.1173945963382721
train-epoch-step: 10-539 -- Loss: 0.23578065633773804
train-epoch-step: 10-540 -- Loss: 0.15822893381118774
train-epoch-step: 10-541 -- Loss: 0.24455134570598602
train-epoch-step: 10-542 -- Loss: 0.2761117219924927
train-epoch-step: 10-543 -- Loss: 0.19442452490329742
train-epoch-step: 10-544 -- Loss: 0.25585421919822693
train-epoch-step: 10-545 -- Loss: 0.222237691283226
train-epoch-step: 10-546 -- Loss: 0.2541104257106781
train-epoch-step: 10-547 -- Loss: 0.2032802700996399
train-epoch-step: 10-548 -- Loss: 0.1074913740158081
train-epoch-step: 10-549 -- Loss: 0.1755802035331726
train-epoch-step: 10-550 -- Loss: 0.23346814513206482
train-epoch-step: 10-551 -- Loss: 0.18984487652778625
train-epoch-step: 10-552 -- Loss: 0.15073762834072113
train-epoch-step: 10-553 -- Loss: 0.21849165856838226
train-epoch-step: 10-554 -- Loss: 0.2061963975429535
train-epoch-step: 10-555 -- Loss: 0.24987831711769104
train-epoch-step: 10-556 -- Loss: 0.19845938682556152
train-epoch-step: 10-557 -- Loss: 0.28619515895843506
train-epoch-step: 10-558 -- Loss: 0.2578352987766266
train-epoch-step: 10-559 -- Loss: 0.1726391613483429
train-epoch-step: 10-560 -- Loss: 0.23411345481872559
train-epoch-step: 10-561 -- Loss: 0.23523768782615662
train-epoch-step: 10-562 -- Loss: 0.21807806193828583
train-epoch-step: 10-563 -- Loss: 0.22117924690246582
train-epoch-step: 10-564 -- Loss: 0.12561152875423431
train-epoch-step: 10-565 -- Loss: 0.21110916137695312
train-epoch-step: 10-566 -- Loss: 0.19285482168197632
train-epoch-step: 10-567 -- Loss: 0.24655087292194366
train-epoch-step: 10-568 -- Loss: 0.18634991347789764
train-epoch-step: 10-569 -- Loss: 0.2671029269695282
train-epoch-step: 10-570 -- Loss: 0.2038344442844391
train-epoch-step: 10-571 -- Loss: 0.25507697463035583
train-epoch-step: 10-572 -- Loss: 0.29293927550315857
train-epoch-step: 10-573 -- Loss: 0.23853260278701782
train-epoch-step: 10-574 -- Loss: 0.2951936721801758
train-epoch-step: 10-575 -- Loss: 0.36561664938926697
train-epoch-step: 10-576 -- Loss: 0.1426573395729065
train-epoch-step: 10-577 -- Loss: 0.1999833732843399
train-epoch-step: 10-578 -- Loss: 0.26866957545280457
train-epoch-step: 10-579 -- Loss: 0.18748381733894348
train-epoch-step: 10-580 -- Loss: 0.21969608962535858
train-epoch-step: 10-581 -- Loss: 0.16091841459274292
train-epoch-step: 10-582 -- Loss: 0.25528931617736816
train-epoch-step: 10-583 -- Loss: 0.27094215154647827
train-epoch-step: 10-584 -- Loss: 0.2298361361026764
train-epoch-step: 10-585 -- Loss: 0.22262218594551086
train-epoch-step: 10-586 -- Loss: 0.3085176646709442
train-epoch-step: 10-587 -- Loss: 0.19127443432807922
train-epoch-step: 10-588 -- Loss: 0.14691492915153503
val-epoch-step: 10-589 -- Loss: 0.24417150020599365
val-epoch-step: 10-590 -- Loss: 0.17016108334064484
val-epoch-step: 10-591 -- Loss: 0.24539224803447723
val-epoch-step: 10-592 -- Loss: 0.20023566484451294
val-epoch-step: 10-593 -- Loss: 0.17214706540107727
val-epoch-step: 10-594 -- Loss: 0.3706008791923523
val-epoch-step: 10-595 -- Loss: 0.2070004940032959
val-epoch-step: 10-596 -- Loss: 0.24035309255123138
val-epoch-step: 10-597 -- Loss: 0.21120846271514893
val-epoch-step: 10-598 -- Loss: 0.1736413985490799
val-epoch-step: 10-599 -- Loss: 0.20913362503051758
val-epoch-step: 10-600 -- Loss: 0.19349578022956848
val-epoch-step: 10-601 -- Loss: 0.17442920804023743
val-epoch-step: 10-602 -- Loss: 0.15635031461715698
val-epoch-step: 10-603 -- Loss: 0.1966588795185089
val-epoch-step: 10-604 -- Loss: 0.16456246376037598
val-epoch-step: 10-605 -- Loss: 0.16851896047592163
val-epoch-step: 10-606 -- Loss: 0.29949215054512024
val-epoch-step: 10-607 -- Loss: 0.15247856080532074
val-epoch-step: 10-608 -- Loss: 0.28171244263648987
val-epoch-step: 10-609 -- Loss: 0.19431181252002716
val-epoch-step: 10-610 -- Loss: 0.21033558249473572
val-epoch-step: 10-611 -- Loss: 0.1870279610157013
val-epoch-step: 10-612 -- Loss: 0.38902997970581055
val-epoch-step: 10-613 -- Loss: 0.19941958785057068
val-epoch-step: 10-614 -- Loss: 0.18013715744018555
val-epoch-step: 10-615 -- Loss: 0.21375754475593567
val-epoch-step: 10-616 -- Loss: 0.17309734225273132
val-epoch-step: 10-617 -- Loss: 0.21458841860294342
val-epoch-step: 10-618 -- Loss: 0.22359246015548706
val-epoch-step: 10-619 -- Loss: 0.24861501157283783
val-epoch-step: 10-620 -- Loss: 0.16234219074249268
val-epoch-step: 10-621 -- Loss: 0.15966802835464478
val-epoch-step: 10-622 -- Loss: 0.16097930073738098
val-epoch-step: 10-623 -- Loss: 0.172994464635849
val-epoch-step: 10-624 -- Loss: 0.19449548423290253
val-epoch-step: 10-625 -- Loss: 0.17786958813667297
val-epoch-step: 10-626 -- Loss: 0.1658102124929428
val-epoch-step: 10-627 -- Loss: 0.2220596969127655
val-epoch-step: 10-628 -- Loss: 0.6184735298156738
val-epoch-step: 10-629 -- Loss: 0.22951528429985046
val-epoch-step: 10-630 -- Loss: 0.3869198262691498
val-epoch-step: 10-631 -- Loss: 0.16509000957012177
val-epoch-step: 10-632 -- Loss: 0.23280416429042816
val-epoch-step: 10-633 -- Loss: 0.17486447095870972
val-epoch-step: 10-634 -- Loss: 0.16247934103012085
val-epoch-step: 10-635 -- Loss: 0.13955754041671753
val-epoch-step: 10-636 -- Loss: 0.19290831685066223
val-epoch-step: 10-637 -- Loss: 0.2033221274614334
val-epoch-step: 10-638 -- Loss: 0.17527449131011963
val-epoch-step: 10-639 -- Loss: 0.30639857053756714
val-epoch-step: 10-640 -- Loss: 0.29249995946884155
val-epoch-step: 10-641 -- Loss: 0.14137138426303864
val-epoch-step: 10-642 -- Loss: 0.2160646766424179
val-epoch-step: 10-643 -- Loss: 0.22465762495994568
val-epoch-step: 10-644 -- Loss: 0.18290574848651886
val-epoch-step: 10-645 -- Loss: 0.2522984743118286
val-epoch-step: 10-646 -- Loss: 0.16207602620124817
val-epoch-step: 10-647 -- Loss: 0.15712383389472961
val-epoch-step: 10-648 -- Loss: 0.1847095638513565
val-epoch-step: 10-649 -- Loss: 0.249989852309227
val-epoch-step: 10-650 -- Loss: 0.2859894633293152
val-epoch-step: 10-651 -- Loss: 0.16609318554401398
val-epoch-step: 10-652 -- Loss: 0.18455347418785095
val-epoch-step: 10-653 -- Loss: 0.23257125914096832
val-epoch-step: 10-654 -- Loss: 0.13286668062210083
Epoch: 10 -- Train Loss: tensor(0.1538, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 46.03 -- Val Loss: tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 46.03
                         Test Loss: 0.0 -- Test Acc: 46.03
train-epoch-step: 11-0 -- Loss: 0.2599647045135498
train-epoch-step: 11-1 -- Loss: 0.1632101684808731
train-epoch-step: 11-2 -- Loss: 0.2320019006729126
train-epoch-step: 11-3 -- Loss: 0.17298710346221924
train-epoch-step: 11-4 -- Loss: 0.2166084498167038
train-epoch-step: 11-5 -- Loss: 0.22465120255947113
train-epoch-step: 11-6 -- Loss: 0.2629431486129761
train-epoch-step: 11-7 -- Loss: 0.1933617889881134
train-epoch-step: 11-8 -- Loss: 0.2257009893655777
train-epoch-step: 11-9 -- Loss: 0.3141064941883087
train-epoch-step: 11-10 -- Loss: 0.273040235042572
train-epoch-step: 11-11 -- Loss: 0.2067941427230835
train-epoch-step: 11-12 -- Loss: 0.18295399844646454
train-epoch-step: 11-13 -- Loss: 0.21291260421276093
train-epoch-step: 11-14 -- Loss: 0.183828204870224
train-epoch-step: 11-15 -- Loss: 0.18651042878627777
train-epoch-step: 11-16 -- Loss: 0.1859603226184845
train-epoch-step: 11-17 -- Loss: 0.24807016551494598
train-epoch-step: 11-18 -- Loss: 0.22558867931365967
train-epoch-step: 11-19 -- Loss: 0.15116748213768005
train-epoch-step: 11-20 -- Loss: 0.2609722316265106
train-epoch-step: 11-21 -- Loss: 0.38547295331954956
train-epoch-step: 11-22 -- Loss: 0.17020538449287415
train-epoch-step: 11-23 -- Loss: 0.21960745751857758
train-epoch-step: 11-24 -- Loss: 0.15468880534172058
train-epoch-step: 11-25 -- Loss: 0.26686060428619385
train-epoch-step: 11-26 -- Loss: 0.23583552241325378
train-epoch-step: 11-27 -- Loss: 0.30407965183258057
train-epoch-step: 11-28 -- Loss: 0.1445993185043335
train-epoch-step: 11-29 -- Loss: 0.2798674702644348
train-epoch-step: 11-30 -- Loss: 0.12819534540176392
train-epoch-step: 11-31 -- Loss: 0.16813138127326965
train-epoch-step: 11-32 -- Loss: 0.1952725052833557
train-epoch-step: 11-33 -- Loss: 0.3048431873321533
train-epoch-step: 11-34 -- Loss: 0.1976442039012909
train-epoch-step: 11-35 -- Loss: 0.29181107878685
train-epoch-step: 11-36 -- Loss: 0.16377928853034973
train-epoch-step: 11-37 -- Loss: 0.16592706739902496
train-epoch-step: 11-38 -- Loss: 0.22488483786582947
train-epoch-step: 11-39 -- Loss: 0.2786876857280731
train-epoch-step: 11-40 -- Loss: 0.24347026646137238
train-epoch-step: 11-41 -- Loss: 0.25024381279945374
train-epoch-step: 11-42 -- Loss: 0.16878122091293335
train-epoch-step: 11-43 -- Loss: 0.32178592681884766
train-epoch-step: 11-44 -- Loss: 0.14284582436084747
train-epoch-step: 11-45 -- Loss: 0.1485242247581482
train-epoch-step: 11-46 -- Loss: 0.21864840388298035
train-epoch-step: 11-47 -- Loss: 0.280892550945282
train-epoch-step: 11-48 -- Loss: 0.1754559576511383
train-epoch-step: 11-49 -- Loss: 0.2442883551120758
train-epoch-step: 11-50 -- Loss: 0.14091208577156067
train-epoch-step: 11-51 -- Loss: 0.22972741723060608
train-epoch-step: 11-52 -- Loss: 0.18110892176628113
train-epoch-step: 11-53 -- Loss: 0.2640915513038635
train-epoch-step: 11-54 -- Loss: 0.33730348944664
train-epoch-step: 11-55 -- Loss: 0.2059839367866516
train-epoch-step: 11-56 -- Loss: 0.21165060997009277
train-epoch-step: 11-57 -- Loss: 0.2689959406852722
train-epoch-step: 11-58 -- Loss: 0.31120651960372925
train-epoch-step: 11-59 -- Loss: 0.3148772120475769
train-epoch-step: 11-60 -- Loss: 0.15218307077884674
train-epoch-step: 11-61 -- Loss: 0.24901020526885986
train-epoch-step: 11-62 -- Loss: 0.21332518756389618
train-epoch-step: 11-63 -- Loss: 0.1613469123840332
train-epoch-step: 11-64 -- Loss: 0.1745479553937912
train-epoch-step: 11-65 -- Loss: 0.21809764206409454
train-epoch-step: 11-66 -- Loss: 0.12823215126991272
train-epoch-step: 11-67 -- Loss: 0.14412149786949158
train-epoch-step: 11-68 -- Loss: 0.26391658186912537
train-epoch-step: 11-69 -- Loss: 0.14965738356113434
train-epoch-step: 11-70 -- Loss: 0.2473522424697876
train-epoch-step: 11-71 -- Loss: 0.29137861728668213
train-epoch-step: 11-72 -- Loss: 0.2100815623998642
train-epoch-step: 11-73 -- Loss: 0.2378465086221695
train-epoch-step: 11-74 -- Loss: 0.11727668344974518
train-epoch-step: 11-75 -- Loss: 0.1535874903202057
train-epoch-step: 11-76 -- Loss: 0.17186781764030457
train-epoch-step: 11-77 -- Loss: 0.2598854899406433
train-epoch-step: 11-78 -- Loss: 0.31766757369041443
train-epoch-step: 11-79 -- Loss: 0.22373881936073303
train-epoch-step: 11-80 -- Loss: 0.3155900835990906
train-epoch-step: 11-81 -- Loss: 0.14231222867965698
train-epoch-step: 11-82 -- Loss: 0.2877286672592163
train-epoch-step: 11-83 -- Loss: 0.22524335980415344
train-epoch-step: 11-84 -- Loss: 0.23237955570220947
train-epoch-step: 11-85 -- Loss: 0.20260781049728394
train-epoch-step: 11-86 -- Loss: 0.14798936247825623
train-epoch-step: 11-87 -- Loss: 0.270700067281723
train-epoch-step: 11-88 -- Loss: 0.16267752647399902
train-epoch-step: 11-89 -- Loss: 0.22328032553195953
train-epoch-step: 11-90 -- Loss: 0.22726209461688995
train-epoch-step: 11-91 -- Loss: 0.2789071500301361
train-epoch-step: 11-92 -- Loss: 0.17890119552612305
train-epoch-step: 11-93 -- Loss: 0.21190008521080017
train-epoch-step: 11-94 -- Loss: 0.2659011781215668
train-epoch-step: 11-95 -- Loss: 0.2318442165851593
train-epoch-step: 11-96 -- Loss: 0.2597365975379944
train-epoch-step: 11-97 -- Loss: 0.2031869888305664
train-epoch-step: 11-98 -- Loss: 0.17429161071777344
train-epoch-step: 11-99 -- Loss: 0.21457251906394958
train-epoch-step: 11-100 -- Loss: 0.21808099746704102
train-epoch-step: 11-101 -- Loss: 0.3148971498012543
train-epoch-step: 11-102 -- Loss: 0.26728910207748413
train-epoch-step: 11-103 -- Loss: 0.22247061133384705
train-epoch-step: 11-104 -- Loss: 0.17292512953281403
train-epoch-step: 11-105 -- Loss: 0.32005298137664795
train-epoch-step: 11-106 -- Loss: 0.21012800931930542
train-epoch-step: 11-107 -- Loss: 0.21821556985378265
train-epoch-step: 11-108 -- Loss: 0.21034342050552368
train-epoch-step: 11-109 -- Loss: 0.1706433892250061
train-epoch-step: 11-110 -- Loss: 0.2130734771490097
train-epoch-step: 11-111 -- Loss: 0.20896562933921814
train-epoch-step: 11-112 -- Loss: 0.1994524449110031
train-epoch-step: 11-113 -- Loss: 0.18933631479740143
train-epoch-step: 11-114 -- Loss: 0.25841426849365234
train-epoch-step: 11-115 -- Loss: 0.2024793028831482
train-epoch-step: 11-116 -- Loss: 0.17738522589206696
train-epoch-step: 11-117 -- Loss: 0.14944037795066833
train-epoch-step: 11-118 -- Loss: 0.2322561889886856
train-epoch-step: 11-119 -- Loss: 0.17671670019626617
train-epoch-step: 11-120 -- Loss: 0.3158900737762451
train-epoch-step: 11-121 -- Loss: 0.3278632164001465
train-epoch-step: 11-122 -- Loss: 0.2449069768190384
train-epoch-step: 11-123 -- Loss: 0.24774053692817688
train-epoch-step: 11-124 -- Loss: 0.14144103229045868
train-epoch-step: 11-125 -- Loss: 0.17722827196121216
train-epoch-step: 11-126 -- Loss: 0.27175503969192505
train-epoch-step: 11-127 -- Loss: 0.2069646418094635
train-epoch-step: 11-128 -- Loss: 0.19635596871376038
train-epoch-step: 11-129 -- Loss: 0.16545015573501587
train-epoch-step: 11-130 -- Loss: 0.22376962006092072
train-epoch-step: 11-131 -- Loss: 0.1615637242794037
train-epoch-step: 11-132 -- Loss: 0.23810887336730957
train-epoch-step: 11-133 -- Loss: 0.13782081007957458
train-epoch-step: 11-134 -- Loss: 0.23148822784423828
train-epoch-step: 11-135 -- Loss: 0.16084349155426025
train-epoch-step: 11-136 -- Loss: 0.15167059004306793
train-epoch-step: 11-137 -- Loss: 0.29870572686195374
train-epoch-step: 11-138 -- Loss: 0.3080104887485504
train-epoch-step: 11-139 -- Loss: 0.151204451918602
train-epoch-step: 11-140 -- Loss: 0.23654615879058838
train-epoch-step: 11-141 -- Loss: 0.2772831320762634
train-epoch-step: 11-142 -- Loss: 0.23643139004707336
train-epoch-step: 11-143 -- Loss: 0.19889456033706665
train-epoch-step: 11-144 -- Loss: 0.21401062607765198
train-epoch-step: 11-145 -- Loss: 0.16164985299110413
train-epoch-step: 11-146 -- Loss: 0.2063647210597992
train-epoch-step: 11-147 -- Loss: 0.207275390625
train-epoch-step: 11-148 -- Loss: 0.20134946703910828
train-epoch-step: 11-149 -- Loss: 0.13805939257144928
train-epoch-step: 11-150 -- Loss: 0.2160891592502594
train-epoch-step: 11-151 -- Loss: 0.2161259651184082
train-epoch-step: 11-152 -- Loss: 0.23363295197486877
train-epoch-step: 11-153 -- Loss: 0.3411709666252136
train-epoch-step: 11-154 -- Loss: 0.15312057733535767
train-epoch-step: 11-155 -- Loss: 0.16245797276496887
train-epoch-step: 11-156 -- Loss: 0.14565010368824005
train-epoch-step: 11-157 -- Loss: 0.1914488971233368
train-epoch-step: 11-158 -- Loss: 0.19379399716854095
train-epoch-step: 11-159 -- Loss: 0.20574674010276794
train-epoch-step: 11-160 -- Loss: 0.27879467606544495
train-epoch-step: 11-161 -- Loss: 0.2387028932571411
train-epoch-step: 11-162 -- Loss: 0.24281951785087585
train-epoch-step: 11-163 -- Loss: 0.21079203486442566
train-epoch-step: 11-164 -- Loss: 0.2165791094303131
train-epoch-step: 11-165 -- Loss: 0.19206102192401886
train-epoch-step: 11-166 -- Loss: 0.1416192501783371
train-epoch-step: 11-167 -- Loss: 0.14213700592517853
train-epoch-step: 11-168 -- Loss: 0.24078801274299622
train-epoch-step: 11-169 -- Loss: 0.16314223408699036
train-epoch-step: 11-170 -- Loss: 0.22968348860740662
train-epoch-step: 11-171 -- Loss: 0.15823718905448914
train-epoch-step: 11-172 -- Loss: 0.2991362512111664
train-epoch-step: 11-173 -- Loss: 0.14758409559726715
train-epoch-step: 11-174 -- Loss: 0.2724306285381317
train-epoch-step: 11-175 -- Loss: 0.20506660640239716
train-epoch-step: 11-176 -- Loss: 0.1569514274597168
train-epoch-step: 11-177 -- Loss: 0.2173270583152771
train-epoch-step: 11-178 -- Loss: 0.21739184856414795
train-epoch-step: 11-179 -- Loss: 0.17026782035827637
train-epoch-step: 11-180 -- Loss: 0.171046644449234
train-epoch-step: 11-181 -- Loss: 0.19497333467006683
train-epoch-step: 11-182 -- Loss: 0.2263660430908203
train-epoch-step: 11-183 -- Loss: 0.3085678517818451
train-epoch-step: 11-184 -- Loss: 0.1638665497303009
train-epoch-step: 11-185 -- Loss: 0.16953787207603455
train-epoch-step: 11-186 -- Loss: 0.2233598232269287
train-epoch-step: 11-187 -- Loss: 0.2432805299758911
train-epoch-step: 11-188 -- Loss: 0.20007798075675964
train-epoch-step: 11-189 -- Loss: 0.14404159784317017
train-epoch-step: 11-190 -- Loss: 0.20722529292106628
train-epoch-step: 11-191 -- Loss: 0.2071067988872528
train-epoch-step: 11-192 -- Loss: 0.28289365768432617
train-epoch-step: 11-193 -- Loss: 0.25295621156692505
train-epoch-step: 11-194 -- Loss: 0.20232313871383667
train-epoch-step: 11-195 -- Loss: 0.18668104708194733
train-epoch-step: 11-196 -- Loss: 0.21613723039627075
train-epoch-step: 11-197 -- Loss: 0.1612919569015503
train-epoch-step: 11-198 -- Loss: 0.1580047756433487
train-epoch-step: 11-199 -- Loss: 0.1745888590812683
train-epoch-step: 11-200 -- Loss: 0.14112329483032227
train-epoch-step: 11-201 -- Loss: 0.2405673861503601
train-epoch-step: 11-202 -- Loss: 0.15743859112262726
train-epoch-step: 11-203 -- Loss: 0.20107698440551758
train-epoch-step: 11-204 -- Loss: 0.17098531126976013
train-epoch-step: 11-205 -- Loss: 0.22055134177207947
train-epoch-step: 11-206 -- Loss: 0.2342659831047058
train-epoch-step: 11-207 -- Loss: 0.15847724676132202
train-epoch-step: 11-208 -- Loss: 0.20674820244312286
train-epoch-step: 11-209 -- Loss: 0.15562546253204346
train-epoch-step: 11-210 -- Loss: 0.15790288150310516
train-epoch-step: 11-211 -- Loss: 0.24160432815551758
train-epoch-step: 11-212 -- Loss: 0.22644956409931183
train-epoch-step: 11-213 -- Loss: 0.1424441784620285
train-epoch-step: 11-214 -- Loss: 0.169205904006958
train-epoch-step: 11-215 -- Loss: 0.15583720803260803
train-epoch-step: 11-216 -- Loss: 0.22641488909721375
train-epoch-step: 11-217 -- Loss: 0.24052856862545013
train-epoch-step: 11-218 -- Loss: 0.17274844646453857
train-epoch-step: 11-219 -- Loss: 0.2217048555612564
train-epoch-step: 11-220 -- Loss: 0.15371403098106384
train-epoch-step: 11-221 -- Loss: 0.23305743932724
train-epoch-step: 11-222 -- Loss: 0.13715693354606628
train-epoch-step: 11-223 -- Loss: 0.19927741587162018
train-epoch-step: 11-224 -- Loss: 0.2287190556526184
train-epoch-step: 11-225 -- Loss: 0.33767539262771606
train-epoch-step: 11-226 -- Loss: 0.24932034313678741
train-epoch-step: 11-227 -- Loss: 0.2824508547782898
train-epoch-step: 11-228 -- Loss: 0.20343846082687378
train-epoch-step: 11-229 -- Loss: 0.20463785529136658
train-epoch-step: 11-230 -- Loss: 0.18877357244491577
train-epoch-step: 11-231 -- Loss: 0.19956614077091217
train-epoch-step: 11-232 -- Loss: 0.23087060451507568
train-epoch-step: 11-233 -- Loss: 0.09566835314035416
train-epoch-step: 11-234 -- Loss: 0.2118188738822937
train-epoch-step: 11-235 -- Loss: 0.18352872133255005
train-epoch-step: 11-236 -- Loss: 0.20090237259864807
train-epoch-step: 11-237 -- Loss: 0.27935174107551575
train-epoch-step: 11-238 -- Loss: 0.17779356241226196
train-epoch-step: 11-239 -- Loss: 0.15628370642662048
train-epoch-step: 11-240 -- Loss: 0.2473941594362259
train-epoch-step: 11-241 -- Loss: 0.1845487654209137
train-epoch-step: 11-242 -- Loss: 0.252053439617157
train-epoch-step: 11-243 -- Loss: 0.25976186990737915
train-epoch-step: 11-244 -- Loss: 0.23593741655349731
train-epoch-step: 11-245 -- Loss: 0.2650623321533203
train-epoch-step: 11-246 -- Loss: 0.295996755361557
train-epoch-step: 11-247 -- Loss: 0.27701136469841003
train-epoch-step: 11-248 -- Loss: 0.21712704002857208
train-epoch-step: 11-249 -- Loss: 0.17181390523910522
train-epoch-step: 11-250 -- Loss: 0.23089370131492615
train-epoch-step: 11-251 -- Loss: 0.12733814120292664
train-epoch-step: 11-252 -- Loss: 0.22045448422431946
train-epoch-step: 11-253 -- Loss: 0.16383838653564453
train-epoch-step: 11-254 -- Loss: 0.2688729763031006
train-epoch-step: 11-255 -- Loss: 0.17364314198493958
train-epoch-step: 11-256 -- Loss: 0.18589439988136292
train-epoch-step: 11-257 -- Loss: 0.22625887393951416
train-epoch-step: 11-258 -- Loss: 0.17229020595550537
train-epoch-step: 11-259 -- Loss: 0.14280879497528076
train-epoch-step: 11-260 -- Loss: 0.24381302297115326
train-epoch-step: 11-261 -- Loss: 0.20693498849868774
train-epoch-step: 11-262 -- Loss: 0.35734909772872925
train-epoch-step: 11-263 -- Loss: 0.23449361324310303
train-epoch-step: 11-264 -- Loss: 0.19628138840198517
train-epoch-step: 11-265 -- Loss: 0.13790187239646912
train-epoch-step: 11-266 -- Loss: 0.1671103537082672
train-epoch-step: 11-267 -- Loss: 0.16279679536819458
train-epoch-step: 11-268 -- Loss: 0.13835880160331726
train-epoch-step: 11-269 -- Loss: 0.19938868284225464
train-epoch-step: 11-270 -- Loss: 0.1306893229484558
train-epoch-step: 11-271 -- Loss: 0.17574715614318848
train-epoch-step: 11-272 -- Loss: 0.13627088069915771
train-epoch-step: 11-273 -- Loss: 0.1512240171432495
train-epoch-step: 11-274 -- Loss: 0.2140529453754425
train-epoch-step: 11-275 -- Loss: 0.2323424220085144
train-epoch-step: 11-276 -- Loss: 0.18261070549488068
train-epoch-step: 11-277 -- Loss: 0.1744898110628128
train-epoch-step: 11-278 -- Loss: 0.17065195739269257
train-epoch-step: 11-279 -- Loss: 0.17089948058128357
train-epoch-step: 11-280 -- Loss: 0.24489659070968628
train-epoch-step: 11-281 -- Loss: 0.21638619899749756
train-epoch-step: 11-282 -- Loss: 0.16247285902500153
train-epoch-step: 11-283 -- Loss: 0.13834181427955627
train-epoch-step: 11-284 -- Loss: 0.24190743267536163
train-epoch-step: 11-285 -- Loss: 0.2186359167098999
train-epoch-step: 11-286 -- Loss: 0.18346309661865234
train-epoch-step: 11-287 -- Loss: 0.24128904938697815
train-epoch-step: 11-288 -- Loss: 0.10989728569984436
train-epoch-step: 11-289 -- Loss: 0.1540154218673706
train-epoch-step: 11-290 -- Loss: 0.21733929216861725
train-epoch-step: 11-291 -- Loss: 0.13240975141525269
train-epoch-step: 11-292 -- Loss: 0.1789076030254364
train-epoch-step: 11-293 -- Loss: 0.16018930077552795
train-epoch-step: 11-294 -- Loss: 0.194091796875
train-epoch-step: 11-295 -- Loss: 0.33156347274780273
train-epoch-step: 11-296 -- Loss: 0.20521952211856842
train-epoch-step: 11-297 -- Loss: 0.19657830893993378
train-epoch-step: 11-298 -- Loss: 0.28330254554748535
train-epoch-step: 11-299 -- Loss: 0.18601086735725403
train-epoch-step: 11-300 -- Loss: 0.20163407921791077
train-epoch-step: 11-301 -- Loss: 0.19484326243400574
train-epoch-step: 11-302 -- Loss: 0.2579975426197052
train-epoch-step: 11-303 -- Loss: 0.23908613622188568
train-epoch-step: 11-304 -- Loss: 0.16989970207214355
train-epoch-step: 11-305 -- Loss: 0.16564880311489105
train-epoch-step: 11-306 -- Loss: 0.29414239525794983
train-epoch-step: 11-307 -- Loss: 0.1939031332731247
train-epoch-step: 11-308 -- Loss: 0.2736700773239136
train-epoch-step: 11-309 -- Loss: 0.17917296290397644
train-epoch-step: 11-310 -- Loss: 0.191933736205101
train-epoch-step: 11-311 -- Loss: 0.18833574652671814
train-epoch-step: 11-312 -- Loss: 0.24333727359771729
train-epoch-step: 11-313 -- Loss: 0.11956294625997543
train-epoch-step: 11-314 -- Loss: 0.23993375897407532
train-epoch-step: 11-315 -- Loss: 0.19123747944831848
train-epoch-step: 11-316 -- Loss: 0.17556223273277283
train-epoch-step: 11-317 -- Loss: 0.17114540934562683
train-epoch-step: 11-318 -- Loss: 0.19145521521568298
train-epoch-step: 11-319 -- Loss: 0.21344634890556335
train-epoch-step: 11-320 -- Loss: 0.13880057632923126
train-epoch-step: 11-321 -- Loss: 0.15579406917095184
train-epoch-step: 11-322 -- Loss: 0.241256445646286
train-epoch-step: 11-323 -- Loss: 0.18488767743110657
train-epoch-step: 11-324 -- Loss: 0.3096826374530792
train-epoch-step: 11-325 -- Loss: 0.17372769117355347
train-epoch-step: 11-326 -- Loss: 0.20221027731895447
train-epoch-step: 11-327 -- Loss: 0.24801543354988098
train-epoch-step: 11-328 -- Loss: 0.22194364666938782
train-epoch-step: 11-329 -- Loss: 0.3647691607475281
train-epoch-step: 11-330 -- Loss: 0.40533995628356934
train-epoch-step: 11-331 -- Loss: 0.25548645853996277
train-epoch-step: 11-332 -- Loss: 0.12610751390457153
train-epoch-step: 11-333 -- Loss: 0.21829688549041748
train-epoch-step: 11-334 -- Loss: 0.17944802343845367
train-epoch-step: 11-335 -- Loss: 0.200175940990448
train-epoch-step: 11-336 -- Loss: 0.19164076447486877
train-epoch-step: 11-337 -- Loss: 0.25065702199935913
train-epoch-step: 11-338 -- Loss: 0.18801599740982056
train-epoch-step: 11-339 -- Loss: 0.16941630840301514
train-epoch-step: 11-340 -- Loss: 0.22750425338745117
train-epoch-step: 11-341 -- Loss: 0.16357958316802979
train-epoch-step: 11-342 -- Loss: 0.19518810510635376
train-epoch-step: 11-343 -- Loss: 0.18600332736968994
train-epoch-step: 11-344 -- Loss: 0.19914445281028748
train-epoch-step: 11-345 -- Loss: 0.1430952399969101
train-epoch-step: 11-346 -- Loss: 0.22571077942848206
train-epoch-step: 11-347 -- Loss: 0.17855241894721985
train-epoch-step: 11-348 -- Loss: 0.23530122637748718
train-epoch-step: 11-349 -- Loss: 0.25256532430648804
train-epoch-step: 11-350 -- Loss: 0.3177555203437805
train-epoch-step: 11-351 -- Loss: 0.23282530903816223
train-epoch-step: 11-352 -- Loss: 0.1580289602279663
train-epoch-step: 11-353 -- Loss: 0.2245110422372818
train-epoch-step: 11-354 -- Loss: 0.319680392742157
train-epoch-step: 11-355 -- Loss: 0.14004255831241608
train-epoch-step: 11-356 -- Loss: 0.1323847770690918
train-epoch-step: 11-357 -- Loss: 0.21850797533988953
train-epoch-step: 11-358 -- Loss: 0.2177540361881256
train-epoch-step: 11-359 -- Loss: 0.16307803988456726
train-epoch-step: 11-360 -- Loss: 0.13718469440937042
train-epoch-step: 11-361 -- Loss: 0.297689288854599
train-epoch-step: 11-362 -- Loss: 0.19773945212364197
train-epoch-step: 11-363 -- Loss: 0.1358862966299057
train-epoch-step: 11-364 -- Loss: 0.21762582659721375
train-epoch-step: 11-365 -- Loss: 0.2060466706752777
train-epoch-step: 11-366 -- Loss: 0.23143219947814941
train-epoch-step: 11-367 -- Loss: 0.30989181995391846
train-epoch-step: 11-368 -- Loss: 0.2482820749282837
train-epoch-step: 11-369 -- Loss: 0.3163618743419647
train-epoch-step: 11-370 -- Loss: 0.14724889397621155
train-epoch-step: 11-371 -- Loss: 0.1334315836429596
train-epoch-step: 11-372 -- Loss: 0.16747432947158813
train-epoch-step: 11-373 -- Loss: 0.2304588407278061
train-epoch-step: 11-374 -- Loss: 0.1772419512271881
train-epoch-step: 11-375 -- Loss: 0.3256862759590149
train-epoch-step: 11-376 -- Loss: 0.2343965619802475
train-epoch-step: 11-377 -- Loss: 0.27306699752807617
train-epoch-step: 11-378 -- Loss: 0.2534012198448181
train-epoch-step: 11-379 -- Loss: 0.13837051391601562
train-epoch-step: 11-380 -- Loss: 0.10424917191267014
train-epoch-step: 11-381 -- Loss: 0.28807270526885986
train-epoch-step: 11-382 -- Loss: 0.26359105110168457
train-epoch-step: 11-383 -- Loss: 0.20261891186237335
train-epoch-step: 11-384 -- Loss: 0.2585841715335846
train-epoch-step: 11-385 -- Loss: 0.23595066368579865
train-epoch-step: 11-386 -- Loss: 0.21965911984443665
train-epoch-step: 11-387 -- Loss: 0.23207257688045502
train-epoch-step: 11-388 -- Loss: 0.263653039932251
train-epoch-step: 11-389 -- Loss: 0.20455367863178253
train-epoch-step: 11-390 -- Loss: 0.15922442078590393
train-epoch-step: 11-391 -- Loss: 0.16699571907520294
train-epoch-step: 11-392 -- Loss: 0.20858687162399292
train-epoch-step: 11-393 -- Loss: 0.18864354491233826
train-epoch-step: 11-394 -- Loss: 0.25146305561065674
train-epoch-step: 11-395 -- Loss: 0.18655870854854584
train-epoch-step: 11-396 -- Loss: 0.15047314763069153
train-epoch-step: 11-397 -- Loss: 0.14546647667884827
train-epoch-step: 11-398 -- Loss: 0.22706934809684753
train-epoch-step: 11-399 -- Loss: 0.21088337898254395
train-epoch-step: 11-400 -- Loss: 0.33466532826423645
train-epoch-step: 11-401 -- Loss: 0.13812953233718872
train-epoch-step: 11-402 -- Loss: 0.2934761643409729
train-epoch-step: 11-403 -- Loss: 0.18711593747138977
train-epoch-step: 11-404 -- Loss: 0.16965675354003906
train-epoch-step: 11-405 -- Loss: 0.17102740705013275
train-epoch-step: 11-406 -- Loss: 0.1963289976119995
train-epoch-step: 11-407 -- Loss: 0.13086630403995514
train-epoch-step: 11-408 -- Loss: 0.18823003768920898
train-epoch-step: 11-409 -- Loss: 0.20945152640342712
train-epoch-step: 11-410 -- Loss: 0.2130698263645172
train-epoch-step: 11-411 -- Loss: 0.22537167370319366
train-epoch-step: 11-412 -- Loss: 0.14530813694000244
train-epoch-step: 11-413 -- Loss: 0.1739453673362732
train-epoch-step: 11-414 -- Loss: 0.15787500143051147
train-epoch-step: 11-415 -- Loss: 0.16310611367225647
train-epoch-step: 11-416 -- Loss: 0.298758864402771
train-epoch-step: 11-417 -- Loss: 0.23242659866809845
train-epoch-step: 11-418 -- Loss: 0.2792086601257324
train-epoch-step: 11-419 -- Loss: 0.18966642022132874
train-epoch-step: 11-420 -- Loss: 0.1798166185617447
train-epoch-step: 11-421 -- Loss: 0.2042890191078186
train-epoch-step: 11-422 -- Loss: 0.1724054217338562
train-epoch-step: 11-423 -- Loss: 0.2068178355693817
train-epoch-step: 11-424 -- Loss: 0.15654616057872772
train-epoch-step: 11-425 -- Loss: 0.20834994316101074
train-epoch-step: 11-426 -- Loss: 0.18889862298965454
train-epoch-step: 11-427 -- Loss: 0.164486825466156
train-epoch-step: 11-428 -- Loss: 0.22851058840751648
train-epoch-step: 11-429 -- Loss: 0.19180889427661896
train-epoch-step: 11-430 -- Loss: 0.17901068925857544
train-epoch-step: 11-431 -- Loss: 0.18937692046165466
train-epoch-step: 11-432 -- Loss: 0.2690046429634094
train-epoch-step: 11-433 -- Loss: 0.15452201664447784
train-epoch-step: 11-434 -- Loss: 0.14872294664382935
train-epoch-step: 11-435 -- Loss: 0.1891082227230072
train-epoch-step: 11-436 -- Loss: 0.17895063757896423
train-epoch-step: 11-437 -- Loss: 0.15655630826950073
train-epoch-step: 11-438 -- Loss: 0.20257408916950226
train-epoch-step: 11-439 -- Loss: 0.30683964490890503
train-epoch-step: 11-440 -- Loss: 0.15128499269485474
train-epoch-step: 11-441 -- Loss: 0.25203996896743774
train-epoch-step: 11-442 -- Loss: 0.2216418981552124
train-epoch-step: 11-443 -- Loss: 0.1812838613986969
train-epoch-step: 11-444 -- Loss: 0.23873327672481537
train-epoch-step: 11-445 -- Loss: 0.19942215085029602
train-epoch-step: 11-446 -- Loss: 0.1754486858844757
train-epoch-step: 11-447 -- Loss: 0.23601004481315613
train-epoch-step: 11-448 -- Loss: 0.28971752524375916
train-epoch-step: 11-449 -- Loss: 0.22321733832359314
train-epoch-step: 11-450 -- Loss: 0.22227606177330017
train-epoch-step: 11-451 -- Loss: 0.16586828231811523
train-epoch-step: 11-452 -- Loss: 0.15251117944717407
train-epoch-step: 11-453 -- Loss: 0.10932202637195587
train-epoch-step: 11-454 -- Loss: 0.2850155532360077
train-epoch-step: 11-455 -- Loss: 0.14896835386753082
train-epoch-step: 11-456 -- Loss: 0.13478153944015503
train-epoch-step: 11-457 -- Loss: 0.24396385252475739
train-epoch-step: 11-458 -- Loss: 0.169712096452713
train-epoch-step: 11-459 -- Loss: 0.25303083658218384
train-epoch-step: 11-460 -- Loss: 0.14090979099273682
train-epoch-step: 11-461 -- Loss: 0.15897098183631897
train-epoch-step: 11-462 -- Loss: 0.17874912917613983
train-epoch-step: 11-463 -- Loss: 0.15337595343589783
train-epoch-step: 11-464 -- Loss: 0.1947512924671173
train-epoch-step: 11-465 -- Loss: 0.28491997718811035
train-epoch-step: 11-466 -- Loss: 0.22410275042057037
train-epoch-step: 11-467 -- Loss: 0.13245633244514465
train-epoch-step: 11-468 -- Loss: 0.2242419421672821
train-epoch-step: 11-469 -- Loss: 0.28030556440353394
train-epoch-step: 11-470 -- Loss: 0.20575383305549622
train-epoch-step: 11-471 -- Loss: 0.1725861132144928
train-epoch-step: 11-472 -- Loss: 0.17912578582763672
train-epoch-step: 11-473 -- Loss: 0.20571213960647583
train-epoch-step: 11-474 -- Loss: 0.1412729173898697
train-epoch-step: 11-475 -- Loss: 0.1298704445362091
train-epoch-step: 11-476 -- Loss: 0.22385168075561523
train-epoch-step: 11-477 -- Loss: 0.2538944482803345
train-epoch-step: 11-478 -- Loss: 0.21799521148204803
train-epoch-step: 11-479 -- Loss: 0.16104568541049957
train-epoch-step: 11-480 -- Loss: 0.2186880260705948
train-epoch-step: 11-481 -- Loss: 0.30698227882385254
train-epoch-step: 11-482 -- Loss: 0.28644779324531555
train-epoch-step: 11-483 -- Loss: 0.2202264815568924
train-epoch-step: 11-484 -- Loss: 0.22672611474990845
train-epoch-step: 11-485 -- Loss: 0.15015548467636108
train-epoch-step: 11-486 -- Loss: 0.2958120107650757
train-epoch-step: 11-487 -- Loss: 0.2556178867816925
train-epoch-step: 11-488 -- Loss: 0.20946089923381805
train-epoch-step: 11-489 -- Loss: 0.24826990067958832
train-epoch-step: 11-490 -- Loss: 0.1575625091791153
train-epoch-step: 11-491 -- Loss: 0.15958288311958313
train-epoch-step: 11-492 -- Loss: 0.13820810616016388
train-epoch-step: 11-493 -- Loss: 0.25670647621154785
train-epoch-step: 11-494 -- Loss: 0.2449527084827423
train-epoch-step: 11-495 -- Loss: 0.23229971528053284
train-epoch-step: 11-496 -- Loss: 0.15485472977161407
train-epoch-step: 11-497 -- Loss: 0.20448043942451477
train-epoch-step: 11-498 -- Loss: 0.16710886359214783
train-epoch-step: 11-499 -- Loss: 0.1975094974040985
train-epoch-step: 11-500 -- Loss: 0.18063268065452576
train-epoch-step: 11-501 -- Loss: 0.24747797846794128
train-epoch-step: 11-502 -- Loss: 0.1843489408493042
train-epoch-step: 11-503 -- Loss: 0.24896195530891418
train-epoch-step: 11-504 -- Loss: 0.1401175558567047
train-epoch-step: 11-505 -- Loss: 0.20040559768676758
train-epoch-step: 11-506 -- Loss: 0.13956774771213531
train-epoch-step: 11-507 -- Loss: 0.2058732956647873
train-epoch-step: 11-508 -- Loss: 0.19921095669269562
train-epoch-step: 11-509 -- Loss: 0.1913786232471466
train-epoch-step: 11-510 -- Loss: 0.14152447879314423
train-epoch-step: 11-511 -- Loss: 0.24827896058559418
train-epoch-step: 11-512 -- Loss: 0.19870753586292267
train-epoch-step: 11-513 -- Loss: 0.24206148087978363
train-epoch-step: 11-514 -- Loss: 0.17095206677913666
train-epoch-step: 11-515 -- Loss: 0.1902024745941162
train-epoch-step: 11-516 -- Loss: 0.1977233588695526
train-epoch-step: 11-517 -- Loss: 0.2050454020500183
train-epoch-step: 11-518 -- Loss: 0.1565876454114914
train-epoch-step: 11-519 -- Loss: 0.15283559262752533
train-epoch-step: 11-520 -- Loss: 0.212862029671669
train-epoch-step: 11-521 -- Loss: 0.25452372431755066
train-epoch-step: 11-522 -- Loss: 0.20962676405906677
train-epoch-step: 11-523 -- Loss: 0.17630285024642944
train-epoch-step: 11-524 -- Loss: 0.19075095653533936
train-epoch-step: 11-525 -- Loss: 0.21135126054286957
train-epoch-step: 11-526 -- Loss: 0.147450253367424
train-epoch-step: 11-527 -- Loss: 0.17498812079429626
train-epoch-step: 11-528 -- Loss: 0.18157827854156494
train-epoch-step: 11-529 -- Loss: 0.20138609409332275
train-epoch-step: 11-530 -- Loss: 0.19527599215507507
train-epoch-step: 11-531 -- Loss: 0.23604363203048706
train-epoch-step: 11-532 -- Loss: 0.19286635518074036
train-epoch-step: 11-533 -- Loss: 0.188416987657547
train-epoch-step: 11-534 -- Loss: 0.15415914356708527
train-epoch-step: 11-535 -- Loss: 0.30737215280532837
train-epoch-step: 11-536 -- Loss: 0.17437182366847992
train-epoch-step: 11-537 -- Loss: 0.17049165070056915
train-epoch-step: 11-538 -- Loss: 0.11492930352687836
train-epoch-step: 11-539 -- Loss: 0.2282862365245819
train-epoch-step: 11-540 -- Loss: 0.15794195234775543
train-epoch-step: 11-541 -- Loss: 0.23631170392036438
train-epoch-step: 11-542 -- Loss: 0.2761719822883606
train-epoch-step: 11-543 -- Loss: 0.18657752871513367
train-epoch-step: 11-544 -- Loss: 0.2548758089542389
train-epoch-step: 11-545 -- Loss: 0.22454407811164856
train-epoch-step: 11-546 -- Loss: 0.2494061291217804
train-epoch-step: 11-547 -- Loss: 0.20452459156513214
train-epoch-step: 11-548 -- Loss: 0.10527575016021729
train-epoch-step: 11-549 -- Loss: 0.17118209600448608
train-epoch-step: 11-550 -- Loss: 0.22638913989067078
train-epoch-step: 11-551 -- Loss: 0.18198485672473907
train-epoch-step: 11-552 -- Loss: 0.14671790599822998
train-epoch-step: 11-553 -- Loss: 0.21341188251972198
train-epoch-step: 11-554 -- Loss: 0.20853957533836365
train-epoch-step: 11-555 -- Loss: 0.24412089586257935
train-epoch-step: 11-556 -- Loss: 0.18916606903076172
train-epoch-step: 11-557 -- Loss: 0.2743239402770996
train-epoch-step: 11-558 -- Loss: 0.25021636486053467
train-epoch-step: 11-559 -- Loss: 0.17209888994693756
train-epoch-step: 11-560 -- Loss: 0.23018580675125122
train-epoch-step: 11-561 -- Loss: 0.21963472664356232
train-epoch-step: 11-562 -- Loss: 0.20629364252090454
train-epoch-step: 11-563 -- Loss: 0.21076229214668274
train-epoch-step: 11-564 -- Loss: 0.11500068008899689
train-epoch-step: 11-565 -- Loss: 0.2064390331506729
train-epoch-step: 11-566 -- Loss: 0.18401095271110535
train-epoch-step: 11-567 -- Loss: 0.2397623509168625
train-epoch-step: 11-568 -- Loss: 0.1884273886680603
train-epoch-step: 11-569 -- Loss: 0.2718711495399475
train-epoch-step: 11-570 -- Loss: 0.19914878904819489
train-epoch-step: 11-571 -- Loss: 0.25097963213920593
train-epoch-step: 11-572 -- Loss: 0.2838687300682068
train-epoch-step: 11-573 -- Loss: 0.2252020388841629
train-epoch-step: 11-574 -- Loss: 0.2883983254432678
train-epoch-step: 11-575 -- Loss: 0.3769390285015106
train-epoch-step: 11-576 -- Loss: 0.13757751882076263
train-epoch-step: 11-577 -- Loss: 0.199945867061615
train-epoch-step: 11-578 -- Loss: 0.2521028220653534
train-epoch-step: 11-579 -- Loss: 0.18288657069206238
train-epoch-step: 11-580 -- Loss: 0.21352332830429077
train-epoch-step: 11-581 -- Loss: 0.16217529773712158
train-epoch-step: 11-582 -- Loss: 0.23273953795433044
train-epoch-step: 11-583 -- Loss: 0.2631867229938507
train-epoch-step: 11-584 -- Loss: 0.218341663479805
train-epoch-step: 11-585 -- Loss: 0.21508607268333435
train-epoch-step: 11-586 -- Loss: 0.29762130975723267
train-epoch-step: 11-587 -- Loss: 0.1816248595714569
train-epoch-step: 11-588 -- Loss: 0.1454826146364212
val-epoch-step: 11-589 -- Loss: 0.2289305031299591
val-epoch-step: 11-590 -- Loss: 0.1697840690612793
val-epoch-step: 11-591 -- Loss: 0.24097758531570435
val-epoch-step: 11-592 -- Loss: 0.20262306928634644
val-epoch-step: 11-593 -- Loss: 0.17555084824562073
val-epoch-step: 11-594 -- Loss: 0.3680863082408905
val-epoch-step: 11-595 -- Loss: 0.20801246166229248
val-epoch-step: 11-596 -- Loss: 0.24084919691085815
val-epoch-step: 11-597 -- Loss: 0.20465253293514252
val-epoch-step: 11-598 -- Loss: 0.1703263223171234
val-epoch-step: 11-599 -- Loss: 0.21138587594032288
val-epoch-step: 11-600 -- Loss: 0.1946447342634201
val-epoch-step: 11-601 -- Loss: 0.1743873506784439
val-epoch-step: 11-602 -- Loss: 0.15589921176433563
val-epoch-step: 11-603 -- Loss: 0.19797518849372864
val-epoch-step: 11-604 -- Loss: 0.16676177084445953
val-epoch-step: 11-605 -- Loss: 0.17276546359062195
val-epoch-step: 11-606 -- Loss: 0.2892891764640808
val-epoch-step: 11-607 -- Loss: 0.1488841474056244
val-epoch-step: 11-608 -- Loss: 0.2772895097732544
val-epoch-step: 11-609 -- Loss: 0.19428306818008423
val-epoch-step: 11-610 -- Loss: 0.20825955271720886
val-epoch-step: 11-611 -- Loss: 0.17927244305610657
val-epoch-step: 11-612 -- Loss: 0.4080885946750641
val-epoch-step: 11-613 -- Loss: 0.19681571424007416
val-epoch-step: 11-614 -- Loss: 0.1772458553314209
val-epoch-step: 11-615 -- Loss: 0.20648759603500366
val-epoch-step: 11-616 -- Loss: 0.17541232705116272
val-epoch-step: 11-617 -- Loss: 0.2058624029159546
val-epoch-step: 11-618 -- Loss: 0.2151101678609848
val-epoch-step: 11-619 -- Loss: 0.24706727266311646
val-epoch-step: 11-620 -- Loss: 0.16777536273002625
val-epoch-step: 11-621 -- Loss: 0.15270213782787323
val-epoch-step: 11-622 -- Loss: 0.1729283481836319
val-epoch-step: 11-623 -- Loss: 0.1734866499900818
val-epoch-step: 11-624 -- Loss: 0.18141663074493408
val-epoch-step: 11-625 -- Loss: 0.17734554409980774
val-epoch-step: 11-626 -- Loss: 0.1646268367767334
val-epoch-step: 11-627 -- Loss: 0.21281208097934723
val-epoch-step: 11-628 -- Loss: 0.5835714936256409
val-epoch-step: 11-629 -- Loss: 0.23044264316558838
val-epoch-step: 11-630 -- Loss: 0.3765786290168762
val-epoch-step: 11-631 -- Loss: 0.1664164811372757
val-epoch-step: 11-632 -- Loss: 0.2247820794582367
val-epoch-step: 11-633 -- Loss: 0.17294609546661377
val-epoch-step: 11-634 -- Loss: 0.16008944809436798
val-epoch-step: 11-635 -- Loss: 0.13309547305107117
val-epoch-step: 11-636 -- Loss: 0.19273123145103455
val-epoch-step: 11-637 -- Loss: 0.1954711526632309
val-epoch-step: 11-638 -- Loss: 0.1789386123418808
val-epoch-step: 11-639 -- Loss: 0.3002496659755707
val-epoch-step: 11-640 -- Loss: 0.2982466220855713
val-epoch-step: 11-641 -- Loss: 0.13784712553024292
val-epoch-step: 11-642 -- Loss: 0.20583577454090118
val-epoch-step: 11-643 -- Loss: 0.2181253582239151
val-epoch-step: 11-644 -- Loss: 0.18633316457271576
val-epoch-step: 11-645 -- Loss: 0.2529035210609436
val-epoch-step: 11-646 -- Loss: 0.16003452241420746
val-epoch-step: 11-647 -- Loss: 0.15357452630996704
val-epoch-step: 11-648 -- Loss: 0.18165695667266846
val-epoch-step: 11-649 -- Loss: 0.23705801367759705
val-epoch-step: 11-650 -- Loss: 0.27712002396583557
val-epoch-step: 11-651 -- Loss: 0.15977782011032104
val-epoch-step: 11-652 -- Loss: 0.18305248022079468
val-epoch-step: 11-653 -- Loss: 0.2237655520439148
val-epoch-step: 11-654 -- Loss: 0.1376265436410904
Epoch: 11 -- Train Loss: tensor(0.1527, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 12-0 -- Loss: 0.25965455174446106
train-epoch-step: 12-1 -- Loss: 0.16278450191020966
train-epoch-step: 12-2 -- Loss: 0.2308449000120163
train-epoch-step: 12-3 -- Loss: 0.17208777368068695
train-epoch-step: 12-4 -- Loss: 0.19369572401046753
train-epoch-step: 12-5 -- Loss: 0.22491618990898132
train-epoch-step: 12-6 -- Loss: 0.2598549723625183
train-epoch-step: 12-7 -- Loss: 0.1940273642539978
train-epoch-step: 12-8 -- Loss: 0.2336650937795639
train-epoch-step: 12-9 -- Loss: 0.28097662329673767
train-epoch-step: 12-10 -- Loss: 0.2499409019947052
train-epoch-step: 12-11 -- Loss: 0.20452965795993805
train-epoch-step: 12-12 -- Loss: 0.18500599265098572
train-epoch-step: 12-13 -- Loss: 0.20999398827552795
train-epoch-step: 12-14 -- Loss: 0.18289616703987122
train-epoch-step: 12-15 -- Loss: 0.18362592160701752
train-epoch-step: 12-16 -- Loss: 0.18233057856559753
train-epoch-step: 12-17 -- Loss: 0.2459019273519516
train-epoch-step: 12-18 -- Loss: 0.2366676926612854
train-epoch-step: 12-19 -- Loss: 0.15469691157341003
train-epoch-step: 12-20 -- Loss: 0.26106661558151245
train-epoch-step: 12-21 -- Loss: 0.3337758481502533
train-epoch-step: 12-22 -- Loss: 0.17197424173355103
train-epoch-step: 12-23 -- Loss: 0.20332852005958557
train-epoch-step: 12-24 -- Loss: 0.14825211465358734
train-epoch-step: 12-25 -- Loss: 0.2654873728752136
train-epoch-step: 12-26 -- Loss: 0.22280970215797424
train-epoch-step: 12-27 -- Loss: 0.3095930814743042
train-epoch-step: 12-28 -- Loss: 0.1474492996931076
train-epoch-step: 12-29 -- Loss: 0.2736746668815613
train-epoch-step: 12-30 -- Loss: 0.12658466398715973
train-epoch-step: 12-31 -- Loss: 0.1660086214542389
train-epoch-step: 12-32 -- Loss: 0.19469903409481049
train-epoch-step: 12-33 -- Loss: 0.3237059414386749
train-epoch-step: 12-34 -- Loss: 0.19753333926200867
train-epoch-step: 12-35 -- Loss: 0.28239014744758606
train-epoch-step: 12-36 -- Loss: 0.1610051691532135
train-epoch-step: 12-37 -- Loss: 0.17104025185108185
train-epoch-step: 12-38 -- Loss: 0.2171737402677536
train-epoch-step: 12-39 -- Loss: 0.27974259853363037
train-epoch-step: 12-40 -- Loss: 0.2274511605501175
train-epoch-step: 12-41 -- Loss: 0.24970459938049316
train-epoch-step: 12-42 -- Loss: 0.17155569791793823
train-epoch-step: 12-43 -- Loss: 0.30756083130836487
train-epoch-step: 12-44 -- Loss: 0.15284425020217896
train-epoch-step: 12-45 -- Loss: 0.14429783821105957
train-epoch-step: 12-46 -- Loss: 0.20877425372600555
train-epoch-step: 12-47 -- Loss: 0.29200035333633423
train-epoch-step: 12-48 -- Loss: 0.1740577518939972
train-epoch-step: 12-49 -- Loss: 0.24663686752319336
train-epoch-step: 12-50 -- Loss: 0.1426415592432022
train-epoch-step: 12-51 -- Loss: 0.23128846287727356
train-epoch-step: 12-52 -- Loss: 0.1818942129611969
train-epoch-step: 12-53 -- Loss: 0.26694798469543457
train-epoch-step: 12-54 -- Loss: 0.36938005685806274
train-epoch-step: 12-55 -- Loss: 0.21448712050914764
train-epoch-step: 12-56 -- Loss: 0.2087412029504776
train-epoch-step: 12-57 -- Loss: 0.26384127140045166
train-epoch-step: 12-58 -- Loss: 0.30501341819763184
train-epoch-step: 12-59 -- Loss: 0.3098069131374359
train-epoch-step: 12-60 -- Loss: 0.15338033437728882
train-epoch-step: 12-61 -- Loss: 0.2600361406803131
train-epoch-step: 12-62 -- Loss: 0.21185603737831116
train-epoch-step: 12-63 -- Loss: 0.16297581791877747
train-epoch-step: 12-64 -- Loss: 0.17681379616260529
train-epoch-step: 12-65 -- Loss: 0.22288429737091064
train-epoch-step: 12-66 -- Loss: 0.12861354649066925
train-epoch-step: 12-67 -- Loss: 0.1480197310447693
train-epoch-step: 12-68 -- Loss: 0.2585614025592804
train-epoch-step: 12-69 -- Loss: 0.14599306881427765
train-epoch-step: 12-70 -- Loss: 0.2531684935092926
train-epoch-step: 12-71 -- Loss: 0.2945414185523987
train-epoch-step: 12-72 -- Loss: 0.20799435675144196
train-epoch-step: 12-73 -- Loss: 0.24563512206077576
train-epoch-step: 12-74 -- Loss: 0.11439552158117294
train-epoch-step: 12-75 -- Loss: 0.15458092093467712
train-epoch-step: 12-76 -- Loss: 0.1681429147720337
train-epoch-step: 12-77 -- Loss: 0.25867652893066406
train-epoch-step: 12-78 -- Loss: 0.3533954620361328
train-epoch-step: 12-79 -- Loss: 0.22092339396476746
train-epoch-step: 12-80 -- Loss: 0.304938942193985
train-epoch-step: 12-81 -- Loss: 0.14798271656036377
train-epoch-step: 12-82 -- Loss: 0.29064494371414185
train-epoch-step: 12-83 -- Loss: 0.22872108221054077
train-epoch-step: 12-84 -- Loss: 0.23139777779579163
train-epoch-step: 12-85 -- Loss: 0.19789321720600128
train-epoch-step: 12-86 -- Loss: 0.14824604988098145
train-epoch-step: 12-87 -- Loss: 0.2626311779022217
train-epoch-step: 12-88 -- Loss: 0.16122931241989136
train-epoch-step: 12-89 -- Loss: 0.23056873679161072
train-epoch-step: 12-90 -- Loss: 0.22468301653862
train-epoch-step: 12-91 -- Loss: 0.27887141704559326
train-epoch-step: 12-92 -- Loss: 0.17725974321365356
train-epoch-step: 12-93 -- Loss: 0.21094301342964172
train-epoch-step: 12-94 -- Loss: 0.2584874927997589
train-epoch-step: 12-95 -- Loss: 0.23687663674354553
train-epoch-step: 12-96 -- Loss: 0.2492567002773285
train-epoch-step: 12-97 -- Loss: 0.2080944925546646
train-epoch-step: 12-98 -- Loss: 0.17165982723236084
train-epoch-step: 12-99 -- Loss: 0.2087658941745758
train-epoch-step: 12-100 -- Loss: 0.21246159076690674
train-epoch-step: 12-101 -- Loss: 0.3290485739707947
train-epoch-step: 12-102 -- Loss: 0.262437641620636
train-epoch-step: 12-103 -- Loss: 0.21504199504852295
train-epoch-step: 12-104 -- Loss: 0.17006683349609375
train-epoch-step: 12-105 -- Loss: 0.3180459141731262
train-epoch-step: 12-106 -- Loss: 0.1920274943113327
train-epoch-step: 12-107 -- Loss: 0.20736388862133026
train-epoch-step: 12-108 -- Loss: 0.2132014036178589
train-epoch-step: 12-109 -- Loss: 0.17023831605911255
train-epoch-step: 12-110 -- Loss: 0.21408608555793762
train-epoch-step: 12-111 -- Loss: 0.2124490737915039
train-epoch-step: 12-112 -- Loss: 0.19247353076934814
train-epoch-step: 12-113 -- Loss: 0.18967457115650177
train-epoch-step: 12-114 -- Loss: 0.237599715590477
train-epoch-step: 12-115 -- Loss: 0.19996580481529236
train-epoch-step: 12-116 -- Loss: 0.17286470532417297
train-epoch-step: 12-117 -- Loss: 0.14381536841392517
train-epoch-step: 12-118 -- Loss: 0.22675132751464844
train-epoch-step: 12-119 -- Loss: 0.17761164903640747
train-epoch-step: 12-120 -- Loss: 0.3074471950531006
train-epoch-step: 12-121 -- Loss: 0.31047672033309937
train-epoch-step: 12-122 -- Loss: 0.24625611305236816
train-epoch-step: 12-123 -- Loss: 0.24757173657417297
train-epoch-step: 12-124 -- Loss: 0.14042648673057556
train-epoch-step: 12-125 -- Loss: 0.17598846554756165
train-epoch-step: 12-126 -- Loss: 0.269070565700531
train-epoch-step: 12-127 -- Loss: 0.2109541893005371
train-epoch-step: 12-128 -- Loss: 0.195209801197052
train-epoch-step: 12-129 -- Loss: 0.1723097562789917
train-epoch-step: 12-130 -- Loss: 0.2383018434047699
train-epoch-step: 12-131 -- Loss: 0.15545761585235596
train-epoch-step: 12-132 -- Loss: 0.2298194319009781
train-epoch-step: 12-133 -- Loss: 0.13780906796455383
train-epoch-step: 12-134 -- Loss: 0.23307618498802185
train-epoch-step: 12-135 -- Loss: 0.15879926085472107
train-epoch-step: 12-136 -- Loss: 0.15363314747810364
train-epoch-step: 12-137 -- Loss: 0.2917017936706543
train-epoch-step: 12-138 -- Loss: 0.3080102801322937
train-epoch-step: 12-139 -- Loss: 0.1496715247631073
train-epoch-step: 12-140 -- Loss: 0.24093565344810486
train-epoch-step: 12-141 -- Loss: 0.26706448197364807
train-epoch-step: 12-142 -- Loss: 0.2330070436000824
train-epoch-step: 12-143 -- Loss: 0.1975657045841217
train-epoch-step: 12-144 -- Loss: 0.21146026253700256
train-epoch-step: 12-145 -- Loss: 0.1613566279411316
train-epoch-step: 12-146 -- Loss: 0.2062017023563385
train-epoch-step: 12-147 -- Loss: 0.20448684692382812
train-epoch-step: 12-148 -- Loss: 0.19573307037353516
train-epoch-step: 12-149 -- Loss: 0.1361197531223297
train-epoch-step: 12-150 -- Loss: 0.21558326482772827
train-epoch-step: 12-151 -- Loss: 0.20827169716358185
train-epoch-step: 12-152 -- Loss: 0.22206439077854156
train-epoch-step: 12-153 -- Loss: 0.3400666117668152
train-epoch-step: 12-154 -- Loss: 0.15279412269592285
train-epoch-step: 12-155 -- Loss: 0.16511929035186768
train-epoch-step: 12-156 -- Loss: 0.14916954934597015
train-epoch-step: 12-157 -- Loss: 0.19225208461284637
train-epoch-step: 12-158 -- Loss: 0.18607476353645325
train-epoch-step: 12-159 -- Loss: 0.20310378074645996
train-epoch-step: 12-160 -- Loss: 0.2652934789657593
train-epoch-step: 12-161 -- Loss: 0.23531393706798553
train-epoch-step: 12-162 -- Loss: 0.24749860167503357
train-epoch-step: 12-163 -- Loss: 0.21006646752357483
train-epoch-step: 12-164 -- Loss: 0.21009176969528198
train-epoch-step: 12-165 -- Loss: 0.19114427268505096
train-epoch-step: 12-166 -- Loss: 0.1385791003704071
train-epoch-step: 12-167 -- Loss: 0.14089778065681458
train-epoch-step: 12-168 -- Loss: 0.23289203643798828
train-epoch-step: 12-169 -- Loss: 0.16356652975082397
train-epoch-step: 12-170 -- Loss: 0.23177699744701385
train-epoch-step: 12-171 -- Loss: 0.15964452922344208
train-epoch-step: 12-172 -- Loss: 0.29572418332099915
train-epoch-step: 12-173 -- Loss: 0.1490338295698166
train-epoch-step: 12-174 -- Loss: 0.2753005027770996
train-epoch-step: 12-175 -- Loss: 0.19880056381225586
train-epoch-step: 12-176 -- Loss: 0.15672871470451355
train-epoch-step: 12-177 -- Loss: 0.21017736196517944
train-epoch-step: 12-178 -- Loss: 0.21418005228042603
train-epoch-step: 12-179 -- Loss: 0.1695924699306488
train-epoch-step: 12-180 -- Loss: 0.17243972420692444
train-epoch-step: 12-181 -- Loss: 0.1976088434457779
train-epoch-step: 12-182 -- Loss: 0.2201102375984192
train-epoch-step: 12-183 -- Loss: 0.30384311079978943
train-epoch-step: 12-184 -- Loss: 0.15474162995815277
train-epoch-step: 12-185 -- Loss: 0.16716328263282776
train-epoch-step: 12-186 -- Loss: 0.2196582555770874
train-epoch-step: 12-187 -- Loss: 0.2472967803478241
train-epoch-step: 12-188 -- Loss: 0.2012549340724945
train-epoch-step: 12-189 -- Loss: 0.13673390448093414
train-epoch-step: 12-190 -- Loss: 0.2059202939271927
train-epoch-step: 12-191 -- Loss: 0.2080059051513672
train-epoch-step: 12-192 -- Loss: 0.2800842523574829
train-epoch-step: 12-193 -- Loss: 0.25670331716537476
train-epoch-step: 12-194 -- Loss: 0.20543673634529114
train-epoch-step: 12-195 -- Loss: 0.1809326708316803
train-epoch-step: 12-196 -- Loss: 0.21578170359134674
train-epoch-step: 12-197 -- Loss: 0.1619543731212616
train-epoch-step: 12-198 -- Loss: 0.15774132311344147
train-epoch-step: 12-199 -- Loss: 0.17339858412742615
train-epoch-step: 12-200 -- Loss: 0.1374075710773468
train-epoch-step: 12-201 -- Loss: 0.23231402039527893
train-epoch-step: 12-202 -- Loss: 0.15092328190803528
train-epoch-step: 12-203 -- Loss: 0.2010926604270935
train-epoch-step: 12-204 -- Loss: 0.16348162293434143
train-epoch-step: 12-205 -- Loss: 0.21436789631843567
train-epoch-step: 12-206 -- Loss: 0.22569042444229126
train-epoch-step: 12-207 -- Loss: 0.1610671877861023
train-epoch-step: 12-208 -- Loss: 0.2052709460258484
train-epoch-step: 12-209 -- Loss: 0.1549852192401886
train-epoch-step: 12-210 -- Loss: 0.15633346140384674
train-epoch-step: 12-211 -- Loss: 0.2296891212463379
train-epoch-step: 12-212 -- Loss: 0.22247669100761414
train-epoch-step: 12-213 -- Loss: 0.1474357545375824
train-epoch-step: 12-214 -- Loss: 0.16562087833881378
train-epoch-step: 12-215 -- Loss: 0.14953404664993286
train-epoch-step: 12-216 -- Loss: 0.22884927690029144
train-epoch-step: 12-217 -- Loss: 0.2396373152732849
train-epoch-step: 12-218 -- Loss: 0.1668699085712433
train-epoch-step: 12-219 -- Loss: 0.2098972052335739
train-epoch-step: 12-220 -- Loss: 0.15124425292015076
train-epoch-step: 12-221 -- Loss: 0.22236427664756775
train-epoch-step: 12-222 -- Loss: 0.13781961798667908
train-epoch-step: 12-223 -- Loss: 0.19573278725147247
train-epoch-step: 12-224 -- Loss: 0.21806199848651886
train-epoch-step: 12-225 -- Loss: 0.32648763060569763
train-epoch-step: 12-226 -- Loss: 0.23235851526260376
train-epoch-step: 12-227 -- Loss: 0.2686174511909485
train-epoch-step: 12-228 -- Loss: 0.19695596396923065
train-epoch-step: 12-229 -- Loss: 0.20258955657482147
train-epoch-step: 12-230 -- Loss: 0.18206492066383362
train-epoch-step: 12-231 -- Loss: 0.19028815627098083
train-epoch-step: 12-232 -- Loss: 0.22910535335540771
train-epoch-step: 12-233 -- Loss: 0.09735143184661865
train-epoch-step: 12-234 -- Loss: 0.2045474350452423
train-epoch-step: 12-235 -- Loss: 0.17924809455871582
train-epoch-step: 12-236 -- Loss: 0.1983691155910492
train-epoch-step: 12-237 -- Loss: 0.2756153345108032
train-epoch-step: 12-238 -- Loss: 0.17460332810878754
train-epoch-step: 12-239 -- Loss: 0.14824506640434265
train-epoch-step: 12-240 -- Loss: 0.2512723207473755
train-epoch-step: 12-241 -- Loss: 0.18294104933738708
train-epoch-step: 12-242 -- Loss: 0.25098034739494324
train-epoch-step: 12-243 -- Loss: 0.2564627528190613
train-epoch-step: 12-244 -- Loss: 0.22451543807983398
train-epoch-step: 12-245 -- Loss: 0.25080645084381104
train-epoch-step: 12-246 -- Loss: 0.270175576210022
train-epoch-step: 12-247 -- Loss: 0.268830806016922
train-epoch-step: 12-248 -- Loss: 0.2146790623664856
train-epoch-step: 12-249 -- Loss: 0.1644258201122284
train-epoch-step: 12-250 -- Loss: 0.2315201461315155
train-epoch-step: 12-251 -- Loss: 0.12380750477313995
train-epoch-step: 12-252 -- Loss: 0.2225756049156189
train-epoch-step: 12-253 -- Loss: 0.16065675020217896
train-epoch-step: 12-254 -- Loss: 0.2590009570121765
train-epoch-step: 12-255 -- Loss: 0.17439256608486176
train-epoch-step: 12-256 -- Loss: 0.18183830380439758
train-epoch-step: 12-257 -- Loss: 0.2190270721912384
train-epoch-step: 12-258 -- Loss: 0.16801327466964722
train-epoch-step: 12-259 -- Loss: 0.13493645191192627
train-epoch-step: 12-260 -- Loss: 0.2441902607679367
train-epoch-step: 12-261 -- Loss: 0.20298513770103455
train-epoch-step: 12-262 -- Loss: 0.3614290952682495
train-epoch-step: 12-263 -- Loss: 0.2333478182554245
train-epoch-step: 12-264 -- Loss: 0.18855953216552734
train-epoch-step: 12-265 -- Loss: 0.1327032595872879
train-epoch-step: 12-266 -- Loss: 0.16679799556732178
train-epoch-step: 12-267 -- Loss: 0.1585550308227539
train-epoch-step: 12-268 -- Loss: 0.1402093768119812
train-epoch-step: 12-269 -- Loss: 0.19534341990947723
train-epoch-step: 12-270 -- Loss: 0.1286366879940033
train-epoch-step: 12-271 -- Loss: 0.19221404194831848
train-epoch-step: 12-272 -- Loss: 0.13723938167095184
train-epoch-step: 12-273 -- Loss: 0.1561189591884613
train-epoch-step: 12-274 -- Loss: 0.22750864923000336
train-epoch-step: 12-275 -- Loss: 0.22653307020664215
train-epoch-step: 12-276 -- Loss: 0.18574124574661255
train-epoch-step: 12-277 -- Loss: 0.17568439245224
train-epoch-step: 12-278 -- Loss: 0.1810181438922882
train-epoch-step: 12-279 -- Loss: 0.17014022171497345
train-epoch-step: 12-280 -- Loss: 0.25230902433395386
train-epoch-step: 12-281 -- Loss: 0.2201942801475525
train-epoch-step: 12-282 -- Loss: 0.16230818629264832
train-epoch-step: 12-283 -- Loss: 0.13916249573230743
train-epoch-step: 12-284 -- Loss: 0.28243905305862427
train-epoch-step: 12-285 -- Loss: 0.22255319356918335
train-epoch-step: 12-286 -- Loss: 0.18427054584026337
train-epoch-step: 12-287 -- Loss: 0.23054975271224976
train-epoch-step: 12-288 -- Loss: 0.10866265743970871
train-epoch-step: 12-289 -- Loss: 0.14991281926631927
train-epoch-step: 12-290 -- Loss: 0.2182387411594391
train-epoch-step: 12-291 -- Loss: 0.13162565231323242
train-epoch-step: 12-292 -- Loss: 0.19213953614234924
train-epoch-step: 12-293 -- Loss: 0.1597651243209839
train-epoch-step: 12-294 -- Loss: 0.19689150154590607
train-epoch-step: 12-295 -- Loss: 0.3472699522972107
train-epoch-step: 12-296 -- Loss: 0.21239334344863892
train-epoch-step: 12-297 -- Loss: 0.20022913813591003
train-epoch-step: 12-298 -- Loss: 0.2833179235458374
train-epoch-step: 12-299 -- Loss: 0.18080995976924896
train-epoch-step: 12-300 -- Loss: 0.2017245590686798
train-epoch-step: 12-301 -- Loss: 0.1881425380706787
train-epoch-step: 12-302 -- Loss: 0.25010019540786743
train-epoch-step: 12-303 -- Loss: 0.2435581088066101
train-epoch-step: 12-304 -- Loss: 0.16831979155540466
train-epoch-step: 12-305 -- Loss: 0.1649443507194519
train-epoch-step: 12-306 -- Loss: 0.28610628843307495
train-epoch-step: 12-307 -- Loss: 0.1919568032026291
train-epoch-step: 12-308 -- Loss: 0.2630545198917389
train-epoch-step: 12-309 -- Loss: 0.17651619017124176
train-epoch-step: 12-310 -- Loss: 0.1883695274591446
train-epoch-step: 12-311 -- Loss: 0.19148680567741394
train-epoch-step: 12-312 -- Loss: 0.23729237914085388
train-epoch-step: 12-313 -- Loss: 0.11412671208381653
train-epoch-step: 12-314 -- Loss: 0.2459513396024704
train-epoch-step: 12-315 -- Loss: 0.19664153456687927
train-epoch-step: 12-316 -- Loss: 0.1769077479839325
train-epoch-step: 12-317 -- Loss: 0.1691630482673645
train-epoch-step: 12-318 -- Loss: 0.1868586242198944
train-epoch-step: 12-319 -- Loss: 0.21110650897026062
train-epoch-step: 12-320 -- Loss: 0.1372097283601761
train-epoch-step: 12-321 -- Loss: 0.1582210808992386
train-epoch-step: 12-322 -- Loss: 0.24344970285892487
train-epoch-step: 12-323 -- Loss: 0.18155992031097412
train-epoch-step: 12-324 -- Loss: 0.30250808596611023
train-epoch-step: 12-325 -- Loss: 0.17739900946617126
train-epoch-step: 12-326 -- Loss: 0.19582624733448029
train-epoch-step: 12-327 -- Loss: 0.24421951174736023
train-epoch-step: 12-328 -- Loss: 0.22037272155284882
train-epoch-step: 12-329 -- Loss: 0.37540245056152344
train-epoch-step: 12-330 -- Loss: 0.4111838936805725
train-epoch-step: 12-331 -- Loss: 0.24764633178710938
train-epoch-step: 12-332 -- Loss: 0.12469818443059921
train-epoch-step: 12-333 -- Loss: 0.21760159730911255
train-epoch-step: 12-334 -- Loss: 0.18517953157424927
train-epoch-step: 12-335 -- Loss: 0.1999950259923935
train-epoch-step: 12-336 -- Loss: 0.1899474859237671
train-epoch-step: 12-337 -- Loss: 0.25148069858551025
train-epoch-step: 12-338 -- Loss: 0.18240618705749512
train-epoch-step: 12-339 -- Loss: 0.16739320755004883
train-epoch-step: 12-340 -- Loss: 0.2260299026966095
train-epoch-step: 12-341 -- Loss: 0.16162103414535522
train-epoch-step: 12-342 -- Loss: 0.194315105676651
train-epoch-step: 12-343 -- Loss: 0.18302954733371735
train-epoch-step: 12-344 -- Loss: 0.19846639037132263
train-epoch-step: 12-345 -- Loss: 0.15356028079986572
train-epoch-step: 12-346 -- Loss: 0.22483229637145996
train-epoch-step: 12-347 -- Loss: 0.17438727617263794
train-epoch-step: 12-348 -- Loss: 0.23707929253578186
train-epoch-step: 12-349 -- Loss: 0.24376022815704346
train-epoch-step: 12-350 -- Loss: 0.31441259384155273
train-epoch-step: 12-351 -- Loss: 0.22427275776863098
train-epoch-step: 12-352 -- Loss: 0.1500920206308365
train-epoch-step: 12-353 -- Loss: 0.2205529361963272
train-epoch-step: 12-354 -- Loss: 0.3208872079849243
train-epoch-step: 12-355 -- Loss: 0.13835427165031433
train-epoch-step: 12-356 -- Loss: 0.13694874942302704
train-epoch-step: 12-357 -- Loss: 0.21484646201133728
train-epoch-step: 12-358 -- Loss: 0.2099676877260208
train-epoch-step: 12-359 -- Loss: 0.16293835639953613
train-epoch-step: 12-360 -- Loss: 0.13601702451705933
train-epoch-step: 12-361 -- Loss: 0.2877282500267029
train-epoch-step: 12-362 -- Loss: 0.1927388310432434
train-epoch-step: 12-363 -- Loss: 0.13924828171730042
train-epoch-step: 12-364 -- Loss: 0.20516598224639893
train-epoch-step: 12-365 -- Loss: 0.19477221369743347
train-epoch-step: 12-366 -- Loss: 0.22818134725093842
train-epoch-step: 12-367 -- Loss: 0.2964814603328705
train-epoch-step: 12-368 -- Loss: 0.23593206703662872
train-epoch-step: 12-369 -- Loss: 0.3056632876396179
train-epoch-step: 12-370 -- Loss: 0.14468175172805786
train-epoch-step: 12-371 -- Loss: 0.1329696923494339
train-epoch-step: 12-372 -- Loss: 0.16327069699764252
train-epoch-step: 12-373 -- Loss: 0.23141108453273773
train-epoch-step: 12-374 -- Loss: 0.17288190126419067
train-epoch-step: 12-375 -- Loss: 0.31935763359069824
train-epoch-step: 12-376 -- Loss: 0.20897740125656128
train-epoch-step: 12-377 -- Loss: 0.257617324590683
train-epoch-step: 12-378 -- Loss: 0.2473512440919876
train-epoch-step: 12-379 -- Loss: 0.13537831604480743
train-epoch-step: 12-380 -- Loss: 0.10191517323255539
train-epoch-step: 12-381 -- Loss: 0.27808237075805664
train-epoch-step: 12-382 -- Loss: 0.2650988698005676
train-epoch-step: 12-383 -- Loss: 0.20070675015449524
train-epoch-step: 12-384 -- Loss: 0.2569863200187683
train-epoch-step: 12-385 -- Loss: 0.22828538715839386
train-epoch-step: 12-386 -- Loss: 0.21977072954177856
train-epoch-step: 12-387 -- Loss: 0.2377779334783554
train-epoch-step: 12-388 -- Loss: 0.2532103657722473
train-epoch-step: 12-389 -- Loss: 0.20001108944416046
train-epoch-step: 12-390 -- Loss: 0.1598438173532486
train-epoch-step: 12-391 -- Loss: 0.16283361613750458
train-epoch-step: 12-392 -- Loss: 0.2036871463060379
train-epoch-step: 12-393 -- Loss: 0.18224123120307922
train-epoch-step: 12-394 -- Loss: 0.24627596139907837
train-epoch-step: 12-395 -- Loss: 0.1861523985862732
train-epoch-step: 12-396 -- Loss: 0.14845263957977295
train-epoch-step: 12-397 -- Loss: 0.14325900375843048
train-epoch-step: 12-398 -- Loss: 0.222311869263649
train-epoch-step: 12-399 -- Loss: 0.20529258251190186
train-epoch-step: 12-400 -- Loss: 0.33411282300949097
train-epoch-step: 12-401 -- Loss: 0.13741102814674377
train-epoch-step: 12-402 -- Loss: 0.29217398166656494
train-epoch-step: 12-403 -- Loss: 0.18069690465927124
train-epoch-step: 12-404 -- Loss: 0.16126865148544312
train-epoch-step: 12-405 -- Loss: 0.16520026326179504
train-epoch-step: 12-406 -- Loss: 0.1898101568222046
train-epoch-step: 12-407 -- Loss: 0.1327941119670868
train-epoch-step: 12-408 -- Loss: 0.18607424199581146
train-epoch-step: 12-409 -- Loss: 0.19352620840072632
train-epoch-step: 12-410 -- Loss: 0.19738851487636566
train-epoch-step: 12-411 -- Loss: 0.2279662787914276
train-epoch-step: 12-412 -- Loss: 0.14521004259586334
train-epoch-step: 12-413 -- Loss: 0.16769522428512573
train-epoch-step: 12-414 -- Loss: 0.15774066746234894
train-epoch-step: 12-415 -- Loss: 0.15720811486244202
train-epoch-step: 12-416 -- Loss: 0.29365453124046326
train-epoch-step: 12-417 -- Loss: 0.2219734787940979
train-epoch-step: 12-418 -- Loss: 0.2842555642127991
train-epoch-step: 12-419 -- Loss: 0.1939924955368042
train-epoch-step: 12-420 -- Loss: 0.17407885193824768
train-epoch-step: 12-421 -- Loss: 0.2070300579071045
train-epoch-step: 12-422 -- Loss: 0.17175863683223724
train-epoch-step: 12-423 -- Loss: 0.20547699928283691
train-epoch-step: 12-424 -- Loss: 0.15511475503444672
train-epoch-step: 12-425 -- Loss: 0.2059481143951416
train-epoch-step: 12-426 -- Loss: 0.19159437716007233
train-epoch-step: 12-427 -- Loss: 0.14885543286800385
train-epoch-step: 12-428 -- Loss: 0.2308492660522461
train-epoch-step: 12-429 -- Loss: 0.1917361468076706
train-epoch-step: 12-430 -- Loss: 0.17092210054397583
train-epoch-step: 12-431 -- Loss: 0.19473549723625183
train-epoch-step: 12-432 -- Loss: 0.27292168140411377
train-epoch-step: 12-433 -- Loss: 0.15446573495864868
train-epoch-step: 12-434 -- Loss: 0.15272894501686096
train-epoch-step: 12-435 -- Loss: 0.1906863898038864
train-epoch-step: 12-436 -- Loss: 0.18002364039421082
train-epoch-step: 12-437 -- Loss: 0.16302704811096191
train-epoch-step: 12-438 -- Loss: 0.20862048864364624
train-epoch-step: 12-439 -- Loss: 0.3120848536491394
train-epoch-step: 12-440 -- Loss: 0.14813028275966644
train-epoch-step: 12-441 -- Loss: 0.24087511003017426
train-epoch-step: 12-442 -- Loss: 0.2210155725479126
train-epoch-step: 12-443 -- Loss: 0.19616645574569702
train-epoch-step: 12-444 -- Loss: 0.22588521242141724
train-epoch-step: 12-445 -- Loss: 0.1995275914669037
train-epoch-step: 12-446 -- Loss: 0.18356963992118835
train-epoch-step: 12-447 -- Loss: 0.24256879091262817
train-epoch-step: 12-448 -- Loss: 0.2716592848300934
train-epoch-step: 12-449 -- Loss: 0.22498008608818054
train-epoch-step: 12-450 -- Loss: 0.22182568907737732
train-epoch-step: 12-451 -- Loss: 0.1651488095521927
train-epoch-step: 12-452 -- Loss: 0.15500743687152863
train-epoch-step: 12-453 -- Loss: 0.10868647694587708
train-epoch-step: 12-454 -- Loss: 0.2811909019947052
train-epoch-step: 12-455 -- Loss: 0.14746886491775513
train-epoch-step: 12-456 -- Loss: 0.1389831304550171
train-epoch-step: 12-457 -- Loss: 0.24244998395442963
train-epoch-step: 12-458 -- Loss: 0.17354142665863037
train-epoch-step: 12-459 -- Loss: 0.2457459717988968
train-epoch-step: 12-460 -- Loss: 0.1460500955581665
train-epoch-step: 12-461 -- Loss: 0.16204582154750824
train-epoch-step: 12-462 -- Loss: 0.18061795830726624
train-epoch-step: 12-463 -- Loss: 0.15509231388568878
train-epoch-step: 12-464 -- Loss: 0.1868659406900406
train-epoch-step: 12-465 -- Loss: 0.28101861476898193
train-epoch-step: 12-466 -- Loss: 0.22700092196464539
train-epoch-step: 12-467 -- Loss: 0.13039520382881165
train-epoch-step: 12-468 -- Loss: 0.2166690081357956
train-epoch-step: 12-469 -- Loss: 0.2655666470527649
train-epoch-step: 12-470 -- Loss: 0.20402652025222778
train-epoch-step: 12-471 -- Loss: 0.17355699837207794
train-epoch-step: 12-472 -- Loss: 0.17478936910629272
train-epoch-step: 12-473 -- Loss: 0.20493340492248535
train-epoch-step: 12-474 -- Loss: 0.13947372138500214
train-epoch-step: 12-475 -- Loss: 0.13045883178710938
train-epoch-step: 12-476 -- Loss: 0.22596657276153564
train-epoch-step: 12-477 -- Loss: 0.27135929465293884
train-epoch-step: 12-478 -- Loss: 0.2145947515964508
train-epoch-step: 12-479 -- Loss: 0.1610029935836792
train-epoch-step: 12-480 -- Loss: 0.21119727194309235
train-epoch-step: 12-481 -- Loss: 0.3070599138736725
train-epoch-step: 12-482 -- Loss: 0.28728336095809937
train-epoch-step: 12-483 -- Loss: 0.21311236917972565
train-epoch-step: 12-484 -- Loss: 0.23005124926567078
train-epoch-step: 12-485 -- Loss: 0.15098515152931213
train-epoch-step: 12-486 -- Loss: 0.28111305832862854
train-epoch-step: 12-487 -- Loss: 0.25659888982772827
train-epoch-step: 12-488 -- Loss: 0.21698608994483948
train-epoch-step: 12-489 -- Loss: 0.2485107183456421
train-epoch-step: 12-490 -- Loss: 0.15849506855010986
train-epoch-step: 12-491 -- Loss: 0.15818896889686584
train-epoch-step: 12-492 -- Loss: 0.13988710939884186
train-epoch-step: 12-493 -- Loss: 0.2551076114177704
train-epoch-step: 12-494 -- Loss: 0.23714913427829742
train-epoch-step: 12-495 -- Loss: 0.23638275265693665
train-epoch-step: 12-496 -- Loss: 0.15211305022239685
train-epoch-step: 12-497 -- Loss: 0.20092245936393738
train-epoch-step: 12-498 -- Loss: 0.1661989390850067
train-epoch-step: 12-499 -- Loss: 0.2023603320121765
train-epoch-step: 12-500 -- Loss: 0.17834553122520447
train-epoch-step: 12-501 -- Loss: 0.25312909483909607
train-epoch-step: 12-502 -- Loss: 0.18415361642837524
train-epoch-step: 12-503 -- Loss: 0.24837644398212433
train-epoch-step: 12-504 -- Loss: 0.1409793347120285
train-epoch-step: 12-505 -- Loss: 0.19795426726341248
train-epoch-step: 12-506 -- Loss: 0.13503645360469818
train-epoch-step: 12-507 -- Loss: 0.20436885952949524
train-epoch-step: 12-508 -- Loss: 0.1944204568862915
train-epoch-step: 12-509 -- Loss: 0.18592260777950287
train-epoch-step: 12-510 -- Loss: 0.14355158805847168
train-epoch-step: 12-511 -- Loss: 0.2450125366449356
train-epoch-step: 12-512 -- Loss: 0.19263997673988342
train-epoch-step: 12-513 -- Loss: 0.2386607825756073
train-epoch-step: 12-514 -- Loss: 0.17093932628631592
train-epoch-step: 12-515 -- Loss: 0.18173691630363464
train-epoch-step: 12-516 -- Loss: 0.1950104981660843
train-epoch-step: 12-517 -- Loss: 0.20499123632907867
train-epoch-step: 12-518 -- Loss: 0.15404033660888672
train-epoch-step: 12-519 -- Loss: 0.14849944412708282
train-epoch-step: 12-520 -- Loss: 0.20917126536369324
train-epoch-step: 12-521 -- Loss: 0.2532806992530823
train-epoch-step: 12-522 -- Loss: 0.19783923029899597
train-epoch-step: 12-523 -- Loss: 0.18187817931175232
train-epoch-step: 12-524 -- Loss: 0.19622892141342163
train-epoch-step: 12-525 -- Loss: 0.21568109095096588
train-epoch-step: 12-526 -- Loss: 0.14715783298015594
train-epoch-step: 12-527 -- Loss: 0.1833125650882721
train-epoch-step: 12-528 -- Loss: 0.17721472680568695
train-epoch-step: 12-529 -- Loss: 0.19314061105251312
train-epoch-step: 12-530 -- Loss: 0.1965973973274231
train-epoch-step: 12-531 -- Loss: 0.23412124812602997
train-epoch-step: 12-532 -- Loss: 0.19632044434547424
train-epoch-step: 12-533 -- Loss: 0.18523572385311127
train-epoch-step: 12-534 -- Loss: 0.15619955956935883
train-epoch-step: 12-535 -- Loss: 0.2939295172691345
train-epoch-step: 12-536 -- Loss: 0.17973078787326813
train-epoch-step: 12-537 -- Loss: 0.16579192876815796
train-epoch-step: 12-538 -- Loss: 0.11552371829748154
train-epoch-step: 12-539 -- Loss: 0.22544947266578674
train-epoch-step: 12-540 -- Loss: 0.1521892547607422
train-epoch-step: 12-541 -- Loss: 0.24011415243148804
train-epoch-step: 12-542 -- Loss: 0.2617085874080658
train-epoch-step: 12-543 -- Loss: 0.18541932106018066
train-epoch-step: 12-544 -- Loss: 0.26067930459976196
train-epoch-step: 12-545 -- Loss: 0.2210894376039505
train-epoch-step: 12-546 -- Loss: 0.24430720508098602
train-epoch-step: 12-547 -- Loss: 0.19865933060646057
train-epoch-step: 12-548 -- Loss: 0.10373879969120026
train-epoch-step: 12-549 -- Loss: 0.16973361372947693
train-epoch-step: 12-550 -- Loss: 0.22833696007728577
train-epoch-step: 12-551 -- Loss: 0.18747082352638245
train-epoch-step: 12-552 -- Loss: 0.14537642896175385
train-epoch-step: 12-553 -- Loss: 0.21181391179561615
train-epoch-step: 12-554 -- Loss: 0.20699837803840637
train-epoch-step: 12-555 -- Loss: 0.24241258203983307
train-epoch-step: 12-556 -- Loss: 0.17953971028327942
train-epoch-step: 12-557 -- Loss: 0.2669123709201813
train-epoch-step: 12-558 -- Loss: 0.26742440462112427
train-epoch-step: 12-559 -- Loss: 0.17418387532234192
train-epoch-step: 12-560 -- Loss: 0.22788192331790924
train-epoch-step: 12-561 -- Loss: 0.22111660242080688
train-epoch-step: 12-562 -- Loss: 0.20778638124465942
train-epoch-step: 12-563 -- Loss: 0.21080049872398376
train-epoch-step: 12-564 -- Loss: 0.11673920601606369
train-epoch-step: 12-565 -- Loss: 0.21399027109146118
train-epoch-step: 12-566 -- Loss: 0.18221907317638397
train-epoch-step: 12-567 -- Loss: 0.24150100350379944
train-epoch-step: 12-568 -- Loss: 0.18165041506290436
train-epoch-step: 12-569 -- Loss: 0.2707479000091553
train-epoch-step: 12-570 -- Loss: 0.21441391110420227
train-epoch-step: 12-571 -- Loss: 0.2512128949165344
train-epoch-step: 12-572 -- Loss: 0.3062904477119446
train-epoch-step: 12-573 -- Loss: 0.22088722884655
train-epoch-step: 12-574 -- Loss: 0.2999348044395447
train-epoch-step: 12-575 -- Loss: 0.3697156608104706
train-epoch-step: 12-576 -- Loss: 0.1519778072834015
train-epoch-step: 12-577 -- Loss: 0.1958869844675064
train-epoch-step: 12-578 -- Loss: 0.2512732148170471
train-epoch-step: 12-579 -- Loss: 0.1861734241247177
train-epoch-step: 12-580 -- Loss: 0.2044997662305832
train-epoch-step: 12-581 -- Loss: 0.1664629578590393
train-epoch-step: 12-582 -- Loss: 0.2323426902294159
train-epoch-step: 12-583 -- Loss: 0.26343846321105957
train-epoch-step: 12-584 -- Loss: 0.2129705846309662
train-epoch-step: 12-585 -- Loss: 0.21676328778266907
train-epoch-step: 12-586 -- Loss: 0.2988939881324768
train-epoch-step: 12-587 -- Loss: 0.18346752226352692
train-epoch-step: 12-588 -- Loss: 0.147093266248703
val-epoch-step: 12-589 -- Loss: 0.23837167024612427
val-epoch-step: 12-590 -- Loss: 0.16416996717453003
val-epoch-step: 12-591 -- Loss: 0.24448294937610626
val-epoch-step: 12-592 -- Loss: 0.1994737684726715
val-epoch-step: 12-593 -- Loss: 0.17471536993980408
val-epoch-step: 12-594 -- Loss: 0.3237937092781067
val-epoch-step: 12-595 -- Loss: 0.2107151299715042
val-epoch-step: 12-596 -- Loss: 0.23363173007965088
val-epoch-step: 12-597 -- Loss: 0.21054227650165558
val-epoch-step: 12-598 -- Loss: 0.17031176388263702
val-epoch-step: 12-599 -- Loss: 0.20811471343040466
val-epoch-step: 12-600 -- Loss: 0.18707925081253052
val-epoch-step: 12-601 -- Loss: 0.17482052743434906
val-epoch-step: 12-602 -- Loss: 0.1557309329509735
val-epoch-step: 12-603 -- Loss: 0.20992562174797058
val-epoch-step: 12-604 -- Loss: 0.16011321544647217
val-epoch-step: 12-605 -- Loss: 0.16244041919708252
val-epoch-step: 12-606 -- Loss: 0.2939978837966919
val-epoch-step: 12-607 -- Loss: 0.1451205164194107
val-epoch-step: 12-608 -- Loss: 0.2757549285888672
val-epoch-step: 12-609 -- Loss: 0.19054460525512695
val-epoch-step: 12-610 -- Loss: 0.2069844901561737
val-epoch-step: 12-611 -- Loss: 0.17797333002090454
val-epoch-step: 12-612 -- Loss: 0.36853110790252686
val-epoch-step: 12-613 -- Loss: 0.20249757170677185
val-epoch-step: 12-614 -- Loss: 0.17535395920276642
val-epoch-step: 12-615 -- Loss: 0.2014157623052597
val-epoch-step: 12-616 -- Loss: 0.16802115738391876
val-epoch-step: 12-617 -- Loss: 0.21037322282791138
val-epoch-step: 12-618 -- Loss: 0.21914538741111755
val-epoch-step: 12-619 -- Loss: 0.23514124751091003
val-epoch-step: 12-620 -- Loss: 0.1563476324081421
val-epoch-step: 12-621 -- Loss: 0.14924609661102295
val-epoch-step: 12-622 -- Loss: 0.17621871829032898
val-epoch-step: 12-623 -- Loss: 0.16874723136425018
val-epoch-step: 12-624 -- Loss: 0.17375683784484863
val-epoch-step: 12-625 -- Loss: 0.17580285668373108
val-epoch-step: 12-626 -- Loss: 0.16516025364398956
val-epoch-step: 12-627 -- Loss: 0.21335521340370178
val-epoch-step: 12-628 -- Loss: 0.5632365345954895
val-epoch-step: 12-629 -- Loss: 0.23151269555091858
val-epoch-step: 12-630 -- Loss: 0.3861084580421448
val-epoch-step: 12-631 -- Loss: 0.16713793575763702
val-epoch-step: 12-632 -- Loss: 0.22135427594184875
val-epoch-step: 12-633 -- Loss: 0.17653284966945648
val-epoch-step: 12-634 -- Loss: 0.16456013917922974
val-epoch-step: 12-635 -- Loss: 0.13514582812786102
val-epoch-step: 12-636 -- Loss: 0.18858829140663147
val-epoch-step: 12-637 -- Loss: 0.20059233903884888
val-epoch-step: 12-638 -- Loss: 0.17276489734649658
val-epoch-step: 12-639 -- Loss: 0.289274126291275
val-epoch-step: 12-640 -- Loss: 0.28944170475006104
val-epoch-step: 12-641 -- Loss: 0.13565653562545776
val-epoch-step: 12-642 -- Loss: 0.20924335718154907
val-epoch-step: 12-643 -- Loss: 0.2230110466480255
val-epoch-step: 12-644 -- Loss: 0.18134114146232605
val-epoch-step: 12-645 -- Loss: 0.2503919005393982
val-epoch-step: 12-646 -- Loss: 0.1588212251663208
val-epoch-step: 12-647 -- Loss: 0.14965838193893433
val-epoch-step: 12-648 -- Loss: 0.17859143018722534
val-epoch-step: 12-649 -- Loss: 0.2354045957326889
val-epoch-step: 12-650 -- Loss: 0.282557874917984
val-epoch-step: 12-651 -- Loss: 0.15992683172225952
val-epoch-step: 12-652 -- Loss: 0.17905473709106445
val-epoch-step: 12-653 -- Loss: 0.23983822762966156
val-epoch-step: 12-654 -- Loss: 0.1394127905368805
Epoch: 12 -- Train Loss: tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 13-0 -- Loss: 0.2522733807563782
train-epoch-step: 13-1 -- Loss: 0.16214710474014282
train-epoch-step: 13-2 -- Loss: 0.22925938665866852
train-epoch-step: 13-3 -- Loss: 0.16889074444770813
train-epoch-step: 13-4 -- Loss: 0.19009023904800415
train-epoch-step: 13-5 -- Loss: 0.22633108496665955
train-epoch-step: 13-6 -- Loss: 0.2586725652217865
train-epoch-step: 13-7 -- Loss: 0.19276952743530273
train-epoch-step: 13-8 -- Loss: 0.22240471839904785
train-epoch-step: 13-9 -- Loss: 0.2688528895378113
train-epoch-step: 13-10 -- Loss: 0.2322610318660736
train-epoch-step: 13-11 -- Loss: 0.20501679182052612
train-epoch-step: 13-12 -- Loss: 0.18941380083560944
train-epoch-step: 13-13 -- Loss: 0.20801284909248352
train-epoch-step: 13-14 -- Loss: 0.1827840507030487
train-epoch-step: 13-15 -- Loss: 0.18266716599464417
train-epoch-step: 13-16 -- Loss: 0.17811881005764008
train-epoch-step: 13-17 -- Loss: 0.24730074405670166
train-epoch-step: 13-18 -- Loss: 0.2268921434879303
train-epoch-step: 13-19 -- Loss: 0.15235809981822968
train-epoch-step: 13-20 -- Loss: 0.27302685379981995
train-epoch-step: 13-21 -- Loss: 0.3452557325363159
train-epoch-step: 13-22 -- Loss: 0.17083977162837982
train-epoch-step: 13-23 -- Loss: 0.1857365071773529
train-epoch-step: 13-24 -- Loss: 0.14418166875839233
train-epoch-step: 13-25 -- Loss: 0.2603475749492645
train-epoch-step: 13-26 -- Loss: 0.2186432182788849
train-epoch-step: 13-27 -- Loss: 0.3308398127555847
train-epoch-step: 13-28 -- Loss: 0.14008820056915283
train-epoch-step: 13-29 -- Loss: 0.27734142541885376
train-epoch-step: 13-30 -- Loss: 0.1228894293308258
train-epoch-step: 13-31 -- Loss: 0.1663043200969696
train-epoch-step: 13-32 -- Loss: 0.19405946135520935
train-epoch-step: 13-33 -- Loss: 0.30529800057411194
train-epoch-step: 13-34 -- Loss: 0.2072070837020874
train-epoch-step: 13-35 -- Loss: 0.2836982309818268
train-epoch-step: 13-36 -- Loss: 0.15869249403476715
train-epoch-step: 13-37 -- Loss: 0.16663533449172974
train-epoch-step: 13-38 -- Loss: 0.22344523668289185
train-epoch-step: 13-39 -- Loss: 0.29984620213508606
train-epoch-step: 13-40 -- Loss: 0.23557811975479126
train-epoch-step: 13-41 -- Loss: 0.251767098903656
train-epoch-step: 13-42 -- Loss: 0.1745702624320984
train-epoch-step: 13-43 -- Loss: 0.36076006293296814
train-epoch-step: 13-44 -- Loss: 0.1478760987520218
train-epoch-step: 13-45 -- Loss: 0.14345037937164307
train-epoch-step: 13-46 -- Loss: 0.20644980669021606
train-epoch-step: 13-47 -- Loss: 0.26636260747909546
train-epoch-step: 13-48 -- Loss: 0.170606791973114
train-epoch-step: 13-49 -- Loss: 0.2384268343448639
train-epoch-step: 13-50 -- Loss: 0.13693805038928986
train-epoch-step: 13-51 -- Loss: 0.2239760458469391
train-epoch-step: 13-52 -- Loss: 0.17723815143108368
train-epoch-step: 13-53 -- Loss: 0.2505122125148773
train-epoch-step: 13-54 -- Loss: 0.34707126021385193
train-epoch-step: 13-55 -- Loss: 0.19824597239494324
train-epoch-step: 13-56 -- Loss: 0.20975381135940552
train-epoch-step: 13-57 -- Loss: 0.2621505558490753
train-epoch-step: 13-58 -- Loss: 0.3238910138607025
train-epoch-step: 13-59 -- Loss: 0.2966294288635254
train-epoch-step: 13-60 -- Loss: 0.14831072092056274
train-epoch-step: 13-61 -- Loss: 0.23373666405677795
train-epoch-step: 13-62 -- Loss: 0.21067817509174347
train-epoch-step: 13-63 -- Loss: 0.16148360073566437
train-epoch-step: 13-64 -- Loss: 0.17585569620132446
train-epoch-step: 13-65 -- Loss: 0.2218095064163208
train-epoch-step: 13-66 -- Loss: 0.1279514729976654
train-epoch-step: 13-67 -- Loss: 0.14581391215324402
train-epoch-step: 13-68 -- Loss: 0.304768443107605
train-epoch-step: 13-69 -- Loss: 0.14552278816699982
train-epoch-step: 13-70 -- Loss: 0.2948353588581085
train-epoch-step: 13-71 -- Loss: 0.29731446504592896
train-epoch-step: 13-72 -- Loss: 0.2079949975013733
train-epoch-step: 13-73 -- Loss: 0.2374613881111145
train-epoch-step: 13-74 -- Loss: 0.11810623109340668
train-epoch-step: 13-75 -- Loss: 0.16377384960651398
train-epoch-step: 13-76 -- Loss: 0.17358969151973724
train-epoch-step: 13-77 -- Loss: 0.27149009704589844
train-epoch-step: 13-78 -- Loss: 0.3080603778362274
train-epoch-step: 13-79 -- Loss: 0.23672081530094147
train-epoch-step: 13-80 -- Loss: 0.33062106370925903
train-epoch-step: 13-81 -- Loss: 0.15163832902908325
train-epoch-step: 13-82 -- Loss: 0.28866255283355713
train-epoch-step: 13-83 -- Loss: 0.23867206275463104
train-epoch-step: 13-84 -- Loss: 0.23566734790802002
train-epoch-step: 13-85 -- Loss: 0.2024434208869934
train-epoch-step: 13-86 -- Loss: 0.15241926908493042
train-epoch-step: 13-87 -- Loss: 0.26085418462753296
train-epoch-step: 13-88 -- Loss: 0.16174305975437164
train-epoch-step: 13-89 -- Loss: 0.22290971875190735
train-epoch-step: 13-90 -- Loss: 0.2303508222103119
train-epoch-step: 13-91 -- Loss: 0.28604966402053833
train-epoch-step: 13-92 -- Loss: 0.18757076561450958
train-epoch-step: 13-93 -- Loss: 0.2227422147989273
train-epoch-step: 13-94 -- Loss: 0.28153178095817566
train-epoch-step: 13-95 -- Loss: 0.2295297384262085
train-epoch-step: 13-96 -- Loss: 0.26241201162338257
train-epoch-step: 13-97 -- Loss: 0.20001527667045593
train-epoch-step: 13-98 -- Loss: 0.17526835203170776
train-epoch-step: 13-99 -- Loss: 0.2090490758419037
train-epoch-step: 13-100 -- Loss: 0.2169508934020996
train-epoch-step: 13-101 -- Loss: 0.3020634651184082
train-epoch-step: 13-102 -- Loss: 0.27765077352523804
train-epoch-step: 13-103 -- Loss: 0.21622249484062195
train-epoch-step: 13-104 -- Loss: 0.16606125235557556
train-epoch-step: 13-105 -- Loss: 0.3081098794937134
train-epoch-step: 13-106 -- Loss: 0.19760721921920776
train-epoch-step: 13-107 -- Loss: 0.21030882000923157
train-epoch-step: 13-108 -- Loss: 0.21320129930973053
train-epoch-step: 13-109 -- Loss: 0.1718941330909729
train-epoch-step: 13-110 -- Loss: 0.2132616937160492
train-epoch-step: 13-111 -- Loss: 0.21184179186820984
train-epoch-step: 13-112 -- Loss: 0.2016477882862091
train-epoch-step: 13-113 -- Loss: 0.1864873170852661
train-epoch-step: 13-114 -- Loss: 0.23575963079929352
train-epoch-step: 13-115 -- Loss: 0.19815465807914734
train-epoch-step: 13-116 -- Loss: 0.16585201025009155
train-epoch-step: 13-117 -- Loss: 0.14415927231311798
train-epoch-step: 13-118 -- Loss: 0.2350425273180008
train-epoch-step: 13-119 -- Loss: 0.17740876972675323
train-epoch-step: 13-120 -- Loss: 0.2996087074279785
train-epoch-step: 13-121 -- Loss: 0.3107544779777527
train-epoch-step: 13-122 -- Loss: 0.24356386065483093
train-epoch-step: 13-123 -- Loss: 0.2368849217891693
train-epoch-step: 13-124 -- Loss: 0.1416613757610321
train-epoch-step: 13-125 -- Loss: 0.1764223277568817
train-epoch-step: 13-126 -- Loss: 0.2581515610218048
train-epoch-step: 13-127 -- Loss: 0.20335356891155243
train-epoch-step: 13-128 -- Loss: 0.1969304382801056
train-epoch-step: 13-129 -- Loss: 0.16881942749023438
train-epoch-step: 13-130 -- Loss: 0.21344566345214844
train-epoch-step: 13-131 -- Loss: 0.15934547781944275
train-epoch-step: 13-132 -- Loss: 0.2224101424217224
train-epoch-step: 13-133 -- Loss: 0.1414673626422882
train-epoch-step: 13-134 -- Loss: 0.23383405804634094
train-epoch-step: 13-135 -- Loss: 0.16207699477672577
train-epoch-step: 13-136 -- Loss: 0.15119925141334534
train-epoch-step: 13-137 -- Loss: 0.28977078199386597
train-epoch-step: 13-138 -- Loss: 0.3023034930229187
train-epoch-step: 13-139 -- Loss: 0.14622075855731964
train-epoch-step: 13-140 -- Loss: 0.23375442624092102
train-epoch-step: 13-141 -- Loss: 0.2540861666202545
train-epoch-step: 13-142 -- Loss: 0.23537611961364746
train-epoch-step: 13-143 -- Loss: 0.2037382423877716
train-epoch-step: 13-144 -- Loss: 0.21104101836681366
train-epoch-step: 13-145 -- Loss: 0.15752506256103516
train-epoch-step: 13-146 -- Loss: 0.20321224629878998
train-epoch-step: 13-147 -- Loss: 0.20715732872486115
train-epoch-step: 13-148 -- Loss: 0.1918448656797409
train-epoch-step: 13-149 -- Loss: 0.137300044298172
train-epoch-step: 13-150 -- Loss: 0.20727166533470154
train-epoch-step: 13-151 -- Loss: 0.2058270275592804
train-epoch-step: 13-152 -- Loss: 0.2198251187801361
train-epoch-step: 13-153 -- Loss: 0.3267781436443329
train-epoch-step: 13-154 -- Loss: 0.15037928521633148
train-epoch-step: 13-155 -- Loss: 0.15477503836154938
train-epoch-step: 13-156 -- Loss: 0.1433819681406021
train-epoch-step: 13-157 -- Loss: 0.18700627982616425
train-epoch-step: 13-158 -- Loss: 0.18757738173007965
train-epoch-step: 13-159 -- Loss: 0.20041801035404205
train-epoch-step: 13-160 -- Loss: 0.25238239765167236
train-epoch-step: 13-161 -- Loss: 0.2302161157131195
train-epoch-step: 13-162 -- Loss: 0.22998154163360596
train-epoch-step: 13-163 -- Loss: 0.21197231113910675
train-epoch-step: 13-164 -- Loss: 0.21308276057243347
train-epoch-step: 13-165 -- Loss: 0.18404267728328705
train-epoch-step: 13-166 -- Loss: 0.13969901204109192
train-epoch-step: 13-167 -- Loss: 0.13817188143730164
train-epoch-step: 13-168 -- Loss: 0.22840335965156555
train-epoch-step: 13-169 -- Loss: 0.16168305277824402
train-epoch-step: 13-170 -- Loss: 0.22391825914382935
train-epoch-step: 13-171 -- Loss: 0.15521886944770813
train-epoch-step: 13-172 -- Loss: 0.28729358315467834
train-epoch-step: 13-173 -- Loss: 0.14695888757705688
train-epoch-step: 13-174 -- Loss: 0.2657814621925354
train-epoch-step: 13-175 -- Loss: 0.20044739544391632
train-epoch-step: 13-176 -- Loss: 0.1574723869562149
train-epoch-step: 13-177 -- Loss: 0.2115267664194107
train-epoch-step: 13-178 -- Loss: 0.21040761470794678
train-epoch-step: 13-179 -- Loss: 0.1759873926639557
train-epoch-step: 13-180 -- Loss: 0.16618362069129944
train-epoch-step: 13-181 -- Loss: 0.19327275454998016
train-epoch-step: 13-182 -- Loss: 0.219099223613739
train-epoch-step: 13-183 -- Loss: 0.299175500869751
train-epoch-step: 13-184 -- Loss: 0.15533658862113953
train-epoch-step: 13-185 -- Loss: 0.164862260222435
train-epoch-step: 13-186 -- Loss: 0.20751139521598816
train-epoch-step: 13-187 -- Loss: 0.23553647100925446
train-epoch-step: 13-188 -- Loss: 0.19638197124004364
train-epoch-step: 13-189 -- Loss: 0.12967263162136078
train-epoch-step: 13-190 -- Loss: 0.2010381668806076
train-epoch-step: 13-191 -- Loss: 0.19642025232315063
train-epoch-step: 13-192 -- Loss: 0.270377516746521
train-epoch-step: 13-193 -- Loss: 0.2528593838214874
train-epoch-step: 13-194 -- Loss: 0.19824765622615814
train-epoch-step: 13-195 -- Loss: 0.17996102571487427
train-epoch-step: 13-196 -- Loss: 0.21787536144256592
train-epoch-step: 13-197 -- Loss: 0.1578880250453949
train-epoch-step: 13-198 -- Loss: 0.14795120060443878
train-epoch-step: 13-199 -- Loss: 0.17110571265220642
train-epoch-step: 13-200 -- Loss: 0.1381368339061737
train-epoch-step: 13-201 -- Loss: 0.22822149097919464
train-epoch-step: 13-202 -- Loss: 0.15083856880664825
train-epoch-step: 13-203 -- Loss: 0.1961974948644638
train-epoch-step: 13-204 -- Loss: 0.15937460958957672
train-epoch-step: 13-205 -- Loss: 0.21073733270168304
train-epoch-step: 13-206 -- Loss: 0.21705925464630127
train-epoch-step: 13-207 -- Loss: 0.15797612071037292
train-epoch-step: 13-208 -- Loss: 0.19980117678642273
train-epoch-step: 13-209 -- Loss: 0.1579957902431488
train-epoch-step: 13-210 -- Loss: 0.15641170740127563
train-epoch-step: 13-211 -- Loss: 0.2303849160671234
train-epoch-step: 13-212 -- Loss: 0.22263982892036438
train-epoch-step: 13-213 -- Loss: 0.14422433078289032
train-epoch-step: 13-214 -- Loss: 0.1650702804327011
train-epoch-step: 13-215 -- Loss: 0.15018704533576965
train-epoch-step: 13-216 -- Loss: 0.22758984565734863
train-epoch-step: 13-217 -- Loss: 0.23664285242557526
train-epoch-step: 13-218 -- Loss: 0.17902791500091553
train-epoch-step: 13-219 -- Loss: 0.20585596561431885
train-epoch-step: 13-220 -- Loss: 0.14926815032958984
train-epoch-step: 13-221 -- Loss: 0.22541941702365875
train-epoch-step: 13-222 -- Loss: 0.13322563469409943
train-epoch-step: 13-223 -- Loss: 0.19675953686237335
train-epoch-step: 13-224 -- Loss: 0.23052182793617249
train-epoch-step: 13-225 -- Loss: 0.33090513944625854
train-epoch-step: 13-226 -- Loss: 0.23750479519367218
train-epoch-step: 13-227 -- Loss: 0.2651422321796417
train-epoch-step: 13-228 -- Loss: 0.20456178486347198
train-epoch-step: 13-229 -- Loss: 0.20601089298725128
train-epoch-step: 13-230 -- Loss: 0.17877426743507385
train-epoch-step: 13-231 -- Loss: 0.19047686457633972
train-epoch-step: 13-232 -- Loss: 0.2259119153022766
train-epoch-step: 13-233 -- Loss: 0.09860536456108093
train-epoch-step: 13-234 -- Loss: 0.21204890310764313
train-epoch-step: 13-235 -- Loss: 0.17670679092407227
train-epoch-step: 13-236 -- Loss: 0.19799257814884186
train-epoch-step: 13-237 -- Loss: 0.27338990569114685
train-epoch-step: 13-238 -- Loss: 0.17256617546081543
train-epoch-step: 13-239 -- Loss: 0.1469951868057251
train-epoch-step: 13-240 -- Loss: 0.24483609199523926
train-epoch-step: 13-241 -- Loss: 0.17789986729621887
train-epoch-step: 13-242 -- Loss: 0.24966296553611755
train-epoch-step: 13-243 -- Loss: 0.2569809556007385
train-epoch-step: 13-244 -- Loss: 0.225589320063591
train-epoch-step: 13-245 -- Loss: 0.2390683889389038
train-epoch-step: 13-246 -- Loss: 0.2575957179069519
train-epoch-step: 13-247 -- Loss: 0.26911911368370056
train-epoch-step: 13-248 -- Loss: 0.21139183640480042
train-epoch-step: 13-249 -- Loss: 0.1594340205192566
train-epoch-step: 13-250 -- Loss: 0.23271667957305908
train-epoch-step: 13-251 -- Loss: 0.1209799125790596
train-epoch-step: 13-252 -- Loss: 0.2232999950647354
train-epoch-step: 13-253 -- Loss: 0.15829214453697205
train-epoch-step: 13-254 -- Loss: 0.25124019384384155
train-epoch-step: 13-255 -- Loss: 0.1659286916255951
train-epoch-step: 13-256 -- Loss: 0.18159769475460052
train-epoch-step: 13-257 -- Loss: 0.2209196835756302
train-epoch-step: 13-258 -- Loss: 0.16280904412269592
train-epoch-step: 13-259 -- Loss: 0.14194613695144653
train-epoch-step: 13-260 -- Loss: 0.24330265820026398
train-epoch-step: 13-261 -- Loss: 0.20775578916072845
train-epoch-step: 13-262 -- Loss: 0.3346236050128937
train-epoch-step: 13-263 -- Loss: 0.22700317203998566
train-epoch-step: 13-264 -- Loss: 0.1913307011127472
train-epoch-step: 13-265 -- Loss: 0.13699975609779358
train-epoch-step: 13-266 -- Loss: 0.16488228738307953
train-epoch-step: 13-267 -- Loss: 0.15123504400253296
train-epoch-step: 13-268 -- Loss: 0.13472206890583038
train-epoch-step: 13-269 -- Loss: 0.19265758991241455
train-epoch-step: 13-270 -- Loss: 0.1228702962398529
train-epoch-step: 13-271 -- Loss: 0.1647649109363556
train-epoch-step: 13-272 -- Loss: 0.13171499967575073
train-epoch-step: 13-273 -- Loss: 0.1388707309961319
train-epoch-step: 13-274 -- Loss: 0.20549465715885162
train-epoch-step: 13-275 -- Loss: 0.23007196187973022
train-epoch-step: 13-276 -- Loss: 0.18080267310142517
train-epoch-step: 13-277 -- Loss: 0.16874322295188904
train-epoch-step: 13-278 -- Loss: 0.16601139307022095
train-epoch-step: 13-279 -- Loss: 0.163755863904953
train-epoch-step: 13-280 -- Loss: 0.2398841232061386
train-epoch-step: 13-281 -- Loss: 0.20869018137454987
train-epoch-step: 13-282 -- Loss: 0.1583465337753296
train-epoch-step: 13-283 -- Loss: 0.13058754801750183
train-epoch-step: 13-284 -- Loss: 0.16899695992469788
train-epoch-step: 13-285 -- Loss: 0.2152632176876068
train-epoch-step: 13-286 -- Loss: 0.18009799718856812
train-epoch-step: 13-287 -- Loss: 0.23623837530612946
train-epoch-step: 13-288 -- Loss: 0.10449004918336868
train-epoch-step: 13-289 -- Loss: 0.14244338870048523
train-epoch-step: 13-290 -- Loss: 0.21496126055717468
train-epoch-step: 13-291 -- Loss: 0.13206088542938232
train-epoch-step: 13-292 -- Loss: 0.1676749885082245
train-epoch-step: 13-293 -- Loss: 0.15880009531974792
train-epoch-step: 13-294 -- Loss: 0.18747705221176147
train-epoch-step: 13-295 -- Loss: 0.33051127195358276
train-epoch-step: 13-296 -- Loss: 0.18249477446079254
train-epoch-step: 13-297 -- Loss: 0.19905701279640198
train-epoch-step: 13-298 -- Loss: 0.2831653952598572
train-epoch-step: 13-299 -- Loss: 0.17695611715316772
train-epoch-step: 13-300 -- Loss: 0.19043920934200287
train-epoch-step: 13-301 -- Loss: 0.19069984555244446
train-epoch-step: 13-302 -- Loss: 0.25258898735046387
train-epoch-step: 13-303 -- Loss: 0.23875203728675842
train-epoch-step: 13-304 -- Loss: 0.16160085797309875
train-epoch-step: 13-305 -- Loss: 0.1736939400434494
train-epoch-step: 13-306 -- Loss: 0.2695462703704834
train-epoch-step: 13-307 -- Loss: 0.18779106438159943
train-epoch-step: 13-308 -- Loss: 0.2646797001361847
train-epoch-step: 13-309 -- Loss: 0.1716529130935669
train-epoch-step: 13-310 -- Loss: 0.19105659425258636
train-epoch-step: 13-311 -- Loss: 0.18562552332878113
train-epoch-step: 13-312 -- Loss: 0.24038077890872955
train-epoch-step: 13-313 -- Loss: 0.11601550132036209
train-epoch-step: 13-314 -- Loss: 0.22857293486595154
train-epoch-step: 13-315 -- Loss: 0.19022251665592194
train-epoch-step: 13-316 -- Loss: 0.1696961373090744
train-epoch-step: 13-317 -- Loss: 0.1650615930557251
train-epoch-step: 13-318 -- Loss: 0.1855696439743042
train-epoch-step: 13-319 -- Loss: 0.20353028178215027
train-epoch-step: 13-320 -- Loss: 0.1301220804452896
train-epoch-step: 13-321 -- Loss: 0.14916303753852844
train-epoch-step: 13-322 -- Loss: 0.23670318722724915
train-epoch-step: 13-323 -- Loss: 0.1849607527256012
train-epoch-step: 13-324 -- Loss: 0.30261850357055664
train-epoch-step: 13-325 -- Loss: 0.17460128664970398
train-epoch-step: 13-326 -- Loss: 0.19083251059055328
train-epoch-step: 13-327 -- Loss: 0.2383587658405304
train-epoch-step: 13-328 -- Loss: 0.2152964025735855
train-epoch-step: 13-329 -- Loss: 0.3619758188724518
train-epoch-step: 13-330 -- Loss: 0.399081826210022
train-epoch-step: 13-331 -- Loss: 0.24676667153835297
train-epoch-step: 13-332 -- Loss: 0.11911556124687195
train-epoch-step: 13-333 -- Loss: 0.210065096616745
train-epoch-step: 13-334 -- Loss: 0.17567184567451477
train-epoch-step: 13-335 -- Loss: 0.19009262323379517
train-epoch-step: 13-336 -- Loss: 0.18790000677108765
train-epoch-step: 13-337 -- Loss: 0.24929562211036682
train-epoch-step: 13-338 -- Loss: 0.1769218146800995
train-epoch-step: 13-339 -- Loss: 0.17089401185512543
train-epoch-step: 13-340 -- Loss: 0.22407937049865723
train-epoch-step: 13-341 -- Loss: 0.1565183848142624
train-epoch-step: 13-342 -- Loss: 0.19140008091926575
train-epoch-step: 13-343 -- Loss: 0.17972275614738464
train-epoch-step: 13-344 -- Loss: 0.19754424691200256
train-epoch-step: 13-345 -- Loss: 0.14584462344646454
train-epoch-step: 13-346 -- Loss: 0.23218296468257904
train-epoch-step: 13-347 -- Loss: 0.17196384072303772
train-epoch-step: 13-348 -- Loss: 0.22720275819301605
train-epoch-step: 13-349 -- Loss: 0.2434844970703125
train-epoch-step: 13-350 -- Loss: 0.29947832226753235
train-epoch-step: 13-351 -- Loss: 0.22577649354934692
train-epoch-step: 13-352 -- Loss: 0.15025506913661957
train-epoch-step: 13-353 -- Loss: 0.22330021858215332
train-epoch-step: 13-354 -- Loss: 0.3217771053314209
train-epoch-step: 13-355 -- Loss: 0.13452208042144775
train-epoch-step: 13-356 -- Loss: 0.12951897084712982
train-epoch-step: 13-357 -- Loss: 0.2097114771604538
train-epoch-step: 13-358 -- Loss: 0.20607990026474
train-epoch-step: 13-359 -- Loss: 0.16420166194438934
train-epoch-step: 13-360 -- Loss: 0.135249063372612
train-epoch-step: 13-361 -- Loss: 0.2756150960922241
train-epoch-step: 13-362 -- Loss: 0.1905209720134735
train-epoch-step: 13-363 -- Loss: 0.1397314965724945
train-epoch-step: 13-364 -- Loss: 0.20514291524887085
train-epoch-step: 13-365 -- Loss: 0.19680264592170715
train-epoch-step: 13-366 -- Loss: 0.22953948378562927
train-epoch-step: 13-367 -- Loss: 0.290344774723053
train-epoch-step: 13-368 -- Loss: 0.23220627009868622
train-epoch-step: 13-369 -- Loss: 0.3101772367954254
train-epoch-step: 13-370 -- Loss: 0.14418500661849976
train-epoch-step: 13-371 -- Loss: 0.13297250866889954
train-epoch-step: 13-372 -- Loss: 0.16141557693481445
train-epoch-step: 13-373 -- Loss: 0.22285327315330505
train-epoch-step: 13-374 -- Loss: 0.17082858085632324
train-epoch-step: 13-375 -- Loss: 0.3054099380970001
train-epoch-step: 13-376 -- Loss: 0.20672756433486938
train-epoch-step: 13-377 -- Loss: 0.26147782802581787
train-epoch-step: 13-378 -- Loss: 0.2419668436050415
train-epoch-step: 13-379 -- Loss: 0.1387118101119995
train-epoch-step: 13-380 -- Loss: 0.10001613199710846
train-epoch-step: 13-381 -- Loss: 0.2807145416736603
train-epoch-step: 13-382 -- Loss: 0.2617681622505188
train-epoch-step: 13-383 -- Loss: 0.19547870755195618
train-epoch-step: 13-384 -- Loss: 0.2582259774208069
train-epoch-step: 13-385 -- Loss: 0.22341062128543854
train-epoch-step: 13-386 -- Loss: 0.2112743854522705
train-epoch-step: 13-387 -- Loss: 0.23433327674865723
train-epoch-step: 13-388 -- Loss: 0.2485426366329193
train-epoch-step: 13-389 -- Loss: 0.1999693065881729
train-epoch-step: 13-390 -- Loss: 0.1535153090953827
train-epoch-step: 13-391 -- Loss: 0.16454806923866272
train-epoch-step: 13-392 -- Loss: 0.20711900293827057
train-epoch-step: 13-393 -- Loss: 0.1797473430633545
train-epoch-step: 13-394 -- Loss: 0.24224434792995453
train-epoch-step: 13-395 -- Loss: 0.18047137558460236
train-epoch-step: 13-396 -- Loss: 0.1457650065422058
train-epoch-step: 13-397 -- Loss: 0.1448558121919632
train-epoch-step: 13-398 -- Loss: 0.22200003266334534
train-epoch-step: 13-399 -- Loss: 0.2029368132352829
train-epoch-step: 13-400 -- Loss: 0.32334059476852417
train-epoch-step: 13-401 -- Loss: 0.1305648684501648
train-epoch-step: 13-402 -- Loss: 0.28739941120147705
train-epoch-step: 13-403 -- Loss: 0.17931264638900757
train-epoch-step: 13-404 -- Loss: 0.1583416759967804
train-epoch-step: 13-405 -- Loss: 0.16918575763702393
train-epoch-step: 13-406 -- Loss: 0.1922406554222107
train-epoch-step: 13-407 -- Loss: 0.13215993344783783
train-epoch-step: 13-408 -- Loss: 0.17967115342617035
train-epoch-step: 13-409 -- Loss: 0.19205844402313232
train-epoch-step: 13-410 -- Loss: 0.1935785561800003
train-epoch-step: 13-411 -- Loss: 0.2232079803943634
train-epoch-step: 13-412 -- Loss: 0.14475573599338531
train-epoch-step: 13-413 -- Loss: 0.16527080535888672
train-epoch-step: 13-414 -- Loss: 0.15485629439353943
train-epoch-step: 13-415 -- Loss: 0.16005414724349976
train-epoch-step: 13-416 -- Loss: 0.2855994999408722
train-epoch-step: 13-417 -- Loss: 0.22155030071735382
train-epoch-step: 13-418 -- Loss: 0.2704983651638031
train-epoch-step: 13-419 -- Loss: 0.19697080552577972
train-epoch-step: 13-420 -- Loss: 0.17169779539108276
train-epoch-step: 13-421 -- Loss: 0.20641157031059265
train-epoch-step: 13-422 -- Loss: 0.17115089297294617
train-epoch-step: 13-423 -- Loss: 0.20511654019355774
train-epoch-step: 13-424 -- Loss: 0.15471039712429047
train-epoch-step: 13-425 -- Loss: 0.1989687979221344
train-epoch-step: 13-426 -- Loss: 0.18667642772197723
train-epoch-step: 13-427 -- Loss: 0.17509207129478455
train-epoch-step: 13-428 -- Loss: 0.23126420378684998
train-epoch-step: 13-429 -- Loss: 0.1883966624736786
train-epoch-step: 13-430 -- Loss: 0.1808529645204544
train-epoch-step: 13-431 -- Loss: 0.18653687834739685
train-epoch-step: 13-432 -- Loss: 0.26784712076187134
train-epoch-step: 13-433 -- Loss: 0.15551882982254028
train-epoch-step: 13-434 -- Loss: 0.1434461772441864
train-epoch-step: 13-435 -- Loss: 0.18817314505577087
train-epoch-step: 13-436 -- Loss: 0.17729642987251282
train-epoch-step: 13-437 -- Loss: 0.15369737148284912
train-epoch-step: 13-438 -- Loss: 0.2265159636735916
train-epoch-step: 13-439 -- Loss: 0.2975544333457947
train-epoch-step: 13-440 -- Loss: 0.14731858670711517
train-epoch-step: 13-441 -- Loss: 0.24399727582931519
train-epoch-step: 13-442 -- Loss: 0.21699342131614685
train-epoch-step: 13-443 -- Loss: 0.18760037422180176
train-epoch-step: 13-444 -- Loss: 0.22893169522285461
train-epoch-step: 13-445 -- Loss: 0.2052105814218521
train-epoch-step: 13-446 -- Loss: 0.18279965221881866
train-epoch-step: 13-447 -- Loss: 0.2239120453596115
train-epoch-step: 13-448 -- Loss: 0.2806079387664795
train-epoch-step: 13-449 -- Loss: 0.22753414511680603
train-epoch-step: 13-450 -- Loss: 0.21141952276229858
train-epoch-step: 13-451 -- Loss: 0.16175128519535065
train-epoch-step: 13-452 -- Loss: 0.15296214818954468
train-epoch-step: 13-453 -- Loss: 0.10324707627296448
train-epoch-step: 13-454 -- Loss: 0.26342737674713135
train-epoch-step: 13-455 -- Loss: 0.14837007224559784
train-epoch-step: 13-456 -- Loss: 0.14281870424747467
train-epoch-step: 13-457 -- Loss: 0.2632829248905182
train-epoch-step: 13-458 -- Loss: 0.1703188568353653
train-epoch-step: 13-459 -- Loss: 0.24468077719211578
train-epoch-step: 13-460 -- Loss: 0.14005142450332642
train-epoch-step: 13-461 -- Loss: 0.1560264229774475
train-epoch-step: 13-462 -- Loss: 0.17976269125938416
train-epoch-step: 13-463 -- Loss: 0.15189820528030396
train-epoch-step: 13-464 -- Loss: 0.19398829340934753
train-epoch-step: 13-465 -- Loss: 0.2727443277835846
train-epoch-step: 13-466 -- Loss: 0.21659323573112488
train-epoch-step: 13-467 -- Loss: 0.1280553936958313
train-epoch-step: 13-468 -- Loss: 0.21509820222854614
train-epoch-step: 13-469 -- Loss: 0.26432275772094727
train-epoch-step: 13-470 -- Loss: 0.20309953391551971
train-epoch-step: 13-471 -- Loss: 0.16872236132621765
train-epoch-step: 13-472 -- Loss: 0.1728648543357849
train-epoch-step: 13-473 -- Loss: 0.19414770603179932
train-epoch-step: 13-474 -- Loss: 0.13600660860538483
train-epoch-step: 13-475 -- Loss: 0.12661412358283997
train-epoch-step: 13-476 -- Loss: 0.2243521511554718
train-epoch-step: 13-477 -- Loss: 0.23553921282291412
train-epoch-step: 13-478 -- Loss: 0.21609702706336975
train-epoch-step: 13-479 -- Loss: 0.16703441739082336
train-epoch-step: 13-480 -- Loss: 0.20993377268314362
train-epoch-step: 13-481 -- Loss: 0.31070637702941895
train-epoch-step: 13-482 -- Loss: 0.29364755749702454
train-epoch-step: 13-483 -- Loss: 0.2060692012310028
train-epoch-step: 13-484 -- Loss: 0.23386847972869873
train-epoch-step: 13-485 -- Loss: 0.14758992195129395
train-epoch-step: 13-486 -- Loss: 0.2748124897480011
train-epoch-step: 13-487 -- Loss: 0.24662187695503235
train-epoch-step: 13-488 -- Loss: 0.2086738795042038
train-epoch-step: 13-489 -- Loss: 0.24055160582065582
train-epoch-step: 13-490 -- Loss: 0.1534850001335144
train-epoch-step: 13-491 -- Loss: 0.15619277954101562
train-epoch-step: 13-492 -- Loss: 0.13922621309757233
train-epoch-step: 13-493 -- Loss: 0.24727608263492584
train-epoch-step: 13-494 -- Loss: 0.24462196230888367
train-epoch-step: 13-495 -- Loss: 0.22853386402130127
train-epoch-step: 13-496 -- Loss: 0.15059441328048706
train-epoch-step: 13-497 -- Loss: 0.1991267204284668
train-epoch-step: 13-498 -- Loss: 0.16400665044784546
train-epoch-step: 13-499 -- Loss: 0.19198480248451233
train-epoch-step: 13-500 -- Loss: 0.1746387481689453
train-epoch-step: 13-501 -- Loss: 0.24897611141204834
train-epoch-step: 13-502 -- Loss: 0.18389315903186798
train-epoch-step: 13-503 -- Loss: 0.23973137140274048
train-epoch-step: 13-504 -- Loss: 0.13756239414215088
train-epoch-step: 13-505 -- Loss: 0.1890132874250412
train-epoch-step: 13-506 -- Loss: 0.13255518674850464
train-epoch-step: 13-507 -- Loss: 0.20187470316886902
train-epoch-step: 13-508 -- Loss: 0.19408656656742096
train-epoch-step: 13-509 -- Loss: 0.18311335146427155
train-epoch-step: 13-510 -- Loss: 0.13856182992458344
train-epoch-step: 13-511 -- Loss: 0.2414422631263733
train-epoch-step: 13-512 -- Loss: 0.19626113772392273
train-epoch-step: 13-513 -- Loss: 0.23414961993694305
train-epoch-step: 13-514 -- Loss: 0.16520535945892334
train-epoch-step: 13-515 -- Loss: 0.18037950992584229
train-epoch-step: 13-516 -- Loss: 0.19023045897483826
train-epoch-step: 13-517 -- Loss: 0.1940644532442093
train-epoch-step: 13-518 -- Loss: 0.1535395085811615
train-epoch-step: 13-519 -- Loss: 0.14556744694709778
train-epoch-step: 13-520 -- Loss: 0.20977374911308289
train-epoch-step: 13-521 -- Loss: 0.2519493103027344
train-epoch-step: 13-522 -- Loss: 0.1963970810174942
train-epoch-step: 13-523 -- Loss: 0.16862431168556213
train-epoch-step: 13-524 -- Loss: 0.18672668933868408
train-epoch-step: 13-525 -- Loss: 0.20678263902664185
train-epoch-step: 13-526 -- Loss: 0.1424175500869751
train-epoch-step: 13-527 -- Loss: 0.17734533548355103
train-epoch-step: 13-528 -- Loss: 0.17645594477653503
train-epoch-step: 13-529 -- Loss: 0.17844121158123016
train-epoch-step: 13-530 -- Loss: 0.1864728182554245
train-epoch-step: 13-531 -- Loss: 0.22257286310195923
train-epoch-step: 13-532 -- Loss: 0.19215083122253418
train-epoch-step: 13-533 -- Loss: 0.1837155967950821
train-epoch-step: 13-534 -- Loss: 0.15933385491371155
train-epoch-step: 13-535 -- Loss: 0.29757213592529297
train-epoch-step: 13-536 -- Loss: 0.17701880633831024
train-epoch-step: 13-537 -- Loss: 0.16837385296821594
train-epoch-step: 13-538 -- Loss: 0.1129305437207222
train-epoch-step: 13-539 -- Loss: 0.2261475920677185
train-epoch-step: 13-540 -- Loss: 0.15233096480369568
train-epoch-step: 13-541 -- Loss: 0.22729447484016418
train-epoch-step: 13-542 -- Loss: 0.25481146574020386
train-epoch-step: 13-543 -- Loss: 0.1815405786037445
train-epoch-step: 13-544 -- Loss: 0.24496470391750336
train-epoch-step: 13-545 -- Loss: 0.2236812263727188
train-epoch-step: 13-546 -- Loss: 0.23956525325775146
train-epoch-step: 13-547 -- Loss: 0.19899539649486542
train-epoch-step: 13-548 -- Loss: 0.10263217240571976
train-epoch-step: 13-549 -- Loss: 0.17105600237846375
train-epoch-step: 13-550 -- Loss: 0.22111810743808746
train-epoch-step: 13-551 -- Loss: 0.17769689857959747
train-epoch-step: 13-552 -- Loss: 0.1477563977241516
train-epoch-step: 13-553 -- Loss: 0.2082827091217041
train-epoch-step: 13-554 -- Loss: 0.2093181312084198
train-epoch-step: 13-555 -- Loss: 0.2363417148590088
train-epoch-step: 13-556 -- Loss: 0.1782779097557068
train-epoch-step: 13-557 -- Loss: 0.25681138038635254
train-epoch-step: 13-558 -- Loss: 0.2546243965625763
train-epoch-step: 13-559 -- Loss: 0.15937024354934692
train-epoch-step: 13-560 -- Loss: 0.2208901047706604
train-epoch-step: 13-561 -- Loss: 0.20833297073841095
train-epoch-step: 13-562 -- Loss: 0.1976504772901535
train-epoch-step: 13-563 -- Loss: 0.2081179916858673
train-epoch-step: 13-564 -- Loss: 0.11112953722476959
train-epoch-step: 13-565 -- Loss: 0.20464354753494263
train-epoch-step: 13-566 -- Loss: 0.17690415680408478
train-epoch-step: 13-567 -- Loss: 0.23531627655029297
train-epoch-step: 13-568 -- Loss: 0.17330190539360046
train-epoch-step: 13-569 -- Loss: 0.2657627463340759
train-epoch-step: 13-570 -- Loss: 0.19980229437351227
train-epoch-step: 13-571 -- Loss: 0.23768216371536255
train-epoch-step: 13-572 -- Loss: 0.298408567905426
train-epoch-step: 13-573 -- Loss: 0.22341768443584442
train-epoch-step: 13-574 -- Loss: 0.2768380641937256
train-epoch-step: 13-575 -- Loss: 0.3478257358074188
train-epoch-step: 13-576 -- Loss: 0.13621273636817932
train-epoch-step: 13-577 -- Loss: 0.19495248794555664
train-epoch-step: 13-578 -- Loss: 0.23901638388633728
train-epoch-step: 13-579 -- Loss: 0.19042536616325378
train-epoch-step: 13-580 -- Loss: 0.21766462922096252
train-epoch-step: 13-581 -- Loss: 0.16426874697208405
train-epoch-step: 13-582 -- Loss: 0.22729270160198212
train-epoch-step: 13-583 -- Loss: 0.25985854864120483
train-epoch-step: 13-584 -- Loss: 0.21440653502941132
train-epoch-step: 13-585 -- Loss: 0.21483314037322998
train-epoch-step: 13-586 -- Loss: 0.28105688095092773
train-epoch-step: 13-587 -- Loss: 0.17745433747768402
train-epoch-step: 13-588 -- Loss: 0.14182311296463013
val-epoch-step: 13-589 -- Loss: 0.22846247255802155
val-epoch-step: 13-590 -- Loss: 0.1647167205810547
val-epoch-step: 13-591 -- Loss: 0.23813381791114807
val-epoch-step: 13-592 -- Loss: 0.19973163306713104
val-epoch-step: 13-593 -- Loss: 0.16984273493289948
val-epoch-step: 13-594 -- Loss: 0.36910319328308105
val-epoch-step: 13-595 -- Loss: 0.20494630932807922
val-epoch-step: 13-596 -- Loss: 0.23904573917388916
val-epoch-step: 13-597 -- Loss: 0.19664287567138672
val-epoch-step: 13-598 -- Loss: 0.16432787477970123
val-epoch-step: 13-599 -- Loss: 0.2020024210214615
val-epoch-step: 13-600 -- Loss: 0.24763700366020203
val-epoch-step: 13-601 -- Loss: 0.17340148985385895
val-epoch-step: 13-602 -- Loss: 0.1524459421634674
val-epoch-step: 13-603 -- Loss: 0.19114471971988678
val-epoch-step: 13-604 -- Loss: 0.16528871655464172
val-epoch-step: 13-605 -- Loss: 0.16753239929676056
val-epoch-step: 13-606 -- Loss: 0.28215399384498596
val-epoch-step: 13-607 -- Loss: 0.14529764652252197
val-epoch-step: 13-608 -- Loss: 0.2709825038909912
val-epoch-step: 13-609 -- Loss: 0.19642546772956848
val-epoch-step: 13-610 -- Loss: 0.19756785035133362
val-epoch-step: 13-611 -- Loss: 0.17464305460453033
val-epoch-step: 13-612 -- Loss: 0.42638376355171204
val-epoch-step: 13-613 -- Loss: 0.192556232213974
val-epoch-step: 13-614 -- Loss: 0.1735663115978241
val-epoch-step: 13-615 -- Loss: 0.20339947938919067
val-epoch-step: 13-616 -- Loss: 0.16863328218460083
val-epoch-step: 13-617 -- Loss: 0.21635793149471283
val-epoch-step: 13-618 -- Loss: 0.21187210083007812
val-epoch-step: 13-619 -- Loss: 0.23385515809059143
val-epoch-step: 13-620 -- Loss: 0.16319145262241364
val-epoch-step: 13-621 -- Loss: 0.14092443883419037
val-epoch-step: 13-622 -- Loss: 0.16189026832580566
val-epoch-step: 13-623 -- Loss: 0.16825182735919952
val-epoch-step: 13-624 -- Loss: 0.16900020837783813
val-epoch-step: 13-625 -- Loss: 0.17814669013023376
val-epoch-step: 13-626 -- Loss: 0.15756282210350037
val-epoch-step: 13-627 -- Loss: 0.21751996874809265
val-epoch-step: 13-628 -- Loss: 0.615434467792511
val-epoch-step: 13-629 -- Loss: 0.246827632188797
val-epoch-step: 13-630 -- Loss: 0.3715406656265259
val-epoch-step: 13-631 -- Loss: 0.15541449189186096
val-epoch-step: 13-632 -- Loss: 0.216805100440979
val-epoch-step: 13-633 -- Loss: 0.17301711440086365
val-epoch-step: 13-634 -- Loss: 0.1537681370973587
val-epoch-step: 13-635 -- Loss: 0.13711731135845184
val-epoch-step: 13-636 -- Loss: 0.18677642941474915
val-epoch-step: 13-637 -- Loss: 0.20197997987270355
val-epoch-step: 13-638 -- Loss: 0.17374707758426666
val-epoch-step: 13-639 -- Loss: 0.2792901396751404
val-epoch-step: 13-640 -- Loss: 0.2810896635055542
val-epoch-step: 13-641 -- Loss: 0.13901641964912415
val-epoch-step: 13-642 -- Loss: 0.21478460729122162
val-epoch-step: 13-643 -- Loss: 0.21833553910255432
val-epoch-step: 13-644 -- Loss: 0.17795848846435547
val-epoch-step: 13-645 -- Loss: 0.23988738656044006
val-epoch-step: 13-646 -- Loss: 0.15227951109409332
val-epoch-step: 13-647 -- Loss: 0.157382071018219
val-epoch-step: 13-648 -- Loss: 0.178645059466362
val-epoch-step: 13-649 -- Loss: 0.23497158288955688
val-epoch-step: 13-650 -- Loss: 0.2751051187515259
val-epoch-step: 13-651 -- Loss: 0.16000202298164368
val-epoch-step: 13-652 -- Loss: 0.1774948537349701
val-epoch-step: 13-653 -- Loss: 0.2213258594274521
val-epoch-step: 13-654 -- Loss: 0.12443055212497711
Epoch: 13 -- Train Loss: tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 14-0 -- Loss: 0.25865036249160767
train-epoch-step: 14-1 -- Loss: 0.15752896666526794
train-epoch-step: 14-2 -- Loss: 0.22041703760623932
train-epoch-step: 14-3 -- Loss: 0.16299723088741302
train-epoch-step: 14-4 -- Loss: 0.18015193939208984
train-epoch-step: 14-5 -- Loss: 0.21904978156089783
train-epoch-step: 14-6 -- Loss: 0.2509302496910095
train-epoch-step: 14-7 -- Loss: 0.19070719182491302
train-epoch-step: 14-8 -- Loss: 0.22428368031978607
train-epoch-step: 14-9 -- Loss: 0.2616509199142456
train-epoch-step: 14-10 -- Loss: 0.23312169313430786
train-epoch-step: 14-11 -- Loss: 0.19851054251194
train-epoch-step: 14-12 -- Loss: 0.17766514420509338
train-epoch-step: 14-13 -- Loss: 0.20031848549842834
train-epoch-step: 14-14 -- Loss: 0.17871183156967163
train-epoch-step: 14-15 -- Loss: 0.1782168447971344
train-epoch-step: 14-16 -- Loss: 0.17891925573349
train-epoch-step: 14-17 -- Loss: 0.24670612812042236
train-epoch-step: 14-18 -- Loss: 0.22287866473197937
train-epoch-step: 14-19 -- Loss: 0.14711257815361023
train-epoch-step: 14-20 -- Loss: 0.25834012031555176
train-epoch-step: 14-21 -- Loss: 0.304349809885025
train-epoch-step: 14-22 -- Loss: 0.15961185097694397
train-epoch-step: 14-23 -- Loss: 0.17953740060329437
train-epoch-step: 14-24 -- Loss: 0.1445489227771759
train-epoch-step: 14-25 -- Loss: 0.255932480096817
train-epoch-step: 14-26 -- Loss: 0.21590356528759003
train-epoch-step: 14-27 -- Loss: 0.2723018229007721
train-epoch-step: 14-28 -- Loss: 0.1353224217891693
train-epoch-step: 14-29 -- Loss: 0.2608996033668518
train-epoch-step: 14-30 -- Loss: 0.12063930928707123
train-epoch-step: 14-31 -- Loss: 0.16462844610214233
train-epoch-step: 14-32 -- Loss: 0.18416765332221985
train-epoch-step: 14-33 -- Loss: 0.2965938448905945
train-epoch-step: 14-34 -- Loss: 0.18916846811771393
train-epoch-step: 14-35 -- Loss: 0.277614951133728
train-epoch-step: 14-36 -- Loss: 0.15043875575065613
train-epoch-step: 14-37 -- Loss: 0.1558675467967987
train-epoch-step: 14-38 -- Loss: 0.20376741886138916
train-epoch-step: 14-39 -- Loss: 0.254528671503067
train-epoch-step: 14-40 -- Loss: 0.22107623517513275
train-epoch-step: 14-41 -- Loss: 0.24109715223312378
train-epoch-step: 14-42 -- Loss: 0.1614077091217041
train-epoch-step: 14-43 -- Loss: 0.3120037913322449
train-epoch-step: 14-44 -- Loss: 0.14194101095199585
train-epoch-step: 14-45 -- Loss: 0.13694770634174347
train-epoch-step: 14-46 -- Loss: 0.19690732657909393
train-epoch-step: 14-47 -- Loss: 0.2612226605415344
train-epoch-step: 14-48 -- Loss: 0.1715998500585556
train-epoch-step: 14-49 -- Loss: 0.23649083077907562
train-epoch-step: 14-50 -- Loss: 0.1296491175889969
train-epoch-step: 14-51 -- Loss: 0.2174256145954132
train-epoch-step: 14-52 -- Loss: 0.1783064603805542
train-epoch-step: 14-53 -- Loss: 0.2500835061073303
train-epoch-step: 14-54 -- Loss: 0.3184531331062317
train-epoch-step: 14-55 -- Loss: 0.1949274241924286
train-epoch-step: 14-56 -- Loss: 0.19943438470363617
train-epoch-step: 14-57 -- Loss: 0.26098254323005676
train-epoch-step: 14-58 -- Loss: 0.3053109645843506
train-epoch-step: 14-59 -- Loss: 0.2948203384876251
train-epoch-step: 14-60 -- Loss: 0.1425899863243103
train-epoch-step: 14-61 -- Loss: 0.2270677536725998
train-epoch-step: 14-62 -- Loss: 0.20764920115470886
train-epoch-step: 14-63 -- Loss: 0.15639960765838623
train-epoch-step: 14-64 -- Loss: 0.17015859484672546
train-epoch-step: 14-65 -- Loss: 0.20740267634391785
train-epoch-step: 14-66 -- Loss: 0.12299038469791412
train-epoch-step: 14-67 -- Loss: 0.14234675467014313
train-epoch-step: 14-68 -- Loss: 0.24772803485393524
train-epoch-step: 14-69 -- Loss: 0.13986913859844208
train-epoch-step: 14-70 -- Loss: 0.2377912700176239
train-epoch-step: 14-71 -- Loss: 0.2905116379261017
train-epoch-step: 14-72 -- Loss: 0.20453429222106934
train-epoch-step: 14-73 -- Loss: 0.2313428372144699
train-epoch-step: 14-74 -- Loss: 0.10987982898950577
train-epoch-step: 14-75 -- Loss: 0.14450716972351074
train-epoch-step: 14-76 -- Loss: 0.1644616723060608
train-epoch-step: 14-77 -- Loss: 0.25230103731155396
train-epoch-step: 14-78 -- Loss: 0.2966703176498413
train-epoch-step: 14-79 -- Loss: 0.21511778235435486
train-epoch-step: 14-80 -- Loss: 0.2955012619495392
train-epoch-step: 14-81 -- Loss: 0.13953565061092377
train-epoch-step: 14-82 -- Loss: 0.2835290729999542
train-epoch-step: 14-83 -- Loss: 0.23574702441692352
train-epoch-step: 14-84 -- Loss: 0.2216404676437378
train-epoch-step: 14-85 -- Loss: 0.1964588463306427
train-epoch-step: 14-86 -- Loss: 0.14577491581439972
train-epoch-step: 14-87 -- Loss: 0.2597881257534027
train-epoch-step: 14-88 -- Loss: 0.1539861559867859
train-epoch-step: 14-89 -- Loss: 0.21490377187728882
train-epoch-step: 14-90 -- Loss: 0.21968713402748108
train-epoch-step: 14-91 -- Loss: 0.27883273363113403
train-epoch-step: 14-92 -- Loss: 0.17055431008338928
train-epoch-step: 14-93 -- Loss: 0.19396266341209412
train-epoch-step: 14-94 -- Loss: 0.2580562233924866
train-epoch-step: 14-95 -- Loss: 0.22218680381774902
train-epoch-step: 14-96 -- Loss: 0.25151264667510986
train-epoch-step: 14-97 -- Loss: 0.20088385045528412
train-epoch-step: 14-98 -- Loss: 0.18118520081043243
train-epoch-step: 14-99 -- Loss: 0.2053529918193817
train-epoch-step: 14-100 -- Loss: 0.20328646898269653
train-epoch-step: 14-101 -- Loss: 0.3049388825893402
train-epoch-step: 14-102 -- Loss: 0.25889477133750916
train-epoch-step: 14-103 -- Loss: 0.20658113062381744
train-epoch-step: 14-104 -- Loss: 0.1673634797334671
train-epoch-step: 14-105 -- Loss: 0.35693493485450745
train-epoch-step: 14-106 -- Loss: 0.18878279626369476
train-epoch-step: 14-107 -- Loss: 0.2099149078130722
train-epoch-step: 14-108 -- Loss: 0.21008290350437164
train-epoch-step: 14-109 -- Loss: 0.16891279816627502
train-epoch-step: 14-110 -- Loss: 0.2116488516330719
train-epoch-step: 14-111 -- Loss: 0.2060171663761139
train-epoch-step: 14-112 -- Loss: 0.20001466572284698
train-epoch-step: 14-113 -- Loss: 0.18163228034973145
train-epoch-step: 14-114 -- Loss: 0.224281445145607
train-epoch-step: 14-115 -- Loss: 0.18470562994480133
train-epoch-step: 14-116 -- Loss: 0.1657705307006836
train-epoch-step: 14-117 -- Loss: 0.14656513929367065
train-epoch-step: 14-118 -- Loss: 0.2311049997806549
train-epoch-step: 14-119 -- Loss: 0.17569872736930847
train-epoch-step: 14-120 -- Loss: 0.28086256980895996
train-epoch-step: 14-121 -- Loss: 0.29253125190734863
train-epoch-step: 14-122 -- Loss: 0.239665225148201
train-epoch-step: 14-123 -- Loss: 0.23060457408428192
train-epoch-step: 14-124 -- Loss: 0.13489243388175964
train-epoch-step: 14-125 -- Loss: 0.17061211168766022
train-epoch-step: 14-126 -- Loss: 0.24424666166305542
train-epoch-step: 14-127 -- Loss: 0.20599064230918884
train-epoch-step: 14-128 -- Loss: 0.19304360449314117
train-epoch-step: 14-129 -- Loss: 0.16376127302646637
train-epoch-step: 14-130 -- Loss: 0.22475378215312958
train-epoch-step: 14-131 -- Loss: 0.15885195136070251
train-epoch-step: 14-132 -- Loss: 0.21579807996749878
train-epoch-step: 14-133 -- Loss: 0.13282257318496704
train-epoch-step: 14-134 -- Loss: 0.23106229305267334
train-epoch-step: 14-135 -- Loss: 0.15496988594532013
train-epoch-step: 14-136 -- Loss: 0.14754194021224976
train-epoch-step: 14-137 -- Loss: 0.29065513610839844
train-epoch-step: 14-138 -- Loss: 0.29228639602661133
train-epoch-step: 14-139 -- Loss: 0.1486520618200302
train-epoch-step: 14-140 -- Loss: 0.2257789671421051
train-epoch-step: 14-141 -- Loss: 0.24899716675281525
train-epoch-step: 14-142 -- Loss: 0.22700931131839752
train-epoch-step: 14-143 -- Loss: 0.19205564260482788
train-epoch-step: 14-144 -- Loss: 0.20451927185058594
train-epoch-step: 14-145 -- Loss: 0.15941143035888672
train-epoch-step: 14-146 -- Loss: 0.19255521893501282
train-epoch-step: 14-147 -- Loss: 0.1989344209432602
train-epoch-step: 14-148 -- Loss: 0.18600526452064514
train-epoch-step: 14-149 -- Loss: 0.13207823038101196
train-epoch-step: 14-150 -- Loss: 0.20312370359897614
train-epoch-step: 14-151 -- Loss: 0.2084031105041504
train-epoch-step: 14-152 -- Loss: 0.21216535568237305
train-epoch-step: 14-153 -- Loss: 0.31351909041404724
train-epoch-step: 14-154 -- Loss: 0.14526057243347168
train-epoch-step: 14-155 -- Loss: 0.15334638953208923
train-epoch-step: 14-156 -- Loss: 0.1405903398990631
train-epoch-step: 14-157 -- Loss: 0.18395820260047913
train-epoch-step: 14-158 -- Loss: 0.1886245608329773
train-epoch-step: 14-159 -- Loss: 0.19225654006004333
train-epoch-step: 14-160 -- Loss: 0.25798162817955017
train-epoch-step: 14-161 -- Loss: 0.22485655546188354
train-epoch-step: 14-162 -- Loss: 0.23836931586265564
train-epoch-step: 14-163 -- Loss: 0.20427261292934418
train-epoch-step: 14-164 -- Loss: 0.21235747635364532
train-epoch-step: 14-165 -- Loss: 0.18439336121082306
train-epoch-step: 14-166 -- Loss: 0.13519258797168732
train-epoch-step: 14-167 -- Loss: 0.13564430177211761
train-epoch-step: 14-168 -- Loss: 0.2295089066028595
train-epoch-step: 14-169 -- Loss: 0.15964552760124207
train-epoch-step: 14-170 -- Loss: 0.2181125432252884
train-epoch-step: 14-171 -- Loss: 0.1556626856327057
train-epoch-step: 14-172 -- Loss: 0.2850015163421631
train-epoch-step: 14-173 -- Loss: 0.14520828425884247
train-epoch-step: 14-174 -- Loss: 0.2708890438079834
train-epoch-step: 14-175 -- Loss: 0.20297597348690033
train-epoch-step: 14-176 -- Loss: 0.14862214028835297
train-epoch-step: 14-177 -- Loss: 0.20826750993728638
train-epoch-step: 14-178 -- Loss: 0.21003982424736023
train-epoch-step: 14-179 -- Loss: 0.16475878655910492
train-epoch-step: 14-180 -- Loss: 0.1674606204032898
train-epoch-step: 14-181 -- Loss: 0.19275276362895966
train-epoch-step: 14-182 -- Loss: 0.20422106981277466
train-epoch-step: 14-183 -- Loss: 0.29622307419776917
train-epoch-step: 14-184 -- Loss: 0.15336713194847107
train-epoch-step: 14-185 -- Loss: 0.1666429340839386
train-epoch-step: 14-186 -- Loss: 0.20982086658477783
train-epoch-step: 14-187 -- Loss: 0.24154813587665558
train-epoch-step: 14-188 -- Loss: 0.18875133991241455
train-epoch-step: 14-189 -- Loss: 0.12710493803024292
train-epoch-step: 14-190 -- Loss: 0.20289631187915802
train-epoch-step: 14-191 -- Loss: 0.1892084777355194
train-epoch-step: 14-192 -- Loss: 0.26941731572151184
train-epoch-step: 14-193 -- Loss: 0.2539779245853424
train-epoch-step: 14-194 -- Loss: 0.19581478834152222
train-epoch-step: 14-195 -- Loss: 0.18235020339488983
train-epoch-step: 14-196 -- Loss: 0.20484806597232819
train-epoch-step: 14-197 -- Loss: 0.155894473195076
train-epoch-step: 14-198 -- Loss: 0.1458364874124527
train-epoch-step: 14-199 -- Loss: 0.16890950500965118
train-epoch-step: 14-200 -- Loss: 0.13741537928581238
train-epoch-step: 14-201 -- Loss: 0.22480939328670502
train-epoch-step: 14-202 -- Loss: 0.14806078374385834
train-epoch-step: 14-203 -- Loss: 0.19511592388153076
train-epoch-step: 14-204 -- Loss: 0.15569844841957092
train-epoch-step: 14-205 -- Loss: 0.21411673724651337
train-epoch-step: 14-206 -- Loss: 0.22697433829307556
train-epoch-step: 14-207 -- Loss: 0.16186118125915527
train-epoch-step: 14-208 -- Loss: 0.1966060996055603
train-epoch-step: 14-209 -- Loss: 0.155100017786026
train-epoch-step: 14-210 -- Loss: 0.15460212528705597
train-epoch-step: 14-211 -- Loss: 0.22630171477794647
train-epoch-step: 14-212 -- Loss: 0.2163684070110321
train-epoch-step: 14-213 -- Loss: 0.14520564675331116
train-epoch-step: 14-214 -- Loss: 0.15897400677204132
train-epoch-step: 14-215 -- Loss: 0.14657723903656006
train-epoch-step: 14-216 -- Loss: 0.22442352771759033
train-epoch-step: 14-217 -- Loss: 0.23444600403308868
train-epoch-step: 14-218 -- Loss: 0.16327275335788727
train-epoch-step: 14-219 -- Loss: 0.2041078358888626
train-epoch-step: 14-220 -- Loss: 0.15137410163879395
train-epoch-step: 14-221 -- Loss: 0.22341987490653992
train-epoch-step: 14-222 -- Loss: 0.1361132115125656
train-epoch-step: 14-223 -- Loss: 0.19533079862594604
train-epoch-step: 14-224 -- Loss: 0.2202603667974472
train-epoch-step: 14-225 -- Loss: 0.3110824227333069
train-epoch-step: 14-226 -- Loss: 0.23161983489990234
train-epoch-step: 14-227 -- Loss: 0.2647310495376587
train-epoch-step: 14-228 -- Loss: 0.20836476981639862
train-epoch-step: 14-229 -- Loss: 0.19258883595466614
train-epoch-step: 14-230 -- Loss: 0.17684760689735413
train-epoch-step: 14-231 -- Loss: 0.1834222972393036
train-epoch-step: 14-232 -- Loss: 0.22205141186714172
train-epoch-step: 14-233 -- Loss: 0.10095179080963135
train-epoch-step: 14-234 -- Loss: 0.2133079618215561
train-epoch-step: 14-235 -- Loss: 0.1660183221101761
train-epoch-step: 14-236 -- Loss: 0.20010389387607574
train-epoch-step: 14-237 -- Loss: 0.27577638626098633
train-epoch-step: 14-238 -- Loss: 0.17403723299503326
train-epoch-step: 14-239 -- Loss: 0.14501522481441498
train-epoch-step: 14-240 -- Loss: 0.23763111233711243
train-epoch-step: 14-241 -- Loss: 0.17676730453968048
train-epoch-step: 14-242 -- Loss: 0.243464395403862
train-epoch-step: 14-243 -- Loss: 0.2561565041542053
train-epoch-step: 14-244 -- Loss: 0.22468173503875732
train-epoch-step: 14-245 -- Loss: 0.2334575355052948
train-epoch-step: 14-246 -- Loss: 0.2509840428829193
train-epoch-step: 14-247 -- Loss: 0.28330543637275696
train-epoch-step: 14-248 -- Loss: 0.20421861112117767
train-epoch-step: 14-249 -- Loss: 0.15792787075042725
train-epoch-step: 14-250 -- Loss: 0.22536250948905945
train-epoch-step: 14-251 -- Loss: 0.1218813806772232
train-epoch-step: 14-252 -- Loss: 0.21428769826889038
train-epoch-step: 14-253 -- Loss: 0.1529974639415741
train-epoch-step: 14-254 -- Loss: 0.24525511264801025
train-epoch-step: 14-255 -- Loss: 0.1668616682291031
train-epoch-step: 14-256 -- Loss: 0.18200260400772095
train-epoch-step: 14-257 -- Loss: 0.21717049181461334
train-epoch-step: 14-258 -- Loss: 0.16337087750434875
train-epoch-step: 14-259 -- Loss: 0.13679352402687073
train-epoch-step: 14-260 -- Loss: 0.2490694522857666
train-epoch-step: 14-261 -- Loss: 0.18675123155117035
train-epoch-step: 14-262 -- Loss: 0.33321836590766907
train-epoch-step: 14-263 -- Loss: 0.22152139246463776
train-epoch-step: 14-264 -- Loss: 0.18622034788131714
train-epoch-step: 14-265 -- Loss: 0.1321481615304947
train-epoch-step: 14-266 -- Loss: 0.1638735979795456
train-epoch-step: 14-267 -- Loss: 0.14710773527622223
train-epoch-step: 14-268 -- Loss: 0.13408565521240234
train-epoch-step: 14-269 -- Loss: 0.1932099610567093
train-epoch-step: 14-270 -- Loss: 0.12407577782869339
train-epoch-step: 14-271 -- Loss: 0.1665131002664566
train-epoch-step: 14-272 -- Loss: 0.1323137879371643
train-epoch-step: 14-273 -- Loss: 0.14197775721549988
train-epoch-step: 14-274 -- Loss: 0.21028734743595123
train-epoch-step: 14-275 -- Loss: 0.22679787874221802
train-epoch-step: 14-276 -- Loss: 0.17568770051002502
train-epoch-step: 14-277 -- Loss: 0.17421279847621918
train-epoch-step: 14-278 -- Loss: 0.17265330255031586
train-epoch-step: 14-279 -- Loss: 0.1679362654685974
train-epoch-step: 14-280 -- Loss: 0.2415662705898285
train-epoch-step: 14-281 -- Loss: 0.20664647221565247
train-epoch-step: 14-282 -- Loss: 0.15790536999702454
train-epoch-step: 14-283 -- Loss: 0.12991665303707123
train-epoch-step: 14-284 -- Loss: 0.16880111396312714
train-epoch-step: 14-285 -- Loss: 0.2089765965938568
train-epoch-step: 14-286 -- Loss: 0.18142172694206238
train-epoch-step: 14-287 -- Loss: 0.2317916303873062
train-epoch-step: 14-288 -- Loss: 0.10452262312173843
train-epoch-step: 14-289 -- Loss: 0.1413850635290146
train-epoch-step: 14-290 -- Loss: 0.2098286747932434
train-epoch-step: 14-291 -- Loss: 0.12919950485229492
train-epoch-step: 14-292 -- Loss: 0.16957426071166992
train-epoch-step: 14-293 -- Loss: 0.15782685577869415
train-epoch-step: 14-294 -- Loss: 0.19506140053272247
train-epoch-step: 14-295 -- Loss: 0.3366025388240814
train-epoch-step: 14-296 -- Loss: 0.1878073662519455
train-epoch-step: 14-297 -- Loss: 0.19379813969135284
train-epoch-step: 14-298 -- Loss: 0.2710239291191101
train-epoch-step: 14-299 -- Loss: 0.1706470251083374
train-epoch-step: 14-300 -- Loss: 0.19112904369831085
train-epoch-step: 14-301 -- Loss: 0.18426001071929932
train-epoch-step: 14-302 -- Loss: 0.2485070526599884
train-epoch-step: 14-303 -- Loss: 0.23411601781845093
train-epoch-step: 14-304 -- Loss: 0.16204607486724854
train-epoch-step: 14-305 -- Loss: 0.16017958521842957
train-epoch-step: 14-306 -- Loss: 0.2620007395744324
train-epoch-step: 14-307 -- Loss: 0.18407872319221497
train-epoch-step: 14-308 -- Loss: 0.24878248572349548
train-epoch-step: 14-309 -- Loss: 0.16944848001003265
train-epoch-step: 14-310 -- Loss: 0.185927614569664
train-epoch-step: 14-311 -- Loss: 0.17949143052101135
train-epoch-step: 14-312 -- Loss: 0.23167084157466888
train-epoch-step: 14-313 -- Loss: 0.11297663301229477
train-epoch-step: 14-314 -- Loss: 0.23096182942390442
train-epoch-step: 14-315 -- Loss: 0.18827182054519653
train-epoch-step: 14-316 -- Loss: 0.17057396471500397
train-epoch-step: 14-317 -- Loss: 0.1715766042470932
train-epoch-step: 14-318 -- Loss: 0.17995378375053406
train-epoch-step: 14-319 -- Loss: 0.20021900534629822
train-epoch-step: 14-320 -- Loss: 0.13089245557785034
train-epoch-step: 14-321 -- Loss: 0.1523790955543518
train-epoch-step: 14-322 -- Loss: 0.2382969707250595
train-epoch-step: 14-323 -- Loss: 0.18168562650680542
train-epoch-step: 14-324 -- Loss: 0.28767120838165283
train-epoch-step: 14-325 -- Loss: 0.16914065182209015
train-epoch-step: 14-326 -- Loss: 0.18666896224021912
train-epoch-step: 14-327 -- Loss: 0.2362278699874878
train-epoch-step: 14-328 -- Loss: 0.20673716068267822
train-epoch-step: 14-329 -- Loss: 0.3602604269981384
train-epoch-step: 14-330 -- Loss: 0.39571771025657654
train-epoch-step: 14-331 -- Loss: 0.22968541085720062
train-epoch-step: 14-332 -- Loss: 0.12360545992851257
train-epoch-step: 14-333 -- Loss: 0.2095213234424591
train-epoch-step: 14-334 -- Loss: 0.1739165037870407
train-epoch-step: 14-335 -- Loss: 0.1919226497411728
train-epoch-step: 14-336 -- Loss: 0.1729777753353119
train-epoch-step: 14-337 -- Loss: 0.24075420200824738
train-epoch-step: 14-338 -- Loss: 0.1770869791507721
train-epoch-step: 14-339 -- Loss: 0.16182692348957062
train-epoch-step: 14-340 -- Loss: 0.2249698042869568
train-epoch-step: 14-341 -- Loss: 0.15626314282417297
train-epoch-step: 14-342 -- Loss: 0.18607176840305328
train-epoch-step: 14-343 -- Loss: 0.17339691519737244
train-epoch-step: 14-344 -- Loss: 0.19285157322883606
train-epoch-step: 14-345 -- Loss: 0.14087362587451935
train-epoch-step: 14-346 -- Loss: 0.21793591976165771
train-epoch-step: 14-347 -- Loss: 0.1667971909046173
train-epoch-step: 14-348 -- Loss: 0.22184424102306366
train-epoch-step: 14-349 -- Loss: 0.23719052970409393
train-epoch-step: 14-350 -- Loss: 0.2910534739494324
train-epoch-step: 14-351 -- Loss: 0.2150849550962448
train-epoch-step: 14-352 -- Loss: 0.14593303203582764
train-epoch-step: 14-353 -- Loss: 0.21563571691513062
train-epoch-step: 14-354 -- Loss: 0.31283414363861084
train-epoch-step: 14-355 -- Loss: 0.13604982197284698
train-epoch-step: 14-356 -- Loss: 0.13155949115753174
train-epoch-step: 14-357 -- Loss: 0.21177715063095093
train-epoch-step: 14-358 -- Loss: 0.206856369972229
train-epoch-step: 14-359 -- Loss: 0.16422806680202484
train-epoch-step: 14-360 -- Loss: 0.13614387810230255
train-epoch-step: 14-361 -- Loss: 0.27350836992263794
train-epoch-step: 14-362 -- Loss: 0.18680712580680847
train-epoch-step: 14-363 -- Loss: 0.14063802361488342
train-epoch-step: 14-364 -- Loss: 0.2055443674325943
train-epoch-step: 14-365 -- Loss: 0.19316773116588593
train-epoch-step: 14-366 -- Loss: 0.2260577380657196
train-epoch-step: 14-367 -- Loss: 0.27186131477355957
train-epoch-step: 14-368 -- Loss: 0.2262287586927414
train-epoch-step: 14-369 -- Loss: 0.3091222643852234
train-epoch-step: 14-370 -- Loss: 0.14069834351539612
train-epoch-step: 14-371 -- Loss: 0.13304148614406586
train-epoch-step: 14-372 -- Loss: 0.15860778093338013
train-epoch-step: 14-373 -- Loss: 0.21838046610355377
train-epoch-step: 14-374 -- Loss: 0.17208875715732574
train-epoch-step: 14-375 -- Loss: 0.29630914330482483
train-epoch-step: 14-376 -- Loss: 0.20571911334991455
train-epoch-step: 14-377 -- Loss: 0.258742094039917
train-epoch-step: 14-378 -- Loss: 0.2417370080947876
train-epoch-step: 14-379 -- Loss: 0.12945199012756348
train-epoch-step: 14-380 -- Loss: 0.10159995406866074
train-epoch-step: 14-381 -- Loss: 0.2687954306602478
train-epoch-step: 14-382 -- Loss: 0.2627744674682617
train-epoch-step: 14-383 -- Loss: 0.19180002808570862
train-epoch-step: 14-384 -- Loss: 0.2557363510131836
train-epoch-step: 14-385 -- Loss: 0.2170717418193817
train-epoch-step: 14-386 -- Loss: 0.20700562000274658
train-epoch-step: 14-387 -- Loss: 0.2286180555820465
train-epoch-step: 14-388 -- Loss: 0.24082115292549133
train-epoch-step: 14-389 -- Loss: 0.1918313354253769
train-epoch-step: 14-390 -- Loss: 0.15179727971553802
train-epoch-step: 14-391 -- Loss: 0.16042645275592804
train-epoch-step: 14-392 -- Loss: 0.1979742795228958
train-epoch-step: 14-393 -- Loss: 0.17562933266162872
train-epoch-step: 14-394 -- Loss: 0.2424767166376114
train-epoch-step: 14-395 -- Loss: 0.18270789086818695
train-epoch-step: 14-396 -- Loss: 0.14075401425361633
train-epoch-step: 14-397 -- Loss: 0.1415547877550125
train-epoch-step: 14-398 -- Loss: 0.22385889291763306
train-epoch-step: 14-399 -- Loss: 0.1998683214187622
train-epoch-step: 14-400 -- Loss: 0.3256126642227173
train-epoch-step: 14-401 -- Loss: 0.13279694318771362
train-epoch-step: 14-402 -- Loss: 0.28880223631858826
train-epoch-step: 14-403 -- Loss: 0.18267738819122314
train-epoch-step: 14-404 -- Loss: 0.15626481175422668
train-epoch-step: 14-405 -- Loss: 0.1603613793849945
train-epoch-step: 14-406 -- Loss: 0.19434869289398193
train-epoch-step: 14-407 -- Loss: 0.13106510043144226
train-epoch-step: 14-408 -- Loss: 0.18457293510437012
train-epoch-step: 14-409 -- Loss: 0.18632568418979645
train-epoch-step: 14-410 -- Loss: 0.19944912195205688
train-epoch-step: 14-411 -- Loss: 0.22957897186279297
train-epoch-step: 14-412 -- Loss: 0.1420358568429947
train-epoch-step: 14-413 -- Loss: 0.16096726059913635
train-epoch-step: 14-414 -- Loss: 0.1544383317232132
train-epoch-step: 14-415 -- Loss: 0.1551668792963028
train-epoch-step: 14-416 -- Loss: 0.284218430519104
train-epoch-step: 14-417 -- Loss: 0.22005870938301086
train-epoch-step: 14-418 -- Loss: 0.26664790511131287
train-epoch-step: 14-419 -- Loss: 0.18908588588237762
train-epoch-step: 14-420 -- Loss: 0.16976779699325562
train-epoch-step: 14-421 -- Loss: 0.20341524481773376
train-epoch-step: 14-422 -- Loss: 0.16952121257781982
train-epoch-step: 14-423 -- Loss: 0.19535231590270996
train-epoch-step: 14-424 -- Loss: 0.15481050312519073
train-epoch-step: 14-425 -- Loss: 0.2031925469636917
train-epoch-step: 14-426 -- Loss: 0.17760276794433594
train-epoch-step: 14-427 -- Loss: 0.15421532094478607
train-epoch-step: 14-428 -- Loss: 0.221538245677948
train-epoch-step: 14-429 -- Loss: 0.18787126243114471
train-epoch-step: 14-430 -- Loss: 0.1604725420475006
train-epoch-step: 14-431 -- Loss: 0.18507353961467743
train-epoch-step: 14-432 -- Loss: 0.2598203420639038
train-epoch-step: 14-433 -- Loss: 0.14619284868240356
train-epoch-step: 14-434 -- Loss: 0.14227579534053802
train-epoch-step: 14-435 -- Loss: 0.17446467280387878
train-epoch-step: 14-436 -- Loss: 0.17743781208992004
train-epoch-step: 14-437 -- Loss: 0.1474745273590088
train-epoch-step: 14-438 -- Loss: 0.19393810629844666
train-epoch-step: 14-439 -- Loss: 0.29269009828567505
train-epoch-step: 14-440 -- Loss: 0.1459190547466278
train-epoch-step: 14-441 -- Loss: 0.23604647815227509
train-epoch-step: 14-442 -- Loss: 0.21815326809883118
train-epoch-step: 14-443 -- Loss: 0.18037772178649902
train-epoch-step: 14-444 -- Loss: 0.19417248666286469
train-epoch-step: 14-445 -- Loss: 0.19527216255664825
train-epoch-step: 14-446 -- Loss: 0.1725667119026184
train-epoch-step: 14-447 -- Loss: 0.2204459309577942
train-epoch-step: 14-448 -- Loss: 0.2570367455482483
train-epoch-step: 14-449 -- Loss: 0.21142292022705078
train-epoch-step: 14-450 -- Loss: 0.21345236897468567
train-epoch-step: 14-451 -- Loss: 0.15594473481178284
train-epoch-step: 14-452 -- Loss: 0.14825330674648285
train-epoch-step: 14-453 -- Loss: 0.10473412275314331
train-epoch-step: 14-454 -- Loss: 0.26033276319503784
train-epoch-step: 14-455 -- Loss: 0.14008523523807526
train-epoch-step: 14-456 -- Loss: 0.13305367529392242
train-epoch-step: 14-457 -- Loss: 0.2380528748035431
train-epoch-step: 14-458 -- Loss: 0.16394397616386414
train-epoch-step: 14-459 -- Loss: 0.2429245114326477
train-epoch-step: 14-460 -- Loss: 0.1366165578365326
train-epoch-step: 14-461 -- Loss: 0.15468719601631165
train-epoch-step: 14-462 -- Loss: 0.17532119154930115
train-epoch-step: 14-463 -- Loss: 0.14832943677902222
train-epoch-step: 14-464 -- Loss: 0.18467320501804352
train-epoch-step: 14-465 -- Loss: 0.2754121422767639
train-epoch-step: 14-466 -- Loss: 0.21535900235176086
train-epoch-step: 14-467 -- Loss: 0.12740188837051392
train-epoch-step: 14-468 -- Loss: 0.1973334550857544
train-epoch-step: 14-469 -- Loss: 0.24008618295192719
train-epoch-step: 14-470 -- Loss: 0.20028524100780487
train-epoch-step: 14-471 -- Loss: 0.17041218280792236
train-epoch-step: 14-472 -- Loss: 0.1690426468849182
train-epoch-step: 14-473 -- Loss: 0.18304315209388733
train-epoch-step: 14-474 -- Loss: 0.13097470998764038
train-epoch-step: 14-475 -- Loss: 0.12678050994873047
train-epoch-step: 14-476 -- Loss: 0.2195621281862259
train-epoch-step: 14-477 -- Loss: 0.23831382393836975
train-epoch-step: 14-478 -- Loss: 0.21183688938617706
train-epoch-step: 14-479 -- Loss: 0.15751932561397552
train-epoch-step: 14-480 -- Loss: 0.21430695056915283
train-epoch-step: 14-481 -- Loss: 0.29962432384490967
train-epoch-step: 14-482 -- Loss: 0.29122889041900635
train-epoch-step: 14-483 -- Loss: 0.1956319510936737
train-epoch-step: 14-484 -- Loss: 0.23412621021270752
train-epoch-step: 14-485 -- Loss: 0.14457188546657562
train-epoch-step: 14-486 -- Loss: 0.2650584876537323
train-epoch-step: 14-487 -- Loss: 0.24721753597259521
train-epoch-step: 14-488 -- Loss: 0.21627572178840637
train-epoch-step: 14-489 -- Loss: 0.23702841997146606
train-epoch-step: 14-490 -- Loss: 0.1546446979045868
train-epoch-step: 14-491 -- Loss: 0.1536843478679657
train-epoch-step: 14-492 -- Loss: 0.13870880007743835
train-epoch-step: 14-493 -- Loss: 0.2518162429332733
train-epoch-step: 14-494 -- Loss: 0.23546911776065826
train-epoch-step: 14-495 -- Loss: 0.22885921597480774
train-epoch-step: 14-496 -- Loss: 0.15116702020168304
train-epoch-step: 14-497 -- Loss: 0.19865815341472626
train-epoch-step: 14-498 -- Loss: 0.1632576584815979
train-epoch-step: 14-499 -- Loss: 0.18757325410842896
train-epoch-step: 14-500 -- Loss: 0.1736452728509903
train-epoch-step: 14-501 -- Loss: 0.24486887454986572
train-epoch-step: 14-502 -- Loss: 0.17959275841712952
train-epoch-step: 14-503 -- Loss: 0.24052071571350098
train-epoch-step: 14-504 -- Loss: 0.13936102390289307
train-epoch-step: 14-505 -- Loss: 0.1889319121837616
train-epoch-step: 14-506 -- Loss: 0.13296598196029663
train-epoch-step: 14-507 -- Loss: 0.20077377557754517
train-epoch-step: 14-508 -- Loss: 0.19636055827140808
train-epoch-step: 14-509 -- Loss: 0.18144458532333374
train-epoch-step: 14-510 -- Loss: 0.13756415247917175
train-epoch-step: 14-511 -- Loss: 0.24125921726226807
train-epoch-step: 14-512 -- Loss: 0.19634921848773956
train-epoch-step: 14-513 -- Loss: 0.2291359156370163
train-epoch-step: 14-514 -- Loss: 0.16207407414913177
train-epoch-step: 14-515 -- Loss: 0.17503534257411957
train-epoch-step: 14-516 -- Loss: 0.1944345235824585
train-epoch-step: 14-517 -- Loss: 0.18812325596809387
train-epoch-step: 14-518 -- Loss: 0.15405884385108948
train-epoch-step: 14-519 -- Loss: 0.14498087763786316
train-epoch-step: 14-520 -- Loss: 0.20686787366867065
train-epoch-step: 14-521 -- Loss: 0.25045067071914673
train-epoch-step: 14-522 -- Loss: 0.19564436376094818
train-epoch-step: 14-523 -- Loss: 0.17220555245876312
train-epoch-step: 14-524 -- Loss: 0.18228167295455933
train-epoch-step: 14-525 -- Loss: 0.2039092779159546
train-epoch-step: 14-526 -- Loss: 0.14274132251739502
train-epoch-step: 14-527 -- Loss: 0.1769450306892395
train-epoch-step: 14-528 -- Loss: 0.1730574369430542
train-epoch-step: 14-529 -- Loss: 0.18893077969551086
train-epoch-step: 14-530 -- Loss: 0.19105291366577148
train-epoch-step: 14-531 -- Loss: 0.22686772048473358
train-epoch-step: 14-532 -- Loss: 0.1874752640724182
train-epoch-step: 14-533 -- Loss: 0.18553566932678223
train-epoch-step: 14-534 -- Loss: 0.15365391969680786
train-epoch-step: 14-535 -- Loss: 0.28965938091278076
train-epoch-step: 14-536 -- Loss: 0.1765555590391159
train-epoch-step: 14-537 -- Loss: 0.16604799032211304
train-epoch-step: 14-538 -- Loss: 0.11566475033760071
train-epoch-step: 14-539 -- Loss: 0.22516635060310364
train-epoch-step: 14-540 -- Loss: 0.15005739033222198
train-epoch-step: 14-541 -- Loss: 0.2366858571767807
train-epoch-step: 14-542 -- Loss: 0.25060999393463135
train-epoch-step: 14-543 -- Loss: 0.18317309021949768
train-epoch-step: 14-544 -- Loss: 0.2548762559890747
train-epoch-step: 14-545 -- Loss: 0.21911366283893585
train-epoch-step: 14-546 -- Loss: 0.22861045598983765
train-epoch-step: 14-547 -- Loss: 0.19640418887138367
train-epoch-step: 14-548 -- Loss: 0.10294277966022491
train-epoch-step: 14-549 -- Loss: 0.16525113582611084
train-epoch-step: 14-550 -- Loss: 0.21985754370689392
train-epoch-step: 14-551 -- Loss: 0.1753348559141159
train-epoch-step: 14-552 -- Loss: 0.14206841588020325
train-epoch-step: 14-553 -- Loss: 0.20561201870441437
train-epoch-step: 14-554 -- Loss: 0.20394019782543182
train-epoch-step: 14-555 -- Loss: 0.23217032849788666
train-epoch-step: 14-556 -- Loss: 0.17410607635974884
train-epoch-step: 14-557 -- Loss: 0.26100122928619385
train-epoch-step: 14-558 -- Loss: 0.24820926785469055
train-epoch-step: 14-559 -- Loss: 0.1568327397108078
train-epoch-step: 14-560 -- Loss: 0.22594934701919556
train-epoch-step: 14-561 -- Loss: 0.21419745683670044
train-epoch-step: 14-562 -- Loss: 0.18774887919425964
train-epoch-step: 14-563 -- Loss: 0.20271766185760498
train-epoch-step: 14-564 -- Loss: 0.11205925792455673
train-epoch-step: 14-565 -- Loss: 0.20771777629852295
train-epoch-step: 14-566 -- Loss: 0.17058372497558594
train-epoch-step: 14-567 -- Loss: 0.2328057736158371
train-epoch-step: 14-568 -- Loss: 0.17333567142486572
train-epoch-step: 14-569 -- Loss: 0.2552720904350281
train-epoch-step: 14-570 -- Loss: 0.1934611201286316
train-epoch-step: 14-571 -- Loss: 0.24332326650619507
train-epoch-step: 14-572 -- Loss: 0.27622532844543457
train-epoch-step: 14-573 -- Loss: 0.21807442605495453
train-epoch-step: 14-574 -- Loss: 0.28684157133102417
train-epoch-step: 14-575 -- Loss: 0.3434518277645111
train-epoch-step: 14-576 -- Loss: 0.13721586763858795
train-epoch-step: 14-577 -- Loss: 0.18807180225849152
train-epoch-step: 14-578 -- Loss: 0.23726239800453186
train-epoch-step: 14-579 -- Loss: 0.17430302500724792
train-epoch-step: 14-580 -- Loss: 0.19841985404491425
train-epoch-step: 14-581 -- Loss: 0.16455912590026855
train-epoch-step: 14-582 -- Loss: 0.22375008463859558
train-epoch-step: 14-583 -- Loss: 0.2531147003173828
train-epoch-step: 14-584 -- Loss: 0.19240041077136993
train-epoch-step: 14-585 -- Loss: 0.21094539761543274
train-epoch-step: 14-586 -- Loss: 0.27747803926467896
train-epoch-step: 14-587 -- Loss: 0.17646941542625427
train-epoch-step: 14-588 -- Loss: 0.13675907254219055
val-epoch-step: 14-589 -- Loss: 0.23386377096176147
val-epoch-step: 14-590 -- Loss: 0.1624789834022522
val-epoch-step: 14-591 -- Loss: 0.2370406687259674
val-epoch-step: 14-592 -- Loss: 0.18980440497398376
val-epoch-step: 14-593 -- Loss: 0.1768987774848938
val-epoch-step: 14-594 -- Loss: 0.3406577408313751
val-epoch-step: 14-595 -- Loss: 0.21123172342777252
val-epoch-step: 14-596 -- Loss: 0.22795021533966064
val-epoch-step: 14-597 -- Loss: 0.19815456867218018
val-epoch-step: 14-598 -- Loss: 0.16346845030784607
val-epoch-step: 14-599 -- Loss: 0.20126241445541382
val-epoch-step: 14-600 -- Loss: 0.24139541387557983
val-epoch-step: 14-601 -- Loss: 0.17083537578582764
val-epoch-step: 14-602 -- Loss: 0.15002644062042236
val-epoch-step: 14-603 -- Loss: 0.19670775532722473
val-epoch-step: 14-604 -- Loss: 0.15710796415805817
val-epoch-step: 14-605 -- Loss: 0.16263338923454285
val-epoch-step: 14-606 -- Loss: 0.2975088655948639
val-epoch-step: 14-607 -- Loss: 0.14175449311733246
val-epoch-step: 14-608 -- Loss: 0.2719220221042633
val-epoch-step: 14-609 -- Loss: 0.18606600165367126
val-epoch-step: 14-610 -- Loss: 0.19568371772766113
val-epoch-step: 14-611 -- Loss: 0.16995558142662048
val-epoch-step: 14-612 -- Loss: 0.41180354356765747
val-epoch-step: 14-613 -- Loss: 0.18477533757686615
val-epoch-step: 14-614 -- Loss: 0.17456358671188354
val-epoch-step: 14-615 -- Loss: 0.19174006581306458
val-epoch-step: 14-616 -- Loss: 0.16066884994506836
val-epoch-step: 14-617 -- Loss: 0.20528556406497955
val-epoch-step: 14-618 -- Loss: 0.2056945562362671
val-epoch-step: 14-619 -- Loss: 0.22166699171066284
val-epoch-step: 14-620 -- Loss: 0.1506025493144989
val-epoch-step: 14-621 -- Loss: 0.13876338303089142
val-epoch-step: 14-622 -- Loss: 0.1541118323802948
val-epoch-step: 14-623 -- Loss: 0.16766837239265442
val-epoch-step: 14-624 -- Loss: 0.16397297382354736
val-epoch-step: 14-625 -- Loss: 0.16746613383293152
val-epoch-step: 14-626 -- Loss: 0.1635923534631729
val-epoch-step: 14-627 -- Loss: 0.2009134739637375
val-epoch-step: 14-628 -- Loss: 0.6069310903549194
val-epoch-step: 14-629 -- Loss: 0.222362220287323
val-epoch-step: 14-630 -- Loss: 0.36111295223236084
val-epoch-step: 14-631 -- Loss: 0.16540178656578064
val-epoch-step: 14-632 -- Loss: 0.2139432281255722
val-epoch-step: 14-633 -- Loss: 0.16369949281215668
val-epoch-step: 14-634 -- Loss: 0.16193325817584991
val-epoch-step: 14-635 -- Loss: 0.13262560963630676
val-epoch-step: 14-636 -- Loss: 0.1848524808883667
val-epoch-step: 14-637 -- Loss: 0.19703331589698792
val-epoch-step: 14-638 -- Loss: 0.1678607314825058
val-epoch-step: 14-639 -- Loss: 0.2801109552383423
val-epoch-step: 14-640 -- Loss: 0.27885115146636963
val-epoch-step: 14-641 -- Loss: 0.13569048047065735
val-epoch-step: 14-642 -- Loss: 0.20713794231414795
val-epoch-step: 14-643 -- Loss: 0.2199396938085556
val-epoch-step: 14-644 -- Loss: 0.1809881627559662
val-epoch-step: 14-645 -- Loss: 0.24511605501174927
val-epoch-step: 14-646 -- Loss: 0.14614266157150269
val-epoch-step: 14-647 -- Loss: 0.14572390913963318
val-epoch-step: 14-648 -- Loss: 0.17396233975887299
val-epoch-step: 14-649 -- Loss: 0.23117034137248993
val-epoch-step: 14-650 -- Loss: 0.2759079039096832
val-epoch-step: 14-651 -- Loss: 0.15753012895584106
val-epoch-step: 14-652 -- Loss: 0.17375028133392334
val-epoch-step: 14-653 -- Loss: 0.22699636220932007
val-epoch-step: 14-654 -- Loss: 0.13172461092472076
Epoch: 14 -- Train Loss: tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 15-0 -- Loss: 0.24736198782920837
train-epoch-step: 15-1 -- Loss: 0.16122327744960785
train-epoch-step: 15-2 -- Loss: 0.22203277051448822
train-epoch-step: 15-3 -- Loss: 0.16066333651542664
train-epoch-step: 15-4 -- Loss: 0.17368805408477783
train-epoch-step: 15-5 -- Loss: 0.22142452001571655
train-epoch-step: 15-6 -- Loss: 0.25402694940567017
train-epoch-step: 15-7 -- Loss: 0.18908923864364624
train-epoch-step: 15-8 -- Loss: 0.2189353108406067
train-epoch-step: 15-9 -- Loss: 0.25975877046585083
train-epoch-step: 15-10 -- Loss: 0.22664794325828552
train-epoch-step: 15-11 -- Loss: 0.1947592794895172
train-epoch-step: 15-12 -- Loss: 0.1770845353603363
train-epoch-step: 15-13 -- Loss: 0.19628645479679108
train-epoch-step: 15-14 -- Loss: 0.17558380961418152
train-epoch-step: 15-15 -- Loss: 0.1819506585597992
train-epoch-step: 15-16 -- Loss: 0.18308395147323608
train-epoch-step: 15-17 -- Loss: 0.2411734163761139
train-epoch-step: 15-18 -- Loss: 0.22309568524360657
train-epoch-step: 15-19 -- Loss: 0.14458878338336945
train-epoch-step: 15-20 -- Loss: 0.25355321168899536
train-epoch-step: 15-21 -- Loss: 0.3210967481136322
train-epoch-step: 15-22 -- Loss: 0.16110050678253174
train-epoch-step: 15-23 -- Loss: 0.1695796400308609
train-epoch-step: 15-24 -- Loss: 0.1407976895570755
train-epoch-step: 15-25 -- Loss: 0.2646928131580353
train-epoch-step: 15-26 -- Loss: 0.2091614454984665
train-epoch-step: 15-27 -- Loss: 0.32024288177490234
train-epoch-step: 15-28 -- Loss: 0.13502490520477295
train-epoch-step: 15-29 -- Loss: 0.27133211493492126
train-epoch-step: 15-30 -- Loss: 0.12084619700908661
train-epoch-step: 15-31 -- Loss: 0.1607663631439209
train-epoch-step: 15-32 -- Loss: 0.18693962693214417
train-epoch-step: 15-33 -- Loss: 0.29396724700927734
train-epoch-step: 15-34 -- Loss: 0.1903541088104248
train-epoch-step: 15-35 -- Loss: 0.27281951904296875
train-epoch-step: 15-36 -- Loss: 0.15126793086528778
train-epoch-step: 15-37 -- Loss: 0.15566638112068176
train-epoch-step: 15-38 -- Loss: 0.2104760706424713
train-epoch-step: 15-39 -- Loss: 0.25749650597572327
train-epoch-step: 15-40 -- Loss: 0.22619733214378357
train-epoch-step: 15-41 -- Loss: 0.23345936834812164
train-epoch-step: 15-42 -- Loss: 0.1640503704547882
train-epoch-step: 15-43 -- Loss: 0.3017691969871521
train-epoch-step: 15-44 -- Loss: 0.1412317156791687
train-epoch-step: 15-45 -- Loss: 0.1449560523033142
train-epoch-step: 15-46 -- Loss: 0.20024630427360535
train-epoch-step: 15-47 -- Loss: 0.23956488072872162
train-epoch-step: 15-48 -- Loss: 0.1686910092830658
train-epoch-step: 15-49 -- Loss: 0.2505813241004944
train-epoch-step: 15-50 -- Loss: 0.13206011056900024
train-epoch-step: 15-51 -- Loss: 0.23022250831127167
train-epoch-step: 15-52 -- Loss: 0.18066081404685974
train-epoch-step: 15-53 -- Loss: 0.25247931480407715
train-epoch-step: 15-54 -- Loss: 0.3209187984466553
train-epoch-step: 15-55 -- Loss: 0.1908978521823883
train-epoch-step: 15-56 -- Loss: 0.19558840990066528
train-epoch-step: 15-57 -- Loss: 0.2627622187137604
train-epoch-step: 15-58 -- Loss: 0.30727073550224304
train-epoch-step: 15-59 -- Loss: 0.27835074067115784
train-epoch-step: 15-60 -- Loss: 0.14467108249664307
train-epoch-step: 15-61 -- Loss: 0.23354165256023407
train-epoch-step: 15-62 -- Loss: 0.21792113780975342
train-epoch-step: 15-63 -- Loss: 0.1551806926727295
train-epoch-step: 15-64 -- Loss: 0.1737421154975891
train-epoch-step: 15-65 -- Loss: 0.21332605183124542
train-epoch-step: 15-66 -- Loss: 0.12342935055494308
train-epoch-step: 15-67 -- Loss: 0.13904863595962524
train-epoch-step: 15-68 -- Loss: 0.2654445171356201
train-epoch-step: 15-69 -- Loss: 0.14480926096439362
train-epoch-step: 15-70 -- Loss: 0.2509223222732544
train-epoch-step: 15-71 -- Loss: 0.2813224792480469
train-epoch-step: 15-72 -- Loss: 0.20100180804729462
train-epoch-step: 15-73 -- Loss: 0.24977034330368042
train-epoch-step: 15-74 -- Loss: 0.11326146125793457
train-epoch-step: 15-75 -- Loss: 0.14619210362434387
train-epoch-step: 15-76 -- Loss: 0.16936904191970825
train-epoch-step: 15-77 -- Loss: 0.25960850715637207
train-epoch-step: 15-78 -- Loss: 0.30015334486961365
train-epoch-step: 15-79 -- Loss: 0.2156088501214981
train-epoch-step: 15-80 -- Loss: 0.31186193227767944
train-epoch-step: 15-81 -- Loss: 0.13714903593063354
train-epoch-step: 15-82 -- Loss: 0.28376293182373047
train-epoch-step: 15-83 -- Loss: 0.23537662625312805
train-epoch-step: 15-84 -- Loss: 0.22218871116638184
train-epoch-step: 15-85 -- Loss: 0.19728681445121765
train-epoch-step: 15-86 -- Loss: 0.1419532299041748
train-epoch-step: 15-87 -- Loss: 0.2553975582122803
train-epoch-step: 15-88 -- Loss: 0.15588462352752686
train-epoch-step: 15-89 -- Loss: 0.21722707152366638
train-epoch-step: 15-90 -- Loss: 0.2147049903869629
train-epoch-step: 15-91 -- Loss: 0.2674787640571594
train-epoch-step: 15-92 -- Loss: 0.1821466088294983
train-epoch-step: 15-93 -- Loss: 0.19283819198608398
train-epoch-step: 15-94 -- Loss: 0.24910299479961395
train-epoch-step: 15-95 -- Loss: 0.22214242815971375
train-epoch-step: 15-96 -- Loss: 0.24803994596004486
train-epoch-step: 15-97 -- Loss: 0.19876722991466522
train-epoch-step: 15-98 -- Loss: 0.16887731850147247
train-epoch-step: 15-99 -- Loss: 0.20474424958229065
train-epoch-step: 15-100 -- Loss: 0.20707803964614868
train-epoch-step: 15-101 -- Loss: 0.3083655834197998
train-epoch-step: 15-102 -- Loss: 0.2540704905986786
train-epoch-step: 15-103 -- Loss: 0.2128281593322754
train-epoch-step: 15-104 -- Loss: 0.16178816556930542
train-epoch-step: 15-105 -- Loss: 0.3031097650527954
train-epoch-step: 15-106 -- Loss: 0.18678396940231323
train-epoch-step: 15-107 -- Loss: 0.2029867172241211
train-epoch-step: 15-108 -- Loss: 0.20449034869670868
train-epoch-step: 15-109 -- Loss: 0.16109229624271393
train-epoch-step: 15-110 -- Loss: 0.20336270332336426
train-epoch-step: 15-111 -- Loss: 0.2017371654510498
train-epoch-step: 15-112 -- Loss: 0.18880429863929749
train-epoch-step: 15-113 -- Loss: 0.17897725105285645
train-epoch-step: 15-114 -- Loss: 0.21812084317207336
train-epoch-step: 15-115 -- Loss: 0.18273864686489105
train-epoch-step: 15-116 -- Loss: 0.15928858518600464
train-epoch-step: 15-117 -- Loss: 0.13886649906635284
train-epoch-step: 15-118 -- Loss: 0.2260587215423584
train-epoch-step: 15-119 -- Loss: 0.17625115811824799
train-epoch-step: 15-120 -- Loss: 0.2808544337749481
train-epoch-step: 15-121 -- Loss: 0.28100651502609253
train-epoch-step: 15-122 -- Loss: 0.24182787537574768
train-epoch-step: 15-123 -- Loss: 0.2275496870279312
train-epoch-step: 15-124 -- Loss: 0.13409316539764404
train-epoch-step: 15-125 -- Loss: 0.16919758915901184
train-epoch-step: 15-126 -- Loss: 0.247478649020195
train-epoch-step: 15-127 -- Loss: 0.1957722157239914
train-epoch-step: 15-128 -- Loss: 0.18676915764808655
train-epoch-step: 15-129 -- Loss: 0.1637502908706665
train-epoch-step: 15-130 -- Loss: 0.2164950668811798
train-epoch-step: 15-131 -- Loss: 0.1540299952030182
train-epoch-step: 15-132 -- Loss: 0.22780779004096985
train-epoch-step: 15-133 -- Loss: 0.13288514316082
train-epoch-step: 15-134 -- Loss: 0.22682693600654602
train-epoch-step: 15-135 -- Loss: 0.15400606393814087
train-epoch-step: 15-136 -- Loss: 0.14397531747817993
train-epoch-step: 15-137 -- Loss: 0.2748981714248657
train-epoch-step: 15-138 -- Loss: 0.29087385535240173
train-epoch-step: 15-139 -- Loss: 0.1447860449552536
train-epoch-step: 15-140 -- Loss: 0.22391396760940552
train-epoch-step: 15-141 -- Loss: 0.24922697246074677
train-epoch-step: 15-142 -- Loss: 0.22663891315460205
train-epoch-step: 15-143 -- Loss: 0.19805669784545898
train-epoch-step: 15-144 -- Loss: 0.20227670669555664
train-epoch-step: 15-145 -- Loss: 0.15326069295406342
train-epoch-step: 15-146 -- Loss: 0.19433075189590454
train-epoch-step: 15-147 -- Loss: 0.19353318214416504
train-epoch-step: 15-148 -- Loss: 0.18261873722076416
train-epoch-step: 15-149 -- Loss: 0.13342903554439545
train-epoch-step: 15-150 -- Loss: 0.20160475373268127
train-epoch-step: 15-151 -- Loss: 0.20524752140045166
train-epoch-step: 15-152 -- Loss: 0.21994610130786896
train-epoch-step: 15-153 -- Loss: 0.30906903743743896
train-epoch-step: 15-154 -- Loss: 0.1452268362045288
train-epoch-step: 15-155 -- Loss: 0.14801934361457825
train-epoch-step: 15-156 -- Loss: 0.13898634910583496
train-epoch-step: 15-157 -- Loss: 0.18462391197681427
train-epoch-step: 15-158 -- Loss: 0.1842043697834015
train-epoch-step: 15-159 -- Loss: 0.19494697451591492
train-epoch-step: 15-160 -- Loss: 0.25008565187454224
train-epoch-step: 15-161 -- Loss: 0.23048259317874908
train-epoch-step: 15-162 -- Loss: 0.22728505730628967
train-epoch-step: 15-163 -- Loss: 0.19822637736797333
train-epoch-step: 15-164 -- Loss: 0.20612089335918427
train-epoch-step: 15-165 -- Loss: 0.18081577122211456
train-epoch-step: 15-166 -- Loss: 0.13808058202266693
train-epoch-step: 15-167 -- Loss: 0.13680705428123474
train-epoch-step: 15-168 -- Loss: 0.2215164452791214
train-epoch-step: 15-169 -- Loss: 0.16008922457695007
train-epoch-step: 15-170 -- Loss: 0.21472667157649994
train-epoch-step: 15-171 -- Loss: 0.15422505140304565
train-epoch-step: 15-172 -- Loss: 0.28196412324905396
train-epoch-step: 15-173 -- Loss: 0.14275656640529633
train-epoch-step: 15-174 -- Loss: 0.2698201537132263
train-epoch-step: 15-175 -- Loss: 0.1968303769826889
train-epoch-step: 15-176 -- Loss: 0.14962707459926605
train-epoch-step: 15-177 -- Loss: 0.20241233706474304
train-epoch-step: 15-178 -- Loss: 0.1981220841407776
train-epoch-step: 15-179 -- Loss: 0.16461093723773956
train-epoch-step: 15-180 -- Loss: 0.16375133395195007
train-epoch-step: 15-181 -- Loss: 0.19121304154396057
train-epoch-step: 15-182 -- Loss: 0.2057817131280899
train-epoch-step: 15-183 -- Loss: 0.29818540811538696
train-epoch-step: 15-184 -- Loss: 0.15002721548080444
train-epoch-step: 15-185 -- Loss: 0.16232186555862427
train-epoch-step: 15-186 -- Loss: 0.20555830001831055
train-epoch-step: 15-187 -- Loss: 0.23218868672847748
train-epoch-step: 15-188 -- Loss: 0.19735486805438995
train-epoch-step: 15-189 -- Loss: 0.11974262446165085
train-epoch-step: 15-190 -- Loss: 0.1979159414768219
train-epoch-step: 15-191 -- Loss: 0.18986475467681885
train-epoch-step: 15-192 -- Loss: 0.25953298807144165
train-epoch-step: 15-193 -- Loss: 0.2452605962753296
train-epoch-step: 15-194 -- Loss: 0.1983877271413803
train-epoch-step: 15-195 -- Loss: 0.1769290715456009
train-epoch-step: 15-196 -- Loss: 0.19517330825328827
train-epoch-step: 15-197 -- Loss: 0.1646398901939392
train-epoch-step: 15-198 -- Loss: 0.14961422979831696
train-epoch-step: 15-199 -- Loss: 0.16881266236305237
train-epoch-step: 15-200 -- Loss: 0.13762743771076202
train-epoch-step: 15-201 -- Loss: 0.22527480125427246
train-epoch-step: 15-202 -- Loss: 0.1448236107826233
train-epoch-step: 15-203 -- Loss: 0.19307783246040344
train-epoch-step: 15-204 -- Loss: 0.16048839688301086
train-epoch-step: 15-205 -- Loss: 0.20265555381774902
train-epoch-step: 15-206 -- Loss: 0.23073509335517883
train-epoch-step: 15-207 -- Loss: 0.16295024752616882
train-epoch-step: 15-208 -- Loss: 0.19441856443881989
train-epoch-step: 15-209 -- Loss: 0.14973606169223785
train-epoch-step: 15-210 -- Loss: 0.15032675862312317
train-epoch-step: 15-211 -- Loss: 0.226088747382164
train-epoch-step: 15-212 -- Loss: 0.21613872051239014
train-epoch-step: 15-213 -- Loss: 0.1450585573911667
train-epoch-step: 15-214 -- Loss: 0.16433118283748627
train-epoch-step: 15-215 -- Loss: 0.14640778303146362
train-epoch-step: 15-216 -- Loss: 0.22212998569011688
train-epoch-step: 15-217 -- Loss: 0.2375497967004776
train-epoch-step: 15-218 -- Loss: 0.1686059534549713
train-epoch-step: 15-219 -- Loss: 0.20017202198505402
train-epoch-step: 15-220 -- Loss: 0.14279904961585999
train-epoch-step: 15-221 -- Loss: 0.22132068872451782
train-epoch-step: 15-222 -- Loss: 0.13274110853672028
train-epoch-step: 15-223 -- Loss: 0.18917216360569
train-epoch-step: 15-224 -- Loss: 0.21753519773483276
train-epoch-step: 15-225 -- Loss: 0.31165510416030884
train-epoch-step: 15-226 -- Loss: 0.2254192978143692
train-epoch-step: 15-227 -- Loss: 0.24302437901496887
train-epoch-step: 15-228 -- Loss: 0.19559785723686218
train-epoch-step: 15-229 -- Loss: 0.19129452109336853
train-epoch-step: 15-230 -- Loss: 0.17452968657016754
train-epoch-step: 15-231 -- Loss: 0.180169016122818
train-epoch-step: 15-232 -- Loss: 0.2225308120250702
train-epoch-step: 15-233 -- Loss: 0.09591938555240631
train-epoch-step: 15-234 -- Loss: 0.20455598831176758
train-epoch-step: 15-235 -- Loss: 0.16869628429412842
train-epoch-step: 15-236 -- Loss: 0.19558866322040558
train-epoch-step: 15-237 -- Loss: 0.26731836795806885
train-epoch-step: 15-238 -- Loss: 0.1715654581785202
train-epoch-step: 15-239 -- Loss: 0.14108774065971375
train-epoch-step: 15-240 -- Loss: 0.24634428322315216
train-epoch-step: 15-241 -- Loss: 0.17332778871059418
train-epoch-step: 15-242 -- Loss: 0.23947232961654663
train-epoch-step: 15-243 -- Loss: 0.25211524963378906
train-epoch-step: 15-244 -- Loss: 0.22129742801189423
train-epoch-step: 15-245 -- Loss: 0.2269224375486374
train-epoch-step: 15-246 -- Loss: 0.24101021885871887
train-epoch-step: 15-247 -- Loss: 0.2572348117828369
train-epoch-step: 15-248 -- Loss: 0.20647044479846954
train-epoch-step: 15-249 -- Loss: 0.15470688045024872
train-epoch-step: 15-250 -- Loss: 0.22904221713542938
train-epoch-step: 15-251 -- Loss: 0.12096554040908813
train-epoch-step: 15-252 -- Loss: 0.215071439743042
train-epoch-step: 15-253 -- Loss: 0.1582842767238617
train-epoch-step: 15-254 -- Loss: 0.2376614511013031
train-epoch-step: 15-255 -- Loss: 0.16244497895240784
train-epoch-step: 15-256 -- Loss: 0.17406684160232544
train-epoch-step: 15-257 -- Loss: 0.21432039141654968
train-epoch-step: 15-258 -- Loss: 0.15997494757175446
train-epoch-step: 15-259 -- Loss: 0.12472011148929596
train-epoch-step: 15-260 -- Loss: 0.23571765422821045
train-epoch-step: 15-261 -- Loss: 0.19346798956394196
train-epoch-step: 15-262 -- Loss: 0.363923043012619
train-epoch-step: 15-263 -- Loss: 0.21494874358177185
train-epoch-step: 15-264 -- Loss: 0.18170982599258423
train-epoch-step: 15-265 -- Loss: 0.13629919290542603
train-epoch-step: 15-266 -- Loss: 0.16240403056144714
train-epoch-step: 15-267 -- Loss: 0.15101101994514465
train-epoch-step: 15-268 -- Loss: 0.1321711540222168
train-epoch-step: 15-269 -- Loss: 0.18413756787776947
train-epoch-step: 15-270 -- Loss: 0.11943869292736053
train-epoch-step: 15-271 -- Loss: 0.15982691943645477
train-epoch-step: 15-272 -- Loss: 0.12833167612552643
train-epoch-step: 15-273 -- Loss: 0.13954445719718933
train-epoch-step: 15-274 -- Loss: 0.20732399821281433
train-epoch-step: 15-275 -- Loss: 0.22105219960212708
train-epoch-step: 15-276 -- Loss: 0.1781240999698639
train-epoch-step: 15-277 -- Loss: 0.17082522809505463
train-epoch-step: 15-278 -- Loss: 0.1665360927581787
train-epoch-step: 15-279 -- Loss: 0.1589740663766861
train-epoch-step: 15-280 -- Loss: 0.24693432450294495
train-epoch-step: 15-281 -- Loss: 0.20781084895133972
train-epoch-step: 15-282 -- Loss: 0.1560831367969513
train-epoch-step: 15-283 -- Loss: 0.13303561508655548
train-epoch-step: 15-284 -- Loss: 0.15177151560783386
train-epoch-step: 15-285 -- Loss: 0.2095356583595276
train-epoch-step: 15-286 -- Loss: 0.17224138975143433
train-epoch-step: 15-287 -- Loss: 0.226090669631958
train-epoch-step: 15-288 -- Loss: 0.10272876918315887
train-epoch-step: 15-289 -- Loss: 0.1397988498210907
train-epoch-step: 15-290 -- Loss: 0.204751119017601
train-epoch-step: 15-291 -- Loss: 0.1281675100326538
train-epoch-step: 15-292 -- Loss: 0.16791562736034393
train-epoch-step: 15-293 -- Loss: 0.151166632771492
train-epoch-step: 15-294 -- Loss: 0.19413769245147705
train-epoch-step: 15-295 -- Loss: 0.30201470851898193
train-epoch-step: 15-296 -- Loss: 0.17405202984809875
train-epoch-step: 15-297 -- Loss: 0.18625780940055847
train-epoch-step: 15-298 -- Loss: 0.2643726170063019
train-epoch-step: 15-299 -- Loss: 0.16760222613811493
train-epoch-step: 15-300 -- Loss: 0.18447840213775635
train-epoch-step: 15-301 -- Loss: 0.19420912861824036
train-epoch-step: 15-302 -- Loss: 0.2510295808315277
train-epoch-step: 15-303 -- Loss: 0.2242097407579422
train-epoch-step: 15-304 -- Loss: 0.1556323766708374
train-epoch-step: 15-305 -- Loss: 0.15924638509750366
train-epoch-step: 15-306 -- Loss: 0.2665283679962158
train-epoch-step: 15-307 -- Loss: 0.18243074417114258
train-epoch-step: 15-308 -- Loss: 0.2430221140384674
train-epoch-step: 15-309 -- Loss: 0.1667053997516632
train-epoch-step: 15-310 -- Loss: 0.1841205656528473
train-epoch-step: 15-311 -- Loss: 0.17644108831882477
train-epoch-step: 15-312 -- Loss: 0.23069895803928375
train-epoch-step: 15-313 -- Loss: 0.10968587547540665
train-epoch-step: 15-314 -- Loss: 0.22463931143283844
train-epoch-step: 15-315 -- Loss: 0.19125071167945862
train-epoch-step: 15-316 -- Loss: 0.16809332370758057
train-epoch-step: 15-317 -- Loss: 0.16134880483150482
train-epoch-step: 15-318 -- Loss: 0.1719832718372345
train-epoch-step: 15-319 -- Loss: 0.19993402063846588
train-epoch-step: 15-320 -- Loss: 0.12661075592041016
train-epoch-step: 15-321 -- Loss: 0.15471357107162476
train-epoch-step: 15-322 -- Loss: 0.2388414591550827
train-epoch-step: 15-323 -- Loss: 0.17453508079051971
train-epoch-step: 15-324 -- Loss: 0.27615082263946533
train-epoch-step: 15-325 -- Loss: 0.16569598019123077
train-epoch-step: 15-326 -- Loss: 0.19667957723140717
train-epoch-step: 15-327 -- Loss: 0.23330184817314148
train-epoch-step: 15-328 -- Loss: 0.2077341228723526
train-epoch-step: 15-329 -- Loss: 0.35223114490509033
train-epoch-step: 15-330 -- Loss: 0.3937482237815857
train-epoch-step: 15-331 -- Loss: 0.22932007908821106
train-epoch-step: 15-332 -- Loss: 0.11226363480091095
train-epoch-step: 15-333 -- Loss: 0.20508338510990143
train-epoch-step: 15-334 -- Loss: 0.1700439453125
train-epoch-step: 15-335 -- Loss: 0.19444289803504944
train-epoch-step: 15-336 -- Loss: 0.17276903986930847
train-epoch-step: 15-337 -- Loss: 0.23528169095516205
train-epoch-step: 15-338 -- Loss: 0.17330139875411987
train-epoch-step: 15-339 -- Loss: 0.159197136759758
train-epoch-step: 15-340 -- Loss: 0.22068998217582703
train-epoch-step: 15-341 -- Loss: 0.15140068531036377
train-epoch-step: 15-342 -- Loss: 0.18691787123680115
train-epoch-step: 15-343 -- Loss: 0.1708994209766388
train-epoch-step: 15-344 -- Loss: 0.19425225257873535
train-epoch-step: 15-345 -- Loss: 0.15254485607147217
train-epoch-step: 15-346 -- Loss: 0.2214096486568451
train-epoch-step: 15-347 -- Loss: 0.16701079905033112
train-epoch-step: 15-348 -- Loss: 0.22424167394638062
train-epoch-step: 15-349 -- Loss: 0.23575171828269958
train-epoch-step: 15-350 -- Loss: 0.30000239610671997
train-epoch-step: 15-351 -- Loss: 0.20937904715538025
train-epoch-step: 15-352 -- Loss: 0.13935314118862152
train-epoch-step: 15-353 -- Loss: 0.21268436312675476
train-epoch-step: 15-354 -- Loss: 0.3005189895629883
train-epoch-step: 15-355 -- Loss: 0.13413923978805542
train-epoch-step: 15-356 -- Loss: 0.12537579238414764
train-epoch-step: 15-357 -- Loss: 0.20948103070259094
train-epoch-step: 15-358 -- Loss: 0.20348051190376282
train-epoch-step: 15-359 -- Loss: 0.15964385867118835
train-epoch-step: 15-360 -- Loss: 0.13487298786640167
train-epoch-step: 15-361 -- Loss: 0.2689630687236786
train-epoch-step: 15-362 -- Loss: 0.18525053560733795
train-epoch-step: 15-363 -- Loss: 0.13139545917510986
train-epoch-step: 15-364 -- Loss: 0.19948598742485046
train-epoch-step: 15-365 -- Loss: 0.18749578297138214
train-epoch-step: 15-366 -- Loss: 0.2211584895849228
train-epoch-step: 15-367 -- Loss: 0.26247695088386536
train-epoch-step: 15-368 -- Loss: 0.23257027566432953
train-epoch-step: 15-369 -- Loss: 0.2999063730239868
train-epoch-step: 15-370 -- Loss: 0.14086610078811646
train-epoch-step: 15-371 -- Loss: 0.1313331127166748
train-epoch-step: 15-372 -- Loss: 0.16251924633979797
train-epoch-step: 15-373 -- Loss: 0.21137145161628723
train-epoch-step: 15-374 -- Loss: 0.16743598878383636
train-epoch-step: 15-375 -- Loss: 0.2909148037433624
train-epoch-step: 15-376 -- Loss: 0.18713028728961945
train-epoch-step: 15-377 -- Loss: 0.25890541076660156
train-epoch-step: 15-378 -- Loss: 0.2404268980026245
train-epoch-step: 15-379 -- Loss: 0.1314546763896942
train-epoch-step: 15-380 -- Loss: 0.09805318713188171
train-epoch-step: 15-381 -- Loss: 0.26499247550964355
train-epoch-step: 15-382 -- Loss: 0.25414127111434937
train-epoch-step: 15-383 -- Loss: 0.19348405301570892
train-epoch-step: 15-384 -- Loss: 0.25712963938713074
train-epoch-step: 15-385 -- Loss: 0.21107856929302216
train-epoch-step: 15-386 -- Loss: 0.20188073813915253
train-epoch-step: 15-387 -- Loss: 0.22729510068893433
train-epoch-step: 15-388 -- Loss: 0.2497093677520752
train-epoch-step: 15-389 -- Loss: 0.19075584411621094
train-epoch-step: 15-390 -- Loss: 0.15356934070587158
train-epoch-step: 15-391 -- Loss: 0.15811121463775635
train-epoch-step: 15-392 -- Loss: 0.19897234439849854
train-epoch-step: 15-393 -- Loss: 0.17754319310188293
train-epoch-step: 15-394 -- Loss: 0.23503896594047546
train-epoch-step: 15-395 -- Loss: 0.18208543956279755
train-epoch-step: 15-396 -- Loss: 0.14229361712932587
train-epoch-step: 15-397 -- Loss: 0.14191581308841705
train-epoch-step: 15-398 -- Loss: 0.21679522097110748
train-epoch-step: 15-399 -- Loss: 0.1953521966934204
train-epoch-step: 15-400 -- Loss: 0.31360724568367004
train-epoch-step: 15-401 -- Loss: 0.13383875787258148
train-epoch-step: 15-402 -- Loss: 0.2706490755081177
train-epoch-step: 15-403 -- Loss: 0.17174401879310608
train-epoch-step: 15-404 -- Loss: 0.15662381052970886
train-epoch-step: 15-405 -- Loss: 0.15667524933815002
train-epoch-step: 15-406 -- Loss: 0.18871518969535828
train-epoch-step: 15-407 -- Loss: 0.1288091391324997
train-epoch-step: 15-408 -- Loss: 0.17423689365386963
train-epoch-step: 15-409 -- Loss: 0.18123787641525269
train-epoch-step: 15-410 -- Loss: 0.18708296120166779
train-epoch-step: 15-411 -- Loss: 0.222438782453537
train-epoch-step: 15-412 -- Loss: 0.14096081256866455
train-epoch-step: 15-413 -- Loss: 0.16165581345558167
train-epoch-step: 15-414 -- Loss: 0.1485530138015747
train-epoch-step: 15-415 -- Loss: 0.1552896499633789
train-epoch-step: 15-416 -- Loss: 0.2777070701122284
train-epoch-step: 15-417 -- Loss: 0.21237808465957642
train-epoch-step: 15-418 -- Loss: 0.26927515864372253
train-epoch-step: 15-419 -- Loss: 0.18179607391357422
train-epoch-step: 15-420 -- Loss: 0.17319341003894806
train-epoch-step: 15-421 -- Loss: 0.19834715127944946
train-epoch-step: 15-422 -- Loss: 0.16507546603679657
train-epoch-step: 15-423 -- Loss: 0.18918107450008392
train-epoch-step: 15-424 -- Loss: 0.15273547172546387
train-epoch-step: 15-425 -- Loss: 0.20004668831825256
train-epoch-step: 15-426 -- Loss: 0.17726993560791016
train-epoch-step: 15-427 -- Loss: 0.14540569484233856
train-epoch-step: 15-428 -- Loss: 0.2140226811170578
train-epoch-step: 15-429 -- Loss: 0.18801115453243256
train-epoch-step: 15-430 -- Loss: 0.16287052631378174
train-epoch-step: 15-431 -- Loss: 0.18570047616958618
train-epoch-step: 15-432 -- Loss: 0.25674623250961304
train-epoch-step: 15-433 -- Loss: 0.15296711027622223
train-epoch-step: 15-434 -- Loss: 0.13808147609233856
train-epoch-step: 15-435 -- Loss: 0.17998020350933075
train-epoch-step: 15-436 -- Loss: 0.17632226645946503
train-epoch-step: 15-437 -- Loss: 0.1482526808977127
train-epoch-step: 15-438 -- Loss: 0.18835613131523132
train-epoch-step: 15-439 -- Loss: 0.289567768573761
train-epoch-step: 15-440 -- Loss: 0.1426752656698227
train-epoch-step: 15-441 -- Loss: 0.2301517128944397
train-epoch-step: 15-442 -- Loss: 0.20667481422424316
train-epoch-step: 15-443 -- Loss: 0.17473797500133514
train-epoch-step: 15-444 -- Loss: 0.19830121099948883
train-epoch-step: 15-445 -- Loss: 0.189112588763237
train-epoch-step: 15-446 -- Loss: 0.1658264845609665
train-epoch-step: 15-447 -- Loss: 0.21235856413841248
train-epoch-step: 15-448 -- Loss: 0.25097689032554626
train-epoch-step: 15-449 -- Loss: 0.20939436554908752
train-epoch-step: 15-450 -- Loss: 0.20490983128547668
train-epoch-step: 15-451 -- Loss: 0.15910354256629944
train-epoch-step: 15-452 -- Loss: 0.14295423030853271
train-epoch-step: 15-453 -- Loss: 0.10143869370222092
train-epoch-step: 15-454 -- Loss: 0.25692659616470337
train-epoch-step: 15-455 -- Loss: 0.1453985869884491
train-epoch-step: 15-456 -- Loss: 0.1330339014530182
train-epoch-step: 15-457 -- Loss: 0.23452404141426086
train-epoch-step: 15-458 -- Loss: 0.17188598215579987
train-epoch-step: 15-459 -- Loss: 0.23841258883476257
train-epoch-step: 15-460 -- Loss: 0.1368708610534668
train-epoch-step: 15-461 -- Loss: 0.15039604902267456
train-epoch-step: 15-462 -- Loss: 0.17388209700584412
train-epoch-step: 15-463 -- Loss: 0.14615382254123688
train-epoch-step: 15-464 -- Loss: 0.1764548420906067
train-epoch-step: 15-465 -- Loss: 0.2615375518798828
train-epoch-step: 15-466 -- Loss: 0.21126341819763184
train-epoch-step: 15-467 -- Loss: 0.12774008512496948
train-epoch-step: 15-468 -- Loss: 0.19071277976036072
train-epoch-step: 15-469 -- Loss: 0.24015206098556519
train-epoch-step: 15-470 -- Loss: 0.19958524405956268
train-epoch-step: 15-471 -- Loss: 0.17733535170555115
train-epoch-step: 15-472 -- Loss: 0.16822338104248047
train-epoch-step: 15-473 -- Loss: 0.17875303328037262
train-epoch-step: 15-474 -- Loss: 0.13386690616607666
train-epoch-step: 15-475 -- Loss: 0.1283625066280365
train-epoch-step: 15-476 -- Loss: 0.21862190961837769
train-epoch-step: 15-477 -- Loss: 0.23388078808784485
train-epoch-step: 15-478 -- Loss: 0.2022455483675003
train-epoch-step: 15-479 -- Loss: 0.1561698615550995
train-epoch-step: 15-480 -- Loss: 0.203610360622406
train-epoch-step: 15-481 -- Loss: 0.3011917173862457
train-epoch-step: 15-482 -- Loss: 0.2881316542625427
train-epoch-step: 15-483 -- Loss: 0.19875842332839966
train-epoch-step: 15-484 -- Loss: 0.22327406704425812
train-epoch-step: 15-485 -- Loss: 0.14308612048625946
train-epoch-step: 15-486 -- Loss: 0.2582574188709259
train-epoch-step: 15-487 -- Loss: 0.24157270789146423
train-epoch-step: 15-488 -- Loss: 0.208939328789711
train-epoch-step: 15-489 -- Loss: 0.2395106852054596
train-epoch-step: 15-490 -- Loss: 0.1530124545097351
train-epoch-step: 15-491 -- Loss: 0.1502295583486557
train-epoch-step: 15-492 -- Loss: 0.13491101562976837
train-epoch-step: 15-493 -- Loss: 0.24282465875148773
train-epoch-step: 15-494 -- Loss: 0.22207173705101013
train-epoch-step: 15-495 -- Loss: 0.22198531031608582
train-epoch-step: 15-496 -- Loss: 0.14839144051074982
train-epoch-step: 15-497 -- Loss: 0.19639171659946442
train-epoch-step: 15-498 -- Loss: 0.15918099880218506
train-epoch-step: 15-499 -- Loss: 0.18461626768112183
train-epoch-step: 15-500 -- Loss: 0.17672814428806305
train-epoch-step: 15-501 -- Loss: 0.2443264275789261
train-epoch-step: 15-502 -- Loss: 0.17658819258213043
train-epoch-step: 15-503 -- Loss: 0.2393970787525177
train-epoch-step: 15-504 -- Loss: 0.13834504783153534
train-epoch-step: 15-505 -- Loss: 0.1930854171514511
train-epoch-step: 15-506 -- Loss: 0.13177913427352905
train-epoch-step: 15-507 -- Loss: 0.19578419625759125
train-epoch-step: 15-508 -- Loss: 0.19387465715408325
train-epoch-step: 15-509 -- Loss: 0.1845875084400177
train-epoch-step: 15-510 -- Loss: 0.1386071741580963
train-epoch-step: 15-511 -- Loss: 0.2414242923259735
train-epoch-step: 15-512 -- Loss: 0.18966685235500336
train-epoch-step: 15-513 -- Loss: 0.22546036541461945
train-epoch-step: 15-514 -- Loss: 0.16412819921970367
train-epoch-step: 15-515 -- Loss: 0.1764955371618271
train-epoch-step: 15-516 -- Loss: 0.18447619676589966
train-epoch-step: 15-517 -- Loss: 0.1876269429922104
train-epoch-step: 15-518 -- Loss: 0.1495818793773651
train-epoch-step: 15-519 -- Loss: 0.14397397637367249
train-epoch-step: 15-520 -- Loss: 0.21083572506904602
train-epoch-step: 15-521 -- Loss: 0.24887309968471527
train-epoch-step: 15-522 -- Loss: 0.2014303356409073
train-epoch-step: 15-523 -- Loss: 0.167129784822464
train-epoch-step: 15-524 -- Loss: 0.18742775917053223
train-epoch-step: 15-525 -- Loss: 0.20885694026947021
train-epoch-step: 15-526 -- Loss: 0.14168283343315125
train-epoch-step: 15-527 -- Loss: 0.16335292160511017
train-epoch-step: 15-528 -- Loss: 0.17413944005966187
train-epoch-step: 15-529 -- Loss: 0.18061614036560059
train-epoch-step: 15-530 -- Loss: 0.18378445506095886
train-epoch-step: 15-531 -- Loss: 0.21669480204582214
train-epoch-step: 15-532 -- Loss: 0.18841417133808136
train-epoch-step: 15-533 -- Loss: 0.18087683618068695
train-epoch-step: 15-534 -- Loss: 0.153692364692688
train-epoch-step: 15-535 -- Loss: 0.28296664357185364
train-epoch-step: 15-536 -- Loss: 0.17356638610363007
train-epoch-step: 15-537 -- Loss: 0.16823773086071014
train-epoch-step: 15-538 -- Loss: 0.11291026324033737
train-epoch-step: 15-539 -- Loss: 0.20696613192558289
train-epoch-step: 15-540 -- Loss: 0.1475917100906372
train-epoch-step: 15-541 -- Loss: 0.23533420264720917
train-epoch-step: 15-542 -- Loss: 0.24422064423561096
train-epoch-step: 15-543 -- Loss: 0.18374158442020416
train-epoch-step: 15-544 -- Loss: 0.24346306920051575
train-epoch-step: 15-545 -- Loss: 0.21517084538936615
train-epoch-step: 15-546 -- Loss: 0.237291157245636
train-epoch-step: 15-547 -- Loss: 0.19341152906417847
train-epoch-step: 15-548 -- Loss: 0.10197392851114273
train-epoch-step: 15-549 -- Loss: 0.16281262040138245
train-epoch-step: 15-550 -- Loss: 0.2145063728094101
train-epoch-step: 15-551 -- Loss: 0.17019295692443848
train-epoch-step: 15-552 -- Loss: 0.1440638303756714
train-epoch-step: 15-553 -- Loss: 0.20416413247585297
train-epoch-step: 15-554 -- Loss: 0.20676010847091675
train-epoch-step: 15-555 -- Loss: 0.2452172189950943
train-epoch-step: 15-556 -- Loss: 0.16715101897716522
train-epoch-step: 15-557 -- Loss: 0.26427942514419556
train-epoch-step: 15-558 -- Loss: 0.23563556373119354
train-epoch-step: 15-559 -- Loss: 0.15651732683181763
train-epoch-step: 15-560 -- Loss: 0.226400226354599
train-epoch-step: 15-561 -- Loss: 0.19569021463394165
train-epoch-step: 15-562 -- Loss: 0.19201388955116272
train-epoch-step: 15-563 -- Loss: 0.20784997940063477
train-epoch-step: 15-564 -- Loss: 0.10924181342124939
train-epoch-step: 15-565 -- Loss: 0.1989116370677948
train-epoch-step: 15-566 -- Loss: 0.180565744638443
train-epoch-step: 15-567 -- Loss: 0.23380500078201294
train-epoch-step: 15-568 -- Loss: 0.17352750897407532
train-epoch-step: 15-569 -- Loss: 0.2530956566333771
train-epoch-step: 15-570 -- Loss: 0.18720701336860657
train-epoch-step: 15-571 -- Loss: 0.230002760887146
train-epoch-step: 15-572 -- Loss: 0.27381056547164917
train-epoch-step: 15-573 -- Loss: 0.21891555190086365
train-epoch-step: 15-574 -- Loss: 0.2682623267173767
train-epoch-step: 15-575 -- Loss: 0.3284803628921509
train-epoch-step: 15-576 -- Loss: 0.13369685411453247
train-epoch-step: 15-577 -- Loss: 0.18643665313720703
train-epoch-step: 15-578 -- Loss: 0.23054853081703186
train-epoch-step: 15-579 -- Loss: 0.18472155928611755
train-epoch-step: 15-580 -- Loss: 0.192611426115036
train-epoch-step: 15-581 -- Loss: 0.15911908447742462
train-epoch-step: 15-582 -- Loss: 0.22133323550224304
train-epoch-step: 15-583 -- Loss: 0.25344032049179077
train-epoch-step: 15-584 -- Loss: 0.20009106397628784
train-epoch-step: 15-585 -- Loss: 0.20948448777198792
train-epoch-step: 15-586 -- Loss: 0.2807699739933014
train-epoch-step: 15-587 -- Loss: 0.17353951930999756
train-epoch-step: 15-588 -- Loss: 0.14106778800487518
val-epoch-step: 15-589 -- Loss: 0.2179960310459137
val-epoch-step: 15-590 -- Loss: 0.17009617388248444
val-epoch-step: 15-591 -- Loss: 0.2381039559841156
val-epoch-step: 15-592 -- Loss: 0.19292603433132172
val-epoch-step: 15-593 -- Loss: 0.15659324824810028
val-epoch-step: 15-594 -- Loss: 0.367745578289032
val-epoch-step: 15-595 -- Loss: 0.202493816614151
val-epoch-step: 15-596 -- Loss: 0.23043487966060638
val-epoch-step: 15-597 -- Loss: 0.19412346184253693
val-epoch-step: 15-598 -- Loss: 0.15773898363113403
val-epoch-step: 15-599 -- Loss: 0.20490407943725586
val-epoch-step: 15-600 -- Loss: 0.21322284638881683
val-epoch-step: 15-601 -- Loss: 0.16527637839317322
val-epoch-step: 15-602 -- Loss: 0.1461050808429718
val-epoch-step: 15-603 -- Loss: 0.20256133377552032
val-epoch-step: 15-604 -- Loss: 0.15988536179065704
val-epoch-step: 15-605 -- Loss: 0.16148622334003448
val-epoch-step: 15-606 -- Loss: 0.2858276963233948
val-epoch-step: 15-607 -- Loss: 0.1421683132648468
val-epoch-step: 15-608 -- Loss: 0.26822197437286377
val-epoch-step: 15-609 -- Loss: 0.17748622596263885
val-epoch-step: 15-610 -- Loss: 0.19609075784683228
val-epoch-step: 15-611 -- Loss: 0.16444222629070282
val-epoch-step: 15-612 -- Loss: 0.46592527627944946
val-epoch-step: 15-613 -- Loss: 0.19738517701625824
val-epoch-step: 15-614 -- Loss: 0.17031532526016235
val-epoch-step: 15-615 -- Loss: 0.1901857703924179
val-epoch-step: 15-616 -- Loss: 0.1626337170600891
val-epoch-step: 15-617 -- Loss: 0.20103201270103455
val-epoch-step: 15-618 -- Loss: 0.19911548495292664
val-epoch-step: 15-619 -- Loss: 0.2235548198223114
val-epoch-step: 15-620 -- Loss: 0.14733414351940155
val-epoch-step: 15-621 -- Loss: 0.14388439059257507
val-epoch-step: 15-622 -- Loss: 0.15474112331867218
val-epoch-step: 15-623 -- Loss: 0.16489394009113312
val-epoch-step: 15-624 -- Loss: 0.16334578394889832
val-epoch-step: 15-625 -- Loss: 0.16913264989852905
val-epoch-step: 15-626 -- Loss: 0.16079238057136536
val-epoch-step: 15-627 -- Loss: 0.20026043057441711
val-epoch-step: 15-628 -- Loss: 0.6488571166992188
val-epoch-step: 15-629 -- Loss: 0.22432775795459747
val-epoch-step: 15-630 -- Loss: 0.36372286081314087
val-epoch-step: 15-631 -- Loss: 0.1562427282333374
val-epoch-step: 15-632 -- Loss: 0.20684552192687988
val-epoch-step: 15-633 -- Loss: 0.16183573007583618
val-epoch-step: 15-634 -- Loss: 0.1524462103843689
val-epoch-step: 15-635 -- Loss: 0.1304667890071869
val-epoch-step: 15-636 -- Loss: 0.19317567348480225
val-epoch-step: 15-637 -- Loss: 0.18995152413845062
val-epoch-step: 15-638 -- Loss: 0.16884836554527283
val-epoch-step: 15-639 -- Loss: 0.27605584263801575
val-epoch-step: 15-640 -- Loss: 0.2739962637424469
val-epoch-step: 15-641 -- Loss: 0.13439075648784637
val-epoch-step: 15-642 -- Loss: 0.20525193214416504
val-epoch-step: 15-643 -- Loss: 0.2119370847940445
val-epoch-step: 15-644 -- Loss: 0.17545448243618011
val-epoch-step: 15-645 -- Loss: 0.24007061123847961
val-epoch-step: 15-646 -- Loss: 0.14559730887413025
val-epoch-step: 15-647 -- Loss: 0.1394372135400772
val-epoch-step: 15-648 -- Loss: 0.17534832656383514
val-epoch-step: 15-649 -- Loss: 0.23237572610378265
val-epoch-step: 15-650 -- Loss: 0.2713240385055542
val-epoch-step: 15-651 -- Loss: 0.155519500374794
val-epoch-step: 15-652 -- Loss: 0.17498810589313507
val-epoch-step: 15-653 -- Loss: 0.21527545154094696
val-epoch-step: 15-654 -- Loss: 0.13002556562423706
Epoch: 15 -- Train Loss: tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 16-0 -- Loss: 0.24536752700805664
train-epoch-step: 16-1 -- Loss: 0.15523719787597656
train-epoch-step: 16-2 -- Loss: 0.2127840220928192
train-epoch-step: 16-3 -- Loss: 0.15681779384613037
train-epoch-step: 16-4 -- Loss: 0.17765720188617706
train-epoch-step: 16-5 -- Loss: 0.21524111926555634
train-epoch-step: 16-6 -- Loss: 0.2362222671508789
train-epoch-step: 16-7 -- Loss: 0.1846783310174942
train-epoch-step: 16-8 -- Loss: 0.21562613546848297
train-epoch-step: 16-9 -- Loss: 0.26591789722442627
train-epoch-step: 16-10 -- Loss: 0.22542817890644073
train-epoch-step: 16-11 -- Loss: 0.19541561603546143
train-epoch-step: 16-12 -- Loss: 0.1775326132774353
train-epoch-step: 16-13 -- Loss: 0.19628390669822693
train-epoch-step: 16-14 -- Loss: 0.18204089999198914
train-epoch-step: 16-15 -- Loss: 0.17840926349163055
train-epoch-step: 16-16 -- Loss: 0.17343036830425262
train-epoch-step: 16-17 -- Loss: 0.2411254197359085
train-epoch-step: 16-18 -- Loss: 0.21672113239765167
train-epoch-step: 16-19 -- Loss: 0.1463557779788971
train-epoch-step: 16-20 -- Loss: 0.2619812786579132
train-epoch-step: 16-21 -- Loss: 0.29133161902427673
train-epoch-step: 16-22 -- Loss: 0.1571124792098999
train-epoch-step: 16-23 -- Loss: 0.1734458953142166
train-epoch-step: 16-24 -- Loss: 0.13880716264247894
train-epoch-step: 16-25 -- Loss: 0.24489746987819672
train-epoch-step: 16-26 -- Loss: 0.21017524600028992
train-epoch-step: 16-27 -- Loss: 0.2567126750946045
train-epoch-step: 16-28 -- Loss: 0.13318590819835663
train-epoch-step: 16-29 -- Loss: 0.2620548605918884
train-epoch-step: 16-30 -- Loss: 0.12080150097608566
train-epoch-step: 16-31 -- Loss: 0.16152623295783997
train-epoch-step: 16-32 -- Loss: 0.18759414553642273
train-epoch-step: 16-33 -- Loss: 0.2994023561477661
train-epoch-step: 16-34 -- Loss: 0.1842140555381775
train-epoch-step: 16-35 -- Loss: 0.2671085596084595
train-epoch-step: 16-36 -- Loss: 0.1493309736251831
train-epoch-step: 16-37 -- Loss: 0.1518065482378006
train-epoch-step: 16-38 -- Loss: 0.20507177710533142
train-epoch-step: 16-39 -- Loss: 0.24765849113464355
train-epoch-step: 16-40 -- Loss: 0.21696141362190247
train-epoch-step: 16-41 -- Loss: 0.23211506009101868
train-epoch-step: 16-42 -- Loss: 0.16151773929595947
train-epoch-step: 16-43 -- Loss: 0.2998446524143219
train-epoch-step: 16-44 -- Loss: 0.1354694366455078
train-epoch-step: 16-45 -- Loss: 0.1305273473262787
train-epoch-step: 16-46 -- Loss: 0.1930263787508011
train-epoch-step: 16-47 -- Loss: 0.24467016756534576
train-epoch-step: 16-48 -- Loss: 0.16527682542800903
train-epoch-step: 16-49 -- Loss: 0.2406083047389984
train-epoch-step: 16-50 -- Loss: 0.13202904164791107
train-epoch-step: 16-51 -- Loss: 0.21287310123443604
train-epoch-step: 16-52 -- Loss: 0.17172712087631226
train-epoch-step: 16-53 -- Loss: 0.22982491552829742
train-epoch-step: 16-54 -- Loss: 0.3005812168121338
train-epoch-step: 16-55 -- Loss: 0.18001803755760193
train-epoch-step: 16-56 -- Loss: 0.1945243924856186
train-epoch-step: 16-57 -- Loss: 0.2613973319530487
train-epoch-step: 16-58 -- Loss: 0.3012771010398865
train-epoch-step: 16-59 -- Loss: 0.2879531681537628
train-epoch-step: 16-60 -- Loss: 0.144979327917099
train-epoch-step: 16-61 -- Loss: 0.22910349071025848
train-epoch-step: 16-62 -- Loss: 0.20325139164924622
train-epoch-step: 16-63 -- Loss: 0.14844897389411926
train-epoch-step: 16-64 -- Loss: 0.15791739523410797
train-epoch-step: 16-65 -- Loss: 0.20772600173950195
train-epoch-step: 16-66 -- Loss: 0.12469690293073654
train-epoch-step: 16-67 -- Loss: 0.13726353645324707
train-epoch-step: 16-68 -- Loss: 0.2517409920692444
train-epoch-step: 16-69 -- Loss: 0.1359877586364746
train-epoch-step: 16-70 -- Loss: 0.2383480668067932
train-epoch-step: 16-71 -- Loss: 0.2865462303161621
train-epoch-step: 16-72 -- Loss: 0.19766287505626678
train-epoch-step: 16-73 -- Loss: 0.23141920566558838
train-epoch-step: 16-74 -- Loss: 0.11146131902933121
train-epoch-step: 16-75 -- Loss: 0.13946382701396942
train-epoch-step: 16-76 -- Loss: 0.16013824939727783
train-epoch-step: 16-77 -- Loss: 0.24241486191749573
train-epoch-step: 16-78 -- Loss: 0.283811092376709
train-epoch-step: 16-79 -- Loss: 0.21150580048561096
train-epoch-step: 16-80 -- Loss: 0.2937798500061035
train-epoch-step: 16-81 -- Loss: 0.13257677853107452
train-epoch-step: 16-82 -- Loss: 0.27139949798583984
train-epoch-step: 16-83 -- Loss: 0.21762175858020782
train-epoch-step: 16-84 -- Loss: 0.2154696136713028
train-epoch-step: 16-85 -- Loss: 0.19800911843776703
train-epoch-step: 16-86 -- Loss: 0.1406233161687851
train-epoch-step: 16-87 -- Loss: 0.247329443693161
train-epoch-step: 16-88 -- Loss: 0.1570453643798828
train-epoch-step: 16-89 -- Loss: 0.2056071013212204
train-epoch-step: 16-90 -- Loss: 0.2116617113351822
train-epoch-step: 16-91 -- Loss: 0.2658449411392212
train-epoch-step: 16-92 -- Loss: 0.1716616451740265
train-epoch-step: 16-93 -- Loss: 0.19397178292274475
train-epoch-step: 16-94 -- Loss: 0.24578258395195007
train-epoch-step: 16-95 -- Loss: 0.21629169583320618
train-epoch-step: 16-96 -- Loss: 0.23611968755722046
train-epoch-step: 16-97 -- Loss: 0.189817875623703
train-epoch-step: 16-98 -- Loss: 0.16905227303504944
train-epoch-step: 16-99 -- Loss: 0.1994689553976059
train-epoch-step: 16-100 -- Loss: 0.2091211974620819
train-epoch-step: 16-101 -- Loss: 0.31391531229019165
train-epoch-step: 16-102 -- Loss: 0.2577366232872009
train-epoch-step: 16-103 -- Loss: 0.2036447674036026
train-epoch-step: 16-104 -- Loss: 0.1599271297454834
train-epoch-step: 16-105 -- Loss: 0.30469757318496704
train-epoch-step: 16-106 -- Loss: 0.19367116689682007
train-epoch-step: 16-107 -- Loss: 0.20313796401023865
train-epoch-step: 16-108 -- Loss: 0.20289933681488037
train-epoch-step: 16-109 -- Loss: 0.17223969101905823
train-epoch-step: 16-110 -- Loss: 0.19828703999519348
train-epoch-step: 16-111 -- Loss: 0.1975971907377243
train-epoch-step: 16-112 -- Loss: 0.18646983802318573
train-epoch-step: 16-113 -- Loss: 0.17613281309604645
train-epoch-step: 16-114 -- Loss: 0.2093464881181717
train-epoch-step: 16-115 -- Loss: 0.18319685757160187
train-epoch-step: 16-116 -- Loss: 0.15653225779533386
train-epoch-step: 16-117 -- Loss: 0.14601585268974304
train-epoch-step: 16-118 -- Loss: 0.2203575074672699
train-epoch-step: 16-119 -- Loss: 0.17049410939216614
train-epoch-step: 16-120 -- Loss: 0.27893128991127014
train-epoch-step: 16-121 -- Loss: 0.280001699924469
train-epoch-step: 16-122 -- Loss: 0.23498176038265228
train-epoch-step: 16-123 -- Loss: 0.2327084094285965
train-epoch-step: 16-124 -- Loss: 0.13295292854309082
train-epoch-step: 16-125 -- Loss: 0.17216594517230988
train-epoch-step: 16-126 -- Loss: 0.241878479719162
train-epoch-step: 16-127 -- Loss: 0.20472893118858337
train-epoch-step: 16-128 -- Loss: 0.18934190273284912
train-epoch-step: 16-129 -- Loss: 0.1685347557067871
train-epoch-step: 16-130 -- Loss: 0.21790821850299835
train-epoch-step: 16-131 -- Loss: 0.15167251229286194
train-epoch-step: 16-132 -- Loss: 0.21773084998130798
train-epoch-step: 16-133 -- Loss: 0.1265089064836502
train-epoch-step: 16-134 -- Loss: 0.2208961546421051
train-epoch-step: 16-135 -- Loss: 0.16003119945526123
train-epoch-step: 16-136 -- Loss: 0.14606939256191254
train-epoch-step: 16-137 -- Loss: 0.27257242798805237
train-epoch-step: 16-138 -- Loss: 0.31272566318511963
train-epoch-step: 16-139 -- Loss: 0.14362174272537231
train-epoch-step: 16-140 -- Loss: 0.22281025350093842
train-epoch-step: 16-141 -- Loss: 0.23905476927757263
train-epoch-step: 16-142 -- Loss: 0.22350773215293884
train-epoch-step: 16-143 -- Loss: 0.19799965620040894
train-epoch-step: 16-144 -- Loss: 0.20287960767745972
train-epoch-step: 16-145 -- Loss: 0.15792176127433777
train-epoch-step: 16-146 -- Loss: 0.19700579345226288
train-epoch-step: 16-147 -- Loss: 0.19805282354354858
train-epoch-step: 16-148 -- Loss: 0.17513129115104675
train-epoch-step: 16-149 -- Loss: 0.1280551254749298
train-epoch-step: 16-150 -- Loss: 0.19899341464042664
train-epoch-step: 16-151 -- Loss: 0.20672963559627533
train-epoch-step: 16-152 -- Loss: 0.20757034420967102
train-epoch-step: 16-153 -- Loss: 0.3135302662849426
train-epoch-step: 16-154 -- Loss: 0.14270003139972687
train-epoch-step: 16-155 -- Loss: 0.14900115132331848
train-epoch-step: 16-156 -- Loss: 0.1350308656692505
train-epoch-step: 16-157 -- Loss: 0.1849280595779419
train-epoch-step: 16-158 -- Loss: 0.17921042442321777
train-epoch-step: 16-159 -- Loss: 0.18943490087985992
train-epoch-step: 16-160 -- Loss: 0.2459990680217743
train-epoch-step: 16-161 -- Loss: 0.2235282063484192
train-epoch-step: 16-162 -- Loss: 0.22543369233608246
train-epoch-step: 16-163 -- Loss: 0.20352229475975037
train-epoch-step: 16-164 -- Loss: 0.20570622384548187
train-epoch-step: 16-165 -- Loss: 0.18422579765319824
train-epoch-step: 16-166 -- Loss: 0.13482463359832764
train-epoch-step: 16-167 -- Loss: 0.1336950957775116
train-epoch-step: 16-168 -- Loss: 0.22087495028972626
train-epoch-step: 16-169 -- Loss: 0.15409237146377563
train-epoch-step: 16-170 -- Loss: 0.21245910227298737
train-epoch-step: 16-171 -- Loss: 0.1579812914133072
train-epoch-step: 16-172 -- Loss: 0.27990153431892395
train-epoch-step: 16-173 -- Loss: 0.148246169090271
train-epoch-step: 16-174 -- Loss: 0.2692314386367798
train-epoch-step: 16-175 -- Loss: 0.19622638821601868
train-epoch-step: 16-176 -- Loss: 0.1481098085641861
train-epoch-step: 16-177 -- Loss: 0.20043057203292847
train-epoch-step: 16-178 -- Loss: 0.20504330098628998
train-epoch-step: 16-179 -- Loss: 0.16645970940589905
train-epoch-step: 16-180 -- Loss: 0.16651636362075806
train-epoch-step: 16-181 -- Loss: 0.17958615720272064
train-epoch-step: 16-182 -- Loss: 0.20228837430477142
train-epoch-step: 16-183 -- Loss: 0.3024662137031555
train-epoch-step: 16-184 -- Loss: 0.1522660255432129
train-epoch-step: 16-185 -- Loss: 0.15709766745567322
train-epoch-step: 16-186 -- Loss: 0.2067773938179016
train-epoch-step: 16-187 -- Loss: 0.2288186252117157
train-epoch-step: 16-188 -- Loss: 0.18675778806209564
train-epoch-step: 16-189 -- Loss: 0.12060035765171051
train-epoch-step: 16-190 -- Loss: 0.1963413804769516
train-epoch-step: 16-191 -- Loss: 0.17974314093589783
train-epoch-step: 16-192 -- Loss: 0.24982225894927979
train-epoch-step: 16-193 -- Loss: 0.24035048484802246
train-epoch-step: 16-194 -- Loss: 0.19352039694786072
train-epoch-step: 16-195 -- Loss: 0.1774987131357193
train-epoch-step: 16-196 -- Loss: 0.188410222530365
train-epoch-step: 16-197 -- Loss: 0.15538327395915985
train-epoch-step: 16-198 -- Loss: 0.1495259702205658
train-epoch-step: 16-199 -- Loss: 0.17123737931251526
train-epoch-step: 16-200 -- Loss: 0.13511072099208832
train-epoch-step: 16-201 -- Loss: 0.2206839621067047
train-epoch-step: 16-202 -- Loss: 0.14259952306747437
train-epoch-step: 16-203 -- Loss: 0.1931898593902588
train-epoch-step: 16-204 -- Loss: 0.16417831182479858
train-epoch-step: 16-205 -- Loss: 0.2013993263244629
train-epoch-step: 16-206 -- Loss: 0.23219428956508636
train-epoch-step: 16-207 -- Loss: 0.1641506552696228
train-epoch-step: 16-208 -- Loss: 0.19193308055400848
train-epoch-step: 16-209 -- Loss: 0.15299080312252045
train-epoch-step: 16-210 -- Loss: 0.1462477147579193
train-epoch-step: 16-211 -- Loss: 0.22935962677001953
train-epoch-step: 16-212 -- Loss: 0.2201545536518097
train-epoch-step: 16-213 -- Loss: 0.13325916230678558
train-epoch-step: 16-214 -- Loss: 0.16067667305469513
train-epoch-step: 16-215 -- Loss: 0.1403154730796814
train-epoch-step: 16-216 -- Loss: 0.21873138844966888
train-epoch-step: 16-217 -- Loss: 0.23343884944915771
train-epoch-step: 16-218 -- Loss: 0.16474752128124237
train-epoch-step: 16-219 -- Loss: 0.18729928135871887
train-epoch-step: 16-220 -- Loss: 0.1408795267343521
train-epoch-step: 16-221 -- Loss: 0.22161109745502472
train-epoch-step: 16-222 -- Loss: 0.12660251557826996
train-epoch-step: 16-223 -- Loss: 0.18919968605041504
train-epoch-step: 16-224 -- Loss: 0.2158753126859665
train-epoch-step: 16-225 -- Loss: 0.29286110401153564
train-epoch-step: 16-226 -- Loss: 0.22263836860656738
train-epoch-step: 16-227 -- Loss: 0.24079594016075134
train-epoch-step: 16-228 -- Loss: 0.19645455479621887
train-epoch-step: 16-229 -- Loss: 0.1903117299079895
train-epoch-step: 16-230 -- Loss: 0.1772485375404358
train-epoch-step: 16-231 -- Loss: 0.17989204823970795
train-epoch-step: 16-232 -- Loss: 0.21463686227798462
train-epoch-step: 16-233 -- Loss: 0.09241960942745209
train-epoch-step: 16-234 -- Loss: 0.2048351913690567
train-epoch-step: 16-235 -- Loss: 0.16219526529312134
train-epoch-step: 16-236 -- Loss: 0.18960942327976227
train-epoch-step: 16-237 -- Loss: 0.28577226400375366
train-epoch-step: 16-238 -- Loss: 0.17071455717086792
train-epoch-step: 16-239 -- Loss: 0.14636294543743134
train-epoch-step: 16-240 -- Loss: 0.24090397357940674
train-epoch-step: 16-241 -- Loss: 0.169009268283844
train-epoch-step: 16-242 -- Loss: 0.24050350487232208
train-epoch-step: 16-243 -- Loss: 0.25236237049102783
train-epoch-step: 16-244 -- Loss: 0.2269333004951477
train-epoch-step: 16-245 -- Loss: 0.22700567543506622
train-epoch-step: 16-246 -- Loss: 0.23554494976997375
train-epoch-step: 16-247 -- Loss: 0.2596477270126343
train-epoch-step: 16-248 -- Loss: 0.20567265152931213
train-epoch-step: 16-249 -- Loss: 0.1557224988937378
train-epoch-step: 16-250 -- Loss: 0.22331488132476807
train-epoch-step: 16-251 -- Loss: 0.11679677665233612
train-epoch-step: 16-252 -- Loss: 0.20729593932628632
train-epoch-step: 16-253 -- Loss: 0.15497556328773499
train-epoch-step: 16-254 -- Loss: 0.24074631929397583
train-epoch-step: 16-255 -- Loss: 0.1594010591506958
train-epoch-step: 16-256 -- Loss: 0.1739099621772766
train-epoch-step: 16-257 -- Loss: 0.21250903606414795
train-epoch-step: 16-258 -- Loss: 0.15855672955513
train-epoch-step: 16-259 -- Loss: 0.13186877965927124
train-epoch-step: 16-260 -- Loss: 0.2208440899848938
train-epoch-step: 16-261 -- Loss: 0.18392938375473022
train-epoch-step: 16-262 -- Loss: 0.35000455379486084
train-epoch-step: 16-263 -- Loss: 0.22553616762161255
train-epoch-step: 16-264 -- Loss: 0.18593254685401917
train-epoch-step: 16-265 -- Loss: 0.13359913229942322
train-epoch-step: 16-266 -- Loss: 0.15979473292827606
train-epoch-step: 16-267 -- Loss: 0.1453809142112732
train-epoch-step: 16-268 -- Loss: 0.13541647791862488
train-epoch-step: 16-269 -- Loss: 0.1845540702342987
train-epoch-step: 16-270 -- Loss: 0.11832253634929657
train-epoch-step: 16-271 -- Loss: 0.1635604202747345
train-epoch-step: 16-272 -- Loss: 0.13024604320526123
train-epoch-step: 16-273 -- Loss: 0.1474655270576477
train-epoch-step: 16-274 -- Loss: 0.22698599100112915
train-epoch-step: 16-275 -- Loss: 0.21843886375427246
train-epoch-step: 16-276 -- Loss: 0.17267632484436035
train-epoch-step: 16-277 -- Loss: 0.1708541065454483
train-epoch-step: 16-278 -- Loss: 0.16496841609477997
train-epoch-step: 16-279 -- Loss: 0.16240376234054565
train-epoch-step: 16-280 -- Loss: 0.24085351824760437
train-epoch-step: 16-281 -- Loss: 0.20702220499515533
train-epoch-step: 16-282 -- Loss: 0.16235992312431335
train-epoch-step: 16-283 -- Loss: 0.13560190796852112
train-epoch-step: 16-284 -- Loss: 0.16451941430568695
train-epoch-step: 16-285 -- Loss: 0.21339967846870422
train-epoch-step: 16-286 -- Loss: 0.1731053739786148
train-epoch-step: 16-287 -- Loss: 0.22990202903747559
train-epoch-step: 16-288 -- Loss: 0.10615003108978271
train-epoch-step: 16-289 -- Loss: 0.13684320449829102
train-epoch-step: 16-290 -- Loss: 0.20682942867279053
train-epoch-step: 16-291 -- Loss: 0.12917067110538483
train-epoch-step: 16-292 -- Loss: 0.16803230345249176
train-epoch-step: 16-293 -- Loss: 0.15420758724212646
train-epoch-step: 16-294 -- Loss: 0.19171589612960815
train-epoch-step: 16-295 -- Loss: 0.31878602504730225
train-epoch-step: 16-296 -- Loss: 0.19818642735481262
train-epoch-step: 16-297 -- Loss: 0.18999609351158142
train-epoch-step: 16-298 -- Loss: 0.2618359625339508
train-epoch-step: 16-299 -- Loss: 0.16700716316699982
train-epoch-step: 16-300 -- Loss: 0.18895378708839417
train-epoch-step: 16-301 -- Loss: 0.1902080774307251
train-epoch-step: 16-302 -- Loss: 0.24156010150909424
train-epoch-step: 16-303 -- Loss: 0.225266695022583
train-epoch-step: 16-304 -- Loss: 0.1549616903066635
train-epoch-step: 16-305 -- Loss: 0.1603773832321167
train-epoch-step: 16-306 -- Loss: 0.25860458612442017
train-epoch-step: 16-307 -- Loss: 0.1815934181213379
train-epoch-step: 16-308 -- Loss: 0.24317368865013123
train-epoch-step: 16-309 -- Loss: 0.16796445846557617
train-epoch-step: 16-310 -- Loss: 0.18496546149253845
train-epoch-step: 16-311 -- Loss: 0.17989671230316162
train-epoch-step: 16-312 -- Loss: 0.23182114958763123
train-epoch-step: 16-313 -- Loss: 0.10977090895175934
train-epoch-step: 16-314 -- Loss: 0.22769445180892944
train-epoch-step: 16-315 -- Loss: 0.18569311499595642
train-epoch-step: 16-316 -- Loss: 0.16663242876529694
train-epoch-step: 16-317 -- Loss: 0.15359444916248322
train-epoch-step: 16-318 -- Loss: 0.1742878556251526
train-epoch-step: 16-319 -- Loss: 0.19577109813690186
train-epoch-step: 16-320 -- Loss: 0.12846273183822632
train-epoch-step: 16-321 -- Loss: 0.14477373659610748
train-epoch-step: 16-322 -- Loss: 0.2255891114473343
train-epoch-step: 16-323 -- Loss: 0.17339977622032166
train-epoch-step: 16-324 -- Loss: 0.279191255569458
train-epoch-step: 16-325 -- Loss: 0.16531267762184143
train-epoch-step: 16-326 -- Loss: 0.18275748193264008
train-epoch-step: 16-327 -- Loss: 0.23445522785186768
train-epoch-step: 16-328 -- Loss: 0.20850232243537903
train-epoch-step: 16-329 -- Loss: 0.35224875807762146
train-epoch-step: 16-330 -- Loss: 0.39719879627227783
train-epoch-step: 16-331 -- Loss: 0.23338712751865387
train-epoch-step: 16-332 -- Loss: 0.1203354001045227
train-epoch-step: 16-333 -- Loss: 0.20497775077819824
train-epoch-step: 16-334 -- Loss: 0.16829043626785278
train-epoch-step: 16-335 -- Loss: 0.19435718655586243
train-epoch-step: 16-336 -- Loss: 0.16800327599048615
train-epoch-step: 16-337 -- Loss: 0.2414899617433548
train-epoch-step: 16-338 -- Loss: 0.172723650932312
train-epoch-step: 16-339 -- Loss: 0.15728184580802917
train-epoch-step: 16-340 -- Loss: 0.217583566904068
train-epoch-step: 16-341 -- Loss: 0.1536017209291458
train-epoch-step: 16-342 -- Loss: 0.18614372611045837
train-epoch-step: 16-343 -- Loss: 0.16922533512115479
train-epoch-step: 16-344 -- Loss: 0.1890224814414978
train-epoch-step: 16-345 -- Loss: 0.14416493475437164
train-epoch-step: 16-346 -- Loss: 0.22407138347625732
train-epoch-step: 16-347 -- Loss: 0.16912081837654114
train-epoch-step: 16-348 -- Loss: 0.23302581906318665
train-epoch-step: 16-349 -- Loss: 0.2294287383556366
train-epoch-step: 16-350 -- Loss: 0.2880380153656006
train-epoch-step: 16-351 -- Loss: 0.21505191922187805
train-epoch-step: 16-352 -- Loss: 0.13867764174938202
train-epoch-step: 16-353 -- Loss: 0.21027523279190063
train-epoch-step: 16-354 -- Loss: 0.2971077859401703
train-epoch-step: 16-355 -- Loss: 0.13152211904525757
train-epoch-step: 16-356 -- Loss: 0.12658779323101044
train-epoch-step: 16-357 -- Loss: 0.20856143534183502
train-epoch-step: 16-358 -- Loss: 0.1989009827375412
train-epoch-step: 16-359 -- Loss: 0.1616370975971222
train-epoch-step: 16-360 -- Loss: 0.1327752321958542
train-epoch-step: 16-361 -- Loss: 0.2575681507587433
train-epoch-step: 16-362 -- Loss: 0.18132945895195007
train-epoch-step: 16-363 -- Loss: 0.12739786505699158
train-epoch-step: 16-364 -- Loss: 0.20358356833457947
train-epoch-step: 16-365 -- Loss: 0.1889529973268509
train-epoch-step: 16-366 -- Loss: 0.2150058150291443
train-epoch-step: 16-367 -- Loss: 0.2617083191871643
train-epoch-step: 16-368 -- Loss: 0.2293686419725418
train-epoch-step: 16-369 -- Loss: 0.3003859519958496
train-epoch-step: 16-370 -- Loss: 0.1341918259859085
train-epoch-step: 16-371 -- Loss: 0.1290186494588852
train-epoch-step: 16-372 -- Loss: 0.15885411202907562
train-epoch-step: 16-373 -- Loss: 0.21763962507247925
train-epoch-step: 16-374 -- Loss: 0.16841551661491394
train-epoch-step: 16-375 -- Loss: 0.29181262850761414
train-epoch-step: 16-376 -- Loss: 0.1921127438545227
train-epoch-step: 16-377 -- Loss: 0.2515563368797302
train-epoch-step: 16-378 -- Loss: 0.22484876215457916
train-epoch-step: 16-379 -- Loss: 0.13165542483329773
train-epoch-step: 16-380 -- Loss: 0.09819835424423218
train-epoch-step: 16-381 -- Loss: 0.27065545320510864
train-epoch-step: 16-382 -- Loss: 0.24941839277744293
train-epoch-step: 16-383 -- Loss: 0.19225847721099854
train-epoch-step: 16-384 -- Loss: 0.2514033913612366
train-epoch-step: 16-385 -- Loss: 0.2112802118062973
train-epoch-step: 16-386 -- Loss: 0.2023726850748062
train-epoch-step: 16-387 -- Loss: 0.22643421590328217
train-epoch-step: 16-388 -- Loss: 0.24473649263381958
train-epoch-step: 16-389 -- Loss: 0.1829299032688141
train-epoch-step: 16-390 -- Loss: 0.15753154456615448
train-epoch-step: 16-391 -- Loss: 0.16259987652301788
train-epoch-step: 16-392 -- Loss: 0.1990305483341217
train-epoch-step: 16-393 -- Loss: 0.17048285901546478
train-epoch-step: 16-394 -- Loss: 0.23487970232963562
train-epoch-step: 16-395 -- Loss: 0.18201781809329987
train-epoch-step: 16-396 -- Loss: 0.14587965607643127
train-epoch-step: 16-397 -- Loss: 0.13869157433509827
train-epoch-step: 16-398 -- Loss: 0.21116477251052856
train-epoch-step: 16-399 -- Loss: 0.19712033867835999
train-epoch-step: 16-400 -- Loss: 0.3100586533546448
train-epoch-step: 16-401 -- Loss: 0.13258540630340576
train-epoch-step: 16-402 -- Loss: 0.27576744556427
train-epoch-step: 16-403 -- Loss: 0.1724483072757721
train-epoch-step: 16-404 -- Loss: 0.15266573429107666
train-epoch-step: 16-405 -- Loss: 0.1616116762161255
train-epoch-step: 16-406 -- Loss: 0.18732987344264984
train-epoch-step: 16-407 -- Loss: 0.1276257187128067
train-epoch-step: 16-408 -- Loss: 0.17524957656860352
train-epoch-step: 16-409 -- Loss: 0.18570472300052643
train-epoch-step: 16-410 -- Loss: 0.19123724102973938
train-epoch-step: 16-411 -- Loss: 0.21165260672569275
train-epoch-step: 16-412 -- Loss: 0.1434863805770874
train-epoch-step: 16-413 -- Loss: 0.16014984250068665
train-epoch-step: 16-414 -- Loss: 0.14764738082885742
train-epoch-step: 16-415 -- Loss: 0.14645709097385406
train-epoch-step: 16-416 -- Loss: 0.2755592167377472
train-epoch-step: 16-417 -- Loss: 0.21454550325870514
train-epoch-step: 16-418 -- Loss: 0.271624892950058
train-epoch-step: 16-419 -- Loss: 0.18262407183647156
train-epoch-step: 16-420 -- Loss: 0.16967326402664185
train-epoch-step: 16-421 -- Loss: 0.19632528722286224
train-epoch-step: 16-422 -- Loss: 0.15701843798160553
train-epoch-step: 16-423 -- Loss: 0.18503086268901825
train-epoch-step: 16-424 -- Loss: 0.1478016972541809
train-epoch-step: 16-425 -- Loss: 0.19580456614494324
train-epoch-step: 16-426 -- Loss: 0.17713874578475952
train-epoch-step: 16-427 -- Loss: 0.13951480388641357
train-epoch-step: 16-428 -- Loss: 0.20954793691635132
train-epoch-step: 16-429 -- Loss: 0.1897871047258377
train-epoch-step: 16-430 -- Loss: 0.16169865429401398
train-epoch-step: 16-431 -- Loss: 0.18342921137809753
train-epoch-step: 16-432 -- Loss: 0.25682345032691956
train-epoch-step: 16-433 -- Loss: 0.14749710261821747
train-epoch-step: 16-434 -- Loss: 0.1367797553539276
train-epoch-step: 16-435 -- Loss: 0.17348013818264008
train-epoch-step: 16-436 -- Loss: 0.17047396302223206
train-epoch-step: 16-437 -- Loss: 0.14341484010219574
train-epoch-step: 16-438 -- Loss: 0.20080068707466125
train-epoch-step: 16-439 -- Loss: 0.28581178188323975
train-epoch-step: 16-440 -- Loss: 0.14466775953769684
train-epoch-step: 16-441 -- Loss: 0.22298210859298706
train-epoch-step: 16-442 -- Loss: 0.20620959997177124
train-epoch-step: 16-443 -- Loss: 0.17581766843795776
train-epoch-step: 16-444 -- Loss: 0.25631025433540344
train-epoch-step: 16-445 -- Loss: 0.1966404914855957
train-epoch-step: 16-446 -- Loss: 0.17719323933124542
train-epoch-step: 16-447 -- Loss: 0.21684063971042633
train-epoch-step: 16-448 -- Loss: 0.2984906733036041
train-epoch-step: 16-449 -- Loss: 0.21875199675559998
train-epoch-step: 16-450 -- Loss: 0.20517078042030334
train-epoch-step: 16-451 -- Loss: 0.16363398730754852
train-epoch-step: 16-452 -- Loss: 0.14828428626060486
train-epoch-step: 16-453 -- Loss: 0.10576517134904861
train-epoch-step: 16-454 -- Loss: 0.26055556535720825
train-epoch-step: 16-455 -- Loss: 0.1403801441192627
train-epoch-step: 16-456 -- Loss: 0.1406233012676239
train-epoch-step: 16-457 -- Loss: 0.24453797936439514
train-epoch-step: 16-458 -- Loss: 0.18012584745883942
train-epoch-step: 16-459 -- Loss: 0.26641789078712463
train-epoch-step: 16-460 -- Loss: 0.140230193734169
train-epoch-step: 16-461 -- Loss: 0.15778149664402008
train-epoch-step: 16-462 -- Loss: 0.18426892161369324
train-epoch-step: 16-463 -- Loss: 0.16391673684120178
train-epoch-step: 16-464 -- Loss: 0.20109358429908752
train-epoch-step: 16-465 -- Loss: 0.345490038394928
train-epoch-step: 16-466 -- Loss: 0.21844139695167542
train-epoch-step: 16-467 -- Loss: 0.1297968178987503
train-epoch-step: 16-468 -- Loss: 0.1978587955236435
train-epoch-step: 16-469 -- Loss: 0.24151308834552765
train-epoch-step: 16-470 -- Loss: 0.19880469143390656
train-epoch-step: 16-471 -- Loss: 0.1670294851064682
train-epoch-step: 16-472 -- Loss: 0.1676764041185379
train-epoch-step: 16-473 -- Loss: 0.19301481544971466
train-epoch-step: 16-474 -- Loss: 0.13341112434864044
train-epoch-step: 16-475 -- Loss: 0.12672863900661469
train-epoch-step: 16-476 -- Loss: 0.2222866266965866
train-epoch-step: 16-477 -- Loss: 0.22464478015899658
train-epoch-step: 16-478 -- Loss: 0.21226845681667328
train-epoch-step: 16-479 -- Loss: 0.15557760000228882
train-epoch-step: 16-480 -- Loss: 0.215600848197937
train-epoch-step: 16-481 -- Loss: 0.30523476004600525
train-epoch-step: 16-482 -- Loss: 0.29540443420410156
train-epoch-step: 16-483 -- Loss: 0.1999630331993103
train-epoch-step: 16-484 -- Loss: 0.2288963347673416
train-epoch-step: 16-485 -- Loss: 0.15473338961601257
train-epoch-step: 16-486 -- Loss: 0.27017703652381897
train-epoch-step: 16-487 -- Loss: 0.248725026845932
train-epoch-step: 16-488 -- Loss: 0.2121744453907013
train-epoch-step: 16-489 -- Loss: 0.2332860231399536
train-epoch-step: 16-490 -- Loss: 0.15325184166431427
train-epoch-step: 16-491 -- Loss: 0.1519201397895813
train-epoch-step: 16-492 -- Loss: 0.13541153073310852
train-epoch-step: 16-493 -- Loss: 0.2348702847957611
train-epoch-step: 16-494 -- Loss: 0.2265806496143341
train-epoch-step: 16-495 -- Loss: 0.22546571493148804
train-epoch-step: 16-496 -- Loss: 0.14750416576862335
train-epoch-step: 16-497 -- Loss: 0.20503339171409607
train-epoch-step: 16-498 -- Loss: 0.16356289386749268
train-epoch-step: 16-499 -- Loss: 0.19305041432380676
train-epoch-step: 16-500 -- Loss: 0.17135794460773468
train-epoch-step: 16-501 -- Loss: 0.24067696928977966
train-epoch-step: 16-502 -- Loss: 0.21679557859897614
train-epoch-step: 16-503 -- Loss: 0.238723024725914
train-epoch-step: 16-504 -- Loss: 0.13202928006649017
train-epoch-step: 16-505 -- Loss: 0.19431105256080627
train-epoch-step: 16-506 -- Loss: 0.13140033185482025
train-epoch-step: 16-507 -- Loss: 0.20762576162815094
train-epoch-step: 16-508 -- Loss: 0.19179204106330872
train-epoch-step: 16-509 -- Loss: 0.1876191794872284
train-epoch-step: 16-510 -- Loss: 0.14231380820274353
train-epoch-step: 16-511 -- Loss: 0.23875829577445984
train-epoch-step: 16-512 -- Loss: 0.19786523282527924
train-epoch-step: 16-513 -- Loss: 0.23497360944747925
train-epoch-step: 16-514 -- Loss: 0.17021813988685608
train-epoch-step: 16-515 -- Loss: 0.18061958253383636
train-epoch-step: 16-516 -- Loss: 0.1864829808473587
train-epoch-step: 16-517 -- Loss: 0.19516395032405853
train-epoch-step: 16-518 -- Loss: 0.15085047483444214
train-epoch-step: 16-519 -- Loss: 0.14605812728405
train-epoch-step: 16-520 -- Loss: 0.20208409428596497
train-epoch-step: 16-521 -- Loss: 0.25390172004699707
train-epoch-step: 16-522 -- Loss: 0.2049393355846405
train-epoch-step: 16-523 -- Loss: 0.16982722282409668
train-epoch-step: 16-524 -- Loss: 0.19478942453861237
train-epoch-step: 16-525 -- Loss: 0.20971480011940002
train-epoch-step: 16-526 -- Loss: 0.14299461245536804
train-epoch-step: 16-527 -- Loss: 0.17013053596019745
train-epoch-step: 16-528 -- Loss: 0.17414861917495728
train-epoch-step: 16-529 -- Loss: 0.18738220632076263
train-epoch-step: 16-530 -- Loss: 0.17621271312236786
train-epoch-step: 16-531 -- Loss: 0.22832351922988892
train-epoch-step: 16-532 -- Loss: 0.19382290542125702
train-epoch-step: 16-533 -- Loss: 0.18397843837738037
train-epoch-step: 16-534 -- Loss: 0.15196675062179565
train-epoch-step: 16-535 -- Loss: 0.2910911738872528
train-epoch-step: 16-536 -- Loss: 0.17193648219108582
train-epoch-step: 16-537 -- Loss: 0.1625579297542572
train-epoch-step: 16-538 -- Loss: 0.11523333936929703
train-epoch-step: 16-539 -- Loss: 0.212568998336792
train-epoch-step: 16-540 -- Loss: 0.14988727867603302
train-epoch-step: 16-541 -- Loss: 0.22062090039253235
train-epoch-step: 16-542 -- Loss: 0.24909162521362305
train-epoch-step: 16-543 -- Loss: 0.1839071810245514
train-epoch-step: 16-544 -- Loss: 0.24771660566329956
train-epoch-step: 16-545 -- Loss: 0.22154821455478668
train-epoch-step: 16-546 -- Loss: 0.23320867121219635
train-epoch-step: 16-547 -- Loss: 0.19234715402126312
train-epoch-step: 16-548 -- Loss: 0.10505058616399765
train-epoch-step: 16-549 -- Loss: 0.16428804397583008
train-epoch-step: 16-550 -- Loss: 0.21560734510421753
train-epoch-step: 16-551 -- Loss: 0.17684057354927063
train-epoch-step: 16-552 -- Loss: 0.14733988046646118
train-epoch-step: 16-553 -- Loss: 0.2027769386768341
train-epoch-step: 16-554 -- Loss: 0.19859743118286133
train-epoch-step: 16-555 -- Loss: 0.2239779680967331
train-epoch-step: 16-556 -- Loss: 0.17310407757759094
train-epoch-step: 16-557 -- Loss: 0.26052412390708923
train-epoch-step: 16-558 -- Loss: 0.24585874378681183
train-epoch-step: 16-559 -- Loss: 0.16217981278896332
train-epoch-step: 16-560 -- Loss: 0.2249915450811386
train-epoch-step: 16-561 -- Loss: 0.2024250626564026
train-epoch-step: 16-562 -- Loss: 0.1894269436597824
train-epoch-step: 16-563 -- Loss: 0.21081727743148804
train-epoch-step: 16-564 -- Loss: 0.10960028320550919
train-epoch-step: 16-565 -- Loss: 0.19929957389831543
train-epoch-step: 16-566 -- Loss: 0.1757894903421402
train-epoch-step: 16-567 -- Loss: 0.22604268789291382
train-epoch-step: 16-568 -- Loss: 0.1721234917640686
train-epoch-step: 16-569 -- Loss: 0.25496524572372437
train-epoch-step: 16-570 -- Loss: 0.18810294568538666
train-epoch-step: 16-571 -- Loss: 0.2288847267627716
train-epoch-step: 16-572 -- Loss: 0.2682131230831146
train-epoch-step: 16-573 -- Loss: 0.21918143332004547
train-epoch-step: 16-574 -- Loss: 0.26777851581573486
train-epoch-step: 16-575 -- Loss: 0.33525902032852173
train-epoch-step: 16-576 -- Loss: 0.13240160048007965
train-epoch-step: 16-577 -- Loss: 0.19372011721134186
train-epoch-step: 16-578 -- Loss: 0.2351296842098236
train-epoch-step: 16-579 -- Loss: 0.17478793859481812
train-epoch-step: 16-580 -- Loss: 0.20632623136043549
train-epoch-step: 16-581 -- Loss: 0.16166174411773682
train-epoch-step: 16-582 -- Loss: 0.2203722447156906
train-epoch-step: 16-583 -- Loss: 0.23598626255989075
train-epoch-step: 16-584 -- Loss: 0.20398829877376556
train-epoch-step: 16-585 -- Loss: 0.21068620681762695
train-epoch-step: 16-586 -- Loss: 0.2782467305660248
train-epoch-step: 16-587 -- Loss: 0.17019398510456085
train-epoch-step: 16-588 -- Loss: 0.13890787959098816
val-epoch-step: 16-589 -- Loss: 0.2202235907316208
val-epoch-step: 16-590 -- Loss: 0.15875589847564697
val-epoch-step: 16-591 -- Loss: 0.23748904466629028
val-epoch-step: 16-592 -- Loss: 0.1953316181898117
val-epoch-step: 16-593 -- Loss: 0.16106227040290833
val-epoch-step: 16-594 -- Loss: 0.3796657621860504
val-epoch-step: 16-595 -- Loss: 0.20519417524337769
val-epoch-step: 16-596 -- Loss: 0.22568738460540771
val-epoch-step: 16-597 -- Loss: 0.19268125295639038
val-epoch-step: 16-598 -- Loss: 0.15870998799800873
val-epoch-step: 16-599 -- Loss: 0.19790083169937134
val-epoch-step: 16-600 -- Loss: 0.20318332314491272
val-epoch-step: 16-601 -- Loss: 0.16413410007953644
val-epoch-step: 16-602 -- Loss: 0.14666089415550232
val-epoch-step: 16-603 -- Loss: 0.18923674523830414
val-epoch-step: 16-604 -- Loss: 0.15924718976020813
val-epoch-step: 16-605 -- Loss: 0.16083121299743652
val-epoch-step: 16-606 -- Loss: 0.2851696312427521
val-epoch-step: 16-607 -- Loss: 0.1369939148426056
val-epoch-step: 16-608 -- Loss: 0.26037442684173584
val-epoch-step: 16-609 -- Loss: 0.1795867681503296
val-epoch-step: 16-610 -- Loss: 0.19243010878562927
val-epoch-step: 16-611 -- Loss: 0.1945975422859192
val-epoch-step: 16-612 -- Loss: 0.44058021903038025
val-epoch-step: 16-613 -- Loss: 0.18333183228969574
val-epoch-step: 16-614 -- Loss: 0.16630254685878754
val-epoch-step: 16-615 -- Loss: 0.18673987686634064
val-epoch-step: 16-616 -- Loss: 0.16065450012683868
val-epoch-step: 16-617 -- Loss: 0.20067813992500305
val-epoch-step: 16-618 -- Loss: 0.202852264046669
val-epoch-step: 16-619 -- Loss: 0.23150081932544708
val-epoch-step: 16-620 -- Loss: 0.1479957103729248
val-epoch-step: 16-621 -- Loss: 0.13954752683639526
val-epoch-step: 16-622 -- Loss: 0.15736757218837738
val-epoch-step: 16-623 -- Loss: 0.16524651646614075
val-epoch-step: 16-624 -- Loss: 0.1630786508321762
val-epoch-step: 16-625 -- Loss: 0.17019715905189514
val-epoch-step: 16-626 -- Loss: 0.15647496283054352
val-epoch-step: 16-627 -- Loss: 0.20557743310928345
val-epoch-step: 16-628 -- Loss: 0.6340492963790894
val-epoch-step: 16-629 -- Loss: 0.23231224715709686
val-epoch-step: 16-630 -- Loss: 0.3623867630958557
val-epoch-step: 16-631 -- Loss: 0.1511777937412262
val-epoch-step: 16-632 -- Loss: 0.22629696130752563
val-epoch-step: 16-633 -- Loss: 0.1637013703584671
val-epoch-step: 16-634 -- Loss: 0.15276911854743958
val-epoch-step: 16-635 -- Loss: 0.12562145292758942
val-epoch-step: 16-636 -- Loss: 0.17775589227676392
val-epoch-step: 16-637 -- Loss: 0.19129836559295654
val-epoch-step: 16-638 -- Loss: 0.16400453448295593
val-epoch-step: 16-639 -- Loss: 0.27573060989379883
val-epoch-step: 16-640 -- Loss: 0.2772313952445984
val-epoch-step: 16-641 -- Loss: 0.13563112914562225
val-epoch-step: 16-642 -- Loss: 0.20730534195899963
val-epoch-step: 16-643 -- Loss: 0.21795181930065155
val-epoch-step: 16-644 -- Loss: 0.17508934438228607
val-epoch-step: 16-645 -- Loss: 0.23363743722438812
val-epoch-step: 16-646 -- Loss: 0.14947572350502014
val-epoch-step: 16-647 -- Loss: 0.14480820298194885
val-epoch-step: 16-648 -- Loss: 0.17041248083114624
val-epoch-step: 16-649 -- Loss: 0.2345411479473114
val-epoch-step: 16-650 -- Loss: 0.267875611782074
val-epoch-step: 16-651 -- Loss: 0.16394832730293274
val-epoch-step: 16-652 -- Loss: 0.16691063344478607
val-epoch-step: 16-653 -- Loss: 0.21472907066345215
val-epoch-step: 16-654 -- Loss: 0.12213416397571564
Epoch: 16 -- Train Loss: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 17-0 -- Loss: 0.2424488365650177
train-epoch-step: 17-1 -- Loss: 0.15945765376091003
train-epoch-step: 17-2 -- Loss: 0.24425753951072693
train-epoch-step: 17-3 -- Loss: 0.1559038609266281
train-epoch-step: 17-4 -- Loss: 0.17710286378860474
train-epoch-step: 17-5 -- Loss: 0.24010860919952393
train-epoch-step: 17-6 -- Loss: 0.26369547843933105
train-epoch-step: 17-7 -- Loss: 0.18882614374160767
train-epoch-step: 17-8 -- Loss: 0.20731642842292786
train-epoch-step: 17-9 -- Loss: 0.27036231756210327
train-epoch-step: 17-10 -- Loss: 0.22445440292358398
train-epoch-step: 17-11 -- Loss: 0.20029830932617188
train-epoch-step: 17-12 -- Loss: 0.17316317558288574
train-epoch-step: 17-13 -- Loss: 0.19837097823619843
train-epoch-step: 17-14 -- Loss: 0.17855146527290344
train-epoch-step: 17-15 -- Loss: 0.17791670560836792
train-epoch-step: 17-16 -- Loss: 0.18085461854934692
train-epoch-step: 17-17 -- Loss: 0.24083009362220764
train-epoch-step: 17-18 -- Loss: 0.20728063583374023
train-epoch-step: 17-19 -- Loss: 0.1401020735502243
train-epoch-step: 17-20 -- Loss: 0.24530746042728424
train-epoch-step: 17-21 -- Loss: 0.31373515725135803
train-epoch-step: 17-22 -- Loss: 0.16209867596626282
train-epoch-step: 17-23 -- Loss: 0.1614377349615097
train-epoch-step: 17-24 -- Loss: 0.13618862628936768
train-epoch-step: 17-25 -- Loss: 0.25189077854156494
train-epoch-step: 17-26 -- Loss: 0.21202847361564636
train-epoch-step: 17-27 -- Loss: 0.3181568384170532
train-epoch-step: 17-28 -- Loss: 0.1311991959810257
train-epoch-step: 17-29 -- Loss: 0.2758811116218567
train-epoch-step: 17-30 -- Loss: 0.12186811864376068
train-epoch-step: 17-31 -- Loss: 0.1542077213525772
train-epoch-step: 17-32 -- Loss: 0.18837684392929077
train-epoch-step: 17-33 -- Loss: 0.31235501170158386
train-epoch-step: 17-34 -- Loss: 0.1821516901254654
train-epoch-step: 17-35 -- Loss: 0.2728603184223175
train-epoch-step: 17-36 -- Loss: 0.16008149087429047
train-epoch-step: 17-37 -- Loss: 0.15214627981185913
train-epoch-step: 17-38 -- Loss: 0.2051680088043213
train-epoch-step: 17-39 -- Loss: 0.25241780281066895
train-epoch-step: 17-40 -- Loss: 0.24763469398021698
train-epoch-step: 17-41 -- Loss: 0.23551636934280396
train-epoch-step: 17-42 -- Loss: 0.16318312287330627
train-epoch-step: 17-43 -- Loss: 0.29057538509368896
train-epoch-step: 17-44 -- Loss: 0.14477227628231049
train-epoch-step: 17-45 -- Loss: 0.13933874666690826
train-epoch-step: 17-46 -- Loss: 0.19819051027297974
train-epoch-step: 17-47 -- Loss: 0.2511075735092163
train-epoch-step: 17-48 -- Loss: 0.1631961464881897
train-epoch-step: 17-49 -- Loss: 0.23932301998138428
train-epoch-step: 17-50 -- Loss: 0.1231774091720581
train-epoch-step: 17-51 -- Loss: 0.20869597792625427
train-epoch-step: 17-52 -- Loss: 0.17433300614356995
train-epoch-step: 17-53 -- Loss: 0.24354086816310883
train-epoch-step: 17-54 -- Loss: 0.3120212256908417
train-epoch-step: 17-55 -- Loss: 0.1870611011981964
train-epoch-step: 17-56 -- Loss: 0.20416463911533356
train-epoch-step: 17-57 -- Loss: 0.2596309781074524
train-epoch-step: 17-58 -- Loss: 0.3054991662502289
train-epoch-step: 17-59 -- Loss: 0.28061163425445557
train-epoch-step: 17-60 -- Loss: 0.14232510328292847
train-epoch-step: 17-61 -- Loss: 0.22057278454303741
train-epoch-step: 17-62 -- Loss: 0.20069053769111633
train-epoch-step: 17-63 -- Loss: 0.152386873960495
train-epoch-step: 17-64 -- Loss: 0.16361141204833984
train-epoch-step: 17-65 -- Loss: 0.20686252415180206
train-epoch-step: 17-66 -- Loss: 0.12214723229408264
train-epoch-step: 17-67 -- Loss: 0.13664397597312927
train-epoch-step: 17-68 -- Loss: 0.24853011965751648
train-epoch-step: 17-69 -- Loss: 0.1373031884431839
train-epoch-step: 17-70 -- Loss: 0.2384752631187439
train-epoch-step: 17-71 -- Loss: 0.27856317162513733
train-epoch-step: 17-72 -- Loss: 0.19878049194812775
train-epoch-step: 17-73 -- Loss: 0.22765257954597473
train-epoch-step: 17-74 -- Loss: 0.11088618636131287
train-epoch-step: 17-75 -- Loss: 0.1412566751241684
train-epoch-step: 17-76 -- Loss: 0.16449210047721863
train-epoch-step: 17-77 -- Loss: 0.24772486090660095
train-epoch-step: 17-78 -- Loss: 0.285514235496521
train-epoch-step: 17-79 -- Loss: 0.2083621323108673
train-epoch-step: 17-80 -- Loss: 0.29295703768730164
train-epoch-step: 17-81 -- Loss: 0.1347171515226364
train-epoch-step: 17-82 -- Loss: 0.2687741816043854
train-epoch-step: 17-83 -- Loss: 0.21155233681201935
train-epoch-step: 17-84 -- Loss: 0.20913179218769073
train-epoch-step: 17-85 -- Loss: 0.19065611064434052
train-epoch-step: 17-86 -- Loss: 0.1374545842409134
train-epoch-step: 17-87 -- Loss: 0.26761260628700256
train-epoch-step: 17-88 -- Loss: 0.15462979674339294
train-epoch-step: 17-89 -- Loss: 0.20108403265476227
train-epoch-step: 17-90 -- Loss: 0.21231496334075928
train-epoch-step: 17-91 -- Loss: 0.26234307885169983
train-epoch-step: 17-92 -- Loss: 0.17406466603279114
train-epoch-step: 17-93 -- Loss: 0.1897549033164978
train-epoch-step: 17-94 -- Loss: 0.23624315857887268
train-epoch-step: 17-95 -- Loss: 0.2160310447216034
train-epoch-step: 17-96 -- Loss: 0.2377479374408722
train-epoch-step: 17-97 -- Loss: 0.19482779502868652
train-epoch-step: 17-98 -- Loss: 0.16286137700080872
train-epoch-step: 17-99 -- Loss: 0.199462890625
train-epoch-step: 17-100 -- Loss: 0.1983465701341629
train-epoch-step: 17-101 -- Loss: 0.3168312907218933
train-epoch-step: 17-102 -- Loss: 0.2524385452270508
train-epoch-step: 17-103 -- Loss: 0.20577657222747803
train-epoch-step: 17-104 -- Loss: 0.1564120054244995
train-epoch-step: 17-105 -- Loss: 0.3047451078891754
train-epoch-step: 17-106 -- Loss: 0.18708622455596924
train-epoch-step: 17-107 -- Loss: 0.20276279747486115
train-epoch-step: 17-108 -- Loss: 0.2042291909456253
train-epoch-step: 17-109 -- Loss: 0.1616683304309845
train-epoch-step: 17-110 -- Loss: 0.19878575205802917
train-epoch-step: 17-111 -- Loss: 0.2023530900478363
train-epoch-step: 17-112 -- Loss: 0.1839548647403717
train-epoch-step: 17-113 -- Loss: 0.17578062415122986
train-epoch-step: 17-114 -- Loss: 0.21465477347373962
train-epoch-step: 17-115 -- Loss: 0.17565618455410004
train-epoch-step: 17-116 -- Loss: 0.1602538824081421
train-epoch-step: 17-117 -- Loss: 0.14450037479400635
train-epoch-step: 17-118 -- Loss: 0.2195385992527008
train-epoch-step: 17-119 -- Loss: 0.17174598574638367
train-epoch-step: 17-120 -- Loss: 0.26971933245658875
train-epoch-step: 17-121 -- Loss: 0.2882835268974304
train-epoch-step: 17-122 -- Loss: 0.23810574412345886
train-epoch-step: 17-123 -- Loss: 0.21926602721214294
train-epoch-step: 17-124 -- Loss: 0.12964452803134918
train-epoch-step: 17-125 -- Loss: 0.16221833229064941
train-epoch-step: 17-126 -- Loss: 0.24272218346595764
train-epoch-step: 17-127 -- Loss: 0.20198217034339905
train-epoch-step: 17-128 -- Loss: 0.184535413980484
train-epoch-step: 17-129 -- Loss: 0.16127261519432068
train-epoch-step: 17-130 -- Loss: 0.21376892924308777
train-epoch-step: 17-131 -- Loss: 0.14820848405361176
train-epoch-step: 17-132 -- Loss: 0.20077921450138092
train-epoch-step: 17-133 -- Loss: 0.12782904505729675
train-epoch-step: 17-134 -- Loss: 0.2203948199748993
train-epoch-step: 17-135 -- Loss: 0.15518391132354736
train-epoch-step: 17-136 -- Loss: 0.1435835361480713
train-epoch-step: 17-137 -- Loss: 0.2740415930747986
train-epoch-step: 17-138 -- Loss: 0.29196658730506897
train-epoch-step: 17-139 -- Loss: 0.14131397008895874
train-epoch-step: 17-140 -- Loss: 0.223300039768219
train-epoch-step: 17-141 -- Loss: 0.24495062232017517
train-epoch-step: 17-142 -- Loss: 0.22033382952213287
train-epoch-step: 17-143 -- Loss: 0.20349934697151184
train-epoch-step: 17-144 -- Loss: 0.19670677185058594
train-epoch-step: 17-145 -- Loss: 0.1532304584980011
train-epoch-step: 17-146 -- Loss: 0.19482219219207764
train-epoch-step: 17-147 -- Loss: 0.2002619206905365
train-epoch-step: 17-148 -- Loss: 0.17111682891845703
train-epoch-step: 17-149 -- Loss: 0.12734074890613556
train-epoch-step: 17-150 -- Loss: 0.19917619228363037
train-epoch-step: 17-151 -- Loss: 0.19851408898830414
train-epoch-step: 17-152 -- Loss: 0.20932428538799286
train-epoch-step: 17-153 -- Loss: 0.2923542857170105
train-epoch-step: 17-154 -- Loss: 0.1449684053659439
train-epoch-step: 17-155 -- Loss: 0.14748366177082062
train-epoch-step: 17-156 -- Loss: 0.1327095329761505
train-epoch-step: 17-157 -- Loss: 0.1907278299331665
train-epoch-step: 17-158 -- Loss: 0.17722022533416748
train-epoch-step: 17-159 -- Loss: 0.19223183393478394
train-epoch-step: 17-160 -- Loss: 0.253619909286499
train-epoch-step: 17-161 -- Loss: 0.22270391881465912
train-epoch-step: 17-162 -- Loss: 0.22073040902614594
train-epoch-step: 17-163 -- Loss: 0.20110753178596497
train-epoch-step: 17-164 -- Loss: 0.20640791952610016
train-epoch-step: 17-165 -- Loss: 0.17509567737579346
train-epoch-step: 17-166 -- Loss: 0.13319186866283417
train-epoch-step: 17-167 -- Loss: 0.13501796126365662
train-epoch-step: 17-168 -- Loss: 0.22599731385707855
train-epoch-step: 17-169 -- Loss: 0.1525259017944336
train-epoch-step: 17-170 -- Loss: 0.21240270137786865
train-epoch-step: 17-171 -- Loss: 0.15321342647075653
train-epoch-step: 17-172 -- Loss: 0.27721506357192993
train-epoch-step: 17-173 -- Loss: 0.14217932522296906
train-epoch-step: 17-174 -- Loss: 0.26968804001808167
train-epoch-step: 17-175 -- Loss: 0.1974453330039978
train-epoch-step: 17-176 -- Loss: 0.14905907213687897
train-epoch-step: 17-177 -- Loss: 0.20320402085781097
train-epoch-step: 17-178 -- Loss: 0.19242195785045624
train-epoch-step: 17-179 -- Loss: 0.16024519503116608
train-epoch-step: 17-180 -- Loss: 0.16291598975658417
train-epoch-step: 17-181 -- Loss: 0.18498103320598602
train-epoch-step: 17-182 -- Loss: 0.2091490924358368
train-epoch-step: 17-183 -- Loss: 0.2877909243106842
train-epoch-step: 17-184 -- Loss: 0.1472475826740265
train-epoch-step: 17-185 -- Loss: 0.15683704614639282
train-epoch-step: 17-186 -- Loss: 0.20500802993774414
train-epoch-step: 17-187 -- Loss: 0.22598236799240112
train-epoch-step: 17-188 -- Loss: 0.1873418092727661
train-epoch-step: 17-189 -- Loss: 0.11991789937019348
train-epoch-step: 17-190 -- Loss: 0.1913456916809082
train-epoch-step: 17-191 -- Loss: 0.18317312002182007
train-epoch-step: 17-192 -- Loss: 0.25994086265563965
train-epoch-step: 17-193 -- Loss: 0.24284116923809052
train-epoch-step: 17-194 -- Loss: 0.19318851828575134
train-epoch-step: 17-195 -- Loss: 0.17715680599212646
train-epoch-step: 17-196 -- Loss: 0.1781724989414215
train-epoch-step: 17-197 -- Loss: 0.15584471821784973
train-epoch-step: 17-198 -- Loss: 0.14698967337608337
train-epoch-step: 17-199 -- Loss: 0.1644730120897293
train-epoch-step: 17-200 -- Loss: 0.13753649592399597
train-epoch-step: 17-201 -- Loss: 0.21984544396400452
train-epoch-step: 17-202 -- Loss: 0.14581334590911865
train-epoch-step: 17-203 -- Loss: 0.1902032345533371
train-epoch-step: 17-204 -- Loss: 0.14979487657546997
train-epoch-step: 17-205 -- Loss: 0.20014849305152893
train-epoch-step: 17-206 -- Loss: 0.22307616472244263
train-epoch-step: 17-207 -- Loss: 0.15877924859523773
train-epoch-step: 17-208 -- Loss: 0.1924811154603958
train-epoch-step: 17-209 -- Loss: 0.1502191573381424
train-epoch-step: 17-210 -- Loss: 0.149014413356781
train-epoch-step: 17-211 -- Loss: 0.21733662486076355
train-epoch-step: 17-212 -- Loss: 0.21365141868591309
train-epoch-step: 17-213 -- Loss: 0.14521068334579468
train-epoch-step: 17-214 -- Loss: 0.15790292620658875
train-epoch-step: 17-215 -- Loss: 0.14002341032028198
train-epoch-step: 17-216 -- Loss: 0.21235258877277374
train-epoch-step: 17-217 -- Loss: 0.2320248782634735
train-epoch-step: 17-218 -- Loss: 0.1591378152370453
train-epoch-step: 17-219 -- Loss: 0.18987999856472015
train-epoch-step: 17-220 -- Loss: 0.13978460431098938
train-epoch-step: 17-221 -- Loss: 0.21846935153007507
train-epoch-step: 17-222 -- Loss: 0.13019037246704102
train-epoch-step: 17-223 -- Loss: 0.1851653754711151
train-epoch-step: 17-224 -- Loss: 0.21235184371471405
train-epoch-step: 17-225 -- Loss: 0.2964158356189728
train-epoch-step: 17-226 -- Loss: 0.22018706798553467
train-epoch-step: 17-227 -- Loss: 0.2424604296684265
train-epoch-step: 17-228 -- Loss: 0.19348886609077454
train-epoch-step: 17-229 -- Loss: 0.18731039762496948
train-epoch-step: 17-230 -- Loss: 0.17789269983768463
train-epoch-step: 17-231 -- Loss: 0.17528313398361206
train-epoch-step: 17-232 -- Loss: 0.21337890625
train-epoch-step: 17-233 -- Loss: 0.09456048905849457
train-epoch-step: 17-234 -- Loss: 0.19668586552143097
train-epoch-step: 17-235 -- Loss: 0.15866799652576447
train-epoch-step: 17-236 -- Loss: 0.19112756848335266
train-epoch-step: 17-237 -- Loss: 0.26722800731658936
train-epoch-step: 17-238 -- Loss: 0.167160302400589
train-epoch-step: 17-239 -- Loss: 0.14517360925674438
train-epoch-step: 17-240 -- Loss: 0.23457658290863037
train-epoch-step: 17-241 -- Loss: 0.16822338104248047
train-epoch-step: 17-242 -- Loss: 0.2402743548154831
train-epoch-step: 17-243 -- Loss: 0.2490810751914978
train-epoch-step: 17-244 -- Loss: 0.22111321985721588
train-epoch-step: 17-245 -- Loss: 0.22433894872665405
train-epoch-step: 17-246 -- Loss: 0.23703396320343018
train-epoch-step: 17-247 -- Loss: 0.26381686329841614
train-epoch-step: 17-248 -- Loss: 0.200846329331398
train-epoch-step: 17-249 -- Loss: 0.1529913693666458
train-epoch-step: 17-250 -- Loss: 0.2250700742006302
train-epoch-step: 17-251 -- Loss: 0.119338758289814
train-epoch-step: 17-252 -- Loss: 0.2081761211156845
train-epoch-step: 17-253 -- Loss: 0.14972297847270966
train-epoch-step: 17-254 -- Loss: 0.23453426361083984
train-epoch-step: 17-255 -- Loss: 0.16502128541469574
train-epoch-step: 17-256 -- Loss: 0.170756995677948
train-epoch-step: 17-257 -- Loss: 0.20353460311889648
train-epoch-step: 17-258 -- Loss: 0.15753690898418427
train-epoch-step: 17-259 -- Loss: 0.12721610069274902
train-epoch-step: 17-260 -- Loss: 0.220315083861351
train-epoch-step: 17-261 -- Loss: 0.1877380609512329
train-epoch-step: 17-262 -- Loss: 0.3630754053592682
train-epoch-step: 17-263 -- Loss: 0.21761351823806763
train-epoch-step: 17-264 -- Loss: 0.18030060827732086
train-epoch-step: 17-265 -- Loss: 0.13600291311740875
train-epoch-step: 17-266 -- Loss: 0.16692878305912018
train-epoch-step: 17-267 -- Loss: 0.1460016667842865
train-epoch-step: 17-268 -- Loss: 0.14491692185401917
train-epoch-step: 17-269 -- Loss: 0.18859541416168213
train-epoch-step: 17-270 -- Loss: 0.1156720444560051
train-epoch-step: 17-271 -- Loss: 0.16409684717655182
train-epoch-step: 17-272 -- Loss: 0.13056257367134094
train-epoch-step: 17-273 -- Loss: 0.13962817192077637
train-epoch-step: 17-274 -- Loss: 0.22396165132522583
train-epoch-step: 17-275 -- Loss: 0.22683145105838776
train-epoch-step: 17-276 -- Loss: 0.17812782526016235
train-epoch-step: 17-277 -- Loss: 0.17106465995311737
train-epoch-step: 17-278 -- Loss: 0.1697738766670227
train-epoch-step: 17-279 -- Loss: 0.16343477368354797
train-epoch-step: 17-280 -- Loss: 0.2463034987449646
train-epoch-step: 17-281 -- Loss: 0.21726340055465698
train-epoch-step: 17-282 -- Loss: 0.15434014797210693
train-epoch-step: 17-283 -- Loss: 0.1372452676296234
train-epoch-step: 17-284 -- Loss: 0.17720243334770203
train-epoch-step: 17-285 -- Loss: 0.2063174545764923
train-epoch-step: 17-286 -- Loss: 0.16974668204784393
train-epoch-step: 17-287 -- Loss: 0.225531205534935
train-epoch-step: 17-288 -- Loss: 0.10471334308385849
train-epoch-step: 17-289 -- Loss: 0.15519264340400696
train-epoch-step: 17-290 -- Loss: 0.20617437362670898
train-epoch-step: 17-291 -- Loss: 0.12759089469909668
train-epoch-step: 17-292 -- Loss: 0.16552092134952545
train-epoch-step: 17-293 -- Loss: 0.15789730846881866
train-epoch-step: 17-294 -- Loss: 0.1827998161315918
train-epoch-step: 17-295 -- Loss: 0.30302053689956665
train-epoch-step: 17-296 -- Loss: 0.1915123462677002
train-epoch-step: 17-297 -- Loss: 0.1885579228401184
train-epoch-step: 17-298 -- Loss: 0.26269882917404175
train-epoch-step: 17-299 -- Loss: 0.16668027639389038
train-epoch-step: 17-300 -- Loss: 0.19595812261104584
train-epoch-step: 17-301 -- Loss: 0.18482188880443573
train-epoch-step: 17-302 -- Loss: 0.24380120635032654
train-epoch-step: 17-303 -- Loss: 0.22726798057556152
train-epoch-step: 17-304 -- Loss: 0.15329010784626007
train-epoch-step: 17-305 -- Loss: 0.1533922553062439
train-epoch-step: 17-306 -- Loss: 0.25959786772727966
train-epoch-step: 17-307 -- Loss: 0.1817028522491455
train-epoch-step: 17-308 -- Loss: 0.2394097000360489
train-epoch-step: 17-309 -- Loss: 0.16855710744857788
train-epoch-step: 17-310 -- Loss: 0.18799248337745667
train-epoch-step: 17-311 -- Loss: 0.18341678380966187
train-epoch-step: 17-312 -- Loss: 0.23854433000087738
train-epoch-step: 17-313 -- Loss: 0.1117553561925888
train-epoch-step: 17-314 -- Loss: 0.21881195902824402
train-epoch-step: 17-315 -- Loss: 0.18107612431049347
train-epoch-step: 17-316 -- Loss: 0.1674436777830124
train-epoch-step: 17-317 -- Loss: 0.15219011902809143
train-epoch-step: 17-318 -- Loss: 0.18049785494804382
train-epoch-step: 17-319 -- Loss: 0.1952105164527893
train-epoch-step: 17-320 -- Loss: 0.12650775909423828
train-epoch-step: 17-321 -- Loss: 0.1480591595172882
train-epoch-step: 17-322 -- Loss: 0.22866317629814148
train-epoch-step: 17-323 -- Loss: 0.17010906338691711
train-epoch-step: 17-324 -- Loss: 0.2759583592414856
train-epoch-step: 17-325 -- Loss: 0.16507568955421448
train-epoch-step: 17-326 -- Loss: 0.1799820065498352
train-epoch-step: 17-327 -- Loss: 0.22435760498046875
train-epoch-step: 17-328 -- Loss: 0.21257713437080383
train-epoch-step: 17-329 -- Loss: 0.35270845890045166
train-epoch-step: 17-330 -- Loss: 0.38173553347587585
train-epoch-step: 17-331 -- Loss: 0.22410818934440613
train-epoch-step: 17-332 -- Loss: 0.11673812568187714
train-epoch-step: 17-333 -- Loss: 0.20234711468219757
train-epoch-step: 17-334 -- Loss: 0.1661071479320526
train-epoch-step: 17-335 -- Loss: 0.19007784128189087
train-epoch-step: 17-336 -- Loss: 0.1734737753868103
train-epoch-step: 17-337 -- Loss: 0.23594319820404053
train-epoch-step: 17-338 -- Loss: 0.17100758850574493
train-epoch-step: 17-339 -- Loss: 0.1547652930021286
train-epoch-step: 17-340 -- Loss: 0.21759745478630066
train-epoch-step: 17-341 -- Loss: 0.1473401039838791
train-epoch-step: 17-342 -- Loss: 0.18013040721416473
train-epoch-step: 17-343 -- Loss: 0.16872894763946533
train-epoch-step: 17-344 -- Loss: 0.18445461988449097
train-epoch-step: 17-345 -- Loss: 0.13848088681697845
train-epoch-step: 17-346 -- Loss: 0.2196500599384308
train-epoch-step: 17-347 -- Loss: 0.16383539140224457
train-epoch-step: 17-348 -- Loss: 0.22056084871292114
train-epoch-step: 17-349 -- Loss: 0.22013920545578003
train-epoch-step: 17-350 -- Loss: 0.2830432951450348
train-epoch-step: 17-351 -- Loss: 0.21322007477283478
train-epoch-step: 17-352 -- Loss: 0.13923028111457825
train-epoch-step: 17-353 -- Loss: 0.21260827779769897
train-epoch-step: 17-354 -- Loss: 0.30335086584091187
train-epoch-step: 17-355 -- Loss: 0.1335793286561966
train-epoch-step: 17-356 -- Loss: 0.1287846714258194
train-epoch-step: 17-357 -- Loss: 0.20516762137413025
train-epoch-step: 17-358 -- Loss: 0.1979096233844757
train-epoch-step: 17-359 -- Loss: 0.15079516172409058
train-epoch-step: 17-360 -- Loss: 0.12959174811840057
train-epoch-step: 17-361 -- Loss: 0.2558614909648895
train-epoch-step: 17-362 -- Loss: 0.18178609013557434
train-epoch-step: 17-363 -- Loss: 0.1268429309129715
train-epoch-step: 17-364 -- Loss: 0.1991858035326004
train-epoch-step: 17-365 -- Loss: 0.18812143802642822
train-epoch-step: 17-366 -- Loss: 0.21513503789901733
train-epoch-step: 17-367 -- Loss: 0.2548893392086029
train-epoch-step: 17-368 -- Loss: 0.2136498987674713
train-epoch-step: 17-369 -- Loss: 0.29378026723861694
train-epoch-step: 17-370 -- Loss: 0.138878732919693
train-epoch-step: 17-371 -- Loss: 0.12758949398994446
train-epoch-step: 17-372 -- Loss: 0.1548157036304474
train-epoch-step: 17-373 -- Loss: 0.2111118733882904
train-epoch-step: 17-374 -- Loss: 0.16809721291065216
train-epoch-step: 17-375 -- Loss: 0.2851298451423645
train-epoch-step: 17-376 -- Loss: 0.18580588698387146
train-epoch-step: 17-377 -- Loss: 0.24298012256622314
train-epoch-step: 17-378 -- Loss: 0.21996374428272247
train-epoch-step: 17-379 -- Loss: 0.12792444229125977
train-epoch-step: 17-380 -- Loss: 0.09693585336208344
train-epoch-step: 17-381 -- Loss: 0.2633057236671448
train-epoch-step: 17-382 -- Loss: 0.26700544357299805
train-epoch-step: 17-383 -- Loss: 0.18358495831489563
train-epoch-step: 17-384 -- Loss: 0.2443719208240509
train-epoch-step: 17-385 -- Loss: 0.21033909916877747
train-epoch-step: 17-386 -- Loss: 0.20284490287303925
train-epoch-step: 17-387 -- Loss: 0.22371968626976013
train-epoch-step: 17-388 -- Loss: 0.2380848228931427
train-epoch-step: 17-389 -- Loss: 0.18482404947280884
train-epoch-step: 17-390 -- Loss: 0.1620500087738037
train-epoch-step: 17-391 -- Loss: 0.15304093062877655
train-epoch-step: 17-392 -- Loss: 0.19397187232971191
train-epoch-step: 17-393 -- Loss: 0.17190487682819366
train-epoch-step: 17-394 -- Loss: 0.23537175357341766
train-epoch-step: 17-395 -- Loss: 0.17785096168518066
train-epoch-step: 17-396 -- Loss: 0.1377393901348114
train-epoch-step: 17-397 -- Loss: 0.13687250018119812
train-epoch-step: 17-398 -- Loss: 0.22057661414146423
train-epoch-step: 17-399 -- Loss: 0.19093464314937592
train-epoch-step: 17-400 -- Loss: 0.3016645908355713
train-epoch-step: 17-401 -- Loss: 0.13027457892894745
train-epoch-step: 17-402 -- Loss: 0.27773645520210266
train-epoch-step: 17-403 -- Loss: 0.17970359325408936
train-epoch-step: 17-404 -- Loss: 0.14881880581378937
train-epoch-step: 17-405 -- Loss: 0.1532583236694336
train-epoch-step: 17-406 -- Loss: 0.187678724527359
train-epoch-step: 17-407 -- Loss: 0.12642961740493774
train-epoch-step: 17-408 -- Loss: 0.18039542436599731
train-epoch-step: 17-409 -- Loss: 0.1820164918899536
train-epoch-step: 17-410 -- Loss: 0.18620958924293518
train-epoch-step: 17-411 -- Loss: 0.21248485147953033
train-epoch-step: 17-412 -- Loss: 0.14077267050743103
train-epoch-step: 17-413 -- Loss: 0.1575314998626709
train-epoch-step: 17-414 -- Loss: 0.1539231240749359
train-epoch-step: 17-415 -- Loss: 0.15228083729743958
train-epoch-step: 17-416 -- Loss: 0.2802475094795227
train-epoch-step: 17-417 -- Loss: 0.20507502555847168
train-epoch-step: 17-418 -- Loss: 0.2660217583179474
train-epoch-step: 17-419 -- Loss: 0.17807400226593018
train-epoch-step: 17-420 -- Loss: 0.16511034965515137
train-epoch-step: 17-421 -- Loss: 0.1954963505268097
train-epoch-step: 17-422 -- Loss: 0.1696133017539978
train-epoch-step: 17-423 -- Loss: 0.19000723958015442
train-epoch-step: 17-424 -- Loss: 0.14645011723041534
train-epoch-step: 17-425 -- Loss: 0.19407342374324799
train-epoch-step: 17-426 -- Loss: 0.17452523112297058
train-epoch-step: 17-427 -- Loss: 0.13805702328681946
train-epoch-step: 17-428 -- Loss: 0.20968815684318542
train-epoch-step: 17-429 -- Loss: 0.1853797286748886
train-epoch-step: 17-430 -- Loss: 0.16296273469924927
train-epoch-step: 17-431 -- Loss: 0.18009833991527557
train-epoch-step: 17-432 -- Loss: 0.26212409138679504
train-epoch-step: 17-433 -- Loss: 0.15039756894111633
train-epoch-step: 17-434 -- Loss: 0.14107219874858856
train-epoch-step: 17-435 -- Loss: 0.1730557084083557
train-epoch-step: 17-436 -- Loss: 0.17209593951702118
train-epoch-step: 17-437 -- Loss: 0.14678992331027985
train-epoch-step: 17-438 -- Loss: 0.18643060326576233
train-epoch-step: 17-439 -- Loss: 0.2852376401424408
train-epoch-step: 17-440 -- Loss: 0.13975518941879272
train-epoch-step: 17-441 -- Loss: 0.2331269383430481
train-epoch-step: 17-442 -- Loss: 0.19800251722335815
train-epoch-step: 17-443 -- Loss: 0.1775181144475937
train-epoch-step: 17-444 -- Loss: 0.1850966066122055
train-epoch-step: 17-445 -- Loss: 0.20063155889511108
train-epoch-step: 17-446 -- Loss: 0.17004846036434174
train-epoch-step: 17-447 -- Loss: 0.21024957299232483
train-epoch-step: 17-448 -- Loss: 0.25061070919036865
train-epoch-step: 17-449 -- Loss: 0.20789478719234467
train-epoch-step: 17-450 -- Loss: 0.2033586949110031
train-epoch-step: 17-451 -- Loss: 0.15369366109371185
train-epoch-step: 17-452 -- Loss: 0.14379346370697021
train-epoch-step: 17-453 -- Loss: 0.10239472985267639
train-epoch-step: 17-454 -- Loss: 0.24714939296245575
train-epoch-step: 17-455 -- Loss: 0.14243438839912415
train-epoch-step: 17-456 -- Loss: 0.12900441884994507
train-epoch-step: 17-457 -- Loss: 0.23550137877464294
train-epoch-step: 17-458 -- Loss: 0.16634419560432434
train-epoch-step: 17-459 -- Loss: 0.23884005844593048
train-epoch-step: 17-460 -- Loss: 0.1380629688501358
train-epoch-step: 17-461 -- Loss: 0.14560525119304657
train-epoch-step: 17-462 -- Loss: 0.1749001145362854
train-epoch-step: 17-463 -- Loss: 0.1462976634502411
train-epoch-step: 17-464 -- Loss: 0.18072307109832764
train-epoch-step: 17-465 -- Loss: 0.27411818504333496
train-epoch-step: 17-466 -- Loss: 0.21653994917869568
train-epoch-step: 17-467 -- Loss: 0.12650896608829498
train-epoch-step: 17-468 -- Loss: 0.18368861079216003
train-epoch-step: 17-469 -- Loss: 0.23756109178066254
train-epoch-step: 17-470 -- Loss: 0.19600246846675873
train-epoch-step: 17-471 -- Loss: 0.16810423135757446
train-epoch-step: 17-472 -- Loss: 0.1649254709482193
train-epoch-step: 17-473 -- Loss: 0.1732860803604126
train-epoch-step: 17-474 -- Loss: 0.1283775418996811
train-epoch-step: 17-475 -- Loss: 0.1266581267118454
train-epoch-step: 17-476 -- Loss: 0.21253536641597748
train-epoch-step: 17-477 -- Loss: 0.2269648164510727
train-epoch-step: 17-478 -- Loss: 0.2028859257698059
train-epoch-step: 17-479 -- Loss: 0.14972493052482605
train-epoch-step: 17-480 -- Loss: 0.20666095614433289
train-epoch-step: 17-481 -- Loss: 0.29386234283447266
train-epoch-step: 17-482 -- Loss: 0.27420324087142944
train-epoch-step: 17-483 -- Loss: 0.19492121040821075
train-epoch-step: 17-484 -- Loss: 0.2214401513338089
train-epoch-step: 17-485 -- Loss: 0.14278796315193176
train-epoch-step: 17-486 -- Loss: 0.26083341240882874
train-epoch-step: 17-487 -- Loss: 0.2378024309873581
train-epoch-step: 17-488 -- Loss: 0.20548351109027863
train-epoch-step: 17-489 -- Loss: 0.2313336879014969
train-epoch-step: 17-490 -- Loss: 0.15238869190216064
train-epoch-step: 17-491 -- Loss: 0.1495196670293808
train-epoch-step: 17-492 -- Loss: 0.13590025901794434
train-epoch-step: 17-493 -- Loss: 0.23924630880355835
train-epoch-step: 17-494 -- Loss: 0.23085397481918335
train-epoch-step: 17-495 -- Loss: 0.21925249695777893
train-epoch-step: 17-496 -- Loss: 0.15094754099845886
train-epoch-step: 17-497 -- Loss: 0.1923668384552002
train-epoch-step: 17-498 -- Loss: 0.16066935658454895
train-epoch-step: 17-499 -- Loss: 0.18631106615066528
train-epoch-step: 17-500 -- Loss: 0.16701000928878784
train-epoch-step: 17-501 -- Loss: 0.2295718491077423
train-epoch-step: 17-502 -- Loss: 0.1809500753879547
train-epoch-step: 17-503 -- Loss: 0.2366076409816742
train-epoch-step: 17-504 -- Loss: 0.14149975776672363
train-epoch-step: 17-505 -- Loss: 0.1857408732175827
train-epoch-step: 17-506 -- Loss: 0.12601684033870697
train-epoch-step: 17-507 -- Loss: 0.19484151899814606
train-epoch-step: 17-508 -- Loss: 0.18864965438842773
train-epoch-step: 17-509 -- Loss: 0.18377062678337097
train-epoch-step: 17-510 -- Loss: 0.13437826931476593
train-epoch-step: 17-511 -- Loss: 0.23269665241241455
train-epoch-step: 17-512 -- Loss: 0.18911950290203094
train-epoch-step: 17-513 -- Loss: 0.2174510508775711
train-epoch-step: 17-514 -- Loss: 0.15586227178573608
train-epoch-step: 17-515 -- Loss: 0.17518924176692963
train-epoch-step: 17-516 -- Loss: 0.18450713157653809
train-epoch-step: 17-517 -- Loss: 0.19253098964691162
train-epoch-step: 17-518 -- Loss: 0.14871501922607422
train-epoch-step: 17-519 -- Loss: 0.14388182759284973
train-epoch-step: 17-520 -- Loss: 0.19950854778289795
train-epoch-step: 17-521 -- Loss: 0.2410220503807068
train-epoch-step: 17-522 -- Loss: 0.18576942384243011
train-epoch-step: 17-523 -- Loss: 0.1661003828048706
train-epoch-step: 17-524 -- Loss: 0.18006663024425507
train-epoch-step: 17-525 -- Loss: 0.20257239043712616
train-epoch-step: 17-526 -- Loss: 0.1375204622745514
train-epoch-step: 17-527 -- Loss: 0.16621603071689606
train-epoch-step: 17-528 -- Loss: 0.17053332924842834
train-epoch-step: 17-529 -- Loss: 0.1686156988143921
train-epoch-step: 17-530 -- Loss: 0.1769481897354126
train-epoch-step: 17-531 -- Loss: 0.21455800533294678
train-epoch-step: 17-532 -- Loss: 0.18370109796524048
train-epoch-step: 17-533 -- Loss: 0.1798647940158844
train-epoch-step: 17-534 -- Loss: 0.14794516563415527
train-epoch-step: 17-535 -- Loss: 0.2857009470462799
train-epoch-step: 17-536 -- Loss: 0.17230549454689026
train-epoch-step: 17-537 -- Loss: 0.1633613258600235
train-epoch-step: 17-538 -- Loss: 0.1140671819448471
train-epoch-step: 17-539 -- Loss: 0.21313555538654327
train-epoch-step: 17-540 -- Loss: 0.1470620036125183
train-epoch-step: 17-541 -- Loss: 0.22041165828704834
train-epoch-step: 17-542 -- Loss: 0.24653755128383636
train-epoch-step: 17-543 -- Loss: 0.18025344610214233
train-epoch-step: 17-544 -- Loss: 0.2463163137435913
train-epoch-step: 17-545 -- Loss: 0.22054427862167358
train-epoch-step: 17-546 -- Loss: 0.227034330368042
train-epoch-step: 17-547 -- Loss: 0.19094669818878174
train-epoch-step: 17-548 -- Loss: 0.1016840711236
train-epoch-step: 17-549 -- Loss: 0.15647727251052856
train-epoch-step: 17-550 -- Loss: 0.210459366440773
train-epoch-step: 17-551 -- Loss: 0.17280620336532593
train-epoch-step: 17-552 -- Loss: 0.1429082155227661
train-epoch-step: 17-553 -- Loss: 0.19825135171413422
train-epoch-step: 17-554 -- Loss: 0.19687515497207642
train-epoch-step: 17-555 -- Loss: 0.23457549512386322
train-epoch-step: 17-556 -- Loss: 0.16334080696105957
train-epoch-step: 17-557 -- Loss: 0.2566017508506775
train-epoch-step: 17-558 -- Loss: 0.2440221607685089
train-epoch-step: 17-559 -- Loss: 0.15968509018421173
train-epoch-step: 17-560 -- Loss: 0.21246960759162903
train-epoch-step: 17-561 -- Loss: 0.2036120444536209
train-epoch-step: 17-562 -- Loss: 0.17913010716438293
train-epoch-step: 17-563 -- Loss: 0.19867946207523346
train-epoch-step: 17-564 -- Loss: 0.11045923829078674
train-epoch-step: 17-565 -- Loss: 0.20527315139770508
train-epoch-step: 17-566 -- Loss: 0.16984054446220398
train-epoch-step: 17-567 -- Loss: 0.22613254189491272
train-epoch-step: 17-568 -- Loss: 0.171402245759964
train-epoch-step: 17-569 -- Loss: 0.2602958083152771
train-epoch-step: 17-570 -- Loss: 0.18372146785259247
train-epoch-step: 17-571 -- Loss: 0.22316153347492218
train-epoch-step: 17-572 -- Loss: 0.27224794030189514
train-epoch-step: 17-573 -- Loss: 0.21798720955848694
train-epoch-step: 17-574 -- Loss: 0.27025240659713745
train-epoch-step: 17-575 -- Loss: 0.3236241042613983
train-epoch-step: 17-576 -- Loss: 0.1345357745885849
train-epoch-step: 17-577 -- Loss: 0.18083415925502777
train-epoch-step: 17-578 -- Loss: 0.2341446727514267
train-epoch-step: 17-579 -- Loss: 0.18970003724098206
train-epoch-step: 17-580 -- Loss: 0.20426957309246063
train-epoch-step: 17-581 -- Loss: 0.16025874018669128
train-epoch-step: 17-582 -- Loss: 0.2219538390636444
train-epoch-step: 17-583 -- Loss: 0.24559149146080017
train-epoch-step: 17-584 -- Loss: 0.19564397633075714
train-epoch-step: 17-585 -- Loss: 0.20724409818649292
train-epoch-step: 17-586 -- Loss: 0.2667026221752167
train-epoch-step: 17-587 -- Loss: 0.17001661658287048
train-epoch-step: 17-588 -- Loss: 0.13452310860157013
val-epoch-step: 17-589 -- Loss: 0.2134585678577423
val-epoch-step: 17-590 -- Loss: 0.15857449173927307
val-epoch-step: 17-591 -- Loss: 0.2321053445339203
val-epoch-step: 17-592 -- Loss: 0.19196635484695435
val-epoch-step: 17-593 -- Loss: 0.16064152121543884
val-epoch-step: 17-594 -- Loss: 0.39362919330596924
val-epoch-step: 17-595 -- Loss: 0.20097699761390686
val-epoch-step: 17-596 -- Loss: 0.2327926605939865
val-epoch-step: 17-597 -- Loss: 0.18405750393867493
val-epoch-step: 17-598 -- Loss: 0.15693813562393188
val-epoch-step: 17-599 -- Loss: 0.1969541311264038
val-epoch-step: 17-600 -- Loss: 0.19555777311325073
val-epoch-step: 17-601 -- Loss: 0.17015138268470764
val-epoch-step: 17-602 -- Loss: 0.14916715025901794
val-epoch-step: 17-603 -- Loss: 0.18620900809764862
val-epoch-step: 17-604 -- Loss: 0.16237899661064148
val-epoch-step: 17-605 -- Loss: 0.15988817811012268
val-epoch-step: 17-606 -- Loss: 0.2801077663898468
val-epoch-step: 17-607 -- Loss: 0.13488493859767914
val-epoch-step: 17-608 -- Loss: 0.2643023133277893
val-epoch-step: 17-609 -- Loss: 0.1813604235649109
val-epoch-step: 17-610 -- Loss: 0.20003348588943481
val-epoch-step: 17-611 -- Loss: 0.1651538610458374
val-epoch-step: 17-612 -- Loss: 0.4841483235359192
val-epoch-step: 17-613 -- Loss: 0.18427494168281555
val-epoch-step: 17-614 -- Loss: 0.16984635591506958
val-epoch-step: 17-615 -- Loss: 0.18347766995429993
val-epoch-step: 17-616 -- Loss: 0.16151930391788483
val-epoch-step: 17-617 -- Loss: 0.2067013680934906
val-epoch-step: 17-618 -- Loss: 0.21354585886001587
val-epoch-step: 17-619 -- Loss: 0.2200748175382614
val-epoch-step: 17-620 -- Loss: 0.14718946814537048
val-epoch-step: 17-621 -- Loss: 0.1400744765996933
val-epoch-step: 17-622 -- Loss: 0.15251468122005463
val-epoch-step: 17-623 -- Loss: 0.16692419350147247
val-epoch-step: 17-624 -- Loss: 0.16265955567359924
val-epoch-step: 17-625 -- Loss: 0.1709061861038208
val-epoch-step: 17-626 -- Loss: 0.1525430828332901
val-epoch-step: 17-627 -- Loss: 0.20808330178260803
val-epoch-step: 17-628 -- Loss: 0.6294943690299988
val-epoch-step: 17-629 -- Loss: 0.2347468137741089
val-epoch-step: 17-630 -- Loss: 0.3601987957954407
val-epoch-step: 17-631 -- Loss: 0.144541397690773
val-epoch-step: 17-632 -- Loss: 0.20753273367881775
val-epoch-step: 17-633 -- Loss: 0.16330477595329285
val-epoch-step: 17-634 -- Loss: 0.14817233383655548
val-epoch-step: 17-635 -- Loss: 0.12405750155448914
val-epoch-step: 17-636 -- Loss: 0.18324685096740723
val-epoch-step: 17-637 -- Loss: 0.19750741124153137
val-epoch-step: 17-638 -- Loss: 0.16642431914806366
val-epoch-step: 17-639 -- Loss: 0.26853233575820923
val-epoch-step: 17-640 -- Loss: 0.26738685369491577
val-epoch-step: 17-641 -- Loss: 0.13461071252822876
val-epoch-step: 17-642 -- Loss: 0.19483298063278198
val-epoch-step: 17-643 -- Loss: 0.2162204086780548
val-epoch-step: 17-644 -- Loss: 0.17739075422286987
val-epoch-step: 17-645 -- Loss: 0.23205915093421936
val-epoch-step: 17-646 -- Loss: 0.14139215648174286
val-epoch-step: 17-647 -- Loss: 0.1423925757408142
val-epoch-step: 17-648 -- Loss: 0.1684875786304474
val-epoch-step: 17-649 -- Loss: 0.2281302809715271
val-epoch-step: 17-650 -- Loss: 0.2746572196483612
val-epoch-step: 17-651 -- Loss: 0.15745827555656433
val-epoch-step: 17-652 -- Loss: 0.16556501388549805
val-epoch-step: 17-653 -- Loss: 0.216141939163208
val-epoch-step: 17-654 -- Loss: 0.12657974660396576
Epoch: 17 -- Train Loss: tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 18-0 -- Loss: 0.2442333996295929
train-epoch-step: 18-1 -- Loss: 0.1530236303806305
train-epoch-step: 18-2 -- Loss: 0.2116999328136444
train-epoch-step: 18-3 -- Loss: 0.15558063983917236
train-epoch-step: 18-4 -- Loss: 0.17838725447654724
train-epoch-step: 18-5 -- Loss: 0.19736135005950928
train-epoch-step: 18-6 -- Loss: 0.24244476854801178
train-epoch-step: 18-7 -- Loss: 0.17643047869205475
train-epoch-step: 18-8 -- Loss: 0.20904213190078735
train-epoch-step: 18-9 -- Loss: 0.25535595417022705
train-epoch-step: 18-10 -- Loss: 0.2347143590450287
train-epoch-step: 18-11 -- Loss: 0.19325685501098633
train-epoch-step: 18-12 -- Loss: 0.17299678921699524
train-epoch-step: 18-13 -- Loss: 0.19599002599716187
train-epoch-step: 18-14 -- Loss: 0.17468999326229095
train-epoch-step: 18-15 -- Loss: 0.17363858222961426
train-epoch-step: 18-16 -- Loss: 0.1697845458984375
train-epoch-step: 18-17 -- Loss: 0.24010787904262543
train-epoch-step: 18-18 -- Loss: 0.21800586581230164
train-epoch-step: 18-19 -- Loss: 0.14055532217025757
train-epoch-step: 18-20 -- Loss: 0.2461632341146469
train-epoch-step: 18-21 -- Loss: 0.2858179807662964
train-epoch-step: 18-22 -- Loss: 0.15763136744499207
train-epoch-step: 18-23 -- Loss: 0.16023924946784973
train-epoch-step: 18-24 -- Loss: 0.14043162763118744
train-epoch-step: 18-25 -- Loss: 0.2356909215450287
train-epoch-step: 18-26 -- Loss: 0.20821774005889893
train-epoch-step: 18-27 -- Loss: 0.2529187798500061
train-epoch-step: 18-28 -- Loss: 0.13090413808822632
train-epoch-step: 18-29 -- Loss: 0.25859224796295166
train-epoch-step: 18-30 -- Loss: 0.11748398840427399
train-epoch-step: 18-31 -- Loss: 0.15513408184051514
train-epoch-step: 18-32 -- Loss: 0.18390846252441406
train-epoch-step: 18-33 -- Loss: 0.3037857413291931
train-epoch-step: 18-34 -- Loss: 0.18097804486751556
train-epoch-step: 18-35 -- Loss: 0.26257872581481934
train-epoch-step: 18-36 -- Loss: 0.1471433788537979
train-epoch-step: 18-37 -- Loss: 0.14763514697551727
train-epoch-step: 18-38 -- Loss: 0.20655924081802368
train-epoch-step: 18-39 -- Loss: 0.24049046635627747
train-epoch-step: 18-40 -- Loss: 0.2162717580795288
train-epoch-step: 18-41 -- Loss: 0.24933598935604095
train-epoch-step: 18-42 -- Loss: 0.159749835729599
train-epoch-step: 18-43 -- Loss: 0.2961669862270355
train-epoch-step: 18-44 -- Loss: 0.1394464671611786
train-epoch-step: 18-45 -- Loss: 0.13300880789756775
train-epoch-step: 18-46 -- Loss: 0.18294134736061096
train-epoch-step: 18-47 -- Loss: 0.22758536040782928
train-epoch-step: 18-48 -- Loss: 0.16216786205768585
train-epoch-step: 18-49 -- Loss: 0.23342730104923248
train-epoch-step: 18-50 -- Loss: 0.12301327288150787
train-epoch-step: 18-51 -- Loss: 0.21203559637069702
train-epoch-step: 18-52 -- Loss: 0.17106065154075623
train-epoch-step: 18-53 -- Loss: 0.24030013382434845
train-epoch-step: 18-54 -- Loss: 0.2969092130661011
train-epoch-step: 18-55 -- Loss: 0.17635788023471832
train-epoch-step: 18-56 -- Loss: 0.19399768114089966
train-epoch-step: 18-57 -- Loss: 0.2445584535598755
train-epoch-step: 18-58 -- Loss: 0.2947005331516266
train-epoch-step: 18-59 -- Loss: 0.25656139850616455
train-epoch-step: 18-60 -- Loss: 0.14290449023246765
train-epoch-step: 18-61 -- Loss: 0.2151167094707489
train-epoch-step: 18-62 -- Loss: 0.19781255722045898
train-epoch-step: 18-63 -- Loss: 0.15097838640213013
train-epoch-step: 18-64 -- Loss: 0.16431739926338196
train-epoch-step: 18-65 -- Loss: 0.1994568258523941
train-epoch-step: 18-66 -- Loss: 0.11650216579437256
train-epoch-step: 18-67 -- Loss: 0.1367880403995514
train-epoch-step: 18-68 -- Loss: 0.23466837406158447
train-epoch-step: 18-69 -- Loss: 0.13379108905792236
train-epoch-step: 18-70 -- Loss: 0.238729327917099
train-epoch-step: 18-71 -- Loss: 0.28818920254707336
train-epoch-step: 18-72 -- Loss: 0.19126522541046143
train-epoch-step: 18-73 -- Loss: 0.22680899500846863
train-epoch-step: 18-74 -- Loss: 0.10777193307876587
train-epoch-step: 18-75 -- Loss: 0.13725027441978455
train-epoch-step: 18-76 -- Loss: 0.1587185114622116
train-epoch-step: 18-77 -- Loss: 0.24919551610946655
train-epoch-step: 18-78 -- Loss: 0.2786937952041626
train-epoch-step: 18-79 -- Loss: 0.2096739262342453
train-epoch-step: 18-80 -- Loss: 0.2977046072483063
train-epoch-step: 18-81 -- Loss: 0.13518355786800385
train-epoch-step: 18-82 -- Loss: 0.26896920800209045
train-epoch-step: 18-83 -- Loss: 0.20635013282299042
train-epoch-step: 18-84 -- Loss: 0.2003743052482605
train-epoch-step: 18-85 -- Loss: 0.1922754943370819
train-epoch-step: 18-86 -- Loss: 0.133901447057724
train-epoch-step: 18-87 -- Loss: 0.25157761573791504
train-epoch-step: 18-88 -- Loss: 0.15410573780536652
train-epoch-step: 18-89 -- Loss: 0.20338712632656097
train-epoch-step: 18-90 -- Loss: 0.2078118473291397
train-epoch-step: 18-91 -- Loss: 0.26746201515197754
train-epoch-step: 18-92 -- Loss: 0.17030145227909088
train-epoch-step: 18-93 -- Loss: 0.18993383646011353
train-epoch-step: 18-94 -- Loss: 0.23333683609962463
train-epoch-step: 18-95 -- Loss: 0.21622401475906372
train-epoch-step: 18-96 -- Loss: 0.23585674166679382
train-epoch-step: 18-97 -- Loss: 0.18880893290042877
train-epoch-step: 18-98 -- Loss: 0.16201883554458618
train-epoch-step: 18-99 -- Loss: 0.20146355032920837
train-epoch-step: 18-100 -- Loss: 0.19204925000667572
train-epoch-step: 18-101 -- Loss: 0.3039993345737457
train-epoch-step: 18-102 -- Loss: 0.250226229429245
train-epoch-step: 18-103 -- Loss: 0.20038294792175293
train-epoch-step: 18-104 -- Loss: 0.16083982586860657
train-epoch-step: 18-105 -- Loss: 0.2936643660068512
train-epoch-step: 18-106 -- Loss: 0.18246930837631226
train-epoch-step: 18-107 -- Loss: 0.19722329080104828
train-epoch-step: 18-108 -- Loss: 0.20029966533184052
train-epoch-step: 18-109 -- Loss: 0.1573030948638916
train-epoch-step: 18-110 -- Loss: 0.19782882928848267
train-epoch-step: 18-111 -- Loss: 0.19022122025489807
train-epoch-step: 18-112 -- Loss: 0.17927539348602295
train-epoch-step: 18-113 -- Loss: 0.1733584702014923
train-epoch-step: 18-114 -- Loss: 0.20931881666183472
train-epoch-step: 18-115 -- Loss: 0.17464083433151245
train-epoch-step: 18-116 -- Loss: 0.1516130268573761
train-epoch-step: 18-117 -- Loss: 0.1399589627981186
train-epoch-step: 18-118 -- Loss: 0.2091035693883896
train-epoch-step: 18-119 -- Loss: 0.1698208451271057
train-epoch-step: 18-120 -- Loss: 0.26989275217056274
train-epoch-step: 18-121 -- Loss: 0.2814784348011017
train-epoch-step: 18-122 -- Loss: 0.2300494909286499
train-epoch-step: 18-123 -- Loss: 0.21608759462833405
train-epoch-step: 18-124 -- Loss: 0.12885956466197968
train-epoch-step: 18-125 -- Loss: 0.16126258671283722
train-epoch-step: 18-126 -- Loss: 0.23882991075515747
train-epoch-step: 18-127 -- Loss: 0.1869780719280243
train-epoch-step: 18-128 -- Loss: 0.17831704020500183
train-epoch-step: 18-129 -- Loss: 0.16455966234207153
train-epoch-step: 18-130 -- Loss: 0.20900648832321167
train-epoch-step: 18-131 -- Loss: 0.14819753170013428
train-epoch-step: 18-132 -- Loss: 0.20383386313915253
train-epoch-step: 18-133 -- Loss: 0.126914843916893
train-epoch-step: 18-134 -- Loss: 0.21878229081630707
train-epoch-step: 18-135 -- Loss: 0.16075876355171204
train-epoch-step: 18-136 -- Loss: 0.13745005428791046
train-epoch-step: 18-137 -- Loss: 0.2751205861568451
train-epoch-step: 18-138 -- Loss: 0.28699469566345215
train-epoch-step: 18-139 -- Loss: 0.14419396221637726
train-epoch-step: 18-140 -- Loss: 0.22595809400081635
train-epoch-step: 18-141 -- Loss: 0.24663856625556946
train-epoch-step: 18-142 -- Loss: 0.2151416838169098
train-epoch-step: 18-143 -- Loss: 0.18619248270988464
train-epoch-step: 18-144 -- Loss: 0.20268318057060242
train-epoch-step: 18-145 -- Loss: 0.1527281105518341
train-epoch-step: 18-146 -- Loss: 0.18964877724647522
train-epoch-step: 18-147 -- Loss: 0.18673394620418549
train-epoch-step: 18-148 -- Loss: 0.17653250694274902
train-epoch-step: 18-149 -- Loss: 0.13183119893074036
train-epoch-step: 18-150 -- Loss: 0.19994980096817017
train-epoch-step: 18-151 -- Loss: 0.19875319302082062
train-epoch-step: 18-152 -- Loss: 0.20244130492210388
train-epoch-step: 18-153 -- Loss: 0.28428229689598083
train-epoch-step: 18-154 -- Loss: 0.14322024583816528
train-epoch-step: 18-155 -- Loss: 0.14812380075454712
train-epoch-step: 18-156 -- Loss: 0.13781684637069702
train-epoch-step: 18-157 -- Loss: 0.1758514642715454
train-epoch-step: 18-158 -- Loss: 0.17683382332324982
train-epoch-step: 18-159 -- Loss: 0.18571698665618896
train-epoch-step: 18-160 -- Loss: 0.2444668859243393
train-epoch-step: 18-161 -- Loss: 0.2169618457555771
train-epoch-step: 18-162 -- Loss: 0.22652500867843628
train-epoch-step: 18-163 -- Loss: 0.1981423944234848
train-epoch-step: 18-164 -- Loss: 0.20750008523464203
train-epoch-step: 18-165 -- Loss: 0.17850151658058167
train-epoch-step: 18-166 -- Loss: 0.13027328252792358
train-epoch-step: 18-167 -- Loss: 0.13602769374847412
train-epoch-step: 18-168 -- Loss: 0.21450760960578918
train-epoch-step: 18-169 -- Loss: 0.15334360301494598
train-epoch-step: 18-170 -- Loss: 0.20891782641410828
train-epoch-step: 18-171 -- Loss: 0.1533569097518921
train-epoch-step: 18-172 -- Loss: 0.2760465145111084
train-epoch-step: 18-173 -- Loss: 0.14047926664352417
train-epoch-step: 18-174 -- Loss: 0.2719098925590515
train-epoch-step: 18-175 -- Loss: 0.19340276718139648
train-epoch-step: 18-176 -- Loss: 0.14565737545490265
train-epoch-step: 18-177 -- Loss: 0.20322810113430023
train-epoch-step: 18-178 -- Loss: 0.19451549649238586
train-epoch-step: 18-179 -- Loss: 0.16360533237457275
train-epoch-step: 18-180 -- Loss: 0.16592422127723694
train-epoch-step: 18-181 -- Loss: 0.18211328983306885
train-epoch-step: 18-182 -- Loss: 0.21035952866077423
train-epoch-step: 18-183 -- Loss: 0.2886781692504883
train-epoch-step: 18-184 -- Loss: 0.15093636512756348
train-epoch-step: 18-185 -- Loss: 0.15440542995929718
train-epoch-step: 18-186 -- Loss: 0.19815340638160706
train-epoch-step: 18-187 -- Loss: 0.22845391929149628
train-epoch-step: 18-188 -- Loss: 0.19247949123382568
train-epoch-step: 18-189 -- Loss: 0.11392820626497269
train-epoch-step: 18-190 -- Loss: 0.18858572840690613
train-epoch-step: 18-191 -- Loss: 0.18505613505840302
train-epoch-step: 18-192 -- Loss: 0.25943127274513245
train-epoch-step: 18-193 -- Loss: 0.22981521487236023
train-epoch-step: 18-194 -- Loss: 0.19361796975135803
train-epoch-step: 18-195 -- Loss: 0.17578734457492828
train-epoch-step: 18-196 -- Loss: 0.18561479449272156
train-epoch-step: 18-197 -- Loss: 0.1527038812637329
train-epoch-step: 18-198 -- Loss: 0.14490380883216858
train-epoch-step: 18-199 -- Loss: 0.1673368364572525
train-epoch-step: 18-200 -- Loss: 0.13472576439380646
train-epoch-step: 18-201 -- Loss: 0.2109292894601822
train-epoch-step: 18-202 -- Loss: 0.14170730113983154
train-epoch-step: 18-203 -- Loss: 0.19246207177639008
train-epoch-step: 18-204 -- Loss: 0.14865025877952576
train-epoch-step: 18-205 -- Loss: 0.19704563915729523
train-epoch-step: 18-206 -- Loss: 0.21996717154979706
train-epoch-step: 18-207 -- Loss: 0.14625084400177002
train-epoch-step: 18-208 -- Loss: 0.18861821293830872
train-epoch-step: 18-209 -- Loss: 0.14883524179458618
train-epoch-step: 18-210 -- Loss: 0.14760591089725494
train-epoch-step: 18-211 -- Loss: 0.2208380103111267
train-epoch-step: 18-212 -- Loss: 0.20695926249027252
train-epoch-step: 18-213 -- Loss: 0.14616435766220093
train-epoch-step: 18-214 -- Loss: 0.15925028920173645
train-epoch-step: 18-215 -- Loss: 0.1411893218755722
train-epoch-step: 18-216 -- Loss: 0.22010192275047302
train-epoch-step: 18-217 -- Loss: 0.22805923223495483
train-epoch-step: 18-218 -- Loss: 0.16359098255634308
train-epoch-step: 18-219 -- Loss: 0.18513450026512146
train-epoch-step: 18-220 -- Loss: 0.14240945875644684
train-epoch-step: 18-221 -- Loss: 0.22185318171977997
train-epoch-step: 18-222 -- Loss: 0.12853187322616577
train-epoch-step: 18-223 -- Loss: 0.1854240596294403
train-epoch-step: 18-224 -- Loss: 0.21384158730506897
train-epoch-step: 18-225 -- Loss: 0.2905028462409973
train-epoch-step: 18-226 -- Loss: 0.22590678930282593
train-epoch-step: 18-227 -- Loss: 0.23322416841983795
train-epoch-step: 18-228 -- Loss: 0.19239899516105652
train-epoch-step: 18-229 -- Loss: 0.18173222243785858
train-epoch-step: 18-230 -- Loss: 0.17620570957660675
train-epoch-step: 18-231 -- Loss: 0.1760036200284958
train-epoch-step: 18-232 -- Loss: 0.21003518998622894
train-epoch-step: 18-233 -- Loss: 0.09357020258903503
train-epoch-step: 18-234 -- Loss: 0.1975782811641693
train-epoch-step: 18-235 -- Loss: 0.15676075220108032
train-epoch-step: 18-236 -- Loss: 0.18869540095329285
train-epoch-step: 18-237 -- Loss: 0.2526809573173523
train-epoch-step: 18-238 -- Loss: 0.1670197695493698
train-epoch-step: 18-239 -- Loss: 0.1368013471364975
train-epoch-step: 18-240 -- Loss: 0.2382252812385559
train-epoch-step: 18-241 -- Loss: 0.1701943278312683
train-epoch-step: 18-242 -- Loss: 0.23860454559326172
train-epoch-step: 18-243 -- Loss: 0.24799150228500366
train-epoch-step: 18-244 -- Loss: 0.22388726472854614
train-epoch-step: 18-245 -- Loss: 0.22517213225364685
train-epoch-step: 18-246 -- Loss: 0.23557180166244507
train-epoch-step: 18-247 -- Loss: 0.2597988247871399
train-epoch-step: 18-248 -- Loss: 0.20483534038066864
train-epoch-step: 18-249 -- Loss: 0.15396320819854736
train-epoch-step: 18-250 -- Loss: 0.22083808481693268
train-epoch-step: 18-251 -- Loss: 0.11499326676130295
train-epoch-step: 18-252 -- Loss: 0.2063232660293579
train-epoch-step: 18-253 -- Loss: 0.1499611884355545
train-epoch-step: 18-254 -- Loss: 0.23701301217079163
train-epoch-step: 18-255 -- Loss: 0.157078817486763
train-epoch-step: 18-256 -- Loss: 0.18168950080871582
train-epoch-step: 18-257 -- Loss: 0.2026318609714508
train-epoch-step: 18-258 -- Loss: 0.1553800404071808
train-epoch-step: 18-259 -- Loss: 0.13118460774421692
train-epoch-step: 18-260 -- Loss: 0.22203737497329712
train-epoch-step: 18-261 -- Loss: 0.1867554783821106
train-epoch-step: 18-262 -- Loss: 0.3232901096343994
train-epoch-step: 18-263 -- Loss: 0.21820154786109924
train-epoch-step: 18-264 -- Loss: 0.18066827952861786
train-epoch-step: 18-265 -- Loss: 0.13361765444278717
train-epoch-step: 18-266 -- Loss: 0.1589418202638626
train-epoch-step: 18-267 -- Loss: 0.14447258412837982
train-epoch-step: 18-268 -- Loss: 0.12751872837543488
train-epoch-step: 18-269 -- Loss: 0.18281255662441254
train-epoch-step: 18-270 -- Loss: 0.11532457172870636
train-epoch-step: 18-271 -- Loss: 0.15902182459831238
train-epoch-step: 18-272 -- Loss: 0.12166614830493927
train-epoch-step: 18-273 -- Loss: 0.13376052677631378
train-epoch-step: 18-274 -- Loss: 0.2061801254749298
train-epoch-step: 18-275 -- Loss: 0.21430085599422455
train-epoch-step: 18-276 -- Loss: 0.16883431375026703
train-epoch-step: 18-277 -- Loss: 0.17073239386081696
train-epoch-step: 18-278 -- Loss: 0.16449233889579773
train-epoch-step: 18-279 -- Loss: 0.15609821677207947
train-epoch-step: 18-280 -- Loss: 0.23158803582191467
train-epoch-step: 18-281 -- Loss: 0.19598570466041565
train-epoch-step: 18-282 -- Loss: 0.15132535994052887
train-epoch-step: 18-283 -- Loss: 0.12770064175128937
train-epoch-step: 18-284 -- Loss: 0.15755999088287354
train-epoch-step: 18-285 -- Loss: 0.20102949440479279
train-epoch-step: 18-286 -- Loss: 0.171198308467865
train-epoch-step: 18-287 -- Loss: 0.2246910184621811
train-epoch-step: 18-288 -- Loss: 0.0993012934923172
train-epoch-step: 18-289 -- Loss: 0.13125014305114746
train-epoch-step: 18-290 -- Loss: 0.1973588913679123
train-epoch-step: 18-291 -- Loss: 0.12509678304195404
train-epoch-step: 18-292 -- Loss: 0.1674061119556427
train-epoch-step: 18-293 -- Loss: 0.14875532686710358
train-epoch-step: 18-294 -- Loss: 0.19307084381580353
train-epoch-step: 18-295 -- Loss: 0.31157779693603516
train-epoch-step: 18-296 -- Loss: 0.17501291632652283
train-epoch-step: 18-297 -- Loss: 0.18406614661216736
train-epoch-step: 18-298 -- Loss: 0.25139477849006653
train-epoch-step: 18-299 -- Loss: 0.18835337460041046
train-epoch-step: 18-300 -- Loss: 0.1816340982913971
train-epoch-step: 18-301 -- Loss: 0.19258466362953186
train-epoch-step: 18-302 -- Loss: 0.25300315022468567
train-epoch-step: 18-303 -- Loss: 0.2250140905380249
train-epoch-step: 18-304 -- Loss: 0.1434607207775116
train-epoch-step: 18-305 -- Loss: 0.16240918636322021
train-epoch-step: 18-306 -- Loss: 0.25999534130096436
train-epoch-step: 18-307 -- Loss: 0.17732952535152435
train-epoch-step: 18-308 -- Loss: 0.2539772093296051
train-epoch-step: 18-309 -- Loss: 0.16544875502586365
train-epoch-step: 18-310 -- Loss: 0.18138276040554047
train-epoch-step: 18-311 -- Loss: 0.17842191457748413
train-epoch-step: 18-312 -- Loss: 0.2338951677083969
train-epoch-step: 18-313 -- Loss: 0.10780312120914459
train-epoch-step: 18-314 -- Loss: 0.21679648756980896
train-epoch-step: 18-315 -- Loss: 0.1813991665840149
train-epoch-step: 18-316 -- Loss: 0.1636972874403
train-epoch-step: 18-317 -- Loss: 0.15388734638690948
train-epoch-step: 18-318 -- Loss: 0.17965170741081238
train-epoch-step: 18-319 -- Loss: 0.17618076503276825
train-epoch-step: 18-320 -- Loss: 0.12557904422283173
train-epoch-step: 18-321 -- Loss: 0.14167913794517517
train-epoch-step: 18-322 -- Loss: 0.2227647453546524
train-epoch-step: 18-323 -- Loss: 0.17427799105644226
train-epoch-step: 18-324 -- Loss: 0.2686069905757904
train-epoch-step: 18-325 -- Loss: 0.1652517169713974
train-epoch-step: 18-326 -- Loss: 0.18576785922050476
train-epoch-step: 18-327 -- Loss: 0.21939149498939514
train-epoch-step: 18-328 -- Loss: 0.20523285865783691
train-epoch-step: 18-329 -- Loss: 0.3522875905036926
train-epoch-step: 18-330 -- Loss: 0.38283926248550415
train-epoch-step: 18-331 -- Loss: 0.2241203486919403
train-epoch-step: 18-332 -- Loss: 0.10684800148010254
train-epoch-step: 18-333 -- Loss: 0.20091485977172852
train-epoch-step: 18-334 -- Loss: 0.16431644558906555
train-epoch-step: 18-335 -- Loss: 0.18897590041160583
train-epoch-step: 18-336 -- Loss: 0.16405877470970154
train-epoch-step: 18-337 -- Loss: 0.2263401746749878
train-epoch-step: 18-338 -- Loss: 0.1703297644853592
train-epoch-step: 18-339 -- Loss: 0.15337300300598145
train-epoch-step: 18-340 -- Loss: 0.21252991259098053
train-epoch-step: 18-341 -- Loss: 0.14974366128444672
train-epoch-step: 18-342 -- Loss: 0.1815115213394165
train-epoch-step: 18-343 -- Loss: 0.16485469043254852
train-epoch-step: 18-344 -- Loss: 0.1874910593032837
train-epoch-step: 18-345 -- Loss: 0.1370854377746582
train-epoch-step: 18-346 -- Loss: 0.21978653967380524
train-epoch-step: 18-347 -- Loss: 0.1639234572649002
train-epoch-step: 18-348 -- Loss: 0.2186315506696701
train-epoch-step: 18-349 -- Loss: 0.22810570895671844
train-epoch-step: 18-350 -- Loss: 0.2833961546421051
train-epoch-step: 18-351 -- Loss: 0.2104240506887436
train-epoch-step: 18-352 -- Loss: 0.1315942108631134
train-epoch-step: 18-353 -- Loss: 0.21189087629318237
train-epoch-step: 18-354 -- Loss: 0.31019774079322815
train-epoch-step: 18-355 -- Loss: 0.13075515627861023
train-epoch-step: 18-356 -- Loss: 0.13024619221687317
train-epoch-step: 18-357 -- Loss: 0.20866326987743378
train-epoch-step: 18-358 -- Loss: 0.19759920239448547
train-epoch-step: 18-359 -- Loss: 0.15440566837787628
train-epoch-step: 18-360 -- Loss: 0.12654593586921692
train-epoch-step: 18-361 -- Loss: 0.2609945237636566
train-epoch-step: 18-362 -- Loss: 0.18248645961284637
train-epoch-step: 18-363 -- Loss: 0.1300577074289322
train-epoch-step: 18-364 -- Loss: 0.198563352227211
train-epoch-step: 18-365 -- Loss: 0.19294670224189758
train-epoch-step: 18-366 -- Loss: 0.2334292232990265
train-epoch-step: 18-367 -- Loss: 0.25735604763031006
train-epoch-step: 18-368 -- Loss: 0.22224542498588562
train-epoch-step: 18-369 -- Loss: 0.2980307936668396
train-epoch-step: 18-370 -- Loss: 0.14424432814121246
train-epoch-step: 18-371 -- Loss: 0.12759724259376526
train-epoch-step: 18-372 -- Loss: 0.15780451893806458
train-epoch-step: 18-373 -- Loss: 0.20694544911384583
train-epoch-step: 18-374 -- Loss: 0.16303077340126038
train-epoch-step: 18-375 -- Loss: 0.285458505153656
train-epoch-step: 18-376 -- Loss: 0.1802051067352295
train-epoch-step: 18-377 -- Loss: 0.2631482183933258
train-epoch-step: 18-378 -- Loss: 0.23054830729961395
train-epoch-step: 18-379 -- Loss: 0.12773339450359344
train-epoch-step: 18-380 -- Loss: 0.09642750769853592
train-epoch-step: 18-381 -- Loss: 0.2606772184371948
train-epoch-step: 18-382 -- Loss: 0.252669095993042
train-epoch-step: 18-383 -- Loss: 0.18264245986938477
train-epoch-step: 18-384 -- Loss: 0.25312915444374084
train-epoch-step: 18-385 -- Loss: 0.2103269100189209
train-epoch-step: 18-386 -- Loss: 0.19988030195236206
train-epoch-step: 18-387 -- Loss: 0.22371312975883484
train-epoch-step: 18-388 -- Loss: 0.22323861718177795
train-epoch-step: 18-389 -- Loss: 0.18417900800704956
train-epoch-step: 18-390 -- Loss: 0.14970973134040833
train-epoch-step: 18-391 -- Loss: 0.15493997931480408
train-epoch-step: 18-392 -- Loss: 0.19485381245613098
train-epoch-step: 18-393 -- Loss: 0.16812646389007568
train-epoch-step: 18-394 -- Loss: 0.22390051186084747
train-epoch-step: 18-395 -- Loss: 0.1747818887233734
train-epoch-step: 18-396 -- Loss: 0.13692939281463623
train-epoch-step: 18-397 -- Loss: 0.1354057937860489
train-epoch-step: 18-398 -- Loss: 0.20666049420833588
train-epoch-step: 18-399 -- Loss: 0.1952374279499054
train-epoch-step: 18-400 -- Loss: 0.29506194591522217
train-epoch-step: 18-401 -- Loss: 0.1273224949836731
train-epoch-step: 18-402 -- Loss: 0.2748609483242035
train-epoch-step: 18-403 -- Loss: 0.1721874177455902
train-epoch-step: 18-404 -- Loss: 0.15242791175842285
train-epoch-step: 18-405 -- Loss: 0.1537654995918274
train-epoch-step: 18-406 -- Loss: 0.1881573349237442
train-epoch-step: 18-407 -- Loss: 0.12377025187015533
train-epoch-step: 18-408 -- Loss: 0.17132753133773804
train-epoch-step: 18-409 -- Loss: 0.17847268283367157
train-epoch-step: 18-410 -- Loss: 0.18727830052375793
train-epoch-step: 18-411 -- Loss: 0.2131013125181198
train-epoch-step: 18-412 -- Loss: 0.14144356548786163
train-epoch-step: 18-413 -- Loss: 0.1542746126651764
train-epoch-step: 18-414 -- Loss: 0.14477375149726868
train-epoch-step: 18-415 -- Loss: 0.14825686812400818
train-epoch-step: 18-416 -- Loss: 0.2727786600589752
train-epoch-step: 18-417 -- Loss: 0.20462098717689514
train-epoch-step: 18-418 -- Loss: 0.25425028800964355
train-epoch-step: 18-419 -- Loss: 0.17597050964832306
train-epoch-step: 18-420 -- Loss: 0.16364994645118713
train-epoch-step: 18-421 -- Loss: 0.19032558798789978
train-epoch-step: 18-422 -- Loss: 0.15753790736198425
train-epoch-step: 18-423 -- Loss: 0.191094309091568
train-epoch-step: 18-424 -- Loss: 0.1452445387840271
train-epoch-step: 18-425 -- Loss: 0.19534002244472504
train-epoch-step: 18-426 -- Loss: 0.17105530202388763
train-epoch-step: 18-427 -- Loss: 0.1318410038948059
train-epoch-step: 18-428 -- Loss: 0.21060813963413239
train-epoch-step: 18-429 -- Loss: 0.18431967496871948
train-epoch-step: 18-430 -- Loss: 0.16222834587097168
train-epoch-step: 18-431 -- Loss: 0.1753731071949005
train-epoch-step: 18-432 -- Loss: 0.25149106979370117
train-epoch-step: 18-433 -- Loss: 0.14471110701560974
train-epoch-step: 18-434 -- Loss: 0.14025524258613586
train-epoch-step: 18-435 -- Loss: 0.16642966866493225
train-epoch-step: 18-436 -- Loss: 0.16694432497024536
train-epoch-step: 18-437 -- Loss: 0.14447684586048126
train-epoch-step: 18-438 -- Loss: 0.18567097187042236
train-epoch-step: 18-439 -- Loss: 0.2812071740627289
train-epoch-step: 18-440 -- Loss: 0.13925385475158691
train-epoch-step: 18-441 -- Loss: 0.21949176490306854
train-epoch-step: 18-442 -- Loss: 0.19561290740966797
train-epoch-step: 18-443 -- Loss: 0.1734774112701416
train-epoch-step: 18-444 -- Loss: 0.18583720922470093
train-epoch-step: 18-445 -- Loss: 0.19508454203605652
train-epoch-step: 18-446 -- Loss: 0.1697556972503662
train-epoch-step: 18-447 -- Loss: 0.21015045046806335
train-epoch-step: 18-448 -- Loss: 0.23843595385551453
train-epoch-step: 18-449 -- Loss: 0.2076847106218338
train-epoch-step: 18-450 -- Loss: 0.20241346955299377
train-epoch-step: 18-451 -- Loss: 0.152704119682312
train-epoch-step: 18-452 -- Loss: 0.13913996517658234
train-epoch-step: 18-453 -- Loss: 0.10164207220077515
train-epoch-step: 18-454 -- Loss: 0.2489302158355713
train-epoch-step: 18-455 -- Loss: 0.13658267259597778
train-epoch-step: 18-456 -- Loss: 0.1322319209575653
train-epoch-step: 18-457 -- Loss: 0.23117311298847198
train-epoch-step: 18-458 -- Loss: 0.16160784661769867
train-epoch-step: 18-459 -- Loss: 0.23296913504600525
train-epoch-step: 18-460 -- Loss: 0.1327308565378189
train-epoch-step: 18-461 -- Loss: 0.14479057490825653
train-epoch-step: 18-462 -- Loss: 0.1740873008966446
train-epoch-step: 18-463 -- Loss: 0.1428554356098175
train-epoch-step: 18-464 -- Loss: 0.1734073907136917
train-epoch-step: 18-465 -- Loss: 0.25579914450645447
train-epoch-step: 18-466 -- Loss: 0.21336832642555237
train-epoch-step: 18-467 -- Loss: 0.11997146904468536
train-epoch-step: 18-468 -- Loss: 0.18339043855667114
train-epoch-step: 18-469 -- Loss: 0.2282116413116455
train-epoch-step: 18-470 -- Loss: 0.1966402232646942
train-epoch-step: 18-471 -- Loss: 0.17471514642238617
train-epoch-step: 18-472 -- Loss: 0.16461557149887085
train-epoch-step: 18-473 -- Loss: 0.175449401140213
train-epoch-step: 18-474 -- Loss: 0.12491264194250107
train-epoch-step: 18-475 -- Loss: 0.127172589302063
train-epoch-step: 18-476 -- Loss: 0.20905399322509766
train-epoch-step: 18-477 -- Loss: 0.22584733366966248
train-epoch-step: 18-478 -- Loss: 0.20497146248817444
train-epoch-step: 18-479 -- Loss: 0.1512710601091385
train-epoch-step: 18-480 -- Loss: 0.20507286489009857
train-epoch-step: 18-481 -- Loss: 0.29117774963378906
train-epoch-step: 18-482 -- Loss: 0.2784869372844696
train-epoch-step: 18-483 -- Loss: 0.19652575254440308
train-epoch-step: 18-484 -- Loss: 0.22431246936321259
train-epoch-step: 18-485 -- Loss: 0.13873043656349182
train-epoch-step: 18-486 -- Loss: 0.26686644554138184
train-epoch-step: 18-487 -- Loss: 0.23965226113796234
train-epoch-step: 18-488 -- Loss: 0.20787525177001953
train-epoch-step: 18-489 -- Loss: 0.2301357388496399
train-epoch-step: 18-490 -- Loss: 0.1491902768611908
train-epoch-step: 18-491 -- Loss: 0.1436542272567749
train-epoch-step: 18-492 -- Loss: 0.13442829251289368
train-epoch-step: 18-493 -- Loss: 0.2364061325788498
train-epoch-step: 18-494 -- Loss: 0.23516836762428284
train-epoch-step: 18-495 -- Loss: 0.21693086624145508
train-epoch-step: 18-496 -- Loss: 0.14638864994049072
train-epoch-step: 18-497 -- Loss: 0.19443291425704956
train-epoch-step: 18-498 -- Loss: 0.15757566690444946
train-epoch-step: 18-499 -- Loss: 0.1785186529159546
train-epoch-step: 18-500 -- Loss: 0.17354996502399445
train-epoch-step: 18-501 -- Loss: 0.23328830301761627
train-epoch-step: 18-502 -- Loss: 0.16523995995521545
train-epoch-step: 18-503 -- Loss: 0.2347393035888672
train-epoch-step: 18-504 -- Loss: 0.13767129182815552
train-epoch-step: 18-505 -- Loss: 0.18161912262439728
train-epoch-step: 18-506 -- Loss: 0.12751343846321106
train-epoch-step: 18-507 -- Loss: 0.19255533814430237
train-epoch-step: 18-508 -- Loss: 0.18678018450737
train-epoch-step: 18-509 -- Loss: 0.18415293097496033
train-epoch-step: 18-510 -- Loss: 0.13421425223350525
train-epoch-step: 18-511 -- Loss: 0.23133891820907593
train-epoch-step: 18-512 -- Loss: 0.1845892071723938
train-epoch-step: 18-513 -- Loss: 0.22074532508850098
train-epoch-step: 18-514 -- Loss: 0.15600866079330444
train-epoch-step: 18-515 -- Loss: 0.1743062287569046
train-epoch-step: 18-516 -- Loss: 0.18480649590492249
train-epoch-step: 18-517 -- Loss: 0.18678902089595795
train-epoch-step: 18-518 -- Loss: 0.14983054995536804
train-epoch-step: 18-519 -- Loss: 0.14104783535003662
train-epoch-step: 18-520 -- Loss: 0.19605626165866852
train-epoch-step: 18-521 -- Loss: 0.23994682729244232
train-epoch-step: 18-522 -- Loss: 0.18265536427497864
train-epoch-step: 18-523 -- Loss: 0.16554541885852814
train-epoch-step: 18-524 -- Loss: 0.18527719378471375
train-epoch-step: 18-525 -- Loss: 0.20460215210914612
train-epoch-step: 18-526 -- Loss: 0.13831321895122528
train-epoch-step: 18-527 -- Loss: 0.15951664745807648
train-epoch-step: 18-528 -- Loss: 0.16764488816261292
train-epoch-step: 18-529 -- Loss: 0.1792883723974228
train-epoch-step: 18-530 -- Loss: 0.17788591980934143
train-epoch-step: 18-531 -- Loss: 0.2228531837463379
train-epoch-step: 18-532 -- Loss: 0.18167293071746826
train-epoch-step: 18-533 -- Loss: 0.18025803565979004
train-epoch-step: 18-534 -- Loss: 0.14404752850532532
train-epoch-step: 18-535 -- Loss: 0.2729014754295349
train-epoch-step: 18-536 -- Loss: 0.16806340217590332
train-epoch-step: 18-537 -- Loss: 0.16216234862804413
train-epoch-step: 18-538 -- Loss: 0.11126265674829483
train-epoch-step: 18-539 -- Loss: 0.20612692832946777
train-epoch-step: 18-540 -- Loss: 0.14511652290821075
train-epoch-step: 18-541 -- Loss: 0.2203863263130188
train-epoch-step: 18-542 -- Loss: 0.247128427028656
train-epoch-step: 18-543 -- Loss: 0.17720863223075867
train-epoch-step: 18-544 -- Loss: 0.2408319115638733
train-epoch-step: 18-545 -- Loss: 0.2116197645664215
train-epoch-step: 18-546 -- Loss: 0.22876238822937012
train-epoch-step: 18-547 -- Loss: 0.195004403591156
train-epoch-step: 18-548 -- Loss: 0.10065300017595291
train-epoch-step: 18-549 -- Loss: 0.1613949090242386
train-epoch-step: 18-550 -- Loss: 0.2129274606704712
train-epoch-step: 18-551 -- Loss: 0.17101292312145233
train-epoch-step: 18-552 -- Loss: 0.1419297456741333
train-epoch-step: 18-553 -- Loss: 0.20035655796527863
train-epoch-step: 18-554 -- Loss: 0.19812169671058655
train-epoch-step: 18-555 -- Loss: 0.2387314736843109
train-epoch-step: 18-556 -- Loss: 0.16602306067943573
train-epoch-step: 18-557 -- Loss: 0.26288044452667236
train-epoch-step: 18-558 -- Loss: 0.24007990956306458
train-epoch-step: 18-559 -- Loss: 0.16053679585456848
train-epoch-step: 18-560 -- Loss: 0.2142116278409958
train-epoch-step: 18-561 -- Loss: 0.20298203825950623
train-epoch-step: 18-562 -- Loss: 0.17374300956726074
train-epoch-step: 18-563 -- Loss: 0.19573813676834106
train-epoch-step: 18-564 -- Loss: 0.10623046010732651
train-epoch-step: 18-565 -- Loss: 0.19986052811145782
train-epoch-step: 18-566 -- Loss: 0.16381511092185974
train-epoch-step: 18-567 -- Loss: 0.22651222348213196
train-epoch-step: 18-568 -- Loss: 0.17291958630084991
train-epoch-step: 18-569 -- Loss: 0.250701904296875
train-epoch-step: 18-570 -- Loss: 0.19756381213665009
train-epoch-step: 18-571 -- Loss: 0.22932004928588867
train-epoch-step: 18-572 -- Loss: 0.2581332325935364
train-epoch-step: 18-573 -- Loss: 0.21800822019577026
train-epoch-step: 18-574 -- Loss: 0.2681386470794678
train-epoch-step: 18-575 -- Loss: 0.31860947608947754
train-epoch-step: 18-576 -- Loss: 0.12933285534381866
train-epoch-step: 18-577 -- Loss: 0.186967670917511
train-epoch-step: 18-578 -- Loss: 0.22862274944782257
train-epoch-step: 18-579 -- Loss: 0.17833136022090912
train-epoch-step: 18-580 -- Loss: 0.1936679482460022
train-epoch-step: 18-581 -- Loss: 0.15167054533958435
train-epoch-step: 18-582 -- Loss: 0.22406792640686035
train-epoch-step: 18-583 -- Loss: 0.24365127086639404
train-epoch-step: 18-584 -- Loss: 0.18165554106235504
train-epoch-step: 18-585 -- Loss: 0.20509758591651917
train-epoch-step: 18-586 -- Loss: 0.2712383568286896
train-epoch-step: 18-587 -- Loss: 0.16917544603347778
train-epoch-step: 18-588 -- Loss: 0.13773402571678162
val-epoch-step: 18-589 -- Loss: 0.21482932567596436
val-epoch-step: 18-590 -- Loss: 0.158631831407547
val-epoch-step: 18-591 -- Loss: 0.22707389295101166
val-epoch-step: 18-592 -- Loss: 0.1878703236579895
val-epoch-step: 18-593 -- Loss: 0.15630392730236053
val-epoch-step: 18-594 -- Loss: 0.413778156042099
val-epoch-step: 18-595 -- Loss: 0.19479943811893463
val-epoch-step: 18-596 -- Loss: 0.23123160004615784
val-epoch-step: 18-597 -- Loss: 0.18431365489959717
val-epoch-step: 18-598 -- Loss: 0.1570078432559967
val-epoch-step: 18-599 -- Loss: 0.1933089792728424
val-epoch-step: 18-600 -- Loss: 0.21065473556518555
val-epoch-step: 18-601 -- Loss: 0.16734226047992706
val-epoch-step: 18-602 -- Loss: 0.14891768991947174
val-epoch-step: 18-603 -- Loss: 0.20291081070899963
val-epoch-step: 18-604 -- Loss: 0.16001392900943756
val-epoch-step: 18-605 -- Loss: 0.15997803211212158
val-epoch-step: 18-606 -- Loss: 0.2828737795352936
val-epoch-step: 18-607 -- Loss: 0.13516172766685486
val-epoch-step: 18-608 -- Loss: 0.2593500018119812
val-epoch-step: 18-609 -- Loss: 0.1816188246011734
val-epoch-step: 18-610 -- Loss: 0.19051137566566467
val-epoch-step: 18-611 -- Loss: 0.1812329739332199
val-epoch-step: 18-612 -- Loss: 0.43893498182296753
val-epoch-step: 18-613 -- Loss: 0.183717742562294
val-epoch-step: 18-614 -- Loss: 0.1715073585510254
val-epoch-step: 18-615 -- Loss: 0.18625496327877045
val-epoch-step: 18-616 -- Loss: 0.1599072813987732
val-epoch-step: 18-617 -- Loss: 0.19614771008491516
val-epoch-step: 18-618 -- Loss: 0.19976070523262024
val-epoch-step: 18-619 -- Loss: 0.22283728420734406
val-epoch-step: 18-620 -- Loss: 0.14370810985565186
val-epoch-step: 18-621 -- Loss: 0.14064109325408936
val-epoch-step: 18-622 -- Loss: 0.15131083130836487
val-epoch-step: 18-623 -- Loss: 0.16459950804710388
val-epoch-step: 18-624 -- Loss: 0.1575581580400467
val-epoch-step: 18-625 -- Loss: 0.1662086546421051
val-epoch-step: 18-626 -- Loss: 0.1538333296775818
val-epoch-step: 18-627 -- Loss: 0.2131078541278839
val-epoch-step: 18-628 -- Loss: 0.6654436588287354
val-epoch-step: 18-629 -- Loss: 0.22498303651809692
val-epoch-step: 18-630 -- Loss: 0.3599328398704529
val-epoch-step: 18-631 -- Loss: 0.15535128116607666
val-epoch-step: 18-632 -- Loss: 0.2076510488986969
val-epoch-step: 18-633 -- Loss: 0.1605781614780426
val-epoch-step: 18-634 -- Loss: 0.14815735816955566
val-epoch-step: 18-635 -- Loss: 0.12604746222496033
val-epoch-step: 18-636 -- Loss: 0.17643803358078003
val-epoch-step: 18-637 -- Loss: 0.1889662891626358
val-epoch-step: 18-638 -- Loss: 0.16214871406555176
val-epoch-step: 18-639 -- Loss: 0.27029895782470703
val-epoch-step: 18-640 -- Loss: 0.27876654267311096
val-epoch-step: 18-641 -- Loss: 0.14157269895076752
val-epoch-step: 18-642 -- Loss: 0.19723762571811676
val-epoch-step: 18-643 -- Loss: 0.21816620230674744
val-epoch-step: 18-644 -- Loss: 0.17180950939655304
val-epoch-step: 18-645 -- Loss: 0.23038384318351746
val-epoch-step: 18-646 -- Loss: 0.14092466235160828
val-epoch-step: 18-647 -- Loss: 0.13989052176475525
val-epoch-step: 18-648 -- Loss: 0.17176678776741028
val-epoch-step: 18-649 -- Loss: 0.21927060186862946
val-epoch-step: 18-650 -- Loss: 0.27030500769615173
val-epoch-step: 18-651 -- Loss: 0.15596002340316772
val-epoch-step: 18-652 -- Loss: 0.16721098124980927
val-epoch-step: 18-653 -- Loss: 0.21374329924583435
val-epoch-step: 18-654 -- Loss: 0.11933974921703339
Epoch: 18 -- Train Loss: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 19-0 -- Loss: 0.23821386694908142
train-epoch-step: 19-1 -- Loss: 0.15082788467407227
train-epoch-step: 19-2 -- Loss: 0.21741428971290588
train-epoch-step: 19-3 -- Loss: 0.15482822060585022
train-epoch-step: 19-4 -- Loss: 0.17774423956871033
train-epoch-step: 19-5 -- Loss: 0.19901609420776367
train-epoch-step: 19-6 -- Loss: 0.23791292309761047
train-epoch-step: 19-7 -- Loss: 0.17940780520439148
train-epoch-step: 19-8 -- Loss: 0.20359598100185394
train-epoch-step: 19-9 -- Loss: 0.2989121675491333
train-epoch-step: 19-10 -- Loss: 0.22623097896575928
train-epoch-step: 19-11 -- Loss: 0.2004311978816986
train-epoch-step: 19-12 -- Loss: 0.1618536114692688
train-epoch-step: 19-13 -- Loss: 0.18680782616138458
train-epoch-step: 19-14 -- Loss: 0.17609374225139618
train-epoch-step: 19-15 -- Loss: 0.16773557662963867
train-epoch-step: 19-16 -- Loss: 0.17980727553367615
train-epoch-step: 19-17 -- Loss: 0.24160662293434143
train-epoch-step: 19-18 -- Loss: 0.21153420209884644
train-epoch-step: 19-19 -- Loss: 0.13728149235248566
train-epoch-step: 19-20 -- Loss: 0.2394694834947586
train-epoch-step: 19-21 -- Loss: 0.2765645980834961
train-epoch-step: 19-22 -- Loss: 0.15190255641937256
train-epoch-step: 19-23 -- Loss: 0.15918344259262085
train-epoch-step: 19-24 -- Loss: 0.13762587308883667
train-epoch-step: 19-25 -- Loss: 0.2426077425479889
train-epoch-step: 19-26 -- Loss: 0.20710590481758118
train-epoch-step: 19-27 -- Loss: 0.25081807374954224
train-epoch-step: 19-28 -- Loss: 0.12998004257678986
train-epoch-step: 19-29 -- Loss: 0.25954505801200867
train-epoch-step: 19-30 -- Loss: 0.12001334130764008
train-epoch-step: 19-31 -- Loss: 0.16030694544315338
train-epoch-step: 19-32 -- Loss: 0.1829913854598999
train-epoch-step: 19-33 -- Loss: 0.29211628437042236
train-epoch-step: 19-34 -- Loss: 0.1812179684638977
train-epoch-step: 19-35 -- Loss: 0.2692308723926544
train-epoch-step: 19-36 -- Loss: 0.1439167559146881
train-epoch-step: 19-37 -- Loss: 0.14670658111572266
train-epoch-step: 19-38 -- Loss: 0.20442861318588257
train-epoch-step: 19-39 -- Loss: 0.23888243734836578
train-epoch-step: 19-40 -- Loss: 0.21125733852386475
train-epoch-step: 19-41 -- Loss: 0.22731153666973114
train-epoch-step: 19-42 -- Loss: 0.1560884416103363
train-epoch-step: 19-43 -- Loss: 0.2819666564464569
train-epoch-step: 19-44 -- Loss: 0.13581131398677826
train-epoch-step: 19-45 -- Loss: 0.12820252776145935
train-epoch-step: 19-46 -- Loss: 0.18528123199939728
train-epoch-step: 19-47 -- Loss: 0.2442808747291565
train-epoch-step: 19-48 -- Loss: 0.1618107259273529
train-epoch-step: 19-49 -- Loss: 0.23156315088272095
train-epoch-step: 19-50 -- Loss: 0.12317439913749695
train-epoch-step: 19-51 -- Loss: 0.20204773545265198
train-epoch-step: 19-52 -- Loss: 0.167050302028656
train-epoch-step: 19-53 -- Loss: 0.22921030223369598
train-epoch-step: 19-54 -- Loss: 0.295592725276947
train-epoch-step: 19-55 -- Loss: 0.1851288378238678
train-epoch-step: 19-56 -- Loss: 0.189176544547081
train-epoch-step: 19-57 -- Loss: 0.24710693955421448
train-epoch-step: 19-58 -- Loss: 0.29305076599121094
train-epoch-step: 19-59 -- Loss: 0.26840269565582275
train-epoch-step: 19-60 -- Loss: 0.14035433530807495
train-epoch-step: 19-61 -- Loss: 0.2220861315727234
train-epoch-step: 19-62 -- Loss: 0.19585588574409485
train-epoch-step: 19-63 -- Loss: 0.151578888297081
train-epoch-step: 19-64 -- Loss: 0.1571130007505417
train-epoch-step: 19-65 -- Loss: 0.19784651696681976
train-epoch-step: 19-66 -- Loss: 0.1176421195268631
train-epoch-step: 19-67 -- Loss: 0.13590097427368164
train-epoch-step: 19-68 -- Loss: 0.23491650819778442
train-epoch-step: 19-69 -- Loss: 0.13345292210578918
train-epoch-step: 19-70 -- Loss: 0.24167627096176147
train-epoch-step: 19-71 -- Loss: 0.27289777994155884
train-epoch-step: 19-72 -- Loss: 0.18879540264606476
train-epoch-step: 19-73 -- Loss: 0.22272145748138428
train-epoch-step: 19-74 -- Loss: 0.1042301207780838
train-epoch-step: 19-75 -- Loss: 0.1378898024559021
train-epoch-step: 19-76 -- Loss: 0.15657244622707367
train-epoch-step: 19-77 -- Loss: 0.2438599169254303
train-epoch-step: 19-78 -- Loss: 0.28011927008628845
train-epoch-step: 19-79 -- Loss: 0.20647095143795013
train-epoch-step: 19-80 -- Loss: 0.2821023762226105
train-epoch-step: 19-81 -- Loss: 0.13574431836605072
train-epoch-step: 19-82 -- Loss: 0.26695019006729126
train-epoch-step: 19-83 -- Loss: 0.21261414885520935
train-epoch-step: 19-84 -- Loss: 0.20701883733272552
train-epoch-step: 19-85 -- Loss: 0.18786536157131195
train-epoch-step: 19-86 -- Loss: 0.13610133528709412
train-epoch-step: 19-87 -- Loss: 0.24844440817832947
train-epoch-step: 19-88 -- Loss: 0.15167920291423798
train-epoch-step: 19-89 -- Loss: 0.19918948411941528
train-epoch-step: 19-90 -- Loss: 0.2039956897497177
train-epoch-step: 19-91 -- Loss: 0.25899386405944824
train-epoch-step: 19-92 -- Loss: 0.16519992053508759
train-epoch-step: 19-93 -- Loss: 0.18147145211696625
train-epoch-step: 19-94 -- Loss: 0.24198076128959656
train-epoch-step: 19-95 -- Loss: 0.2056378424167633
train-epoch-step: 19-96 -- Loss: 0.23294945061206818
train-epoch-step: 19-97 -- Loss: 0.1917160004377365
train-epoch-step: 19-98 -- Loss: 0.16179800033569336
train-epoch-step: 19-99 -- Loss: 0.19152535498142242
train-epoch-step: 19-100 -- Loss: 0.19607160985469818
train-epoch-step: 19-101 -- Loss: 0.29821139574050903
train-epoch-step: 19-102 -- Loss: 0.24599191546440125
train-epoch-step: 19-103 -- Loss: 0.19531233608722687
train-epoch-step: 19-104 -- Loss: 0.15505710244178772
train-epoch-step: 19-105 -- Loss: 0.2874375283718109
train-epoch-step: 19-106 -- Loss: 0.17826133966445923
train-epoch-step: 19-107 -- Loss: 0.20164453983306885
train-epoch-step: 19-108 -- Loss: 0.19542032480239868
train-epoch-step: 19-109 -- Loss: 0.15667088329792023
train-epoch-step: 19-110 -- Loss: 0.19202624261379242
train-epoch-step: 19-111 -- Loss: 0.19407549500465393
train-epoch-step: 19-112 -- Loss: 0.18134281039237976
train-epoch-step: 19-113 -- Loss: 0.1733068972826004
train-epoch-step: 19-114 -- Loss: 0.207769975066185
train-epoch-step: 19-115 -- Loss: 0.17665137350559235
train-epoch-step: 19-116 -- Loss: 0.15366464853286743
train-epoch-step: 19-117 -- Loss: 0.1376836895942688
train-epoch-step: 19-118 -- Loss: 0.21181228756904602
train-epoch-step: 19-119 -- Loss: 0.16853547096252441
train-epoch-step: 19-120 -- Loss: 0.269192099571228
train-epoch-step: 19-121 -- Loss: 0.28903865814208984
train-epoch-step: 19-122 -- Loss: 0.2273324579000473
train-epoch-step: 19-123 -- Loss: 0.21753372251987457
train-epoch-step: 19-124 -- Loss: 0.13451111316680908
train-epoch-step: 19-125 -- Loss: 0.15937265753746033
train-epoch-step: 19-126 -- Loss: 0.2347753494977951
train-epoch-step: 19-127 -- Loss: 0.18463784456253052
train-epoch-step: 19-128 -- Loss: 0.18245995044708252
train-epoch-step: 19-129 -- Loss: 0.15793229639530182
train-epoch-step: 19-130 -- Loss: 0.20757566392421722
train-epoch-step: 19-131 -- Loss: 0.1485215723514557
train-epoch-step: 19-132 -- Loss: 0.2123541682958603
train-epoch-step: 19-133 -- Loss: 0.12659551203250885
train-epoch-step: 19-134 -- Loss: 0.21144774556159973
train-epoch-step: 19-135 -- Loss: 0.14890079200267792
train-epoch-step: 19-136 -- Loss: 0.13534460961818695
train-epoch-step: 19-137 -- Loss: 0.27988606691360474
train-epoch-step: 19-138 -- Loss: 0.28994956612586975
train-epoch-step: 19-139 -- Loss: 0.14131566882133484
train-epoch-step: 19-140 -- Loss: 0.21463827788829803
train-epoch-step: 19-141 -- Loss: 0.23935484886169434
train-epoch-step: 19-142 -- Loss: 0.2143903225660324
train-epoch-step: 19-143 -- Loss: 0.1879677027463913
train-epoch-step: 19-144 -- Loss: 0.19666998088359833
train-epoch-step: 19-145 -- Loss: 0.1499749720096588
train-epoch-step: 19-146 -- Loss: 0.19057761132717133
train-epoch-step: 19-147 -- Loss: 0.18861952424049377
train-epoch-step: 19-148 -- Loss: 0.17467628419399261
train-epoch-step: 19-149 -- Loss: 0.12280303984880447
train-epoch-step: 19-150 -- Loss: 0.19777844846248627
train-epoch-step: 19-151 -- Loss: 0.21580669283866882
train-epoch-step: 19-152 -- Loss: 0.21609890460968018
train-epoch-step: 19-153 -- Loss: 0.28700101375579834
train-epoch-step: 19-154 -- Loss: 0.14513984322547913
train-epoch-step: 19-155 -- Loss: 0.14274339377880096
train-epoch-step: 19-156 -- Loss: 0.1328456699848175
train-epoch-step: 19-157 -- Loss: 0.18709829449653625
train-epoch-step: 19-158 -- Loss: 0.17605696618556976
train-epoch-step: 19-159 -- Loss: 0.19249527156352997
train-epoch-step: 19-160 -- Loss: 0.24588003754615784
train-epoch-step: 19-161 -- Loss: 0.22212135791778564
train-epoch-step: 19-162 -- Loss: 0.22373661398887634
train-epoch-step: 19-163 -- Loss: 0.20254677534103394
train-epoch-step: 19-164 -- Loss: 0.20265114307403564
train-epoch-step: 19-165 -- Loss: 0.1749783754348755
train-epoch-step: 19-166 -- Loss: 0.13311569392681122
train-epoch-step: 19-167 -- Loss: 0.14004145562648773
train-epoch-step: 19-168 -- Loss: 0.21110782027244568
train-epoch-step: 19-169 -- Loss: 0.14693784713745117
train-epoch-step: 19-170 -- Loss: 0.21228864789009094
train-epoch-step: 19-171 -- Loss: 0.15067125856876373
train-epoch-step: 19-172 -- Loss: 0.2702402174472809
train-epoch-step: 19-173 -- Loss: 0.14361415803432465
train-epoch-step: 19-174 -- Loss: 0.2658245265483856
train-epoch-step: 19-175 -- Loss: 0.20497561991214752
train-epoch-step: 19-176 -- Loss: 0.14209099113941193
train-epoch-step: 19-177 -- Loss: 0.19758161902427673
train-epoch-step: 19-178 -- Loss: 0.20731697976589203
train-epoch-step: 19-179 -- Loss: 0.15653473138809204
train-epoch-step: 19-180 -- Loss: 0.1620754897594452
train-epoch-step: 19-181 -- Loss: 0.18854975700378418
train-epoch-step: 19-182 -- Loss: 0.20463111996650696
train-epoch-step: 19-183 -- Loss: 0.28684067726135254
train-epoch-step: 19-184 -- Loss: 0.14260455965995789
train-epoch-step: 19-185 -- Loss: 0.15131638944149017
train-epoch-step: 19-186 -- Loss: 0.20169274508953094
train-epoch-step: 19-187 -- Loss: 0.22115877270698547
train-epoch-step: 19-188 -- Loss: 0.18418684601783752
train-epoch-step: 19-189 -- Loss: 0.12022772431373596
train-epoch-step: 19-190 -- Loss: 0.19509363174438477
train-epoch-step: 19-191 -- Loss: 0.17840753495693207
train-epoch-step: 19-192 -- Loss: 0.24917589128017426
train-epoch-step: 19-193 -- Loss: 0.2291516363620758
train-epoch-step: 19-194 -- Loss: 0.19779682159423828
train-epoch-step: 19-195 -- Loss: 0.17363888025283813
train-epoch-step: 19-196 -- Loss: 0.17579439282417297
train-epoch-step: 19-197 -- Loss: 0.1497524380683899
train-epoch-step: 19-198 -- Loss: 0.14071109890937805
train-epoch-step: 19-199 -- Loss: 0.1610301434993744
train-epoch-step: 19-200 -- Loss: 0.1382671594619751
train-epoch-step: 19-201 -- Loss: 0.2216540277004242
train-epoch-step: 19-202 -- Loss: 0.1419926881790161
train-epoch-step: 19-203 -- Loss: 0.18491914868354797
train-epoch-step: 19-204 -- Loss: 0.14841055870056152
train-epoch-step: 19-205 -- Loss: 0.2189645767211914
train-epoch-step: 19-206 -- Loss: 0.21927191317081451
train-epoch-step: 19-207 -- Loss: 0.1653364598751068
train-epoch-step: 19-208 -- Loss: 0.18192507326602936
train-epoch-step: 19-209 -- Loss: 0.15423059463500977
train-epoch-step: 19-210 -- Loss: 0.1432187259197235
train-epoch-step: 19-211 -- Loss: 0.2277417629957199
train-epoch-step: 19-212 -- Loss: 0.2137363851070404
train-epoch-step: 19-213 -- Loss: 0.14416442811489105
train-epoch-step: 19-214 -- Loss: 0.1610737144947052
train-epoch-step: 19-215 -- Loss: 0.13926628232002258
train-epoch-step: 19-216 -- Loss: 0.22263211011886597
train-epoch-step: 19-217 -- Loss: 0.2283574640750885
train-epoch-step: 19-218 -- Loss: 0.16047614812850952
train-epoch-step: 19-219 -- Loss: 0.19906379282474518
train-epoch-step: 19-220 -- Loss: 0.14176365733146667
train-epoch-step: 19-221 -- Loss: 0.21739917993545532
train-epoch-step: 19-222 -- Loss: 0.12471436709165573
train-epoch-step: 19-223 -- Loss: 0.1874566376209259
train-epoch-step: 19-224 -- Loss: 0.21851523220539093
train-epoch-step: 19-225 -- Loss: 0.28572842478752136
train-epoch-step: 19-226 -- Loss: 0.21921837329864502
train-epoch-step: 19-227 -- Loss: 0.2334035038948059
train-epoch-step: 19-228 -- Loss: 0.19048570096492767
train-epoch-step: 19-229 -- Loss: 0.1823996752500534
train-epoch-step: 19-230 -- Loss: 0.17425653338432312
train-epoch-step: 19-231 -- Loss: 0.18281587958335876
train-epoch-step: 19-232 -- Loss: 0.20915579795837402
train-epoch-step: 19-233 -- Loss: 0.09141027182340622
train-epoch-step: 19-234 -- Loss: 0.19268009066581726
train-epoch-step: 19-235 -- Loss: 0.1593037247657776
train-epoch-step: 19-236 -- Loss: 0.18772168457508087
train-epoch-step: 19-237 -- Loss: 0.2506043314933777
train-epoch-step: 19-238 -- Loss: 0.16393956542015076
train-epoch-step: 19-239 -- Loss: 0.13839799165725708
train-epoch-step: 19-240 -- Loss: 0.23434972763061523
train-epoch-step: 19-241 -- Loss: 0.16605383157730103
train-epoch-step: 19-242 -- Loss: 0.237219899892807
train-epoch-step: 19-243 -- Loss: 0.24161042273044586
train-epoch-step: 19-244 -- Loss: 0.21452754735946655
train-epoch-step: 19-245 -- Loss: 0.21610520780086517
train-epoch-step: 19-246 -- Loss: 0.23251280188560486
train-epoch-step: 19-247 -- Loss: 0.23671706020832062
train-epoch-step: 19-248 -- Loss: 0.1954583078622818
train-epoch-step: 19-249 -- Loss: 0.14815190434455872
train-epoch-step: 19-250 -- Loss: 0.20965777337551117
train-epoch-step: 19-251 -- Loss: 0.11395936459302902
train-epoch-step: 19-252 -- Loss: 0.2023290991783142
train-epoch-step: 19-253 -- Loss: 0.14874017238616943
train-epoch-step: 19-254 -- Loss: 0.23106710612773895
train-epoch-step: 19-255 -- Loss: 0.16592702269554138
train-epoch-step: 19-256 -- Loss: 0.16383793950080872
train-epoch-step: 19-257 -- Loss: 0.20282714068889618
train-epoch-step: 19-258 -- Loss: 0.1528140902519226
train-epoch-step: 19-259 -- Loss: 0.11690916121006012
train-epoch-step: 19-260 -- Loss: 0.22583836317062378
train-epoch-step: 19-261 -- Loss: 0.17910200357437134
train-epoch-step: 19-262 -- Loss: 0.3434646725654602
train-epoch-step: 19-263 -- Loss: 0.21543537080287933
train-epoch-step: 19-264 -- Loss: 0.17891621589660645
train-epoch-step: 19-265 -- Loss: 0.1403433382511139
train-epoch-step: 19-266 -- Loss: 0.1578134298324585
train-epoch-step: 19-267 -- Loss: 0.14051508903503418
train-epoch-step: 19-268 -- Loss: 0.12745240330696106
train-epoch-step: 19-269 -- Loss: 0.18112552165985107
train-epoch-step: 19-270 -- Loss: 0.11447054147720337
train-epoch-step: 19-271 -- Loss: 0.15465909242630005
train-epoch-step: 19-272 -- Loss: 0.12907227873802185
train-epoch-step: 19-273 -- Loss: 0.13331569731235504
train-epoch-step: 19-274 -- Loss: 0.20441454648971558
train-epoch-step: 19-275 -- Loss: 0.2183513045310974
train-epoch-step: 19-276 -- Loss: 0.16846150159835815
train-epoch-step: 19-277 -- Loss: 0.16514073312282562
train-epoch-step: 19-278 -- Loss: 0.16135342419147491
train-epoch-step: 19-279 -- Loss: 0.15765830874443054
train-epoch-step: 19-280 -- Loss: 0.22936242818832397
train-epoch-step: 19-281 -- Loss: 0.19551727175712585
train-epoch-step: 19-282 -- Loss: 0.15431667864322662
train-epoch-step: 19-283 -- Loss: 0.1306661069393158
train-epoch-step: 19-284 -- Loss: 0.15108227729797363
train-epoch-step: 19-285 -- Loss: 0.2064037322998047
train-epoch-step: 19-286 -- Loss: 0.17157253623008728
train-epoch-step: 19-287 -- Loss: 0.2195994257926941
train-epoch-step: 19-288 -- Loss: 0.10254684090614319
train-epoch-step: 19-289 -- Loss: 0.13066773116588593
train-epoch-step: 19-290 -- Loss: 0.19702588021755219
train-epoch-step: 19-291 -- Loss: 0.12402787804603577
train-epoch-step: 19-292 -- Loss: 0.16078433394432068
train-epoch-step: 19-293 -- Loss: 0.156223326921463
train-epoch-step: 19-294 -- Loss: 0.18107002973556519
train-epoch-step: 19-295 -- Loss: 0.30396920442581177
train-epoch-step: 19-296 -- Loss: 0.16802342236042023
train-epoch-step: 19-297 -- Loss: 0.18097147345542908
train-epoch-step: 19-298 -- Loss: 0.2503478527069092
train-epoch-step: 19-299 -- Loss: 0.1595076620578766
train-epoch-step: 19-300 -- Loss: 0.17794883251190186
train-epoch-step: 19-301 -- Loss: 0.1771538257598877
train-epoch-step: 19-302 -- Loss: 0.24005620181560516
train-epoch-step: 19-303 -- Loss: 0.21718622744083405
train-epoch-step: 19-304 -- Loss: 0.14453727006912231
train-epoch-step: 19-305 -- Loss: 0.15228836238384247
train-epoch-step: 19-306 -- Loss: 0.2437024563550949
train-epoch-step: 19-307 -- Loss: 0.17350801825523376
train-epoch-step: 19-308 -- Loss: 0.22708876430988312
train-epoch-step: 19-309 -- Loss: 0.1624557077884674
train-epoch-step: 19-310 -- Loss: 0.17285242676734924
train-epoch-step: 19-311 -- Loss: 0.17340950667858124
train-epoch-step: 19-312 -- Loss: 0.22475090622901917
train-epoch-step: 19-313 -- Loss: 0.10566622018814087
train-epoch-step: 19-314 -- Loss: 0.21465717256069183
train-epoch-step: 19-315 -- Loss: 0.17752468585968018
train-epoch-step: 19-316 -- Loss: 0.1606244295835495
train-epoch-step: 19-317 -- Loss: 0.1591624915599823
train-epoch-step: 19-318 -- Loss: 0.17069697380065918
train-epoch-step: 19-319 -- Loss: 0.18137609958648682
train-epoch-step: 19-320 -- Loss: 0.12686875462532043
train-epoch-step: 19-321 -- Loss: 0.146211177110672
train-epoch-step: 19-322 -- Loss: 0.22549456357955933
train-epoch-step: 19-323 -- Loss: 0.16946977376937866
train-epoch-step: 19-324 -- Loss: 0.2668219208717346
train-epoch-step: 19-325 -- Loss: 0.16744688153266907
train-epoch-step: 19-326 -- Loss: 0.18159036338329315
train-epoch-step: 19-327 -- Loss: 0.2235972285270691
train-epoch-step: 19-328 -- Loss: 0.20242181420326233
train-epoch-step: 19-329 -- Loss: 0.35138222575187683
train-epoch-step: 19-330 -- Loss: 0.38103151321411133
train-epoch-step: 19-331 -- Loss: 0.217423677444458
train-epoch-step: 19-332 -- Loss: 0.10986107587814331
train-epoch-step: 19-333 -- Loss: 0.2003544121980667
train-epoch-step: 19-334 -- Loss: 0.16669629514217377
train-epoch-step: 19-335 -- Loss: 0.1891097128391266
train-epoch-step: 19-336 -- Loss: 0.1663801372051239
train-epoch-step: 19-337 -- Loss: 0.22896675765514374
train-epoch-step: 19-338 -- Loss: 0.1652504801750183
train-epoch-step: 19-339 -- Loss: 0.15515530109405518
train-epoch-step: 19-340 -- Loss: 0.21155741810798645
train-epoch-step: 19-341 -- Loss: 0.15135782957077026
train-epoch-step: 19-342 -- Loss: 0.1760014146566391
train-epoch-step: 19-343 -- Loss: 0.16382050514221191
train-epoch-step: 19-344 -- Loss: 0.18131177127361298
train-epoch-step: 19-345 -- Loss: 0.13220340013504028
train-epoch-step: 19-346 -- Loss: 0.21628770232200623
train-epoch-step: 19-347 -- Loss: 0.16476570069789886
train-epoch-step: 19-348 -- Loss: 0.21195611357688904
train-epoch-step: 19-349 -- Loss: 0.2212594747543335
train-epoch-step: 19-350 -- Loss: 0.2782852053642273
train-epoch-step: 19-351 -- Loss: 0.20249825716018677
train-epoch-step: 19-352 -- Loss: 0.12718579173088074
train-epoch-step: 19-353 -- Loss: 0.20542623102664948
train-epoch-step: 19-354 -- Loss: 0.2964092493057251
train-epoch-step: 19-355 -- Loss: 0.12781858444213867
train-epoch-step: 19-356 -- Loss: 0.1262660026550293
train-epoch-step: 19-357 -- Loss: 0.20538194477558136
train-epoch-step: 19-358 -- Loss: 0.19290810823440552
train-epoch-step: 19-359 -- Loss: 0.15752163529396057
train-epoch-step: 19-360 -- Loss: 0.13003009557724
train-epoch-step: 19-361 -- Loss: 0.2534431219100952
train-epoch-step: 19-362 -- Loss: 0.18036624789237976
train-epoch-step: 19-363 -- Loss: 0.12852917611598969
train-epoch-step: 19-364 -- Loss: 0.19397109746932983
train-epoch-step: 19-365 -- Loss: 0.19160112738609314
train-epoch-step: 19-366 -- Loss: 0.22600534558296204
train-epoch-step: 19-367 -- Loss: 0.2538585066795349
train-epoch-step: 19-368 -- Loss: 0.216910257935524
train-epoch-step: 19-369 -- Loss: 0.2928239703178406
train-epoch-step: 19-370 -- Loss: 0.13868561387062073
train-epoch-step: 19-371 -- Loss: 0.12645170092582703
train-epoch-step: 19-372 -- Loss: 0.15459087491035461
train-epoch-step: 19-373 -- Loss: 0.20180876553058624
train-epoch-step: 19-374 -- Loss: 0.16367925703525543
train-epoch-step: 19-375 -- Loss: 0.28889593482017517
train-epoch-step: 19-376 -- Loss: 0.18472455441951752
train-epoch-step: 19-377 -- Loss: 0.25034651160240173
train-epoch-step: 19-378 -- Loss: 0.224152073264122
train-epoch-step: 19-379 -- Loss: 0.12815210223197937
train-epoch-step: 19-380 -- Loss: 0.09575669467449188
train-epoch-step: 19-381 -- Loss: 0.2699248492717743
train-epoch-step: 19-382 -- Loss: 0.2477853000164032
train-epoch-step: 19-383 -- Loss: 0.19244889914989471
train-epoch-step: 19-384 -- Loss: 0.2547817826271057
train-epoch-step: 19-385 -- Loss: 0.20839570462703705
train-epoch-step: 19-386 -- Loss: 0.19628286361694336
train-epoch-step: 19-387 -- Loss: 0.22322019934654236
train-epoch-step: 19-388 -- Loss: 0.23668983578681946
train-epoch-step: 19-389 -- Loss: 0.17908194661140442
train-epoch-step: 19-390 -- Loss: 0.1575755476951599
train-epoch-step: 19-391 -- Loss: 0.1553005874156952
train-epoch-step: 19-392 -- Loss: 0.2009693682193756
train-epoch-step: 19-393 -- Loss: 0.17099043726921082
train-epoch-step: 19-394 -- Loss: 0.22753995656967163
train-epoch-step: 19-395 -- Loss: 0.17757286131381989
train-epoch-step: 19-396 -- Loss: 0.13571704924106598
train-epoch-step: 19-397 -- Loss: 0.1324247121810913
train-epoch-step: 19-398 -- Loss: 0.20700252056121826
train-epoch-step: 19-399 -- Loss: 0.1932506263256073
train-epoch-step: 19-400 -- Loss: 0.31274479627609253
train-epoch-step: 19-401 -- Loss: 0.1294633448123932
train-epoch-step: 19-402 -- Loss: 0.2719268500804901
train-epoch-step: 19-403 -- Loss: 0.16781485080718994
train-epoch-step: 19-404 -- Loss: 0.1495717465877533
train-epoch-step: 19-405 -- Loss: 0.15136578679084778
train-epoch-step: 19-406 -- Loss: 0.190695121884346
train-epoch-step: 19-407 -- Loss: 0.12515956163406372
train-epoch-step: 19-408 -- Loss: 0.16987833380699158
train-epoch-step: 19-409 -- Loss: 0.18137414753437042
train-epoch-step: 19-410 -- Loss: 0.18615251779556274
train-epoch-step: 19-411 -- Loss: 0.21370385587215424
train-epoch-step: 19-412 -- Loss: 0.13935674726963043
train-epoch-step: 19-413 -- Loss: 0.15512768924236298
train-epoch-step: 19-414 -- Loss: 0.14250513911247253
train-epoch-step: 19-415 -- Loss: 0.15306776762008667
train-epoch-step: 19-416 -- Loss: 0.27058154344558716
train-epoch-step: 19-417 -- Loss: 0.19785401225090027
train-epoch-step: 19-418 -- Loss: 0.24855762720108032
train-epoch-step: 19-419 -- Loss: 0.19747048616409302
train-epoch-step: 19-420 -- Loss: 0.16887971758842468
train-epoch-step: 19-421 -- Loss: 0.191551074385643
train-epoch-step: 19-422 -- Loss: 0.1622149795293808
train-epoch-step: 19-423 -- Loss: 0.1865023523569107
train-epoch-step: 19-424 -- Loss: 0.1449446827173233
train-epoch-step: 19-425 -- Loss: 0.1940523087978363
train-epoch-step: 19-426 -- Loss: 0.1727653443813324
train-epoch-step: 19-427 -- Loss: 0.13896694779396057
train-epoch-step: 19-428 -- Loss: 0.1967572271823883
train-epoch-step: 19-429 -- Loss: 0.18209317326545715
train-epoch-step: 19-430 -- Loss: 0.14944536983966827
train-epoch-step: 19-431 -- Loss: 0.17566543817520142
train-epoch-step: 19-432 -- Loss: 0.2529374361038208
train-epoch-step: 19-433 -- Loss: 0.14477679133415222
train-epoch-step: 19-434 -- Loss: 0.14090855419635773
train-epoch-step: 19-435 -- Loss: 0.16629701852798462
train-epoch-step: 19-436 -- Loss: 0.17151248455047607
train-epoch-step: 19-437 -- Loss: 0.14234577119350433
train-epoch-step: 19-438 -- Loss: 0.19460996985435486
train-epoch-step: 19-439 -- Loss: 0.27855372428894043
train-epoch-step: 19-440 -- Loss: 0.1413947492837906
train-epoch-step: 19-441 -- Loss: 0.21754132211208344
train-epoch-step: 19-442 -- Loss: 0.19525599479675293
train-epoch-step: 19-443 -- Loss: 0.17359814047813416
train-epoch-step: 19-444 -- Loss: 0.18945573270320892
train-epoch-step: 19-445 -- Loss: 0.18451759219169617
train-epoch-step: 19-446 -- Loss: 0.16426339745521545
train-epoch-step: 19-447 -- Loss: 0.20833593606948853
train-epoch-step: 19-448 -- Loss: 0.24096748232841492
train-epoch-step: 19-449 -- Loss: 0.21600036323070526
train-epoch-step: 19-450 -- Loss: 0.19619324803352356
train-epoch-step: 19-451 -- Loss: 0.15218454599380493
train-epoch-step: 19-452 -- Loss: 0.14025671780109406
train-epoch-step: 19-453 -- Loss: 0.10052117705345154
train-epoch-step: 19-454 -- Loss: 0.244729146361351
train-epoch-step: 19-455 -- Loss: 0.13503234088420868
train-epoch-step: 19-456 -- Loss: 0.13105909526348114
train-epoch-step: 19-457 -- Loss: 0.22602605819702148
train-epoch-step: 19-458 -- Loss: 0.16204707324504852
train-epoch-step: 19-459 -- Loss: 0.23161762952804565
train-epoch-step: 19-460 -- Loss: 0.1323985606431961
train-epoch-step: 19-461 -- Loss: 0.1438034623861313
train-epoch-step: 19-462 -- Loss: 0.1811094582080841
train-epoch-step: 19-463 -- Loss: 0.1441625952720642
train-epoch-step: 19-464 -- Loss: 0.17284871637821198
train-epoch-step: 19-465 -- Loss: 0.2617473304271698
train-epoch-step: 19-466 -- Loss: 0.21491605043411255
train-epoch-step: 19-467 -- Loss: 0.12499277293682098
train-epoch-step: 19-468 -- Loss: 0.18413546681404114
train-epoch-step: 19-469 -- Loss: 0.2315405011177063
train-epoch-step: 19-470 -- Loss: 0.1864158809185028
train-epoch-step: 19-471 -- Loss: 0.16337555646896362
train-epoch-step: 19-472 -- Loss: 0.1664772778749466
train-epoch-step: 19-473 -- Loss: 0.17789797484874725
train-epoch-step: 19-474 -- Loss: 0.13054783642292023
train-epoch-step: 19-475 -- Loss: 0.12219075858592987
train-epoch-step: 19-476 -- Loss: 0.20806556940078735
train-epoch-step: 19-477 -- Loss: 0.22233588993549347
train-epoch-step: 19-478 -- Loss: 0.1996004730463028
train-epoch-step: 19-479 -- Loss: 0.1500622034072876
train-epoch-step: 19-480 -- Loss: 0.20277011394500732
train-epoch-step: 19-481 -- Loss: 0.2980872690677643
train-epoch-step: 19-482 -- Loss: 0.2707599997520447
train-epoch-step: 19-483 -- Loss: 0.19253385066986084
train-epoch-step: 19-484 -- Loss: 0.22759918868541718
train-epoch-step: 19-485 -- Loss: 0.1364700049161911
train-epoch-step: 19-486 -- Loss: 0.24739544093608856
train-epoch-step: 19-487 -- Loss: 0.2422340214252472
train-epoch-step: 19-488 -- Loss: 0.20168735086917877
train-epoch-step: 19-489 -- Loss: 0.22901514172554016
train-epoch-step: 19-490 -- Loss: 0.14770129323005676
train-epoch-step: 19-491 -- Loss: 0.14019550383090973
train-epoch-step: 19-492 -- Loss: 0.13423597812652588
train-epoch-step: 19-493 -- Loss: 0.22456525266170502
train-epoch-step: 19-494 -- Loss: 0.22102761268615723
train-epoch-step: 19-495 -- Loss: 0.21484990417957306
train-epoch-step: 19-496 -- Loss: 0.14594532549381256
train-epoch-step: 19-497 -- Loss: 0.19046664237976074
train-epoch-step: 19-498 -- Loss: 0.16016924381256104
train-epoch-step: 19-499 -- Loss: 0.17971062660217285
train-epoch-step: 19-500 -- Loss: 0.16535909473896027
train-epoch-step: 19-501 -- Loss: 0.22615474462509155
train-epoch-step: 19-502 -- Loss: 0.16640639305114746
train-epoch-step: 19-503 -- Loss: 0.23512843251228333
train-epoch-step: 19-504 -- Loss: 0.13343366980552673
train-epoch-step: 19-505 -- Loss: 0.18687698245048523
train-epoch-step: 19-506 -- Loss: 0.1255854070186615
train-epoch-step: 19-507 -- Loss: 0.19266223907470703
train-epoch-step: 19-508 -- Loss: 0.18467441201210022
train-epoch-step: 19-509 -- Loss: 0.17575114965438843
train-epoch-step: 19-510 -- Loss: 0.13132815062999725
train-epoch-step: 19-511 -- Loss: 0.22318418323993683
train-epoch-step: 19-512 -- Loss: 0.18874862790107727
train-epoch-step: 19-513 -- Loss: 0.22112414240837097
train-epoch-step: 19-514 -- Loss: 0.16626781225204468
train-epoch-step: 19-515 -- Loss: 0.1718624383211136
train-epoch-step: 19-516 -- Loss: 0.18590512871742249
train-epoch-step: 19-517 -- Loss: 0.18452337384223938
train-epoch-step: 19-518 -- Loss: 0.15033084154129028
train-epoch-step: 19-519 -- Loss: 0.14142856001853943
train-epoch-step: 19-520 -- Loss: 0.19520732760429382
train-epoch-step: 19-521 -- Loss: 0.24172964692115784
train-epoch-step: 19-522 -- Loss: 0.18613684177398682
train-epoch-step: 19-523 -- Loss: 0.16302643716335297
train-epoch-step: 19-524 -- Loss: 0.1796136498451233
train-epoch-step: 19-525 -- Loss: 0.2025001347064972
train-epoch-step: 19-526 -- Loss: 0.13548916578292847
train-epoch-step: 19-527 -- Loss: 0.16931696236133575
train-epoch-step: 19-528 -- Loss: 0.16442114114761353
train-epoch-step: 19-529 -- Loss: 0.1743779182434082
train-epoch-step: 19-530 -- Loss: 0.17423120141029358
train-epoch-step: 19-531 -- Loss: 0.21239811182022095
train-epoch-step: 19-532 -- Loss: 0.17979754507541656
train-epoch-step: 19-533 -- Loss: 0.18520396947860718
train-epoch-step: 19-534 -- Loss: 0.14999443292617798
train-epoch-step: 19-535 -- Loss: 0.2841094732284546
train-epoch-step: 19-536 -- Loss: 0.17249852418899536
train-epoch-step: 19-537 -- Loss: 0.15851932764053345
train-epoch-step: 19-538 -- Loss: 0.11162742972373962
train-epoch-step: 19-539 -- Loss: 0.21348837018013
train-epoch-step: 19-540 -- Loss: 0.1452712118625641
train-epoch-step: 19-541 -- Loss: 0.21901947259902954
train-epoch-step: 19-542 -- Loss: 0.23669034242630005
train-epoch-step: 19-543 -- Loss: 0.17729038000106812
train-epoch-step: 19-544 -- Loss: 0.2430974841117859
train-epoch-step: 19-545 -- Loss: 0.21235841512680054
train-epoch-step: 19-546 -- Loss: 0.23193547129631042
train-epoch-step: 19-547 -- Loss: 0.18789345026016235
train-epoch-step: 19-548 -- Loss: 0.10091941803693771
train-epoch-step: 19-549 -- Loss: 0.1576576828956604
train-epoch-step: 19-550 -- Loss: 0.20692943036556244
train-epoch-step: 19-551 -- Loss: 0.16810476779937744
train-epoch-step: 19-552 -- Loss: 0.14312508702278137
train-epoch-step: 19-553 -- Loss: 0.20084905624389648
train-epoch-step: 19-554 -- Loss: 0.20082876086235046
train-epoch-step: 19-555 -- Loss: 0.2316572219133377
train-epoch-step: 19-556 -- Loss: 0.16571184992790222
train-epoch-step: 19-557 -- Loss: 0.2594186067581177
train-epoch-step: 19-558 -- Loss: 0.23597590625286102
train-epoch-step: 19-559 -- Loss: 0.1590096652507782
train-epoch-step: 19-560 -- Loss: 0.2130238562822342
train-epoch-step: 19-561 -- Loss: 0.1961972862482071
train-epoch-step: 19-562 -- Loss: 0.18361128866672516
train-epoch-step: 19-563 -- Loss: 0.19818294048309326
train-epoch-step: 19-564 -- Loss: 0.10640417039394379
train-epoch-step: 19-565 -- Loss: 0.19403661787509918
train-epoch-step: 19-566 -- Loss: 0.17010179162025452
train-epoch-step: 19-567 -- Loss: 0.22397050261497498
train-epoch-step: 19-568 -- Loss: 0.1634451448917389
train-epoch-step: 19-569 -- Loss: 0.25423410534858704
train-epoch-step: 19-570 -- Loss: 0.1827022135257721
train-epoch-step: 19-571 -- Loss: 0.2262383997440338
train-epoch-step: 19-572 -- Loss: 0.25301945209503174
train-epoch-step: 19-573 -- Loss: 0.21997061371803284
train-epoch-step: 19-574 -- Loss: 0.274721622467041
train-epoch-step: 19-575 -- Loss: 0.3063190281391144
train-epoch-step: 19-576 -- Loss: 0.12699083983898163
train-epoch-step: 19-577 -- Loss: 0.17493441700935364
train-epoch-step: 19-578 -- Loss: 0.2412046194076538
train-epoch-step: 19-579 -- Loss: 0.1798837035894394
train-epoch-step: 19-580 -- Loss: 0.1897026002407074
train-epoch-step: 19-581 -- Loss: 0.1450643241405487
train-epoch-step: 19-582 -- Loss: 0.21393266320228577
train-epoch-step: 19-583 -- Loss: 0.235855370759964
train-epoch-step: 19-584 -- Loss: 0.1758304387331009
train-epoch-step: 19-585 -- Loss: 0.20036587119102478
train-epoch-step: 19-586 -- Loss: 0.27449721097946167
train-epoch-step: 19-587 -- Loss: 0.16735514998435974
train-epoch-step: 19-588 -- Loss: 0.13553497195243835
val-epoch-step: 19-589 -- Loss: 0.22025859355926514
val-epoch-step: 19-590 -- Loss: 0.15874838829040527
val-epoch-step: 19-591 -- Loss: 0.23258548974990845
val-epoch-step: 19-592 -- Loss: 0.18328088521957397
val-epoch-step: 19-593 -- Loss: 0.18386057019233704
val-epoch-step: 19-594 -- Loss: 0.35293546319007874
val-epoch-step: 19-595 -- Loss: 0.19094355404376984
val-epoch-step: 19-596 -- Loss: 0.2026647925376892
val-epoch-step: 19-597 -- Loss: 0.18619215488433838
val-epoch-step: 19-598 -- Loss: 0.1490251123905182
val-epoch-step: 19-599 -- Loss: 0.19002212584018707
val-epoch-step: 19-600 -- Loss: 0.1776498258113861
val-epoch-step: 19-601 -- Loss: 0.1715105026960373
val-epoch-step: 19-602 -- Loss: 0.14804166555404663
val-epoch-step: 19-603 -- Loss: 0.19821788370609283
val-epoch-step: 19-604 -- Loss: 0.1569189429283142
val-epoch-step: 19-605 -- Loss: 0.1556752324104309
val-epoch-step: 19-606 -- Loss: 0.28376415371894836
val-epoch-step: 19-607 -- Loss: 0.13039043545722961
val-epoch-step: 19-608 -- Loss: 0.26195165514945984
val-epoch-step: 19-609 -- Loss: 0.18221822381019592
val-epoch-step: 19-610 -- Loss: 0.1906205415725708
val-epoch-step: 19-611 -- Loss: 0.16166624426841736
val-epoch-step: 19-612 -- Loss: 0.4045489430427551
val-epoch-step: 19-613 -- Loss: 0.17990604043006897
val-epoch-step: 19-614 -- Loss: 0.16588935256004333
val-epoch-step: 19-615 -- Loss: 0.18968448042869568
val-epoch-step: 19-616 -- Loss: 0.16212376952171326
val-epoch-step: 19-617 -- Loss: 0.19475215673446655
val-epoch-step: 19-618 -- Loss: 0.20738409459590912
val-epoch-step: 19-619 -- Loss: 0.21478340029716492
val-epoch-step: 19-620 -- Loss: 0.1411420702934265
val-epoch-step: 19-621 -- Loss: 0.13165956735610962
val-epoch-step: 19-622 -- Loss: 0.15262547135353088
val-epoch-step: 19-623 -- Loss: 0.15852653980255127
val-epoch-step: 19-624 -- Loss: 0.1544230878353119
val-epoch-step: 19-625 -- Loss: 0.15999826788902283
val-epoch-step: 19-626 -- Loss: 0.1521310955286026
val-epoch-step: 19-627 -- Loss: 0.19758175313472748
val-epoch-step: 19-628 -- Loss: 0.5305485129356384
val-epoch-step: 19-629 -- Loss: 0.21198418736457825
val-epoch-step: 19-630 -- Loss: 0.36570391058921814
val-epoch-step: 19-631 -- Loss: 0.1570071578025818
val-epoch-step: 19-632 -- Loss: 0.2099808305501938
val-epoch-step: 19-633 -- Loss: 0.15737447142601013
val-epoch-step: 19-634 -- Loss: 0.15275242924690247
val-epoch-step: 19-635 -- Loss: 0.1282750517129898
val-epoch-step: 19-636 -- Loss: 0.1770201027393341
val-epoch-step: 19-637 -- Loss: 0.18919862806797028
val-epoch-step: 19-638 -- Loss: 0.1680719405412674
val-epoch-step: 19-639 -- Loss: 0.27212321758270264
val-epoch-step: 19-640 -- Loss: 0.2662484049797058
val-epoch-step: 19-641 -- Loss: 0.13608399033546448
val-epoch-step: 19-642 -- Loss: 0.1963149905204773
val-epoch-step: 19-643 -- Loss: 0.21223628520965576
val-epoch-step: 19-644 -- Loss: 0.1739518642425537
val-epoch-step: 19-645 -- Loss: 0.23168542981147766
val-epoch-step: 19-646 -- Loss: 0.14168578386306763
val-epoch-step: 19-647 -- Loss: 0.14406952261924744
val-epoch-step: 19-648 -- Loss: 0.17120671272277832
val-epoch-step: 19-649 -- Loss: 0.22095917165279388
val-epoch-step: 19-650 -- Loss: 0.26532548666000366
val-epoch-step: 19-651 -- Loss: 0.1552455872297287
val-epoch-step: 19-652 -- Loss: 0.16696599125862122
val-epoch-step: 19-653 -- Loss: 0.21445313096046448
val-epoch-step: 19-654 -- Loss: 0.11897026002407074
Epoch: 19 -- Train Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 20-0 -- Loss: 0.23920661211013794
train-epoch-step: 20-1 -- Loss: 0.14865128695964813
train-epoch-step: 20-2 -- Loss: 0.20519623160362244
train-epoch-step: 20-3 -- Loss: 0.15119709074497223
train-epoch-step: 20-4 -- Loss: 0.1682506948709488
train-epoch-step: 20-5 -- Loss: 0.19837257266044617
train-epoch-step: 20-6 -- Loss: 0.23585358262062073
train-epoch-step: 20-7 -- Loss: 0.17861540615558624
train-epoch-step: 20-8 -- Loss: 0.19889895617961884
train-epoch-step: 20-9 -- Loss: 0.2536798119544983
train-epoch-step: 20-10 -- Loss: 0.23579877614974976
train-epoch-step: 20-11 -- Loss: 0.1904357373714447
train-epoch-step: 20-12 -- Loss: 0.15929806232452393
train-epoch-step: 20-13 -- Loss: 0.20659737288951874
train-epoch-step: 20-14 -- Loss: 0.17607776820659637
train-epoch-step: 20-15 -- Loss: 0.18145200610160828
train-epoch-step: 20-16 -- Loss: 0.1696268767118454
train-epoch-step: 20-17 -- Loss: 0.23395419120788574
train-epoch-step: 20-18 -- Loss: 0.21664965152740479
train-epoch-step: 20-19 -- Loss: 0.13962596654891968
train-epoch-step: 20-20 -- Loss: 0.2409384846687317
train-epoch-step: 20-21 -- Loss: 0.2717015743255615
train-epoch-step: 20-22 -- Loss: 0.14735393226146698
train-epoch-step: 20-23 -- Loss: 0.15828463435173035
train-epoch-step: 20-24 -- Loss: 0.13410727679729462
train-epoch-step: 20-25 -- Loss: 0.22776272892951965
train-epoch-step: 20-26 -- Loss: 0.20194695889949799
train-epoch-step: 20-27 -- Loss: 0.24507403373718262
train-epoch-step: 20-28 -- Loss: 0.12831397354602814
train-epoch-step: 20-29 -- Loss: 0.26261502504348755
train-epoch-step: 20-30 -- Loss: 0.11678013950586319
train-epoch-step: 20-31 -- Loss: 0.15679237246513367
train-epoch-step: 20-32 -- Loss: 0.17749303579330444
train-epoch-step: 20-33 -- Loss: 0.2920810282230377
train-epoch-step: 20-34 -- Loss: 0.18096639215946198
train-epoch-step: 20-35 -- Loss: 0.2519433796405792
train-epoch-step: 20-36 -- Loss: 0.1443604826927185
train-epoch-step: 20-37 -- Loss: 0.14981167018413544
train-epoch-step: 20-38 -- Loss: 0.19243483245372772
train-epoch-step: 20-39 -- Loss: 0.23354506492614746
train-epoch-step: 20-40 -- Loss: 0.22167626023292542
train-epoch-step: 20-41 -- Loss: 0.22707441449165344
train-epoch-step: 20-42 -- Loss: 0.15438812971115112
train-epoch-step: 20-43 -- Loss: 0.28341910243034363
train-epoch-step: 20-44 -- Loss: 0.1346346139907837
train-epoch-step: 20-45 -- Loss: 0.13250398635864258
train-epoch-step: 20-46 -- Loss: 0.18573084473609924
train-epoch-step: 20-47 -- Loss: 0.2358151376247406
train-epoch-step: 20-48 -- Loss: 0.16238297522068024
train-epoch-step: 20-49 -- Loss: 0.23663663864135742
train-epoch-step: 20-50 -- Loss: 0.11643228679895401
train-epoch-step: 20-51 -- Loss: 0.19799263775348663
train-epoch-step: 20-52 -- Loss: 0.1640661060810089
train-epoch-step: 20-53 -- Loss: 0.21579736471176147
train-epoch-step: 20-54 -- Loss: 0.2954511046409607
train-epoch-step: 20-55 -- Loss: 0.1854940503835678
train-epoch-step: 20-56 -- Loss: 0.240043044090271
train-epoch-step: 20-57 -- Loss: 0.2475431114435196
train-epoch-step: 20-58 -- Loss: 0.29742661118507385
train-epoch-step: 20-59 -- Loss: 0.2671390175819397
train-epoch-step: 20-60 -- Loss: 0.14062029123306274
train-epoch-step: 20-61 -- Loss: 0.21276339888572693
train-epoch-step: 20-62 -- Loss: 0.1978132575750351
train-epoch-step: 20-63 -- Loss: 0.1447800099849701
train-epoch-step: 20-64 -- Loss: 0.16728997230529785
train-epoch-step: 20-65 -- Loss: 0.197307288646698
train-epoch-step: 20-66 -- Loss: 0.11668413132429123
train-epoch-step: 20-67 -- Loss: 0.1365317851305008
train-epoch-step: 20-68 -- Loss: 0.2348759025335312
train-epoch-step: 20-69 -- Loss: 0.12891918420791626
train-epoch-step: 20-70 -- Loss: 0.23199838399887085
train-epoch-step: 20-71 -- Loss: 0.2720206379890442
train-epoch-step: 20-72 -- Loss: 0.18953388929367065
train-epoch-step: 20-73 -- Loss: 0.2201695293188095
train-epoch-step: 20-74 -- Loss: 0.10810110718011856
train-epoch-step: 20-75 -- Loss: 0.13639414310455322
train-epoch-step: 20-76 -- Loss: 0.15369735658168793
train-epoch-step: 20-77 -- Loss: 0.24617967009544373
train-epoch-step: 20-78 -- Loss: 0.27758458256721497
train-epoch-step: 20-79 -- Loss: 0.20356762409210205
train-epoch-step: 20-80 -- Loss: 0.29690486192703247
train-epoch-step: 20-81 -- Loss: 0.13870951533317566
train-epoch-step: 20-82 -- Loss: 0.2810094952583313
train-epoch-step: 20-83 -- Loss: 0.2167426496744156
train-epoch-step: 20-84 -- Loss: 0.21698185801506042
train-epoch-step: 20-85 -- Loss: 0.1928454041481018
train-epoch-step: 20-86 -- Loss: 0.13190878927707672
train-epoch-step: 20-87 -- Loss: 0.2448018193244934
train-epoch-step: 20-88 -- Loss: 0.15293599665164948
train-epoch-step: 20-89 -- Loss: 0.20481906831264496
train-epoch-step: 20-90 -- Loss: 0.20644348859786987
train-epoch-step: 20-91 -- Loss: 0.2654437720775604
train-epoch-step: 20-92 -- Loss: 0.16822406649589539
train-epoch-step: 20-93 -- Loss: 0.18742409348487854
train-epoch-step: 20-94 -- Loss: 0.22865116596221924
train-epoch-step: 20-95 -- Loss: 0.21497291326522827
train-epoch-step: 20-96 -- Loss: 0.2301570028066635
train-epoch-step: 20-97 -- Loss: 0.18997947871685028
train-epoch-step: 20-98 -- Loss: 0.16210371255874634
train-epoch-step: 20-99 -- Loss: 0.19620735943317413
train-epoch-step: 20-100 -- Loss: 0.20479023456573486
train-epoch-step: 20-101 -- Loss: 0.2973981499671936
train-epoch-step: 20-102 -- Loss: 0.24156439304351807
train-epoch-step: 20-103 -- Loss: 0.1934908777475357
train-epoch-step: 20-104 -- Loss: 0.1573953777551651
train-epoch-step: 20-105 -- Loss: 0.3125985264778137
train-epoch-step: 20-106 -- Loss: 0.18303370475769043
train-epoch-step: 20-107 -- Loss: 0.19856752455234528
train-epoch-step: 20-108 -- Loss: 0.2001529484987259
train-epoch-step: 20-109 -- Loss: 0.15828581154346466
train-epoch-step: 20-110 -- Loss: 0.21230508387088776
train-epoch-step: 20-111 -- Loss: 0.18981805443763733
train-epoch-step: 20-112 -- Loss: 0.18007278442382812
train-epoch-step: 20-113 -- Loss: 0.17275460064411163
train-epoch-step: 20-114 -- Loss: 0.20714768767356873
train-epoch-step: 20-115 -- Loss: 0.1759924292564392
train-epoch-step: 20-116 -- Loss: 0.1543973833322525
train-epoch-step: 20-117 -- Loss: 0.13619829714298248
train-epoch-step: 20-118 -- Loss: 0.2163308560848236
train-epoch-step: 20-119 -- Loss: 0.16401232779026031
train-epoch-step: 20-120 -- Loss: 0.26425740122795105
train-epoch-step: 20-121 -- Loss: 0.25930097699165344
train-epoch-step: 20-122 -- Loss: 0.23696351051330566
train-epoch-step: 20-123 -- Loss: 0.21567752957344055
train-epoch-step: 20-124 -- Loss: 0.1291932761669159
train-epoch-step: 20-125 -- Loss: 0.16052107512950897
train-epoch-step: 20-126 -- Loss: 0.2455960214138031
train-epoch-step: 20-127 -- Loss: 0.19303947687149048
train-epoch-step: 20-128 -- Loss: 0.19334131479263306
train-epoch-step: 20-129 -- Loss: 0.15509387850761414
train-epoch-step: 20-130 -- Loss: 0.21274735033512115
train-epoch-step: 20-131 -- Loss: 0.14454422891139984
train-epoch-step: 20-132 -- Loss: 0.20125120878219604
train-epoch-step: 20-133 -- Loss: 0.12458518147468567
train-epoch-step: 20-134 -- Loss: 0.23152366280555725
train-epoch-step: 20-135 -- Loss: 0.15174652636051178
train-epoch-step: 20-136 -- Loss: 0.13980987668037415
train-epoch-step: 20-137 -- Loss: 0.27143460512161255
train-epoch-step: 20-138 -- Loss: 0.274410605430603
train-epoch-step: 20-139 -- Loss: 0.14663776755332947
train-epoch-step: 20-140 -- Loss: 0.229690819978714
train-epoch-step: 20-141 -- Loss: 0.25191500782966614
train-epoch-step: 20-142 -- Loss: 0.20834246277809143
train-epoch-step: 20-143 -- Loss: 0.18751287460327148
train-epoch-step: 20-144 -- Loss: 0.20415249466896057
train-epoch-step: 20-145 -- Loss: 0.1513531506061554
train-epoch-step: 20-146 -- Loss: 0.19999746978282928
train-epoch-step: 20-147 -- Loss: 0.18519437313079834
train-epoch-step: 20-148 -- Loss: 0.17241674661636353
train-epoch-step: 20-149 -- Loss: 0.12977521121501923
train-epoch-step: 20-150 -- Loss: 0.19501565396785736
train-epoch-step: 20-151 -- Loss: 0.1946728527545929
train-epoch-step: 20-152 -- Loss: 0.2000991702079773
train-epoch-step: 20-153 -- Loss: 0.27909040451049805
train-epoch-step: 20-154 -- Loss: 0.13880722224712372
train-epoch-step: 20-155 -- Loss: 0.14260238409042358
train-epoch-step: 20-156 -- Loss: 0.13441646099090576
train-epoch-step: 20-157 -- Loss: 0.17884095013141632
train-epoch-step: 20-158 -- Loss: 0.17779091000556946
train-epoch-step: 20-159 -- Loss: 0.18911221623420715
train-epoch-step: 20-160 -- Loss: 0.24045729637145996
train-epoch-step: 20-161 -- Loss: 0.21801763772964478
train-epoch-step: 20-162 -- Loss: 0.22147442400455475
train-epoch-step: 20-163 -- Loss: 0.19470930099487305
train-epoch-step: 20-164 -- Loss: 0.20293408632278442
train-epoch-step: 20-165 -- Loss: 0.1757054626941681
train-epoch-step: 20-166 -- Loss: 0.13819673657417297
train-epoch-step: 20-167 -- Loss: 0.13328275084495544
train-epoch-step: 20-168 -- Loss: 0.21403200924396515
train-epoch-step: 20-169 -- Loss: 0.15092235803604126
train-epoch-step: 20-170 -- Loss: 0.20991170406341553
train-epoch-step: 20-171 -- Loss: 0.1559222787618637
train-epoch-step: 20-172 -- Loss: 0.2745901942253113
train-epoch-step: 20-173 -- Loss: 0.14301489293575287
train-epoch-step: 20-174 -- Loss: 0.25951606035232544
train-epoch-step: 20-175 -- Loss: 0.19456543028354645
train-epoch-step: 20-176 -- Loss: 0.14480352401733398
train-epoch-step: 20-177 -- Loss: 0.19805245101451874
train-epoch-step: 20-178 -- Loss: 0.19314447045326233
train-epoch-step: 20-179 -- Loss: 0.15631163120269775
train-epoch-step: 20-180 -- Loss: 0.1586657166481018
train-epoch-step: 20-181 -- Loss: 0.18938203155994415
train-epoch-step: 20-182 -- Loss: 0.1998787820339203
train-epoch-step: 20-183 -- Loss: 0.2982931435108185
train-epoch-step: 20-184 -- Loss: 0.14727044105529785
train-epoch-step: 20-185 -- Loss: 0.15646156668663025
train-epoch-step: 20-186 -- Loss: 0.20634976029396057
train-epoch-step: 20-187 -- Loss: 0.21946460008621216
train-epoch-step: 20-188 -- Loss: 0.1814669817686081
train-epoch-step: 20-189 -- Loss: 0.11511046439409256
train-epoch-step: 20-190 -- Loss: 0.19191564619541168
train-epoch-step: 20-191 -- Loss: 0.17948618531227112
train-epoch-step: 20-192 -- Loss: 0.24793267250061035
train-epoch-step: 20-193 -- Loss: 0.23486140370368958
train-epoch-step: 20-194 -- Loss: 0.19040712714195251
train-epoch-step: 20-195 -- Loss: 0.17983199656009674
train-epoch-step: 20-196 -- Loss: 0.18243545293807983
train-epoch-step: 20-197 -- Loss: 0.14676883816719055
train-epoch-step: 20-198 -- Loss: 0.1365196406841278
train-epoch-step: 20-199 -- Loss: 0.16326723992824554
train-epoch-step: 20-200 -- Loss: 0.1326279640197754
train-epoch-step: 20-201 -- Loss: 0.2088121920824051
train-epoch-step: 20-202 -- Loss: 0.13811075687408447
train-epoch-step: 20-203 -- Loss: 0.18372683227062225
train-epoch-step: 20-204 -- Loss: 0.15022626519203186
train-epoch-step: 20-205 -- Loss: 0.19768592715263367
train-epoch-step: 20-206 -- Loss: 0.21209484338760376
train-epoch-step: 20-207 -- Loss: 0.15001019835472107
train-epoch-step: 20-208 -- Loss: 0.19085001945495605
train-epoch-step: 20-209 -- Loss: 0.14637279510498047
train-epoch-step: 20-210 -- Loss: 0.139192134141922
train-epoch-step: 20-211 -- Loss: 0.21680204570293427
train-epoch-step: 20-212 -- Loss: 0.2124689221382141
train-epoch-step: 20-213 -- Loss: 0.1426500678062439
train-epoch-step: 20-214 -- Loss: 0.1545199304819107
train-epoch-step: 20-215 -- Loss: 0.13434067368507385
train-epoch-step: 20-216 -- Loss: 0.2141624093055725
train-epoch-step: 20-217 -- Loss: 0.2240706831216812
train-epoch-step: 20-218 -- Loss: 0.16243481636047363
train-epoch-step: 20-219 -- Loss: 0.19990593194961548
train-epoch-step: 20-220 -- Loss: 0.14010468125343323
train-epoch-step: 20-221 -- Loss: 0.21286329627037048
train-epoch-step: 20-222 -- Loss: 0.12445808202028275
train-epoch-step: 20-223 -- Loss: 0.18430458009243011
train-epoch-step: 20-224 -- Loss: 0.2091766595840454
train-epoch-step: 20-225 -- Loss: 0.28444382548332214
train-epoch-step: 20-226 -- Loss: 0.21934790909290314
train-epoch-step: 20-227 -- Loss: 0.2456100583076477
train-epoch-step: 20-228 -- Loss: 0.18818619847297668
train-epoch-step: 20-229 -- Loss: 0.19120365381240845
train-epoch-step: 20-230 -- Loss: 0.1681145429611206
train-epoch-step: 20-231 -- Loss: 0.1712823510169983
train-epoch-step: 20-232 -- Loss: 0.21286845207214355
train-epoch-step: 20-233 -- Loss: 0.09242871403694153
train-epoch-step: 20-234 -- Loss: 0.1966463029384613
train-epoch-step: 20-235 -- Loss: 0.15540257096290588
train-epoch-step: 20-236 -- Loss: 0.18579396605491638
train-epoch-step: 20-237 -- Loss: 0.2553709149360657
train-epoch-step: 20-238 -- Loss: 0.16726253926753998
train-epoch-step: 20-239 -- Loss: 0.13740254938602448
train-epoch-step: 20-240 -- Loss: 0.23015126585960388
train-epoch-step: 20-241 -- Loss: 0.1655547022819519
train-epoch-step: 20-242 -- Loss: 0.22650383412837982
train-epoch-step: 20-243 -- Loss: 0.2419801950454712
train-epoch-step: 20-244 -- Loss: 0.22139039635658264
train-epoch-step: 20-245 -- Loss: 0.2148767113685608
train-epoch-step: 20-246 -- Loss: 0.2352980077266693
train-epoch-step: 20-247 -- Loss: 0.24556952714920044
train-epoch-step: 20-248 -- Loss: 0.19641518592834473
train-epoch-step: 20-249 -- Loss: 0.15261855721473694
train-epoch-step: 20-250 -- Loss: 0.21096809208393097
train-epoch-step: 20-251 -- Loss: 0.11340615153312683
train-epoch-step: 20-252 -- Loss: 0.20834504067897797
train-epoch-step: 20-253 -- Loss: 0.149021178483963
train-epoch-step: 20-254 -- Loss: 0.230887308716774
train-epoch-step: 20-255 -- Loss: 0.15308038890361786
train-epoch-step: 20-256 -- Loss: 0.17170587182044983
train-epoch-step: 20-257 -- Loss: 0.19912394881248474
train-epoch-step: 20-258 -- Loss: 0.15217885375022888
train-epoch-step: 20-259 -- Loss: 0.1388811469078064
train-epoch-step: 20-260 -- Loss: 0.21915051341056824
train-epoch-step: 20-261 -- Loss: 0.19139543175697327
train-epoch-step: 20-262 -- Loss: 0.32071465253829956
train-epoch-step: 20-263 -- Loss: 0.21692198514938354
train-epoch-step: 20-264 -- Loss: 0.1781480312347412
train-epoch-step: 20-265 -- Loss: 0.13224318623542786
train-epoch-step: 20-266 -- Loss: 0.15996260941028595
train-epoch-step: 20-267 -- Loss: 0.14578835666179657
train-epoch-step: 20-268 -- Loss: 0.1298845112323761
train-epoch-step: 20-269 -- Loss: 0.1795383095741272
train-epoch-step: 20-270 -- Loss: 0.11505764722824097
train-epoch-step: 20-271 -- Loss: 0.15734931826591492
train-epoch-step: 20-272 -- Loss: 0.12118297070264816
train-epoch-step: 20-273 -- Loss: 0.1333974301815033
train-epoch-step: 20-274 -- Loss: 0.19843576848506927
train-epoch-step: 20-275 -- Loss: 0.2149922251701355
train-epoch-step: 20-276 -- Loss: 0.16858066618442535
train-epoch-step: 20-277 -- Loss: 0.16527612507343292
train-epoch-step: 20-278 -- Loss: 0.15826183557510376
train-epoch-step: 20-279 -- Loss: 0.16333943605422974
train-epoch-step: 20-280 -- Loss: 0.2335149049758911
train-epoch-step: 20-281 -- Loss: 0.20173108577728271
train-epoch-step: 20-282 -- Loss: 0.14878210425376892
train-epoch-step: 20-283 -- Loss: 0.12612932920455933
train-epoch-step: 20-284 -- Loss: 0.16151241958141327
train-epoch-step: 20-285 -- Loss: 0.2007848173379898
train-epoch-step: 20-286 -- Loss: 0.1671108901500702
train-epoch-step: 20-287 -- Loss: 0.2286408394575119
train-epoch-step: 20-288 -- Loss: 0.09815439581871033
train-epoch-step: 20-289 -- Loss: 0.1290661096572876
train-epoch-step: 20-290 -- Loss: 0.19653519988059998
train-epoch-step: 20-291 -- Loss: 0.12404969334602356
train-epoch-step: 20-292 -- Loss: 0.16138827800750732
train-epoch-step: 20-293 -- Loss: 0.15084168314933777
train-epoch-step: 20-294 -- Loss: 0.1832742691040039
train-epoch-step: 20-295 -- Loss: 0.28990060091018677
train-epoch-step: 20-296 -- Loss: 0.17097832262516022
train-epoch-step: 20-297 -- Loss: 0.18467164039611816
train-epoch-step: 20-298 -- Loss: 0.25504109263420105
train-epoch-step: 20-299 -- Loss: 0.15329411625862122
train-epoch-step: 20-300 -- Loss: 0.19003085792064667
train-epoch-step: 20-301 -- Loss: 0.18941250443458557
train-epoch-step: 20-302 -- Loss: 0.23903876543045044
train-epoch-step: 20-303 -- Loss: 0.22461523115634918
train-epoch-step: 20-304 -- Loss: 0.1364567130804062
train-epoch-step: 20-305 -- Loss: 0.1611013114452362
train-epoch-step: 20-306 -- Loss: 0.2659338712692261
train-epoch-step: 20-307 -- Loss: 0.17571480572223663
train-epoch-step: 20-308 -- Loss: 0.2440640926361084
train-epoch-step: 20-309 -- Loss: 0.17194242775440216
train-epoch-step: 20-310 -- Loss: 0.17723903059959412
train-epoch-step: 20-311 -- Loss: 0.17364469170570374
train-epoch-step: 20-312 -- Loss: 0.2248591184616089
train-epoch-step: 20-313 -- Loss: 0.11276432871818542
train-epoch-step: 20-314 -- Loss: 0.21417886018753052
train-epoch-step: 20-315 -- Loss: 0.1794370859861374
train-epoch-step: 20-316 -- Loss: 0.15834400057792664
train-epoch-step: 20-317 -- Loss: 0.1536591351032257
train-epoch-step: 20-318 -- Loss: 0.1734435260295868
train-epoch-step: 20-319 -- Loss: 0.18834234774112701
train-epoch-step: 20-320 -- Loss: 0.12563782930374146
train-epoch-step: 20-321 -- Loss: 0.14520035684108734
train-epoch-step: 20-322 -- Loss: 0.2202139049768448
train-epoch-step: 20-323 -- Loss: 0.16436345875263214
train-epoch-step: 20-324 -- Loss: 0.26722562313079834
train-epoch-step: 20-325 -- Loss: 0.1664394736289978
train-epoch-step: 20-326 -- Loss: 0.18346165120601654
train-epoch-step: 20-327 -- Loss: 0.22297342121601105
train-epoch-step: 20-328 -- Loss: 0.20213793218135834
train-epoch-step: 20-329 -- Loss: 0.34371206164360046
train-epoch-step: 20-330 -- Loss: 0.3803001046180725
train-epoch-step: 20-331 -- Loss: 0.2178538590669632
train-epoch-step: 20-332 -- Loss: 0.10769686102867126
train-epoch-step: 20-333 -- Loss: 0.19866278767585754
train-epoch-step: 20-334 -- Loss: 0.16298289597034454
train-epoch-step: 20-335 -- Loss: 0.18441015481948853
train-epoch-step: 20-336 -- Loss: 0.16292895376682281
train-epoch-step: 20-337 -- Loss: 0.2313651740550995
train-epoch-step: 20-338 -- Loss: 0.16936270892620087
train-epoch-step: 20-339 -- Loss: 0.15460802614688873
train-epoch-step: 20-340 -- Loss: 0.21165041625499725
train-epoch-step: 20-341 -- Loss: 0.14854668080806732
train-epoch-step: 20-342 -- Loss: 0.1741238385438919
train-epoch-step: 20-343 -- Loss: 0.1616796851158142
train-epoch-step: 20-344 -- Loss: 0.18598110973834991
train-epoch-step: 20-345 -- Loss: 0.139407679438591
train-epoch-step: 20-346 -- Loss: 0.2195051610469818
train-epoch-step: 20-347 -- Loss: 0.15764403343200684
train-epoch-step: 20-348 -- Loss: 0.22242328524589539
train-epoch-step: 20-349 -- Loss: 0.21943049132823944
train-epoch-step: 20-350 -- Loss: 0.2786145806312561
train-epoch-step: 20-351 -- Loss: 0.204083651304245
train-epoch-step: 20-352 -- Loss: 0.13320747017860413
train-epoch-step: 20-353 -- Loss: 0.20116853713989258
train-epoch-step: 20-354 -- Loss: 0.2950712740421295
train-epoch-step: 20-355 -- Loss: 0.1252884715795517
train-epoch-step: 20-356 -- Loss: 0.12255897372961044
train-epoch-step: 20-357 -- Loss: 0.20244833827018738
train-epoch-step: 20-358 -- Loss: 0.19252781569957733
train-epoch-step: 20-359 -- Loss: 0.14879867434501648
train-epoch-step: 20-360 -- Loss: 0.13051417469978333
train-epoch-step: 20-361 -- Loss: 0.24975605309009552
train-epoch-step: 20-362 -- Loss: 0.17894986271858215
train-epoch-step: 20-363 -- Loss: 0.12010277807712555
train-epoch-step: 20-364 -- Loss: 0.19177193939685822
train-epoch-step: 20-365 -- Loss: 0.18587392568588257
train-epoch-step: 20-366 -- Loss: 0.22085684537887573
train-epoch-step: 20-367 -- Loss: 0.2440076470375061
train-epoch-step: 20-368 -- Loss: 0.21264204382896423
train-epoch-step: 20-369 -- Loss: 0.2947971820831299
train-epoch-step: 20-370 -- Loss: 0.1355009824037552
train-epoch-step: 20-371 -- Loss: 0.12811094522476196
train-epoch-step: 20-372 -- Loss: 0.15334676206111908
train-epoch-step: 20-373 -- Loss: 0.19678083062171936
train-epoch-step: 20-374 -- Loss: 0.16236713528633118
train-epoch-step: 20-375 -- Loss: 0.27954086661338806
train-epoch-step: 20-376 -- Loss: 0.1788017451763153
train-epoch-step: 20-377 -- Loss: 0.26506543159484863
train-epoch-step: 20-378 -- Loss: 0.21450167894363403
train-epoch-step: 20-379 -- Loss: 0.12573522329330444
train-epoch-step: 20-380 -- Loss: 0.0948953628540039
train-epoch-step: 20-381 -- Loss: 0.2601816654205322
train-epoch-step: 20-382 -- Loss: 0.25241518020629883
train-epoch-step: 20-383 -- Loss: 0.18496879935264587
train-epoch-step: 20-384 -- Loss: 0.2526434361934662
train-epoch-step: 20-385 -- Loss: 0.21581873297691345
train-epoch-step: 20-386 -- Loss: 0.2041313648223877
train-epoch-step: 20-387 -- Loss: 0.21694256365299225
train-epoch-step: 20-388 -- Loss: 0.21535810828208923
train-epoch-step: 20-389 -- Loss: 0.18704853951931
train-epoch-step: 20-390 -- Loss: 0.15551482141017914
train-epoch-step: 20-391 -- Loss: 0.15702639520168304
train-epoch-step: 20-392 -- Loss: 0.19047781825065613
train-epoch-step: 20-393 -- Loss: 0.1718875616788864
train-epoch-step: 20-394 -- Loss: 0.22691267728805542
train-epoch-step: 20-395 -- Loss: 0.17000111937522888
train-epoch-step: 20-396 -- Loss: 0.13090212643146515
train-epoch-step: 20-397 -- Loss: 0.13698317110538483
train-epoch-step: 20-398 -- Loss: 0.21334493160247803
train-epoch-step: 20-399 -- Loss: 0.18571774661540985
train-epoch-step: 20-400 -- Loss: 0.30461567640304565
train-epoch-step: 20-401 -- Loss: 0.1292048692703247
train-epoch-step: 20-402 -- Loss: 0.2712576687335968
train-epoch-step: 20-403 -- Loss: 0.1740952581167221
train-epoch-step: 20-404 -- Loss: 0.1450778692960739
train-epoch-step: 20-405 -- Loss: 0.14886465668678284
train-epoch-step: 20-406 -- Loss: 0.17775723338127136
train-epoch-step: 20-407 -- Loss: 0.12552224099636078
train-epoch-step: 20-408 -- Loss: 0.17238003015518188
train-epoch-step: 20-409 -- Loss: 0.1771237999200821
train-epoch-step: 20-410 -- Loss: 0.19006341695785522
train-epoch-step: 20-411 -- Loss: 0.22271126508712769
train-epoch-step: 20-412 -- Loss: 0.14056453108787537
train-epoch-step: 20-413 -- Loss: 0.15445850789546967
train-epoch-step: 20-414 -- Loss: 0.14900371432304382
train-epoch-step: 20-415 -- Loss: 0.14036907255649567
train-epoch-step: 20-416 -- Loss: 0.27442288398742676
train-epoch-step: 20-417 -- Loss: 0.20373976230621338
train-epoch-step: 20-418 -- Loss: 0.257487416267395
train-epoch-step: 20-419 -- Loss: 0.1736210137605667
train-epoch-step: 20-420 -- Loss: 0.16358575224876404
train-epoch-step: 20-421 -- Loss: 0.19617001712322235
train-epoch-step: 20-422 -- Loss: 0.1566627025604248
train-epoch-step: 20-423 -- Loss: 0.19007474184036255
train-epoch-step: 20-424 -- Loss: 0.14437194168567657
train-epoch-step: 20-425 -- Loss: 0.195381298661232
train-epoch-step: 20-426 -- Loss: 0.16986782848834991
train-epoch-step: 20-427 -- Loss: 0.13441650569438934
train-epoch-step: 20-428 -- Loss: 0.21023127436637878
train-epoch-step: 20-429 -- Loss: 0.18173667788505554
train-epoch-step: 20-430 -- Loss: 0.15037411451339722
train-epoch-step: 20-431 -- Loss: 0.17575936019420624
train-epoch-step: 20-432 -- Loss: 0.25507453083992004
train-epoch-step: 20-433 -- Loss: 0.14317335188388824
train-epoch-step: 20-434 -- Loss: 0.13426406681537628
train-epoch-step: 20-435 -- Loss: 0.16274218261241913
train-epoch-step: 20-436 -- Loss: 0.16588422656059265
train-epoch-step: 20-437 -- Loss: 0.13952642679214478
train-epoch-step: 20-438 -- Loss: 0.17916129529476166
train-epoch-step: 20-439 -- Loss: 0.27582836151123047
train-epoch-step: 20-440 -- Loss: 0.1392139345407486
train-epoch-step: 20-441 -- Loss: 0.21960589289665222
train-epoch-step: 20-442 -- Loss: 0.19477906823158264
train-epoch-step: 20-443 -- Loss: 0.16310381889343262
train-epoch-step: 20-444 -- Loss: 0.23954129219055176
train-epoch-step: 20-445 -- Loss: 0.18645069003105164
train-epoch-step: 20-446 -- Loss: 0.16262464225292206
train-epoch-step: 20-447 -- Loss: 0.20388895273208618
train-epoch-step: 20-448 -- Loss: 0.24586515128612518
train-epoch-step: 20-449 -- Loss: 0.201649472117424
train-epoch-step: 20-450 -- Loss: 0.2064744234085083
train-epoch-step: 20-451 -- Loss: 0.1877279281616211
train-epoch-step: 20-452 -- Loss: 0.1405559927225113
train-epoch-step: 20-453 -- Loss: 0.10525000095367432
train-epoch-step: 20-454 -- Loss: 0.24631938338279724
train-epoch-step: 20-455 -- Loss: 0.13364660739898682
train-epoch-step: 20-456 -- Loss: 0.13000857830047607
train-epoch-step: 20-457 -- Loss: 0.24470166862010956
train-epoch-step: 20-458 -- Loss: 0.17262229323387146
train-epoch-step: 20-459 -- Loss: 0.3086055517196655
train-epoch-step: 20-460 -- Loss: 0.1365271806716919
train-epoch-step: 20-461 -- Loss: 0.1450752168893814
train-epoch-step: 20-462 -- Loss: 0.16922084987163544
train-epoch-step: 20-463 -- Loss: 0.15308763086795807
train-epoch-step: 20-464 -- Loss: 0.18667759001255035
train-epoch-step: 20-465 -- Loss: 0.36575353145599365
train-epoch-step: 20-466 -- Loss: 0.22028318047523499
train-epoch-step: 20-467 -- Loss: 0.12200114130973816
train-epoch-step: 20-468 -- Loss: 0.22307956218719482
train-epoch-step: 20-469 -- Loss: 0.2782103419303894
train-epoch-step: 20-470 -- Loss: 0.20807164907455444
train-epoch-step: 20-471 -- Loss: 0.17817531526088715
train-epoch-step: 20-472 -- Loss: 0.17118576169013977
train-epoch-step: 20-473 -- Loss: 0.17532606422901154
train-epoch-step: 20-474 -- Loss: 0.13631628453731537
train-epoch-step: 20-475 -- Loss: 0.12510693073272705
train-epoch-step: 20-476 -- Loss: 0.22202792763710022
train-epoch-step: 20-477 -- Loss: 0.22433878481388092
train-epoch-step: 20-478 -- Loss: 0.22358299791812897
train-epoch-step: 20-479 -- Loss: 0.1589309275150299
train-epoch-step: 20-480 -- Loss: 0.22369156777858734
train-epoch-step: 20-481 -- Loss: 0.31064626574516296
train-epoch-step: 20-482 -- Loss: 0.2913492023944855
train-epoch-step: 20-483 -- Loss: 0.1943468600511551
train-epoch-step: 20-484 -- Loss: 0.231403648853302
train-epoch-step: 20-485 -- Loss: 0.1502344012260437
train-epoch-step: 20-486 -- Loss: 0.26052817702293396
train-epoch-step: 20-487 -- Loss: 0.24360057711601257
train-epoch-step: 20-488 -- Loss: 0.21987515687942505
train-epoch-step: 20-489 -- Loss: 0.22960029542446136
train-epoch-step: 20-490 -- Loss: 0.14713478088378906
train-epoch-step: 20-491 -- Loss: 0.15033447742462158
train-epoch-step: 20-492 -- Loss: 0.14027240872383118
train-epoch-step: 20-493 -- Loss: 0.21937040984630585
train-epoch-step: 20-494 -- Loss: 0.2184809148311615
train-epoch-step: 20-495 -- Loss: 0.22954383492469788
train-epoch-step: 20-496 -- Loss: 0.14042744040489197
train-epoch-step: 20-497 -- Loss: 0.20594030618667603
train-epoch-step: 20-498 -- Loss: 0.16058193147182465
train-epoch-step: 20-499 -- Loss: 0.18609625101089478
train-epoch-step: 20-500 -- Loss: 0.16425976157188416
train-epoch-step: 20-501 -- Loss: 0.24987024068832397
train-epoch-step: 20-502 -- Loss: 0.24042895436286926
train-epoch-step: 20-503 -- Loss: 0.24471399188041687
train-epoch-step: 20-504 -- Loss: 0.13043737411499023
train-epoch-step: 20-505 -- Loss: 0.18303225934505463
train-epoch-step: 20-506 -- Loss: 0.12742021679878235
train-epoch-step: 20-507 -- Loss: 0.20645159482955933
train-epoch-step: 20-508 -- Loss: 0.1882171630859375
train-epoch-step: 20-509 -- Loss: 0.1856190264225006
train-epoch-step: 20-510 -- Loss: 0.13611586391925812
train-epoch-step: 20-511 -- Loss: 0.2399939000606537
train-epoch-step: 20-512 -- Loss: 0.18961575627326965
train-epoch-step: 20-513 -- Loss: 0.211546391248703
train-epoch-step: 20-514 -- Loss: 0.15560084581375122
train-epoch-step: 20-515 -- Loss: 0.17401769757270813
train-epoch-step: 20-516 -- Loss: 0.18468210101127625
train-epoch-step: 20-517 -- Loss: 0.18661345541477203
train-epoch-step: 20-518 -- Loss: 0.1558396816253662
train-epoch-step: 20-519 -- Loss: 0.14239318668842316
train-epoch-step: 20-520 -- Loss: 0.20215676724910736
train-epoch-step: 20-521 -- Loss: 0.2371899038553238
train-epoch-step: 20-522 -- Loss: 0.18644703924655914
train-epoch-step: 20-523 -- Loss: 0.1674891710281372
train-epoch-step: 20-524 -- Loss: 0.18250352144241333
train-epoch-step: 20-525 -- Loss: 0.20663674175739288
train-epoch-step: 20-526 -- Loss: 0.13734787702560425
train-epoch-step: 20-527 -- Loss: 0.16590234637260437
train-epoch-step: 20-528 -- Loss: 0.16822075843811035
train-epoch-step: 20-529 -- Loss: 0.17186769843101501
train-epoch-step: 20-530 -- Loss: 0.1742095798254013
train-epoch-step: 20-531 -- Loss: 0.22321727871894836
train-epoch-step: 20-532 -- Loss: 0.1810278743505478
train-epoch-step: 20-533 -- Loss: 0.18273711204528809
train-epoch-step: 20-534 -- Loss: 0.1468927264213562
train-epoch-step: 20-535 -- Loss: 0.2806556224822998
train-epoch-step: 20-536 -- Loss: 0.17165948450565338
train-epoch-step: 20-537 -- Loss: 0.15639430284500122
train-epoch-step: 20-538 -- Loss: 0.10954886674880981
train-epoch-step: 20-539 -- Loss: 0.20850004255771637
train-epoch-step: 20-540 -- Loss: 0.14326182007789612
train-epoch-step: 20-541 -- Loss: 0.21974927186965942
train-epoch-step: 20-542 -- Loss: 0.2393384724855423
train-epoch-step: 20-543 -- Loss: 0.17553770542144775
train-epoch-step: 20-544 -- Loss: 0.2369895577430725
train-epoch-step: 20-545 -- Loss: 0.20224934816360474
train-epoch-step: 20-546 -- Loss: 0.23502346873283386
train-epoch-step: 20-547 -- Loss: 0.1904039978981018
train-epoch-step: 20-548 -- Loss: 0.09920883178710938
train-epoch-step: 20-549 -- Loss: 0.16018995642662048
train-epoch-step: 20-550 -- Loss: 0.2077963650226593
train-epoch-step: 20-551 -- Loss: 0.17248013615608215
train-epoch-step: 20-552 -- Loss: 0.13392339646816254
train-epoch-step: 20-553 -- Loss: 0.2056894302368164
train-epoch-step: 20-554 -- Loss: 0.20107002556324005
train-epoch-step: 20-555 -- Loss: 0.23689395189285278
train-epoch-step: 20-556 -- Loss: 0.16609178483486176
train-epoch-step: 20-557 -- Loss: 0.24995997548103333
train-epoch-step: 20-558 -- Loss: 0.2400086671113968
train-epoch-step: 20-559 -- Loss: 0.15763595700263977
train-epoch-step: 20-560 -- Loss: 0.21933138370513916
train-epoch-step: 20-561 -- Loss: 0.19862204790115356
train-epoch-step: 20-562 -- Loss: 0.17381733655929565
train-epoch-step: 20-563 -- Loss: 0.199057936668396
train-epoch-step: 20-564 -- Loss: 0.10761688649654388
train-epoch-step: 20-565 -- Loss: 0.20014579594135284
train-epoch-step: 20-566 -- Loss: 0.1663101613521576
train-epoch-step: 20-567 -- Loss: 0.22090430557727814
train-epoch-step: 20-568 -- Loss: 0.16923917829990387
train-epoch-step: 20-569 -- Loss: 0.25033608078956604
train-epoch-step: 20-570 -- Loss: 0.1826627254486084
train-epoch-step: 20-571 -- Loss: 0.2280648946762085
train-epoch-step: 20-572 -- Loss: 0.25325483083724976
train-epoch-step: 20-573 -- Loss: 0.21578571200370789
train-epoch-step: 20-574 -- Loss: 0.25878050923347473
train-epoch-step: 20-575 -- Loss: 0.310883104801178
train-epoch-step: 20-576 -- Loss: 0.1273205578327179
train-epoch-step: 20-577 -- Loss: 0.18074965476989746
train-epoch-step: 20-578 -- Loss: 0.2261962890625
train-epoch-step: 20-579 -- Loss: 0.18721917271614075
train-epoch-step: 20-580 -- Loss: 0.18745079636573792
train-epoch-step: 20-581 -- Loss: 0.15730181336402893
train-epoch-step: 20-582 -- Loss: 0.21955586969852448
train-epoch-step: 20-583 -- Loss: 0.23819167912006378
train-epoch-step: 20-584 -- Loss: 0.1769634485244751
train-epoch-step: 20-585 -- Loss: 0.20239773392677307
train-epoch-step: 20-586 -- Loss: 0.28443196415901184
train-epoch-step: 20-587 -- Loss: 0.1664714217185974
train-epoch-step: 20-588 -- Loss: 0.13491961359977722
val-epoch-step: 20-589 -- Loss: 0.2278648465871811
val-epoch-step: 20-590 -- Loss: 0.16047939658164978
val-epoch-step: 20-591 -- Loss: 0.23726274073123932
val-epoch-step: 20-592 -- Loss: 0.18205071985721588
val-epoch-step: 20-593 -- Loss: 0.1549241840839386
val-epoch-step: 20-594 -- Loss: 0.498215913772583
val-epoch-step: 20-595 -- Loss: 0.19351531565189362
val-epoch-step: 20-596 -- Loss: 0.2116202712059021
val-epoch-step: 20-597 -- Loss: 0.188958078622818
val-epoch-step: 20-598 -- Loss: 0.1534038782119751
val-epoch-step: 20-599 -- Loss: 0.19247758388519287
val-epoch-step: 20-600 -- Loss: 0.18355698883533478
val-epoch-step: 20-601 -- Loss: 0.1661578118801117
val-epoch-step: 20-602 -- Loss: 0.14802971482276917
val-epoch-step: 20-603 -- Loss: 0.19013261795043945
val-epoch-step: 20-604 -- Loss: 0.15701957046985626
val-epoch-step: 20-605 -- Loss: 0.15280839800834656
val-epoch-step: 20-606 -- Loss: 0.2744292616844177
val-epoch-step: 20-607 -- Loss: 0.13707499206066132
val-epoch-step: 20-608 -- Loss: 0.2659444212913513
val-epoch-step: 20-609 -- Loss: 0.17828762531280518
val-epoch-step: 20-610 -- Loss: 0.19143860042095184
val-epoch-step: 20-611 -- Loss: 0.16820383071899414
val-epoch-step: 20-612 -- Loss: 0.4917203187942505
val-epoch-step: 20-613 -- Loss: 0.17885293066501617
val-epoch-step: 20-614 -- Loss: 0.16324125230312347
val-epoch-step: 20-615 -- Loss: 0.18316201865673065
val-epoch-step: 20-616 -- Loss: 0.15990033745765686
val-epoch-step: 20-617 -- Loss: 0.19821599125862122
val-epoch-step: 20-618 -- Loss: 0.19762419164180756
val-epoch-step: 20-619 -- Loss: 0.21748018264770508
val-epoch-step: 20-620 -- Loss: 0.1456652134656906
val-epoch-step: 20-621 -- Loss: 0.1350131779909134
val-epoch-step: 20-622 -- Loss: 0.15503954887390137
val-epoch-step: 20-623 -- Loss: 0.16315551102161407
val-epoch-step: 20-624 -- Loss: 0.15519624948501587
val-epoch-step: 20-625 -- Loss: 0.16559943556785583
val-epoch-step: 20-626 -- Loss: 0.1541028469800949
val-epoch-step: 20-627 -- Loss: 0.2026287168264389
val-epoch-step: 20-628 -- Loss: 0.6945930123329163
val-epoch-step: 20-629 -- Loss: 0.24771296977996826
val-epoch-step: 20-630 -- Loss: 0.3619575798511505
val-epoch-step: 20-631 -- Loss: 0.15548226237297058
val-epoch-step: 20-632 -- Loss: 0.2281396985054016
val-epoch-step: 20-633 -- Loss: 0.15867918729782104
val-epoch-step: 20-634 -- Loss: 0.1505756676197052
val-epoch-step: 20-635 -- Loss: 0.12041378766298294
val-epoch-step: 20-636 -- Loss: 0.17889395356178284
val-epoch-step: 20-637 -- Loss: 0.18747317790985107
val-epoch-step: 20-638 -- Loss: 0.17270566523075104
val-epoch-step: 20-639 -- Loss: 0.2768276035785675
val-epoch-step: 20-640 -- Loss: 0.26630812883377075
val-epoch-step: 20-641 -- Loss: 0.13406866788864136
val-epoch-step: 20-642 -- Loss: 0.18964903056621552
val-epoch-step: 20-643 -- Loss: 0.20799227058887482
val-epoch-step: 20-644 -- Loss: 0.17436011135578156
val-epoch-step: 20-645 -- Loss: 0.22971585392951965
val-epoch-step: 20-646 -- Loss: 0.13970135152339935
val-epoch-step: 20-647 -- Loss: 0.14584201574325562
val-epoch-step: 20-648 -- Loss: 0.16897869110107422
val-epoch-step: 20-649 -- Loss: 0.22144098579883575
val-epoch-step: 20-650 -- Loss: 0.26001062989234924
val-epoch-step: 20-651 -- Loss: 0.150019109249115
val-epoch-step: 20-652 -- Loss: 0.16878339648246765
val-epoch-step: 20-653 -- Loss: 0.22317099571228027
val-epoch-step: 20-654 -- Loss: 0.12164836376905441
Epoch: 20 -- Train Loss: tensor(0.1467, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 70.05 -- Val Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 70.05
                         Test Loss: 0.0 -- Test Acc: 70.05
train-epoch-step: 21-0 -- Loss: 0.23475278913974762
train-epoch-step: 21-1 -- Loss: 0.1529311239719391
train-epoch-step: 21-2 -- Loss: 0.21076565980911255
train-epoch-step: 21-3 -- Loss: 0.15092900395393372
train-epoch-step: 21-4 -- Loss: 0.17336776852607727
train-epoch-step: 21-5 -- Loss: 0.2022353708744049
train-epoch-step: 21-6 -- Loss: 0.23848822712898254
train-epoch-step: 21-7 -- Loss: 0.17672765254974365
train-epoch-step: 21-8 -- Loss: 0.19839288294315338
train-epoch-step: 21-9 -- Loss: 0.2557297945022583
train-epoch-step: 21-10 -- Loss: 0.21589654684066772
train-epoch-step: 21-11 -- Loss: 0.19039617478847504
train-epoch-step: 21-12 -- Loss: 0.15916554629802704
train-epoch-step: 21-13 -- Loss: 0.20034253597259521
train-epoch-step: 21-14 -- Loss: 0.17435359954833984
train-epoch-step: 21-15 -- Loss: 0.1636575162410736
train-epoch-step: 21-16 -- Loss: 0.17144250869750977
train-epoch-step: 21-17 -- Loss: 0.23108750581741333
train-epoch-step: 21-18 -- Loss: 0.20687897503376007
train-epoch-step: 21-19 -- Loss: 0.14386102557182312
train-epoch-step: 21-20 -- Loss: 0.2381313145160675
train-epoch-step: 21-21 -- Loss: 0.2718697786331177
train-epoch-step: 21-22 -- Loss: 0.15142366290092468
train-epoch-step: 21-23 -- Loss: 0.15900754928588867
train-epoch-step: 21-24 -- Loss: 0.13281817734241486
train-epoch-step: 21-25 -- Loss: 0.245865598320961
train-epoch-step: 21-26 -- Loss: 0.20140281319618225
train-epoch-step: 21-27 -- Loss: 0.253068208694458
train-epoch-step: 21-28 -- Loss: 0.13201569020748138
train-epoch-step: 21-29 -- Loss: 0.2531256377696991
train-epoch-step: 21-30 -- Loss: 0.11993736028671265
train-epoch-step: 21-31 -- Loss: 0.14870096743106842
train-epoch-step: 21-32 -- Loss: 0.17932237684726715
train-epoch-step: 21-33 -- Loss: 0.2895769774913788
train-epoch-step: 21-34 -- Loss: 0.1848060041666031
train-epoch-step: 21-35 -- Loss: 0.26434245705604553
train-epoch-step: 21-36 -- Loss: 0.14692378044128418
train-epoch-step: 21-37 -- Loss: 0.14438235759735107
train-epoch-step: 21-38 -- Loss: 0.20195317268371582
train-epoch-step: 21-39 -- Loss: 0.24150986969470978
train-epoch-step: 21-40 -- Loss: 0.20556193590164185
train-epoch-step: 21-41 -- Loss: 0.22981992363929749
train-epoch-step: 21-42 -- Loss: 0.15543882548809052
train-epoch-step: 21-43 -- Loss: 0.29600468277931213
train-epoch-step: 21-44 -- Loss: 0.13384179770946503
train-epoch-step: 21-45 -- Loss: 0.13508322834968567
train-epoch-step: 21-46 -- Loss: 0.1810145378112793
train-epoch-step: 21-47 -- Loss: 0.2380276918411255
train-epoch-step: 21-48 -- Loss: 0.1662711650133133
train-epoch-step: 21-49 -- Loss: 0.2291366457939148
train-epoch-step: 21-50 -- Loss: 0.1250659078359604
train-epoch-step: 21-51 -- Loss: 0.19940178096294403
train-epoch-step: 21-52 -- Loss: 0.16745947301387787
train-epoch-step: 21-53 -- Loss: 0.2206127792596817
train-epoch-step: 21-54 -- Loss: 0.296138197183609
train-epoch-step: 21-55 -- Loss: 0.17861321568489075
train-epoch-step: 21-56 -- Loss: 0.18980544805526733
train-epoch-step: 21-57 -- Loss: 0.25213730335235596
train-epoch-step: 21-58 -- Loss: 0.30135655403137207
train-epoch-step: 21-59 -- Loss: 0.25371652841567993
train-epoch-step: 21-60 -- Loss: 0.13694986701011658
train-epoch-step: 21-61 -- Loss: 0.2127918004989624
train-epoch-step: 21-62 -- Loss: 0.19367271661758423
train-epoch-step: 21-63 -- Loss: 0.15756168961524963
train-epoch-step: 21-64 -- Loss: 0.15486304461956024
train-epoch-step: 21-65 -- Loss: 0.1907396912574768
train-epoch-step: 21-66 -- Loss: 0.1163908839225769
train-epoch-step: 21-67 -- Loss: 0.13350209593772888
train-epoch-step: 21-68 -- Loss: 0.2327246516942978
train-epoch-step: 21-69 -- Loss: 0.12788738310337067
train-epoch-step: 21-70 -- Loss: 0.24420738220214844
train-epoch-step: 21-71 -- Loss: 0.27064719796180725
train-epoch-step: 21-72 -- Loss: 0.18644076585769653
train-epoch-step: 21-73 -- Loss: 0.21643072366714478
train-epoch-step: 21-74 -- Loss: 0.10624746233224869
train-epoch-step: 21-75 -- Loss: 0.1358654797077179
train-epoch-step: 21-76 -- Loss: 0.15180984139442444
train-epoch-step: 21-77 -- Loss: 0.2430994212627411
train-epoch-step: 21-78 -- Loss: 0.280426025390625
train-epoch-step: 21-79 -- Loss: 0.2003994584083557
train-epoch-step: 21-80 -- Loss: 0.281289279460907
train-epoch-step: 21-81 -- Loss: 0.13068678975105286
train-epoch-step: 21-82 -- Loss: 0.26531821489334106
train-epoch-step: 21-83 -- Loss: 0.197642982006073
train-epoch-step: 21-84 -- Loss: 0.19804660975933075
train-epoch-step: 21-85 -- Loss: 0.19004875421524048
train-epoch-step: 21-86 -- Loss: 0.13393531739711761
train-epoch-step: 21-87 -- Loss: 0.24044160544872284
train-epoch-step: 21-88 -- Loss: 0.1519542932510376
train-epoch-step: 21-89 -- Loss: 0.19285880029201508
train-epoch-step: 21-90 -- Loss: 0.20094920694828033
train-epoch-step: 21-91 -- Loss: 0.25493836402893066
train-epoch-step: 21-92 -- Loss: 0.16416622698307037
train-epoch-step: 21-93 -- Loss: 0.1930985152721405
train-epoch-step: 21-94 -- Loss: 0.2551596164703369
train-epoch-step: 21-95 -- Loss: 0.2062269002199173
train-epoch-step: 21-96 -- Loss: 0.23048385977745056
train-epoch-step: 21-97 -- Loss: 0.18980617821216583
train-epoch-step: 21-98 -- Loss: 0.16335782408714294
train-epoch-step: 21-99 -- Loss: 0.18900269269943237
train-epoch-step: 21-100 -- Loss: 0.1898685097694397
train-epoch-step: 21-101 -- Loss: 0.29611098766326904
train-epoch-step: 21-102 -- Loss: 0.23498862981796265
train-epoch-step: 21-103 -- Loss: 0.1960148960351944
train-epoch-step: 21-104 -- Loss: 0.15765827894210815
train-epoch-step: 21-105 -- Loss: 0.2875446677207947
train-epoch-step: 21-106 -- Loss: 0.1811838150024414
train-epoch-step: 21-107 -- Loss: 0.19421543180942535
train-epoch-step: 21-108 -- Loss: 0.19581666588783264
train-epoch-step: 21-109 -- Loss: 0.1558401882648468
train-epoch-step: 21-110 -- Loss: 0.1980856955051422
train-epoch-step: 21-111 -- Loss: 0.1912628710269928
train-epoch-step: 21-112 -- Loss: 0.17984890937805176
train-epoch-step: 21-113 -- Loss: 0.17271672189235687
train-epoch-step: 21-114 -- Loss: 0.20247328281402588
train-epoch-step: 21-115 -- Loss: 0.16997405886650085
train-epoch-step: 21-116 -- Loss: 0.14508956670761108
train-epoch-step: 21-117 -- Loss: 0.1336803287267685
train-epoch-step: 21-118 -- Loss: 0.2131737321615219
train-epoch-step: 21-119 -- Loss: 0.16402947902679443
train-epoch-step: 21-120 -- Loss: 0.25801360607147217
train-epoch-step: 21-121 -- Loss: 0.28921961784362793
train-epoch-step: 21-122 -- Loss: 0.22735418379306793
train-epoch-step: 21-123 -- Loss: 0.20947042107582092
train-epoch-step: 21-124 -- Loss: 0.13554514944553375
train-epoch-step: 21-125 -- Loss: 0.1657903492450714
train-epoch-step: 21-126 -- Loss: 0.23247990012168884
train-epoch-step: 21-127 -- Loss: 0.1823369264602661
train-epoch-step: 21-128 -- Loss: 0.1813749372959137
train-epoch-step: 21-129 -- Loss: 0.1536027193069458
train-epoch-step: 21-130 -- Loss: 0.20904579758644104
train-epoch-step: 21-131 -- Loss: 0.14403049647808075
train-epoch-step: 21-132 -- Loss: 0.20407328009605408
train-epoch-step: 21-133 -- Loss: 0.12204030156135559
train-epoch-step: 21-134 -- Loss: 0.21273577213287354
train-epoch-step: 21-135 -- Loss: 0.15871869027614594
train-epoch-step: 21-136 -- Loss: 0.13796399533748627
train-epoch-step: 21-137 -- Loss: 0.2619353234767914
train-epoch-step: 21-138 -- Loss: 0.2786141335964203
train-epoch-step: 21-139 -- Loss: 0.13633131980895996
train-epoch-step: 21-140 -- Loss: 0.21669846773147583
train-epoch-step: 21-141 -- Loss: 0.24592071771621704
train-epoch-step: 21-142 -- Loss: 0.21411314606666565
train-epoch-step: 21-143 -- Loss: 0.1904776692390442
train-epoch-step: 21-144 -- Loss: 0.2091795802116394
train-epoch-step: 21-145 -- Loss: 0.15284225344657898
train-epoch-step: 21-146 -- Loss: 0.19254574179649353
train-epoch-step: 21-147 -- Loss: 0.18282654881477356
train-epoch-step: 21-148 -- Loss: 0.16569650173187256
train-epoch-step: 21-149 -- Loss: 0.12773224711418152
train-epoch-step: 21-150 -- Loss: 0.19038504362106323
train-epoch-step: 21-151 -- Loss: 0.20559431612491608
train-epoch-step: 21-152 -- Loss: 0.19572103023529053
train-epoch-step: 21-153 -- Loss: 0.2872990071773529
train-epoch-step: 21-154 -- Loss: 0.13961608707904816
train-epoch-step: 21-155 -- Loss: 0.14585569500923157
train-epoch-step: 21-156 -- Loss: 0.12974049150943756
train-epoch-step: 21-157 -- Loss: 0.17642170190811157
train-epoch-step: 21-158 -- Loss: 0.17235177755355835
train-epoch-step: 21-159 -- Loss: 0.18800699710845947
train-epoch-step: 21-160 -- Loss: 0.23594042658805847
train-epoch-step: 21-161 -- Loss: 0.21338501572608948
train-epoch-step: 21-162 -- Loss: 0.2216404676437378
train-epoch-step: 21-163 -- Loss: 0.19418737292289734
train-epoch-step: 21-164 -- Loss: 0.1984960287809372
train-epoch-step: 21-165 -- Loss: 0.17228737473487854
train-epoch-step: 21-166 -- Loss: 0.12837830185890198
train-epoch-step: 21-167 -- Loss: 0.12969264388084412
train-epoch-step: 21-168 -- Loss: 0.22449442744255066
train-epoch-step: 21-169 -- Loss: 0.1464919149875641
train-epoch-step: 21-170 -- Loss: 0.2056589424610138
train-epoch-step: 21-171 -- Loss: 0.15000544488430023
train-epoch-step: 21-172 -- Loss: 0.2650299668312073
train-epoch-step: 21-173 -- Loss: 0.14253301918506622
train-epoch-step: 21-174 -- Loss: 0.25578948855400085
train-epoch-step: 21-175 -- Loss: 0.19166575372219086
train-epoch-step: 21-176 -- Loss: 0.13975094258785248
train-epoch-step: 21-177 -- Loss: 0.19268807768821716
train-epoch-step: 21-178 -- Loss: 0.1940099149942398
train-epoch-step: 21-179 -- Loss: 0.15454447269439697
train-epoch-step: 21-180 -- Loss: 0.1648527979850769
train-epoch-step: 21-181 -- Loss: 0.18059058487415314
train-epoch-step: 21-182 -- Loss: 0.2015097588300705
train-epoch-step: 21-183 -- Loss: 0.2913579046726227
train-epoch-step: 21-184 -- Loss: 0.14467068016529083
train-epoch-step: 21-185 -- Loss: 0.1535748392343521
train-epoch-step: 21-186 -- Loss: 0.19721907377243042
train-epoch-step: 21-187 -- Loss: 0.2147800773382187
train-epoch-step: 21-188 -- Loss: 0.18414127826690674
train-epoch-step: 21-189 -- Loss: 0.11390994489192963
train-epoch-step: 21-190 -- Loss: 0.18992364406585693
train-epoch-step: 21-191 -- Loss: 0.18258972465991974
train-epoch-step: 21-192 -- Loss: 0.24642372131347656
train-epoch-step: 21-193 -- Loss: 0.23778533935546875
train-epoch-step: 21-194 -- Loss: 0.1899772733449936
train-epoch-step: 21-195 -- Loss: 0.1704038381576538
train-epoch-step: 21-196 -- Loss: 0.18433161079883575
train-epoch-step: 21-197 -- Loss: 0.15166707336902618
train-epoch-step: 21-198 -- Loss: 0.13603071868419647
train-epoch-step: 21-199 -- Loss: 0.1599777340888977
train-epoch-step: 21-200 -- Loss: 0.13251282274723053
train-epoch-step: 21-201 -- Loss: 0.21029335260391235
train-epoch-step: 21-202 -- Loss: 0.14115259051322937
train-epoch-step: 21-203 -- Loss: 0.18123909831047058
train-epoch-step: 21-204 -- Loss: 0.14973412454128265
train-epoch-step: 21-205 -- Loss: 0.1939433515071869
train-epoch-step: 21-206 -- Loss: 0.21033959090709686
train-epoch-step: 21-207 -- Loss: 0.16227400302886963
train-epoch-step: 21-208 -- Loss: 0.18718886375427246
train-epoch-step: 21-209 -- Loss: 0.1500411033630371
train-epoch-step: 21-210 -- Loss: 0.1455805003643036
train-epoch-step: 21-211 -- Loss: 0.2171085774898529
train-epoch-step: 21-212 -- Loss: 0.20538610219955444
train-epoch-step: 21-213 -- Loss: 0.13613219559192657
train-epoch-step: 21-214 -- Loss: 0.15911708772182465
train-epoch-step: 21-215 -- Loss: 0.13627582788467407
train-epoch-step: 21-216 -- Loss: 0.22286786139011383
train-epoch-step: 21-217 -- Loss: 0.23214635252952576
train-epoch-step: 21-218 -- Loss: 0.15386465191841125
train-epoch-step: 21-219 -- Loss: 0.18294546008110046
train-epoch-step: 21-220 -- Loss: 0.139510378241539
train-epoch-step: 21-221 -- Loss: 0.214067280292511
train-epoch-step: 21-222 -- Loss: 0.12601524591445923
train-epoch-step: 21-223 -- Loss: 0.18497857451438904
train-epoch-step: 21-224 -- Loss: 0.20074033737182617
train-epoch-step: 21-225 -- Loss: 0.2818743884563446
train-epoch-step: 21-226 -- Loss: 0.220035582780838
train-epoch-step: 21-227 -- Loss: 0.2303355187177658
train-epoch-step: 21-228 -- Loss: 0.19240638613700867
train-epoch-step: 21-229 -- Loss: 0.18270054459571838
train-epoch-step: 21-230 -- Loss: 0.16867052018642426
train-epoch-step: 21-231 -- Loss: 0.16655641794204712
train-epoch-step: 21-232 -- Loss: 0.20451845228672028
train-epoch-step: 21-233 -- Loss: 0.08883148431777954
train-epoch-step: 21-234 -- Loss: 0.1864793747663498
train-epoch-step: 21-235 -- Loss: 0.15602798759937286
train-epoch-step: 21-236 -- Loss: 0.18690399825572968
train-epoch-step: 21-237 -- Loss: 0.25461307168006897
train-epoch-step: 21-238 -- Loss: 0.1635921448469162
train-epoch-step: 21-239 -- Loss: 0.1339494287967682
train-epoch-step: 21-240 -- Loss: 0.23354719579219818
train-epoch-step: 21-241 -- Loss: 0.1610199511051178
train-epoch-step: 21-242 -- Loss: 0.23584428429603577
train-epoch-step: 21-243 -- Loss: 0.24047338962554932
train-epoch-step: 21-244 -- Loss: 0.21544305980205536
train-epoch-step: 21-245 -- Loss: 0.2176043689250946
train-epoch-step: 21-246 -- Loss: 0.23186030983924866
train-epoch-step: 21-247 -- Loss: 0.23082484304904938
train-epoch-step: 21-248 -- Loss: 0.19372643530368805
train-epoch-step: 21-249 -- Loss: 0.14698189496994019
train-epoch-step: 21-250 -- Loss: 0.2119569331407547
train-epoch-step: 21-251 -- Loss: 0.11119472235441208
train-epoch-step: 21-252 -- Loss: 0.20326486229896545
train-epoch-step: 21-253 -- Loss: 0.1440546214580536
train-epoch-step: 21-254 -- Loss: 0.22321878373622894
train-epoch-step: 21-255 -- Loss: 0.15577693283557892
train-epoch-step: 21-256 -- Loss: 0.15691804885864258
train-epoch-step: 21-257 -- Loss: 0.2009270042181015
train-epoch-step: 21-258 -- Loss: 0.15587393939495087
train-epoch-step: 21-259 -- Loss: 0.11911740899085999
train-epoch-step: 21-260 -- Loss: 0.22773289680480957
train-epoch-step: 21-261 -- Loss: 0.19208407402038574
train-epoch-step: 21-262 -- Loss: 0.333331823348999
train-epoch-step: 21-263 -- Loss: 0.21890944242477417
train-epoch-step: 21-264 -- Loss: 0.18116767704486847
train-epoch-step: 21-265 -- Loss: 0.12929248809814453
train-epoch-step: 21-266 -- Loss: 0.1612033247947693
train-epoch-step: 21-267 -- Loss: 0.14029352366924286
train-epoch-step: 21-268 -- Loss: 0.1359560489654541
train-epoch-step: 21-269 -- Loss: 0.17679288983345032
train-epoch-step: 21-270 -- Loss: 0.1140628531575203
train-epoch-step: 21-271 -- Loss: 0.15561829507350922
train-epoch-step: 21-272 -- Loss: 0.1203007698059082
train-epoch-step: 21-273 -- Loss: 0.1302276849746704
train-epoch-step: 21-274 -- Loss: 0.1954955756664276
train-epoch-step: 21-275 -- Loss: 0.21987558901309967
train-epoch-step: 21-276 -- Loss: 0.16303810477256775
train-epoch-step: 21-277 -- Loss: 0.16269563138484955
train-epoch-step: 21-278 -- Loss: 0.1486530303955078
train-epoch-step: 21-279 -- Loss: 0.16122913360595703
train-epoch-step: 21-280 -- Loss: 0.2397802472114563
train-epoch-step: 21-281 -- Loss: 0.2067570686340332
train-epoch-step: 21-282 -- Loss: 0.14905278384685516
train-epoch-step: 21-283 -- Loss: 0.13064095377922058
train-epoch-step: 21-284 -- Loss: 0.15803059935569763
train-epoch-step: 21-285 -- Loss: 0.20471595227718353
train-epoch-step: 21-286 -- Loss: 0.16652539372444153
train-epoch-step: 21-287 -- Loss: 0.2196313440799713
train-epoch-step: 21-288 -- Loss: 0.10170233249664307
train-epoch-step: 21-289 -- Loss: 0.13545487821102142
train-epoch-step: 21-290 -- Loss: 0.19283443689346313
train-epoch-step: 21-291 -- Loss: 0.12479807436466217
train-epoch-step: 21-292 -- Loss: 0.1599021553993225
train-epoch-step: 21-293 -- Loss: 0.14605595171451569
train-epoch-step: 21-294 -- Loss: 0.17609421908855438
train-epoch-step: 21-295 -- Loss: 0.2904166281223297
train-epoch-step: 21-296 -- Loss: 0.16935445368289948
train-epoch-step: 21-297 -- Loss: 0.1832764446735382
train-epoch-step: 21-298 -- Loss: 0.24203896522521973
train-epoch-step: 21-299 -- Loss: 0.16231714189052582
train-epoch-step: 21-300 -- Loss: 0.17925526201725006
train-epoch-step: 21-301 -- Loss: 0.18133677542209625
train-epoch-step: 21-302 -- Loss: 0.23258230090141296
train-epoch-step: 21-303 -- Loss: 0.21636629104614258
train-epoch-step: 21-304 -- Loss: 0.13505977392196655
train-epoch-step: 21-305 -- Loss: 0.16669665277004242
train-epoch-step: 21-306 -- Loss: 0.25156259536743164
train-epoch-step: 21-307 -- Loss: 0.178126260638237
train-epoch-step: 21-308 -- Loss: 0.25374555587768555
train-epoch-step: 21-309 -- Loss: 0.167219340801239
train-epoch-step: 21-310 -- Loss: 0.1726226508617401
train-epoch-step: 21-311 -- Loss: 0.17702548205852509
train-epoch-step: 21-312 -- Loss: 0.22492893040180206
train-epoch-step: 21-313 -- Loss: 0.10995673388242722
train-epoch-step: 21-314 -- Loss: 0.21069861948490143
train-epoch-step: 21-315 -- Loss: 0.17873945832252502
train-epoch-step: 21-316 -- Loss: 0.16260352730751038
train-epoch-step: 21-317 -- Loss: 0.15064013004302979
train-epoch-step: 21-318 -- Loss: 0.1772845983505249
train-epoch-step: 21-319 -- Loss: 0.18081939220428467
train-epoch-step: 21-320 -- Loss: 0.12753081321716309
train-epoch-step: 21-321 -- Loss: 0.14413881301879883
train-epoch-step: 21-322 -- Loss: 0.2191801220178604
train-epoch-step: 21-323 -- Loss: 0.1680232137441635
train-epoch-step: 21-324 -- Loss: 0.26685330271720886
train-epoch-step: 21-325 -- Loss: 0.158478781580925
train-epoch-step: 21-326 -- Loss: 0.1740807294845581
train-epoch-step: 21-327 -- Loss: 0.22167211771011353
train-epoch-step: 21-328 -- Loss: 0.20263083279132843
train-epoch-step: 21-329 -- Loss: 0.3481937646865845
train-epoch-step: 21-330 -- Loss: 0.38890546560287476
train-epoch-step: 21-331 -- Loss: 0.2223767787218094
train-epoch-step: 21-332 -- Loss: 0.10705263912677765
train-epoch-step: 21-333 -- Loss: 0.19646582007408142
train-epoch-step: 21-334 -- Loss: 0.16383424401283264
train-epoch-step: 21-335 -- Loss: 0.18616053462028503
train-epoch-step: 21-336 -- Loss: 0.1688443124294281
train-epoch-step: 21-337 -- Loss: 0.23374515771865845
train-epoch-step: 21-338 -- Loss: 0.16502992808818817
train-epoch-step: 21-339 -- Loss: 0.15078303217887878
train-epoch-step: 21-340 -- Loss: 0.20974719524383545
train-epoch-step: 21-341 -- Loss: 0.1459275186061859
train-epoch-step: 21-342 -- Loss: 0.17189617455005646
train-epoch-step: 21-343 -- Loss: 0.16108360886573792
train-epoch-step: 21-344 -- Loss: 0.17851728200912476
train-epoch-step: 21-345 -- Loss: 0.13486936688423157
train-epoch-step: 21-346 -- Loss: 0.21939611434936523
train-epoch-step: 21-347 -- Loss: 0.15673166513442993
train-epoch-step: 21-348 -- Loss: 0.2109558880329132
train-epoch-step: 21-349 -- Loss: 0.21106776595115662
train-epoch-step: 21-350 -- Loss: 0.2691943049430847
train-epoch-step: 21-351 -- Loss: 0.19694000482559204
train-epoch-step: 21-352 -- Loss: 0.1353786438703537
train-epoch-step: 21-353 -- Loss: 0.20534037053585052
train-epoch-step: 21-354 -- Loss: 0.29385900497436523
train-epoch-step: 21-355 -- Loss: 0.1245967373251915
train-epoch-step: 21-356 -- Loss: 0.1186760812997818
train-epoch-step: 21-357 -- Loss: 0.20874179899692535
train-epoch-step: 21-358 -- Loss: 0.19460180401802063
train-epoch-step: 21-359 -- Loss: 0.14819735288619995
train-epoch-step: 21-360 -- Loss: 0.1272307187318802
train-epoch-step: 21-361 -- Loss: 0.24337813258171082
train-epoch-step: 21-362 -- Loss: 0.17545698583126068
train-epoch-step: 21-363 -- Loss: 0.11918453872203827
train-epoch-step: 21-364 -- Loss: 0.19075123965740204
train-epoch-step: 21-365 -- Loss: 0.18640907108783722
train-epoch-step: 21-366 -- Loss: 0.22289220988750458
train-epoch-step: 21-367 -- Loss: 0.24377313256263733
train-epoch-step: 21-368 -- Loss: 0.211043119430542
train-epoch-step: 21-369 -- Loss: 0.291662335395813
train-epoch-step: 21-370 -- Loss: 0.13768288493156433
train-epoch-step: 21-371 -- Loss: 0.12533041834831238
train-epoch-step: 21-372 -- Loss: 0.1477806270122528
train-epoch-step: 21-373 -- Loss: 0.19812430441379547
train-epoch-step: 21-374 -- Loss: 0.16095343232154846
train-epoch-step: 21-375 -- Loss: 0.28493809700012207
train-epoch-step: 21-376 -- Loss: 0.18137775361537933
train-epoch-step: 21-377 -- Loss: 0.2388582080602646
train-epoch-step: 21-378 -- Loss: 0.21466174721717834
train-epoch-step: 21-379 -- Loss: 0.13043726980686188
train-epoch-step: 21-380 -- Loss: 0.09376858919858932
train-epoch-step: 21-381 -- Loss: 0.25407975912094116
train-epoch-step: 21-382 -- Loss: 0.2468390166759491
train-epoch-step: 21-383 -- Loss: 0.18151777982711792
train-epoch-step: 21-384 -- Loss: 0.25409987568855286
train-epoch-step: 21-385 -- Loss: 0.2023434340953827
train-epoch-step: 21-386 -- Loss: 0.19733843207359314
train-epoch-step: 21-387 -- Loss: 0.21866890788078308
train-epoch-step: 21-388 -- Loss: 0.20836007595062256
train-epoch-step: 21-389 -- Loss: 0.17212702333927155
train-epoch-step: 21-390 -- Loss: 0.14876818656921387
train-epoch-step: 21-391 -- Loss: 0.15219265222549438
train-epoch-step: 21-392 -- Loss: 0.20253121852874756
train-epoch-step: 21-393 -- Loss: 0.1649581342935562
train-epoch-step: 21-394 -- Loss: 0.22661834955215454
train-epoch-step: 21-395 -- Loss: 0.16691052913665771
train-epoch-step: 21-396 -- Loss: 0.1323014497756958
train-epoch-step: 21-397 -- Loss: 0.1307184398174286
train-epoch-step: 21-398 -- Loss: 0.20967377722263336
train-epoch-step: 21-399 -- Loss: 0.1846442073583603
train-epoch-step: 21-400 -- Loss: 0.29583966732025146
train-epoch-step: 21-401 -- Loss: 0.12654873728752136
train-epoch-step: 21-402 -- Loss: 0.2696375846862793
train-epoch-step: 21-403 -- Loss: 0.16091763973236084
train-epoch-step: 21-404 -- Loss: 0.14706523716449738
train-epoch-step: 21-405 -- Loss: 0.15175049006938934
train-epoch-step: 21-406 -- Loss: 0.17761939764022827
train-epoch-step: 21-407 -- Loss: 0.1195203885436058
train-epoch-step: 21-408 -- Loss: 0.16582688689231873
train-epoch-step: 21-409 -- Loss: 0.18504080176353455
train-epoch-step: 21-410 -- Loss: 0.18291068077087402
train-epoch-step: 21-411 -- Loss: 0.20920579135417938
train-epoch-step: 21-412 -- Loss: 0.13982316851615906
train-epoch-step: 21-413 -- Loss: 0.1577029526233673
train-epoch-step: 21-414 -- Loss: 0.14096955955028534
train-epoch-step: 21-415 -- Loss: 0.14149421453475952
train-epoch-step: 21-416 -- Loss: 0.27850794792175293
train-epoch-step: 21-417 -- Loss: 0.2018125355243683
train-epoch-step: 21-418 -- Loss: 0.24225422739982605
train-epoch-step: 21-419 -- Loss: 0.17610865831375122
train-epoch-step: 21-420 -- Loss: 0.16407941281795502
train-epoch-step: 21-421 -- Loss: 0.18791504204273224
train-epoch-step: 21-422 -- Loss: 0.15891559422016144
train-epoch-step: 21-423 -- Loss: 0.18203800916671753
train-epoch-step: 21-424 -- Loss: 0.1429162174463272
train-epoch-step: 21-425 -- Loss: 0.19553467631340027
train-epoch-step: 21-426 -- Loss: 0.1674521267414093
train-epoch-step: 21-427 -- Loss: 0.1286722719669342
train-epoch-step: 21-428 -- Loss: 0.20281188189983368
train-epoch-step: 21-429 -- Loss: 0.17735464870929718
train-epoch-step: 21-430 -- Loss: 0.14844679832458496
train-epoch-step: 21-431 -- Loss: 0.17116475105285645
train-epoch-step: 21-432 -- Loss: 0.24836237728595734
train-epoch-step: 21-433 -- Loss: 0.14107193052768707
train-epoch-step: 21-434 -- Loss: 0.13315236568450928
train-epoch-step: 21-435 -- Loss: 0.16106672585010529
train-epoch-step: 21-436 -- Loss: 0.16312140226364136
train-epoch-step: 21-437 -- Loss: 0.1380891352891922
train-epoch-step: 21-438 -- Loss: 0.17721030116081238
train-epoch-step: 21-439 -- Loss: 0.2805124819278717
train-epoch-step: 21-440 -- Loss: 0.14001937210559845
train-epoch-step: 21-441 -- Loss: 0.21990883350372314
train-epoch-step: 21-442 -- Loss: 0.19866245985031128
train-epoch-step: 21-443 -- Loss: 0.16757799685001373
train-epoch-step: 21-444 -- Loss: 0.18470612168312073
train-epoch-step: 21-445 -- Loss: 0.1935049295425415
train-epoch-step: 21-446 -- Loss: 0.1603018194437027
train-epoch-step: 21-447 -- Loss: 0.20187965035438538
train-epoch-step: 21-448 -- Loss: 0.24297833442687988
train-epoch-step: 21-449 -- Loss: 0.202068492770195
train-epoch-step: 21-450 -- Loss: 0.19593432545661926
train-epoch-step: 21-451 -- Loss: 0.15633773803710938
train-epoch-step: 21-452 -- Loss: 0.14172494411468506
train-epoch-step: 21-453 -- Loss: 0.10053718090057373
train-epoch-step: 21-454 -- Loss: 0.2389318346977234
train-epoch-step: 21-455 -- Loss: 0.13035990297794342
train-epoch-step: 21-456 -- Loss: 0.12749436497688293
train-epoch-step: 21-457 -- Loss: 0.2258949726819992
train-epoch-step: 21-458 -- Loss: 0.17025074362754822
train-epoch-step: 21-459 -- Loss: 0.23812918365001678
train-epoch-step: 21-460 -- Loss: 0.13302847743034363
train-epoch-step: 21-461 -- Loss: 0.14049115777015686
train-epoch-step: 21-462 -- Loss: 0.16776233911514282
train-epoch-step: 21-463 -- Loss: 0.14007088541984558
train-epoch-step: 21-464 -- Loss: 0.16870787739753723
train-epoch-step: 21-465 -- Loss: 0.2555975914001465
train-epoch-step: 21-466 -- Loss: 0.20952023565769196
train-epoch-step: 21-467 -- Loss: 0.12094861268997192
train-epoch-step: 21-468 -- Loss: 0.17729875445365906
train-epoch-step: 21-469 -- Loss: 0.22562207281589508
train-epoch-step: 21-470 -- Loss: 0.1951615959405899
train-epoch-step: 21-471 -- Loss: 0.16347913444042206
train-epoch-step: 21-472 -- Loss: 0.16390255093574524
train-epoch-step: 21-473 -- Loss: 0.16808444261550903
train-epoch-step: 21-474 -- Loss: 0.1216588020324707
train-epoch-step: 21-475 -- Loss: 0.11890757083892822
train-epoch-step: 21-476 -- Loss: 0.20810212194919586
train-epoch-step: 21-477 -- Loss: 0.2176682949066162
train-epoch-step: 21-478 -- Loss: 0.20671235024929047
train-epoch-step: 21-479 -- Loss: 0.15549138188362122
train-epoch-step: 21-480 -- Loss: 0.21258489787578583
train-epoch-step: 21-481 -- Loss: 0.28878894448280334
train-epoch-step: 21-482 -- Loss: 0.2638443112373352
train-epoch-step: 21-483 -- Loss: 0.19205808639526367
train-epoch-step: 21-484 -- Loss: 0.2184334695339203
train-epoch-step: 21-485 -- Loss: 0.1342671662569046
train-epoch-step: 21-486 -- Loss: 0.23971955478191376
train-epoch-step: 21-487 -- Loss: 0.24337954819202423
train-epoch-step: 21-488 -- Loss: 0.19780278205871582
train-epoch-step: 21-489 -- Loss: 0.2253129631280899
train-epoch-step: 21-490 -- Loss: 0.15250876545906067
train-epoch-step: 21-491 -- Loss: 0.14194445312023163
train-epoch-step: 21-492 -- Loss: 0.1289835423231125
train-epoch-step: 21-493 -- Loss: 0.21163028478622437
train-epoch-step: 21-494 -- Loss: 0.21836908161640167
train-epoch-step: 21-495 -- Loss: 0.21525852382183075
train-epoch-step: 21-496 -- Loss: 0.14363732933998108
train-epoch-step: 21-497 -- Loss: 0.18882784247398376
train-epoch-step: 21-498 -- Loss: 0.1537584364414215
train-epoch-step: 21-499 -- Loss: 0.1763952225446701
train-epoch-step: 21-500 -- Loss: 0.1614999622106552
train-epoch-step: 21-501 -- Loss: 0.22706928849220276
train-epoch-step: 21-502 -- Loss: 0.16576722264289856
train-epoch-step: 21-503 -- Loss: 0.22921903431415558
train-epoch-step: 21-504 -- Loss: 0.13058747351169586
train-epoch-step: 21-505 -- Loss: 0.17786158621311188
train-epoch-step: 21-506 -- Loss: 0.1226484552025795
train-epoch-step: 21-507 -- Loss: 0.18718551099300385
train-epoch-step: 21-508 -- Loss: 0.1833564043045044
train-epoch-step: 21-509 -- Loss: 0.1754416823387146
train-epoch-step: 21-510 -- Loss: 0.13412275910377502
train-epoch-step: 21-511 -- Loss: 0.22332435846328735
train-epoch-step: 21-512 -- Loss: 0.1851477026939392
train-epoch-step: 21-513 -- Loss: 0.20951294898986816
train-epoch-step: 21-514 -- Loss: 0.15372620522975922
train-epoch-step: 21-515 -- Loss: 0.16553965210914612
train-epoch-step: 21-516 -- Loss: 0.1787269413471222
train-epoch-step: 21-517 -- Loss: 0.1769072562456131
train-epoch-step: 21-518 -- Loss: 0.14395740628242493
train-epoch-step: 21-519 -- Loss: 0.14032606780529022
train-epoch-step: 21-520 -- Loss: 0.1935739815235138
train-epoch-step: 21-521 -- Loss: 0.23864945769309998
train-epoch-step: 21-522 -- Loss: 0.1793411821126938
train-epoch-step: 21-523 -- Loss: 0.1614294946193695
train-epoch-step: 21-524 -- Loss: 0.17576517164707184
train-epoch-step: 21-525 -- Loss: 0.19797030091285706
train-epoch-step: 21-526 -- Loss: 0.1347021609544754
train-epoch-step: 21-527 -- Loss: 0.16383236646652222
train-epoch-step: 21-528 -- Loss: 0.162815660238266
train-epoch-step: 21-529 -- Loss: 0.17222383618354797
train-epoch-step: 21-530 -- Loss: 0.19001486897468567
train-epoch-step: 21-531 -- Loss: 0.20573201775550842
train-epoch-step: 21-532 -- Loss: 0.17882636189460754
train-epoch-step: 21-533 -- Loss: 0.17917263507843018
train-epoch-step: 21-534 -- Loss: 0.1408863067626953
train-epoch-step: 21-535 -- Loss: 0.2688383460044861
train-epoch-step: 21-536 -- Loss: 0.1634303629398346
train-epoch-step: 21-537 -- Loss: 0.1536424607038498
train-epoch-step: 21-538 -- Loss: 0.10911369323730469
train-epoch-step: 21-539 -- Loss: 0.2575775384902954
train-epoch-step: 21-540 -- Loss: 0.14147049188613892
train-epoch-step: 21-541 -- Loss: 0.21793992817401886
train-epoch-step: 21-542 -- Loss: 0.2317708283662796
train-epoch-step: 21-543 -- Loss: 0.1825350821018219
train-epoch-step: 21-544 -- Loss: 0.25051358342170715
train-epoch-step: 21-545 -- Loss: 0.2044999897480011
train-epoch-step: 21-546 -- Loss: 0.22954747080802917
train-epoch-step: 21-547 -- Loss: 0.19203463196754456
train-epoch-step: 21-548 -- Loss: 0.0983974039554596
train-epoch-step: 21-549 -- Loss: 0.16855618357658386
train-epoch-step: 21-550 -- Loss: 0.23936988413333893
train-epoch-step: 21-551 -- Loss: 0.17408370971679688
train-epoch-step: 21-552 -- Loss: 0.1380821168422699
train-epoch-step: 21-553 -- Loss: 0.19694262742996216
train-epoch-step: 21-554 -- Loss: 0.19395235180854797
train-epoch-step: 21-555 -- Loss: 0.21691110730171204
train-epoch-step: 21-556 -- Loss: 0.16079281270503998
train-epoch-step: 21-557 -- Loss: 0.2650409936904907
train-epoch-step: 21-558 -- Loss: 0.23630160093307495
train-epoch-step: 21-559 -- Loss: 0.14630818367004395
train-epoch-step: 21-560 -- Loss: 0.22085055708885193
train-epoch-step: 21-561 -- Loss: 0.19798427820205688
train-epoch-step: 21-562 -- Loss: 0.18016760051250458
train-epoch-step: 21-563 -- Loss: 0.1944558322429657
train-epoch-step: 21-564 -- Loss: 0.10656298696994781
train-epoch-step: 21-565 -- Loss: 0.19221743941307068
train-epoch-step: 21-566 -- Loss: 0.1579432487487793
train-epoch-step: 21-567 -- Loss: 0.2259041666984558
train-epoch-step: 21-568 -- Loss: 0.16502922773361206
train-epoch-step: 21-569 -- Loss: 0.2513803243637085
train-epoch-step: 21-570 -- Loss: 0.175386443734169
train-epoch-step: 21-571 -- Loss: 0.22711941599845886
train-epoch-step: 21-572 -- Loss: 0.2568836808204651
train-epoch-step: 21-573 -- Loss: 0.21876178681850433
train-epoch-step: 21-574 -- Loss: 0.2853850722312927
train-epoch-step: 21-575 -- Loss: 0.3132767677307129
train-epoch-step: 21-576 -- Loss: 0.12317201495170593
train-epoch-step: 21-577 -- Loss: 0.17489081621170044
train-epoch-step: 21-578 -- Loss: 0.22791902720928192
train-epoch-step: 21-579 -- Loss: 0.17254900932312012
train-epoch-step: 21-580 -- Loss: 0.1833917200565338
train-epoch-step: 21-581 -- Loss: 0.14784172177314758
train-epoch-step: 21-582 -- Loss: 0.21704375743865967
train-epoch-step: 21-583 -- Loss: 0.2357446253299713
train-epoch-step: 21-584 -- Loss: 0.18545302748680115
train-epoch-step: 21-585 -- Loss: 0.20222124457359314
train-epoch-step: 21-586 -- Loss: 0.26756563782691956
train-epoch-step: 21-587 -- Loss: 0.16570277512073517
train-epoch-step: 21-588 -- Loss: 0.13242444396018982
val-epoch-step: 21-589 -- Loss: 0.2145656794309616
val-epoch-step: 21-590 -- Loss: 0.16238388419151306
val-epoch-step: 21-591 -- Loss: 0.2296905815601349
val-epoch-step: 21-592 -- Loss: 0.18148307502269745
val-epoch-step: 21-593 -- Loss: 0.17186395823955536
val-epoch-step: 21-594 -- Loss: 0.3672010898590088
val-epoch-step: 21-595 -- Loss: 0.18182843923568726
val-epoch-step: 21-596 -- Loss: 0.21117421984672546
val-epoch-step: 21-597 -- Loss: 0.178473562002182
val-epoch-step: 21-598 -- Loss: 0.15377770364284515
val-epoch-step: 21-599 -- Loss: 0.19020086526870728
val-epoch-step: 21-600 -- Loss: 0.23126372694969177
val-epoch-step: 21-601 -- Loss: 0.1591399908065796
val-epoch-step: 21-602 -- Loss: 0.14420732855796814
val-epoch-step: 21-603 -- Loss: 0.2050206959247589
val-epoch-step: 21-604 -- Loss: 0.15943476557731628
val-epoch-step: 21-605 -- Loss: 0.15523669123649597
val-epoch-step: 21-606 -- Loss: 0.2874397039413452
val-epoch-step: 21-607 -- Loss: 0.132389098405838
val-epoch-step: 21-608 -- Loss: 0.260703444480896
val-epoch-step: 21-609 -- Loss: 0.17639049887657166
val-epoch-step: 21-610 -- Loss: 0.18791933357715607
val-epoch-step: 21-611 -- Loss: 0.16351786255836487
val-epoch-step: 21-612 -- Loss: 0.4094652235507965
val-epoch-step: 21-613 -- Loss: 0.17771008610725403
val-epoch-step: 21-614 -- Loss: 0.17728589475154877
val-epoch-step: 21-615 -- Loss: 0.18471108376979828
val-epoch-step: 21-616 -- Loss: 0.15951964259147644
val-epoch-step: 21-617 -- Loss: 0.1910248100757599
val-epoch-step: 21-618 -- Loss: 0.20359760522842407
val-epoch-step: 21-619 -- Loss: 0.22105982899665833
val-epoch-step: 21-620 -- Loss: 0.15320001542568207
val-epoch-step: 21-621 -- Loss: 0.13639850914478302
val-epoch-step: 21-622 -- Loss: 0.14892370998859406
val-epoch-step: 21-623 -- Loss: 0.15926332771778107
val-epoch-step: 21-624 -- Loss: 0.15508760511875153
val-epoch-step: 21-625 -- Loss: 0.16854053735733032
val-epoch-step: 21-626 -- Loss: 0.15075141191482544
val-epoch-step: 21-627 -- Loss: 0.1953275501728058
val-epoch-step: 21-628 -- Loss: 0.6600635647773743
val-epoch-step: 21-629 -- Loss: 0.21343210339546204
val-epoch-step: 21-630 -- Loss: 0.3630446791648865
val-epoch-step: 21-631 -- Loss: 0.14660270512104034
val-epoch-step: 21-632 -- Loss: 0.2019365429878235
val-epoch-step: 21-633 -- Loss: 0.1586378514766693
val-epoch-step: 21-634 -- Loss: 0.14922493696212769
val-epoch-step: 21-635 -- Loss: 0.12152843177318573
val-epoch-step: 21-636 -- Loss: 0.17416974902153015
val-epoch-step: 21-637 -- Loss: 0.18836593627929688
val-epoch-step: 21-638 -- Loss: 0.15526001155376434
val-epoch-step: 21-639 -- Loss: 0.2678815424442291
val-epoch-step: 21-640 -- Loss: 0.26197949051856995
val-epoch-step: 21-641 -- Loss: 0.13684557378292084
val-epoch-step: 21-642 -- Loss: 0.19258402287960052
val-epoch-step: 21-643 -- Loss: 0.21549361944198608
val-epoch-step: 21-644 -- Loss: 0.16937457025051117
val-epoch-step: 21-645 -- Loss: 0.22629797458648682
val-epoch-step: 21-646 -- Loss: 0.13930055499076843
val-epoch-step: 21-647 -- Loss: 0.1344374269247055
val-epoch-step: 21-648 -- Loss: 0.16952942311763763
val-epoch-step: 21-649 -- Loss: 0.22289130091667175
val-epoch-step: 21-650 -- Loss: 0.2592446506023407
val-epoch-step: 21-651 -- Loss: 0.14925086498260498
val-epoch-step: 21-652 -- Loss: 0.16385549306869507
val-epoch-step: 21-653 -- Loss: 0.20769400894641876
val-epoch-step: 21-654 -- Loss: 0.11462230980396271
Epoch: 21 -- Train Loss: tensor(0.1460, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1457, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 22-0 -- Loss: 0.23255236446857452
train-epoch-step: 22-1 -- Loss: 0.14893987774848938
train-epoch-step: 22-2 -- Loss: 0.20440413057804108
train-epoch-step: 22-3 -- Loss: 0.1493695229291916
train-epoch-step: 22-4 -- Loss: 0.1717158704996109
train-epoch-step: 22-5 -- Loss: 0.197676420211792
train-epoch-step: 22-6 -- Loss: 0.23313191533088684
train-epoch-step: 22-7 -- Loss: 0.17584793269634247
train-epoch-step: 22-8 -- Loss: 0.19444426894187927
train-epoch-step: 22-9 -- Loss: 0.2593066692352295
train-epoch-step: 22-10 -- Loss: 0.21305879950523376
train-epoch-step: 22-11 -- Loss: 0.19574801623821259
train-epoch-step: 22-12 -- Loss: 0.1579260528087616
train-epoch-step: 22-13 -- Loss: 0.18905866146087646
train-epoch-step: 22-14 -- Loss: 0.172065868973732
train-epoch-step: 22-15 -- Loss: 0.17021843791007996
train-epoch-step: 22-16 -- Loss: 0.1717381328344345
train-epoch-step: 22-17 -- Loss: 0.23041488230228424
train-epoch-step: 22-18 -- Loss: 0.2053517997264862
train-epoch-step: 22-19 -- Loss: 0.13496102392673492
train-epoch-step: 22-20 -- Loss: 0.22586393356323242
train-epoch-step: 22-21 -- Loss: 0.27540335059165955
train-epoch-step: 22-22 -- Loss: 0.1449086219072342
train-epoch-step: 22-23 -- Loss: 0.14753355085849762
train-epoch-step: 22-24 -- Loss: 0.1305307149887085
train-epoch-step: 22-25 -- Loss: 0.24358654022216797
train-epoch-step: 22-26 -- Loss: 0.19802288711071014
train-epoch-step: 22-27 -- Loss: 0.2562282681465149
train-epoch-step: 22-28 -- Loss: 0.13166941702365875
train-epoch-step: 22-29 -- Loss: 0.25414812564849854
train-epoch-step: 22-30 -- Loss: 0.11570984125137329
train-epoch-step: 22-31 -- Loss: 0.14586710929870605
train-epoch-step: 22-32 -- Loss: 0.17963746190071106
train-epoch-step: 22-33 -- Loss: 0.2826429009437561
train-epoch-step: 22-34 -- Loss: 0.18001936376094818
train-epoch-step: 22-35 -- Loss: 0.2587399184703827
train-epoch-step: 22-36 -- Loss: 0.1429518461227417
train-epoch-step: 22-37 -- Loss: 0.14533677697181702
train-epoch-step: 22-38 -- Loss: 0.19616296887397766
train-epoch-step: 22-39 -- Loss: 0.2407398521900177
train-epoch-step: 22-40 -- Loss: 0.2075735628604889
train-epoch-step: 22-41 -- Loss: 0.222278892993927
train-epoch-step: 22-42 -- Loss: 0.1536477506160736
train-epoch-step: 22-43 -- Loss: 0.2757734954357147
train-epoch-step: 22-44 -- Loss: 0.13198675215244293
train-epoch-step: 22-45 -- Loss: 0.1316220760345459
train-epoch-step: 22-46 -- Loss: 0.17926065623760223
train-epoch-step: 22-47 -- Loss: 0.21657823026180267
train-epoch-step: 22-48 -- Loss: 0.16046591103076935
train-epoch-step: 22-49 -- Loss: 0.236668199300766
train-epoch-step: 22-50 -- Loss: 0.12242239713668823
train-epoch-step: 22-51 -- Loss: 0.19551140069961548
train-epoch-step: 22-52 -- Loss: 0.16269108653068542
train-epoch-step: 22-53 -- Loss: 0.2200060337781906
train-epoch-step: 22-54 -- Loss: 0.2891182005405426
train-epoch-step: 22-55 -- Loss: 0.172446146607399
train-epoch-step: 22-56 -- Loss: 0.1800006926059723
train-epoch-step: 22-57 -- Loss: 0.24367713928222656
train-epoch-step: 22-58 -- Loss: 0.2901969254016876
train-epoch-step: 22-59 -- Loss: 0.259198397397995
train-epoch-step: 22-60 -- Loss: 0.13894711434841156
train-epoch-step: 22-61 -- Loss: 0.2247612178325653
train-epoch-step: 22-62 -- Loss: 0.1891939342021942
train-epoch-step: 22-63 -- Loss: 0.148653045296669
train-epoch-step: 22-64 -- Loss: 0.15896740555763245
train-epoch-step: 22-65 -- Loss: 0.18962648510932922
train-epoch-step: 22-66 -- Loss: 0.1136365681886673
train-epoch-step: 22-67 -- Loss: 0.1319340616464615
train-epoch-step: 22-68 -- Loss: 0.2240329086780548
train-epoch-step: 22-69 -- Loss: 0.1269608736038208
train-epoch-step: 22-70 -- Loss: 0.23973160982131958
train-epoch-step: 22-71 -- Loss: 0.27071988582611084
train-epoch-step: 22-72 -- Loss: 0.1887609213590622
train-epoch-step: 22-73 -- Loss: 0.24188119173049927
train-epoch-step: 22-74 -- Loss: 0.10207285732030869
train-epoch-step: 22-75 -- Loss: 0.13299818336963654
train-epoch-step: 22-76 -- Loss: 0.15248242020606995
train-epoch-step: 22-77 -- Loss: 0.23861064016819
train-epoch-step: 22-78 -- Loss: 0.28146275877952576
train-epoch-step: 22-79 -- Loss: 0.2016632854938507
train-epoch-step: 22-80 -- Loss: 0.2824832797050476
train-epoch-step: 22-81 -- Loss: 0.13431526720523834
train-epoch-step: 22-82 -- Loss: 0.2570546567440033
train-epoch-step: 22-83 -- Loss: 0.19049003720283508
train-epoch-step: 22-84 -- Loss: 0.19586363434791565
train-epoch-step: 22-85 -- Loss: 0.18225789070129395
train-epoch-step: 22-86 -- Loss: 0.13038282096385956
train-epoch-step: 22-87 -- Loss: 0.24291744828224182
train-epoch-step: 22-88 -- Loss: 0.14589345455169678
train-epoch-step: 22-89 -- Loss: 0.1895555853843689
train-epoch-step: 22-90 -- Loss: 0.19678911566734314
train-epoch-step: 22-91 -- Loss: 0.25408047437667847
train-epoch-step: 22-92 -- Loss: 0.1628025770187378
train-epoch-step: 22-93 -- Loss: 0.1943882405757904
train-epoch-step: 22-94 -- Loss: 0.2338646799325943
train-epoch-step: 22-95 -- Loss: 0.20262043178081512
train-epoch-step: 22-96 -- Loss: 0.22408293187618256
train-epoch-step: 22-97 -- Loss: 0.19254064559936523
train-epoch-step: 22-98 -- Loss: 0.1623886078596115
train-epoch-step: 22-99 -- Loss: 0.19998201727867126
train-epoch-step: 22-100 -- Loss: 0.19495099782943726
train-epoch-step: 22-101 -- Loss: 0.2871716618537903
train-epoch-step: 22-102 -- Loss: 0.2341330349445343
train-epoch-step: 22-103 -- Loss: 0.19588786363601685
train-epoch-step: 22-104 -- Loss: 0.15405459702014923
train-epoch-step: 22-105 -- Loss: 0.29081106185913086
train-epoch-step: 22-106 -- Loss: 0.17988239228725433
train-epoch-step: 22-107 -- Loss: 0.19334405660629272
train-epoch-step: 22-108 -- Loss: 0.19590841233730316
train-epoch-step: 22-109 -- Loss: 0.15846703946590424
train-epoch-step: 22-110 -- Loss: 0.18830034136772156
train-epoch-step: 22-111 -- Loss: 0.1942625194787979
train-epoch-step: 22-112 -- Loss: 0.17521017789840698
train-epoch-step: 22-113 -- Loss: 0.16769228875637054
train-epoch-step: 22-114 -- Loss: 0.20356491208076477
train-epoch-step: 22-115 -- Loss: 0.16925205290317535
train-epoch-step: 22-116 -- Loss: 0.14501053094863892
train-epoch-step: 22-117 -- Loss: 0.1303810179233551
train-epoch-step: 22-118 -- Loss: 0.2038988620042801
train-epoch-step: 22-119 -- Loss: 0.16326278448104858
train-epoch-step: 22-120 -- Loss: 0.26075881719589233
train-epoch-step: 22-121 -- Loss: 0.26524314284324646
train-epoch-step: 22-122 -- Loss: 0.2280004769563675
train-epoch-step: 22-123 -- Loss: 0.21705085039138794
train-epoch-step: 22-124 -- Loss: 0.1348917931318283
train-epoch-step: 22-125 -- Loss: 0.16180524230003357
train-epoch-step: 22-126 -- Loss: 0.2369382381439209
train-epoch-step: 22-127 -- Loss: 0.19246980547904968
train-epoch-step: 22-128 -- Loss: 0.1775006353855133
train-epoch-step: 22-129 -- Loss: 0.15436185896396637
train-epoch-step: 22-130 -- Loss: 0.19771763682365417
train-epoch-step: 22-131 -- Loss: 0.1453038454055786
train-epoch-step: 22-132 -- Loss: 0.21212366223335266
train-epoch-step: 22-133 -- Loss: 0.12137504667043686
train-epoch-step: 22-134 -- Loss: 0.2084813117980957
train-epoch-step: 22-135 -- Loss: 0.14056557416915894
train-epoch-step: 22-136 -- Loss: 0.1368105262517929
train-epoch-step: 22-137 -- Loss: 0.2529134750366211
train-epoch-step: 22-138 -- Loss: 0.27870261669158936
train-epoch-step: 22-139 -- Loss: 0.1398453712463379
train-epoch-step: 22-140 -- Loss: 0.21529081463813782
train-epoch-step: 22-141 -- Loss: 0.24588635563850403
train-epoch-step: 22-142 -- Loss: 0.21006974577903748
train-epoch-step: 22-143 -- Loss: 0.19153590500354767
train-epoch-step: 22-144 -- Loss: 0.20021793246269226
train-epoch-step: 22-145 -- Loss: 0.1489194631576538
train-epoch-step: 22-146 -- Loss: 0.18708539009094238
train-epoch-step: 22-147 -- Loss: 0.1805259883403778
train-epoch-step: 22-148 -- Loss: 0.16982363164424896
train-epoch-step: 22-149 -- Loss: 0.12418228387832642
train-epoch-step: 22-150 -- Loss: 0.19253797829151154
train-epoch-step: 22-151 -- Loss: 0.19441846013069153
train-epoch-step: 22-152 -- Loss: 0.19554638862609863
train-epoch-step: 22-153 -- Loss: 0.2765728235244751
train-epoch-step: 22-154 -- Loss: 0.14324592053890228
train-epoch-step: 22-155 -- Loss: 0.14304132759571075
train-epoch-step: 22-156 -- Loss: 0.1274927258491516
train-epoch-step: 22-157 -- Loss: 0.17860546708106995
train-epoch-step: 22-158 -- Loss: 0.17118757963180542
train-epoch-step: 22-159 -- Loss: 0.1838018149137497
train-epoch-step: 22-160 -- Loss: 0.2337893843650818
train-epoch-step: 22-161 -- Loss: 0.21323460340499878
train-epoch-step: 22-162 -- Loss: 0.22907669842243195
train-epoch-step: 22-163 -- Loss: 0.2012811303138733
train-epoch-step: 22-164 -- Loss: 0.1986711472272873
train-epoch-step: 22-165 -- Loss: 0.17645934224128723
train-epoch-step: 22-166 -- Loss: 0.1334603875875473
train-epoch-step: 22-167 -- Loss: 0.13803036510944366
train-epoch-step: 22-168 -- Loss: 0.2094765603542328
train-epoch-step: 22-169 -- Loss: 0.1526062786579132
train-epoch-step: 22-170 -- Loss: 0.21138018369674683
train-epoch-step: 22-171 -- Loss: 0.14866888523101807
train-epoch-step: 22-172 -- Loss: 0.2734975218772888
train-epoch-step: 22-173 -- Loss: 0.1420283168554306
train-epoch-step: 22-174 -- Loss: 0.2628379762172699
train-epoch-step: 22-175 -- Loss: 0.18880707025527954
train-epoch-step: 22-176 -- Loss: 0.14397062361240387
train-epoch-step: 22-177 -- Loss: 0.19488196074962616
train-epoch-step: 22-178 -- Loss: 0.19214382767677307
train-epoch-step: 22-179 -- Loss: 0.15438444912433624
train-epoch-step: 22-180 -- Loss: 0.16006436944007874
train-epoch-step: 22-181 -- Loss: 0.17418086528778076
train-epoch-step: 22-182 -- Loss: 0.18651054799556732
train-epoch-step: 22-183 -- Loss: 0.28913944959640503
train-epoch-step: 22-184 -- Loss: 0.14999589323997498
train-epoch-step: 22-185 -- Loss: 0.15171048045158386
train-epoch-step: 22-186 -- Loss: 0.19868609309196472
train-epoch-step: 22-187 -- Loss: 0.22160722315311432
train-epoch-step: 22-188 -- Loss: 0.1842144876718521
train-epoch-step: 22-189 -- Loss: 0.11249326914548874
train-epoch-step: 22-190 -- Loss: 0.188358873128891
train-epoch-step: 22-191 -- Loss: 0.17945578694343567
train-epoch-step: 22-192 -- Loss: 0.24170070886611938
train-epoch-step: 22-193 -- Loss: 0.22611340880393982
train-epoch-step: 22-194 -- Loss: 0.19444917142391205
train-epoch-step: 22-195 -- Loss: 0.1740710288286209
train-epoch-step: 22-196 -- Loss: 0.18276122212409973
train-epoch-step: 22-197 -- Loss: 0.14370501041412354
train-epoch-step: 22-198 -- Loss: 0.1375577449798584
train-epoch-step: 22-199 -- Loss: 0.1569850742816925
train-epoch-step: 22-200 -- Loss: 0.12837015092372894
train-epoch-step: 22-201 -- Loss: 0.21120470762252808
train-epoch-step: 22-202 -- Loss: 0.13899198174476624
train-epoch-step: 22-203 -- Loss: 0.1830201894044876
train-epoch-step: 22-204 -- Loss: 0.14680171012878418
train-epoch-step: 22-205 -- Loss: 0.19581902027130127
train-epoch-step: 22-206 -- Loss: 0.20339399576187134
train-epoch-step: 22-207 -- Loss: 0.1365050971508026
train-epoch-step: 22-208 -- Loss: 0.1874694973230362
train-epoch-step: 22-209 -- Loss: 0.1493680626153946
train-epoch-step: 22-210 -- Loss: 0.1412053257226944
train-epoch-step: 22-211 -- Loss: 0.2236434519290924
train-epoch-step: 22-212 -- Loss: 0.20666465163230896
train-epoch-step: 22-213 -- Loss: 0.13230648636817932
train-epoch-step: 22-214 -- Loss: 0.1608343869447708
train-epoch-step: 22-215 -- Loss: 0.1387704461812973
train-epoch-step: 22-216 -- Loss: 0.2081247717142105
train-epoch-step: 22-217 -- Loss: 0.2201356291770935
train-epoch-step: 22-218 -- Loss: 0.15407554805278778
train-epoch-step: 22-219 -- Loss: 0.18192696571350098
train-epoch-step: 22-220 -- Loss: 0.13970905542373657
train-epoch-step: 22-221 -- Loss: 0.21260406076908112
train-epoch-step: 22-222 -- Loss: 0.1266515851020813
train-epoch-step: 22-223 -- Loss: 0.18055428564548492
train-epoch-step: 22-224 -- Loss: 0.2001613825559616
train-epoch-step: 22-225 -- Loss: 0.2970527708530426
train-epoch-step: 22-226 -- Loss: 0.22188353538513184
train-epoch-step: 22-227 -- Loss: 0.23103854060173035
train-epoch-step: 22-228 -- Loss: 0.1850416362285614
train-epoch-step: 22-229 -- Loss: 0.17884188890457153
train-epoch-step: 22-230 -- Loss: 0.17080426216125488
train-epoch-step: 22-231 -- Loss: 0.16124926507472992
train-epoch-step: 22-232 -- Loss: 0.20592252910137177
train-epoch-step: 22-233 -- Loss: 0.08820061385631561
train-epoch-step: 22-234 -- Loss: 0.19140198826789856
train-epoch-step: 22-235 -- Loss: 0.15392082929611206
train-epoch-step: 22-236 -- Loss: 0.18668928742408752
train-epoch-step: 22-237 -- Loss: 0.25174185633659363
train-epoch-step: 22-238 -- Loss: 0.16178223490715027
train-epoch-step: 22-239 -- Loss: 0.1357746422290802
train-epoch-step: 22-240 -- Loss: 0.22978153824806213
train-epoch-step: 22-241 -- Loss: 0.1608688235282898
train-epoch-step: 22-242 -- Loss: 0.23153376579284668
train-epoch-step: 22-243 -- Loss: 0.24413490295410156
train-epoch-step: 22-244 -- Loss: 0.21113839745521545
train-epoch-step: 22-245 -- Loss: 0.21574687957763672
train-epoch-step: 22-246 -- Loss: 0.23094582557678223
train-epoch-step: 22-247 -- Loss: 0.22665636241436005
train-epoch-step: 22-248 -- Loss: 0.1913101077079773
train-epoch-step: 22-249 -- Loss: 0.14938072860240936
train-epoch-step: 22-250 -- Loss: 0.2241365760564804
train-epoch-step: 22-251 -- Loss: 0.11592677235603333
train-epoch-step: 22-252 -- Loss: 0.20079408586025238
train-epoch-step: 22-253 -- Loss: 0.14110241830348969
train-epoch-step: 22-254 -- Loss: 0.22042900323867798
train-epoch-step: 22-255 -- Loss: 0.15548363327980042
train-epoch-step: 22-256 -- Loss: 0.15343612432479858
train-epoch-step: 22-257 -- Loss: 0.20049796998500824
train-epoch-step: 22-258 -- Loss: 0.1525837928056717
train-epoch-step: 22-259 -- Loss: 0.13098753988742828
train-epoch-step: 22-260 -- Loss: 0.2256680130958557
train-epoch-step: 22-261 -- Loss: 0.18176797032356262
train-epoch-step: 22-262 -- Loss: 0.321977436542511
train-epoch-step: 22-263 -- Loss: 0.20732751488685608
train-epoch-step: 22-264 -- Loss: 0.17930229008197784
train-epoch-step: 22-265 -- Loss: 0.14314980804920197
train-epoch-step: 22-266 -- Loss: 0.16236555576324463
train-epoch-step: 22-267 -- Loss: 0.14221158623695374
train-epoch-step: 22-268 -- Loss: 0.12684784829616547
train-epoch-step: 22-269 -- Loss: 0.17913077771663666
train-epoch-step: 22-270 -- Loss: 0.11161825805902481
train-epoch-step: 22-271 -- Loss: 0.15529125928878784
train-epoch-step: 22-272 -- Loss: 0.1180339977145195
train-epoch-step: 22-273 -- Loss: 0.1376931369304657
train-epoch-step: 22-274 -- Loss: 0.19959300756454468
train-epoch-step: 22-275 -- Loss: 0.21525263786315918
train-epoch-step: 22-276 -- Loss: 0.16931621730327606
train-epoch-step: 22-277 -- Loss: 0.16127029061317444
train-epoch-step: 22-278 -- Loss: 0.15183939039707184
train-epoch-step: 22-279 -- Loss: 0.15722429752349854
train-epoch-step: 22-280 -- Loss: 0.23584827780723572
train-epoch-step: 22-281 -- Loss: 0.1866920292377472
train-epoch-step: 22-282 -- Loss: 0.1483992338180542
train-epoch-step: 22-283 -- Loss: 0.12332256883382797
train-epoch-step: 22-284 -- Loss: 0.14233863353729248
train-epoch-step: 22-285 -- Loss: 0.20468206703662872
train-epoch-step: 22-286 -- Loss: 0.16141557693481445
train-epoch-step: 22-287 -- Loss: 0.21908941864967346
train-epoch-step: 22-288 -- Loss: 0.09944524616003036
train-epoch-step: 22-289 -- Loss: 0.1279466152191162
train-epoch-step: 22-290 -- Loss: 0.18923026323318481
train-epoch-step: 22-291 -- Loss: 0.12508979439735413
train-epoch-step: 22-292 -- Loss: 0.15927767753601074
train-epoch-step: 22-293 -- Loss: 0.1424938589334488
train-epoch-step: 22-294 -- Loss: 0.17673492431640625
train-epoch-step: 22-295 -- Loss: 0.28610163927078247
train-epoch-step: 22-296 -- Loss: 0.1640310436487198
train-epoch-step: 22-297 -- Loss: 0.17795658111572266
train-epoch-step: 22-298 -- Loss: 0.23872917890548706
train-epoch-step: 22-299 -- Loss: 0.1560608446598053
train-epoch-step: 22-300 -- Loss: 0.17202115058898926
train-epoch-step: 22-301 -- Loss: 0.17867258191108704
train-epoch-step: 22-302 -- Loss: 0.2299799621105194
train-epoch-step: 22-303 -- Loss: 0.21428349614143372
train-epoch-step: 22-304 -- Loss: 0.13703873753547668
train-epoch-step: 22-305 -- Loss: 0.14848819375038147
train-epoch-step: 22-306 -- Loss: 0.253592312335968
train-epoch-step: 22-307 -- Loss: 0.1718665361404419
train-epoch-step: 22-308 -- Loss: 0.23073002696037292
train-epoch-step: 22-309 -- Loss: 0.1617722362279892
train-epoch-step: 22-310 -- Loss: 0.17083397507667542
train-epoch-step: 22-311 -- Loss: 0.173219233751297
train-epoch-step: 22-312 -- Loss: 0.22335277497768402
train-epoch-step: 22-313 -- Loss: 0.10753042995929718
train-epoch-step: 22-314 -- Loss: 0.2083008736371994
train-epoch-step: 22-315 -- Loss: 0.1716768443584442
train-epoch-step: 22-316 -- Loss: 0.1554674208164215
train-epoch-step: 22-317 -- Loss: 0.16284632682800293
train-epoch-step: 22-318 -- Loss: 0.1705961525440216
train-epoch-step: 22-319 -- Loss: 0.1853702813386917
train-epoch-step: 22-320 -- Loss: 0.12112440168857574
train-epoch-step: 22-321 -- Loss: 0.13514992594718933
train-epoch-step: 22-322 -- Loss: 0.22078581154346466
train-epoch-step: 22-323 -- Loss: 0.17260341346263885
train-epoch-step: 22-324 -- Loss: 0.2689540386199951
train-epoch-step: 22-325 -- Loss: 0.16388168931007385
train-epoch-step: 22-326 -- Loss: 0.17582593858242035
train-epoch-step: 22-327 -- Loss: 0.21892817318439484
train-epoch-step: 22-328 -- Loss: 0.20491339266300201
train-epoch-step: 22-329 -- Loss: 0.3433728814125061
train-epoch-step: 22-330 -- Loss: 0.3629385232925415
train-epoch-step: 22-331 -- Loss: 0.2201704978942871
train-epoch-step: 22-332 -- Loss: 0.1066974401473999
train-epoch-step: 22-333 -- Loss: 0.1973886787891388
train-epoch-step: 22-334 -- Loss: 0.16024012863636017
train-epoch-step: 22-335 -- Loss: 0.18254952132701874
train-epoch-step: 22-336 -- Loss: 0.16053424775600433
train-epoch-step: 22-337 -- Loss: 0.21896766126155853
train-epoch-step: 22-338 -- Loss: 0.16088621318340302
train-epoch-step: 22-339 -- Loss: 0.14533130824565887
train-epoch-step: 22-340 -- Loss: 0.20976167917251587
train-epoch-step: 22-341 -- Loss: 0.1494593322277069
train-epoch-step: 22-342 -- Loss: 0.17291298508644104
train-epoch-step: 22-343 -- Loss: 0.15962433815002441
train-epoch-step: 22-344 -- Loss: 0.1849239021539688
train-epoch-step: 22-345 -- Loss: 0.13555744290351868
train-epoch-step: 22-346 -- Loss: 0.21891075372695923
train-epoch-step: 22-347 -- Loss: 0.1594584882259369
train-epoch-step: 22-348 -- Loss: 0.21408696472644806
train-epoch-step: 22-349 -- Loss: 0.21381297707557678
train-epoch-step: 22-350 -- Loss: 0.2858011722564697
train-epoch-step: 22-351 -- Loss: 0.2038845717906952
train-epoch-step: 22-352 -- Loss: 0.13550108671188354
train-epoch-step: 22-353 -- Loss: 0.19796070456504822
train-epoch-step: 22-354 -- Loss: 0.29341360926628113
train-epoch-step: 22-355 -- Loss: 0.12267911434173584
train-epoch-step: 22-356 -- Loss: 0.12109220027923584
train-epoch-step: 22-357 -- Loss: 0.2004663050174713
train-epoch-step: 22-358 -- Loss: 0.19217975437641144
train-epoch-step: 22-359 -- Loss: 0.1532348096370697
train-epoch-step: 22-360 -- Loss: 0.12310303747653961
train-epoch-step: 22-361 -- Loss: 0.25275668501853943
train-epoch-step: 22-362 -- Loss: 0.1757296770811081
train-epoch-step: 22-363 -- Loss: 0.1235436350107193
train-epoch-step: 22-364 -- Loss: 0.19127269089221954
train-epoch-step: 22-365 -- Loss: 0.18229693174362183
train-epoch-step: 22-366 -- Loss: 0.21755684912204742
train-epoch-step: 22-367 -- Loss: 0.24191798269748688
train-epoch-step: 22-368 -- Loss: 0.21335653960704803
train-epoch-step: 22-369 -- Loss: 0.28896936774253845
train-epoch-step: 22-370 -- Loss: 0.12917256355285645
train-epoch-step: 22-371 -- Loss: 0.12450550496578217
train-epoch-step: 22-372 -- Loss: 0.15929850935935974
train-epoch-step: 22-373 -- Loss: 0.20630063116550446
train-epoch-step: 22-374 -- Loss: 0.16549208760261536
train-epoch-step: 22-375 -- Loss: 0.2804599702358246
train-epoch-step: 22-376 -- Loss: 0.16807669401168823
train-epoch-step: 22-377 -- Loss: 0.24539154767990112
train-epoch-step: 22-378 -- Loss: 0.21739381551742554
train-epoch-step: 22-379 -- Loss: 0.12657003104686737
train-epoch-step: 22-380 -- Loss: 0.09681139886379242
train-epoch-step: 22-381 -- Loss: 0.25981587171554565
train-epoch-step: 22-382 -- Loss: 0.24395859241485596
train-epoch-step: 22-383 -- Loss: 0.1859978586435318
train-epoch-step: 22-384 -- Loss: 0.24294959008693695
train-epoch-step: 22-385 -- Loss: 0.2001432478427887
train-epoch-step: 22-386 -- Loss: 0.19747799634933472
train-epoch-step: 22-387 -- Loss: 0.2188197672367096
train-epoch-step: 22-388 -- Loss: 0.2197847068309784
train-epoch-step: 22-389 -- Loss: 0.18361857533454895
train-epoch-step: 22-390 -- Loss: 0.1525011956691742
train-epoch-step: 22-391 -- Loss: 0.154404878616333
train-epoch-step: 22-392 -- Loss: 0.1937040090560913
train-epoch-step: 22-393 -- Loss: 0.16438186168670654
train-epoch-step: 22-394 -- Loss: 0.22314879298210144
train-epoch-step: 22-395 -- Loss: 0.17236700654029846
train-epoch-step: 22-396 -- Loss: 0.1346072107553482
train-epoch-step: 22-397 -- Loss: 0.13181546330451965
train-epoch-step: 22-398 -- Loss: 0.20581918954849243
train-epoch-step: 22-399 -- Loss: 0.187151700258255
train-epoch-step: 22-400 -- Loss: 0.3014163374900818
train-epoch-step: 22-401 -- Loss: 0.12649907171726227
train-epoch-step: 22-402 -- Loss: 0.2657936215400696
train-epoch-step: 22-403 -- Loss: 0.17292660474777222
train-epoch-step: 22-404 -- Loss: 0.146689772605896
train-epoch-step: 22-405 -- Loss: 0.14810699224472046
train-epoch-step: 22-406 -- Loss: 0.17796817421913147
train-epoch-step: 22-407 -- Loss: 0.12275964021682739
train-epoch-step: 22-408 -- Loss: 0.17023788392543793
train-epoch-step: 22-409 -- Loss: 0.17861810326576233
train-epoch-step: 22-410 -- Loss: 0.18375810980796814
train-epoch-step: 22-411 -- Loss: 0.2128468006849289
train-epoch-step: 22-412 -- Loss: 0.1386234313249588
train-epoch-step: 22-413 -- Loss: 0.15333083271980286
train-epoch-step: 22-414 -- Loss: 0.13978740572929382
train-epoch-step: 22-415 -- Loss: 0.1416802853345871
train-epoch-step: 22-416 -- Loss: 0.2671828269958496
train-epoch-step: 22-417 -- Loss: 0.19983580708503723
train-epoch-step: 22-418 -- Loss: 0.24444931745529175
train-epoch-step: 22-419 -- Loss: 0.17239664494991302
train-epoch-step: 22-420 -- Loss: 0.16980870068073273
train-epoch-step: 22-421 -- Loss: 0.18862450122833252
train-epoch-step: 22-422 -- Loss: 0.15583783388137817
train-epoch-step: 22-423 -- Loss: 0.18587811291217804
train-epoch-step: 22-424 -- Loss: 0.14281243085861206
train-epoch-step: 22-425 -- Loss: 0.18918748199939728
train-epoch-step: 22-426 -- Loss: 0.16331402957439423
train-epoch-step: 22-427 -- Loss: 0.1254984736442566
train-epoch-step: 22-428 -- Loss: 0.20487771928310394
train-epoch-step: 22-429 -- Loss: 0.18114016950130463
train-epoch-step: 22-430 -- Loss: 0.14458012580871582
train-epoch-step: 22-431 -- Loss: 0.17330172657966614
train-epoch-step: 22-432 -- Loss: 0.24615664780139923
train-epoch-step: 22-433 -- Loss: 0.13999110460281372
train-epoch-step: 22-434 -- Loss: 0.1335269808769226
train-epoch-step: 22-435 -- Loss: 0.16114859282970428
train-epoch-step: 22-436 -- Loss: 0.16596058011054993
train-epoch-step: 22-437 -- Loss: 0.1404186338186264
train-epoch-step: 22-438 -- Loss: 0.17521969974040985
train-epoch-step: 22-439 -- Loss: 0.2734653353691101
train-epoch-step: 22-440 -- Loss: 0.13593819737434387
train-epoch-step: 22-441 -- Loss: 0.2154654860496521
train-epoch-step: 22-442 -- Loss: 0.18957391381263733
train-epoch-step: 22-443 -- Loss: 0.16361430287361145
train-epoch-step: 22-444 -- Loss: 0.1808595061302185
train-epoch-step: 22-445 -- Loss: 0.18833880126476288
train-epoch-step: 22-446 -- Loss: 0.16011886298656464
train-epoch-step: 22-447 -- Loss: 0.19792130589485168
train-epoch-step: 22-448 -- Loss: 0.2282547652721405
train-epoch-step: 22-449 -- Loss: 0.20920051634311676
train-epoch-step: 22-450 -- Loss: 0.19121518731117249
train-epoch-step: 22-451 -- Loss: 0.14894023537635803
train-epoch-step: 22-452 -- Loss: 0.13845637440681458
train-epoch-step: 22-453 -- Loss: 0.10157566517591476
train-epoch-step: 22-454 -- Loss: 0.23283971846103668
train-epoch-step: 22-455 -- Loss: 0.13243187963962555
train-epoch-step: 22-456 -- Loss: 0.1250336468219757
train-epoch-step: 22-457 -- Loss: 0.22457215189933777
train-epoch-step: 22-458 -- Loss: 0.1548311710357666
train-epoch-step: 22-459 -- Loss: 0.22932223975658417
train-epoch-step: 22-460 -- Loss: 0.13047124445438385
train-epoch-step: 22-461 -- Loss: 0.14100432395935059
train-epoch-step: 22-462 -- Loss: 0.16872072219848633
train-epoch-step: 22-463 -- Loss: 0.14188900589942932
train-epoch-step: 22-464 -- Loss: 0.17210015654563904
train-epoch-step: 22-465 -- Loss: 0.2457137405872345
train-epoch-step: 22-466 -- Loss: 0.213202103972435
train-epoch-step: 22-467 -- Loss: 0.1172533929347992
train-epoch-step: 22-468 -- Loss: 0.17316044867038727
train-epoch-step: 22-469 -- Loss: 0.22227951884269714
train-epoch-step: 22-470 -- Loss: 0.19302333891391754
train-epoch-step: 22-471 -- Loss: 0.16169343888759613
train-epoch-step: 22-472 -- Loss: 0.15987518429756165
train-epoch-step: 22-473 -- Loss: 0.15858280658721924
train-epoch-step: 22-474 -- Loss: 0.12376274168491364
train-epoch-step: 22-475 -- Loss: 0.12235195189714432
train-epoch-step: 22-476 -- Loss: 0.20735862851142883
train-epoch-step: 22-477 -- Loss: 0.22457294166088104
train-epoch-step: 22-478 -- Loss: 0.19701851904392242
train-epoch-step: 22-479 -- Loss: 0.1498231440782547
train-epoch-step: 22-480 -- Loss: 0.19658109545707703
train-epoch-step: 22-481 -- Loss: 0.28814148902893066
train-epoch-step: 22-482 -- Loss: 0.26005086302757263
train-epoch-step: 22-483 -- Loss: 0.194585919380188
train-epoch-step: 22-484 -- Loss: 0.2278691828250885
train-epoch-step: 22-485 -- Loss: 0.1316870003938675
train-epoch-step: 22-486 -- Loss: 0.24329394102096558
train-epoch-step: 22-487 -- Loss: 0.24202561378479004
train-epoch-step: 22-488 -- Loss: 0.1996799111366272
train-epoch-step: 22-489 -- Loss: 0.2283606082201004
train-epoch-step: 22-490 -- Loss: 0.14859497547149658
train-epoch-step: 22-491 -- Loss: 0.1412244737148285
train-epoch-step: 22-492 -- Loss: 0.13070866465568542
train-epoch-step: 22-493 -- Loss: 0.21386529505252838
train-epoch-step: 22-494 -- Loss: 0.21613910794258118
train-epoch-step: 22-495 -- Loss: 0.20787551999092102
train-epoch-step: 22-496 -- Loss: 0.14597178995609283
train-epoch-step: 22-497 -- Loss: 0.18961204588413239
train-epoch-step: 22-498 -- Loss: 0.15217292308807373
train-epoch-step: 22-499 -- Loss: 0.17301148176193237
train-epoch-step: 22-500 -- Loss: 0.16099460422992706
train-epoch-step: 22-501 -- Loss: 0.21353350579738617
train-epoch-step: 22-502 -- Loss: 0.16266781091690063
train-epoch-step: 22-503 -- Loss: 0.23406991362571716
train-epoch-step: 22-504 -- Loss: 0.1333368420600891
train-epoch-step: 22-505 -- Loss: 0.17604926228523254
train-epoch-step: 22-506 -- Loss: 0.12239112704992294
train-epoch-step: 22-507 -- Loss: 0.19289454817771912
train-epoch-step: 22-508 -- Loss: 0.1804865151643753
train-epoch-step: 22-509 -- Loss: 0.17481398582458496
train-epoch-step: 22-510 -- Loss: 0.13417504727840424
train-epoch-step: 22-511 -- Loss: 0.22250519692897797
train-epoch-step: 22-512 -- Loss: 0.1765008270740509
train-epoch-step: 22-513 -- Loss: 0.20700058341026306
train-epoch-step: 22-514 -- Loss: 0.151168555021286
train-epoch-step: 22-515 -- Loss: 0.16743671894073486
train-epoch-step: 22-516 -- Loss: 0.1734761893749237
train-epoch-step: 22-517 -- Loss: 0.17604105174541473
train-epoch-step: 22-518 -- Loss: 0.14567942917346954
train-epoch-step: 22-519 -- Loss: 0.14057108759880066
train-epoch-step: 22-520 -- Loss: 0.19739791750907898
train-epoch-step: 22-521 -- Loss: 0.23239544034004211
train-epoch-step: 22-522 -- Loss: 0.18747255206108093
train-epoch-step: 22-523 -- Loss: 0.1610950231552124
train-epoch-step: 22-524 -- Loss: 0.17248141765594482
train-epoch-step: 22-525 -- Loss: 0.19320063292980194
train-epoch-step: 22-526 -- Loss: 0.13490954041481018
train-epoch-step: 22-527 -- Loss: 0.16581277549266815
train-epoch-step: 22-528 -- Loss: 0.16266852617263794
train-epoch-step: 22-529 -- Loss: 0.16293270885944366
train-epoch-step: 22-530 -- Loss: 0.16837933659553528
train-epoch-step: 22-531 -- Loss: 0.20298530161380768
train-epoch-step: 22-532 -- Loss: 0.1782059520483017
train-epoch-step: 22-533 -- Loss: 0.1749517172574997
train-epoch-step: 22-534 -- Loss: 0.14015308022499084
train-epoch-step: 22-535 -- Loss: 0.2856457829475403
train-epoch-step: 22-536 -- Loss: 0.16063779592514038
train-epoch-step: 22-537 -- Loss: 0.1515989601612091
train-epoch-step: 22-538 -- Loss: 0.10749489814043045
train-epoch-step: 22-539 -- Loss: 0.2003355324268341
train-epoch-step: 22-540 -- Loss: 0.1412290334701538
train-epoch-step: 22-541 -- Loss: 0.2150019407272339
train-epoch-step: 22-542 -- Loss: 0.26158270239830017
train-epoch-step: 22-543 -- Loss: 0.17461146414279938
train-epoch-step: 22-544 -- Loss: 0.23638398945331573
train-epoch-step: 22-545 -- Loss: 0.2022572010755539
train-epoch-step: 22-546 -- Loss: 0.2184290736913681
train-epoch-step: 22-547 -- Loss: 0.19591619074344635
train-epoch-step: 22-548 -- Loss: 0.09813860058784485
train-epoch-step: 22-549 -- Loss: 0.1593089997768402
train-epoch-step: 22-550 -- Loss: 0.213241308927536
train-epoch-step: 22-551 -- Loss: 0.16567450761795044
train-epoch-step: 22-552 -- Loss: 0.14269877970218658
train-epoch-step: 22-553 -- Loss: 0.201328307390213
train-epoch-step: 22-554 -- Loss: 0.22240900993347168
train-epoch-step: 22-555 -- Loss: 0.24503926932811737
train-epoch-step: 22-556 -- Loss: 0.1762547791004181
train-epoch-step: 22-557 -- Loss: 0.26305797696113586
train-epoch-step: 22-558 -- Loss: 0.24583940207958221
train-epoch-step: 22-559 -- Loss: 0.1473664939403534
train-epoch-step: 22-560 -- Loss: 0.2174532115459442
train-epoch-step: 22-561 -- Loss: 0.20339080691337585
train-epoch-step: 22-562 -- Loss: 0.1836264729499817
train-epoch-step: 22-563 -- Loss: 0.19935953617095947
train-epoch-step: 22-564 -- Loss: 0.10797283053398132
train-epoch-step: 22-565 -- Loss: 0.19700554013252258
train-epoch-step: 22-566 -- Loss: 0.1719467043876648
train-epoch-step: 22-567 -- Loss: 0.22220134735107422
train-epoch-step: 22-568 -- Loss: 0.15911419689655304
train-epoch-step: 22-569 -- Loss: 0.25449079275131226
train-epoch-step: 22-570 -- Loss: 0.18083299696445465
train-epoch-step: 22-571 -- Loss: 0.2235213667154312
train-epoch-step: 22-572 -- Loss: 0.2515276074409485
train-epoch-step: 22-573 -- Loss: 0.21100641787052155
train-epoch-step: 22-574 -- Loss: 0.26085489988327026
train-epoch-step: 22-575 -- Loss: 0.31639155745506287
train-epoch-step: 22-576 -- Loss: 0.12603533267974854
train-epoch-step: 22-577 -- Loss: 0.18316413462162018
train-epoch-step: 22-578 -- Loss: 0.22780126333236694
train-epoch-step: 22-579 -- Loss: 0.17239192128181458
train-epoch-step: 22-580 -- Loss: 0.19132326543331146
train-epoch-step: 22-581 -- Loss: 0.15171568095684052
train-epoch-step: 22-582 -- Loss: 0.21438968181610107
train-epoch-step: 22-583 -- Loss: 0.22550520300865173
train-epoch-step: 22-584 -- Loss: 0.1810983121395111
train-epoch-step: 22-585 -- Loss: 0.20065301656723022
train-epoch-step: 22-586 -- Loss: 0.2666187286376953
train-epoch-step: 22-587 -- Loss: 0.16924075782299042
train-epoch-step: 22-588 -- Loss: 0.13592809438705444
val-epoch-step: 22-589 -- Loss: 0.2155725359916687
val-epoch-step: 22-590 -- Loss: 0.15822362899780273
val-epoch-step: 22-591 -- Loss: 0.2492525428533554
val-epoch-step: 22-592 -- Loss: 0.18137311935424805
val-epoch-step: 22-593 -- Loss: 0.16198867559432983
val-epoch-step: 22-594 -- Loss: 0.39273601770401
val-epoch-step: 22-595 -- Loss: 0.1851707100868225
val-epoch-step: 22-596 -- Loss: 0.20592166483402252
val-epoch-step: 22-597 -- Loss: 0.18606902658939362
val-epoch-step: 22-598 -- Loss: 0.1592690795660019
val-epoch-step: 22-599 -- Loss: 0.18675266206264496
val-epoch-step: 22-600 -- Loss: 0.2366344928741455
val-epoch-step: 22-601 -- Loss: 0.17291328310966492
val-epoch-step: 22-602 -- Loss: 0.1492270529270172
val-epoch-step: 22-603 -- Loss: 0.20673498511314392
val-epoch-step: 22-604 -- Loss: 0.1643662452697754
val-epoch-step: 22-605 -- Loss: 0.15273621678352356
val-epoch-step: 22-606 -- Loss: 0.3024137318134308
val-epoch-step: 22-607 -- Loss: 0.136092871427536
val-epoch-step: 22-608 -- Loss: 0.25837746262550354
val-epoch-step: 22-609 -- Loss: 0.18201404809951782
val-epoch-step: 22-610 -- Loss: 0.1923440545797348
val-epoch-step: 22-611 -- Loss: 0.16218456625938416
val-epoch-step: 22-612 -- Loss: 0.38230741024017334
val-epoch-step: 22-613 -- Loss: 0.1822151094675064
val-epoch-step: 22-614 -- Loss: 0.15970362722873688
val-epoch-step: 22-615 -- Loss: 0.18218296766281128
val-epoch-step: 22-616 -- Loss: 0.16865268349647522
val-epoch-step: 22-617 -- Loss: 0.19629350304603577
val-epoch-step: 22-618 -- Loss: 0.2088671773672104
val-epoch-step: 22-619 -- Loss: 0.2186889350414276
val-epoch-step: 22-620 -- Loss: 0.15950386226177216
val-epoch-step: 22-621 -- Loss: 0.14230762422084808
val-epoch-step: 22-622 -- Loss: 0.15261632204055786
val-epoch-step: 22-623 -- Loss: 0.15710318088531494
val-epoch-step: 22-624 -- Loss: 0.1499122679233551
val-epoch-step: 22-625 -- Loss: 0.16940903663635254
val-epoch-step: 22-626 -- Loss: 0.152134969830513
val-epoch-step: 22-627 -- Loss: 0.19588366150856018
val-epoch-step: 22-628 -- Loss: 0.7105985283851624
val-epoch-step: 22-629 -- Loss: 0.20671643316745758
val-epoch-step: 22-630 -- Loss: 0.3540191054344177
val-epoch-step: 22-631 -- Loss: 0.15433235466480255
val-epoch-step: 22-632 -- Loss: 0.20873203873634338
val-epoch-step: 22-633 -- Loss: 0.16159984469413757
val-epoch-step: 22-634 -- Loss: 0.15434260666370392
val-epoch-step: 22-635 -- Loss: 0.12184591591358185
val-epoch-step: 22-636 -- Loss: 0.19000867009162903
val-epoch-step: 22-637 -- Loss: 0.1926976591348648
val-epoch-step: 22-638 -- Loss: 0.1612803339958191
val-epoch-step: 22-639 -- Loss: 0.2724788784980774
val-epoch-step: 22-640 -- Loss: 0.26305919885635376
val-epoch-step: 22-641 -- Loss: 0.14204652607440948
val-epoch-step: 22-642 -- Loss: 0.19612392783164978
val-epoch-step: 22-643 -- Loss: 0.2118757963180542
val-epoch-step: 22-644 -- Loss: 0.1750127375125885
val-epoch-step: 22-645 -- Loss: 0.2291598916053772
val-epoch-step: 22-646 -- Loss: 0.14213983714580536
val-epoch-step: 22-647 -- Loss: 0.1419745683670044
val-epoch-step: 22-648 -- Loss: 0.16971172392368317
val-epoch-step: 22-649 -- Loss: 0.21444396674633026
val-epoch-step: 22-650 -- Loss: 0.2692945599555969
val-epoch-step: 22-651 -- Loss: 0.15211287140846252
val-epoch-step: 22-652 -- Loss: 0.16516825556755066
val-epoch-step: 22-653 -- Loss: 0.20374193787574768
val-epoch-step: 22-654 -- Loss: 0.11305481195449829
Epoch: 22 -- Train Loss: tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 23-0 -- Loss: 0.24047483503818512
train-epoch-step: 23-1 -- Loss: 0.1509552001953125
train-epoch-step: 23-2 -- Loss: 0.20820316672325134
train-epoch-step: 23-3 -- Loss: 0.15060409903526306
train-epoch-step: 23-4 -- Loss: 0.17034664750099182
train-epoch-step: 23-5 -- Loss: 0.19838199019432068
train-epoch-step: 23-6 -- Loss: 0.2338075339794159
train-epoch-step: 23-7 -- Loss: 0.17900121212005615
train-epoch-step: 23-8 -- Loss: 0.19318947196006775
train-epoch-step: 23-9 -- Loss: 0.24950742721557617
train-epoch-step: 23-10 -- Loss: 0.20564447343349457
train-epoch-step: 23-11 -- Loss: 0.18130221962928772
train-epoch-step: 23-12 -- Loss: 0.16242769360542297
train-epoch-step: 23-13 -- Loss: 0.18645405769348145
train-epoch-step: 23-14 -- Loss: 0.16991133987903595
train-epoch-step: 23-15 -- Loss: 0.16848720610141754
train-epoch-step: 23-16 -- Loss: 0.16708321869373322
train-epoch-step: 23-17 -- Loss: 0.22576560080051422
train-epoch-step: 23-18 -- Loss: 0.20039190351963043
train-epoch-step: 23-19 -- Loss: 0.13997097313404083
train-epoch-step: 23-20 -- Loss: 0.2365054488182068
train-epoch-step: 23-21 -- Loss: 0.2834417521953583
train-epoch-step: 23-22 -- Loss: 0.1522527039051056
train-epoch-step: 23-23 -- Loss: 0.15903925895690918
train-epoch-step: 23-24 -- Loss: 0.13296516239643097
train-epoch-step: 23-25 -- Loss: 0.23800767958164215
train-epoch-step: 23-26 -- Loss: 0.19707627594470978
train-epoch-step: 23-27 -- Loss: 0.23840779066085815
train-epoch-step: 23-28 -- Loss: 0.1262001097202301
train-epoch-step: 23-29 -- Loss: 0.2535102665424347
train-epoch-step: 23-30 -- Loss: 0.11302544176578522
train-epoch-step: 23-31 -- Loss: 0.14354828000068665
train-epoch-step: 23-32 -- Loss: 0.18179476261138916
train-epoch-step: 23-33 -- Loss: 0.2901911735534668
train-epoch-step: 23-34 -- Loss: 0.17931438982486725
train-epoch-step: 23-35 -- Loss: 0.25571638345718384
train-epoch-step: 23-36 -- Loss: 0.1445172131061554
train-epoch-step: 23-37 -- Loss: 0.14614605903625488
train-epoch-step: 23-38 -- Loss: 0.20228257775306702
train-epoch-step: 23-39 -- Loss: 0.22214873135089874
train-epoch-step: 23-40 -- Loss: 0.19785378873348236
train-epoch-step: 23-41 -- Loss: 0.22777609527111053
train-epoch-step: 23-42 -- Loss: 0.16147276759147644
train-epoch-step: 23-43 -- Loss: 0.27983537316322327
train-epoch-step: 23-44 -- Loss: 0.13225732743740082
train-epoch-step: 23-45 -- Loss: 0.13151443004608154
train-epoch-step: 23-46 -- Loss: 0.17910200357437134
train-epoch-step: 23-47 -- Loss: 0.22386576235294342
train-epoch-step: 23-48 -- Loss: 0.16076678037643433
train-epoch-step: 23-49 -- Loss: 0.2343330979347229
train-epoch-step: 23-50 -- Loss: 0.11968646943569183
train-epoch-step: 23-51 -- Loss: 0.19538813829421997
train-epoch-step: 23-52 -- Loss: 0.16995389759540558
train-epoch-step: 23-53 -- Loss: 0.2382086217403412
train-epoch-step: 23-54 -- Loss: 0.29063689708709717
train-epoch-step: 23-55 -- Loss: 0.17035645246505737
train-epoch-step: 23-56 -- Loss: 0.18570782244205475
train-epoch-step: 23-57 -- Loss: 0.24454404413700104
train-epoch-step: 23-58 -- Loss: 0.3027690351009369
train-epoch-step: 23-59 -- Loss: 0.2595917284488678
train-epoch-step: 23-60 -- Loss: 0.13746824860572815
train-epoch-step: 23-61 -- Loss: 0.20580947399139404
train-epoch-step: 23-62 -- Loss: 0.18952235579490662
train-epoch-step: 23-63 -- Loss: 0.1495402604341507
train-epoch-step: 23-64 -- Loss: 0.1557368040084839
train-epoch-step: 23-65 -- Loss: 0.19149848818778992
train-epoch-step: 23-66 -- Loss: 0.12160076200962067
train-epoch-step: 23-67 -- Loss: 0.13289028406143188
train-epoch-step: 23-68 -- Loss: 0.2302730530500412
train-epoch-step: 23-69 -- Loss: 0.12627054750919342
train-epoch-step: 23-70 -- Loss: 0.228223979473114
train-epoch-step: 23-71 -- Loss: 0.2680673897266388
train-epoch-step: 23-72 -- Loss: 0.18951380252838135
train-epoch-step: 23-73 -- Loss: 0.22100558876991272
train-epoch-step: 23-74 -- Loss: 0.10351516306400299
train-epoch-step: 23-75 -- Loss: 0.13990958034992218
train-epoch-step: 23-76 -- Loss: 0.1490151286125183
train-epoch-step: 23-77 -- Loss: 0.23879769444465637
train-epoch-step: 23-78 -- Loss: 0.2836345434188843
train-epoch-step: 23-79 -- Loss: 0.19595947861671448
train-epoch-step: 23-80 -- Loss: 0.27592694759368896
train-epoch-step: 23-81 -- Loss: 0.12863512337207794
train-epoch-step: 23-82 -- Loss: 0.2816673815250397
train-epoch-step: 23-83 -- Loss: 0.19373391568660736
train-epoch-step: 23-84 -- Loss: 0.1970212459564209
train-epoch-step: 23-85 -- Loss: 0.18215589225292206
train-epoch-step: 23-86 -- Loss: 0.13590121269226074
train-epoch-step: 23-87 -- Loss: 0.24456600844860077
train-epoch-step: 23-88 -- Loss: 0.1484455019235611
train-epoch-step: 23-89 -- Loss: 0.19519567489624023
train-epoch-step: 23-90 -- Loss: 0.19793498516082764
train-epoch-step: 23-91 -- Loss: 0.25683534145355225
train-epoch-step: 23-92 -- Loss: 0.16095007956027985
train-epoch-step: 23-93 -- Loss: 0.17960569262504578
train-epoch-step: 23-94 -- Loss: 0.23535823822021484
train-epoch-step: 23-95 -- Loss: 0.2003568559885025
train-epoch-step: 23-96 -- Loss: 0.22086289525032043
train-epoch-step: 23-97 -- Loss: 0.1850641518831253
train-epoch-step: 23-98 -- Loss: 0.15583932399749756
train-epoch-step: 23-99 -- Loss: 0.1854141652584076
train-epoch-step: 23-100 -- Loss: 0.190519779920578
train-epoch-step: 23-101 -- Loss: 0.28922414779663086
train-epoch-step: 23-102 -- Loss: 0.22679349780082703
train-epoch-step: 23-103 -- Loss: 0.19040904939174652
train-epoch-step: 23-104 -- Loss: 0.15385913848876953
train-epoch-step: 23-105 -- Loss: 0.2738856375217438
train-epoch-step: 23-106 -- Loss: 0.17743122577667236
train-epoch-step: 23-107 -- Loss: 0.19187293946743011
train-epoch-step: 23-108 -- Loss: 0.19621197879314423
train-epoch-step: 23-109 -- Loss: 0.15841835737228394
train-epoch-step: 23-110 -- Loss: 0.19247254729270935
train-epoch-step: 23-111 -- Loss: 0.18556736409664154
train-epoch-step: 23-112 -- Loss: 0.17717236280441284
train-epoch-step: 23-113 -- Loss: 0.167283296585083
train-epoch-step: 23-114 -- Loss: 0.20059332251548767
train-epoch-step: 23-115 -- Loss: 0.17040979862213135
train-epoch-step: 23-116 -- Loss: 0.1450488418340683
train-epoch-step: 23-117 -- Loss: 0.13350991904735565
train-epoch-step: 23-118 -- Loss: 0.1976035237312317
train-epoch-step: 23-119 -- Loss: 0.16361677646636963
train-epoch-step: 23-120 -- Loss: 0.25673389434814453
train-epoch-step: 23-121 -- Loss: 0.26720497012138367
train-epoch-step: 23-122 -- Loss: 0.2250911295413971
train-epoch-step: 23-123 -- Loss: 0.20950058102607727
train-epoch-step: 23-124 -- Loss: 0.12602946162223816
train-epoch-step: 23-125 -- Loss: 0.160272017121315
train-epoch-step: 23-126 -- Loss: 0.23557209968566895
train-epoch-step: 23-127 -- Loss: 0.18636316061019897
train-epoch-step: 23-128 -- Loss: 0.17573100328445435
train-epoch-step: 23-129 -- Loss: 0.15047034621238708
train-epoch-step: 23-130 -- Loss: 0.19671542942523956
train-epoch-step: 23-131 -- Loss: 0.14500173926353455
train-epoch-step: 23-132 -- Loss: 0.19319084286689758
train-epoch-step: 23-133 -- Loss: 0.12255918979644775
train-epoch-step: 23-134 -- Loss: 0.20251703262329102
train-epoch-step: 23-135 -- Loss: 0.14002066850662231
train-epoch-step: 23-136 -- Loss: 0.1308586746454239
train-epoch-step: 23-137 -- Loss: 0.25352489948272705
train-epoch-step: 23-138 -- Loss: 0.27144354581832886
train-epoch-step: 23-139 -- Loss: 0.13681648671627045
train-epoch-step: 23-140 -- Loss: 0.21445254981517792
train-epoch-step: 23-141 -- Loss: 0.2366807758808136
train-epoch-step: 23-142 -- Loss: 0.20976021885871887
train-epoch-step: 23-143 -- Loss: 0.18400390446186066
train-epoch-step: 23-144 -- Loss: 0.19798481464385986
train-epoch-step: 23-145 -- Loss: 0.144905686378479
train-epoch-step: 23-146 -- Loss: 0.19373339414596558
train-epoch-step: 23-147 -- Loss: 0.18194778263568878
train-epoch-step: 23-148 -- Loss: 0.1653425395488739
train-epoch-step: 23-149 -- Loss: 0.12917199730873108
train-epoch-step: 23-150 -- Loss: 0.18973621726036072
train-epoch-step: 23-151 -- Loss: 0.19740530848503113
train-epoch-step: 23-152 -- Loss: 0.1986568123102188
train-epoch-step: 23-153 -- Loss: 0.3141315281391144
train-epoch-step: 23-154 -- Loss: 0.13574320077896118
train-epoch-step: 23-155 -- Loss: 0.1453222632408142
train-epoch-step: 23-156 -- Loss: 0.1292029172182083
train-epoch-step: 23-157 -- Loss: 0.19073624908924103
train-epoch-step: 23-158 -- Loss: 0.16790220141410828
train-epoch-step: 23-159 -- Loss: 0.1926122009754181
train-epoch-step: 23-160 -- Loss: 0.22923928499221802
train-epoch-step: 23-161 -- Loss: 0.22027909755706787
train-epoch-step: 23-162 -- Loss: 0.21848978102207184
train-epoch-step: 23-163 -- Loss: 0.19329558312892914
train-epoch-step: 23-164 -- Loss: 0.19778478145599365
train-epoch-step: 23-165 -- Loss: 0.16797490417957306
train-epoch-step: 23-166 -- Loss: 0.12768088281154633
train-epoch-step: 23-167 -- Loss: 0.13775722682476044
train-epoch-step: 23-168 -- Loss: 0.2120736837387085
train-epoch-step: 23-169 -- Loss: 0.15151923894882202
train-epoch-step: 23-170 -- Loss: 0.2040528655052185
train-epoch-step: 23-171 -- Loss: 0.15290731191635132
train-epoch-step: 23-172 -- Loss: 0.264292448759079
train-epoch-step: 23-173 -- Loss: 0.14223255217075348
train-epoch-step: 23-174 -- Loss: 0.25788772106170654
train-epoch-step: 23-175 -- Loss: 0.18914926052093506
train-epoch-step: 23-176 -- Loss: 0.1436418741941452
train-epoch-step: 23-177 -- Loss: 0.19416138529777527
train-epoch-step: 23-178 -- Loss: 0.18730954825878143
train-epoch-step: 23-179 -- Loss: 0.16246160864830017
train-epoch-step: 23-180 -- Loss: 0.16260972619056702
train-epoch-step: 23-181 -- Loss: 0.1787533015012741
train-epoch-step: 23-182 -- Loss: 0.19461770355701447
train-epoch-step: 23-183 -- Loss: 0.28167960047721863
train-epoch-step: 23-184 -- Loss: 0.14468610286712646
train-epoch-step: 23-185 -- Loss: 0.14627331495285034
train-epoch-step: 23-186 -- Loss: 0.1971605122089386
train-epoch-step: 23-187 -- Loss: 0.21219730377197266
train-epoch-step: 23-188 -- Loss: 0.18675841391086578
train-epoch-step: 23-189 -- Loss: 0.11260392516851425
train-epoch-step: 23-190 -- Loss: 0.18680784106254578
train-epoch-step: 23-191 -- Loss: 0.17681367695331573
train-epoch-step: 23-192 -- Loss: 0.24340516328811646
train-epoch-step: 23-193 -- Loss: 0.2221844345331192
train-epoch-step: 23-194 -- Loss: 0.19453556835651398
train-epoch-step: 23-195 -- Loss: 0.17344504594802856
train-epoch-step: 23-196 -- Loss: 0.17372968792915344
train-epoch-step: 23-197 -- Loss: 0.1419396698474884
train-epoch-step: 23-198 -- Loss: 0.13483530282974243
train-epoch-step: 23-199 -- Loss: 0.15991149842739105
train-epoch-step: 23-200 -- Loss: 0.12974941730499268
train-epoch-step: 23-201 -- Loss: 0.20423249900341034
train-epoch-step: 23-202 -- Loss: 0.142953559756279
train-epoch-step: 23-203 -- Loss: 0.1812249720096588
train-epoch-step: 23-204 -- Loss: 0.14435601234436035
train-epoch-step: 23-205 -- Loss: 0.21589428186416626
train-epoch-step: 23-206 -- Loss: 0.2111693024635315
train-epoch-step: 23-207 -- Loss: 0.16829849779605865
train-epoch-step: 23-208 -- Loss: 0.18353399634361267
train-epoch-step: 23-209 -- Loss: 0.1461651772260666
train-epoch-step: 23-210 -- Loss: 0.1397564560174942
train-epoch-step: 23-211 -- Loss: 0.21587775647640228
train-epoch-step: 23-212 -- Loss: 0.20867499709129333
train-epoch-step: 23-213 -- Loss: 0.13604490458965302
train-epoch-step: 23-214 -- Loss: 0.15263406932353973
train-epoch-step: 23-215 -- Loss: 0.1331881284713745
train-epoch-step: 23-216 -- Loss: 0.20933100581169128
train-epoch-step: 23-217 -- Loss: 0.21976201236248016
train-epoch-step: 23-218 -- Loss: 0.15192945301532745
train-epoch-step: 23-219 -- Loss: 0.19175055623054504
train-epoch-step: 23-220 -- Loss: 0.1377648562192917
train-epoch-step: 23-221 -- Loss: 0.21238406002521515
train-epoch-step: 23-222 -- Loss: 0.12290206551551819
train-epoch-step: 23-223 -- Loss: 0.1780446469783783
train-epoch-step: 23-224 -- Loss: 0.2018805742263794
train-epoch-step: 23-225 -- Loss: 0.2854927182197571
train-epoch-step: 23-226 -- Loss: 0.21024329960346222
train-epoch-step: 23-227 -- Loss: 0.22681717574596405
train-epoch-step: 23-228 -- Loss: 0.18641898036003113
train-epoch-step: 23-229 -- Loss: 0.1793133020401001
train-epoch-step: 23-230 -- Loss: 0.1757226288318634
train-epoch-step: 23-231 -- Loss: 0.1625066101551056
train-epoch-step: 23-232 -- Loss: 0.19962283968925476
train-epoch-step: 23-233 -- Loss: 0.09163906425237656
train-epoch-step: 23-234 -- Loss: 0.18546339869499207
train-epoch-step: 23-235 -- Loss: 0.16257762908935547
train-epoch-step: 23-236 -- Loss: 0.1896243393421173
train-epoch-step: 23-237 -- Loss: 0.24799297749996185
train-epoch-step: 23-238 -- Loss: 0.16396187245845795
train-epoch-step: 23-239 -- Loss: 0.14895156025886536
train-epoch-step: 23-240 -- Loss: 0.22224241495132446
train-epoch-step: 23-241 -- Loss: 0.16282719373703003
train-epoch-step: 23-242 -- Loss: 0.23206999897956848
train-epoch-step: 23-243 -- Loss: 0.23978394269943237
train-epoch-step: 23-244 -- Loss: 0.21729540824890137
train-epoch-step: 23-245 -- Loss: 0.21795262396335602
train-epoch-step: 23-246 -- Loss: 0.22465983033180237
train-epoch-step: 23-247 -- Loss: 0.223970428109169
train-epoch-step: 23-248 -- Loss: 0.1938229352235794
train-epoch-step: 23-249 -- Loss: 0.1456483006477356
train-epoch-step: 23-250 -- Loss: 0.2106592357158661
train-epoch-step: 23-251 -- Loss: 0.11270323395729065
train-epoch-step: 23-252 -- Loss: 0.21957676112651825
train-epoch-step: 23-253 -- Loss: 0.14114707708358765
train-epoch-step: 23-254 -- Loss: 0.22412285208702087
train-epoch-step: 23-255 -- Loss: 0.1534903198480606
train-epoch-step: 23-256 -- Loss: 0.15834476053714752
train-epoch-step: 23-257 -- Loss: 0.19238786399364471
train-epoch-step: 23-258 -- Loss: 0.152949720621109
train-epoch-step: 23-259 -- Loss: 0.11681444942951202
train-epoch-step: 23-260 -- Loss: 0.21111923456192017
train-epoch-step: 23-261 -- Loss: 0.1834896355867386
train-epoch-step: 23-262 -- Loss: 0.3231985569000244
train-epoch-step: 23-263 -- Loss: 0.24169789254665375
train-epoch-step: 23-264 -- Loss: 0.17909777164459229
train-epoch-step: 23-265 -- Loss: 0.13441020250320435
train-epoch-step: 23-266 -- Loss: 0.16687390208244324
train-epoch-step: 23-267 -- Loss: 0.14578641951084137
train-epoch-step: 23-268 -- Loss: 0.14280658960342407
train-epoch-step: 23-269 -- Loss: 0.1797889918088913
train-epoch-step: 23-270 -- Loss: 0.11449256539344788
train-epoch-step: 23-271 -- Loss: 0.15654054284095764
train-epoch-step: 23-272 -- Loss: 0.12847661972045898
train-epoch-step: 23-273 -- Loss: 0.13308532536029816
train-epoch-step: 23-274 -- Loss: 0.2060564160346985
train-epoch-step: 23-275 -- Loss: 0.22620487213134766
train-epoch-step: 23-276 -- Loss: 0.17361482977867126
train-epoch-step: 23-277 -- Loss: 0.1601617932319641
train-epoch-step: 23-278 -- Loss: 0.16333654522895813
train-epoch-step: 23-279 -- Loss: 0.16228853166103363
train-epoch-step: 23-280 -- Loss: 0.24108585715293884
train-epoch-step: 23-281 -- Loss: 0.20091211795806885
train-epoch-step: 23-282 -- Loss: 0.15639054775238037
train-epoch-step: 23-283 -- Loss: 0.1348629891872406
train-epoch-step: 23-284 -- Loss: 0.15230503678321838
train-epoch-step: 23-285 -- Loss: 0.2184869647026062
train-epoch-step: 23-286 -- Loss: 0.16968265175819397
train-epoch-step: 23-287 -- Loss: 0.2229430079460144
train-epoch-step: 23-288 -- Loss: 0.102518729865551
train-epoch-step: 23-289 -- Loss: 0.12737977504730225
train-epoch-step: 23-290 -- Loss: 0.1951223909854889
train-epoch-step: 23-291 -- Loss: 0.12456726282835007
train-epoch-step: 23-292 -- Loss: 0.1634809374809265
train-epoch-step: 23-293 -- Loss: 0.14457161724567413
train-epoch-step: 23-294 -- Loss: 0.1702217012643814
train-epoch-step: 23-295 -- Loss: 0.2829539477825165
train-epoch-step: 23-296 -- Loss: 0.18355384469032288
train-epoch-step: 23-297 -- Loss: 0.18988825380802155
train-epoch-step: 23-298 -- Loss: 0.24180163443088531
train-epoch-step: 23-299 -- Loss: 0.164747416973114
train-epoch-step: 23-300 -- Loss: 0.17152099311351776
train-epoch-step: 23-301 -- Loss: 0.17925341427326202
train-epoch-step: 23-302 -- Loss: 0.23073583841323853
train-epoch-step: 23-303 -- Loss: 0.2222057282924652
train-epoch-step: 23-304 -- Loss: 0.1447375863790512
train-epoch-step: 23-305 -- Loss: 0.15357665717601776
train-epoch-step: 23-306 -- Loss: 0.2445058971643448
train-epoch-step: 23-307 -- Loss: 0.17507103085517883
train-epoch-step: 23-308 -- Loss: 0.23354187607765198
train-epoch-step: 23-309 -- Loss: 0.16301092505455017
train-epoch-step: 23-310 -- Loss: 0.17755180597305298
train-epoch-step: 23-311 -- Loss: 0.16617967188358307
train-epoch-step: 23-312 -- Loss: 0.22097483277320862
train-epoch-step: 23-313 -- Loss: 0.10534489154815674
train-epoch-step: 23-314 -- Loss: 0.20809638500213623
train-epoch-step: 23-315 -- Loss: 0.17880286276340485
train-epoch-step: 23-316 -- Loss: 0.16221925616264343
train-epoch-step: 23-317 -- Loss: 0.14800697565078735
train-epoch-step: 23-318 -- Loss: 0.17481745779514313
train-epoch-step: 23-319 -- Loss: 0.18330249190330505
train-epoch-step: 23-320 -- Loss: 0.1290096491575241
train-epoch-step: 23-321 -- Loss: 0.13820700347423553
train-epoch-step: 23-322 -- Loss: 0.22387726604938507
train-epoch-step: 23-323 -- Loss: 0.16279347240924835
train-epoch-step: 23-324 -- Loss: 0.26304158568382263
train-epoch-step: 23-325 -- Loss: 0.15763041377067566
train-epoch-step: 23-326 -- Loss: 0.17539921402931213
train-epoch-step: 23-327 -- Loss: 0.2136835902929306
train-epoch-step: 23-328 -- Loss: 0.20087209343910217
train-epoch-step: 23-329 -- Loss: 0.35241562128067017
train-epoch-step: 23-330 -- Loss: 0.36530202627182007
train-epoch-step: 23-331 -- Loss: 0.21234793961048126
train-epoch-step: 23-332 -- Loss: 0.1037578135728836
train-epoch-step: 23-333 -- Loss: 0.1986972689628601
train-epoch-step: 23-334 -- Loss: 0.16220316290855408
train-epoch-step: 23-335 -- Loss: 0.1840769499540329
train-epoch-step: 23-336 -- Loss: 0.159771129488945
train-epoch-step: 23-337 -- Loss: 0.22199106216430664
train-epoch-step: 23-338 -- Loss: 0.16893239319324493
train-epoch-step: 23-339 -- Loss: 0.14915937185287476
train-epoch-step: 23-340 -- Loss: 0.20870397984981537
train-epoch-step: 23-341 -- Loss: 0.1443226933479309
train-epoch-step: 23-342 -- Loss: 0.16951234638690948
train-epoch-step: 23-343 -- Loss: 0.16027337312698364
train-epoch-step: 23-344 -- Loss: 0.1786707043647766
train-epoch-step: 23-345 -- Loss: 0.14091607928276062
train-epoch-step: 23-346 -- Loss: 0.23137801885604858
train-epoch-step: 23-347 -- Loss: 0.16356909275054932
train-epoch-step: 23-348 -- Loss: 0.2133006602525711
train-epoch-step: 23-349 -- Loss: 0.21565204858779907
train-epoch-step: 23-350 -- Loss: 0.27103516459465027
train-epoch-step: 23-351 -- Loss: 0.2028551548719406
train-epoch-step: 23-352 -- Loss: 0.13073447346687317
train-epoch-step: 23-353 -- Loss: 0.20625577867031097
train-epoch-step: 23-354 -- Loss: 0.30226191878318787
train-epoch-step: 23-355 -- Loss: 0.12699899077415466
train-epoch-step: 23-356 -- Loss: 0.11923398822546005
train-epoch-step: 23-357 -- Loss: 0.20570528507232666
train-epoch-step: 23-358 -- Loss: 0.188374862074852
train-epoch-step: 23-359 -- Loss: 0.14538629353046417
train-epoch-step: 23-360 -- Loss: 0.12603461742401123
train-epoch-step: 23-361 -- Loss: 0.24312806129455566
train-epoch-step: 23-362 -- Loss: 0.17544715106487274
train-epoch-step: 23-363 -- Loss: 0.11931153386831284
train-epoch-step: 23-364 -- Loss: 0.18677090108394623
train-epoch-step: 23-365 -- Loss: 0.18270589411258698
train-epoch-step: 23-366 -- Loss: 0.20076045393943787
train-epoch-step: 23-367 -- Loss: 0.2476433962583542
train-epoch-step: 23-368 -- Loss: 0.20708566904067993
train-epoch-step: 23-369 -- Loss: 0.2863764762878418
train-epoch-step: 23-370 -- Loss: 0.1358928233385086
train-epoch-step: 23-371 -- Loss: 0.12565267086029053
train-epoch-step: 23-372 -- Loss: 0.1480882167816162
train-epoch-step: 23-373 -- Loss: 0.1977202296257019
train-epoch-step: 23-374 -- Loss: 0.16194845736026764
train-epoch-step: 23-375 -- Loss: 0.2881954610347748
train-epoch-step: 23-376 -- Loss: 0.16961364448070526
train-epoch-step: 23-377 -- Loss: 0.242168128490448
train-epoch-step: 23-378 -- Loss: 0.21905869245529175
train-epoch-step: 23-379 -- Loss: 0.12477239221334457
train-epoch-step: 23-380 -- Loss: 0.09436279535293579
train-epoch-step: 23-381 -- Loss: 0.26126277446746826
train-epoch-step: 23-382 -- Loss: 0.23977304995059967
train-epoch-step: 23-383 -- Loss: 0.18318402767181396
train-epoch-step: 23-384 -- Loss: 0.24484997987747192
train-epoch-step: 23-385 -- Loss: 0.19938738644123077
train-epoch-step: 23-386 -- Loss: 0.19091711938381195
train-epoch-step: 23-387 -- Loss: 0.21593979001045227
train-epoch-step: 23-388 -- Loss: 0.19636543095111847
train-epoch-step: 23-389 -- Loss: 0.17377500236034393
train-epoch-step: 23-390 -- Loss: 0.14949363470077515
train-epoch-step: 23-391 -- Loss: 0.14954274892807007
train-epoch-step: 23-392 -- Loss: 0.19734108448028564
train-epoch-step: 23-393 -- Loss: 0.1595277488231659
train-epoch-step: 23-394 -- Loss: 0.22142978012561798
train-epoch-step: 23-395 -- Loss: 0.17243286967277527
train-epoch-step: 23-396 -- Loss: 0.12867377698421478
train-epoch-step: 23-397 -- Loss: 0.13236811757087708
train-epoch-step: 23-398 -- Loss: 0.20298036932945251
train-epoch-step: 23-399 -- Loss: 0.17927555739879608
train-epoch-step: 23-400 -- Loss: 0.27724146842956543
train-epoch-step: 23-401 -- Loss: 0.12552857398986816
train-epoch-step: 23-402 -- Loss: 0.2656460702419281
train-epoch-step: 23-403 -- Loss: 0.16746003925800323
train-epoch-step: 23-404 -- Loss: 0.1442628800868988
train-epoch-step: 23-405 -- Loss: 0.15070511400699615
train-epoch-step: 23-406 -- Loss: 0.1745966523885727
train-epoch-step: 23-407 -- Loss: 0.12079064548015594
train-epoch-step: 23-408 -- Loss: 0.16475322842597961
train-epoch-step: 23-409 -- Loss: 0.1773899346590042
train-epoch-step: 23-410 -- Loss: 0.1770831048488617
train-epoch-step: 23-411 -- Loss: 0.20619282126426697
train-epoch-step: 23-412 -- Loss: 0.13817156851291656
train-epoch-step: 23-413 -- Loss: 0.15043005347251892
train-epoch-step: 23-414 -- Loss: 0.14421536028385162
train-epoch-step: 23-415 -- Loss: 0.1492556482553482
train-epoch-step: 23-416 -- Loss: 0.27585113048553467
train-epoch-step: 23-417 -- Loss: 0.19836223125457764
train-epoch-step: 23-418 -- Loss: 0.24624940752983093
train-epoch-step: 23-419 -- Loss: 0.1722392588853836
train-epoch-step: 23-420 -- Loss: 0.1604675054550171
train-epoch-step: 23-421 -- Loss: 0.1836414337158203
train-epoch-step: 23-422 -- Loss: 0.1543394774198532
train-epoch-step: 23-423 -- Loss: 0.1872255802154541
train-epoch-step: 23-424 -- Loss: 0.14297431707382202
train-epoch-step: 23-425 -- Loss: 0.18969303369522095
train-epoch-step: 23-426 -- Loss: 0.16720058023929596
train-epoch-step: 23-427 -- Loss: 0.12831148505210876
train-epoch-step: 23-428 -- Loss: 0.20901308953762054
train-epoch-step: 23-429 -- Loss: 0.17987138032913208
train-epoch-step: 23-430 -- Loss: 0.15629199147224426
train-epoch-step: 23-431 -- Loss: 0.17117127776145935
train-epoch-step: 23-432 -- Loss: 0.2487092763185501
train-epoch-step: 23-433 -- Loss: 0.14196166396141052
train-epoch-step: 23-434 -- Loss: 0.13438040018081665
train-epoch-step: 23-435 -- Loss: 0.16790419816970825
train-epoch-step: 23-436 -- Loss: 0.16271813213825226
train-epoch-step: 23-437 -- Loss: 0.14093925058841705
train-epoch-step: 23-438 -- Loss: 0.17889775335788727
train-epoch-step: 23-439 -- Loss: 0.2808503806591034
train-epoch-step: 23-440 -- Loss: 0.13953329622745514
train-epoch-step: 23-441 -- Loss: 0.21004711091518402
train-epoch-step: 23-442 -- Loss: 0.1926301270723343
train-epoch-step: 23-443 -- Loss: 0.16370978951454163
train-epoch-step: 23-444 -- Loss: 0.18298721313476562
train-epoch-step: 23-445 -- Loss: 0.19024479389190674
train-epoch-step: 23-446 -- Loss: 0.15647748112678528
train-epoch-step: 23-447 -- Loss: 0.20043157041072845
train-epoch-step: 23-448 -- Loss: 0.23704570531845093
train-epoch-step: 23-449 -- Loss: 0.19370923936367035
train-epoch-step: 23-450 -- Loss: 0.18673473596572876
train-epoch-step: 23-451 -- Loss: 0.1488995999097824
train-epoch-step: 23-452 -- Loss: 0.1366066038608551
train-epoch-step: 23-453 -- Loss: 0.10024268925189972
train-epoch-step: 23-454 -- Loss: 0.2431066781282425
train-epoch-step: 23-455 -- Loss: 0.1257699877023697
train-epoch-step: 23-456 -- Loss: 0.12571586668491364
train-epoch-step: 23-457 -- Loss: 0.22114120423793793
train-epoch-step: 23-458 -- Loss: 0.1539241522550583
train-epoch-step: 23-459 -- Loss: 0.22737523913383484
train-epoch-step: 23-460 -- Loss: 0.13219091296195984
train-epoch-step: 23-461 -- Loss: 0.14314916729927063
train-epoch-step: 23-462 -- Loss: 0.16736078262329102
train-epoch-step: 23-463 -- Loss: 0.1378398984670639
train-epoch-step: 23-464 -- Loss: 0.17052218317985535
train-epoch-step: 23-465 -- Loss: 0.2528843581676483
train-epoch-step: 23-466 -- Loss: 0.20664456486701965
train-epoch-step: 23-467 -- Loss: 0.11647426337003708
train-epoch-step: 23-468 -- Loss: 0.1754099726676941
train-epoch-step: 23-469 -- Loss: 0.2220815122127533
train-epoch-step: 23-470 -- Loss: 0.18069003522396088
train-epoch-step: 23-471 -- Loss: 0.1623106598854065
train-epoch-step: 23-472 -- Loss: 0.16011661291122437
train-epoch-step: 23-473 -- Loss: 0.1690235435962677
train-epoch-step: 23-474 -- Loss: 0.125746488571167
train-epoch-step: 23-475 -- Loss: 0.1135096400976181
train-epoch-step: 23-476 -- Loss: 0.2018391489982605
train-epoch-step: 23-477 -- Loss: 0.2215685248374939
train-epoch-step: 23-478 -- Loss: 0.19617220759391785
train-epoch-step: 23-479 -- Loss: 0.14941570162773132
train-epoch-step: 23-480 -- Loss: 0.20221881568431854
train-epoch-step: 23-481 -- Loss: 0.29035264253616333
train-epoch-step: 23-482 -- Loss: 0.29017406702041626
train-epoch-step: 23-483 -- Loss: 0.18489912152290344
train-epoch-step: 23-484 -- Loss: 0.21866756677627563
train-epoch-step: 23-485 -- Loss: 0.1303829401731491
train-epoch-step: 23-486 -- Loss: 0.2553555369377136
train-epoch-step: 23-487 -- Loss: 0.23541715741157532
train-epoch-step: 23-488 -- Loss: 0.2115914225578308
train-epoch-step: 23-489 -- Loss: 0.22501718997955322
train-epoch-step: 23-490 -- Loss: 0.15541991591453552
train-epoch-step: 23-491 -- Loss: 0.15382352471351624
train-epoch-step: 23-492 -- Loss: 0.12916100025177002
train-epoch-step: 23-493 -- Loss: 0.22031870484352112
train-epoch-step: 23-494 -- Loss: 0.21393132209777832
train-epoch-step: 23-495 -- Loss: 0.20864756405353546
train-epoch-step: 23-496 -- Loss: 0.14310969412326813
train-epoch-step: 23-497 -- Loss: 0.18946599960327148
train-epoch-step: 23-498 -- Loss: 0.16588100790977478
train-epoch-step: 23-499 -- Loss: 0.17619448900222778
train-epoch-step: 23-500 -- Loss: 0.15883512794971466
train-epoch-step: 23-501 -- Loss: 0.246854767203331
train-epoch-step: 23-502 -- Loss: 0.16677413880825043
train-epoch-step: 23-503 -- Loss: 0.23119154572486877
train-epoch-step: 23-504 -- Loss: 0.13898831605911255
train-epoch-step: 23-505 -- Loss: 0.18562497198581696
train-epoch-step: 23-506 -- Loss: 0.12793566286563873
train-epoch-step: 23-507 -- Loss: 0.18682801723480225
train-epoch-step: 23-508 -- Loss: 0.1837710291147232
train-epoch-step: 23-509 -- Loss: 0.17621085047721863
train-epoch-step: 23-510 -- Loss: 0.13226069509983063
train-epoch-step: 23-511 -- Loss: 0.22251659631729126
train-epoch-step: 23-512 -- Loss: 0.1823694407939911
train-epoch-step: 23-513 -- Loss: 0.2068704068660736
train-epoch-step: 23-514 -- Loss: 0.15313376486301422
train-epoch-step: 23-515 -- Loss: 0.1670524775981903
train-epoch-step: 23-516 -- Loss: 0.18001306056976318
train-epoch-step: 23-517 -- Loss: 0.18099799752235413
train-epoch-step: 23-518 -- Loss: 0.1411570906639099
train-epoch-step: 23-519 -- Loss: 0.13818378746509552
train-epoch-step: 23-520 -- Loss: 0.19059783220291138
train-epoch-step: 23-521 -- Loss: 0.23969508707523346
train-epoch-step: 23-522 -- Loss: 0.1845976561307907
train-epoch-step: 23-523 -- Loss: 0.15990164875984192
train-epoch-step: 23-524 -- Loss: 0.17346258461475372
train-epoch-step: 23-525 -- Loss: 0.19736361503601074
train-epoch-step: 23-526 -- Loss: 0.1326066106557846
train-epoch-step: 23-527 -- Loss: 0.1648360639810562
train-epoch-step: 23-528 -- Loss: 0.1583559215068817
train-epoch-step: 23-529 -- Loss: 0.16638243198394775
train-epoch-step: 23-530 -- Loss: 0.17017872631549835
train-epoch-step: 23-531 -- Loss: 0.20828808844089508
train-epoch-step: 23-532 -- Loss: 0.17338769137859344
train-epoch-step: 23-533 -- Loss: 0.17769941687583923
train-epoch-step: 23-534 -- Loss: 0.14421872794628143
train-epoch-step: 23-535 -- Loss: 0.26724180579185486
train-epoch-step: 23-536 -- Loss: 0.16642636060714722
train-epoch-step: 23-537 -- Loss: 0.1520121544599533
train-epoch-step: 23-538 -- Loss: 0.10644274204969406
train-epoch-step: 23-539 -- Loss: 0.18949231505393982
train-epoch-step: 23-540 -- Loss: 0.13957947492599487
train-epoch-step: 23-541 -- Loss: 0.21340236067771912
train-epoch-step: 23-542 -- Loss: 0.22866010665893555
train-epoch-step: 23-543 -- Loss: 0.17449668049812317
train-epoch-step: 23-544 -- Loss: 0.23441049456596375
train-epoch-step: 23-545 -- Loss: 0.19857636094093323
train-epoch-step: 23-546 -- Loss: 0.22434648871421814
train-epoch-step: 23-547 -- Loss: 0.1880986988544464
train-epoch-step: 23-548 -- Loss: 0.09917944669723511
train-epoch-step: 23-549 -- Loss: 0.15694397687911987
train-epoch-step: 23-550 -- Loss: 0.20618441700935364
train-epoch-step: 23-551 -- Loss: 0.16088657081127167
train-epoch-step: 23-552 -- Loss: 0.13333186507225037
train-epoch-step: 23-553 -- Loss: 0.2025151252746582
train-epoch-step: 23-554 -- Loss: 0.19410261511802673
train-epoch-step: 23-555 -- Loss: 0.22196882963180542
train-epoch-step: 23-556 -- Loss: 0.1579902619123459
train-epoch-step: 23-557 -- Loss: 0.2537659704685211
train-epoch-step: 23-558 -- Loss: 0.22607873380184174
train-epoch-step: 23-559 -- Loss: 0.142441526055336
train-epoch-step: 23-560 -- Loss: 0.21129247546195984
train-epoch-step: 23-561 -- Loss: 0.19173477590084076
train-epoch-step: 23-562 -- Loss: 0.16919907927513123
train-epoch-step: 23-563 -- Loss: 0.19442838430404663
train-epoch-step: 23-564 -- Loss: 0.10614657402038574
train-epoch-step: 23-565 -- Loss: 0.19727326929569244
train-epoch-step: 23-566 -- Loss: 0.15404468774795532
train-epoch-step: 23-567 -- Loss: 0.2154301404953003
train-epoch-step: 23-568 -- Loss: 0.1591264307498932
train-epoch-step: 23-569 -- Loss: 0.25140252709388733
train-epoch-step: 23-570 -- Loss: 0.18170256912708282
train-epoch-step: 23-571 -- Loss: 0.21357297897338867
train-epoch-step: 23-572 -- Loss: 0.24482271075248718
train-epoch-step: 23-573 -- Loss: 0.20970205962657928
train-epoch-step: 23-574 -- Loss: 0.2561039328575134
train-epoch-step: 23-575 -- Loss: 0.30780553817749023
train-epoch-step: 23-576 -- Loss: 0.12502263486385345
train-epoch-step: 23-577 -- Loss: 0.17187191545963287
train-epoch-step: 23-578 -- Loss: 0.22569812834262848
train-epoch-step: 23-579 -- Loss: 0.17060934007167816
train-epoch-step: 23-580 -- Loss: 0.18183816969394684
train-epoch-step: 23-581 -- Loss: 0.14491404592990875
train-epoch-step: 23-582 -- Loss: 0.21690088510513306
train-epoch-step: 23-583 -- Loss: 0.22138750553131104
train-epoch-step: 23-584 -- Loss: 0.17112943530082703
train-epoch-step: 23-585 -- Loss: 0.19902727007865906
train-epoch-step: 23-586 -- Loss: 0.26992303133010864
train-epoch-step: 23-587 -- Loss: 0.16541266441345215
train-epoch-step: 23-588 -- Loss: 0.129146546125412
val-epoch-step: 23-589 -- Loss: 0.20743250846862793
val-epoch-step: 23-590 -- Loss: 0.15528738498687744
val-epoch-step: 23-591 -- Loss: 0.2398417890071869
val-epoch-step: 23-592 -- Loss: 0.1792040318250656
val-epoch-step: 23-593 -- Loss: 0.17634519934654236
val-epoch-step: 23-594 -- Loss: 0.34604135155677795
val-epoch-step: 23-595 -- Loss: 0.18243321776390076
val-epoch-step: 23-596 -- Loss: 0.19859978556632996
val-epoch-step: 23-597 -- Loss: 0.17539048194885254
val-epoch-step: 23-598 -- Loss: 0.1518358737230301
val-epoch-step: 23-599 -- Loss: 0.18931052088737488
val-epoch-step: 23-600 -- Loss: 0.19087305665016174
val-epoch-step: 23-601 -- Loss: 0.1624518781900406
val-epoch-step: 23-602 -- Loss: 0.14275357127189636
val-epoch-step: 23-603 -- Loss: 0.21631541848182678
val-epoch-step: 23-604 -- Loss: 0.15543097257614136
val-epoch-step: 23-605 -- Loss: 0.15004481375217438
val-epoch-step: 23-606 -- Loss: 0.2614481449127197
val-epoch-step: 23-607 -- Loss: 0.127208411693573
val-epoch-step: 23-608 -- Loss: 0.26086220145225525
val-epoch-step: 23-609 -- Loss: 0.19512245059013367
val-epoch-step: 23-610 -- Loss: 0.18541482090950012
val-epoch-step: 23-611 -- Loss: 0.15945762395858765
val-epoch-step: 23-612 -- Loss: 0.4284878075122833
val-epoch-step: 23-613 -- Loss: 0.18156488239765167
val-epoch-step: 23-614 -- Loss: 0.1647089421749115
val-epoch-step: 23-615 -- Loss: 0.18251632153987885
val-epoch-step: 23-616 -- Loss: 0.16105473041534424
val-epoch-step: 23-617 -- Loss: 0.19043734669685364
val-epoch-step: 23-618 -- Loss: 0.20340585708618164
val-epoch-step: 23-619 -- Loss: 0.2318636178970337
val-epoch-step: 23-620 -- Loss: 0.15849746763706207
val-epoch-step: 23-621 -- Loss: 0.1311401128768921
val-epoch-step: 23-622 -- Loss: 0.14510147273540497
val-epoch-step: 23-623 -- Loss: 0.15837594866752625
val-epoch-step: 23-624 -- Loss: 0.14734353125095367
val-epoch-step: 23-625 -- Loss: 0.16180521249771118
val-epoch-step: 23-626 -- Loss: 0.1497003138065338
val-epoch-step: 23-627 -- Loss: 0.19662931561470032
val-epoch-step: 23-628 -- Loss: 0.6899000406265259
val-epoch-step: 23-629 -- Loss: 0.20418377220630646
val-epoch-step: 23-630 -- Loss: 0.3606291711330414
val-epoch-step: 23-631 -- Loss: 0.149560809135437
val-epoch-step: 23-632 -- Loss: 0.21089008450508118
val-epoch-step: 23-633 -- Loss: 0.1595156490802765
val-epoch-step: 23-634 -- Loss: 0.15609081089496613
val-epoch-step: 23-635 -- Loss: 0.12112686038017273
val-epoch-step: 23-636 -- Loss: 0.18372485041618347
val-epoch-step: 23-637 -- Loss: 0.18676643073558807
val-epoch-step: 23-638 -- Loss: 0.1613888293504715
val-epoch-step: 23-639 -- Loss: 0.2679101228713989
val-epoch-step: 23-640 -- Loss: 0.2804623246192932
val-epoch-step: 23-641 -- Loss: 0.1339268535375595
val-epoch-step: 23-642 -- Loss: 0.19410841166973114
val-epoch-step: 23-643 -- Loss: 0.21129678189754486
val-epoch-step: 23-644 -- Loss: 0.17617104947566986
val-epoch-step: 23-645 -- Loss: 0.23343756794929504
val-epoch-step: 23-646 -- Loss: 0.13961364328861237
val-epoch-step: 23-647 -- Loss: 0.13725054264068604
val-epoch-step: 23-648 -- Loss: 0.16758905351161957
val-epoch-step: 23-649 -- Loss: 0.21302364766597748
val-epoch-step: 23-650 -- Loss: 0.25552892684936523
val-epoch-step: 23-651 -- Loss: 0.15091782808303833
val-epoch-step: 23-652 -- Loss: 0.15814785659313202
val-epoch-step: 23-653 -- Loss: 0.20366303622722626
val-epoch-step: 23-654 -- Loss: 0.1146157905459404
Epoch: 23 -- Train Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1450, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 24-0 -- Loss: 0.23506107926368713
train-epoch-step: 24-1 -- Loss: 0.14662833511829376
train-epoch-step: 24-2 -- Loss: 0.2132262885570526
train-epoch-step: 24-3 -- Loss: 0.15041619539260864
train-epoch-step: 24-4 -- Loss: 0.1707555055618286
train-epoch-step: 24-5 -- Loss: 0.18926018476486206
train-epoch-step: 24-6 -- Loss: 0.21977180242538452
train-epoch-step: 24-7 -- Loss: 0.17268319427967072
train-epoch-step: 24-8 -- Loss: 0.1897987425327301
train-epoch-step: 24-9 -- Loss: 0.24791403114795685
train-epoch-step: 24-10 -- Loss: 0.20534121990203857
train-epoch-step: 24-11 -- Loss: 0.19218307733535767
train-epoch-step: 24-12 -- Loss: 0.15685530006885529
train-epoch-step: 24-13 -- Loss: 0.18411098420619965
train-epoch-step: 24-14 -- Loss: 0.1720995306968689
train-epoch-step: 24-15 -- Loss: 0.16489437222480774
train-epoch-step: 24-16 -- Loss: 0.16756026446819305
train-epoch-step: 24-17 -- Loss: 0.2284095138311386
train-epoch-step: 24-18 -- Loss: 0.20491784811019897
train-epoch-step: 24-19 -- Loss: 0.1399209350347519
train-epoch-step: 24-20 -- Loss: 0.238709956407547
train-epoch-step: 24-21 -- Loss: 0.26185381412506104
train-epoch-step: 24-22 -- Loss: 0.1510613113641739
train-epoch-step: 24-23 -- Loss: 0.1482461839914322
train-epoch-step: 24-24 -- Loss: 0.13204175233840942
train-epoch-step: 24-25 -- Loss: 0.2432435154914856
train-epoch-step: 24-26 -- Loss: 0.19830666482448578
train-epoch-step: 24-27 -- Loss: 0.2401978075504303
train-epoch-step: 24-28 -- Loss: 0.12668365240097046
train-epoch-step: 24-29 -- Loss: 0.25367704033851624
train-epoch-step: 24-30 -- Loss: 0.11413833498954773
train-epoch-step: 24-31 -- Loss: 0.14262671768665314
train-epoch-step: 24-32 -- Loss: 0.17749539017677307
train-epoch-step: 24-33 -- Loss: 0.2840218245983124
train-epoch-step: 24-34 -- Loss: 0.1845325231552124
train-epoch-step: 24-35 -- Loss: 0.25990578532218933
train-epoch-step: 24-36 -- Loss: 0.139652281999588
train-epoch-step: 24-37 -- Loss: 0.1437193602323532
train-epoch-step: 24-38 -- Loss: 0.1850212961435318
train-epoch-step: 24-39 -- Loss: 0.22149018943309784
train-epoch-step: 24-40 -- Loss: 0.2024000883102417
train-epoch-step: 24-41 -- Loss: 0.22639146447181702
train-epoch-step: 24-42 -- Loss: 0.15137949585914612
train-epoch-step: 24-43 -- Loss: 0.27780091762542725
train-epoch-step: 24-44 -- Loss: 0.13506129384040833
train-epoch-step: 24-45 -- Loss: 0.13214516639709473
train-epoch-step: 24-46 -- Loss: 0.18266461789608002
train-epoch-step: 24-47 -- Loss: 0.23719380795955658
train-epoch-step: 24-48 -- Loss: 0.16020502150058746
train-epoch-step: 24-49 -- Loss: 0.2269492745399475
train-epoch-step: 24-50 -- Loss: 0.1167837381362915
train-epoch-step: 24-51 -- Loss: 0.19802750647068024
train-epoch-step: 24-52 -- Loss: 0.16247957944869995
train-epoch-step: 24-53 -- Loss: 0.23553909361362457
train-epoch-step: 24-54 -- Loss: 0.2891963720321655
train-epoch-step: 24-55 -- Loss: 0.18472249805927277
train-epoch-step: 24-56 -- Loss: 0.18724265694618225
train-epoch-step: 24-57 -- Loss: 0.2603279650211334
train-epoch-step: 24-58 -- Loss: 0.305891215801239
train-epoch-step: 24-59 -- Loss: 0.2555113732814789
train-epoch-step: 24-60 -- Loss: 0.1384999305009842
train-epoch-step: 24-61 -- Loss: 0.22264723479747772
train-epoch-step: 24-62 -- Loss: 0.18851089477539062
train-epoch-step: 24-63 -- Loss: 0.15507623553276062
train-epoch-step: 24-64 -- Loss: 0.1585928201675415
train-epoch-step: 24-65 -- Loss: 0.19431574642658234
train-epoch-step: 24-66 -- Loss: 0.11298374831676483
train-epoch-step: 24-67 -- Loss: 0.13406594097614288
train-epoch-step: 24-68 -- Loss: 0.2339848428964615
train-epoch-step: 24-69 -- Loss: 0.12453022599220276
train-epoch-step: 24-70 -- Loss: 0.22945259511470795
train-epoch-step: 24-71 -- Loss: 0.27394744753837585
train-epoch-step: 24-72 -- Loss: 0.18019556999206543
train-epoch-step: 24-73 -- Loss: 0.2201073318719864
train-epoch-step: 24-74 -- Loss: 0.1028076633810997
train-epoch-step: 24-75 -- Loss: 0.13454847037792206
train-epoch-step: 24-76 -- Loss: 0.15471549332141876
train-epoch-step: 24-77 -- Loss: 0.2322525531053543
train-epoch-step: 24-78 -- Loss: 0.2762768864631653
train-epoch-step: 24-79 -- Loss: 0.2093273401260376
train-epoch-step: 24-80 -- Loss: 0.27846968173980713
train-epoch-step: 24-81 -- Loss: 0.13273313641548157
train-epoch-step: 24-82 -- Loss: 0.2612141966819763
train-epoch-step: 24-83 -- Loss: 0.1937038004398346
train-epoch-step: 24-84 -- Loss: 0.1926361322402954
train-epoch-step: 24-85 -- Loss: 0.1821618676185608
train-epoch-step: 24-86 -- Loss: 0.13456763327121735
train-epoch-step: 24-87 -- Loss: 0.22688132524490356
train-epoch-step: 24-88 -- Loss: 0.14948107302188873
train-epoch-step: 24-89 -- Loss: 0.19058486819267273
train-epoch-step: 24-90 -- Loss: 0.19687965512275696
train-epoch-step: 24-91 -- Loss: 0.2557893991470337
train-epoch-step: 24-92 -- Loss: 0.16078341007232666
train-epoch-step: 24-93 -- Loss: 0.17855720221996307
train-epoch-step: 24-94 -- Loss: 0.22507017850875854
train-epoch-step: 24-95 -- Loss: 0.1925031840801239
train-epoch-step: 24-96 -- Loss: 0.2244485318660736
train-epoch-step: 24-97 -- Loss: 0.18168319761753082
train-epoch-step: 24-98 -- Loss: 0.15883421897888184
train-epoch-step: 24-99 -- Loss: 0.18450792133808136
train-epoch-step: 24-100 -- Loss: 0.18974262475967407
train-epoch-step: 24-101 -- Loss: 0.2884608507156372
train-epoch-step: 24-102 -- Loss: 0.2232147455215454
train-epoch-step: 24-103 -- Loss: 0.20316974818706512
train-epoch-step: 24-104 -- Loss: 0.1543576717376709
train-epoch-step: 24-105 -- Loss: 0.286367267370224
train-epoch-step: 24-106 -- Loss: 0.17716500163078308
train-epoch-step: 24-107 -- Loss: 0.1945905089378357
train-epoch-step: 24-108 -- Loss: 0.19187693297863007
train-epoch-step: 24-109 -- Loss: 0.15376640856266022
train-epoch-step: 24-110 -- Loss: 0.18737322092056274
train-epoch-step: 24-111 -- Loss: 0.18874868750572205
train-epoch-step: 24-112 -- Loss: 0.16933345794677734
train-epoch-step: 24-113 -- Loss: 0.16583040356636047
train-epoch-step: 24-114 -- Loss: 0.20118381083011627
train-epoch-step: 24-115 -- Loss: 0.1744961142539978
train-epoch-step: 24-116 -- Loss: 0.1462496668100357
train-epoch-step: 24-117 -- Loss: 0.13068795204162598
train-epoch-step: 24-118 -- Loss: 0.20270538330078125
train-epoch-step: 24-119 -- Loss: 0.17306850850582123
train-epoch-step: 24-120 -- Loss: 0.251961886882782
train-epoch-step: 24-121 -- Loss: 0.24684347212314606
train-epoch-step: 24-122 -- Loss: 0.22188913822174072
train-epoch-step: 24-123 -- Loss: 0.20509691536426544
train-epoch-step: 24-124 -- Loss: 0.13673311471939087
train-epoch-step: 24-125 -- Loss: 0.16236451268196106
train-epoch-step: 24-126 -- Loss: 0.23625311255455017
train-epoch-step: 24-127 -- Loss: 0.1932094395160675
train-epoch-step: 24-128 -- Loss: 0.17531690001487732
train-epoch-step: 24-129 -- Loss: 0.15257303416728973
train-epoch-step: 24-130 -- Loss: 0.19526717066764832
train-epoch-step: 24-131 -- Loss: 0.14469611644744873
train-epoch-step: 24-132 -- Loss: 0.19280558824539185
train-epoch-step: 24-133 -- Loss: 0.12499936670064926
train-epoch-step: 24-134 -- Loss: 0.2015874832868576
train-epoch-step: 24-135 -- Loss: 0.14364884793758392
train-epoch-step: 24-136 -- Loss: 0.14197134971618652
train-epoch-step: 24-137 -- Loss: 0.2535298466682434
train-epoch-step: 24-138 -- Loss: 0.268370121717453
train-epoch-step: 24-139 -- Loss: 0.13490627706050873
train-epoch-step: 24-140 -- Loss: 0.21073779463768005
train-epoch-step: 24-141 -- Loss: 0.24009822309017181
train-epoch-step: 24-142 -- Loss: 0.21052339673042297
train-epoch-step: 24-143 -- Loss: 0.19526375830173492
train-epoch-step: 24-144 -- Loss: 0.21002808213233948
train-epoch-step: 24-145 -- Loss: 0.14639437198638916
train-epoch-step: 24-146 -- Loss: 0.18764549493789673
train-epoch-step: 24-147 -- Loss: 0.1767856925725937
train-epoch-step: 24-148 -- Loss: 0.17080196738243103
train-epoch-step: 24-149 -- Loss: 0.1249399483203888
train-epoch-step: 24-150 -- Loss: 0.18893678486347198
train-epoch-step: 24-151 -- Loss: 0.1983301192522049
train-epoch-step: 24-152 -- Loss: 0.20369473099708557
train-epoch-step: 24-153 -- Loss: 0.2797549366950989
train-epoch-step: 24-154 -- Loss: 0.14066967368125916
train-epoch-step: 24-155 -- Loss: 0.1403280794620514
train-epoch-step: 24-156 -- Loss: 0.12607169151306152
train-epoch-step: 24-157 -- Loss: 0.17479747533798218
train-epoch-step: 24-158 -- Loss: 0.1663491278886795
train-epoch-step: 24-159 -- Loss: 0.1910305917263031
train-epoch-step: 24-160 -- Loss: 0.23624809086322784
train-epoch-step: 24-161 -- Loss: 0.20839954912662506
train-epoch-step: 24-162 -- Loss: 0.22080108523368835
train-epoch-step: 24-163 -- Loss: 0.2024814337491989
train-epoch-step: 24-164 -- Loss: 0.19900603592395782
train-epoch-step: 24-165 -- Loss: 0.17541679739952087
train-epoch-step: 24-166 -- Loss: 0.1288989931344986
train-epoch-step: 24-167 -- Loss: 0.13613635301589966
train-epoch-step: 24-168 -- Loss: 0.20636364817619324
train-epoch-step: 24-169 -- Loss: 0.14979395270347595
train-epoch-step: 24-170 -- Loss: 0.20822978019714355
train-epoch-step: 24-171 -- Loss: 0.14671829342842102
train-epoch-step: 24-172 -- Loss: 0.2703932225704193
train-epoch-step: 24-173 -- Loss: 0.14649495482444763
train-epoch-step: 24-174 -- Loss: 0.2572175860404968
train-epoch-step: 24-175 -- Loss: 0.1865765005350113
train-epoch-step: 24-176 -- Loss: 0.1398194283246994
train-epoch-step: 24-177 -- Loss: 0.18606720864772797
train-epoch-step: 24-178 -- Loss: 0.18357573449611664
train-epoch-step: 24-179 -- Loss: 0.15995025634765625
train-epoch-step: 24-180 -- Loss: 0.16095000505447388
train-epoch-step: 24-181 -- Loss: 0.17390725016593933
train-epoch-step: 24-182 -- Loss: 0.19926045835018158
train-epoch-step: 24-183 -- Loss: 0.28184831142425537
train-epoch-step: 24-184 -- Loss: 0.1450614184141159
train-epoch-step: 24-185 -- Loss: 0.14850439131259918
train-epoch-step: 24-186 -- Loss: 0.20345643162727356
train-epoch-step: 24-187 -- Loss: 0.21768981218338013
train-epoch-step: 24-188 -- Loss: 0.18687930703163147
train-epoch-step: 24-189 -- Loss: 0.11032998561859131
train-epoch-step: 24-190 -- Loss: 0.184728741645813
train-epoch-step: 24-191 -- Loss: 0.16899381577968597
train-epoch-step: 24-192 -- Loss: 0.24455592036247253
train-epoch-step: 24-193 -- Loss: 0.21824437379837036
train-epoch-step: 24-194 -- Loss: 0.18890391290187836
train-epoch-step: 24-195 -- Loss: 0.17159904539585114
train-epoch-step: 24-196 -- Loss: 0.19678983092308044
train-epoch-step: 24-197 -- Loss: 0.1400914490222931
train-epoch-step: 24-198 -- Loss: 0.13345643877983093
train-epoch-step: 24-199 -- Loss: 0.15994231402873993
train-epoch-step: 24-200 -- Loss: 0.13202513754367828
train-epoch-step: 24-201 -- Loss: 0.2016347050666809
train-epoch-step: 24-202 -- Loss: 0.13927455246448517
train-epoch-step: 24-203 -- Loss: 0.18046680092811584
train-epoch-step: 24-204 -- Loss: 0.14773395657539368
train-epoch-step: 24-205 -- Loss: 0.20348545908927917
train-epoch-step: 24-206 -- Loss: 0.20791718363761902
train-epoch-step: 24-207 -- Loss: 0.16202351450920105
train-epoch-step: 24-208 -- Loss: 0.18429800868034363
train-epoch-step: 24-209 -- Loss: 0.147084042429924
train-epoch-step: 24-210 -- Loss: 0.1394147127866745
train-epoch-step: 24-211 -- Loss: 0.21453766524791718
train-epoch-step: 24-212 -- Loss: 0.20235294103622437
train-epoch-step: 24-213 -- Loss: 0.13181021809577942
train-epoch-step: 24-214 -- Loss: 0.15325134992599487
train-epoch-step: 24-215 -- Loss: 0.13233567774295807
train-epoch-step: 24-216 -- Loss: 0.20736654102802277
train-epoch-step: 24-217 -- Loss: 0.21470066905021667
train-epoch-step: 24-218 -- Loss: 0.1538548767566681
train-epoch-step: 24-219 -- Loss: 0.1868138164281845
train-epoch-step: 24-220 -- Loss: 0.13495570421218872
train-epoch-step: 24-221 -- Loss: 0.20796237885951996
train-epoch-step: 24-222 -- Loss: 0.11969318985939026
train-epoch-step: 24-223 -- Loss: 0.17836077511310577
train-epoch-step: 24-224 -- Loss: 0.19744420051574707
train-epoch-step: 24-225 -- Loss: 0.2852642834186554
train-epoch-step: 24-226 -- Loss: 0.2074054777622223
train-epoch-step: 24-227 -- Loss: 0.2304196059703827
train-epoch-step: 24-228 -- Loss: 0.18064312636852264
train-epoch-step: 24-229 -- Loss: 0.17492519319057465
train-epoch-step: 24-230 -- Loss: 0.17089110612869263
train-epoch-step: 24-231 -- Loss: 0.16085126996040344
train-epoch-step: 24-232 -- Loss: 0.19523198902606964
train-epoch-step: 24-233 -- Loss: 0.0899384543299675
train-epoch-step: 24-234 -- Loss: 0.18904869258403778
train-epoch-step: 24-235 -- Loss: 0.16282615065574646
train-epoch-step: 24-236 -- Loss: 0.18619462847709656
train-epoch-step: 24-237 -- Loss: 0.25025928020477295
train-epoch-step: 24-238 -- Loss: 0.16347108781337738
train-epoch-step: 24-239 -- Loss: 0.12828245759010315
train-epoch-step: 24-240 -- Loss: 0.23089486360549927
train-epoch-step: 24-241 -- Loss: 0.16153573989868164
train-epoch-step: 24-242 -- Loss: 0.23409920930862427
train-epoch-step: 24-243 -- Loss: 0.24068523943424225
train-epoch-step: 24-244 -- Loss: 0.2190520465373993
train-epoch-step: 24-245 -- Loss: 0.22433359920978546
train-epoch-step: 24-246 -- Loss: 0.22493362426757812
train-epoch-step: 24-247 -- Loss: 0.22427476942539215
train-epoch-step: 24-248 -- Loss: 0.19324913620948792
train-epoch-step: 24-249 -- Loss: 0.14497464895248413
train-epoch-step: 24-250 -- Loss: 0.20845139026641846
train-epoch-step: 24-251 -- Loss: 0.11003810912370682
train-epoch-step: 24-252 -- Loss: 0.19826042652130127
train-epoch-step: 24-253 -- Loss: 0.14222225546836853
train-epoch-step: 24-254 -- Loss: 0.22103911638259888
train-epoch-step: 24-255 -- Loss: 0.15304361283779144
train-epoch-step: 24-256 -- Loss: 0.16220316290855408
train-epoch-step: 24-257 -- Loss: 0.1982860118150711
train-epoch-step: 24-258 -- Loss: 0.15191537141799927
train-epoch-step: 24-259 -- Loss: 0.11845672875642776
train-epoch-step: 24-260 -- Loss: 0.20847241580486298
train-epoch-step: 24-261 -- Loss: 0.19148781895637512
train-epoch-step: 24-262 -- Loss: 0.31289762258529663
train-epoch-step: 24-263 -- Loss: 0.20792925357818604
train-epoch-step: 24-264 -- Loss: 0.17386455833911896
train-epoch-step: 24-265 -- Loss: 0.13110926747322083
train-epoch-step: 24-266 -- Loss: 0.1537269651889801
train-epoch-step: 24-267 -- Loss: 0.13342741131782532
train-epoch-step: 24-268 -- Loss: 0.1253577172756195
train-epoch-step: 24-269 -- Loss: 0.17841149866580963
train-epoch-step: 24-270 -- Loss: 0.11070754379034042
train-epoch-step: 24-271 -- Loss: 0.15676787495613098
train-epoch-step: 24-272 -- Loss: 0.11897075176239014
train-epoch-step: 24-273 -- Loss: 0.12817946076393127
train-epoch-step: 24-274 -- Loss: 0.1951531022787094
train-epoch-step: 24-275 -- Loss: 0.21373172104358673
train-epoch-step: 24-276 -- Loss: 0.1660994589328766
train-epoch-step: 24-277 -- Loss: 0.16212600469589233
train-epoch-step: 24-278 -- Loss: 0.14515207707881927
train-epoch-step: 24-279 -- Loss: 0.15218894183635712
train-epoch-step: 24-280 -- Loss: 0.22582101821899414
train-epoch-step: 24-281 -- Loss: 0.18501396477222443
train-epoch-step: 24-282 -- Loss: 0.1484202891588211
train-epoch-step: 24-283 -- Loss: 0.12372276186943054
train-epoch-step: 24-284 -- Loss: 0.15552040934562683
train-epoch-step: 24-285 -- Loss: 0.19965916872024536
train-epoch-step: 24-286 -- Loss: 0.15830431878566742
train-epoch-step: 24-287 -- Loss: 0.21057242155075073
train-epoch-step: 24-288 -- Loss: 0.10089482367038727
train-epoch-step: 24-289 -- Loss: 0.1284649521112442
train-epoch-step: 24-290 -- Loss: 0.18895244598388672
train-epoch-step: 24-291 -- Loss: 0.11940249800682068
train-epoch-step: 24-292 -- Loss: 0.15748563408851624
train-epoch-step: 24-293 -- Loss: 0.1434246301651001
train-epoch-step: 24-294 -- Loss: 0.1886778473854065
train-epoch-step: 24-295 -- Loss: 0.28400224447250366
train-epoch-step: 24-296 -- Loss: 0.16372185945510864
train-epoch-step: 24-297 -- Loss: 0.18028493225574493
train-epoch-step: 24-298 -- Loss: 0.24566960334777832
train-epoch-step: 24-299 -- Loss: 0.15778684616088867
train-epoch-step: 24-300 -- Loss: 0.17654067277908325
train-epoch-step: 24-301 -- Loss: 0.17189684510231018
train-epoch-step: 24-302 -- Loss: 0.23334631323814392
train-epoch-step: 24-303 -- Loss: 0.2140958458185196
train-epoch-step: 24-304 -- Loss: 0.14356687664985657
train-epoch-step: 24-305 -- Loss: 0.14737427234649658
train-epoch-step: 24-306 -- Loss: 0.2409200817346573
train-epoch-step: 24-307 -- Loss: 0.17024652659893036
train-epoch-step: 24-308 -- Loss: 0.23081092536449432
train-epoch-step: 24-309 -- Loss: 0.16302885115146637
train-epoch-step: 24-310 -- Loss: 0.1655724048614502
train-epoch-step: 24-311 -- Loss: 0.16826045513153076
train-epoch-step: 24-312 -- Loss: 0.21134677529335022
train-epoch-step: 24-313 -- Loss: 0.10322359204292297
train-epoch-step: 24-314 -- Loss: 0.20645639300346375
train-epoch-step: 24-315 -- Loss: 0.17844277620315552
train-epoch-step: 24-316 -- Loss: 0.15975189208984375
train-epoch-step: 24-317 -- Loss: 0.14955928921699524
train-epoch-step: 24-318 -- Loss: 0.1627521961927414
train-epoch-step: 24-319 -- Loss: 0.175122931599617
train-epoch-step: 24-320 -- Loss: 0.12233343720436096
train-epoch-step: 24-321 -- Loss: 0.13983024656772614
train-epoch-step: 24-322 -- Loss: 0.2167181521654129
train-epoch-step: 24-323 -- Loss: 0.16825848817825317
train-epoch-step: 24-324 -- Loss: 0.26740381121635437
train-epoch-step: 24-325 -- Loss: 0.16785487532615662
train-epoch-step: 24-326 -- Loss: 0.1811758428812027
train-epoch-step: 24-327 -- Loss: 0.21503378450870514
train-epoch-step: 24-328 -- Loss: 0.19299305975437164
train-epoch-step: 24-329 -- Loss: 0.3593009114265442
train-epoch-step: 24-330 -- Loss: 0.3726058006286621
train-epoch-step: 24-331 -- Loss: 0.21128281950950623
train-epoch-step: 24-332 -- Loss: 0.10064808279275894
train-epoch-step: 24-333 -- Loss: 0.19202649593353271
train-epoch-step: 24-334 -- Loss: 0.157928004860878
train-epoch-step: 24-335 -- Loss: 0.18678471446037292
train-epoch-step: 24-336 -- Loss: 0.1578158289194107
train-epoch-step: 24-337 -- Loss: 0.2130330502986908
train-epoch-step: 24-338 -- Loss: 0.16540245711803436
train-epoch-step: 24-339 -- Loss: 0.14463767409324646
train-epoch-step: 24-340 -- Loss: 0.2065410614013672
train-epoch-step: 24-341 -- Loss: 0.1455041617155075
train-epoch-step: 24-342 -- Loss: 0.16758644580841064
train-epoch-step: 24-343 -- Loss: 0.15963904559612274
train-epoch-step: 24-344 -- Loss: 0.17376405000686646
train-epoch-step: 24-345 -- Loss: 0.13121384382247925
train-epoch-step: 24-346 -- Loss: 0.21885456144809723
train-epoch-step: 24-347 -- Loss: 0.15414060652256012
train-epoch-step: 24-348 -- Loss: 0.21476468443870544
train-epoch-step: 24-349 -- Loss: 0.2096807062625885
train-epoch-step: 24-350 -- Loss: 0.2635015845298767
train-epoch-step: 24-351 -- Loss: 0.20231758058071136
train-epoch-step: 24-352 -- Loss: 0.12929192185401917
train-epoch-step: 24-353 -- Loss: 0.20449323952198029
train-epoch-step: 24-354 -- Loss: 0.29187947511672974
train-epoch-step: 24-355 -- Loss: 0.12516218423843384
train-epoch-step: 24-356 -- Loss: 0.11986487358808517
train-epoch-step: 24-357 -- Loss: 0.20237739384174347
train-epoch-step: 24-358 -- Loss: 0.18697278201580048
train-epoch-step: 24-359 -- Loss: 0.1649502068758011
train-epoch-step: 24-360 -- Loss: 0.1255131959915161
train-epoch-step: 24-361 -- Loss: 0.24077488481998444
train-epoch-step: 24-362 -- Loss: 0.17616775631904602
train-epoch-step: 24-363 -- Loss: 0.12756851315498352
train-epoch-step: 24-364 -- Loss: 0.18533417582511902
train-epoch-step: 24-365 -- Loss: 0.17758432030677795
train-epoch-step: 24-366 -- Loss: 0.21503105759620667
train-epoch-step: 24-367 -- Loss: 0.2390212118625641
train-epoch-step: 24-368 -- Loss: 0.21187236905097961
train-epoch-step: 24-369 -- Loss: 0.28435012698173523
train-epoch-step: 24-370 -- Loss: 0.1285860687494278
train-epoch-step: 24-371 -- Loss: 0.12381843477487564
train-epoch-step: 24-372 -- Loss: 0.1544448733329773
train-epoch-step: 24-373 -- Loss: 0.20572590827941895
train-epoch-step: 24-374 -- Loss: 0.15701347589492798
train-epoch-step: 24-375 -- Loss: 0.2821972966194153
train-epoch-step: 24-376 -- Loss: 0.17536039650440216
train-epoch-step: 24-377 -- Loss: 0.23836451768875122
train-epoch-step: 24-378 -- Loss: 0.2205786556005478
train-epoch-step: 24-379 -- Loss: 0.12361858785152435
train-epoch-step: 24-380 -- Loss: 0.09386923164129257
train-epoch-step: 24-381 -- Loss: 0.25407129526138306
train-epoch-step: 24-382 -- Loss: 0.23982176184654236
train-epoch-step: 24-383 -- Loss: 0.1880224049091339
train-epoch-step: 24-384 -- Loss: 0.26019519567489624
train-epoch-step: 24-385 -- Loss: 0.19605503976345062
train-epoch-step: 24-386 -- Loss: 0.19622308015823364
train-epoch-step: 24-387 -- Loss: 0.21043896675109863
train-epoch-step: 24-388 -- Loss: 0.21293076872825623
train-epoch-step: 24-389 -- Loss: 0.17357946932315826
train-epoch-step: 24-390 -- Loss: 0.1489892154932022
train-epoch-step: 24-391 -- Loss: 0.15069791674613953
train-epoch-step: 24-392 -- Loss: 0.19181156158447266
train-epoch-step: 24-393 -- Loss: 0.16305121779441833
train-epoch-step: 24-394 -- Loss: 0.2201719880104065
train-epoch-step: 24-395 -- Loss: 0.17087146639823914
train-epoch-step: 24-396 -- Loss: 0.13060253858566284
train-epoch-step: 24-397 -- Loss: 0.13215039670467377
train-epoch-step: 24-398 -- Loss: 0.20478421449661255
train-epoch-step: 24-399 -- Loss: 0.1853403002023697
train-epoch-step: 24-400 -- Loss: 0.2879452109336853
train-epoch-step: 24-401 -- Loss: 0.12995320558547974
train-epoch-step: 24-402 -- Loss: 0.2615610361099243
train-epoch-step: 24-403 -- Loss: 0.16503414511680603
train-epoch-step: 24-404 -- Loss: 0.1413707733154297
train-epoch-step: 24-405 -- Loss: 0.1457776427268982
train-epoch-step: 24-406 -- Loss: 0.17998161911964417
train-epoch-step: 24-407 -- Loss: 0.12021242082118988
train-epoch-step: 24-408 -- Loss: 0.16871723532676697
train-epoch-step: 24-409 -- Loss: 0.17709898948669434
train-epoch-step: 24-410 -- Loss: 0.17791850864887238
train-epoch-step: 24-411 -- Loss: 0.21184754371643066
train-epoch-step: 24-412 -- Loss: 0.13457569479942322
train-epoch-step: 24-413 -- Loss: 0.152171328663826
train-epoch-step: 24-414 -- Loss: 0.13722263276576996
train-epoch-step: 24-415 -- Loss: 0.1374320387840271
train-epoch-step: 24-416 -- Loss: 0.270467072725296
train-epoch-step: 24-417 -- Loss: 0.19778917729854584
train-epoch-step: 24-418 -- Loss: 0.2552812695503235
train-epoch-step: 24-419 -- Loss: 0.17410025000572205
train-epoch-step: 24-420 -- Loss: 0.15826644003391266
train-epoch-step: 24-421 -- Loss: 0.2092437893152237
train-epoch-step: 24-422 -- Loss: 0.1579548418521881
train-epoch-step: 24-423 -- Loss: 0.18259374797344208
train-epoch-step: 24-424 -- Loss: 0.14503517746925354
train-epoch-step: 24-425 -- Loss: 0.1872323453426361
train-epoch-step: 24-426 -- Loss: 0.16803936660289764
train-epoch-step: 24-427 -- Loss: 0.13152463734149933
train-epoch-step: 24-428 -- Loss: 0.20213332772254944
train-epoch-step: 24-429 -- Loss: 0.18544277548789978
train-epoch-step: 24-430 -- Loss: 0.17926129698753357
train-epoch-step: 24-431 -- Loss: 0.171153262257576
train-epoch-step: 24-432 -- Loss: 0.2446068525314331
train-epoch-step: 24-433 -- Loss: 0.1429775208234787
train-epoch-step: 24-434 -- Loss: 0.1356327086687088
train-epoch-step: 24-435 -- Loss: 0.17600823938846588
train-epoch-step: 24-436 -- Loss: 0.16240233182907104
train-epoch-step: 24-437 -- Loss: 0.1426950842142105
train-epoch-step: 24-438 -- Loss: 0.17023295164108276
train-epoch-step: 24-439 -- Loss: 0.28618520498275757
train-epoch-step: 24-440 -- Loss: 0.13687214255332947
train-epoch-step: 24-441 -- Loss: 0.21254579722881317
train-epoch-step: 24-442 -- Loss: 0.18714603781700134
train-epoch-step: 24-443 -- Loss: 0.16773349046707153
train-epoch-step: 24-444 -- Loss: 0.18302218616008759
train-epoch-step: 24-445 -- Loss: 0.1846686601638794
train-epoch-step: 24-446 -- Loss: 0.15808100998401642
train-epoch-step: 24-447 -- Loss: 0.20260244607925415
train-epoch-step: 24-448 -- Loss: 0.2442215085029602
train-epoch-step: 24-449 -- Loss: 0.2035714089870453
train-epoch-step: 24-450 -- Loss: 0.18950089812278748
train-epoch-step: 24-451 -- Loss: 0.14780709147453308
train-epoch-step: 24-452 -- Loss: 0.13695432245731354
train-epoch-step: 24-453 -- Loss: 0.0990966185927391
train-epoch-step: 24-454 -- Loss: 0.23551622033119202
train-epoch-step: 24-455 -- Loss: 0.13537058234214783
train-epoch-step: 24-456 -- Loss: 0.1245884820818901
train-epoch-step: 24-457 -- Loss: 0.22384490072727203
train-epoch-step: 24-458 -- Loss: 0.1619878113269806
train-epoch-step: 24-459 -- Loss: 0.22998514771461487
train-epoch-step: 24-460 -- Loss: 0.13262522220611572
train-epoch-step: 24-461 -- Loss: 0.1389806568622589
train-epoch-step: 24-462 -- Loss: 0.16668090224266052
train-epoch-step: 24-463 -- Loss: 0.14212650060653687
train-epoch-step: 24-464 -- Loss: 0.1747463196516037
train-epoch-step: 24-465 -- Loss: 0.2562991678714752
train-epoch-step: 24-466 -- Loss: 0.2123355269432068
train-epoch-step: 24-467 -- Loss: 0.11540046334266663
train-epoch-step: 24-468 -- Loss: 0.17482773959636688
train-epoch-step: 24-469 -- Loss: 0.2178892344236374
train-epoch-step: 24-470 -- Loss: 0.18411268293857574
train-epoch-step: 24-471 -- Loss: 0.16199249029159546
train-epoch-step: 24-472 -- Loss: 0.16380372643470764
train-epoch-step: 24-473 -- Loss: 0.15711583197116852
train-epoch-step: 24-474 -- Loss: 0.12612520158290863
train-epoch-step: 24-475 -- Loss: 0.11601637303829193
train-epoch-step: 24-476 -- Loss: 0.20847183465957642
train-epoch-step: 24-477 -- Loss: 0.21094103157520294
train-epoch-step: 24-478 -- Loss: 0.19200117886066437
train-epoch-step: 24-479 -- Loss: 0.14736035466194153
train-epoch-step: 24-480 -- Loss: 0.20203621685504913
train-epoch-step: 24-481 -- Loss: 0.2931678295135498
train-epoch-step: 24-482 -- Loss: 0.25149619579315186
train-epoch-step: 24-483 -- Loss: 0.18513908982276917
train-epoch-step: 24-484 -- Loss: 0.2198474407196045
train-epoch-step: 24-485 -- Loss: 0.1303820163011551
train-epoch-step: 24-486 -- Loss: 0.24130019545555115
train-epoch-step: 24-487 -- Loss: 0.2379123419523239
train-epoch-step: 24-488 -- Loss: 0.19321487843990326
train-epoch-step: 24-489 -- Loss: 0.224942147731781
train-epoch-step: 24-490 -- Loss: 0.14244139194488525
train-epoch-step: 24-491 -- Loss: 0.1486140936613083
train-epoch-step: 24-492 -- Loss: 0.12552140653133392
train-epoch-step: 24-493 -- Loss: 0.2084057480096817
train-epoch-step: 24-494 -- Loss: 0.2144722193479538
train-epoch-step: 24-495 -- Loss: 0.20705212652683258
train-epoch-step: 24-496 -- Loss: 0.14008501172065735
train-epoch-step: 24-497 -- Loss: 0.19311442971229553
train-epoch-step: 24-498 -- Loss: 0.15308886766433716
train-epoch-step: 24-499 -- Loss: 0.17461910843849182
train-epoch-step: 24-500 -- Loss: 0.1614401489496231
train-epoch-step: 24-501 -- Loss: 0.2190757840871811
train-epoch-step: 24-502 -- Loss: 0.1706101894378662
train-epoch-step: 24-503 -- Loss: 0.2244122326374054
train-epoch-step: 24-504 -- Loss: 0.12415726482868195
train-epoch-step: 24-505 -- Loss: 0.1759108603000641
train-epoch-step: 24-506 -- Loss: 0.12422695010900497
train-epoch-step: 24-507 -- Loss: 0.18498682975769043
train-epoch-step: 24-508 -- Loss: 0.1833931803703308
train-epoch-step: 24-509 -- Loss: 0.1712045967578888
train-epoch-step: 24-510 -- Loss: 0.13461492955684662
train-epoch-step: 24-511 -- Loss: 0.2236836701631546
train-epoch-step: 24-512 -- Loss: 0.18438902497291565
train-epoch-step: 24-513 -- Loss: 0.20661228895187378
train-epoch-step: 24-514 -- Loss: 0.15291117131710052
train-epoch-step: 24-515 -- Loss: 0.1634632647037506
train-epoch-step: 24-516 -- Loss: 0.17681831121444702
train-epoch-step: 24-517 -- Loss: 0.17998456954956055
train-epoch-step: 24-518 -- Loss: 0.14285682141780853
train-epoch-step: 24-519 -- Loss: 0.13675054907798767
train-epoch-step: 24-520 -- Loss: 0.19322305917739868
train-epoch-step: 24-521 -- Loss: 0.23352396488189697
train-epoch-step: 24-522 -- Loss: 0.17530325055122375
train-epoch-step: 24-523 -- Loss: 0.16463862359523773
train-epoch-step: 24-524 -- Loss: 0.17121581733226776
train-epoch-step: 24-525 -- Loss: 0.19405655562877655
train-epoch-step: 24-526 -- Loss: 0.13307279348373413
train-epoch-step: 24-527 -- Loss: 0.15831094980239868
train-epoch-step: 24-528 -- Loss: 0.16524076461791992
train-epoch-step: 24-529 -- Loss: 0.16719786822795868
train-epoch-step: 24-530 -- Loss: 0.19188538193702698
train-epoch-step: 24-531 -- Loss: 0.21249479055404663
train-epoch-step: 24-532 -- Loss: 0.17471149563789368
train-epoch-step: 24-533 -- Loss: 0.17383034527301788
train-epoch-step: 24-534 -- Loss: 0.1364685595035553
train-epoch-step: 24-535 -- Loss: 0.26226651668548584
train-epoch-step: 24-536 -- Loss: 0.16627007722854614
train-epoch-step: 24-537 -- Loss: 0.1639961302280426
train-epoch-step: 24-538 -- Loss: 0.10692009329795837
train-epoch-step: 24-539 -- Loss: 0.19077855348587036
train-epoch-step: 24-540 -- Loss: 0.13932445645332336
train-epoch-step: 24-541 -- Loss: 0.2113451510667801
train-epoch-step: 24-542 -- Loss: 0.24125078320503235
train-epoch-step: 24-543 -- Loss: 0.1746460199356079
train-epoch-step: 24-544 -- Loss: 0.23445576429367065
train-epoch-step: 24-545 -- Loss: 0.1986294835805893
train-epoch-step: 24-546 -- Loss: 0.22102439403533936
train-epoch-step: 24-547 -- Loss: 0.18233250081539154
train-epoch-step: 24-548 -- Loss: 0.10077790915966034
train-epoch-step: 24-549 -- Loss: 0.16215579211711884
train-epoch-step: 24-550 -- Loss: 0.2044336050748825
train-epoch-step: 24-551 -- Loss: 0.16402174532413483
train-epoch-step: 24-552 -- Loss: 0.1363786906003952
train-epoch-step: 24-553 -- Loss: 0.20202654600143433
train-epoch-step: 24-554 -- Loss: 0.20165231823921204
train-epoch-step: 24-555 -- Loss: 0.2209126502275467
train-epoch-step: 24-556 -- Loss: 0.1687072515487671
train-epoch-step: 24-557 -- Loss: 0.24642392992973328
train-epoch-step: 24-558 -- Loss: 0.23746082186698914
train-epoch-step: 24-559 -- Loss: 0.15022128820419312
train-epoch-step: 24-560 -- Loss: 0.2265859842300415
train-epoch-step: 24-561 -- Loss: 0.19708362221717834
train-epoch-step: 24-562 -- Loss: 0.16987884044647217
train-epoch-step: 24-563 -- Loss: 0.18914075195789337
train-epoch-step: 24-564 -- Loss: 0.10380454361438751
train-epoch-step: 24-565 -- Loss: 0.19872654974460602
train-epoch-step: 24-566 -- Loss: 0.15485629439353943
train-epoch-step: 24-567 -- Loss: 0.21568390727043152
train-epoch-step: 24-568 -- Loss: 0.16607944667339325
train-epoch-step: 24-569 -- Loss: 0.24725313484668732
train-epoch-step: 24-570 -- Loss: 0.19262850284576416
train-epoch-step: 24-571 -- Loss: 0.22604021430015564
train-epoch-step: 24-572 -- Loss: 0.24500542879104614
train-epoch-step: 24-573 -- Loss: 0.21018525958061218
train-epoch-step: 24-574 -- Loss: 0.2543836832046509
train-epoch-step: 24-575 -- Loss: 0.3026435077190399
train-epoch-step: 24-576 -- Loss: 0.12656831741333008
train-epoch-step: 24-577 -- Loss: 0.1726057529449463
train-epoch-step: 24-578 -- Loss: 0.22654980421066284
train-epoch-step: 24-579 -- Loss: 0.17581522464752197
train-epoch-step: 24-580 -- Loss: 0.1828663945198059
train-epoch-step: 24-581 -- Loss: 0.15412963926792145
train-epoch-step: 24-582 -- Loss: 0.2063380777835846
train-epoch-step: 24-583 -- Loss: 0.24224722385406494
train-epoch-step: 24-584 -- Loss: 0.17089521884918213
train-epoch-step: 24-585 -- Loss: 0.19747783243656158
train-epoch-step: 24-586 -- Loss: 0.26100075244903564
train-epoch-step: 24-587 -- Loss: 0.16207298636436462
train-epoch-step: 24-588 -- Loss: 0.13139723241329193
val-epoch-step: 24-589 -- Loss: 0.23847931623458862
val-epoch-step: 24-590 -- Loss: 0.1572573482990265
val-epoch-step: 24-591 -- Loss: 0.23374821245670319
val-epoch-step: 24-592 -- Loss: 0.17991983890533447
val-epoch-step: 24-593 -- Loss: 0.15487298369407654
val-epoch-step: 24-594 -- Loss: 0.3569680452346802
val-epoch-step: 24-595 -- Loss: 0.18317995965480804
val-epoch-step: 24-596 -- Loss: 0.200382262468338
val-epoch-step: 24-597 -- Loss: 0.1761196255683899
val-epoch-step: 24-598 -- Loss: 0.15604336559772491
val-epoch-step: 24-599 -- Loss: 0.18823298811912537
val-epoch-step: 24-600 -- Loss: 0.2068517953157425
val-epoch-step: 24-601 -- Loss: 0.1622774749994278
val-epoch-step: 24-602 -- Loss: 0.13898131251335144
val-epoch-step: 24-603 -- Loss: 0.21858097612857819
val-epoch-step: 24-604 -- Loss: 0.15350036323070526
val-epoch-step: 24-605 -- Loss: 0.14973613619804382
val-epoch-step: 24-606 -- Loss: 0.2791029214859009
val-epoch-step: 24-607 -- Loss: 0.13023023307323456
val-epoch-step: 24-608 -- Loss: 0.258301705121994
val-epoch-step: 24-609 -- Loss: 0.17252419888973236
val-epoch-step: 24-610 -- Loss: 0.1879168301820755
val-epoch-step: 24-611 -- Loss: 0.15742644667625427
val-epoch-step: 24-612 -- Loss: 0.3788919448852539
val-epoch-step: 24-613 -- Loss: 0.17759649455547333
val-epoch-step: 24-614 -- Loss: 0.17368389666080475
val-epoch-step: 24-615 -- Loss: 0.18071603775024414
val-epoch-step: 24-616 -- Loss: 0.15834484994411469
val-epoch-step: 24-617 -- Loss: 0.19390073418617249
val-epoch-step: 24-618 -- Loss: 0.18966470658779144
val-epoch-step: 24-619 -- Loss: 0.21812650561332703
val-epoch-step: 24-620 -- Loss: 0.1429653912782669
val-epoch-step: 24-621 -- Loss: 0.1284763365983963
val-epoch-step: 24-622 -- Loss: 0.14904417097568512
val-epoch-step: 24-623 -- Loss: 0.15952210128307343
val-epoch-step: 24-624 -- Loss: 0.15424418449401855
val-epoch-step: 24-625 -- Loss: 0.1671375334262848
val-epoch-step: 24-626 -- Loss: 0.15069714188575745
val-epoch-step: 24-627 -- Loss: 0.189032644033432
val-epoch-step: 24-628 -- Loss: 0.6160739660263062
val-epoch-step: 24-629 -- Loss: 0.19344691932201385
val-epoch-step: 24-630 -- Loss: 0.36013180017471313
val-epoch-step: 24-631 -- Loss: 0.14978298544883728
val-epoch-step: 24-632 -- Loss: 0.19753074645996094
val-epoch-step: 24-633 -- Loss: 0.15704239904880524
val-epoch-step: 24-634 -- Loss: 0.15472765266895294
val-epoch-step: 24-635 -- Loss: 0.1240529790520668
val-epoch-step: 24-636 -- Loss: 0.17152515053749084
val-epoch-step: 24-637 -- Loss: 0.1909278780221939
val-epoch-step: 24-638 -- Loss: 0.14801086485385895
val-epoch-step: 24-639 -- Loss: 0.2567913234233856
val-epoch-step: 24-640 -- Loss: 0.2672865688800812
val-epoch-step: 24-641 -- Loss: 0.12675690650939941
val-epoch-step: 24-642 -- Loss: 0.19457115232944489
val-epoch-step: 24-643 -- Loss: 0.21051570773124695
val-epoch-step: 24-644 -- Loss: 0.16826458275318146
val-epoch-step: 24-645 -- Loss: 0.22525104880332947
val-epoch-step: 24-646 -- Loss: 0.13582564890384674
val-epoch-step: 24-647 -- Loss: 0.13948726654052734
val-epoch-step: 24-648 -- Loss: 0.16212880611419678
val-epoch-step: 24-649 -- Loss: 0.21527636051177979
val-epoch-step: 24-650 -- Loss: 0.2616537809371948
val-epoch-step: 24-651 -- Loss: 0.1517668068408966
val-epoch-step: 24-652 -- Loss: 0.15812769532203674
val-epoch-step: 24-653 -- Loss: 0.21417400240898132
val-epoch-step: 24-654 -- Loss: 0.11744769662618637
Epoch: 24 -- Train Loss: tensor(0.1448, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 25-0 -- Loss: 0.23162683844566345
train-epoch-step: 25-1 -- Loss: 0.15206396579742432
train-epoch-step: 25-2 -- Loss: 0.20059393346309662
train-epoch-step: 25-3 -- Loss: 0.14510875940322876
train-epoch-step: 25-4 -- Loss: 0.16597586870193481
train-epoch-step: 25-5 -- Loss: 0.18763016164302826
train-epoch-step: 25-6 -- Loss: 0.22839610278606415
train-epoch-step: 25-7 -- Loss: 0.17128410935401917
train-epoch-step: 25-8 -- Loss: 0.19736289978027344
train-epoch-step: 25-9 -- Loss: 0.23715761303901672
train-epoch-step: 25-10 -- Loss: 0.2052505612373352
train-epoch-step: 25-11 -- Loss: 0.17828628420829773
train-epoch-step: 25-12 -- Loss: 0.15482649207115173
train-epoch-step: 25-13 -- Loss: 0.1843976080417633
train-epoch-step: 25-14 -- Loss: 0.1674041599035263
train-epoch-step: 25-15 -- Loss: 0.16456975042819977
train-epoch-step: 25-16 -- Loss: 0.17127293348312378
train-epoch-step: 25-17 -- Loss: 0.23389825224876404
train-epoch-step: 25-18 -- Loss: 0.2003680169582367
train-epoch-step: 25-19 -- Loss: 0.13285872340202332
train-epoch-step: 25-20 -- Loss: 0.22275665402412415
train-epoch-step: 25-21 -- Loss: 0.3086261749267578
train-epoch-step: 25-22 -- Loss: 0.15193411707878113
train-epoch-step: 25-23 -- Loss: 0.14908131957054138
train-epoch-step: 25-24 -- Loss: 0.13482797145843506
train-epoch-step: 25-25 -- Loss: 0.2563420832157135
train-epoch-step: 25-26 -- Loss: 0.21629363298416138
train-epoch-step: 25-27 -- Loss: 0.3042250871658325
train-epoch-step: 25-28 -- Loss: 0.1296638399362564
train-epoch-step: 25-29 -- Loss: 0.27046480774879456
train-epoch-step: 25-30 -- Loss: 0.11845391988754272
train-epoch-step: 25-31 -- Loss: 0.1480080634355545
train-epoch-step: 25-32 -- Loss: 0.18165048956871033
train-epoch-step: 25-33 -- Loss: 0.2904270589351654
train-epoch-step: 25-34 -- Loss: 0.18737059831619263
train-epoch-step: 25-35 -- Loss: 0.26064443588256836
train-epoch-step: 25-36 -- Loss: 0.14713284373283386
train-epoch-step: 25-37 -- Loss: 0.1446589082479477
train-epoch-step: 25-38 -- Loss: 0.21195755898952484
train-epoch-step: 25-39 -- Loss: 0.25560227036476135
train-epoch-step: 25-40 -- Loss: 0.21913978457450867
train-epoch-step: 25-41 -- Loss: 0.2262040078639984
train-epoch-step: 25-42 -- Loss: 0.1536787897348404
train-epoch-step: 25-43 -- Loss: 0.3206698000431061
train-epoch-step: 25-44 -- Loss: 0.1345406472682953
train-epoch-step: 25-45 -- Loss: 0.12612813711166382
train-epoch-step: 25-46 -- Loss: 0.17869822680950165
train-epoch-step: 25-47 -- Loss: 0.24070775508880615
train-epoch-step: 25-48 -- Loss: 0.16103771328926086
train-epoch-step: 25-49 -- Loss: 0.24174155294895172
train-epoch-step: 25-50 -- Loss: 0.12329994887113571
train-epoch-step: 25-51 -- Loss: 0.21961389482021332
train-epoch-step: 25-52 -- Loss: 0.16964495182037354
train-epoch-step: 25-53 -- Loss: 0.2182179093360901
train-epoch-step: 25-54 -- Loss: 0.29434746503829956
train-epoch-step: 25-55 -- Loss: 0.1741451621055603
train-epoch-step: 25-56 -- Loss: 0.1880941092967987
train-epoch-step: 25-57 -- Loss: 0.24188530445098877
train-epoch-step: 25-58 -- Loss: 0.28933271765708923
train-epoch-step: 25-59 -- Loss: 0.271799236536026
train-epoch-step: 25-60 -- Loss: 0.14481082558631897
train-epoch-step: 25-61 -- Loss: 0.21240025758743286
train-epoch-step: 25-62 -- Loss: 0.19496148824691772
train-epoch-step: 25-63 -- Loss: 0.14425478875637054
train-epoch-step: 25-64 -- Loss: 0.16671115159988403
train-epoch-step: 25-65 -- Loss: 0.18669387698173523
train-epoch-step: 25-66 -- Loss: 0.11639997363090515
train-epoch-step: 25-67 -- Loss: 0.13065789639949799
train-epoch-step: 25-68 -- Loss: 0.22645726799964905
train-epoch-step: 25-69 -- Loss: 0.1378171443939209
train-epoch-step: 25-70 -- Loss: 0.2320861518383026
train-epoch-step: 25-71 -- Loss: 0.27613896131515503
train-epoch-step: 25-72 -- Loss: 0.18604181706905365
train-epoch-step: 25-73 -- Loss: 0.23436997830867767
train-epoch-step: 25-74 -- Loss: 0.10357099026441574
train-epoch-step: 25-75 -- Loss: 0.13245734572410583
train-epoch-step: 25-76 -- Loss: 0.15372110903263092
train-epoch-step: 25-77 -- Loss: 0.23340392112731934
train-epoch-step: 25-78 -- Loss: 0.2634464204311371
train-epoch-step: 25-79 -- Loss: 0.20841708779335022
train-epoch-step: 25-80 -- Loss: 0.271985799074173
train-epoch-step: 25-81 -- Loss: 0.13089004158973694
train-epoch-step: 25-82 -- Loss: 0.258229523897171
train-epoch-step: 25-83 -- Loss: 0.18837566673755646
train-epoch-step: 25-84 -- Loss: 0.2034623622894287
train-epoch-step: 25-85 -- Loss: 0.1828688383102417
train-epoch-step: 25-86 -- Loss: 0.13080310821533203
train-epoch-step: 25-87 -- Loss: 0.2356615513563156
train-epoch-step: 25-88 -- Loss: 0.15666580200195312
train-epoch-step: 25-89 -- Loss: 0.19296853244304657
train-epoch-step: 25-90 -- Loss: 0.19866235554218292
train-epoch-step: 25-91 -- Loss: 0.25775980949401855
train-epoch-step: 25-92 -- Loss: 0.15845425426959991
train-epoch-step: 25-93 -- Loss: 0.17998242378234863
train-epoch-step: 25-94 -- Loss: 0.2269640862941742
train-epoch-step: 25-95 -- Loss: 0.20112678408622742
train-epoch-step: 25-96 -- Loss: 0.22664935886859894
train-epoch-step: 25-97 -- Loss: 0.17873817682266235
train-epoch-step: 25-98 -- Loss: 0.1577778160572052
train-epoch-step: 25-99 -- Loss: 0.1830798089504242
train-epoch-step: 25-100 -- Loss: 0.19145452976226807
train-epoch-step: 25-101 -- Loss: 0.28112050890922546
train-epoch-step: 25-102 -- Loss: 0.23296475410461426
train-epoch-step: 25-103 -- Loss: 0.19359265267848969
train-epoch-step: 25-104 -- Loss: 0.1525191366672516
train-epoch-step: 25-105 -- Loss: 0.28265222907066345
train-epoch-step: 25-106 -- Loss: 0.17835773527622223
train-epoch-step: 25-107 -- Loss: 0.1918899565935135
train-epoch-step: 25-108 -- Loss: 0.19365616142749786
train-epoch-step: 25-109 -- Loss: 0.15324673056602478
train-epoch-step: 25-110 -- Loss: 0.1887984275817871
train-epoch-step: 25-111 -- Loss: 0.19013109803199768
train-epoch-step: 25-112 -- Loss: 0.17911306023597717
train-epoch-step: 25-113 -- Loss: 0.16545896232128143
train-epoch-step: 25-114 -- Loss: 0.20966646075248718
train-epoch-step: 25-115 -- Loss: 0.16998963057994843
train-epoch-step: 25-116 -- Loss: 0.14843599498271942
train-epoch-step: 25-117 -- Loss: 0.13467974960803986
train-epoch-step: 25-118 -- Loss: 0.20265710353851318
train-epoch-step: 25-119 -- Loss: 0.16401620209217072
train-epoch-step: 25-120 -- Loss: 0.2590096890926361
train-epoch-step: 25-121 -- Loss: 0.26355308294296265
train-epoch-step: 25-122 -- Loss: 0.2277030646800995
train-epoch-step: 25-123 -- Loss: 0.2157379537820816
train-epoch-step: 25-124 -- Loss: 0.13006222248077393
train-epoch-step: 25-125 -- Loss: 0.1611400842666626
train-epoch-step: 25-126 -- Loss: 0.23880606889724731
train-epoch-step: 25-127 -- Loss: 0.18062403798103333
train-epoch-step: 25-128 -- Loss: 0.17591533064842224
train-epoch-step: 25-129 -- Loss: 0.14769908785820007
train-epoch-step: 25-130 -- Loss: 0.1964634358882904
train-epoch-step: 25-131 -- Loss: 0.1451902538537979
train-epoch-step: 25-132 -- Loss: 0.19975978136062622
train-epoch-step: 25-133 -- Loss: 0.12063303589820862
train-epoch-step: 25-134 -- Loss: 0.20988060534000397
train-epoch-step: 25-135 -- Loss: 0.15114225447177887
train-epoch-step: 25-136 -- Loss: 0.13629385828971863
train-epoch-step: 25-137 -- Loss: 0.25921469926834106
train-epoch-step: 25-138 -- Loss: 0.2721221446990967
train-epoch-step: 25-139 -- Loss: 0.1339297890663147
train-epoch-step: 25-140 -- Loss: 0.2122364491224289
train-epoch-step: 25-141 -- Loss: 0.24294523894786835
train-epoch-step: 25-142 -- Loss: 0.21097293496131897
train-epoch-step: 25-143 -- Loss: 0.187104269862175
train-epoch-step: 25-144 -- Loss: 0.1930105984210968
train-epoch-step: 25-145 -- Loss: 0.14454449713230133
train-epoch-step: 25-146 -- Loss: 0.18784010410308838
train-epoch-step: 25-147 -- Loss: 0.17213532328605652
train-epoch-step: 25-148 -- Loss: 0.17121851444244385
train-epoch-step: 25-149 -- Loss: 0.12282095104455948
train-epoch-step: 25-150 -- Loss: 0.196146622300148
train-epoch-step: 25-151 -- Loss: 0.22126522660255432
train-epoch-step: 25-152 -- Loss: 0.20139195024967194
train-epoch-step: 25-153 -- Loss: 0.2808051109313965
train-epoch-step: 25-154 -- Loss: 0.13662776350975037
train-epoch-step: 25-155 -- Loss: 0.1455143541097641
train-epoch-step: 25-156 -- Loss: 0.12107814848423004
train-epoch-step: 25-157 -- Loss: 0.18249788880348206
train-epoch-step: 25-158 -- Loss: 0.16929413378238678
train-epoch-step: 25-159 -- Loss: 0.1876468062400818
train-epoch-step: 25-160 -- Loss: 0.2265663594007492
train-epoch-step: 25-161 -- Loss: 0.21547800302505493
train-epoch-step: 25-162 -- Loss: 0.22147727012634277
train-epoch-step: 25-163 -- Loss: 0.19974417984485626
train-epoch-step: 25-164 -- Loss: 0.1995246559381485
train-epoch-step: 25-165 -- Loss: 0.1809006631374359
train-epoch-step: 25-166 -- Loss: 0.12604068219661713
train-epoch-step: 25-167 -- Loss: 0.13744772970676422
train-epoch-step: 25-168 -- Loss: 0.21054762601852417
train-epoch-step: 25-169 -- Loss: 0.14181838929653168
train-epoch-step: 25-170 -- Loss: 0.20592114329338074
train-epoch-step: 25-171 -- Loss: 0.15015435218811035
train-epoch-step: 25-172 -- Loss: 0.2742246985435486
train-epoch-step: 25-173 -- Loss: 0.13985362648963928
train-epoch-step: 25-174 -- Loss: 0.26042574644088745
train-epoch-step: 25-175 -- Loss: 0.19084380567073822
train-epoch-step: 25-176 -- Loss: 0.14375954866409302
train-epoch-step: 25-177 -- Loss: 0.1897820234298706
train-epoch-step: 25-178 -- Loss: 0.18432241678237915
train-epoch-step: 25-179 -- Loss: 0.1587570756673813
train-epoch-step: 25-180 -- Loss: 0.16279979050159454
train-epoch-step: 25-181 -- Loss: 0.1721375435590744
train-epoch-step: 25-182 -- Loss: 0.19594933092594147
train-epoch-step: 25-183 -- Loss: 0.2834847867488861
train-epoch-step: 25-184 -- Loss: 0.14581725001335144
train-epoch-step: 25-185 -- Loss: 0.14851002395153046
train-epoch-step: 25-186 -- Loss: 0.19685614109039307
train-epoch-step: 25-187 -- Loss: 0.2191508412361145
train-epoch-step: 25-188 -- Loss: 0.1855742633342743
train-epoch-step: 25-189 -- Loss: 0.11104084551334381
train-epoch-step: 25-190 -- Loss: 0.18859010934829712
train-epoch-step: 25-191 -- Loss: 0.16904976963996887
train-epoch-step: 25-192 -- Loss: 0.23926092684268951
train-epoch-step: 25-193 -- Loss: 0.2213246077299118
train-epoch-step: 25-194 -- Loss: 0.19366785883903503
train-epoch-step: 25-195 -- Loss: 0.17595325410366058
train-epoch-step: 25-196 -- Loss: 0.17232376337051392
train-epoch-step: 25-197 -- Loss: 0.13600170612335205
train-epoch-step: 25-198 -- Loss: 0.13670684397220612
train-epoch-step: 25-199 -- Loss: 0.1534906029701233
train-epoch-step: 25-200 -- Loss: 0.12860748171806335
train-epoch-step: 25-201 -- Loss: 0.20110124349594116
train-epoch-step: 25-202 -- Loss: 0.13744531571865082
train-epoch-step: 25-203 -- Loss: 0.1796794831752777
train-epoch-step: 25-204 -- Loss: 0.1409936547279358
train-epoch-step: 25-205 -- Loss: 0.19029703736305237
train-epoch-step: 25-206 -- Loss: 0.20489908754825592
train-epoch-step: 25-207 -- Loss: 0.13615132868289948
train-epoch-step: 25-208 -- Loss: 0.18189626932144165
train-epoch-step: 25-209 -- Loss: 0.14498986303806305
train-epoch-step: 25-210 -- Loss: 0.1394781619310379
train-epoch-step: 25-211 -- Loss: 0.21292099356651306
train-epoch-step: 25-212 -- Loss: 0.20151372253894806
train-epoch-step: 25-213 -- Loss: 0.1421814262866974
train-epoch-step: 25-214 -- Loss: 0.1522260159254074
train-epoch-step: 25-215 -- Loss: 0.13089944422245026
train-epoch-step: 25-216 -- Loss: 0.2131987363100052
train-epoch-step: 25-217 -- Loss: 0.21519434452056885
train-epoch-step: 25-218 -- Loss: 0.14984431862831116
train-epoch-step: 25-219 -- Loss: 0.17474640905857086
train-epoch-step: 25-220 -- Loss: 0.13600784540176392
train-epoch-step: 25-221 -- Loss: 0.21267011761665344
train-epoch-step: 25-222 -- Loss: 0.12277311831712723
train-epoch-step: 25-223 -- Loss: 0.18063569068908691
train-epoch-step: 25-224 -- Loss: 0.20554296672344208
train-epoch-step: 25-225 -- Loss: 0.28412458300590515
train-epoch-step: 25-226 -- Loss: 0.20867593586444855
train-epoch-step: 25-227 -- Loss: 0.2233511060476303
train-epoch-step: 25-228 -- Loss: 0.18220189213752747
train-epoch-step: 25-229 -- Loss: 0.1800900399684906
train-epoch-step: 25-230 -- Loss: 0.1660466492176056
train-epoch-step: 25-231 -- Loss: 0.16275428235530853
train-epoch-step: 25-232 -- Loss: 0.19727706909179688
train-epoch-step: 25-233 -- Loss: 0.08879585564136505
train-epoch-step: 25-234 -- Loss: 0.1865271031856537
train-epoch-step: 25-235 -- Loss: 0.1516922116279602
train-epoch-step: 25-236 -- Loss: 0.18112987279891968
train-epoch-step: 25-237 -- Loss: 0.2476329803466797
train-epoch-step: 25-238 -- Loss: 0.16370679438114166
train-epoch-step: 25-239 -- Loss: 0.13026459515094757
train-epoch-step: 25-240 -- Loss: 0.23227959871292114
train-epoch-step: 25-241 -- Loss: 0.15457916259765625
train-epoch-step: 25-242 -- Loss: 0.22898489236831665
train-epoch-step: 25-243 -- Loss: 0.24465630948543549
train-epoch-step: 25-244 -- Loss: 0.21111123263835907
train-epoch-step: 25-245 -- Loss: 0.21097494661808014
train-epoch-step: 25-246 -- Loss: 0.23847125470638275
train-epoch-step: 25-247 -- Loss: 0.21331419050693512
train-epoch-step: 25-248 -- Loss: 0.19135746359825134
train-epoch-step: 25-249 -- Loss: 0.1424093246459961
train-epoch-step: 25-250 -- Loss: 0.21075785160064697
train-epoch-step: 25-251 -- Loss: 0.11176978796720505
train-epoch-step: 25-252 -- Loss: 0.2071811556816101
train-epoch-step: 25-253 -- Loss: 0.140311598777771
train-epoch-step: 25-254 -- Loss: 0.22068722546100616
train-epoch-step: 25-255 -- Loss: 0.1517333984375
train-epoch-step: 25-256 -- Loss: 0.16705811023712158
train-epoch-step: 25-257 -- Loss: 0.19506758451461792
train-epoch-step: 25-258 -- Loss: 0.15139809250831604
train-epoch-step: 25-259 -- Loss: 0.11648061871528625
train-epoch-step: 25-260 -- Loss: 0.21094967424869537
train-epoch-step: 25-261 -- Loss: 0.17533858120441437
train-epoch-step: 25-262 -- Loss: 0.3223346769809723
train-epoch-step: 25-263 -- Loss: 0.20184876024723053
train-epoch-step: 25-264 -- Loss: 0.1777850091457367
train-epoch-step: 25-265 -- Loss: 0.13411788642406464
train-epoch-step: 25-266 -- Loss: 0.15146875381469727
train-epoch-step: 25-267 -- Loss: 0.13443511724472046
train-epoch-step: 25-268 -- Loss: 0.11896023154258728
train-epoch-step: 25-269 -- Loss: 0.1752372533082962
train-epoch-step: 25-270 -- Loss: 0.11071869730949402
train-epoch-step: 25-271 -- Loss: 0.1522047370672226
train-epoch-step: 25-272 -- Loss: 0.12126781046390533
train-epoch-step: 25-273 -- Loss: 0.1286277025938034
train-epoch-step: 25-274 -- Loss: 0.1880132257938385
train-epoch-step: 25-275 -- Loss: 0.21858610212802887
train-epoch-step: 25-276 -- Loss: 0.16600622236728668
train-epoch-step: 25-277 -- Loss: 0.1619042456150055
train-epoch-step: 25-278 -- Loss: 0.14865469932556152
train-epoch-step: 25-279 -- Loss: 0.1529177874326706
train-epoch-step: 25-280 -- Loss: 0.22822104394435883
train-epoch-step: 25-281 -- Loss: 0.1827501505613327
train-epoch-step: 25-282 -- Loss: 0.14874713122844696
train-epoch-step: 25-283 -- Loss: 0.1244388297200203
train-epoch-step: 25-284 -- Loss: 0.15268707275390625
train-epoch-step: 25-285 -- Loss: 0.19312193989753723
train-epoch-step: 25-286 -- Loss: 0.16147670149803162
train-epoch-step: 25-287 -- Loss: 0.2087659239768982
train-epoch-step: 25-288 -- Loss: 0.09857553243637085
train-epoch-step: 25-289 -- Loss: 0.1349511742591858
train-epoch-step: 25-290 -- Loss: 0.1973613202571869
train-epoch-step: 25-291 -- Loss: 0.12141333520412445
train-epoch-step: 25-292 -- Loss: 0.1540609896183014
train-epoch-step: 25-293 -- Loss: 0.15046469867229462
train-epoch-step: 25-294 -- Loss: 0.1744190901517868
train-epoch-step: 25-295 -- Loss: 0.2813056707382202
train-epoch-step: 25-296 -- Loss: 0.16149386763572693
train-epoch-step: 25-297 -- Loss: 0.18071295320987701
train-epoch-step: 25-298 -- Loss: 0.23983952403068542
train-epoch-step: 25-299 -- Loss: 0.1537545919418335
train-epoch-step: 25-300 -- Loss: 0.1923886388540268
train-epoch-step: 25-301 -- Loss: 0.17660588026046753
train-epoch-step: 25-302 -- Loss: 0.22527149319648743
train-epoch-step: 25-303 -- Loss: 0.21396255493164062
train-epoch-step: 25-304 -- Loss: 0.13785392045974731
train-epoch-step: 25-305 -- Loss: 0.1468714326620102
train-epoch-step: 25-306 -- Loss: 0.2440536618232727
train-epoch-step: 25-307 -- Loss: 0.17357417941093445
train-epoch-step: 25-308 -- Loss: 0.22365355491638184
train-epoch-step: 25-309 -- Loss: 0.1663457304239273
train-epoch-step: 25-310 -- Loss: 0.1652626395225525
train-epoch-step: 25-311 -- Loss: 0.16892635822296143
train-epoch-step: 25-312 -- Loss: 0.21592968702316284
train-epoch-step: 25-313 -- Loss: 0.0992238000035286
train-epoch-step: 25-314 -- Loss: 0.212259441614151
train-epoch-step: 25-315 -- Loss: 0.1752641201019287
train-epoch-step: 25-316 -- Loss: 0.15713346004486084
train-epoch-step: 25-317 -- Loss: 0.14774183928966522
train-epoch-step: 25-318 -- Loss: 0.16855274140834808
train-epoch-step: 25-319 -- Loss: 0.174869105219841
train-epoch-step: 25-320 -- Loss: 0.12524619698524475
train-epoch-step: 25-321 -- Loss: 0.13502295315265656
train-epoch-step: 25-322 -- Loss: 0.21975424885749817
train-epoch-step: 25-323 -- Loss: 0.16568772494792938
train-epoch-step: 25-324 -- Loss: 0.2632361650466919
train-epoch-step: 25-325 -- Loss: 0.15810617804527283
train-epoch-step: 25-326 -- Loss: 0.17479108273983002
train-epoch-step: 25-327 -- Loss: 0.2082114815711975
train-epoch-step: 25-328 -- Loss: 0.19940637052059174
train-epoch-step: 25-329 -- Loss: 0.34564438462257385
train-epoch-step: 25-330 -- Loss: 0.3705793023109436
train-epoch-step: 25-331 -- Loss: 0.2150120735168457
train-epoch-step: 25-332 -- Loss: 0.10391364991664886
train-epoch-step: 25-333 -- Loss: 0.1938502937555313
train-epoch-step: 25-334 -- Loss: 0.16005803644657135
train-epoch-step: 25-335 -- Loss: 0.1882426142692566
train-epoch-step: 25-336 -- Loss: 0.15412454307079315
train-epoch-step: 25-337 -- Loss: 0.2176712602376938
train-epoch-step: 25-338 -- Loss: 0.16526570916175842
train-epoch-step: 25-339 -- Loss: 0.14614009857177734
train-epoch-step: 25-340 -- Loss: 0.20549479126930237
train-epoch-step: 25-341 -- Loss: 0.14337608218193054
train-epoch-step: 25-342 -- Loss: 0.1703770011663437
train-epoch-step: 25-343 -- Loss: 0.15985488891601562
train-epoch-step: 25-344 -- Loss: 0.17487770318984985
train-epoch-step: 25-345 -- Loss: 0.13060705363750458
train-epoch-step: 25-346 -- Loss: 0.22238066792488098
train-epoch-step: 25-347 -- Loss: 0.16085487604141235
train-epoch-step: 25-348 -- Loss: 0.20820805430412292
train-epoch-step: 25-349 -- Loss: 0.21309085190296173
train-epoch-step: 25-350 -- Loss: 0.2667904198169708
train-epoch-step: 25-351 -- Loss: 0.19768795371055603
train-epoch-step: 25-352 -- Loss: 0.13372839987277985
train-epoch-step: 25-353 -- Loss: 0.1959982067346573
train-epoch-step: 25-354 -- Loss: 0.29172244668006897
train-epoch-step: 25-355 -- Loss: 0.12122920155525208
train-epoch-step: 25-356 -- Loss: 0.11956065893173218
train-epoch-step: 25-357 -- Loss: 0.19579921662807465
train-epoch-step: 25-358 -- Loss: 0.18786251544952393
train-epoch-step: 25-359 -- Loss: 0.1444864273071289
train-epoch-step: 25-360 -- Loss: 0.13201649487018585
train-epoch-step: 25-361 -- Loss: 0.23953433334827423
train-epoch-step: 25-362 -- Loss: 0.17174221575260162
train-epoch-step: 25-363 -- Loss: 0.1114545539021492
train-epoch-step: 25-364 -- Loss: 0.1845240592956543
train-epoch-step: 25-365 -- Loss: 0.18150226771831512
train-epoch-step: 25-366 -- Loss: 0.21269534528255463
train-epoch-step: 25-367 -- Loss: 0.24501553177833557
train-epoch-step: 25-368 -- Loss: 0.20921725034713745
train-epoch-step: 25-369 -- Loss: 0.2793804407119751
train-epoch-step: 25-370 -- Loss: 0.1265018731355667
train-epoch-step: 25-371 -- Loss: 0.1229361891746521
train-epoch-step: 25-372 -- Loss: 0.15105578303337097
train-epoch-step: 25-373 -- Loss: 0.19515526294708252
train-epoch-step: 25-374 -- Loss: 0.15993383526802063
train-epoch-step: 25-375 -- Loss: 0.27749019861221313
train-epoch-step: 25-376 -- Loss: 0.17324697971343994
train-epoch-step: 25-377 -- Loss: 0.24431543052196503
train-epoch-step: 25-378 -- Loss: 0.209855318069458
train-epoch-step: 25-379 -- Loss: 0.12589223682880402
train-epoch-step: 25-380 -- Loss: 0.09606552869081497
train-epoch-step: 25-381 -- Loss: 0.25302499532699585
train-epoch-step: 25-382 -- Loss: 0.2560083568096161
train-epoch-step: 25-383 -- Loss: 0.1880989372730255
train-epoch-step: 25-384 -- Loss: 0.24495457112789154
train-epoch-step: 25-385 -- Loss: 0.1959075629711151
train-epoch-step: 25-386 -- Loss: 0.19634532928466797
train-epoch-step: 25-387 -- Loss: 0.2121707797050476
train-epoch-step: 25-388 -- Loss: 0.20236045122146606
train-epoch-step: 25-389 -- Loss: 0.17365168035030365
train-epoch-step: 25-390 -- Loss: 0.15513725578784943
train-epoch-step: 25-391 -- Loss: 0.14838680624961853
train-epoch-step: 25-392 -- Loss: 0.19328302145004272
train-epoch-step: 25-393 -- Loss: 0.16145510971546173
train-epoch-step: 25-394 -- Loss: 0.22113606333732605
train-epoch-step: 25-395 -- Loss: 0.18119776248931885
train-epoch-step: 25-396 -- Loss: 0.13081131875514984
train-epoch-step: 25-397 -- Loss: 0.13170906901359558
train-epoch-step: 25-398 -- Loss: 0.20681697130203247
train-epoch-step: 25-399 -- Loss: 0.18443195521831512
train-epoch-step: 25-400 -- Loss: 0.2932506799697876
train-epoch-step: 25-401 -- Loss: 0.12814702093601227
train-epoch-step: 25-402 -- Loss: 0.2634861469268799
train-epoch-step: 25-403 -- Loss: 0.16270926594734192
train-epoch-step: 25-404 -- Loss: 0.14174339175224304
train-epoch-step: 25-405 -- Loss: 0.16050371527671814
train-epoch-step: 25-406 -- Loss: 0.17048302292823792
train-epoch-step: 25-407 -- Loss: 0.11708861589431763
train-epoch-step: 25-408 -- Loss: 0.1640639752149582
train-epoch-step: 25-409 -- Loss: 0.17392908036708832
train-epoch-step: 25-410 -- Loss: 0.18014615774154663
train-epoch-step: 25-411 -- Loss: 0.2108282893896103
train-epoch-step: 25-412 -- Loss: 0.13401731848716736
train-epoch-step: 25-413 -- Loss: 0.15084265172481537
train-epoch-step: 25-414 -- Loss: 0.13706505298614502
train-epoch-step: 25-415 -- Loss: 0.13681280612945557
train-epoch-step: 25-416 -- Loss: 0.2641248404979706
train-epoch-step: 25-417 -- Loss: 0.19916774332523346
train-epoch-step: 25-418 -- Loss: 0.2396869957447052
train-epoch-step: 25-419 -- Loss: 0.17150810360908508
train-epoch-step: 25-420 -- Loss: 0.1583552360534668
train-epoch-step: 25-421 -- Loss: 0.18452295660972595
train-epoch-step: 25-422 -- Loss: 0.15327702462673187
train-epoch-step: 25-423 -- Loss: 0.18447065353393555
train-epoch-step: 25-424 -- Loss: 0.14401492476463318
train-epoch-step: 25-425 -- Loss: 0.19153395295143127
train-epoch-step: 25-426 -- Loss: 0.16782687604427338
train-epoch-step: 25-427 -- Loss: 0.12601155042648315
train-epoch-step: 25-428 -- Loss: 0.20633049309253693
train-epoch-step: 25-429 -- Loss: 0.1794472187757492
train-epoch-step: 25-430 -- Loss: 0.1424962878227234
train-epoch-step: 25-431 -- Loss: 0.17059369385242462
train-epoch-step: 25-432 -- Loss: 0.2512668967247009
train-epoch-step: 25-433 -- Loss: 0.14111098647117615
train-epoch-step: 25-434 -- Loss: 0.13559861481189728
train-epoch-step: 25-435 -- Loss: 0.16255001723766327
train-epoch-step: 25-436 -- Loss: 0.16162799298763275
train-epoch-step: 25-437 -- Loss: 0.13320791721343994
train-epoch-step: 25-438 -- Loss: 0.1701865941286087
train-epoch-step: 25-439 -- Loss: 0.2728426158428192
train-epoch-step: 25-440 -- Loss: 0.13601866364479065
train-epoch-step: 25-441 -- Loss: 0.20386403799057007
train-epoch-step: 25-442 -- Loss: 0.1928728222846985
train-epoch-step: 25-443 -- Loss: 0.16120214760303497
train-epoch-step: 25-444 -- Loss: 0.1769857257604599
train-epoch-step: 25-445 -- Loss: 0.1829010397195816
train-epoch-step: 25-446 -- Loss: 0.16619887948036194
train-epoch-step: 25-447 -- Loss: 0.19471335411071777
train-epoch-step: 25-448 -- Loss: 0.22986018657684326
train-epoch-step: 25-449 -- Loss: 0.1941736340522766
train-epoch-step: 25-450 -- Loss: 0.1880178302526474
train-epoch-step: 25-451 -- Loss: 0.1459854245185852
train-epoch-step: 25-452 -- Loss: 0.1342652291059494
train-epoch-step: 25-453 -- Loss: 0.10325506329536438
train-epoch-step: 25-454 -- Loss: 0.23798465728759766
train-epoch-step: 25-455 -- Loss: 0.1298026442527771
train-epoch-step: 25-456 -- Loss: 0.12170837819576263
train-epoch-step: 25-457 -- Loss: 0.21867625415325165
train-epoch-step: 25-458 -- Loss: 0.1494244933128357
train-epoch-step: 25-459 -- Loss: 0.22449961304664612
train-epoch-step: 25-460 -- Loss: 0.13072195649147034
train-epoch-step: 25-461 -- Loss: 0.13789209723472595
train-epoch-step: 25-462 -- Loss: 0.16404207050800323
train-epoch-step: 25-463 -- Loss: 0.14037469029426575
train-epoch-step: 25-464 -- Loss: 0.1695692539215088
train-epoch-step: 25-465 -- Loss: 0.2534113824367523
train-epoch-step: 25-466 -- Loss: 0.2019158899784088
train-epoch-step: 25-467 -- Loss: 0.11553937196731567
train-epoch-step: 25-468 -- Loss: 0.17288769781589508
train-epoch-step: 25-469 -- Loss: 0.21097742021083832
train-epoch-step: 25-470 -- Loss: 0.1803267002105713
train-epoch-step: 25-471 -- Loss: 0.16142621636390686
train-epoch-step: 25-472 -- Loss: 0.16129553318023682
train-epoch-step: 25-473 -- Loss: 0.15646091103553772
train-epoch-step: 25-474 -- Loss: 0.13056480884552002
train-epoch-step: 25-475 -- Loss: 0.11356756091117859
train-epoch-step: 25-476 -- Loss: 0.20877432823181152
train-epoch-step: 25-477 -- Loss: 0.20585434138774872
train-epoch-step: 25-478 -- Loss: 0.1929558366537094
train-epoch-step: 25-479 -- Loss: 0.14617589116096497
train-epoch-step: 25-480 -- Loss: 0.20568934082984924
train-epoch-step: 25-481 -- Loss: 0.28358912467956543
train-epoch-step: 25-482 -- Loss: 0.2562022805213928
train-epoch-step: 25-483 -- Loss: 0.18395690619945526
train-epoch-step: 25-484 -- Loss: 0.2175208032131195
train-epoch-step: 25-485 -- Loss: 0.1314319670200348
train-epoch-step: 25-486 -- Loss: 0.2457098364830017
train-epoch-step: 25-487 -- Loss: 0.24211668968200684
train-epoch-step: 25-488 -- Loss: 0.20663206279277802
train-epoch-step: 25-489 -- Loss: 0.21816639602184296
train-epoch-step: 25-490 -- Loss: 0.14197669923305511
train-epoch-step: 25-491 -- Loss: 0.1392820030450821
train-epoch-step: 25-492 -- Loss: 0.1264205425977707
train-epoch-step: 25-493 -- Loss: 0.24492530524730682
train-epoch-step: 25-494 -- Loss: 0.21037864685058594
train-epoch-step: 25-495 -- Loss: 0.2100924402475357
train-epoch-step: 25-496 -- Loss: 0.1401783525943756
train-epoch-step: 25-497 -- Loss: 0.18496790528297424
train-epoch-step: 25-498 -- Loss: 0.14991886913776398
train-epoch-step: 25-499 -- Loss: 0.17352509498596191
train-epoch-step: 25-500 -- Loss: 0.15588758885860443
train-epoch-step: 25-501 -- Loss: 0.2206045389175415
train-epoch-step: 25-502 -- Loss: 0.15999753773212433
train-epoch-step: 25-503 -- Loss: 0.2213020771741867
train-epoch-step: 25-504 -- Loss: 0.13201367855072021
train-epoch-step: 25-505 -- Loss: 0.1740950495004654
train-epoch-step: 25-506 -- Loss: 0.12046604603528976
train-epoch-step: 25-507 -- Loss: 0.18572774529457092
train-epoch-step: 25-508 -- Loss: 0.1813906729221344
train-epoch-step: 25-509 -- Loss: 0.16882693767547607
train-epoch-step: 25-510 -- Loss: 0.1292937994003296
train-epoch-step: 25-511 -- Loss: 0.22697529196739197
train-epoch-step: 25-512 -- Loss: 0.17743970453739166
train-epoch-step: 25-513 -- Loss: 0.20117944478988647
train-epoch-step: 25-514 -- Loss: 0.15251044929027557
train-epoch-step: 25-515 -- Loss: 0.1626548171043396
train-epoch-step: 25-516 -- Loss: 0.1735571324825287
train-epoch-step: 25-517 -- Loss: 0.1748000830411911
train-epoch-step: 25-518 -- Loss: 0.14659610390663147
train-epoch-step: 25-519 -- Loss: 0.1390339732170105
train-epoch-step: 25-520 -- Loss: 0.194510817527771
train-epoch-step: 25-521 -- Loss: 0.23258346319198608
train-epoch-step: 25-522 -- Loss: 0.18303754925727844
train-epoch-step: 25-523 -- Loss: 0.16445884108543396
train-epoch-step: 25-524 -- Loss: 0.17939512431621552
train-epoch-step: 25-525 -- Loss: 0.19123457372188568
train-epoch-step: 25-526 -- Loss: 0.13236089050769806
train-epoch-step: 25-527 -- Loss: 0.16265177726745605
train-epoch-step: 25-528 -- Loss: 0.16518647968769073
train-epoch-step: 25-529 -- Loss: 0.16634370386600494
train-epoch-step: 25-530 -- Loss: 0.17192280292510986
train-epoch-step: 25-531 -- Loss: 0.20754489302635193
train-epoch-step: 25-532 -- Loss: 0.17234230041503906
train-epoch-step: 25-533 -- Loss: 0.17458230257034302
train-epoch-step: 25-534 -- Loss: 0.14164409041404724
train-epoch-step: 25-535 -- Loss: 0.26062431931495667
train-epoch-step: 25-536 -- Loss: 0.16495046019554138
train-epoch-step: 25-537 -- Loss: 0.15125110745429993
train-epoch-step: 25-538 -- Loss: 0.11007289588451385
train-epoch-step: 25-539 -- Loss: 0.19128143787384033
train-epoch-step: 25-540 -- Loss: 0.13974244892597198
train-epoch-step: 25-541 -- Loss: 0.21455714106559753
train-epoch-step: 25-542 -- Loss: 0.22676974534988403
train-epoch-step: 25-543 -- Loss: 0.17132879793643951
train-epoch-step: 25-544 -- Loss: 0.23047450184822083
train-epoch-step: 25-545 -- Loss: 0.19678762555122375
train-epoch-step: 25-546 -- Loss: 0.2203858643770218
train-epoch-step: 25-547 -- Loss: 0.18180552124977112
train-epoch-step: 25-548 -- Loss: 0.09955216199159622
train-epoch-step: 25-549 -- Loss: 0.1537705361843109
train-epoch-step: 25-550 -- Loss: 0.20106974244117737
train-epoch-step: 25-551 -- Loss: 0.161200612783432
train-epoch-step: 25-552 -- Loss: 0.1373530775308609
train-epoch-step: 25-553 -- Loss: 0.19027720391750336
train-epoch-step: 25-554 -- Loss: 0.19177260994911194
train-epoch-step: 25-555 -- Loss: 0.22077780961990356
train-epoch-step: 25-556 -- Loss: 0.1585671752691269
train-epoch-step: 25-557 -- Loss: 0.2459889054298401
train-epoch-step: 25-558 -- Loss: 0.23622801899909973
train-epoch-step: 25-559 -- Loss: 0.1474035382270813
train-epoch-step: 25-560 -- Loss: 0.20762696862220764
train-epoch-step: 25-561 -- Loss: 0.18679946660995483
train-epoch-step: 25-562 -- Loss: 0.16853687167167664
train-epoch-step: 25-563 -- Loss: 0.18730123341083527
train-epoch-step: 25-564 -- Loss: 0.10256824642419815
train-epoch-step: 25-565 -- Loss: 0.18713945150375366
train-epoch-step: 25-566 -- Loss: 0.15695351362228394
train-epoch-step: 25-567 -- Loss: 0.22055836021900177
train-epoch-step: 25-568 -- Loss: 0.159626767039299
train-epoch-step: 25-569 -- Loss: 0.2449694275856018
train-epoch-step: 25-570 -- Loss: 0.1770540177822113
train-epoch-step: 25-571 -- Loss: 0.2174236923456192
train-epoch-step: 25-572 -- Loss: 0.24097245931625366
train-epoch-step: 25-573 -- Loss: 0.20504939556121826
train-epoch-step: 25-574 -- Loss: 0.2587193548679352
train-epoch-step: 25-575 -- Loss: 0.2979949116706848
train-epoch-step: 25-576 -- Loss: 0.12431681901216507
train-epoch-step: 25-577 -- Loss: 0.17050381004810333
train-epoch-step: 25-578 -- Loss: 0.22260451316833496
train-epoch-step: 25-579 -- Loss: 0.17223353683948517
train-epoch-step: 25-580 -- Loss: 0.18154771625995636
train-epoch-step: 25-581 -- Loss: 0.15014269948005676
train-epoch-step: 25-582 -- Loss: 0.21182163059711456
train-epoch-step: 25-583 -- Loss: 0.22592607140541077
train-epoch-step: 25-584 -- Loss: 0.17183226346969604
train-epoch-step: 25-585 -- Loss: 0.19518877565860748
train-epoch-step: 25-586 -- Loss: 0.25873416662216187
train-epoch-step: 25-587 -- Loss: 0.16390779614448547
train-epoch-step: 25-588 -- Loss: 0.13131430745124817
val-epoch-step: 25-589 -- Loss: 0.2119661271572113
val-epoch-step: 25-590 -- Loss: 0.1517430990934372
val-epoch-step: 25-591 -- Loss: 0.23106680810451508
val-epoch-step: 25-592 -- Loss: 0.17801007628440857
val-epoch-step: 25-593 -- Loss: 0.1665268838405609
val-epoch-step: 25-594 -- Loss: 0.3749130368232727
val-epoch-step: 25-595 -- Loss: 0.1764782965183258
val-epoch-step: 25-596 -- Loss: 0.20881596207618713
val-epoch-step: 25-597 -- Loss: 0.18035247921943665
val-epoch-step: 25-598 -- Loss: 0.1501624882221222
val-epoch-step: 25-599 -- Loss: 0.1863243579864502
val-epoch-step: 25-600 -- Loss: 0.2235332876443863
val-epoch-step: 25-601 -- Loss: 0.15813006460666656
val-epoch-step: 25-602 -- Loss: 0.1380252242088318
val-epoch-step: 25-603 -- Loss: 0.18714958429336548
val-epoch-step: 25-604 -- Loss: 0.1512567549943924
val-epoch-step: 25-605 -- Loss: 0.15163134038448334
val-epoch-step: 25-606 -- Loss: 0.28197142481803894
val-epoch-step: 25-607 -- Loss: 0.13018468022346497
val-epoch-step: 25-608 -- Loss: 0.257068395614624
val-epoch-step: 25-609 -- Loss: 0.17311802506446838
val-epoch-step: 25-610 -- Loss: 0.1876090168952942
val-epoch-step: 25-611 -- Loss: 0.18710868060588837
val-epoch-step: 25-612 -- Loss: 0.47567176818847656
val-epoch-step: 25-613 -- Loss: 0.17520463466644287
val-epoch-step: 25-614 -- Loss: 0.16462403535842896
val-epoch-step: 25-615 -- Loss: 0.18038368225097656
val-epoch-step: 25-616 -- Loss: 0.15077611804008484
val-epoch-step: 25-617 -- Loss: 0.1924217790365219
val-epoch-step: 25-618 -- Loss: 0.18319952487945557
val-epoch-step: 25-619 -- Loss: 0.22918881475925446
val-epoch-step: 25-620 -- Loss: 0.15654899179935455
val-epoch-step: 25-621 -- Loss: 0.13201653957366943
val-epoch-step: 25-622 -- Loss: 0.146073117852211
val-epoch-step: 25-623 -- Loss: 0.15595000982284546
val-epoch-step: 25-624 -- Loss: 0.14514265954494476
val-epoch-step: 25-625 -- Loss: 0.16044293344020844
val-epoch-step: 25-626 -- Loss: 0.14940720796585083
val-epoch-step: 25-627 -- Loss: 0.19111470878124237
val-epoch-step: 25-628 -- Loss: 0.5986202955245972
val-epoch-step: 25-629 -- Loss: 0.21617932617664337
val-epoch-step: 25-630 -- Loss: 0.34881842136383057
val-epoch-step: 25-631 -- Loss: 0.1440238356590271
val-epoch-step: 25-632 -- Loss: 0.20602166652679443
val-epoch-step: 25-633 -- Loss: 0.15840306878089905
val-epoch-step: 25-634 -- Loss: 0.14802215993404388
val-epoch-step: 25-635 -- Loss: 0.11828387528657913
val-epoch-step: 25-636 -- Loss: 0.17031320929527283
val-epoch-step: 25-637 -- Loss: 0.1865764856338501
val-epoch-step: 25-638 -- Loss: 0.17032018303871155
val-epoch-step: 25-639 -- Loss: 0.259090781211853
val-epoch-step: 25-640 -- Loss: 0.2504607141017914
val-epoch-step: 25-641 -- Loss: 0.12871447205543518
val-epoch-step: 25-642 -- Loss: 0.19807161390781403
val-epoch-step: 25-643 -- Loss: 0.20829680562019348
val-epoch-step: 25-644 -- Loss: 0.16540060937404633
val-epoch-step: 25-645 -- Loss: 0.22283178567886353
val-epoch-step: 25-646 -- Loss: 0.13882780075073242
val-epoch-step: 25-647 -- Loss: 0.13602463901042938
val-epoch-step: 25-648 -- Loss: 0.16363179683685303
val-epoch-step: 25-649 -- Loss: 0.21040359139442444
val-epoch-step: 25-650 -- Loss: 0.2538386285305023
val-epoch-step: 25-651 -- Loss: 0.1429530680179596
val-epoch-step: 25-652 -- Loss: 0.15660536289215088
val-epoch-step: 25-653 -- Loss: 0.23814061284065247
val-epoch-step: 25-654 -- Loss: 0.12483994662761688
Epoch: 25 -- Train Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 26-0 -- Loss: 0.22593672573566437
train-epoch-step: 26-1 -- Loss: 0.1443115621805191
train-epoch-step: 26-2 -- Loss: 0.2018449306488037
train-epoch-step: 26-3 -- Loss: 0.1396915763616562
train-epoch-step: 26-4 -- Loss: 0.16402173042297363
train-epoch-step: 26-5 -- Loss: 0.19299721717834473
train-epoch-step: 26-6 -- Loss: 0.22527751326560974
train-epoch-step: 26-7 -- Loss: 0.1684785932302475
train-epoch-step: 26-8 -- Loss: 0.19054193794727325
train-epoch-step: 26-9 -- Loss: 0.24338087439537048
train-epoch-step: 26-10 -- Loss: 0.20492397248744965
train-epoch-step: 26-11 -- Loss: 0.17937710881233215
train-epoch-step: 26-12 -- Loss: 0.15603207051753998
train-epoch-step: 26-13 -- Loss: 0.1821882277727127
train-epoch-step: 26-14 -- Loss: 0.17827817797660828
train-epoch-step: 26-15 -- Loss: 0.16214559972286224
train-epoch-step: 26-16 -- Loss: 0.17020109295845032
train-epoch-step: 26-17 -- Loss: 0.22995218634605408
train-epoch-step: 26-18 -- Loss: 0.1960841864347458
train-epoch-step: 26-19 -- Loss: 0.13458369672298431
train-epoch-step: 26-20 -- Loss: 0.2231782227754593
train-epoch-step: 26-21 -- Loss: 0.25752854347229004
train-epoch-step: 26-22 -- Loss: 0.156624436378479
train-epoch-step: 26-23 -- Loss: 0.15199807286262512
train-epoch-step: 26-24 -- Loss: 0.1321844756603241
train-epoch-step: 26-25 -- Loss: 0.23923078179359436
train-epoch-step: 26-26 -- Loss: 0.1978328377008438
train-epoch-step: 26-27 -- Loss: 0.23956702649593353
train-epoch-step: 26-28 -- Loss: 0.12617133557796478
train-epoch-step: 26-29 -- Loss: 0.24614714086055756
train-epoch-step: 26-30 -- Loss: 0.1121382936835289
train-epoch-step: 26-31 -- Loss: 0.1396959125995636
train-epoch-step: 26-32 -- Loss: 0.17722684144973755
train-epoch-step: 26-33 -- Loss: 0.2930591106414795
train-epoch-step: 26-34 -- Loss: 0.18207673728466034
train-epoch-step: 26-35 -- Loss: 0.25471818447113037
train-epoch-step: 26-36 -- Loss: 0.1428433209657669
train-epoch-step: 26-37 -- Loss: 0.14193332195281982
train-epoch-step: 26-38 -- Loss: 0.19315776228904724
train-epoch-step: 26-39 -- Loss: 0.23673361539840698
train-epoch-step: 26-40 -- Loss: 0.19544106721878052
train-epoch-step: 26-41 -- Loss: 0.21648049354553223
train-epoch-step: 26-42 -- Loss: 0.15414288640022278
train-epoch-step: 26-43 -- Loss: 0.2676572799682617
train-epoch-step: 26-44 -- Loss: 0.12781912088394165
train-epoch-step: 26-45 -- Loss: 0.12221839278936386
train-epoch-step: 26-46 -- Loss: 0.1780966967344284
train-epoch-step: 26-47 -- Loss: 0.21293029189109802
train-epoch-step: 26-48 -- Loss: 0.15786035358905792
train-epoch-step: 26-49 -- Loss: 0.22672507166862488
train-epoch-step: 26-50 -- Loss: 0.12298848479986191
train-epoch-step: 26-51 -- Loss: 0.18129898607730865
train-epoch-step: 26-52 -- Loss: 0.16276852786540985
train-epoch-step: 26-53 -- Loss: 0.219256192445755
train-epoch-step: 26-54 -- Loss: 0.28716468811035156
train-epoch-step: 26-55 -- Loss: 0.18338501453399658
train-epoch-step: 26-56 -- Loss: 0.17990535497665405
train-epoch-step: 26-57 -- Loss: 0.2399698942899704
train-epoch-step: 26-58 -- Loss: 0.2921925187110901
train-epoch-step: 26-59 -- Loss: 0.25223323702812195
train-epoch-step: 26-60 -- Loss: 0.1331569403409958
train-epoch-step: 26-61 -- Loss: 0.21230602264404297
train-epoch-step: 26-62 -- Loss: 0.1851559579372406
train-epoch-step: 26-63 -- Loss: 0.14549991488456726
train-epoch-step: 26-64 -- Loss: 0.14871001243591309
train-epoch-step: 26-65 -- Loss: 0.18320408463478088
train-epoch-step: 26-66 -- Loss: 0.11096139252185822
train-epoch-step: 26-67 -- Loss: 0.13131478428840637
train-epoch-step: 26-68 -- Loss: 0.2222047597169876
train-epoch-step: 26-69 -- Loss: 0.1257922649383545
train-epoch-step: 26-70 -- Loss: 0.22039127349853516
train-epoch-step: 26-71 -- Loss: 0.2606539726257324
train-epoch-step: 26-72 -- Loss: 0.17979559302330017
train-epoch-step: 26-73 -- Loss: 0.21885991096496582
train-epoch-step: 26-74 -- Loss: 0.09984178841114044
train-epoch-step: 26-75 -- Loss: 0.1332365721464157
train-epoch-step: 26-76 -- Loss: 0.14816713333129883
train-epoch-step: 26-77 -- Loss: 0.23404522240161896
train-epoch-step: 26-78 -- Loss: 0.2724575698375702
train-epoch-step: 26-79 -- Loss: 0.1937490701675415
train-epoch-step: 26-80 -- Loss: 0.2763630151748657
train-epoch-step: 26-81 -- Loss: 0.1306021809577942
train-epoch-step: 26-82 -- Loss: 0.25854259729385376
train-epoch-step: 26-83 -- Loss: 0.1821271777153015
train-epoch-step: 26-84 -- Loss: 0.19075921177864075
train-epoch-step: 26-85 -- Loss: 0.1802145540714264
train-epoch-step: 26-86 -- Loss: 0.13393473625183105
train-epoch-step: 26-87 -- Loss: 0.2341829538345337
train-epoch-step: 26-88 -- Loss: 0.14878587424755096
train-epoch-step: 26-89 -- Loss: 0.1889297217130661
train-epoch-step: 26-90 -- Loss: 0.19684506952762604
train-epoch-step: 26-91 -- Loss: 0.2545216679573059
train-epoch-step: 26-92 -- Loss: 0.15957283973693848
train-epoch-step: 26-93 -- Loss: 0.1791447103023529
train-epoch-step: 26-94 -- Loss: 0.22708594799041748
train-epoch-step: 26-95 -- Loss: 0.1924235224723816
train-epoch-step: 26-96 -- Loss: 0.22373805940151215
train-epoch-step: 26-97 -- Loss: 0.18054360151290894
train-epoch-step: 26-98 -- Loss: 0.15554757416248322
train-epoch-step: 26-99 -- Loss: 0.18367426097393036
train-epoch-step: 26-100 -- Loss: 0.18859006464481354
train-epoch-step: 26-101 -- Loss: 0.27600574493408203
train-epoch-step: 26-102 -- Loss: 0.2247556447982788
train-epoch-step: 26-103 -- Loss: 0.18849146366119385
train-epoch-step: 26-104 -- Loss: 0.1487395316362381
train-epoch-step: 26-105 -- Loss: 0.28990501165390015
train-epoch-step: 26-106 -- Loss: 0.18108868598937988
train-epoch-step: 26-107 -- Loss: 0.19301649928092957
train-epoch-step: 26-108 -- Loss: 0.19035843014717102
train-epoch-step: 26-109 -- Loss: 0.1492801159620285
train-epoch-step: 26-110 -- Loss: 0.1859009712934494
train-epoch-step: 26-111 -- Loss: 0.18292468786239624
train-epoch-step: 26-112 -- Loss: 0.17608755826950073
train-epoch-step: 26-113 -- Loss: 0.163082554936409
train-epoch-step: 26-114 -- Loss: 0.1982254683971405
train-epoch-step: 26-115 -- Loss: 0.1631973683834076
train-epoch-step: 26-116 -- Loss: 0.14347921311855316
train-epoch-step: 26-117 -- Loss: 0.1326489895582199
train-epoch-step: 26-118 -- Loss: 0.20051009953022003
train-epoch-step: 26-119 -- Loss: 0.15335208177566528
train-epoch-step: 26-120 -- Loss: 0.2518846392631531
train-epoch-step: 26-121 -- Loss: 0.2712303102016449
train-epoch-step: 26-122 -- Loss: 0.2197502851486206
train-epoch-step: 26-123 -- Loss: 0.20581093430519104
train-epoch-step: 26-124 -- Loss: 0.1347162127494812
train-epoch-step: 26-125 -- Loss: 0.15793897211551666
train-epoch-step: 26-126 -- Loss: 0.23013333976268768
train-epoch-step: 26-127 -- Loss: 0.18649622797966003
train-epoch-step: 26-128 -- Loss: 0.17788460850715637
train-epoch-step: 26-129 -- Loss: 0.14934371411800385
train-epoch-step: 26-130 -- Loss: 0.19646091759204865
train-epoch-step: 26-131 -- Loss: 0.13674762845039368
train-epoch-step: 26-132 -- Loss: 0.19085480272769928
train-epoch-step: 26-133 -- Loss: 0.1189611405134201
train-epoch-step: 26-134 -- Loss: 0.20369069278240204
train-epoch-step: 26-135 -- Loss: 0.15066730976104736
train-epoch-step: 26-136 -- Loss: 0.1329430639743805
train-epoch-step: 26-137 -- Loss: 0.24863220751285553
train-epoch-step: 26-138 -- Loss: 0.2657049894332886
train-epoch-step: 26-139 -- Loss: 0.1360168755054474
train-epoch-step: 26-140 -- Loss: 0.20736074447631836
train-epoch-step: 26-141 -- Loss: 0.23974955081939697
train-epoch-step: 26-142 -- Loss: 0.20500412583351135
train-epoch-step: 26-143 -- Loss: 0.1862253099679947
train-epoch-step: 26-144 -- Loss: 0.2036696821451187
train-epoch-step: 26-145 -- Loss: 0.14458197355270386
train-epoch-step: 26-146 -- Loss: 0.18124531209468842
train-epoch-step: 26-147 -- Loss: 0.1750364750623703
train-epoch-step: 26-148 -- Loss: 0.16383904218673706
train-epoch-step: 26-149 -- Loss: 0.12532810866832733
train-epoch-step: 26-150 -- Loss: 0.18835245072841644
train-epoch-step: 26-151 -- Loss: 0.19281941652297974
train-epoch-step: 26-152 -- Loss: 0.1995496153831482
train-epoch-step: 26-153 -- Loss: 0.2736668288707733
train-epoch-step: 26-154 -- Loss: 0.13895532488822937
train-epoch-step: 26-155 -- Loss: 0.1405406892299652
train-epoch-step: 26-156 -- Loss: 0.1208067461848259
train-epoch-step: 26-157 -- Loss: 0.17762985825538635
train-epoch-step: 26-158 -- Loss: 0.17008636891841888
train-epoch-step: 26-159 -- Loss: 0.18330377340316772
train-epoch-step: 26-160 -- Loss: 0.22269628942012787
train-epoch-step: 26-161 -- Loss: 0.20719178020954132
train-epoch-step: 26-162 -- Loss: 0.22338712215423584
train-epoch-step: 26-163 -- Loss: 0.1988844871520996
train-epoch-step: 26-164 -- Loss: 0.1939103901386261
train-epoch-step: 26-165 -- Loss: 0.1630493700504303
train-epoch-step: 26-166 -- Loss: 0.13306382298469543
train-epoch-step: 26-167 -- Loss: 0.13092555105686188
train-epoch-step: 26-168 -- Loss: 0.20844845473766327
train-epoch-step: 26-169 -- Loss: 0.14388738572597504
train-epoch-step: 26-170 -- Loss: 0.20918551087379456
train-epoch-step: 26-171 -- Loss: 0.1511267125606537
train-epoch-step: 26-172 -- Loss: 0.26918381452560425
train-epoch-step: 26-173 -- Loss: 0.1426648199558258
train-epoch-step: 26-174 -- Loss: 0.2585648000240326
train-epoch-step: 26-175 -- Loss: 0.18793848156929016
train-epoch-step: 26-176 -- Loss: 0.14019715785980225
train-epoch-step: 26-177 -- Loss: 0.18626408278942108
train-epoch-step: 26-178 -- Loss: 0.18251927196979523
train-epoch-step: 26-179 -- Loss: 0.15892143547534943
train-epoch-step: 26-180 -- Loss: 0.15644827485084534
train-epoch-step: 26-181 -- Loss: 0.17893245816230774
train-epoch-step: 26-182 -- Loss: 0.19326630234718323
train-epoch-step: 26-183 -- Loss: 0.27910149097442627
train-epoch-step: 26-184 -- Loss: 0.14034445583820343
train-epoch-step: 26-185 -- Loss: 0.1422433853149414
train-epoch-step: 26-186 -- Loss: 0.1982986330986023
train-epoch-step: 26-187 -- Loss: 0.21523815393447876
train-epoch-step: 26-188 -- Loss: 0.17999815940856934
train-epoch-step: 26-189 -- Loss: 0.10856467485427856
train-epoch-step: 26-190 -- Loss: 0.18951331079006195
train-epoch-step: 26-191 -- Loss: 0.17601832747459412
train-epoch-step: 26-192 -- Loss: 0.24830478429794312
train-epoch-step: 26-193 -- Loss: 0.24473509192466736
train-epoch-step: 26-194 -- Loss: 0.18900346755981445
train-epoch-step: 26-195 -- Loss: 0.1690494865179062
train-epoch-step: 26-196 -- Loss: 0.17351683974266052
train-epoch-step: 26-197 -- Loss: 0.13727159798145294
train-epoch-step: 26-198 -- Loss: 0.13371598720550537
train-epoch-step: 26-199 -- Loss: 0.15079811215400696
train-epoch-step: 26-200 -- Loss: 0.13134171068668365
train-epoch-step: 26-201 -- Loss: 0.2010754942893982
train-epoch-step: 26-202 -- Loss: 0.13964708149433136
train-epoch-step: 26-203 -- Loss: 0.18076254427433014
train-epoch-step: 26-204 -- Loss: 0.14319731295108795
train-epoch-step: 26-205 -- Loss: 0.18691009283065796
train-epoch-step: 26-206 -- Loss: 0.19950467348098755
train-epoch-step: 26-207 -- Loss: 0.1339910924434662
train-epoch-step: 26-208 -- Loss: 0.1816929280757904
train-epoch-step: 26-209 -- Loss: 0.1450331062078476
train-epoch-step: 26-210 -- Loss: 0.14102907478809357
train-epoch-step: 26-211 -- Loss: 0.22172287106513977
train-epoch-step: 26-212 -- Loss: 0.20365901291370392
train-epoch-step: 26-213 -- Loss: 0.1267910599708557
train-epoch-step: 26-214 -- Loss: 0.152743399143219
train-epoch-step: 26-215 -- Loss: 0.1305113434791565
train-epoch-step: 26-216 -- Loss: 0.2083790898323059
train-epoch-step: 26-217 -- Loss: 0.21488717198371887
train-epoch-step: 26-218 -- Loss: 0.15021689236164093
train-epoch-step: 26-219 -- Loss: 0.17530189454555511
train-epoch-step: 26-220 -- Loss: 0.13273456692695618
train-epoch-step: 26-221 -- Loss: 0.21190206706523895
train-epoch-step: 26-222 -- Loss: 0.11965139955282211
train-epoch-step: 26-223 -- Loss: 0.17526814341545105
train-epoch-step: 26-224 -- Loss: 0.19655823707580566
train-epoch-step: 26-225 -- Loss: 0.2781851887702942
train-epoch-step: 26-226 -- Loss: 0.21280425786972046
train-epoch-step: 26-227 -- Loss: 0.22625161707401276
train-epoch-step: 26-228 -- Loss: 0.18283094465732574
train-epoch-step: 26-229 -- Loss: 0.17628346383571625
train-epoch-step: 26-230 -- Loss: 0.16306158900260925
train-epoch-step: 26-231 -- Loss: 0.16049370169639587
train-epoch-step: 26-232 -- Loss: 0.1980293095111847
train-epoch-step: 26-233 -- Loss: 0.08575868606567383
train-epoch-step: 26-234 -- Loss: 0.18058177828788757
train-epoch-step: 26-235 -- Loss: 0.15229444205760956
train-epoch-step: 26-236 -- Loss: 0.1844000369310379
train-epoch-step: 26-237 -- Loss: 0.2499179244041443
train-epoch-step: 26-238 -- Loss: 0.15856972336769104
train-epoch-step: 26-239 -- Loss: 0.1311616599559784
train-epoch-step: 26-240 -- Loss: 0.2315933257341385
train-epoch-step: 26-241 -- Loss: 0.15703634917736053
train-epoch-step: 26-242 -- Loss: 0.22738519310951233
train-epoch-step: 26-243 -- Loss: 0.2367158830165863
train-epoch-step: 26-244 -- Loss: 0.20763684809207916
train-epoch-step: 26-245 -- Loss: 0.21423465013504028
train-epoch-step: 26-246 -- Loss: 0.23824429512023926
train-epoch-step: 26-247 -- Loss: 0.21938025951385498
train-epoch-step: 26-248 -- Loss: 0.18805235624313354
train-epoch-step: 26-249 -- Loss: 0.1414550542831421
train-epoch-step: 26-250 -- Loss: 0.20626583695411682
train-epoch-step: 26-251 -- Loss: 0.11041873693466187
train-epoch-step: 26-252 -- Loss: 0.2008504420518875
train-epoch-step: 26-253 -- Loss: 0.1386820673942566
train-epoch-step: 26-254 -- Loss: 0.21880429983139038
train-epoch-step: 26-255 -- Loss: 0.15051454305648804
train-epoch-step: 26-256 -- Loss: 0.1727648377418518
train-epoch-step: 26-257 -- Loss: 0.1983168125152588
train-epoch-step: 26-258 -- Loss: 0.15379546582698822
train-epoch-step: 26-259 -- Loss: 0.12307877838611603
train-epoch-step: 26-260 -- Loss: 0.20891571044921875
train-epoch-step: 26-261 -- Loss: 0.18895094096660614
train-epoch-step: 26-262 -- Loss: 0.31169772148132324
train-epoch-step: 26-263 -- Loss: 0.20339815318584442
train-epoch-step: 26-264 -- Loss: 0.17767810821533203
train-epoch-step: 26-265 -- Loss: 0.13289742171764374
train-epoch-step: 26-266 -- Loss: 0.1577150523662567
train-epoch-step: 26-267 -- Loss: 0.13857226073741913
train-epoch-step: 26-268 -- Loss: 0.12188008427619934
train-epoch-step: 26-269 -- Loss: 0.1766430139541626
train-epoch-step: 26-270 -- Loss: 0.10933879017829895
train-epoch-step: 26-271 -- Loss: 0.1524883359670639
train-epoch-step: 26-272 -- Loss: 0.11645004153251648
train-epoch-step: 26-273 -- Loss: 0.13019375503063202
train-epoch-step: 26-274 -- Loss: 0.1905314028263092
train-epoch-step: 26-275 -- Loss: 0.21757221221923828
train-epoch-step: 26-276 -- Loss: 0.17261198163032532
train-epoch-step: 26-277 -- Loss: 0.16196241974830627
train-epoch-step: 26-278 -- Loss: 0.14475677907466888
train-epoch-step: 26-279 -- Loss: 0.15560013055801392
train-epoch-step: 26-280 -- Loss: 0.23528032004833221
train-epoch-step: 26-281 -- Loss: 0.18306806683540344
train-epoch-step: 26-282 -- Loss: 0.14559993147850037
train-epoch-step: 26-283 -- Loss: 0.12308402359485626
train-epoch-step: 26-284 -- Loss: 0.14554885029792786
train-epoch-step: 26-285 -- Loss: 0.19906362891197205
train-epoch-step: 26-286 -- Loss: 0.15964050590991974
train-epoch-step: 26-287 -- Loss: 0.22090701758861542
train-epoch-step: 26-288 -- Loss: 0.09898567199707031
train-epoch-step: 26-289 -- Loss: 0.12438397109508514
train-epoch-step: 26-290 -- Loss: 0.19684875011444092
train-epoch-step: 26-291 -- Loss: 0.12225951254367828
train-epoch-step: 26-292 -- Loss: 0.15843737125396729
train-epoch-step: 26-293 -- Loss: 0.1452951729297638
train-epoch-step: 26-294 -- Loss: 0.17077283561229706
train-epoch-step: 26-295 -- Loss: 0.27416566014289856
train-epoch-step: 26-296 -- Loss: 0.16564148664474487
train-epoch-step: 26-297 -- Loss: 0.17871703207492828
train-epoch-step: 26-298 -- Loss: 0.2404729723930359
train-epoch-step: 26-299 -- Loss: 0.15463796257972717
train-epoch-step: 26-300 -- Loss: 0.17494839429855347
train-epoch-step: 26-301 -- Loss: 0.19374284148216248
train-epoch-step: 26-302 -- Loss: 0.2273443639278412
train-epoch-step: 26-303 -- Loss: 0.21177594363689423
train-epoch-step: 26-304 -- Loss: 0.13717058300971985
train-epoch-step: 26-305 -- Loss: 0.14682069420814514
train-epoch-step: 26-306 -- Loss: 0.2336387038230896
train-epoch-step: 26-307 -- Loss: 0.1680617332458496
train-epoch-step: 26-308 -- Loss: 0.2326599806547165
train-epoch-step: 26-309 -- Loss: 0.1538834124803543
train-epoch-step: 26-310 -- Loss: 0.1648043394088745
train-epoch-step: 26-311 -- Loss: 0.17053203284740448
train-epoch-step: 26-312 -- Loss: 0.20847895741462708
train-epoch-step: 26-313 -- Loss: 0.1010066494345665
train-epoch-step: 26-314 -- Loss: 0.2029387652873993
train-epoch-step: 26-315 -- Loss: 0.1789940595626831
train-epoch-step: 26-316 -- Loss: 0.15521495044231415
train-epoch-step: 26-317 -- Loss: 0.15620911121368408
train-epoch-step: 26-318 -- Loss: 0.16985106468200684
train-epoch-step: 26-319 -- Loss: 0.18218481540679932
train-epoch-step: 26-320 -- Loss: 0.12429282069206238
train-epoch-step: 26-321 -- Loss: 0.13929960131645203
train-epoch-step: 26-322 -- Loss: 0.21717579662799835
train-epoch-step: 26-323 -- Loss: 0.1639910340309143
train-epoch-step: 26-324 -- Loss: 0.2628582715988159
train-epoch-step: 26-325 -- Loss: 0.1573583036661148
train-epoch-step: 26-326 -- Loss: 0.17539966106414795
train-epoch-step: 26-327 -- Loss: 0.20662108063697815
train-epoch-step: 26-328 -- Loss: 0.19600853323936462
train-epoch-step: 26-329 -- Loss: 0.3449655771255493
train-epoch-step: 26-330 -- Loss: 0.3644676208496094
train-epoch-step: 26-331 -- Loss: 0.2098965346813202
train-epoch-step: 26-332 -- Loss: 0.10423944890499115
train-epoch-step: 26-333 -- Loss: 0.19236169755458832
train-epoch-step: 26-334 -- Loss: 0.1581306904554367
train-epoch-step: 26-335 -- Loss: 0.1786748170852661
train-epoch-step: 26-336 -- Loss: 0.15383826196193695
train-epoch-step: 26-337 -- Loss: 0.219594806432724
train-epoch-step: 26-338 -- Loss: 0.1697649508714676
train-epoch-step: 26-339 -- Loss: 0.14847910404205322
train-epoch-step: 26-340 -- Loss: 0.2011086642742157
train-epoch-step: 26-341 -- Loss: 0.14100787043571472
train-epoch-step: 26-342 -- Loss: 0.1697610765695572
train-epoch-step: 26-343 -- Loss: 0.15870006382465363
train-epoch-step: 26-344 -- Loss: 0.17026428878307343
train-epoch-step: 26-345 -- Loss: 0.1312789022922516
train-epoch-step: 26-346 -- Loss: 0.21873030066490173
train-epoch-step: 26-347 -- Loss: 0.15215927362442017
train-epoch-step: 26-348 -- Loss: 0.20895767211914062
train-epoch-step: 26-349 -- Loss: 0.2107408046722412
train-epoch-step: 26-350 -- Loss: 0.2577987015247345
train-epoch-step: 26-351 -- Loss: 0.2012081891298294
train-epoch-step: 26-352 -- Loss: 0.12897878885269165
train-epoch-step: 26-353 -- Loss: 0.1958351880311966
train-epoch-step: 26-354 -- Loss: 0.2839193344116211
train-epoch-step: 26-355 -- Loss: 0.12074499577283859
train-epoch-step: 26-356 -- Loss: 0.11885310709476471
train-epoch-step: 26-357 -- Loss: 0.18890368938446045
train-epoch-step: 26-358 -- Loss: 0.18589100241661072
train-epoch-step: 26-359 -- Loss: 0.14568033814430237
train-epoch-step: 26-360 -- Loss: 0.12381622195243835
train-epoch-step: 26-361 -- Loss: 0.24187275767326355
train-epoch-step: 26-362 -- Loss: 0.1690608263015747
train-epoch-step: 26-363 -- Loss: 0.11324784904718399
train-epoch-step: 26-364 -- Loss: 0.18878087401390076
train-epoch-step: 26-365 -- Loss: 0.17709863185882568
train-epoch-step: 26-366 -- Loss: 0.20243224501609802
train-epoch-step: 26-367 -- Loss: 0.23716847598552704
train-epoch-step: 26-368 -- Loss: 0.210676372051239
train-epoch-step: 26-369 -- Loss: 0.28423354029655457
train-epoch-step: 26-370 -- Loss: 0.12668105959892273
train-epoch-step: 26-371 -- Loss: 0.12501341104507446
train-epoch-step: 26-372 -- Loss: 0.14816759526729584
train-epoch-step: 26-373 -- Loss: 0.19439886510372162
train-epoch-step: 26-374 -- Loss: 0.1584489941596985
train-epoch-step: 26-375 -- Loss: 0.28591570258140564
train-epoch-step: 26-376 -- Loss: 0.16606633365154266
train-epoch-step: 26-377 -- Loss: 0.2352190464735031
train-epoch-step: 26-378 -- Loss: 0.21035078167915344
train-epoch-step: 26-379 -- Loss: 0.12115157395601273
train-epoch-step: 26-380 -- Loss: 0.09458286315202713
train-epoch-step: 26-381 -- Loss: 0.25262489914894104
train-epoch-step: 26-382 -- Loss: 0.2378833144903183
train-epoch-step: 26-383 -- Loss: 0.179610937833786
train-epoch-step: 26-384 -- Loss: 0.22973407804965973
train-epoch-step: 26-385 -- Loss: 0.19710564613342285
train-epoch-step: 26-386 -- Loss: 0.1854836344718933
train-epoch-step: 26-387 -- Loss: 0.20947301387786865
train-epoch-step: 26-388 -- Loss: 0.2113763391971588
train-epoch-step: 26-389 -- Loss: 0.16897869110107422
train-epoch-step: 26-390 -- Loss: 0.14998598396778107
train-epoch-step: 26-391 -- Loss: 0.15231718122959137
train-epoch-step: 26-392 -- Loss: 0.19481860101222992
train-epoch-step: 26-393 -- Loss: 0.16319547593593597
train-epoch-step: 26-394 -- Loss: 0.2172711193561554
train-epoch-step: 26-395 -- Loss: 0.16404065489768982
train-epoch-step: 26-396 -- Loss: 0.12869536876678467
train-epoch-step: 26-397 -- Loss: 0.12525534629821777
train-epoch-step: 26-398 -- Loss: 0.20482710003852844
train-epoch-step: 26-399 -- Loss: 0.18649627268314362
train-epoch-step: 26-400 -- Loss: 0.2956492304801941
train-epoch-step: 26-401 -- Loss: 0.12755954265594482
train-epoch-step: 26-402 -- Loss: 0.26988211274147034
train-epoch-step: 26-403 -- Loss: 0.1614474058151245
train-epoch-step: 26-404 -- Loss: 0.14107076823711395
train-epoch-step: 26-405 -- Loss: 0.15100200474262238
train-epoch-step: 26-406 -- Loss: 0.17325912415981293
train-epoch-step: 26-407 -- Loss: 0.11585311591625214
train-epoch-step: 26-408 -- Loss: 0.1675851047039032
train-epoch-step: 26-409 -- Loss: 0.1741303950548172
train-epoch-step: 26-410 -- Loss: 0.18368583917617798
train-epoch-step: 26-411 -- Loss: 0.21725478768348694
train-epoch-step: 26-412 -- Loss: 0.13699480891227722
train-epoch-step: 26-413 -- Loss: 0.15303559601306915
train-epoch-step: 26-414 -- Loss: 0.13556529581546783
train-epoch-step: 26-415 -- Loss: 0.14046704769134521
train-epoch-step: 26-416 -- Loss: 0.27666378021240234
train-epoch-step: 26-417 -- Loss: 0.1988976001739502
train-epoch-step: 26-418 -- Loss: 0.23795977234840393
train-epoch-step: 26-419 -- Loss: 0.1812480241060257
train-epoch-step: 26-420 -- Loss: 0.1567607820034027
train-epoch-step: 26-421 -- Loss: 0.18274186551570892
train-epoch-step: 26-422 -- Loss: 0.15432868897914886
train-epoch-step: 26-423 -- Loss: 0.18450477719306946
train-epoch-step: 26-424 -- Loss: 0.1398712694644928
train-epoch-step: 26-425 -- Loss: 0.18732886016368866
train-epoch-step: 26-426 -- Loss: 0.1630447655916214
train-epoch-step: 26-427 -- Loss: 0.1249489113688469
train-epoch-step: 26-428 -- Loss: 0.1999727189540863
train-epoch-step: 26-429 -- Loss: 0.1801999807357788
train-epoch-step: 26-430 -- Loss: 0.14263418316841125
train-epoch-step: 26-431 -- Loss: 0.17028847336769104
train-epoch-step: 26-432 -- Loss: 0.24745243787765503
train-epoch-step: 26-433 -- Loss: 0.15711542963981628
train-epoch-step: 26-434 -- Loss: 0.13080668449401855
train-epoch-step: 26-435 -- Loss: 0.15289533138275146
train-epoch-step: 26-436 -- Loss: 0.16096189618110657
train-epoch-step: 26-437 -- Loss: 0.1366901993751526
train-epoch-step: 26-438 -- Loss: 0.17092157900333405
train-epoch-step: 26-439 -- Loss: 0.2867566645145416
train-epoch-step: 26-440 -- Loss: 0.13668176531791687
train-epoch-step: 26-441 -- Loss: 0.20433932542800903
train-epoch-step: 26-442 -- Loss: 0.1833556592464447
train-epoch-step: 26-443 -- Loss: 0.16281525790691376
train-epoch-step: 26-444 -- Loss: 0.18178583681583405
train-epoch-step: 26-445 -- Loss: 0.1836809664964676
train-epoch-step: 26-446 -- Loss: 0.15995898842811584
train-epoch-step: 26-447 -- Loss: 0.19370001554489136
train-epoch-step: 26-448 -- Loss: 0.22636853158473969
train-epoch-step: 26-449 -- Loss: 0.1990063190460205
train-epoch-step: 26-450 -- Loss: 0.18370971083641052
train-epoch-step: 26-451 -- Loss: 0.14772668480873108
train-epoch-step: 26-452 -- Loss: 0.14402399957180023
train-epoch-step: 26-453 -- Loss: 0.09540063142776489
train-epoch-step: 26-454 -- Loss: 0.23673143982887268
train-epoch-step: 26-455 -- Loss: 0.12582312524318695
train-epoch-step: 26-456 -- Loss: 0.12577173113822937
train-epoch-step: 26-457 -- Loss: 0.22622525691986084
train-epoch-step: 26-458 -- Loss: 0.14965085685253143
train-epoch-step: 26-459 -- Loss: 0.2215692102909088
train-epoch-step: 26-460 -- Loss: 0.12777677178382874
train-epoch-step: 26-461 -- Loss: 0.1390724629163742
train-epoch-step: 26-462 -- Loss: 0.1671282947063446
train-epoch-step: 26-463 -- Loss: 0.1375088393688202
train-epoch-step: 26-464 -- Loss: 0.176219642162323
train-epoch-step: 26-465 -- Loss: 0.2465168535709381
train-epoch-step: 26-466 -- Loss: 0.20196136832237244
train-epoch-step: 26-467 -- Loss: 0.11336548626422882
train-epoch-step: 26-468 -- Loss: 0.17132535576820374
train-epoch-step: 26-469 -- Loss: 0.21666750311851501
train-epoch-step: 26-470 -- Loss: 0.18263059854507446
train-epoch-step: 26-471 -- Loss: 0.17008483409881592
train-epoch-step: 26-472 -- Loss: 0.15903744101524353
train-epoch-step: 26-473 -- Loss: 0.15857183933258057
train-epoch-step: 26-474 -- Loss: 0.1255970150232315
train-epoch-step: 26-475 -- Loss: 0.12390505522489548
train-epoch-step: 26-476 -- Loss: 0.20237240195274353
train-epoch-step: 26-477 -- Loss: 0.23227500915527344
train-epoch-step: 26-478 -- Loss: 0.19824329018592834
train-epoch-step: 26-479 -- Loss: 0.15332117676734924
train-epoch-step: 26-480 -- Loss: 0.19974298775196075
train-epoch-step: 26-481 -- Loss: 0.2893025875091553
train-epoch-step: 26-482 -- Loss: 0.25284919142723083
train-epoch-step: 26-483 -- Loss: 0.19455061852931976
train-epoch-step: 26-484 -- Loss: 0.21885158121585846
train-epoch-step: 26-485 -- Loss: 0.13632211089134216
train-epoch-step: 26-486 -- Loss: 0.24175146222114563
train-epoch-step: 26-487 -- Loss: 0.23465828597545624
train-epoch-step: 26-488 -- Loss: 0.2082795351743698
train-epoch-step: 26-489 -- Loss: 0.22084888815879822
train-epoch-step: 26-490 -- Loss: 0.1487685889005661
train-epoch-step: 26-491 -- Loss: 0.149727463722229
train-epoch-step: 26-492 -- Loss: 0.13001422584056854
train-epoch-step: 26-493 -- Loss: 0.21090912818908691
train-epoch-step: 26-494 -- Loss: 0.22134995460510254
train-epoch-step: 26-495 -- Loss: 0.21793386340141296
train-epoch-step: 26-496 -- Loss: 0.14420433342456818
train-epoch-step: 26-497 -- Loss: 0.1951901763677597
train-epoch-step: 26-498 -- Loss: 0.1597946286201477
train-epoch-step: 26-499 -- Loss: 0.17826849222183228
train-epoch-step: 26-500 -- Loss: 0.1577710509300232
train-epoch-step: 26-501 -- Loss: 0.22529783844947815
train-epoch-step: 26-502 -- Loss: 0.17201773822307587
train-epoch-step: 26-503 -- Loss: 0.22798378765583038
train-epoch-step: 26-504 -- Loss: 0.12143801152706146
train-epoch-step: 26-505 -- Loss: 0.17173989117145538
train-epoch-step: 26-506 -- Loss: 0.12624900043010712
train-epoch-step: 26-507 -- Loss: 0.19159695506095886
train-epoch-step: 26-508 -- Loss: 0.1772063821554184
train-epoch-step: 26-509 -- Loss: 0.1783614158630371
train-epoch-step: 26-510 -- Loss: 0.12852749228477478
train-epoch-step: 26-511 -- Loss: 0.21881552040576935
train-epoch-step: 26-512 -- Loss: 0.18058013916015625
train-epoch-step: 26-513 -- Loss: 0.1963304877281189
train-epoch-step: 26-514 -- Loss: 0.1478547751903534
train-epoch-step: 26-515 -- Loss: 0.16399690508842468
train-epoch-step: 26-516 -- Loss: 0.1751638501882553
train-epoch-step: 26-517 -- Loss: 0.17594680190086365
train-epoch-step: 26-518 -- Loss: 0.14735236763954163
train-epoch-step: 26-519 -- Loss: 0.13590413331985474
train-epoch-step: 26-520 -- Loss: 0.1877550184726715
train-epoch-step: 26-521 -- Loss: 0.2327924370765686
train-epoch-step: 26-522 -- Loss: 0.17914921045303345
train-epoch-step: 26-523 -- Loss: 0.16814225912094116
train-epoch-step: 26-524 -- Loss: 0.1706921011209488
train-epoch-step: 26-525 -- Loss: 0.19181986153125763
train-epoch-step: 26-526 -- Loss: 0.12958228588104248
train-epoch-step: 26-527 -- Loss: 0.1596713811159134
train-epoch-step: 26-528 -- Loss: 0.16006222367286682
train-epoch-step: 26-529 -- Loss: 0.16853907704353333
train-epoch-step: 26-530 -- Loss: 0.17012587189674377
train-epoch-step: 26-531 -- Loss: 0.2076234668493271
train-epoch-step: 26-532 -- Loss: 0.17598994076251984
train-epoch-step: 26-533 -- Loss: 0.17666423320770264
train-epoch-step: 26-534 -- Loss: 0.1332908421754837
train-epoch-step: 26-535 -- Loss: 0.2549644410610199
train-epoch-step: 26-536 -- Loss: 0.1695520132780075
train-epoch-step: 26-537 -- Loss: 0.15540236234664917
train-epoch-step: 26-538 -- Loss: 0.10602462291717529
train-epoch-step: 26-539 -- Loss: 0.19295088946819305
train-epoch-step: 26-540 -- Loss: 0.13849890232086182
train-epoch-step: 26-541 -- Loss: 0.2124014049768448
train-epoch-step: 26-542 -- Loss: 0.2268703430891037
train-epoch-step: 26-543 -- Loss: 0.16978657245635986
train-epoch-step: 26-544 -- Loss: 0.23424768447875977
train-epoch-step: 26-545 -- Loss: 0.19925859570503235
train-epoch-step: 26-546 -- Loss: 0.22350698709487915
train-epoch-step: 26-547 -- Loss: 0.18627193570137024
train-epoch-step: 26-548 -- Loss: 0.10056653618812561
train-epoch-step: 26-549 -- Loss: 0.15490175783634186
train-epoch-step: 26-550 -- Loss: 0.19989313185214996
train-epoch-step: 26-551 -- Loss: 0.15791596472263336
train-epoch-step: 26-552 -- Loss: 0.13284146785736084
train-epoch-step: 26-553 -- Loss: 0.18835680186748505
train-epoch-step: 26-554 -- Loss: 0.19296181201934814
train-epoch-step: 26-555 -- Loss: 0.22385674715042114
train-epoch-step: 26-556 -- Loss: 0.15371108055114746
train-epoch-step: 26-557 -- Loss: 0.24098804593086243
train-epoch-step: 26-558 -- Loss: 0.23695939779281616
train-epoch-step: 26-559 -- Loss: 0.14140300452709198
train-epoch-step: 26-560 -- Loss: 0.20942643284797668
train-epoch-step: 26-561 -- Loss: 0.18587180972099304
train-epoch-step: 26-562 -- Loss: 0.17037585377693176
train-epoch-step: 26-563 -- Loss: 0.19488245248794556
train-epoch-step: 26-564 -- Loss: 0.1021883636713028
train-epoch-step: 26-565 -- Loss: 0.18791961669921875
train-epoch-step: 26-566 -- Loss: 0.15132080018520355
train-epoch-step: 26-567 -- Loss: 0.21604633331298828
train-epoch-step: 26-568 -- Loss: 0.16121360659599304
train-epoch-step: 26-569 -- Loss: 0.24590182304382324
train-epoch-step: 26-570 -- Loss: 0.17150694131851196
train-epoch-step: 26-571 -- Loss: 0.21544718742370605
train-epoch-step: 26-572 -- Loss: 0.24207833409309387
train-epoch-step: 26-573 -- Loss: 0.20884087681770325
train-epoch-step: 26-574 -- Loss: 0.2529177665710449
train-epoch-step: 26-575 -- Loss: 0.2944016456604004
train-epoch-step: 26-576 -- Loss: 0.1224081814289093
train-epoch-step: 26-577 -- Loss: 0.16909603774547577
train-epoch-step: 26-578 -- Loss: 0.21709877252578735
train-epoch-step: 26-579 -- Loss: 0.1635923981666565
train-epoch-step: 26-580 -- Loss: 0.18063348531723022
train-epoch-step: 26-581 -- Loss: 0.14326699078083038
train-epoch-step: 26-582 -- Loss: 0.2070470154285431
train-epoch-step: 26-583 -- Loss: 0.2237120270729065
train-epoch-step: 26-584 -- Loss: 0.17141848802566528
train-epoch-step: 26-585 -- Loss: 0.19524887204170227
train-epoch-step: 26-586 -- Loss: 0.25710758566856384
train-epoch-step: 26-587 -- Loss: 0.16797639429569244
train-epoch-step: 26-588 -- Loss: 0.12918910384178162
val-epoch-step: 26-589 -- Loss: 0.21868577599525452
val-epoch-step: 26-590 -- Loss: 0.15484316647052765
val-epoch-step: 26-591 -- Loss: 0.24132400751113892
val-epoch-step: 26-592 -- Loss: 0.18195828795433044
val-epoch-step: 26-593 -- Loss: 0.1548040360212326
val-epoch-step: 26-594 -- Loss: 0.4333038330078125
val-epoch-step: 26-595 -- Loss: 0.17973795533180237
val-epoch-step: 26-596 -- Loss: 0.21839705109596252
val-epoch-step: 26-597 -- Loss: 0.17869038879871368
val-epoch-step: 26-598 -- Loss: 0.15337368845939636
val-epoch-step: 26-599 -- Loss: 0.1853267103433609
val-epoch-step: 26-600 -- Loss: 0.1903470903635025
val-epoch-step: 26-601 -- Loss: 0.15924717485904694
val-epoch-step: 26-602 -- Loss: 0.1423311084508896
val-epoch-step: 26-603 -- Loss: 0.1981339305639267
val-epoch-step: 26-604 -- Loss: 0.15153548121452332
val-epoch-step: 26-605 -- Loss: 0.15186935663223267
val-epoch-step: 26-606 -- Loss: 0.2771235704421997
val-epoch-step: 26-607 -- Loss: 0.13308005034923553
val-epoch-step: 26-608 -- Loss: 0.2450028359889984
val-epoch-step: 26-609 -- Loss: 0.1717008352279663
val-epoch-step: 26-610 -- Loss: 0.18341761827468872
val-epoch-step: 26-611 -- Loss: 0.16460567712783813
val-epoch-step: 26-612 -- Loss: 0.3794974088668823
val-epoch-step: 26-613 -- Loss: 0.17406322062015533
val-epoch-step: 26-614 -- Loss: 0.17683757841587067
val-epoch-step: 26-615 -- Loss: 0.1776590794324875
val-epoch-step: 26-616 -- Loss: 0.1603403240442276
val-epoch-step: 26-617 -- Loss: 0.19098106026649475
val-epoch-step: 26-618 -- Loss: 0.18763133883476257
val-epoch-step: 26-619 -- Loss: 0.2255636751651764
val-epoch-step: 26-620 -- Loss: 0.15471556782722473
val-epoch-step: 26-621 -- Loss: 0.13176476955413818
val-epoch-step: 26-622 -- Loss: 0.14419609308242798
val-epoch-step: 26-623 -- Loss: 0.15575633943080902
val-epoch-step: 26-624 -- Loss: 0.15186014771461487
val-epoch-step: 26-625 -- Loss: 0.16291457414627075
val-epoch-step: 26-626 -- Loss: 0.15380144119262695
val-epoch-step: 26-627 -- Loss: 0.19100701808929443
val-epoch-step: 26-628 -- Loss: 0.6303225159645081
val-epoch-step: 26-629 -- Loss: 0.21271435916423798
val-epoch-step: 26-630 -- Loss: 0.3533492088317871
val-epoch-step: 26-631 -- Loss: 0.14228017628192902
val-epoch-step: 26-632 -- Loss: 0.21075919270515442
val-epoch-step: 26-633 -- Loss: 0.1534593552350998
val-epoch-step: 26-634 -- Loss: 0.15655960142612457
val-epoch-step: 26-635 -- Loss: 0.12296517938375473
val-epoch-step: 26-636 -- Loss: 0.17688137292861938
val-epoch-step: 26-637 -- Loss: 0.18252858519554138
val-epoch-step: 26-638 -- Loss: 0.17404332756996155
val-epoch-step: 26-639 -- Loss: 0.25536906719207764
val-epoch-step: 26-640 -- Loss: 0.25945547223091125
val-epoch-step: 26-641 -- Loss: 0.13322404026985168
val-epoch-step: 26-642 -- Loss: 0.21395879983901978
val-epoch-step: 26-643 -- Loss: 0.20563313364982605
val-epoch-step: 26-644 -- Loss: 0.16612359881401062
val-epoch-step: 26-645 -- Loss: 0.2234477996826172
val-epoch-step: 26-646 -- Loss: 0.14030387997627258
val-epoch-step: 26-647 -- Loss: 0.13911613821983337
val-epoch-step: 26-648 -- Loss: 0.16083741188049316
val-epoch-step: 26-649 -- Loss: 0.21060776710510254
val-epoch-step: 26-650 -- Loss: 0.2647823393344879
val-epoch-step: 26-651 -- Loss: 0.1453932374715805
val-epoch-step: 26-652 -- Loss: 0.16054879128932953
val-epoch-step: 26-653 -- Loss: 0.22359035909175873
val-epoch-step: 26-654 -- Loss: 0.1156449094414711
Epoch: 26 -- Train Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1446, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 27-0 -- Loss: 0.22562173008918762
train-epoch-step: 27-1 -- Loss: 0.15077641606330872
train-epoch-step: 27-2 -- Loss: 0.20670227706432343
train-epoch-step: 27-3 -- Loss: 0.15816226601600647
train-epoch-step: 27-4 -- Loss: 0.16047438979148865
train-epoch-step: 27-5 -- Loss: 0.1836872547864914
train-epoch-step: 27-6 -- Loss: 0.2213137298822403
train-epoch-step: 27-7 -- Loss: 0.1726689487695694
train-epoch-step: 27-8 -- Loss: 0.18399649858474731
train-epoch-step: 27-9 -- Loss: 0.22749555110931396
train-epoch-step: 27-10 -- Loss: 0.19345572590827942
train-epoch-step: 27-11 -- Loss: 0.20270982384681702
train-epoch-step: 27-12 -- Loss: 0.15296943485736847
train-epoch-step: 27-13 -- Loss: 0.1763107180595398
train-epoch-step: 27-14 -- Loss: 0.1663946807384491
train-epoch-step: 27-15 -- Loss: 0.16251417994499207
train-epoch-step: 27-16 -- Loss: 0.16678674519062042
train-epoch-step: 27-17 -- Loss: 0.22369982302188873
train-epoch-step: 27-18 -- Loss: 0.1999613493680954
train-epoch-step: 27-19 -- Loss: 0.13525253534317017
train-epoch-step: 27-20 -- Loss: 0.2165878713130951
train-epoch-step: 27-21 -- Loss: 0.2852213978767395
train-epoch-step: 27-22 -- Loss: 0.14695455133914948
train-epoch-step: 27-23 -- Loss: 0.15291638672351837
train-epoch-step: 27-24 -- Loss: 0.12899993360042572
train-epoch-step: 27-25 -- Loss: 0.24557769298553467
train-epoch-step: 27-26 -- Loss: 0.2013198435306549
train-epoch-step: 27-27 -- Loss: 0.23868045210838318
train-epoch-step: 27-28 -- Loss: 0.12781770527362823
train-epoch-step: 27-29 -- Loss: 0.24279052019119263
train-epoch-step: 27-30 -- Loss: 0.11619839072227478
train-epoch-step: 27-31 -- Loss: 0.14119084179401398
train-epoch-step: 27-32 -- Loss: 0.17507362365722656
train-epoch-step: 27-33 -- Loss: 0.28396767377853394
train-epoch-step: 27-34 -- Loss: 0.17589809000492096
train-epoch-step: 27-35 -- Loss: 0.24680203199386597
train-epoch-step: 27-36 -- Loss: 0.1378609538078308
train-epoch-step: 27-37 -- Loss: 0.14408549666404724
train-epoch-step: 27-38 -- Loss: 0.17981968820095062
train-epoch-step: 27-39 -- Loss: 0.2297954112291336
train-epoch-step: 27-40 -- Loss: 0.19784121215343475
train-epoch-step: 27-41 -- Loss: 0.2196640968322754
train-epoch-step: 27-42 -- Loss: 0.15105785429477692
train-epoch-step: 27-43 -- Loss: 0.2697184085845947
train-epoch-step: 27-44 -- Loss: 0.13845419883728027
train-epoch-step: 27-45 -- Loss: 0.11640825867652893
train-epoch-step: 27-46 -- Loss: 0.17490485310554504
train-epoch-step: 27-47 -- Loss: 0.21401160955429077
train-epoch-step: 27-48 -- Loss: 0.1559586524963379
train-epoch-step: 27-49 -- Loss: 0.2263813465833664
train-epoch-step: 27-50 -- Loss: 0.11952973902225494
train-epoch-step: 27-51 -- Loss: 0.19282904267311096
train-epoch-step: 27-52 -- Loss: 0.16997165977954865
train-epoch-step: 27-53 -- Loss: 0.21148671209812164
train-epoch-step: 27-54 -- Loss: 0.28922444581985474
train-epoch-step: 27-55 -- Loss: 0.16683967411518097
train-epoch-step: 27-56 -- Loss: 0.17706559598445892
train-epoch-step: 27-57 -- Loss: 0.2378716915845871
train-epoch-step: 27-58 -- Loss: 0.2962983250617981
train-epoch-step: 27-59 -- Loss: 0.25982820987701416
train-epoch-step: 27-60 -- Loss: 0.13399970531463623
train-epoch-step: 27-61 -- Loss: 0.20294064283370972
train-epoch-step: 27-62 -- Loss: 0.18851198256015778
train-epoch-step: 27-63 -- Loss: 0.14947037398815155
train-epoch-step: 27-64 -- Loss: 0.14994487166404724
train-epoch-step: 27-65 -- Loss: 0.1927318125963211
train-epoch-step: 27-66 -- Loss: 0.11143524199724197
train-epoch-step: 27-67 -- Loss: 0.13026776909828186
train-epoch-step: 27-68 -- Loss: 0.22089168429374695
train-epoch-step: 27-69 -- Loss: 0.1270759105682373
train-epoch-step: 27-70 -- Loss: 0.22713437676429749
train-epoch-step: 27-71 -- Loss: 0.2594503164291382
train-epoch-step: 27-72 -- Loss: 0.18164388835430145
train-epoch-step: 27-73 -- Loss: 0.21941348910331726
train-epoch-step: 27-74 -- Loss: 0.09778322279453278
train-epoch-step: 27-75 -- Loss: 0.1295057088136673
train-epoch-step: 27-76 -- Loss: 0.15490253269672394
train-epoch-step: 27-77 -- Loss: 0.23663592338562012
train-epoch-step: 27-78 -- Loss: 0.2642172574996948
train-epoch-step: 27-79 -- Loss: 0.2011527568101883
train-epoch-step: 27-80 -- Loss: 0.25425857305526733
train-epoch-step: 27-81 -- Loss: 0.1314200460910797
train-epoch-step: 27-82 -- Loss: 0.25882062315940857
train-epoch-step: 27-83 -- Loss: 0.23009911179542542
train-epoch-step: 27-84 -- Loss: 0.193070650100708
train-epoch-step: 27-85 -- Loss: 0.18314193189144135
train-epoch-step: 27-86 -- Loss: 0.12361980974674225
train-epoch-step: 27-87 -- Loss: 0.2236858755350113
train-epoch-step: 27-88 -- Loss: 0.14347951114177704
train-epoch-step: 27-89 -- Loss: 0.19079522788524628
train-epoch-step: 27-90 -- Loss: 0.1980501264333725
train-epoch-step: 27-91 -- Loss: 0.24911651015281677
train-epoch-step: 27-92 -- Loss: 0.15762493014335632
train-epoch-step: 27-93 -- Loss: 0.17949865758419037
train-epoch-step: 27-94 -- Loss: 0.24133017659187317
train-epoch-step: 27-95 -- Loss: 0.19305419921875
train-epoch-step: 27-96 -- Loss: 0.22366365790367126
train-epoch-step: 27-97 -- Loss: 0.181089386343956
train-epoch-step: 27-98 -- Loss: 0.16640493273735046
train-epoch-step: 27-99 -- Loss: 0.18693655729293823
train-epoch-step: 27-100 -- Loss: 0.18960082530975342
train-epoch-step: 27-101 -- Loss: 0.28801995515823364
train-epoch-step: 27-102 -- Loss: 0.2408699244260788
train-epoch-step: 27-103 -- Loss: 0.1915343552827835
train-epoch-step: 27-104 -- Loss: 0.15428300201892853
train-epoch-step: 27-105 -- Loss: 0.275872141122818
train-epoch-step: 27-106 -- Loss: 0.18355052173137665
train-epoch-step: 27-107 -- Loss: 0.19164207577705383
train-epoch-step: 27-108 -- Loss: 0.19110243022441864
train-epoch-step: 27-109 -- Loss: 0.15059100091457367
train-epoch-step: 27-110 -- Loss: 0.18653085827827454
train-epoch-step: 27-111 -- Loss: 0.1854327768087387
train-epoch-step: 27-112 -- Loss: 0.17678968608379364
train-epoch-step: 27-113 -- Loss: 0.16948390007019043
train-epoch-step: 27-114 -- Loss: 0.20244146883487701
train-epoch-step: 27-115 -- Loss: 0.16777858138084412
train-epoch-step: 27-116 -- Loss: 0.13986341655254364
train-epoch-step: 27-117 -- Loss: 0.131802499294281
train-epoch-step: 27-118 -- Loss: 0.20500445365905762
train-epoch-step: 27-119 -- Loss: 0.1568593680858612
train-epoch-step: 27-120 -- Loss: 0.2558937072753906
train-epoch-step: 27-121 -- Loss: 0.25755491852760315
train-epoch-step: 27-122 -- Loss: 0.2268942892551422
train-epoch-step: 27-123 -- Loss: 0.20664498209953308
train-epoch-step: 27-124 -- Loss: 0.1262899786233902
train-epoch-step: 27-125 -- Loss: 0.155573308467865
train-epoch-step: 27-126 -- Loss: 0.22996702790260315
train-epoch-step: 27-127 -- Loss: 0.1820930391550064
train-epoch-step: 27-128 -- Loss: 0.17437005043029785
train-epoch-step: 27-129 -- Loss: 0.1430477499961853
train-epoch-step: 27-130 -- Loss: 0.20045778155326843
train-epoch-step: 27-131 -- Loss: 0.13851261138916016
train-epoch-step: 27-132 -- Loss: 0.19752104580402374
train-epoch-step: 27-133 -- Loss: 0.11874715238809586
train-epoch-step: 27-134 -- Loss: 0.20442266762256622
train-epoch-step: 27-135 -- Loss: 0.15485817193984985
train-epoch-step: 27-136 -- Loss: 0.1345033496618271
train-epoch-step: 27-137 -- Loss: 0.25524452328681946
train-epoch-step: 27-138 -- Loss: 0.27755725383758545
train-epoch-step: 27-139 -- Loss: 0.13632524013519287
train-epoch-step: 27-140 -- Loss: 0.20513510704040527
train-epoch-step: 27-141 -- Loss: 0.23961107432842255
train-epoch-step: 27-142 -- Loss: 0.20086266100406647
train-epoch-step: 27-143 -- Loss: 0.17672006785869598
train-epoch-step: 27-144 -- Loss: 0.19247588515281677
train-epoch-step: 27-145 -- Loss: 0.14131413400173187
train-epoch-step: 27-146 -- Loss: 0.1826629787683487
train-epoch-step: 27-147 -- Loss: 0.17243027687072754
train-epoch-step: 27-148 -- Loss: 0.16645219922065735
train-epoch-step: 27-149 -- Loss: 0.12492954730987549
train-epoch-step: 27-150 -- Loss: 0.188853919506073
train-epoch-step: 27-151 -- Loss: 0.19997921586036682
train-epoch-step: 27-152 -- Loss: 0.19551913440227509
train-epoch-step: 27-153 -- Loss: 0.2699335813522339
train-epoch-step: 27-154 -- Loss: 0.13375642895698547
train-epoch-step: 27-155 -- Loss: 0.13851182162761688
train-epoch-step: 27-156 -- Loss: 0.12261322140693665
train-epoch-step: 27-157 -- Loss: 0.1707935929298401
train-epoch-step: 27-158 -- Loss: 0.17048172652721405
train-epoch-step: 27-159 -- Loss: 0.19033432006835938
train-epoch-step: 27-160 -- Loss: 0.23284366726875305
train-epoch-step: 27-161 -- Loss: 0.20645973086357117
train-epoch-step: 27-162 -- Loss: 0.21917429566383362
train-epoch-step: 27-163 -- Loss: 0.19237658381462097
train-epoch-step: 27-164 -- Loss: 0.19552017748355865
train-epoch-step: 27-165 -- Loss: 0.1708677113056183
train-epoch-step: 27-166 -- Loss: 0.12172579020261765
train-epoch-step: 27-167 -- Loss: 0.13157156109809875
train-epoch-step: 27-168 -- Loss: 0.20581579208374023
train-epoch-step: 27-169 -- Loss: 0.14442425966262817
train-epoch-step: 27-170 -- Loss: 0.20516927540302277
train-epoch-step: 27-171 -- Loss: 0.14531798660755157
train-epoch-step: 27-172 -- Loss: 0.27001336216926575
train-epoch-step: 27-173 -- Loss: 0.14054685831069946
train-epoch-step: 27-174 -- Loss: 0.2538449168205261
train-epoch-step: 27-175 -- Loss: 0.18914979696273804
train-epoch-step: 27-176 -- Loss: 0.13938578963279724
train-epoch-step: 27-177 -- Loss: 0.19511350989341736
train-epoch-step: 27-178 -- Loss: 0.17964255809783936
train-epoch-step: 27-179 -- Loss: 0.154295414686203
train-epoch-step: 27-180 -- Loss: 0.15778732299804688
train-epoch-step: 27-181 -- Loss: 0.17814962565898895
train-epoch-step: 27-182 -- Loss: 0.1904425323009491
train-epoch-step: 27-183 -- Loss: 0.28926196694374084
train-epoch-step: 27-184 -- Loss: 0.14034153521060944
train-epoch-step: 27-185 -- Loss: 0.14544324576854706
train-epoch-step: 27-186 -- Loss: 0.20077575743198395
train-epoch-step: 27-187 -- Loss: 0.22258521616458893
train-epoch-step: 27-188 -- Loss: 0.18109694123268127
train-epoch-step: 27-189 -- Loss: 0.10947561264038086
train-epoch-step: 27-190 -- Loss: 0.18197353184223175
train-epoch-step: 27-191 -- Loss: 0.1680513620376587
train-epoch-step: 27-192 -- Loss: 0.23741498589515686
train-epoch-step: 27-193 -- Loss: 0.2119051218032837
train-epoch-step: 27-194 -- Loss: 0.18681150674819946
train-epoch-step: 27-195 -- Loss: 0.17103546857833862
train-epoch-step: 27-196 -- Loss: 0.17471233010292053
train-epoch-step: 27-197 -- Loss: 0.1310821771621704
train-epoch-step: 27-198 -- Loss: 0.13055016100406647
train-epoch-step: 27-199 -- Loss: 0.1609177589416504
train-epoch-step: 27-200 -- Loss: 0.12934985756874084
train-epoch-step: 27-201 -- Loss: 0.20165324211120605
train-epoch-step: 27-202 -- Loss: 0.13776250183582306
train-epoch-step: 27-203 -- Loss: 0.1767513006925583
train-epoch-step: 27-204 -- Loss: 0.14559045433998108
train-epoch-step: 27-205 -- Loss: 0.18606582283973694
train-epoch-step: 27-206 -- Loss: 0.20283633470535278
train-epoch-step: 27-207 -- Loss: 0.13329799473285675
train-epoch-step: 27-208 -- Loss: 0.18171833455562592
train-epoch-step: 27-209 -- Loss: 0.1440274864435196
train-epoch-step: 27-210 -- Loss: 0.13984650373458862
train-epoch-step: 27-211 -- Loss: 0.2219727635383606
train-epoch-step: 27-212 -- Loss: 0.20333807170391083
train-epoch-step: 27-213 -- Loss: 0.13037028908729553
train-epoch-step: 27-214 -- Loss: 0.15233469009399414
train-epoch-step: 27-215 -- Loss: 0.1323072761297226
train-epoch-step: 27-216 -- Loss: 0.20428752899169922
train-epoch-step: 27-217 -- Loss: 0.2216050624847412
train-epoch-step: 27-218 -- Loss: 0.1497613489627838
train-epoch-step: 27-219 -- Loss: 0.17868414521217346
train-epoch-step: 27-220 -- Loss: 0.13036619126796722
train-epoch-step: 27-221 -- Loss: 0.2098640501499176
train-epoch-step: 27-222 -- Loss: 0.12121941149234772
train-epoch-step: 27-223 -- Loss: 0.17565564811229706
train-epoch-step: 27-224 -- Loss: 0.2014835774898529
train-epoch-step: 27-225 -- Loss: 0.2728995084762573
train-epoch-step: 27-226 -- Loss: 0.20937584340572357
train-epoch-step: 27-227 -- Loss: 0.22200194001197815
train-epoch-step: 27-228 -- Loss: 0.18610036373138428
train-epoch-step: 27-229 -- Loss: 0.18043316900730133
train-epoch-step: 27-230 -- Loss: 0.16686499118804932
train-epoch-step: 27-231 -- Loss: 0.1648467779159546
train-epoch-step: 27-232 -- Loss: 0.18907731771469116
train-epoch-step: 27-233 -- Loss: 0.08543294668197632
train-epoch-step: 27-234 -- Loss: 0.1851978600025177
train-epoch-step: 27-235 -- Loss: 0.15481486916542053
train-epoch-step: 27-236 -- Loss: 0.18062208592891693
train-epoch-step: 27-237 -- Loss: 0.24575941264629364
train-epoch-step: 27-238 -- Loss: 0.16170160472393036
train-epoch-step: 27-239 -- Loss: 0.12838716804981232
train-epoch-step: 27-240 -- Loss: 0.23629143834114075
train-epoch-step: 27-241 -- Loss: 0.15417201817035675
train-epoch-step: 27-242 -- Loss: 0.22737838327884674
train-epoch-step: 27-243 -- Loss: 0.2447032332420349
train-epoch-step: 27-244 -- Loss: 0.21226295828819275
train-epoch-step: 27-245 -- Loss: 0.21625390648841858
train-epoch-step: 27-246 -- Loss: 0.229078471660614
train-epoch-step: 27-247 -- Loss: 0.21310298144817352
train-epoch-step: 27-248 -- Loss: 0.19103601574897766
train-epoch-step: 27-249 -- Loss: 0.14249467849731445
train-epoch-step: 27-250 -- Loss: 0.2062005251646042
train-epoch-step: 27-251 -- Loss: 0.10746125876903534
train-epoch-step: 27-252 -- Loss: 0.20858652889728546
train-epoch-step: 27-253 -- Loss: 0.13582131266593933
train-epoch-step: 27-254 -- Loss: 0.219114288687706
train-epoch-step: 27-255 -- Loss: 0.15416912734508514
train-epoch-step: 27-256 -- Loss: 0.16851909458637238
train-epoch-step: 27-257 -- Loss: 0.19075272977352142
train-epoch-step: 27-258 -- Loss: 0.14991925656795502
train-epoch-step: 27-259 -- Loss: 0.12894973158836365
train-epoch-step: 27-260 -- Loss: 0.20925447344779968
train-epoch-step: 27-261 -- Loss: 0.17252270877361298
train-epoch-step: 27-262 -- Loss: 0.3285512626171112
train-epoch-step: 27-263 -- Loss: 0.2026742398738861
train-epoch-step: 27-264 -- Loss: 0.17590920627117157
train-epoch-step: 27-265 -- Loss: 0.12308318167924881
train-epoch-step: 27-266 -- Loss: 0.15576398372650146
train-epoch-step: 27-267 -- Loss: 0.14449679851531982
train-epoch-step: 27-268 -- Loss: 0.14760832488536835
train-epoch-step: 27-269 -- Loss: 0.17330661416053772
train-epoch-step: 27-270 -- Loss: 0.11153241246938705
train-epoch-step: 27-271 -- Loss: 0.15692022442817688
train-epoch-step: 27-272 -- Loss: 0.11935430765151978
train-epoch-step: 27-273 -- Loss: 0.12794338166713715
train-epoch-step: 27-274 -- Loss: 0.1924765259027481
train-epoch-step: 27-275 -- Loss: 0.21799823641777039
train-epoch-step: 27-276 -- Loss: 0.18155384063720703
train-epoch-step: 27-277 -- Loss: 0.16386815905570984
train-epoch-step: 27-278 -- Loss: 0.1477482169866562
train-epoch-step: 27-279 -- Loss: 0.14804697036743164
train-epoch-step: 27-280 -- Loss: 0.2284841239452362
train-epoch-step: 27-281 -- Loss: 0.19008785486221313
train-epoch-step: 27-282 -- Loss: 0.14579465985298157
train-epoch-step: 27-283 -- Loss: 0.12053079158067703
train-epoch-step: 27-284 -- Loss: 0.14236298203468323
train-epoch-step: 27-285 -- Loss: 0.19532302021980286
train-epoch-step: 27-286 -- Loss: 0.1581740826368332
train-epoch-step: 27-287 -- Loss: 0.20971977710723877
train-epoch-step: 27-288 -- Loss: 0.09769946336746216
train-epoch-step: 27-289 -- Loss: 0.12444333732128143
train-epoch-step: 27-290 -- Loss: 0.19711819291114807
train-epoch-step: 27-291 -- Loss: 0.12210018187761307
train-epoch-step: 27-292 -- Loss: 0.16595861315727234
train-epoch-step: 27-293 -- Loss: 0.14400313794612885
train-epoch-step: 27-294 -- Loss: 0.16765478253364563
train-epoch-step: 27-295 -- Loss: 0.2833634316921234
train-epoch-step: 27-296 -- Loss: 0.1672278195619583
train-epoch-step: 27-297 -- Loss: 0.18338148295879364
train-epoch-step: 27-298 -- Loss: 0.2454136312007904
train-epoch-step: 27-299 -- Loss: 0.15229900181293488
train-epoch-step: 27-300 -- Loss: 0.1728854775428772
train-epoch-step: 27-301 -- Loss: 0.16996833682060242
train-epoch-step: 27-302 -- Loss: 0.22057493031024933
train-epoch-step: 27-303 -- Loss: 0.21563014388084412
train-epoch-step: 27-304 -- Loss: 0.12909436225891113
train-epoch-step: 27-305 -- Loss: 0.1558069884777069
train-epoch-step: 27-306 -- Loss: 0.2410709410905838
train-epoch-step: 27-307 -- Loss: 0.17096497118473053
train-epoch-step: 27-308 -- Loss: 0.2279607057571411
train-epoch-step: 27-309 -- Loss: 0.15730038285255432
train-epoch-step: 27-310 -- Loss: 0.16682428121566772
train-epoch-step: 27-311 -- Loss: 0.1662026196718216
train-epoch-step: 27-312 -- Loss: 0.2109082043170929
train-epoch-step: 27-313 -- Loss: 0.1021701917052269
train-epoch-step: 27-314 -- Loss: 0.20129847526550293
train-epoch-step: 27-315 -- Loss: 0.17124713957309723
train-epoch-step: 27-316 -- Loss: 0.1560058295726776
train-epoch-step: 27-317 -- Loss: 0.14349696040153503
train-epoch-step: 27-318 -- Loss: 0.16636954247951508
train-epoch-step: 27-319 -- Loss: 0.17105332016944885
train-epoch-step: 27-320 -- Loss: 0.12510089576244354
train-epoch-step: 27-321 -- Loss: 0.1512245386838913
train-epoch-step: 27-322 -- Loss: 0.21527493000030518
train-epoch-step: 27-323 -- Loss: 0.1625422090291977
train-epoch-step: 27-324 -- Loss: 0.25951075553894043
train-epoch-step: 27-325 -- Loss: 0.15418407320976257
train-epoch-step: 27-326 -- Loss: 0.17002266645431519
train-epoch-step: 27-327 -- Loss: 0.22453108429908752
train-epoch-step: 27-328 -- Loss: 0.19802498817443848
train-epoch-step: 27-329 -- Loss: 0.33558496832847595
train-epoch-step: 27-330 -- Loss: 0.3659115135669708
train-epoch-step: 27-331 -- Loss: 0.21836775541305542
train-epoch-step: 27-332 -- Loss: 0.10218758136034012
train-epoch-step: 27-333 -- Loss: 0.19142498075962067
train-epoch-step: 27-334 -- Loss: 0.1578577756881714
train-epoch-step: 27-335 -- Loss: 0.17806817591190338
train-epoch-step: 27-336 -- Loss: 0.15487098693847656
train-epoch-step: 27-337 -- Loss: 0.21957296133041382
train-epoch-step: 27-338 -- Loss: 0.16259580850601196
train-epoch-step: 27-339 -- Loss: 0.1497514545917511
train-epoch-step: 27-340 -- Loss: 0.20357546210289001
train-epoch-step: 27-341 -- Loss: 0.14221777021884918
train-epoch-step: 27-342 -- Loss: 0.1701400727033615
train-epoch-step: 27-343 -- Loss: 0.15887397527694702
train-epoch-step: 27-344 -- Loss: 0.17711177468299866
train-epoch-step: 27-345 -- Loss: 0.14850860834121704
train-epoch-step: 27-346 -- Loss: 0.21337714791297913
train-epoch-step: 27-347 -- Loss: 0.15608544647693634
train-epoch-step: 27-348 -- Loss: 0.21658551692962646
train-epoch-step: 27-349 -- Loss: 0.2131069302558899
train-epoch-step: 27-350 -- Loss: 0.2655877470970154
train-epoch-step: 27-351 -- Loss: 0.19557355344295502
train-epoch-step: 27-352 -- Loss: 0.12859724462032318
train-epoch-step: 27-353 -- Loss: 0.1986636221408844
train-epoch-step: 27-354 -- Loss: 0.2929377555847168
train-epoch-step: 27-355 -- Loss: 0.12725509703159332
train-epoch-step: 27-356 -- Loss: 0.12220634520053864
train-epoch-step: 27-357 -- Loss: 0.19438636302947998
train-epoch-step: 27-358 -- Loss: 0.18723034858703613
train-epoch-step: 27-359 -- Loss: 0.15498974919319153
train-epoch-step: 27-360 -- Loss: 0.1226426437497139
train-epoch-step: 27-361 -- Loss: 0.2472703754901886
train-epoch-step: 27-362 -- Loss: 0.17601855099201202
train-epoch-step: 27-363 -- Loss: 0.11180821806192398
train-epoch-step: 27-364 -- Loss: 0.18472273647785187
train-epoch-step: 27-365 -- Loss: 0.1794510781764984
train-epoch-step: 27-366 -- Loss: 0.20903560519218445
train-epoch-step: 27-367 -- Loss: 0.23926371335983276
train-epoch-step: 27-368 -- Loss: 0.21874260902404785
train-epoch-step: 27-369 -- Loss: 0.2802531123161316
train-epoch-step: 27-370 -- Loss: 0.12928685545921326
train-epoch-step: 27-371 -- Loss: 0.12370309233665466
train-epoch-step: 27-372 -- Loss: 0.1524946540594101
train-epoch-step: 27-373 -- Loss: 0.19962871074676514
train-epoch-step: 27-374 -- Loss: 0.16000406444072723
train-epoch-step: 27-375 -- Loss: 0.27747824788093567
train-epoch-step: 27-376 -- Loss: 0.16583499312400818
train-epoch-step: 27-377 -- Loss: 0.24062123894691467
train-epoch-step: 27-378 -- Loss: 0.20485904812812805
train-epoch-step: 27-379 -- Loss: 0.1240893304347992
train-epoch-step: 27-380 -- Loss: 0.09554600715637207
train-epoch-step: 27-381 -- Loss: 0.2485194206237793
train-epoch-step: 27-382 -- Loss: 0.2406654953956604
train-epoch-step: 27-383 -- Loss: 0.19058595597743988
train-epoch-step: 27-384 -- Loss: 0.23631757497787476
train-epoch-step: 27-385 -- Loss: 0.20884093642234802
train-epoch-step: 27-386 -- Loss: 0.18619388341903687
train-epoch-step: 27-387 -- Loss: 0.20472213625907898
train-epoch-step: 27-388 -- Loss: 0.2122868299484253
train-epoch-step: 27-389 -- Loss: 0.16864819824695587
train-epoch-step: 27-390 -- Loss: 0.14651848375797272
train-epoch-step: 27-391 -- Loss: 0.14652368426322937
train-epoch-step: 27-392 -- Loss: 0.1866922378540039
train-epoch-step: 27-393 -- Loss: 0.16102895140647888
train-epoch-step: 27-394 -- Loss: 0.2091628462076187
train-epoch-step: 27-395 -- Loss: 0.1633812040090561
train-epoch-step: 27-396 -- Loss: 0.12651030719280243
train-epoch-step: 27-397 -- Loss: 0.1281336545944214
train-epoch-step: 27-398 -- Loss: 0.20726808905601501
train-epoch-step: 27-399 -- Loss: 0.185031458735466
train-epoch-step: 27-400 -- Loss: 0.29029881954193115
train-epoch-step: 27-401 -- Loss: 0.11972665041685104
train-epoch-step: 27-402 -- Loss: 0.2567685842514038
train-epoch-step: 27-403 -- Loss: 0.16192160546779633
train-epoch-step: 27-404 -- Loss: 0.1406584531068802
train-epoch-step: 27-405 -- Loss: 0.15478147566318512
train-epoch-step: 27-406 -- Loss: 0.1735658049583435
train-epoch-step: 27-407 -- Loss: 0.11554545909166336
train-epoch-step: 27-408 -- Loss: 0.16158483922481537
train-epoch-step: 27-409 -- Loss: 0.17389944195747375
train-epoch-step: 27-410 -- Loss: 0.17611613869667053
train-epoch-step: 27-411 -- Loss: 0.21329237520694733
train-epoch-step: 27-412 -- Loss: 0.13101863861083984
train-epoch-step: 27-413 -- Loss: 0.14893251657485962
train-epoch-step: 27-414 -- Loss: 0.13707458972930908
train-epoch-step: 27-415 -- Loss: 0.136382594704628
train-epoch-step: 27-416 -- Loss: 0.2643899619579315
train-epoch-step: 27-417 -- Loss: 0.19718441367149353
train-epoch-step: 27-418 -- Loss: 0.23502877354621887
train-epoch-step: 27-419 -- Loss: 0.17190532386302948
train-epoch-step: 27-420 -- Loss: 0.1581120491027832
train-epoch-step: 27-421 -- Loss: 0.18256525695323944
train-epoch-step: 27-422 -- Loss: 0.15016134083271027
train-epoch-step: 27-423 -- Loss: 0.18492794036865234
train-epoch-step: 27-424 -- Loss: 0.14325721561908722
train-epoch-step: 27-425 -- Loss: 0.18283326923847198
train-epoch-step: 27-426 -- Loss: 0.16550806164741516
train-epoch-step: 27-427 -- Loss: 0.12594197690486908
train-epoch-step: 27-428 -- Loss: 0.20082217454910278
train-epoch-step: 27-429 -- Loss: 0.17858904600143433
train-epoch-step: 27-430 -- Loss: 0.1395900845527649
train-epoch-step: 27-431 -- Loss: 0.169390007853508
train-epoch-step: 27-432 -- Loss: 0.24588188529014587
train-epoch-step: 27-433 -- Loss: 0.13974519073963165
train-epoch-step: 27-434 -- Loss: 0.13161788880825043
train-epoch-step: 27-435 -- Loss: 0.16297531127929688
train-epoch-step: 27-436 -- Loss: 0.159885972738266
train-epoch-step: 27-437 -- Loss: 0.1331120878458023
train-epoch-step: 27-438 -- Loss: 0.17075517773628235
train-epoch-step: 27-439 -- Loss: 0.27273422479629517
train-epoch-step: 27-440 -- Loss: 0.13673201203346252
train-epoch-step: 27-441 -- Loss: 0.2137109637260437
train-epoch-step: 27-442 -- Loss: 0.17898085713386536
train-epoch-step: 27-443 -- Loss: 0.16163863241672516
train-epoch-step: 27-444 -- Loss: 0.19543112814426422
train-epoch-step: 27-445 -- Loss: 0.1791365146636963
train-epoch-step: 27-446 -- Loss: 0.16382700204849243
train-epoch-step: 27-447 -- Loss: 0.19657109677791595
train-epoch-step: 27-448 -- Loss: 0.22850091755390167
train-epoch-step: 27-449 -- Loss: 0.2049943208694458
train-epoch-step: 27-450 -- Loss: 0.18875816464424133
train-epoch-step: 27-451 -- Loss: 0.1470629721879959
train-epoch-step: 27-452 -- Loss: 0.13459187746047974
train-epoch-step: 27-453 -- Loss: 0.09631377458572388
train-epoch-step: 27-454 -- Loss: 0.23842932283878326
train-epoch-step: 27-455 -- Loss: 0.12976060807704926
train-epoch-step: 27-456 -- Loss: 0.12073881924152374
train-epoch-step: 27-457 -- Loss: 0.22129634022712708
train-epoch-step: 27-458 -- Loss: 0.17308707535266876
train-epoch-step: 27-459 -- Loss: 0.22902631759643555
train-epoch-step: 27-460 -- Loss: 0.1268533170223236
train-epoch-step: 27-461 -- Loss: 0.13970932364463806
train-epoch-step: 27-462 -- Loss: 0.16741988062858582
train-epoch-step: 27-463 -- Loss: 0.1450430154800415
train-epoch-step: 27-464 -- Loss: 0.16582168638706207
train-epoch-step: 27-465 -- Loss: 0.2510281801223755
train-epoch-step: 27-466 -- Loss: 0.21102945506572723
train-epoch-step: 27-467 -- Loss: 0.11965577304363251
train-epoch-step: 27-468 -- Loss: 0.17302747070789337
train-epoch-step: 27-469 -- Loss: 0.22514213621616364
train-epoch-step: 27-470 -- Loss: 0.18109063804149628
train-epoch-step: 27-471 -- Loss: 0.16670897603034973
train-epoch-step: 27-472 -- Loss: 0.16086922585964203
train-epoch-step: 27-473 -- Loss: 0.1557110697031021
train-epoch-step: 27-474 -- Loss: 0.1308145821094513
train-epoch-step: 27-475 -- Loss: 0.11818856745958328
train-epoch-step: 27-476 -- Loss: 0.209660604596138
train-epoch-step: 27-477 -- Loss: 0.20973940193653107
train-epoch-step: 27-478 -- Loss: 0.2066330909729004
train-epoch-step: 27-479 -- Loss: 0.15112188458442688
train-epoch-step: 27-480 -- Loss: 0.1973930448293686
train-epoch-step: 27-481 -- Loss: 0.2917223572731018
train-epoch-step: 27-482 -- Loss: 0.25563064217567444
train-epoch-step: 27-483 -- Loss: 0.19129687547683716
train-epoch-step: 27-484 -- Loss: 0.21271786093711853
train-epoch-step: 27-485 -- Loss: 0.13185212016105652
train-epoch-step: 27-486 -- Loss: 0.24139896035194397
train-epoch-step: 27-487 -- Loss: 0.24272000789642334
train-epoch-step: 27-488 -- Loss: 0.21091242134571075
train-epoch-step: 27-489 -- Loss: 0.2226869910955429
train-epoch-step: 27-490 -- Loss: 0.14341513812541962
train-epoch-step: 27-491 -- Loss: 0.138846293091774
train-epoch-step: 27-492 -- Loss: 0.1290144920349121
train-epoch-step: 27-493 -- Loss: 0.21084891259670258
train-epoch-step: 27-494 -- Loss: 0.2067108452320099
train-epoch-step: 27-495 -- Loss: 0.20708395540714264
train-epoch-step: 27-496 -- Loss: 0.14321060478687286
train-epoch-step: 27-497 -- Loss: 0.1917479932308197
train-epoch-step: 27-498 -- Loss: 0.15547630190849304
train-epoch-step: 27-499 -- Loss: 0.1789095401763916
train-epoch-step: 27-500 -- Loss: 0.15803395211696625
train-epoch-step: 27-501 -- Loss: 0.22054971754550934
train-epoch-step: 27-502 -- Loss: 0.15500551462173462
train-epoch-step: 27-503 -- Loss: 0.22036439180374146
train-epoch-step: 27-504 -- Loss: 0.12179344892501831
train-epoch-step: 27-505 -- Loss: 0.178408682346344
train-epoch-step: 27-506 -- Loss: 0.1185968890786171
train-epoch-step: 27-507 -- Loss: 0.18838325142860413
train-epoch-step: 27-508 -- Loss: 0.17430347204208374
train-epoch-step: 27-509 -- Loss: 0.17367269098758698
train-epoch-step: 27-510 -- Loss: 0.12985385954380035
train-epoch-step: 27-511 -- Loss: 0.23054881393909454
train-epoch-step: 27-512 -- Loss: 0.1812610626220703
train-epoch-step: 27-513 -- Loss: 0.19013634324073792
train-epoch-step: 27-514 -- Loss: 0.14850494265556335
train-epoch-step: 27-515 -- Loss: 0.16115443408489227
train-epoch-step: 27-516 -- Loss: 0.17547526955604553
train-epoch-step: 27-517 -- Loss: 0.17627611756324768
train-epoch-step: 27-518 -- Loss: 0.14226332306861877
train-epoch-step: 27-519 -- Loss: 0.13969296216964722
train-epoch-step: 27-520 -- Loss: 0.18884000182151794
train-epoch-step: 27-521 -- Loss: 0.22919359803199768
train-epoch-step: 27-522 -- Loss: 0.18048608303070068
train-epoch-step: 27-523 -- Loss: 0.1593461036682129
train-epoch-step: 27-524 -- Loss: 0.1707145720720291
train-epoch-step: 27-525 -- Loss: 0.19189633429050446
train-epoch-step: 27-526 -- Loss: 0.13126961886882782
train-epoch-step: 27-527 -- Loss: 0.15750202536582947
train-epoch-step: 27-528 -- Loss: 0.15884166955947876
train-epoch-step: 27-529 -- Loss: 0.16771110892295837
train-epoch-step: 27-530 -- Loss: 0.17408807575702667
train-epoch-step: 27-531 -- Loss: 0.20346085727214813
train-epoch-step: 27-532 -- Loss: 0.1792210340499878
train-epoch-step: 27-533 -- Loss: 0.17109300196170807
train-epoch-step: 27-534 -- Loss: 0.13286878168582916
train-epoch-step: 27-535 -- Loss: 0.2529970705509186
train-epoch-step: 27-536 -- Loss: 0.15815554559230804
train-epoch-step: 27-537 -- Loss: 0.15240879356861115
train-epoch-step: 27-538 -- Loss: 0.10369640588760376
train-epoch-step: 27-539 -- Loss: 0.18351630866527557
train-epoch-step: 27-540 -- Loss: 0.13580501079559326
train-epoch-step: 27-541 -- Loss: 0.21664582192897797
train-epoch-step: 27-542 -- Loss: 0.22385546565055847
train-epoch-step: 27-543 -- Loss: 0.17226243019104004
train-epoch-step: 27-544 -- Loss: 0.23148426413536072
train-epoch-step: 27-545 -- Loss: 0.19267579913139343
train-epoch-step: 27-546 -- Loss: 0.2067219316959381
train-epoch-step: 27-547 -- Loss: 0.17780271172523499
train-epoch-step: 27-548 -- Loss: 0.09660286456346512
train-epoch-step: 27-549 -- Loss: 0.1618914008140564
train-epoch-step: 27-550 -- Loss: 0.19865649938583374
train-epoch-step: 27-551 -- Loss: 0.15471166372299194
train-epoch-step: 27-552 -- Loss: 0.13720634579658508
train-epoch-step: 27-553 -- Loss: 0.19241975247859955
train-epoch-step: 27-554 -- Loss: 0.19346226751804352
train-epoch-step: 27-555 -- Loss: 0.22132810950279236
train-epoch-step: 27-556 -- Loss: 0.14774693548679352
train-epoch-step: 27-557 -- Loss: 0.2416556179523468
train-epoch-step: 27-558 -- Loss: 0.23165848851203918
train-epoch-step: 27-559 -- Loss: 0.1444227546453476
train-epoch-step: 27-560 -- Loss: 0.20633111894130707
train-epoch-step: 27-561 -- Loss: 0.19333535432815552
train-epoch-step: 27-562 -- Loss: 0.16730302572250366
train-epoch-step: 27-563 -- Loss: 0.18766435980796814
train-epoch-step: 27-564 -- Loss: 0.10098211467266083
train-epoch-step: 27-565 -- Loss: 0.18763667345046997
train-epoch-step: 27-566 -- Loss: 0.15228816866874695
train-epoch-step: 27-567 -- Loss: 0.21793705224990845
train-epoch-step: 27-568 -- Loss: 0.1644919514656067
train-epoch-step: 27-569 -- Loss: 0.23746685683727264
train-epoch-step: 27-570 -- Loss: 0.1741553694009781
train-epoch-step: 27-571 -- Loss: 0.2166982740163803
train-epoch-step: 27-572 -- Loss: 0.2533600926399231
train-epoch-step: 27-573 -- Loss: 0.2055254876613617
train-epoch-step: 27-574 -- Loss: 0.259671688079834
train-epoch-step: 27-575 -- Loss: 0.31341904401779175
train-epoch-step: 27-576 -- Loss: 0.12128669023513794
train-epoch-step: 27-577 -- Loss: 0.16608022153377533
train-epoch-step: 27-578 -- Loss: 0.22083276510238647
train-epoch-step: 27-579 -- Loss: 0.16793881356716156
train-epoch-step: 27-580 -- Loss: 0.1803549826145172
train-epoch-step: 27-581 -- Loss: 0.13891558349132538
train-epoch-step: 27-582 -- Loss: 0.20829850435256958
train-epoch-step: 27-583 -- Loss: 0.22188937664031982
train-epoch-step: 27-584 -- Loss: 0.1691201627254486
train-epoch-step: 27-585 -- Loss: 0.1981588751077652
train-epoch-step: 27-586 -- Loss: 0.26511454582214355
train-epoch-step: 27-587 -- Loss: 0.16678452491760254
train-epoch-step: 27-588 -- Loss: 0.12966609001159668
val-epoch-step: 27-589 -- Loss: 0.22110658884048462
val-epoch-step: 27-590 -- Loss: 0.1539364904165268
val-epoch-step: 27-591 -- Loss: 0.23057232797145844
val-epoch-step: 27-592 -- Loss: 0.1784844547510147
val-epoch-step: 27-593 -- Loss: 0.1717107892036438
val-epoch-step: 27-594 -- Loss: 0.382087767124176
val-epoch-step: 27-595 -- Loss: 0.18258196115493774
val-epoch-step: 27-596 -- Loss: 0.2062743902206421
val-epoch-step: 27-597 -- Loss: 0.17512887716293335
val-epoch-step: 27-598 -- Loss: 0.15342901647090912
val-epoch-step: 27-599 -- Loss: 0.184670090675354
val-epoch-step: 27-600 -- Loss: 0.19870823621749878
val-epoch-step: 27-601 -- Loss: 0.1557563990354538
val-epoch-step: 27-602 -- Loss: 0.14174240827560425
val-epoch-step: 27-603 -- Loss: 0.19216015934944153
val-epoch-step: 27-604 -- Loss: 0.1484672576189041
val-epoch-step: 27-605 -- Loss: 0.14916175603866577
val-epoch-step: 27-606 -- Loss: 0.271897554397583
val-epoch-step: 27-607 -- Loss: 0.12916065752506256
val-epoch-step: 27-608 -- Loss: 0.25192928314208984
val-epoch-step: 27-609 -- Loss: 0.16650798916816711
val-epoch-step: 27-610 -- Loss: 0.1818273514509201
val-epoch-step: 27-611 -- Loss: 0.15374687314033508
val-epoch-step: 27-612 -- Loss: 0.42905324697494507
val-epoch-step: 27-613 -- Loss: 0.17403359711170197
val-epoch-step: 27-614 -- Loss: 0.17067231237888336
val-epoch-step: 27-615 -- Loss: 0.1799304038286209
val-epoch-step: 27-616 -- Loss: 0.15072450041770935
val-epoch-step: 27-617 -- Loss: 0.19172754883766174
val-epoch-step: 27-618 -- Loss: 0.1822359561920166
val-epoch-step: 27-619 -- Loss: 0.22812002897262573
val-epoch-step: 27-620 -- Loss: 0.13993847370147705
val-epoch-step: 27-621 -- Loss: 0.1281246840953827
val-epoch-step: 27-622 -- Loss: 0.1473112851381302
val-epoch-step: 27-623 -- Loss: 0.15484420955181122
val-epoch-step: 27-624 -- Loss: 0.14191076159477234
val-epoch-step: 27-625 -- Loss: 0.1603865921497345
val-epoch-step: 27-626 -- Loss: 0.14776714146137238
val-epoch-step: 27-627 -- Loss: 0.193330317735672
val-epoch-step: 27-628 -- Loss: 0.5489611029624939
val-epoch-step: 27-629 -- Loss: 0.2069464921951294
val-epoch-step: 27-630 -- Loss: 0.3534754514694214
val-epoch-step: 27-631 -- Loss: 0.1416010558605194
val-epoch-step: 27-632 -- Loss: 0.2127116322517395
val-epoch-step: 27-633 -- Loss: 0.15424223244190216
val-epoch-step: 27-634 -- Loss: 0.1398465484380722
val-epoch-step: 27-635 -- Loss: 0.12011821568012238
val-epoch-step: 27-636 -- Loss: 0.17327097058296204
val-epoch-step: 27-637 -- Loss: 0.18947874009609222
val-epoch-step: 27-638 -- Loss: 0.1568903774023056
val-epoch-step: 27-639 -- Loss: 0.25792884826660156
val-epoch-step: 27-640 -- Loss: 0.251219242811203
val-epoch-step: 27-641 -- Loss: 0.13125106692314148
val-epoch-step: 27-642 -- Loss: 0.18060238659381866
val-epoch-step: 27-643 -- Loss: 0.20789273083209991
val-epoch-step: 27-644 -- Loss: 0.1665576845407486
val-epoch-step: 27-645 -- Loss: 0.2222084403038025
val-epoch-step: 27-646 -- Loss: 0.1364453285932541
val-epoch-step: 27-647 -- Loss: 0.13846540451049805
val-epoch-step: 27-648 -- Loss: 0.16245916485786438
val-epoch-step: 27-649 -- Loss: 0.21215833723545074
val-epoch-step: 27-650 -- Loss: 0.2568705677986145
val-epoch-step: 27-651 -- Loss: 0.14443649351596832
val-epoch-step: 27-652 -- Loss: 0.154611736536026
val-epoch-step: 27-653 -- Loss: 0.2068447470664978
val-epoch-step: 27-654 -- Loss: 0.11679206043481827
Epoch: 27 -- Train Loss: tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1440, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 28-0 -- Loss: 0.22612084448337555
train-epoch-step: 28-1 -- Loss: 0.14823009073734283
train-epoch-step: 28-2 -- Loss: 0.20514950156211853
train-epoch-step: 28-3 -- Loss: 0.14424444735050201
train-epoch-step: 28-4 -- Loss: 0.15917716920375824
train-epoch-step: 28-5 -- Loss: 0.18381354212760925
train-epoch-step: 28-6 -- Loss: 0.22082974016666412
train-epoch-step: 28-7 -- Loss: 0.1698620468378067
train-epoch-step: 28-8 -- Loss: 0.18703502416610718
train-epoch-step: 28-9 -- Loss: 0.2487407922744751
train-epoch-step: 28-10 -- Loss: 0.20532819628715515
train-epoch-step: 28-11 -- Loss: 0.18400898575782776
train-epoch-step: 28-12 -- Loss: 0.1522943675518036
train-epoch-step: 28-13 -- Loss: 0.18524053692817688
train-epoch-step: 28-14 -- Loss: 0.16422131657600403
train-epoch-step: 28-15 -- Loss: 0.1674128919839859
train-epoch-step: 28-16 -- Loss: 0.16450999677181244
train-epoch-step: 28-17 -- Loss: 0.22729238867759705
train-epoch-step: 28-18 -- Loss: 0.19831626117229462
train-epoch-step: 28-19 -- Loss: 0.13480748236179352
train-epoch-step: 28-20 -- Loss: 0.22722814977169037
train-epoch-step: 28-21 -- Loss: 0.24855241179466248
train-epoch-step: 28-22 -- Loss: 0.14520666003227234
train-epoch-step: 28-23 -- Loss: 0.1529480218887329
train-epoch-step: 28-24 -- Loss: 0.12826378643512726
train-epoch-step: 28-25 -- Loss: 0.22597160935401917
train-epoch-step: 28-26 -- Loss: 0.19805501401424408
train-epoch-step: 28-27 -- Loss: 0.23877307772636414
train-epoch-step: 28-28 -- Loss: 0.13015112280845642
train-epoch-step: 28-29 -- Loss: 0.24321699142456055
train-epoch-step: 28-30 -- Loss: 0.10947263985872269
train-epoch-step: 28-31 -- Loss: 0.13827462494373322
train-epoch-step: 28-32 -- Loss: 0.17359602451324463
train-epoch-step: 28-33 -- Loss: 0.28210288286209106
train-epoch-step: 28-34 -- Loss: 0.1763792335987091
train-epoch-step: 28-35 -- Loss: 0.2577364444732666
train-epoch-step: 28-36 -- Loss: 0.13932687044143677
train-epoch-step: 28-37 -- Loss: 0.1401476114988327
train-epoch-step: 28-38 -- Loss: 0.1815979927778244
train-epoch-step: 28-39 -- Loss: 0.23087188601493835
train-epoch-step: 28-40 -- Loss: 0.21520453691482544
train-epoch-step: 28-41 -- Loss: 0.21979735791683197
train-epoch-step: 28-42 -- Loss: 0.14714841544628143
train-epoch-step: 28-43 -- Loss: 0.26785433292388916
train-epoch-step: 28-44 -- Loss: 0.12673449516296387
train-epoch-step: 28-45 -- Loss: 0.12739905714988708
train-epoch-step: 28-46 -- Loss: 0.17281989753246307
train-epoch-step: 28-47 -- Loss: 0.21964199841022491
train-epoch-step: 28-48 -- Loss: 0.16277697682380676
train-epoch-step: 28-49 -- Loss: 0.23854434490203857
train-epoch-step: 28-50 -- Loss: 0.11891621351242065
train-epoch-step: 28-51 -- Loss: 0.1983407437801361
train-epoch-step: 28-52 -- Loss: 0.15801508724689484
train-epoch-step: 28-53 -- Loss: 0.21023514866828918
train-epoch-step: 28-54 -- Loss: 0.29623714089393616
train-epoch-step: 28-55 -- Loss: 0.16901420056819916
train-epoch-step: 28-56 -- Loss: 0.17891979217529297
train-epoch-step: 28-57 -- Loss: 0.2405799925327301
train-epoch-step: 28-58 -- Loss: 0.2882094979286194
train-epoch-step: 28-59 -- Loss: 0.24290473759174347
train-epoch-step: 28-60 -- Loss: 0.13494013249874115
train-epoch-step: 28-61 -- Loss: 0.2032501995563507
train-epoch-step: 28-62 -- Loss: 0.19626104831695557
train-epoch-step: 28-63 -- Loss: 0.15191927552223206
train-epoch-step: 28-64 -- Loss: 0.14909003674983978
train-epoch-step: 28-65 -- Loss: 0.18243519961833954
train-epoch-step: 28-66 -- Loss: 0.1090288981795311
train-epoch-step: 28-67 -- Loss: 0.12660430371761322
train-epoch-step: 28-68 -- Loss: 0.214671790599823
train-epoch-step: 28-69 -- Loss: 0.1285681128501892
train-epoch-step: 28-70 -- Loss: 0.23308289051055908
train-epoch-step: 28-71 -- Loss: 0.2535299062728882
train-epoch-step: 28-72 -- Loss: 0.17550460994243622
train-epoch-step: 28-73 -- Loss: 0.21149516105651855
train-epoch-step: 28-74 -- Loss: 0.09919745475053787
train-epoch-step: 28-75 -- Loss: 0.12896202504634857
train-epoch-step: 28-76 -- Loss: 0.15143626928329468
train-epoch-step: 28-77 -- Loss: 0.23149418830871582
train-epoch-step: 28-78 -- Loss: 0.2636019289493561
train-epoch-step: 28-79 -- Loss: 0.19592061638832092
train-epoch-step: 28-80 -- Loss: 0.27377909421920776
train-epoch-step: 28-81 -- Loss: 0.12541894614696503
train-epoch-step: 28-82 -- Loss: 0.2531525194644928
train-epoch-step: 28-83 -- Loss: 0.17540988326072693
train-epoch-step: 28-84 -- Loss: 0.19560493528842926
train-epoch-step: 28-85 -- Loss: 0.1790032833814621
train-epoch-step: 28-86 -- Loss: 0.13094711303710938
train-epoch-step: 28-87 -- Loss: 0.23333066701889038
train-epoch-step: 28-88 -- Loss: 0.14615213871002197
train-epoch-step: 28-89 -- Loss: 0.19271253049373627
train-epoch-step: 28-90 -- Loss: 0.19560638070106506
train-epoch-step: 28-91 -- Loss: 0.2452440708875656
train-epoch-step: 28-92 -- Loss: 0.15884926915168762
train-epoch-step: 28-93 -- Loss: 0.17915374040603638
train-epoch-step: 28-94 -- Loss: 0.2203957736492157
train-epoch-step: 28-95 -- Loss: 0.1926804482936859
train-epoch-step: 28-96 -- Loss: 0.2160303294658661
train-epoch-step: 28-97 -- Loss: 0.18408870697021484
train-epoch-step: 28-98 -- Loss: 0.15630050003528595
train-epoch-step: 28-99 -- Loss: 0.192428320646286
train-epoch-step: 28-100 -- Loss: 0.1943012923002243
train-epoch-step: 28-101 -- Loss: 0.2797631025314331
train-epoch-step: 28-102 -- Loss: 0.22528329491615295
train-epoch-step: 28-103 -- Loss: 0.18579523265361786
train-epoch-step: 28-104 -- Loss: 0.1540476381778717
train-epoch-step: 28-105 -- Loss: 0.27970391511917114
train-epoch-step: 28-106 -- Loss: 0.1795349270105362
train-epoch-step: 28-107 -- Loss: 0.18502745032310486
train-epoch-step: 28-108 -- Loss: 0.19074887037277222
train-epoch-step: 28-109 -- Loss: 0.14556673169136047
train-epoch-step: 28-110 -- Loss: 0.18113793432712555
train-epoch-step: 28-111 -- Loss: 0.1813252568244934
train-epoch-step: 28-112 -- Loss: 0.17756211757659912
train-epoch-step: 28-113 -- Loss: 0.16488982737064362
train-epoch-step: 28-114 -- Loss: 0.2046968638896942
train-epoch-step: 28-115 -- Loss: 0.16443605720996857
train-epoch-step: 28-116 -- Loss: 0.1389939785003662
train-epoch-step: 28-117 -- Loss: 0.1335311233997345
train-epoch-step: 28-118 -- Loss: 0.19775842130184174
train-epoch-step: 28-119 -- Loss: 0.15401409566402435
train-epoch-step: 28-120 -- Loss: 0.25926926732063293
train-epoch-step: 28-121 -- Loss: 0.25049424171447754
train-epoch-step: 28-122 -- Loss: 0.22329431772232056
train-epoch-step: 28-123 -- Loss: 0.20316679775714874
train-epoch-step: 28-124 -- Loss: 0.12688575685024261
train-epoch-step: 28-125 -- Loss: 0.16164246201515198
train-epoch-step: 28-126 -- Loss: 0.23775732517242432
train-epoch-step: 28-127 -- Loss: 0.19237226247787476
train-epoch-step: 28-128 -- Loss: 0.1760292500257492
train-epoch-step: 28-129 -- Loss: 0.1524021327495575
train-epoch-step: 28-130 -- Loss: 0.20545142889022827
train-epoch-step: 28-131 -- Loss: 0.13803789019584656
train-epoch-step: 28-132 -- Loss: 0.19688063859939575
train-epoch-step: 28-133 -- Loss: 0.11744650453329086
train-epoch-step: 28-134 -- Loss: 0.20151042938232422
train-epoch-step: 28-135 -- Loss: 0.138642817735672
train-epoch-step: 28-136 -- Loss: 0.13106970489025116
train-epoch-step: 28-137 -- Loss: 0.2466726005077362
train-epoch-step: 28-138 -- Loss: 0.2657245993614197
train-epoch-step: 28-139 -- Loss: 0.13528196513652802
train-epoch-step: 28-140 -- Loss: 0.2121485322713852
train-epoch-step: 28-141 -- Loss: 0.23255297541618347
train-epoch-step: 28-142 -- Loss: 0.2063121497631073
train-epoch-step: 28-143 -- Loss: 0.17823323607444763
train-epoch-step: 28-144 -- Loss: 0.19393596053123474
train-epoch-step: 28-145 -- Loss: 0.14189518988132477
train-epoch-step: 28-146 -- Loss: 0.18577110767364502
train-epoch-step: 28-147 -- Loss: 0.17554263770580292
train-epoch-step: 28-148 -- Loss: 0.15955257415771484
train-epoch-step: 28-149 -- Loss: 0.11900313198566437
train-epoch-step: 28-150 -- Loss: 0.18823106586933136
train-epoch-step: 28-151 -- Loss: 0.19465652108192444
train-epoch-step: 28-152 -- Loss: 0.18925009667873383
train-epoch-step: 28-153 -- Loss: 0.2751469016075134
train-epoch-step: 28-154 -- Loss: 0.131275475025177
train-epoch-step: 28-155 -- Loss: 0.1378895342350006
train-epoch-step: 28-156 -- Loss: 0.12198810279369354
train-epoch-step: 28-157 -- Loss: 0.1672070473432541
train-epoch-step: 28-158 -- Loss: 0.16682325303554535
train-epoch-step: 28-159 -- Loss: 0.17839567363262177
train-epoch-step: 28-160 -- Loss: 0.22342348098754883
train-epoch-step: 28-161 -- Loss: 0.20737656950950623
train-epoch-step: 28-162 -- Loss: 0.21600888669490814
train-epoch-step: 28-163 -- Loss: 0.19139210879802704
train-epoch-step: 28-164 -- Loss: 0.19464486837387085
train-epoch-step: 28-165 -- Loss: 0.1702297180891037
train-epoch-step: 28-166 -- Loss: 0.12723994255065918
train-epoch-step: 28-167 -- Loss: 0.130806103348732
train-epoch-step: 28-168 -- Loss: 0.2163618505001068
train-epoch-step: 28-169 -- Loss: 0.13835440576076508
train-epoch-step: 28-170 -- Loss: 0.20065900683403015
train-epoch-step: 28-171 -- Loss: 0.14434295892715454
train-epoch-step: 28-172 -- Loss: 0.2649610936641693
train-epoch-step: 28-173 -- Loss: 0.1377042829990387
train-epoch-step: 28-174 -- Loss: 0.24758780002593994
train-epoch-step: 28-175 -- Loss: 0.18890613317489624
train-epoch-step: 28-176 -- Loss: 0.13772225379943848
train-epoch-step: 28-177 -- Loss: 0.18852882087230682
train-epoch-step: 28-178 -- Loss: 0.18460193276405334
train-epoch-step: 28-179 -- Loss: 0.15173368155956268
train-epoch-step: 28-180 -- Loss: 0.1554107815027237
train-epoch-step: 28-181 -- Loss: 0.16915298998355865
train-epoch-step: 28-182 -- Loss: 0.19179758429527283
train-epoch-step: 28-183 -- Loss: 0.2910555899143219
train-epoch-step: 28-184 -- Loss: 0.15077778697013855
train-epoch-step: 28-185 -- Loss: 0.1418265700340271
train-epoch-step: 28-186 -- Loss: 0.19211485981941223
train-epoch-step: 28-187 -- Loss: 0.21201971173286438
train-epoch-step: 28-188 -- Loss: 0.188737154006958
train-epoch-step: 28-189 -- Loss: 0.11044251173734665
train-epoch-step: 28-190 -- Loss: 0.18170666694641113
train-epoch-step: 28-191 -- Loss: 0.16522720456123352
train-epoch-step: 28-192 -- Loss: 0.23431065678596497
train-epoch-step: 28-193 -- Loss: 0.21448557078838348
train-epoch-step: 28-194 -- Loss: 0.18489593267440796
train-epoch-step: 28-195 -- Loss: 0.1699853241443634
train-epoch-step: 28-196 -- Loss: 0.17319855093955994
train-epoch-step: 28-197 -- Loss: 0.13465994596481323
train-epoch-step: 28-198 -- Loss: 0.13044488430023193
train-epoch-step: 28-199 -- Loss: 0.1520170420408249
train-epoch-step: 28-200 -- Loss: 0.1274128258228302
train-epoch-step: 28-201 -- Loss: 0.19669820368289948
train-epoch-step: 28-202 -- Loss: 0.13896173238754272
train-epoch-step: 28-203 -- Loss: 0.1774415671825409
train-epoch-step: 28-204 -- Loss: 0.13690237700939178
train-epoch-step: 28-205 -- Loss: 0.19115078449249268
train-epoch-step: 28-206 -- Loss: 0.20235230028629303
train-epoch-step: 28-207 -- Loss: 0.13194464147090912
train-epoch-step: 28-208 -- Loss: 0.17889058589935303
train-epoch-step: 28-209 -- Loss: 0.14281953871250153
train-epoch-step: 28-210 -- Loss: 0.13827595114707947
train-epoch-step: 28-211 -- Loss: 0.21475833654403687
train-epoch-step: 28-212 -- Loss: 0.202924907207489
train-epoch-step: 28-213 -- Loss: 0.12937860190868378
train-epoch-step: 28-214 -- Loss: 0.15273332595825195
train-epoch-step: 28-215 -- Loss: 0.13540518283843994
train-epoch-step: 28-216 -- Loss: 0.20768482983112335
train-epoch-step: 28-217 -- Loss: 0.2504936158657074
train-epoch-step: 28-218 -- Loss: 0.14602136611938477
train-epoch-step: 28-219 -- Loss: 0.1760016828775406
train-epoch-step: 28-220 -- Loss: 0.1282796561717987
train-epoch-step: 28-221 -- Loss: 0.20666861534118652
train-epoch-step: 28-222 -- Loss: 0.12142934650182724
train-epoch-step: 28-223 -- Loss: 0.1880866289138794
train-epoch-step: 28-224 -- Loss: 0.21713581681251526
train-epoch-step: 28-225 -- Loss: 0.2854085862636566
train-epoch-step: 28-226 -- Loss: 0.21139425039291382
train-epoch-step: 28-227 -- Loss: 0.2715209126472473
train-epoch-step: 28-228 -- Loss: 0.17816966772079468
train-epoch-step: 28-229 -- Loss: 0.1848088651895523
train-epoch-step: 28-230 -- Loss: 0.17121896147727966
train-epoch-step: 28-231 -- Loss: 0.18802054226398468
train-epoch-step: 28-232 -- Loss: 0.22766880691051483
train-epoch-step: 28-233 -- Loss: 0.08818136155605316
train-epoch-step: 28-234 -- Loss: 0.19196265935897827
train-epoch-step: 28-235 -- Loss: 0.14861595630645752
train-epoch-step: 28-236 -- Loss: 0.2532521188259125
train-epoch-step: 28-237 -- Loss: 0.2648998200893402
train-epoch-step: 28-238 -- Loss: 0.16302426159381866
train-epoch-step: 28-239 -- Loss: 0.1294027715921402
train-epoch-step: 28-240 -- Loss: 0.2408704161643982
train-epoch-step: 28-241 -- Loss: 0.16345100104808807
train-epoch-step: 28-242 -- Loss: 0.24403105676174164
train-epoch-step: 28-243 -- Loss: 0.28302621841430664
train-epoch-step: 28-244 -- Loss: 0.2369759976863861
train-epoch-step: 28-245 -- Loss: 0.2215481549501419
train-epoch-step: 28-246 -- Loss: 0.28321337699890137
train-epoch-step: 28-247 -- Loss: 0.21694859862327576
train-epoch-step: 28-248 -- Loss: 0.18732121586799622
train-epoch-step: 28-249 -- Loss: 0.15837454795837402
train-epoch-step: 28-250 -- Loss: 0.20857776701450348
train-epoch-step: 28-251 -- Loss: 0.10999264568090439
train-epoch-step: 28-252 -- Loss: 0.2031290978193283
train-epoch-step: 28-253 -- Loss: 0.16361325979232788
train-epoch-step: 28-254 -- Loss: 0.22612768411636353
train-epoch-step: 28-255 -- Loss: 0.15739287436008453
train-epoch-step: 28-256 -- Loss: 0.17547211050987244
train-epoch-step: 28-257 -- Loss: 0.20122314989566803
train-epoch-step: 28-258 -- Loss: 0.14830942451953888
train-epoch-step: 28-259 -- Loss: 0.13919684290885925
train-epoch-step: 28-260 -- Loss: 0.2170500010251999
train-epoch-step: 28-261 -- Loss: 0.18460392951965332
train-epoch-step: 28-262 -- Loss: 0.32972076535224915
train-epoch-step: 28-263 -- Loss: 0.2111707180738449
train-epoch-step: 28-264 -- Loss: 0.18523120880126953
train-epoch-step: 28-265 -- Loss: 0.1397857964038849
train-epoch-step: 28-266 -- Loss: 0.16318121552467346
train-epoch-step: 28-267 -- Loss: 0.13565722107887268
train-epoch-step: 28-268 -- Loss: 0.13481579720973969
train-epoch-step: 28-269 -- Loss: 0.18820349872112274
train-epoch-step: 28-270 -- Loss: 0.11258617043495178
train-epoch-step: 28-271 -- Loss: 0.15578843653202057
train-epoch-step: 28-272 -- Loss: 0.12013427168130875
train-epoch-step: 28-273 -- Loss: 0.1274174600839615
train-epoch-step: 28-274 -- Loss: 0.21309536695480347
train-epoch-step: 28-275 -- Loss: 0.23079316318035126
train-epoch-step: 28-276 -- Loss: 0.163519948720932
train-epoch-step: 28-277 -- Loss: 0.16217730939388275
train-epoch-step: 28-278 -- Loss: 0.15810354053974152
train-epoch-step: 28-279 -- Loss: 0.15226241946220398
train-epoch-step: 28-280 -- Loss: 0.23553380370140076
train-epoch-step: 28-281 -- Loss: 0.18636904656887054
train-epoch-step: 28-282 -- Loss: 0.1450766623020172
train-epoch-step: 28-283 -- Loss: 0.12280748039484024
train-epoch-step: 28-284 -- Loss: 0.14288991689682007
train-epoch-step: 28-285 -- Loss: 0.20059125125408173
train-epoch-step: 28-286 -- Loss: 0.16327738761901855
train-epoch-step: 28-287 -- Loss: 0.20861390233039856
train-epoch-step: 28-288 -- Loss: 0.09995212405920029
train-epoch-step: 28-289 -- Loss: 0.12886931002140045
train-epoch-step: 28-290 -- Loss: 0.1885477602481842
train-epoch-step: 28-291 -- Loss: 0.12272706627845764
train-epoch-step: 28-292 -- Loss: 0.15943247079849243
train-epoch-step: 28-293 -- Loss: 0.13930386304855347
train-epoch-step: 28-294 -- Loss: 0.20194919407367706
train-epoch-step: 28-295 -- Loss: 0.27582529187202454
train-epoch-step: 28-296 -- Loss: 0.17149750888347626
train-epoch-step: 28-297 -- Loss: 0.17988994717597961
train-epoch-step: 28-298 -- Loss: 0.23589126765727997
train-epoch-step: 28-299 -- Loss: 0.15412311255931854
train-epoch-step: 28-300 -- Loss: 0.1711759716272354
train-epoch-step: 28-301 -- Loss: 0.18589110672473907
train-epoch-step: 28-302 -- Loss: 0.22731666266918182
train-epoch-step: 28-303 -- Loss: 0.2123599648475647
train-epoch-step: 28-304 -- Loss: 0.1303487867116928
train-epoch-step: 28-305 -- Loss: 0.14799082279205322
train-epoch-step: 28-306 -- Loss: 0.243161141872406
train-epoch-step: 28-307 -- Loss: 0.17123821377754211
train-epoch-step: 28-308 -- Loss: 0.22359487414360046
train-epoch-step: 28-309 -- Loss: 0.16549783945083618
train-epoch-step: 28-310 -- Loss: 0.1660792976617813
train-epoch-step: 28-311 -- Loss: 0.16189837455749512
train-epoch-step: 28-312 -- Loss: 0.21344764530658722
train-epoch-step: 28-313 -- Loss: 0.10941191762685776
train-epoch-step: 28-314 -- Loss: 0.19683079421520233
train-epoch-step: 28-315 -- Loss: 0.1760808378458023
train-epoch-step: 28-316 -- Loss: 0.1574280858039856
train-epoch-step: 28-317 -- Loss: 0.1479450762271881
train-epoch-step: 28-318 -- Loss: 0.1639588177204132
train-epoch-step: 28-319 -- Loss: 0.177972674369812
train-epoch-step: 28-320 -- Loss: 0.12219090759754181
train-epoch-step: 28-321 -- Loss: 0.1513325423002243
train-epoch-step: 28-322 -- Loss: 0.22436027228832245
train-epoch-step: 28-323 -- Loss: 0.16656962037086487
train-epoch-step: 28-324 -- Loss: 0.258889377117157
train-epoch-step: 28-325 -- Loss: 0.15632984042167664
train-epoch-step: 28-326 -- Loss: 0.17473311722278595
train-epoch-step: 28-327 -- Loss: 0.2157788723707199
train-epoch-step: 28-328 -- Loss: 0.20655199885368347
train-epoch-step: 28-329 -- Loss: 0.339460551738739
train-epoch-step: 28-330 -- Loss: 0.36277085542678833
train-epoch-step: 28-331 -- Loss: 0.21708258986473083
train-epoch-step: 28-332 -- Loss: 0.10565924644470215
train-epoch-step: 28-333 -- Loss: 0.1930629312992096
train-epoch-step: 28-334 -- Loss: 0.16606518626213074
train-epoch-step: 28-335 -- Loss: 0.18030278384685516
train-epoch-step: 28-336 -- Loss: 0.1563999354839325
train-epoch-step: 28-337 -- Loss: 0.20727455615997314
train-epoch-step: 28-338 -- Loss: 0.16451747715473175
train-epoch-step: 28-339 -- Loss: 0.1449880599975586
train-epoch-step: 28-340 -- Loss: 0.2042923867702484
train-epoch-step: 28-341 -- Loss: 0.14249518513679504
train-epoch-step: 28-342 -- Loss: 0.17114287614822388
train-epoch-step: 28-343 -- Loss: 0.15500962734222412
train-epoch-step: 28-344 -- Loss: 0.1642674207687378
train-epoch-step: 28-345 -- Loss: 0.13322199881076813
train-epoch-step: 28-346 -- Loss: 0.21868541836738586
train-epoch-step: 28-347 -- Loss: 0.15240007638931274
train-epoch-step: 28-348 -- Loss: 0.20434722304344177
train-epoch-step: 28-349 -- Loss: 0.21328209340572357
train-epoch-step: 28-350 -- Loss: 0.25874558091163635
train-epoch-step: 28-351 -- Loss: 0.1957167685031891
train-epoch-step: 28-352 -- Loss: 0.13007450103759766
train-epoch-step: 28-353 -- Loss: 0.20008817315101624
train-epoch-step: 28-354 -- Loss: 0.29285478591918945
train-epoch-step: 28-355 -- Loss: 0.12071755528450012
train-epoch-step: 28-356 -- Loss: 0.11676006764173508
train-epoch-step: 28-357 -- Loss: 0.1975054144859314
train-epoch-step: 28-358 -- Loss: 0.18929319083690643
train-epoch-step: 28-359 -- Loss: 0.14451971650123596
train-epoch-step: 28-360 -- Loss: 0.12409195303916931
train-epoch-step: 28-361 -- Loss: 0.24115493893623352
train-epoch-step: 28-362 -- Loss: 0.17150408029556274
train-epoch-step: 28-363 -- Loss: 0.13027352094650269
train-epoch-step: 28-364 -- Loss: 0.18083202838897705
train-epoch-step: 28-365 -- Loss: 0.17463374137878418
train-epoch-step: 28-366 -- Loss: 0.20036345720291138
train-epoch-step: 28-367 -- Loss: 0.23992730677127838
train-epoch-step: 28-368 -- Loss: 0.21102771162986755
train-epoch-step: 28-369 -- Loss: 0.28113582730293274
train-epoch-step: 28-370 -- Loss: 0.12738260626792908
train-epoch-step: 28-371 -- Loss: 0.12348891794681549
train-epoch-step: 28-372 -- Loss: 0.15027621388435364
train-epoch-step: 28-373 -- Loss: 0.20837970077991486
train-epoch-step: 28-374 -- Loss: 0.15727494657039642
train-epoch-step: 28-375 -- Loss: 0.27126991748809814
train-epoch-step: 28-376 -- Loss: 0.17370730638504028
train-epoch-step: 28-377 -- Loss: 0.235934779047966
train-epoch-step: 28-378 -- Loss: 0.20074735581874847
train-epoch-step: 28-379 -- Loss: 0.12242534756660461
train-epoch-step: 28-380 -- Loss: 0.09489117562770844
train-epoch-step: 28-381 -- Loss: 0.2540369927883148
train-epoch-step: 28-382 -- Loss: 0.23484057188034058
train-epoch-step: 28-383 -- Loss: 0.18123604357242584
train-epoch-step: 28-384 -- Loss: 0.23269011080265045
train-epoch-step: 28-385 -- Loss: 0.201096773147583
train-epoch-step: 28-386 -- Loss: 0.1908596307039261
train-epoch-step: 28-387 -- Loss: 0.2107708752155304
train-epoch-step: 28-388 -- Loss: 0.1957307755947113
train-epoch-step: 28-389 -- Loss: 0.17270737886428833
train-epoch-step: 28-390 -- Loss: 0.14207789301872253
train-epoch-step: 28-391 -- Loss: 0.1524517983198166
train-epoch-step: 28-392 -- Loss: 0.18858157098293304
train-epoch-step: 28-393 -- Loss: 0.16221007704734802
train-epoch-step: 28-394 -- Loss: 0.2121092528104782
train-epoch-step: 28-395 -- Loss: 0.1847558170557022
train-epoch-step: 28-396 -- Loss: 0.12834399938583374
train-epoch-step: 28-397 -- Loss: 0.12765370309352875
train-epoch-step: 28-398 -- Loss: 0.19864951074123383
train-epoch-step: 28-399 -- Loss: 0.18428412079811096
train-epoch-step: 28-400 -- Loss: 0.2918801009654999
train-epoch-step: 28-401 -- Loss: 0.12633675336837769
train-epoch-step: 28-402 -- Loss: 0.26827654242515564
train-epoch-step: 28-403 -- Loss: 0.15469680726528168
train-epoch-step: 28-404 -- Loss: 0.13922494649887085
train-epoch-step: 28-405 -- Loss: 0.15733790397644043
train-epoch-step: 28-406 -- Loss: 0.1763269007205963
train-epoch-step: 28-407 -- Loss: 0.11308298259973526
train-epoch-step: 28-408 -- Loss: 0.16207541525363922
train-epoch-step: 28-409 -- Loss: 0.1785019338130951
train-epoch-step: 28-410 -- Loss: 0.17673170566558838
train-epoch-step: 28-411 -- Loss: 0.21183189749717712
train-epoch-step: 28-412 -- Loss: 0.13253656029701233
train-epoch-step: 28-413 -- Loss: 0.14948883652687073
train-epoch-step: 28-414 -- Loss: 0.13330188393592834
train-epoch-step: 28-415 -- Loss: 0.14590294659137726
train-epoch-step: 28-416 -- Loss: 0.27256909012794495
train-epoch-step: 28-417 -- Loss: 0.19207872450351715
train-epoch-step: 28-418 -- Loss: 0.23561516404151917
train-epoch-step: 28-419 -- Loss: 0.18948578834533691
train-epoch-step: 28-420 -- Loss: 0.1567476987838745
train-epoch-step: 28-421 -- Loss: 0.18277199566364288
train-epoch-step: 28-422 -- Loss: 0.15372394025325775
train-epoch-step: 28-423 -- Loss: 0.17814278602600098
train-epoch-step: 28-424 -- Loss: 0.14087636768817902
train-epoch-step: 28-425 -- Loss: 0.1882491111755371
train-epoch-step: 28-426 -- Loss: 0.15835337340831757
train-epoch-step: 28-427 -- Loss: 0.12424686551094055
train-epoch-step: 28-428 -- Loss: 0.20364972949028015
train-epoch-step: 28-429 -- Loss: 0.1781240999698639
train-epoch-step: 28-430 -- Loss: 0.1531839668750763
train-epoch-step: 28-431 -- Loss: 0.16690872609615326
train-epoch-step: 28-432 -- Loss: 0.24158945679664612
train-epoch-step: 28-433 -- Loss: 0.14846841990947723
train-epoch-step: 28-434 -- Loss: 0.13291124999523163
train-epoch-step: 28-435 -- Loss: 0.17018860578536987
train-epoch-step: 28-436 -- Loss: 0.16209231317043304
train-epoch-step: 28-437 -- Loss: 0.134687602519989
train-epoch-step: 28-438 -- Loss: 0.1682925969362259
train-epoch-step: 28-439 -- Loss: 0.26538363099098206
train-epoch-step: 28-440 -- Loss: 0.13420400023460388
train-epoch-step: 28-441 -- Loss: 0.20124433934688568
train-epoch-step: 28-442 -- Loss: 0.17818935215473175
train-epoch-step: 28-443 -- Loss: 0.15958072245121002
train-epoch-step: 28-444 -- Loss: 0.17858847975730896
train-epoch-step: 28-445 -- Loss: 0.18174931406974792
train-epoch-step: 28-446 -- Loss: 0.16009621322155
train-epoch-step: 28-447 -- Loss: 0.1924249529838562
train-epoch-step: 28-448 -- Loss: 0.22824585437774658
train-epoch-step: 28-449 -- Loss: 0.1931164264678955
train-epoch-step: 28-450 -- Loss: 0.1884036809206009
train-epoch-step: 28-451 -- Loss: 0.14538785815238953
train-epoch-step: 28-452 -- Loss: 0.13465747237205505
train-epoch-step: 28-453 -- Loss: 0.10971974581480026
train-epoch-step: 28-454 -- Loss: 0.24093791842460632
train-epoch-step: 28-455 -- Loss: 0.12870529294013977
train-epoch-step: 28-456 -- Loss: 0.12278204411268234
train-epoch-step: 28-457 -- Loss: 0.22295346856117249
train-epoch-step: 28-458 -- Loss: 0.1555655598640442
train-epoch-step: 28-459 -- Loss: 0.21547123789787292
train-epoch-step: 28-460 -- Loss: 0.13310359418392181
train-epoch-step: 28-461 -- Loss: 0.1367134153842926
train-epoch-step: 28-462 -- Loss: 0.17210890352725983
train-epoch-step: 28-463 -- Loss: 0.1404087245464325
train-epoch-step: 28-464 -- Loss: 0.16770833730697632
train-epoch-step: 28-465 -- Loss: 0.24440839886665344
train-epoch-step: 28-466 -- Loss: 0.20114092528820038
train-epoch-step: 28-467 -- Loss: 0.11678490042686462
train-epoch-step: 28-468 -- Loss: 0.17955069243907928
train-epoch-step: 28-469 -- Loss: 0.2515028119087219
train-epoch-step: 28-470 -- Loss: 0.18754273653030396
train-epoch-step: 28-471 -- Loss: 0.16366513073444366
train-epoch-step: 28-472 -- Loss: 0.16016104817390442
train-epoch-step: 28-473 -- Loss: 0.15398737788200378
train-epoch-step: 28-474 -- Loss: 0.12180644273757935
train-epoch-step: 28-475 -- Loss: 0.117686927318573
train-epoch-step: 28-476 -- Loss: 0.20347875356674194
train-epoch-step: 28-477 -- Loss: 0.2067449986934662
train-epoch-step: 28-478 -- Loss: 0.1987060010433197
train-epoch-step: 28-479 -- Loss: 0.1455938220024109
train-epoch-step: 28-480 -- Loss: 0.19912376999855042
train-epoch-step: 28-481 -- Loss: 0.29083552956581116
train-epoch-step: 28-482 -- Loss: 0.2546795606613159
train-epoch-step: 28-483 -- Loss: 0.1861690878868103
train-epoch-step: 28-484 -- Loss: 0.21432426571846008
train-epoch-step: 28-485 -- Loss: 0.1304091215133667
train-epoch-step: 28-486 -- Loss: 0.24695579707622528
train-epoch-step: 28-487 -- Loss: 0.2368169128894806
train-epoch-step: 28-488 -- Loss: 0.19893057644367218
train-epoch-step: 28-489 -- Loss: 0.22347676753997803
train-epoch-step: 28-490 -- Loss: 0.1363491415977478
train-epoch-step: 28-491 -- Loss: 0.13845276832580566
train-epoch-step: 28-492 -- Loss: 0.12720496952533722
train-epoch-step: 28-493 -- Loss: 0.20450542867183685
train-epoch-step: 28-494 -- Loss: 0.20785969495773315
train-epoch-step: 28-495 -- Loss: 0.20766741037368774
train-epoch-step: 28-496 -- Loss: 0.1398695409297943
train-epoch-step: 28-497 -- Loss: 0.1891414225101471
train-epoch-step: 28-498 -- Loss: 0.15553659200668335
train-epoch-step: 28-499 -- Loss: 0.17759069800376892
train-epoch-step: 28-500 -- Loss: 0.1598682999610901
train-epoch-step: 28-501 -- Loss: 0.21858832240104675
train-epoch-step: 28-502 -- Loss: 0.15960466861724854
train-epoch-step: 28-503 -- Loss: 0.22720889747142792
train-epoch-step: 28-504 -- Loss: 0.12075813859701157
train-epoch-step: 28-505 -- Loss: 0.1757345050573349
train-epoch-step: 28-506 -- Loss: 0.12071572244167328
train-epoch-step: 28-507 -- Loss: 0.1880328357219696
train-epoch-step: 28-508 -- Loss: 0.1751548796892166
train-epoch-step: 28-509 -- Loss: 0.16864730417728424
train-epoch-step: 28-510 -- Loss: 0.1276666820049286
train-epoch-step: 28-511 -- Loss: 0.21971425414085388
train-epoch-step: 28-512 -- Loss: 0.17829857766628265
train-epoch-step: 28-513 -- Loss: 0.20410341024398804
train-epoch-step: 28-514 -- Loss: 0.14604519307613373
train-epoch-step: 28-515 -- Loss: 0.16220931708812714
train-epoch-step: 28-516 -- Loss: 0.17321547865867615
train-epoch-step: 28-517 -- Loss: 0.17603279650211334
train-epoch-step: 28-518 -- Loss: 0.14233852922916412
train-epoch-step: 28-519 -- Loss: 0.1341174989938736
train-epoch-step: 28-520 -- Loss: 0.18964263796806335
train-epoch-step: 28-521 -- Loss: 0.23231695592403412
train-epoch-step: 28-522 -- Loss: 0.175956591963768
train-epoch-step: 28-523 -- Loss: 0.1616540104150772
train-epoch-step: 28-524 -- Loss: 0.17183098196983337
train-epoch-step: 28-525 -- Loss: 0.19841371476650238
train-epoch-step: 28-526 -- Loss: 0.13206824660301208
train-epoch-step: 28-527 -- Loss: 0.16852664947509766
train-epoch-step: 28-528 -- Loss: 0.15637102723121643
train-epoch-step: 28-529 -- Loss: 0.15726017951965332
train-epoch-step: 28-530 -- Loss: 0.1710999608039856
train-epoch-step: 28-531 -- Loss: 0.2007373720407486
train-epoch-step: 28-532 -- Loss: 0.171477273106575
train-epoch-step: 28-533 -- Loss: 0.17086206376552582
train-epoch-step: 28-534 -- Loss: 0.12911511957645416
train-epoch-step: 28-535 -- Loss: 0.2660072445869446
train-epoch-step: 28-536 -- Loss: 0.1611030399799347
train-epoch-step: 28-537 -- Loss: 0.14865557849407196
train-epoch-step: 28-538 -- Loss: 0.1096411943435669
train-epoch-step: 28-539 -- Loss: 0.2052045464515686
train-epoch-step: 28-540 -- Loss: 0.13885758817195892
train-epoch-step: 28-541 -- Loss: 0.21640536189079285
train-epoch-step: 28-542 -- Loss: 0.22541694343090057
train-epoch-step: 28-543 -- Loss: 0.17042559385299683
train-epoch-step: 28-544 -- Loss: 0.22891126573085785
train-epoch-step: 28-545 -- Loss: 0.20061877369880676
train-epoch-step: 28-546 -- Loss: 0.21798022091388702
train-epoch-step: 28-547 -- Loss: 0.18520675599575043
train-epoch-step: 28-548 -- Loss: 0.09697684645652771
train-epoch-step: 28-549 -- Loss: 0.15660026669502258
train-epoch-step: 28-550 -- Loss: 0.20152121782302856
train-epoch-step: 28-551 -- Loss: 0.1597040891647339
train-epoch-step: 28-552 -- Loss: 0.1267659217119217
train-epoch-step: 28-553 -- Loss: 0.19074025750160217
train-epoch-step: 28-554 -- Loss: 0.18916328251361847
train-epoch-step: 28-555 -- Loss: 0.21190032362937927
train-epoch-step: 28-556 -- Loss: 0.18936479091644287
train-epoch-step: 28-557 -- Loss: 0.2459162175655365
train-epoch-step: 28-558 -- Loss: 0.22772520780563354
train-epoch-step: 28-559 -- Loss: 0.14550012350082397
train-epoch-step: 28-560 -- Loss: 0.2149111032485962
train-epoch-step: 28-561 -- Loss: 0.18262849748134613
train-epoch-step: 28-562 -- Loss: 0.16674354672431946
train-epoch-step: 28-563 -- Loss: 0.18740038573741913
train-epoch-step: 28-564 -- Loss: 0.0986904501914978
train-epoch-step: 28-565 -- Loss: 0.2097233533859253
train-epoch-step: 28-566 -- Loss: 0.1601262390613556
train-epoch-step: 28-567 -- Loss: 0.2157917022705078
train-epoch-step: 28-568 -- Loss: 0.16233684122562408
train-epoch-step: 28-569 -- Loss: 0.2454882562160492
train-epoch-step: 28-570 -- Loss: 0.1828952431678772
train-epoch-step: 28-571 -- Loss: 0.22627225518226624
train-epoch-step: 28-572 -- Loss: 0.2450348138809204
train-epoch-step: 28-573 -- Loss: 0.2064015120267868
train-epoch-step: 28-574 -- Loss: 0.2514076828956604
train-epoch-step: 28-575 -- Loss: 0.31321007013320923
train-epoch-step: 28-576 -- Loss: 0.13394032418727875
train-epoch-step: 28-577 -- Loss: 0.1737830936908722
train-epoch-step: 28-578 -- Loss: 0.21586568653583527
train-epoch-step: 28-579 -- Loss: 0.16953717172145844
train-epoch-step: 28-580 -- Loss: 0.17765647172927856
train-epoch-step: 28-581 -- Loss: 0.14016902446746826
train-epoch-step: 28-582 -- Loss: 0.21570344269275665
train-epoch-step: 28-583 -- Loss: 0.2214404046535492
train-epoch-step: 28-584 -- Loss: 0.1818164587020874
train-epoch-step: 28-585 -- Loss: 0.2062266767024994
train-epoch-step: 28-586 -- Loss: 0.26282191276550293
train-epoch-step: 28-587 -- Loss: 0.1632302701473236
train-epoch-step: 28-588 -- Loss: 0.13054677844047546
val-epoch-step: 28-589 -- Loss: 0.21141417324543
val-epoch-step: 28-590 -- Loss: 0.15395431220531464
val-epoch-step: 28-591 -- Loss: 0.2393515557050705
val-epoch-step: 28-592 -- Loss: 0.17740453779697418
val-epoch-step: 28-593 -- Loss: 0.17350122332572937
val-epoch-step: 28-594 -- Loss: 0.38245487213134766
val-epoch-step: 28-595 -- Loss: 0.1869242638349533
val-epoch-step: 28-596 -- Loss: 0.20884934067726135
val-epoch-step: 28-597 -- Loss: 0.1820552945137024
val-epoch-step: 28-598 -- Loss: 0.15782754123210907
val-epoch-step: 28-599 -- Loss: 0.19398018717765808
val-epoch-step: 28-600 -- Loss: 0.16610747575759888
val-epoch-step: 28-601 -- Loss: 0.15916569530963898
val-epoch-step: 28-602 -- Loss: 0.1381678432226181
val-epoch-step: 28-603 -- Loss: 0.19899500906467438
val-epoch-step: 28-604 -- Loss: 0.15029172599315643
val-epoch-step: 28-605 -- Loss: 0.14904706180095673
val-epoch-step: 28-606 -- Loss: 0.27022016048431396
val-epoch-step: 28-607 -- Loss: 0.13186335563659668
val-epoch-step: 28-608 -- Loss: 0.2474087029695511
val-epoch-step: 28-609 -- Loss: 0.17983576655387878
val-epoch-step: 28-610 -- Loss: 0.18379563093185425
val-epoch-step: 28-611 -- Loss: 0.1573188155889511
val-epoch-step: 28-612 -- Loss: 0.4571613371372223
val-epoch-step: 28-613 -- Loss: 0.17781060934066772
val-epoch-step: 28-614 -- Loss: 0.16314385831356049
val-epoch-step: 28-615 -- Loss: 0.17790672183036804
val-epoch-step: 28-616 -- Loss: 0.15699228644371033
val-epoch-step: 28-617 -- Loss: 0.18660160899162292
val-epoch-step: 28-618 -- Loss: 0.21402785181999207
val-epoch-step: 28-619 -- Loss: 0.20962406694889069
val-epoch-step: 28-620 -- Loss: 0.15100529789924622
val-epoch-step: 28-621 -- Loss: 0.129259392619133
val-epoch-step: 28-622 -- Loss: 0.15495547652244568
val-epoch-step: 28-623 -- Loss: 0.15375185012817383
val-epoch-step: 28-624 -- Loss: 0.14364641904830933
val-epoch-step: 28-625 -- Loss: 0.15977632999420166
val-epoch-step: 28-626 -- Loss: 0.15040172636508942
val-epoch-step: 28-627 -- Loss: 0.19350022077560425
val-epoch-step: 28-628 -- Loss: 0.7008248567581177
val-epoch-step: 28-629 -- Loss: 0.2206796109676361
val-epoch-step: 28-630 -- Loss: 0.35694175958633423
val-epoch-step: 28-631 -- Loss: 0.14288529753684998
val-epoch-step: 28-632 -- Loss: 0.2064141035079956
val-epoch-step: 28-633 -- Loss: 0.1564645618200302
val-epoch-step: 28-634 -- Loss: 0.1554621160030365
val-epoch-step: 28-635 -- Loss: 0.1169227585196495
val-epoch-step: 28-636 -- Loss: 0.17033420503139496
val-epoch-step: 28-637 -- Loss: 0.18275615572929382
val-epoch-step: 28-638 -- Loss: 0.15837892889976501
val-epoch-step: 28-639 -- Loss: 0.2668319642543793
val-epoch-step: 28-640 -- Loss: 0.25906795263290405
val-epoch-step: 28-641 -- Loss: 0.13548530638217926
val-epoch-step: 28-642 -- Loss: 0.1957075446844101
val-epoch-step: 28-643 -- Loss: 0.20776957273483276
val-epoch-step: 28-644 -- Loss: 0.17349596321582794
val-epoch-step: 28-645 -- Loss: 0.2228342741727829
val-epoch-step: 28-646 -- Loss: 0.13531029224395752
val-epoch-step: 28-647 -- Loss: 0.14339177310466766
val-epoch-step: 28-648 -- Loss: 0.1628769338130951
val-epoch-step: 28-649 -- Loss: 0.21883726119995117
val-epoch-step: 28-650 -- Loss: 0.2600768804550171
val-epoch-step: 28-651 -- Loss: 0.1502208411693573
val-epoch-step: 28-652 -- Loss: 0.15796642005443573
val-epoch-step: 28-653 -- Loss: 0.2306004911661148
val-epoch-step: 28-654 -- Loss: 0.11765787750482559
Epoch: 28 -- Train Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 29-0 -- Loss: 0.2333398461341858
train-epoch-step: 29-1 -- Loss: 0.14825589954853058
train-epoch-step: 29-2 -- Loss: 0.2055903524160385
train-epoch-step: 29-3 -- Loss: 0.14401821792125702
train-epoch-step: 29-4 -- Loss: 0.16595037281513214
train-epoch-step: 29-5 -- Loss: 0.19099470973014832
train-epoch-step: 29-6 -- Loss: 0.22339443862438202
train-epoch-step: 29-7 -- Loss: 0.16841930150985718
train-epoch-step: 29-8 -- Loss: 0.2019481360912323
train-epoch-step: 29-9 -- Loss: 0.23478397727012634
train-epoch-step: 29-10 -- Loss: 0.19679881632328033
train-epoch-step: 29-11 -- Loss: 0.18566317856311798
train-epoch-step: 29-12 -- Loss: 0.15365274250507355
train-epoch-step: 29-13 -- Loss: 0.18741166591644287
train-epoch-step: 29-14 -- Loss: 0.17893894016742706
train-epoch-step: 29-15 -- Loss: 0.16178768873214722
train-epoch-step: 29-16 -- Loss: 0.17688801884651184
train-epoch-step: 29-17 -- Loss: 0.23290450870990753
train-epoch-step: 29-18 -- Loss: 0.20625174045562744
train-epoch-step: 29-19 -- Loss: 0.13757696747779846
train-epoch-step: 29-20 -- Loss: 0.21604016423225403
train-epoch-step: 29-21 -- Loss: 0.24875709414482117
train-epoch-step: 29-22 -- Loss: 0.14412501454353333
train-epoch-step: 29-23 -- Loss: 0.14834251999855042
train-epoch-step: 29-24 -- Loss: 0.12969788908958435
train-epoch-step: 29-25 -- Loss: 0.2548401653766632
train-epoch-step: 29-26 -- Loss: 0.2042442262172699
train-epoch-step: 29-27 -- Loss: 0.24249455332756042
train-epoch-step: 29-28 -- Loss: 0.13499855995178223
train-epoch-step: 29-29 -- Loss: 0.24489450454711914
train-epoch-step: 29-30 -- Loss: 0.11601941287517548
train-epoch-step: 29-31 -- Loss: 0.14452236890792847
train-epoch-step: 29-32 -- Loss: 0.18358708918094635
train-epoch-step: 29-33 -- Loss: 0.28057053685188293
train-epoch-step: 29-34 -- Loss: 0.17483769357204437
train-epoch-step: 29-35 -- Loss: 0.25863415002822876
train-epoch-step: 29-36 -- Loss: 0.14126883447170258
train-epoch-step: 29-37 -- Loss: 0.14402949810028076
train-epoch-step: 29-38 -- Loss: 0.18686842918395996
train-epoch-step: 29-39 -- Loss: 0.23855426907539368
train-epoch-step: 29-40 -- Loss: 0.19730785489082336
train-epoch-step: 29-41 -- Loss: 0.22775745391845703
train-epoch-step: 29-42 -- Loss: 0.15132759511470795
train-epoch-step: 29-43 -- Loss: 0.27211058139801025
train-epoch-step: 29-44 -- Loss: 0.13175787031650543
train-epoch-step: 29-45 -- Loss: 0.11934944242238998
train-epoch-step: 29-46 -- Loss: 0.18527641892433167
train-epoch-step: 29-47 -- Loss: 0.20137575268745422
train-epoch-step: 29-48 -- Loss: 0.15990231931209564
train-epoch-step: 29-49 -- Loss: 0.2288057804107666
train-epoch-step: 29-50 -- Loss: 0.1137685626745224
train-epoch-step: 29-51 -- Loss: 0.19064950942993164
train-epoch-step: 29-52 -- Loss: 0.16158656775951385
train-epoch-step: 29-53 -- Loss: 0.2114882618188858
train-epoch-step: 29-54 -- Loss: 0.28849858045578003
train-epoch-step: 29-55 -- Loss: 0.17355091869831085
train-epoch-step: 29-56 -- Loss: 0.17833620309829712
train-epoch-step: 29-57 -- Loss: 0.2357807755470276
train-epoch-step: 29-58 -- Loss: 0.28751176595687866
train-epoch-step: 29-59 -- Loss: 0.24021482467651367
train-epoch-step: 29-60 -- Loss: 0.13262496888637543
train-epoch-step: 29-61 -- Loss: 0.19941338896751404
train-epoch-step: 29-62 -- Loss: 0.18540288507938385
train-epoch-step: 29-63 -- Loss: 0.14270813763141632
train-epoch-step: 29-64 -- Loss: 0.14951367676258087
train-epoch-step: 29-65 -- Loss: 0.18547332286834717
train-epoch-step: 29-66 -- Loss: 0.1100805252790451
train-epoch-step: 29-67 -- Loss: 0.1347064971923828
train-epoch-step: 29-68 -- Loss: 0.22725129127502441
train-epoch-step: 29-69 -- Loss: 0.12306682020425797
train-epoch-step: 29-70 -- Loss: 0.23348501324653625
train-epoch-step: 29-71 -- Loss: 0.2571024000644684
train-epoch-step: 29-72 -- Loss: 0.1788398027420044
train-epoch-step: 29-73 -- Loss: 0.2118483930826187
train-epoch-step: 29-74 -- Loss: 0.10030490905046463
train-epoch-step: 29-75 -- Loss: 0.12944234907627106
train-epoch-step: 29-76 -- Loss: 0.1553501933813095
train-epoch-step: 29-77 -- Loss: 0.22831211984157562
train-epoch-step: 29-78 -- Loss: 0.2705330550670624
train-epoch-step: 29-79 -- Loss: 0.1960015892982483
train-epoch-step: 29-80 -- Loss: 0.26936769485473633
train-epoch-step: 29-81 -- Loss: 0.12448789179325104
train-epoch-step: 29-82 -- Loss: 0.25387805700302124
train-epoch-step: 29-83 -- Loss: 0.18370036780834198
train-epoch-step: 29-84 -- Loss: 0.18959887325763702
train-epoch-step: 29-85 -- Loss: 0.17451375722885132
train-epoch-step: 29-86 -- Loss: 0.13054117560386658
train-epoch-step: 29-87 -- Loss: 0.22777217626571655
train-epoch-step: 29-88 -- Loss: 0.1402096450328827
train-epoch-step: 29-89 -- Loss: 0.1893409788608551
train-epoch-step: 29-90 -- Loss: 0.19587287306785583
train-epoch-step: 29-91 -- Loss: 0.2537075877189636
train-epoch-step: 29-92 -- Loss: 0.15882965922355652
train-epoch-step: 29-93 -- Loss: 0.18446797132492065
train-epoch-step: 29-94 -- Loss: 0.2300986349582672
train-epoch-step: 29-95 -- Loss: 0.19376015663146973
train-epoch-step: 29-96 -- Loss: 0.21960105001926422
train-epoch-step: 29-97 -- Loss: 0.17929768562316895
train-epoch-step: 29-98 -- Loss: 0.15594041347503662
train-epoch-step: 29-99 -- Loss: 0.1835324764251709
train-epoch-step: 29-100 -- Loss: 0.19213850796222687
train-epoch-step: 29-101 -- Loss: 0.2990128993988037
train-epoch-step: 29-102 -- Loss: 0.23013854026794434
train-epoch-step: 29-103 -- Loss: 0.19334644079208374
train-epoch-step: 29-104 -- Loss: 0.15430131554603577
train-epoch-step: 29-105 -- Loss: 0.2764945924282074
train-epoch-step: 29-106 -- Loss: 0.17638647556304932
train-epoch-step: 29-107 -- Loss: 0.18547901511192322
train-epoch-step: 29-108 -- Loss: 0.19296911358833313
train-epoch-step: 29-109 -- Loss: 0.15125738084316254
train-epoch-step: 29-110 -- Loss: 0.18460749089717865
train-epoch-step: 29-111 -- Loss: 0.18509402871131897
train-epoch-step: 29-112 -- Loss: 0.16695821285247803
train-epoch-step: 29-113 -- Loss: 0.16330955922603607
train-epoch-step: 29-114 -- Loss: 0.20028361678123474
train-epoch-step: 29-115 -- Loss: 0.16503849625587463
train-epoch-step: 29-116 -- Loss: 0.14229515194892883
train-epoch-step: 29-117 -- Loss: 0.1291157752275467
train-epoch-step: 29-118 -- Loss: 0.20077556371688843
train-epoch-step: 29-119 -- Loss: 0.153292715549469
train-epoch-step: 29-120 -- Loss: 0.25468355417251587
train-epoch-step: 29-121 -- Loss: 0.24745531380176544
train-epoch-step: 29-122 -- Loss: 0.21847669780254364
train-epoch-step: 29-123 -- Loss: 0.20501795411109924
train-epoch-step: 29-124 -- Loss: 0.12458351254463196
train-epoch-step: 29-125 -- Loss: 0.156685009598732
train-epoch-step: 29-126 -- Loss: 0.23386384546756744
train-epoch-step: 29-127 -- Loss: 0.18349689245224
train-epoch-step: 29-128 -- Loss: 0.17035365104675293
train-epoch-step: 29-129 -- Loss: 0.14463643729686737
train-epoch-step: 29-130 -- Loss: 0.1949007660150528
train-epoch-step: 29-131 -- Loss: 0.13892817497253418
train-epoch-step: 29-132 -- Loss: 0.19199416041374207
train-epoch-step: 29-133 -- Loss: 0.11800266802310944
train-epoch-step: 29-134 -- Loss: 0.19764378666877747
train-epoch-step: 29-135 -- Loss: 0.13889718055725098
train-epoch-step: 29-136 -- Loss: 0.12558019161224365
train-epoch-step: 29-137 -- Loss: 0.247236967086792
train-epoch-step: 29-138 -- Loss: 0.25718894600868225
train-epoch-step: 29-139 -- Loss: 0.13700129091739655
train-epoch-step: 29-140 -- Loss: 0.20861506462097168
train-epoch-step: 29-141 -- Loss: 0.2313288301229477
train-epoch-step: 29-142 -- Loss: 0.20335018634796143
train-epoch-step: 29-143 -- Loss: 0.17969587445259094
train-epoch-step: 29-144 -- Loss: 0.19840486347675323
train-epoch-step: 29-145 -- Loss: 0.14304542541503906
train-epoch-step: 29-146 -- Loss: 0.18202605843544006
train-epoch-step: 29-147 -- Loss: 0.17336422204971313
train-epoch-step: 29-148 -- Loss: 0.15921932458877563
train-epoch-step: 29-149 -- Loss: 0.12333469092845917
train-epoch-step: 29-150 -- Loss: 0.1875113993883133
train-epoch-step: 29-151 -- Loss: 0.2044028639793396
train-epoch-step: 29-152 -- Loss: 0.20074346661567688
train-epoch-step: 29-153 -- Loss: 0.2750481069087982
train-epoch-step: 29-154 -- Loss: 0.1327010691165924
train-epoch-step: 29-155 -- Loss: 0.13609373569488525
train-epoch-step: 29-156 -- Loss: 0.12161694467067719
train-epoch-step: 29-157 -- Loss: 0.16840943694114685
train-epoch-step: 29-158 -- Loss: 0.16575013101100922
train-epoch-step: 29-159 -- Loss: 0.18658021092414856
train-epoch-step: 29-160 -- Loss: 0.22135674953460693
train-epoch-step: 29-161 -- Loss: 0.20760825276374817
train-epoch-step: 29-162 -- Loss: 0.21179035305976868
train-epoch-step: 29-163 -- Loss: 0.18890100717544556
train-epoch-step: 29-164 -- Loss: 0.19021424651145935
train-epoch-step: 29-165 -- Loss: 0.166526660323143
train-epoch-step: 29-166 -- Loss: 0.12902288138866425
train-epoch-step: 29-167 -- Loss: 0.12843480706214905
train-epoch-step: 29-168 -- Loss: 0.21246996521949768
train-epoch-step: 29-169 -- Loss: 0.1418943852186203
train-epoch-step: 29-170 -- Loss: 0.19770380854606628
train-epoch-step: 29-171 -- Loss: 0.14100304245948792
train-epoch-step: 29-172 -- Loss: 0.26536402106285095
train-epoch-step: 29-173 -- Loss: 0.13585591316223145
train-epoch-step: 29-174 -- Loss: 0.24602621793746948
train-epoch-step: 29-175 -- Loss: 0.18696941435337067
train-epoch-step: 29-176 -- Loss: 0.13879746198654175
train-epoch-step: 29-177 -- Loss: 0.18323631584644318
train-epoch-step: 29-178 -- Loss: 0.18082742393016815
train-epoch-step: 29-179 -- Loss: 0.16586583852767944
train-epoch-step: 29-180 -- Loss: 0.15059955418109894
train-epoch-step: 29-181 -- Loss: 0.17070384323596954
train-epoch-step: 29-182 -- Loss: 0.1859368234872818
train-epoch-step: 29-183 -- Loss: 0.2745116055011749
train-epoch-step: 29-184 -- Loss: 0.14429737627506256
train-epoch-step: 29-185 -- Loss: 0.14173847436904907
train-epoch-step: 29-186 -- Loss: 0.18727384507656097
train-epoch-step: 29-187 -- Loss: 0.2117338329553604
train-epoch-step: 29-188 -- Loss: 0.17489688098430634
train-epoch-step: 29-189 -- Loss: 0.1065916121006012
train-epoch-step: 29-190 -- Loss: 0.1826671063899994
train-epoch-step: 29-191 -- Loss: 0.16449114680290222
train-epoch-step: 29-192 -- Loss: 0.2302922010421753
train-epoch-step: 29-193 -- Loss: 0.21030882000923157
train-epoch-step: 29-194 -- Loss: 0.18378208577632904
train-epoch-step: 29-195 -- Loss: 0.17013996839523315
train-epoch-step: 29-196 -- Loss: 0.1730375587940216
train-epoch-step: 29-197 -- Loss: 0.13675181567668915
train-epoch-step: 29-198 -- Loss: 0.1286359429359436
train-epoch-step: 29-199 -- Loss: 0.15465101599693298
train-epoch-step: 29-200 -- Loss: 0.1305152177810669
train-epoch-step: 29-201 -- Loss: 0.19992366433143616
train-epoch-step: 29-202 -- Loss: 0.13825345039367676
train-epoch-step: 29-203 -- Loss: 0.1780529022216797
train-epoch-step: 29-204 -- Loss: 0.1437162607908249
train-epoch-step: 29-205 -- Loss: 0.18627575039863586
train-epoch-step: 29-206 -- Loss: 0.20288719236850739
train-epoch-step: 29-207 -- Loss: 0.14159002900123596
train-epoch-step: 29-208 -- Loss: 0.18378755450248718
train-epoch-step: 29-209 -- Loss: 0.14091409742832184
train-epoch-step: 29-210 -- Loss: 0.13551732897758484
train-epoch-step: 29-211 -- Loss: 0.21095825731754303
train-epoch-step: 29-212 -- Loss: 0.19885669648647308
train-epoch-step: 29-213 -- Loss: 0.135023295879364
train-epoch-step: 29-214 -- Loss: 0.15079639852046967
train-epoch-step: 29-215 -- Loss: 0.1340491771697998
train-epoch-step: 29-216 -- Loss: 0.21377494931221008
train-epoch-step: 29-217 -- Loss: 0.21711817383766174
train-epoch-step: 29-218 -- Loss: 0.1461235135793686
train-epoch-step: 29-219 -- Loss: 0.17279085516929626
train-epoch-step: 29-220 -- Loss: 0.13362380862236023
train-epoch-step: 29-221 -- Loss: 0.2138090878725052
train-epoch-step: 29-222 -- Loss: 0.12168782204389572
train-epoch-step: 29-223 -- Loss: 0.17521682381629944
train-epoch-step: 29-224 -- Loss: 0.19293053448200226
train-epoch-step: 29-225 -- Loss: 0.2791402041912079
train-epoch-step: 29-226 -- Loss: 0.2060219645500183
train-epoch-step: 29-227 -- Loss: 0.22675764560699463
train-epoch-step: 29-228 -- Loss: 0.18720966577529907
train-epoch-step: 29-229 -- Loss: 0.17432086169719696
train-epoch-step: 29-230 -- Loss: 0.16255003213882446
train-epoch-step: 29-231 -- Loss: 0.15900808572769165
train-epoch-step: 29-232 -- Loss: 0.18733134865760803
train-epoch-step: 29-233 -- Loss: 0.08537416160106659
train-epoch-step: 29-234 -- Loss: 0.17724427580833435
train-epoch-step: 29-235 -- Loss: 0.148342564702034
train-epoch-step: 29-236 -- Loss: 0.18018090724945068
train-epoch-step: 29-237 -- Loss: 0.2446768581867218
train-epoch-step: 29-238 -- Loss: 0.1595020741224289
train-epoch-step: 29-239 -- Loss: 0.12933219969272614
train-epoch-step: 29-240 -- Loss: 0.2241368591785431
train-epoch-step: 29-241 -- Loss: 0.15434762835502625
train-epoch-step: 29-242 -- Loss: 0.22605842351913452
train-epoch-step: 29-243 -- Loss: 0.2355586290359497
train-epoch-step: 29-244 -- Loss: 0.20548051595687866
train-epoch-step: 29-245 -- Loss: 0.2110525369644165
train-epoch-step: 29-246 -- Loss: 0.22520725429058075
train-epoch-step: 29-247 -- Loss: 0.2220764309167862
train-epoch-step: 29-248 -- Loss: 0.1898856908082962
train-epoch-step: 29-249 -- Loss: 0.14057619869709015
train-epoch-step: 29-250 -- Loss: 0.2037670612335205
train-epoch-step: 29-251 -- Loss: 0.10974742472171783
train-epoch-step: 29-252 -- Loss: 0.20064222812652588
train-epoch-step: 29-253 -- Loss: 0.14906585216522217
train-epoch-step: 29-254 -- Loss: 0.2194143533706665
train-epoch-step: 29-255 -- Loss: 0.1514836698770523
train-epoch-step: 29-256 -- Loss: 0.1673496812582016
train-epoch-step: 29-257 -- Loss: 0.19313713908195496
train-epoch-step: 29-258 -- Loss: 0.1469312161207199
train-epoch-step: 29-259 -- Loss: 0.13029040396213531
train-epoch-step: 29-260 -- Loss: 0.20730732381343842
train-epoch-step: 29-261 -- Loss: 0.19081097841262817
train-epoch-step: 29-262 -- Loss: 0.3189200758934021
train-epoch-step: 29-263 -- Loss: 0.2077483981847763
train-epoch-step: 29-264 -- Loss: 0.17751209437847137
train-epoch-step: 29-265 -- Loss: 0.13545548915863037
train-epoch-step: 29-266 -- Loss: 0.15467728674411774
train-epoch-step: 29-267 -- Loss: 0.12905272841453552
train-epoch-step: 29-268 -- Loss: 0.12076645344495773
train-epoch-step: 29-269 -- Loss: 0.1823579967021942
train-epoch-step: 29-270 -- Loss: 0.11012981086969376
train-epoch-step: 29-271 -- Loss: 0.15305040776729584
train-epoch-step: 29-272 -- Loss: 0.11879859864711761
train-epoch-step: 29-273 -- Loss: 0.1282944530248642
train-epoch-step: 29-274 -- Loss: 0.18717069923877716
train-epoch-step: 29-275 -- Loss: 0.21182572841644287
train-epoch-step: 29-276 -- Loss: 0.16717565059661865
train-epoch-step: 29-277 -- Loss: 0.16192422807216644
train-epoch-step: 29-278 -- Loss: 0.1479545533657074
train-epoch-step: 29-279 -- Loss: 0.15315033495426178
train-epoch-step: 29-280 -- Loss: 0.22392410039901733
train-epoch-step: 29-281 -- Loss: 0.1831987351179123
train-epoch-step: 29-282 -- Loss: 0.14502312242984772
train-epoch-step: 29-283 -- Loss: 0.11948707699775696
train-epoch-step: 29-284 -- Loss: 0.1467013955116272
train-epoch-step: 29-285 -- Loss: 0.19178472459316254
train-epoch-step: 29-286 -- Loss: 0.15746429562568665
train-epoch-step: 29-287 -- Loss: 0.20436373353004456
train-epoch-step: 29-288 -- Loss: 0.09584064781665802
train-epoch-step: 29-289 -- Loss: 0.1246136724948883
train-epoch-step: 29-290 -- Loss: 0.18665048480033875
train-epoch-step: 29-291 -- Loss: 0.11771490424871445
train-epoch-step: 29-292 -- Loss: 0.15741196274757385
train-epoch-step: 29-293 -- Loss: 0.1390116959810257
train-epoch-step: 29-294 -- Loss: 0.16353704035282135
train-epoch-step: 29-295 -- Loss: 0.28598552942276
train-epoch-step: 29-296 -- Loss: 0.16262167692184448
train-epoch-step: 29-297 -- Loss: 0.17741967737674713
train-epoch-step: 29-298 -- Loss: 0.2336045503616333
train-epoch-step: 29-299 -- Loss: 0.1486714631319046
train-epoch-step: 29-300 -- Loss: 0.17251642048358917
train-epoch-step: 29-301 -- Loss: 0.18620891869068146
train-epoch-step: 29-302 -- Loss: 0.21814486384391785
train-epoch-step: 29-303 -- Loss: 0.203264981508255
train-epoch-step: 29-304 -- Loss: 0.12964171171188354
train-epoch-step: 29-305 -- Loss: 0.15286575257778168
train-epoch-step: 29-306 -- Loss: 0.24465976655483246
train-epoch-step: 29-307 -- Loss: 0.16829025745391846
train-epoch-step: 29-308 -- Loss: 0.22432297468185425
train-epoch-step: 29-309 -- Loss: 0.15874755382537842
train-epoch-step: 29-310 -- Loss: 0.16682693362236023
train-epoch-step: 29-311 -- Loss: 0.1622011363506317
train-epoch-step: 29-312 -- Loss: 0.20529377460479736
train-epoch-step: 29-313 -- Loss: 0.10062789171934128
train-epoch-step: 29-314 -- Loss: 0.19302068650722504
train-epoch-step: 29-315 -- Loss: 0.17310786247253418
train-epoch-step: 29-316 -- Loss: 0.15358476340770721
train-epoch-step: 29-317 -- Loss: 0.13990433514118195
train-epoch-step: 29-318 -- Loss: 0.16646969318389893
train-epoch-step: 29-319 -- Loss: 0.1743428111076355
train-epoch-step: 29-320 -- Loss: 0.12321339547634125
train-epoch-step: 29-321 -- Loss: 0.13368016481399536
train-epoch-step: 29-322 -- Loss: 0.21891742944717407
train-epoch-step: 29-323 -- Loss: 0.16349945962429047
train-epoch-step: 29-324 -- Loss: 0.256532222032547
train-epoch-step: 29-325 -- Loss: 0.15553925931453705
train-epoch-step: 29-326 -- Loss: 0.17440660297870636
train-epoch-step: 29-327 -- Loss: 0.20236584544181824
train-epoch-step: 29-328 -- Loss: 0.19976499676704407
train-epoch-step: 29-329 -- Loss: 0.34482258558273315
train-epoch-step: 29-330 -- Loss: 0.37096118927001953
train-epoch-step: 29-331 -- Loss: 0.21461188793182373
train-epoch-step: 29-332 -- Loss: 0.10654835402965546
train-epoch-step: 29-333 -- Loss: 0.1934080421924591
train-epoch-step: 29-334 -- Loss: 0.15370501577854156
train-epoch-step: 29-335 -- Loss: 0.1779700666666031
train-epoch-step: 29-336 -- Loss: 0.15900397300720215
train-epoch-step: 29-337 -- Loss: 0.21150152385234833
train-epoch-step: 29-338 -- Loss: 0.16351228952407837
train-epoch-step: 29-339 -- Loss: 0.14408047497272491
train-epoch-step: 29-340 -- Loss: 0.21147051453590393
train-epoch-step: 29-341 -- Loss: 0.13917720317840576
train-epoch-step: 29-342 -- Loss: 0.16886426508426666
train-epoch-step: 29-343 -- Loss: 0.15524475276470184
train-epoch-step: 29-344 -- Loss: 0.17229731380939484
train-epoch-step: 29-345 -- Loss: 0.13123337924480438
train-epoch-step: 29-346 -- Loss: 0.20915450155735016
train-epoch-step: 29-347 -- Loss: 0.15277568995952606
train-epoch-step: 29-348 -- Loss: 0.20405898988246918
train-epoch-step: 29-349 -- Loss: 0.20752859115600586
train-epoch-step: 29-350 -- Loss: 0.2602235674858093
train-epoch-step: 29-351 -- Loss: 0.19535475969314575
train-epoch-step: 29-352 -- Loss: 0.12921807169914246
train-epoch-step: 29-353 -- Loss: 0.2001083940267563
train-epoch-step: 29-354 -- Loss: 0.2854931056499481
train-epoch-step: 29-355 -- Loss: 0.11849306523799896
train-epoch-step: 29-356 -- Loss: 0.11872045695781708
train-epoch-step: 29-357 -- Loss: 0.20254266262054443
train-epoch-step: 29-358 -- Loss: 0.186063751578331
train-epoch-step: 29-359 -- Loss: 0.1406242698431015
train-epoch-step: 29-360 -- Loss: 0.12464030832052231
train-epoch-step: 29-361 -- Loss: 0.23574243485927582
train-epoch-step: 29-362 -- Loss: 0.1758771687746048
train-epoch-step: 29-363 -- Loss: 0.11264222860336304
train-epoch-step: 29-364 -- Loss: 0.18612046539783478
train-epoch-step: 29-365 -- Loss: 0.181332528591156
train-epoch-step: 29-366 -- Loss: 0.21612904965877533
train-epoch-step: 29-367 -- Loss: 0.23334194719791412
train-epoch-step: 29-368 -- Loss: 0.20350351929664612
train-epoch-step: 29-369 -- Loss: 0.2830837666988373
train-epoch-step: 29-370 -- Loss: 0.12559780478477478
train-epoch-step: 29-371 -- Loss: 0.1222231537103653
train-epoch-step: 29-372 -- Loss: 0.15197619795799255
train-epoch-step: 29-373 -- Loss: 0.18674872815608978
train-epoch-step: 29-374 -- Loss: 0.15424159169197083
train-epoch-step: 29-375 -- Loss: 0.26933664083480835
train-epoch-step: 29-376 -- Loss: 0.16324761509895325
train-epoch-step: 29-377 -- Loss: 0.2380276620388031
train-epoch-step: 29-378 -- Loss: 0.20453302562236786
train-epoch-step: 29-379 -- Loss: 0.12630318105220795
train-epoch-step: 29-380 -- Loss: 0.09310361742973328
train-epoch-step: 29-381 -- Loss: 0.24868100881576538
train-epoch-step: 29-382 -- Loss: 0.24407526850700378
train-epoch-step: 29-383 -- Loss: 0.18491113185882568
train-epoch-step: 29-384 -- Loss: 0.23805485665798187
train-epoch-step: 29-385 -- Loss: 0.1990090310573578
train-epoch-step: 29-386 -- Loss: 0.19212877750396729
train-epoch-step: 29-387 -- Loss: 0.20722882449626923
train-epoch-step: 29-388 -- Loss: 0.20764416456222534
train-epoch-step: 29-389 -- Loss: 0.16819587349891663
train-epoch-step: 29-390 -- Loss: 0.15473584830760956
train-epoch-step: 29-391 -- Loss: 0.1484064757823944
train-epoch-step: 29-392 -- Loss: 0.18616408109664917
train-epoch-step: 29-393 -- Loss: 0.15958935022354126
train-epoch-step: 29-394 -- Loss: 0.21495920419692993
train-epoch-step: 29-395 -- Loss: 0.16456803679466248
train-epoch-step: 29-396 -- Loss: 0.12892135977745056
train-epoch-step: 29-397 -- Loss: 0.1271846890449524
train-epoch-step: 29-398 -- Loss: 0.20229072868824005
train-epoch-step: 29-399 -- Loss: 0.17975538969039917
train-epoch-step: 29-400 -- Loss: 0.2871573865413666
train-epoch-step: 29-401 -- Loss: 0.11915460228919983
train-epoch-step: 29-402 -- Loss: 0.26181817054748535
train-epoch-step: 29-403 -- Loss: 0.15688584744930267
train-epoch-step: 29-404 -- Loss: 0.14089323580265045
train-epoch-step: 29-405 -- Loss: 0.14536675810813904
train-epoch-step: 29-406 -- Loss: 0.18156923353672028
train-epoch-step: 29-407 -- Loss: 0.1170637235045433
train-epoch-step: 29-408 -- Loss: 0.16263282299041748
train-epoch-step: 29-409 -- Loss: 0.17234933376312256
train-epoch-step: 29-410 -- Loss: 0.18337132036685944
train-epoch-step: 29-411 -- Loss: 0.2180652916431427
train-epoch-step: 29-412 -- Loss: 0.13022162020206451
train-epoch-step: 29-413 -- Loss: 0.1489599347114563
train-epoch-step: 29-414 -- Loss: 0.13849282264709473
train-epoch-step: 29-415 -- Loss: 0.13615599274635315
train-epoch-step: 29-416 -- Loss: 0.2652440369129181
train-epoch-step: 29-417 -- Loss: 0.19847875833511353
train-epoch-step: 29-418 -- Loss: 0.23703627288341522
train-epoch-step: 29-419 -- Loss: 0.17168107628822327
train-epoch-step: 29-420 -- Loss: 0.15651360154151917
train-epoch-step: 29-421 -- Loss: 0.18432004749774933
train-epoch-step: 29-422 -- Loss: 0.15380163490772247
train-epoch-step: 29-423 -- Loss: 0.1867028921842575
train-epoch-step: 29-424 -- Loss: 0.13885974884033203
train-epoch-step: 29-425 -- Loss: 0.18829987943172455
train-epoch-step: 29-426 -- Loss: 0.15943819284439087
train-epoch-step: 29-427 -- Loss: 0.12864765524864197
train-epoch-step: 29-428 -- Loss: 0.21389919519424438
train-epoch-step: 29-429 -- Loss: 0.1758328676223755
train-epoch-step: 29-430 -- Loss: 0.14309564232826233
train-epoch-step: 29-431 -- Loss: 0.18439574539661407
train-epoch-step: 29-432 -- Loss: 0.24647530913352966
train-epoch-step: 29-433 -- Loss: 0.1407468616962433
train-epoch-step: 29-434 -- Loss: 0.1351282000541687
train-epoch-step: 29-435 -- Loss: 0.16305573284626007
train-epoch-step: 29-436 -- Loss: 0.1704009771347046
train-epoch-step: 29-437 -- Loss: 0.13364076614379883
train-epoch-step: 29-438 -- Loss: 0.17230913043022156
train-epoch-step: 29-439 -- Loss: 0.2703494131565094
train-epoch-step: 29-440 -- Loss: 0.13344824314117432
train-epoch-step: 29-441 -- Loss: 0.20438513159751892
train-epoch-step: 29-442 -- Loss: 0.18353724479675293
train-epoch-step: 29-443 -- Loss: 0.1555403769016266
train-epoch-step: 29-444 -- Loss: 0.17340496182441711
train-epoch-step: 29-445 -- Loss: 0.18406985700130463
train-epoch-step: 29-446 -- Loss: 0.15448209643363953
train-epoch-step: 29-447 -- Loss: 0.19915512204170227
train-epoch-step: 29-448 -- Loss: 0.22735054790973663
train-epoch-step: 29-449 -- Loss: 0.19163450598716736
train-epoch-step: 29-450 -- Loss: 0.18562205135822296
train-epoch-step: 29-451 -- Loss: 0.14255958795547485
train-epoch-step: 29-452 -- Loss: 0.1382046788930893
train-epoch-step: 29-453 -- Loss: 0.09517115354537964
train-epoch-step: 29-454 -- Loss: 0.2388366311788559
train-epoch-step: 29-455 -- Loss: 0.1309814155101776
train-epoch-step: 29-456 -- Loss: 0.12389650195837021
train-epoch-step: 29-457 -- Loss: 0.21635255217552185
train-epoch-step: 29-458 -- Loss: 0.1528415083885193
train-epoch-step: 29-459 -- Loss: 0.221498042345047
train-epoch-step: 29-460 -- Loss: 0.12582752108573914
train-epoch-step: 29-461 -- Loss: 0.13724437355995178
train-epoch-step: 29-462 -- Loss: 0.1653078943490982
train-epoch-step: 29-463 -- Loss: 0.13697533309459686
train-epoch-step: 29-464 -- Loss: 0.16785243153572083
train-epoch-step: 29-465 -- Loss: 0.245408296585083
train-epoch-step: 29-466 -- Loss: 0.20344793796539307
train-epoch-step: 29-467 -- Loss: 0.11464911699295044
train-epoch-step: 29-468 -- Loss: 0.17216713726520538
train-epoch-step: 29-469 -- Loss: 0.21709318459033966
train-epoch-step: 29-470 -- Loss: 0.19204145669937134
train-epoch-step: 29-471 -- Loss: 0.15555523335933685
train-epoch-step: 29-472 -- Loss: 0.15624834597110748
train-epoch-step: 29-473 -- Loss: 0.16166254878044128
train-epoch-step: 29-474 -- Loss: 0.1210499182343483
train-epoch-step: 29-475 -- Loss: 0.11043284833431244
train-epoch-step: 29-476 -- Loss: 0.20691902935504913
train-epoch-step: 29-477 -- Loss: 0.20146796107292175
train-epoch-step: 29-478 -- Loss: 0.19680625200271606
train-epoch-step: 29-479 -- Loss: 0.14036068320274353
train-epoch-step: 29-480 -- Loss: 0.1935577690601349
train-epoch-step: 29-481 -- Loss: 0.2803821563720703
train-epoch-step: 29-482 -- Loss: 0.25812020897865295
train-epoch-step: 29-483 -- Loss: 0.18066856265068054
train-epoch-step: 29-484 -- Loss: 0.2162308692932129
train-epoch-step: 29-485 -- Loss: 0.12999793887138367
train-epoch-step: 29-486 -- Loss: 0.23721280694007874
train-epoch-step: 29-487 -- Loss: 0.23446333408355713
train-epoch-step: 29-488 -- Loss: 0.18891648948192596
train-epoch-step: 29-489 -- Loss: 0.2194591611623764
train-epoch-step: 29-490 -- Loss: 0.14062844216823578
train-epoch-step: 29-491 -- Loss: 0.13681522011756897
train-epoch-step: 29-492 -- Loss: 0.12702082097530365
train-epoch-step: 29-493 -- Loss: 0.20681318640708923
train-epoch-step: 29-494 -- Loss: 0.2081267535686493
train-epoch-step: 29-495 -- Loss: 0.20170721411705017
train-epoch-step: 29-496 -- Loss: 0.13998334109783173
train-epoch-step: 29-497 -- Loss: 0.18368308246135712
train-epoch-step: 29-498 -- Loss: 0.1510607898235321
train-epoch-step: 29-499 -- Loss: 0.1731959581375122
train-epoch-step: 29-500 -- Loss: 0.15729907155036926
train-epoch-step: 29-501 -- Loss: 0.21658456325531006
train-epoch-step: 29-502 -- Loss: 0.15638937056064606
train-epoch-step: 29-503 -- Loss: 0.22372983396053314
train-epoch-step: 29-504 -- Loss: 0.1264006793498993
train-epoch-step: 29-505 -- Loss: 0.17035548388957977
train-epoch-step: 29-506 -- Loss: 0.1184830442070961
train-epoch-step: 29-507 -- Loss: 0.18779312074184418
train-epoch-step: 29-508 -- Loss: 0.1765977144241333
train-epoch-step: 29-509 -- Loss: 0.17093516886234283
train-epoch-step: 29-510 -- Loss: 0.13563108444213867
train-epoch-step: 29-511 -- Loss: 0.21743345260620117
train-epoch-step: 29-512 -- Loss: 0.17510917782783508
train-epoch-step: 29-513 -- Loss: 0.19618317484855652
train-epoch-step: 29-514 -- Loss: 0.14802461862564087
train-epoch-step: 29-515 -- Loss: 0.16496729850769043
train-epoch-step: 29-516 -- Loss: 0.1728494018316269
train-epoch-step: 29-517 -- Loss: 0.17374096810817719
train-epoch-step: 29-518 -- Loss: 0.1378530114889145
train-epoch-step: 29-519 -- Loss: 0.13542036712169647
train-epoch-step: 29-520 -- Loss: 0.1886449158191681
train-epoch-step: 29-521 -- Loss: 0.2307153344154358
train-epoch-step: 29-522 -- Loss: 0.17931470274925232
train-epoch-step: 29-523 -- Loss: 0.16023308038711548
train-epoch-step: 29-524 -- Loss: 0.17001788318157196
train-epoch-step: 29-525 -- Loss: 0.18880659341812134
train-epoch-step: 29-526 -- Loss: 0.1323452740907669
train-epoch-step: 29-527 -- Loss: 0.15563811361789703
train-epoch-step: 29-528 -- Loss: 0.15911640226840973
train-epoch-step: 29-529 -- Loss: 0.1613440364599228
train-epoch-step: 29-530 -- Loss: 0.17028333246707916
train-epoch-step: 29-531 -- Loss: 0.21697916090488434
train-epoch-step: 29-532 -- Loss: 0.176473006606102
train-epoch-step: 29-533 -- Loss: 0.17840181291103363
train-epoch-step: 29-534 -- Loss: 0.13044767081737518
train-epoch-step: 29-535 -- Loss: 0.28988155722618103
train-epoch-step: 29-536 -- Loss: 0.16563117504119873
train-epoch-step: 29-537 -- Loss: 0.15041598677635193
train-epoch-step: 29-538 -- Loss: 0.10575802624225616
train-epoch-step: 29-539 -- Loss: 0.19115060567855835
train-epoch-step: 29-540 -- Loss: 0.14128148555755615
train-epoch-step: 29-541 -- Loss: 0.20759527385234833
train-epoch-step: 29-542 -- Loss: 0.24450832605361938
train-epoch-step: 29-543 -- Loss: 0.17280219495296478
train-epoch-step: 29-544 -- Loss: 0.2331375926733017
train-epoch-step: 29-545 -- Loss: 0.1939316838979721
train-epoch-step: 29-546 -- Loss: 0.22892718017101288
train-epoch-step: 29-547 -- Loss: 0.18450967967510223
train-epoch-step: 29-548 -- Loss: 0.09615860879421234
train-epoch-step: 29-549 -- Loss: 0.15598049759864807
train-epoch-step: 29-550 -- Loss: 0.20176373422145844
train-epoch-step: 29-551 -- Loss: 0.16040459275245667
train-epoch-step: 29-552 -- Loss: 0.1326054185628891
train-epoch-step: 29-553 -- Loss: 0.19879215955734253
train-epoch-step: 29-554 -- Loss: 0.1944909244775772
train-epoch-step: 29-555 -- Loss: 0.216934472322464
train-epoch-step: 29-556 -- Loss: 0.15927375853061676
train-epoch-step: 29-557 -- Loss: 0.25002965331077576
train-epoch-step: 29-558 -- Loss: 0.2310827076435089
train-epoch-step: 29-559 -- Loss: 0.14758911728858948
train-epoch-step: 29-560 -- Loss: 0.20721444487571716
train-epoch-step: 29-561 -- Loss: 0.18704763054847717
train-epoch-step: 29-562 -- Loss: 0.16729365289211273
train-epoch-step: 29-563 -- Loss: 0.18867868185043335
train-epoch-step: 29-564 -- Loss: 0.10118866711854935
train-epoch-step: 29-565 -- Loss: 0.1879911571741104
train-epoch-step: 29-566 -- Loss: 0.15617159008979797
train-epoch-step: 29-567 -- Loss: 0.22265443205833435
train-epoch-step: 29-568 -- Loss: 0.16275866329669952
train-epoch-step: 29-569 -- Loss: 0.26054060459136963
train-epoch-step: 29-570 -- Loss: 0.18608680367469788
train-epoch-step: 29-571 -- Loss: 0.2174389362335205
train-epoch-step: 29-572 -- Loss: 0.23943917453289032
train-epoch-step: 29-573 -- Loss: 0.2052687704563141
train-epoch-step: 29-574 -- Loss: 0.25916987657546997
train-epoch-step: 29-575 -- Loss: 0.3186788260936737
train-epoch-step: 29-576 -- Loss: 0.12372013926506042
train-epoch-step: 29-577 -- Loss: 0.18358755111694336
train-epoch-step: 29-578 -- Loss: 0.21951550245285034
train-epoch-step: 29-579 -- Loss: 0.17243771255016327
train-epoch-step: 29-580 -- Loss: 0.17861351370811462
train-epoch-step: 29-581 -- Loss: 0.14355696737766266
train-epoch-step: 29-582 -- Loss: 0.20957297086715698
train-epoch-step: 29-583 -- Loss: 0.22980746626853943
train-epoch-step: 29-584 -- Loss: 0.1701052039861679
train-epoch-step: 29-585 -- Loss: 0.19550567865371704
train-epoch-step: 29-586 -- Loss: 0.2554047107696533
train-epoch-step: 29-587 -- Loss: 0.16313835978507996
train-epoch-step: 29-588 -- Loss: 0.12923181056976318
val-epoch-step: 29-589 -- Loss: 0.2079666256904602
val-epoch-step: 29-590 -- Loss: 0.1548331081867218
val-epoch-step: 29-591 -- Loss: 0.22988072037696838
val-epoch-step: 29-592 -- Loss: 0.1783449649810791
val-epoch-step: 29-593 -- Loss: 0.16389699280261993
val-epoch-step: 29-594 -- Loss: 0.48064371943473816
val-epoch-step: 29-595 -- Loss: 0.21442976593971252
val-epoch-step: 29-596 -- Loss: 0.20140743255615234
val-epoch-step: 29-597 -- Loss: 0.18145647644996643
val-epoch-step: 29-598 -- Loss: 0.15139351785182953
val-epoch-step: 29-599 -- Loss: 0.18755777180194855
val-epoch-step: 29-600 -- Loss: 0.22876101732254028
val-epoch-step: 29-601 -- Loss: 0.1526668667793274
val-epoch-step: 29-602 -- Loss: 0.1371750831604004
val-epoch-step: 29-603 -- Loss: 0.19200310111045837
val-epoch-step: 29-604 -- Loss: 0.1521565020084381
val-epoch-step: 29-605 -- Loss: 0.14974293112754822
val-epoch-step: 29-606 -- Loss: 0.26555025577545166
val-epoch-step: 29-607 -- Loss: 0.13323216140270233
val-epoch-step: 29-608 -- Loss: 0.2519507110118866
val-epoch-step: 29-609 -- Loss: 0.16970780491828918
val-epoch-step: 29-610 -- Loss: 0.18686744570732117
val-epoch-step: 29-611 -- Loss: 0.20395517349243164
val-epoch-step: 29-612 -- Loss: 0.4882408678531647
val-epoch-step: 29-613 -- Loss: 0.17559963464736938
val-epoch-step: 29-614 -- Loss: 0.1797347366809845
val-epoch-step: 29-615 -- Loss: 0.17894889414310455
val-epoch-step: 29-616 -- Loss: 0.14913761615753174
val-epoch-step: 29-617 -- Loss: 0.18751689791679382
val-epoch-step: 29-618 -- Loss: 0.18517915904521942
val-epoch-step: 29-619 -- Loss: 0.23657548427581787
val-epoch-step: 29-620 -- Loss: 0.14143438637256622
val-epoch-step: 29-621 -- Loss: 0.17426517605781555
val-epoch-step: 29-622 -- Loss: 0.14660495519638062
val-epoch-step: 29-623 -- Loss: 0.15716497600078583
val-epoch-step: 29-624 -- Loss: 0.14686545729637146
val-epoch-step: 29-625 -- Loss: 0.1617460995912552
val-epoch-step: 29-626 -- Loss: 0.15554353594779968
val-epoch-step: 29-627 -- Loss: 0.18807032704353333
val-epoch-step: 29-628 -- Loss: 0.7488417625427246
val-epoch-step: 29-629 -- Loss: 0.22021764516830444
val-epoch-step: 29-630 -- Loss: 0.35307690501213074
val-epoch-step: 29-631 -- Loss: 0.14297771453857422
val-epoch-step: 29-632 -- Loss: 0.21326583623886108
val-epoch-step: 29-633 -- Loss: 0.15587583184242249
val-epoch-step: 29-634 -- Loss: 0.13665948808193207
val-epoch-step: 29-635 -- Loss: 0.1130933091044426
val-epoch-step: 29-636 -- Loss: 0.16812273859977722
val-epoch-step: 29-637 -- Loss: 0.18546080589294434
val-epoch-step: 29-638 -- Loss: 0.16438616812229156
val-epoch-step: 29-639 -- Loss: 0.2678040862083435
val-epoch-step: 29-640 -- Loss: 0.2705005705356598
val-epoch-step: 29-641 -- Loss: 0.12917813658714294
val-epoch-step: 29-642 -- Loss: 0.19707456231117249
val-epoch-step: 29-643 -- Loss: 0.21446774899959564
val-epoch-step: 29-644 -- Loss: 0.16903004050254822
val-epoch-step: 29-645 -- Loss: 0.22386804223060608
val-epoch-step: 29-646 -- Loss: 0.14447803795337677
val-epoch-step: 29-647 -- Loss: 0.13327953219413757
val-epoch-step: 29-648 -- Loss: 0.16174305975437164
val-epoch-step: 29-649 -- Loss: 0.20957358181476593
val-epoch-step: 29-650 -- Loss: 0.26107266545295715
val-epoch-step: 29-651 -- Loss: 0.15448345243930817
val-epoch-step: 29-652 -- Loss: 0.1572979837656021
val-epoch-step: 29-653 -- Loss: 0.20897525548934937
val-epoch-step: 29-654 -- Loss: 0.11479774117469788
Epoch: 29 -- Train Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1443, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 30-0 -- Loss: 0.22800958156585693
train-epoch-step: 30-1 -- Loss: 0.14698904752731323
train-epoch-step: 30-2 -- Loss: 0.20239141583442688
train-epoch-step: 30-3 -- Loss: 0.1452122926712036
train-epoch-step: 30-4 -- Loss: 0.15955869853496552
train-epoch-step: 30-5 -- Loss: 0.19453397393226624
train-epoch-step: 30-6 -- Loss: 0.2336479127407074
train-epoch-step: 30-7 -- Loss: 0.1694124937057495
train-epoch-step: 30-8 -- Loss: 0.1921806037425995
train-epoch-step: 30-9 -- Loss: 0.2368239462375641
train-epoch-step: 30-10 -- Loss: 0.20272982120513916
train-epoch-step: 30-11 -- Loss: 0.1758277714252472
train-epoch-step: 30-12 -- Loss: 0.15338973701000214
train-epoch-step: 30-13 -- Loss: 0.183008074760437
train-epoch-step: 30-14 -- Loss: 0.16985464096069336
train-epoch-step: 30-15 -- Loss: 0.16355392336845398
train-epoch-step: 30-16 -- Loss: 0.17601634562015533
train-epoch-step: 30-17 -- Loss: 0.2280185967683792
train-epoch-step: 30-18 -- Loss: 0.20135118067264557
train-epoch-step: 30-19 -- Loss: 0.1348751187324524
train-epoch-step: 30-20 -- Loss: 0.2169499695301056
train-epoch-step: 30-21 -- Loss: 0.25648462772369385
train-epoch-step: 30-22 -- Loss: 0.14825385808944702
train-epoch-step: 30-23 -- Loss: 0.14643560349941254
train-epoch-step: 30-24 -- Loss: 0.12979654967784882
train-epoch-step: 30-25 -- Loss: 0.2579442262649536
train-epoch-step: 30-26 -- Loss: 0.19211938977241516
train-epoch-step: 30-27 -- Loss: 0.2537326216697693
train-epoch-step: 30-28 -- Loss: 0.12698379158973694
train-epoch-step: 30-29 -- Loss: 0.25145223736763
train-epoch-step: 30-30 -- Loss: 0.11219964176416397
train-epoch-step: 30-31 -- Loss: 0.1582561433315277
train-epoch-step: 30-32 -- Loss: 0.18141978979110718
train-epoch-step: 30-33 -- Loss: 0.2842448353767395
train-epoch-step: 30-34 -- Loss: 0.17376068234443665
train-epoch-step: 30-35 -- Loss: 0.254257470369339
train-epoch-step: 30-36 -- Loss: 0.13859446346759796
train-epoch-step: 30-37 -- Loss: 0.14160355925559998
train-epoch-step: 30-38 -- Loss: 0.18512125313282013
train-epoch-step: 30-39 -- Loss: 0.22470460832118988
train-epoch-step: 30-40 -- Loss: 0.21595317125320435
train-epoch-step: 30-41 -- Loss: 0.21793252229690552
train-epoch-step: 30-42 -- Loss: 0.15141454339027405
train-epoch-step: 30-43 -- Loss: 0.2857106029987335
train-epoch-step: 30-44 -- Loss: 0.13086578249931335
train-epoch-step: 30-45 -- Loss: 0.12017901241779327
train-epoch-step: 30-46 -- Loss: 0.17912164330482483
train-epoch-step: 30-47 -- Loss: 0.21844837069511414
train-epoch-step: 30-48 -- Loss: 0.1554740071296692
train-epoch-step: 30-49 -- Loss: 0.23518425226211548
train-epoch-step: 30-50 -- Loss: 0.11578971147537231
train-epoch-step: 30-51 -- Loss: 0.18224576115608215
train-epoch-step: 30-52 -- Loss: 0.15955068171024323
train-epoch-step: 30-53 -- Loss: 0.2194395661354065
train-epoch-step: 30-54 -- Loss: 0.2899535894393921
train-epoch-step: 30-55 -- Loss: 0.17484399676322937
train-epoch-step: 30-56 -- Loss: 0.18491975963115692
train-epoch-step: 30-57 -- Loss: 0.23759454488754272
train-epoch-step: 30-58 -- Loss: 0.28104692697525024
train-epoch-step: 30-59 -- Loss: 0.25492024421691895
train-epoch-step: 30-60 -- Loss: 0.13311749696731567
train-epoch-step: 30-61 -- Loss: 0.20127469301223755
train-epoch-step: 30-62 -- Loss: 0.18778251111507416
train-epoch-step: 30-63 -- Loss: 0.14475120604038239
train-epoch-step: 30-64 -- Loss: 0.14552468061447144
train-epoch-step: 30-65 -- Loss: 0.18067432940006256
train-epoch-step: 30-66 -- Loss: 0.11444651335477829
train-epoch-step: 30-67 -- Loss: 0.13068152964115143
train-epoch-step: 30-68 -- Loss: 0.21943281590938568
train-epoch-step: 30-69 -- Loss: 0.12618955969810486
train-epoch-step: 30-70 -- Loss: 0.23077286779880524
train-epoch-step: 30-71 -- Loss: 0.2575985789299011
train-epoch-step: 30-72 -- Loss: 0.17880961298942566
train-epoch-step: 30-73 -- Loss: 0.20979709923267365
train-epoch-step: 30-74 -- Loss: 0.09862282127141953
train-epoch-step: 30-75 -- Loss: 0.12808085978031158
train-epoch-step: 30-76 -- Loss: 0.1490664780139923
train-epoch-step: 30-77 -- Loss: 0.23033086955547333
train-epoch-step: 30-78 -- Loss: 0.2624877989292145
train-epoch-step: 30-79 -- Loss: 0.19111984968185425
train-epoch-step: 30-80 -- Loss: 0.2513912320137024
train-epoch-step: 30-81 -- Loss: 0.13099882006645203
train-epoch-step: 30-82 -- Loss: 0.2542302906513214
train-epoch-step: 30-83 -- Loss: 0.1801975518465042
train-epoch-step: 30-84 -- Loss: 0.1922301948070526
train-epoch-step: 30-85 -- Loss: 0.1761098951101303
train-epoch-step: 30-86 -- Loss: 0.13242439925670624
train-epoch-step: 30-87 -- Loss: 0.22380855679512024
train-epoch-step: 30-88 -- Loss: 0.1450597047805786
train-epoch-step: 30-89 -- Loss: 0.18656891584396362
train-epoch-step: 30-90 -- Loss: 0.19672931730747223
train-epoch-step: 30-91 -- Loss: 0.25779756903648376
train-epoch-step: 30-92 -- Loss: 0.15498965978622437
train-epoch-step: 30-93 -- Loss: 0.17178049683570862
train-epoch-step: 30-94 -- Loss: 0.22060933709144592
train-epoch-step: 30-95 -- Loss: 0.19290751218795776
train-epoch-step: 30-96 -- Loss: 0.22202008962631226
train-epoch-step: 30-97 -- Loss: 0.17622710764408112
train-epoch-step: 30-98 -- Loss: 0.1530693918466568
train-epoch-step: 30-99 -- Loss: 0.17964401841163635
train-epoch-step: 30-100 -- Loss: 0.1861714869737625
train-epoch-step: 30-101 -- Loss: 0.28027012944221497
train-epoch-step: 30-102 -- Loss: 0.22186432778835297
train-epoch-step: 30-103 -- Loss: 0.18750768899917603
train-epoch-step: 30-104 -- Loss: 0.1491554230451584
train-epoch-step: 30-105 -- Loss: 0.281810998916626
train-epoch-step: 30-106 -- Loss: 0.1772715151309967
train-epoch-step: 30-107 -- Loss: 0.18808613717556
train-epoch-step: 30-108 -- Loss: 0.1871132254600525
train-epoch-step: 30-109 -- Loss: 0.149307981133461
train-epoch-step: 30-110 -- Loss: 0.18264932930469513
train-epoch-step: 30-111 -- Loss: 0.17787829041481018
train-epoch-step: 30-112 -- Loss: 0.16862960159778595
train-epoch-step: 30-113 -- Loss: 0.16134385764598846
train-epoch-step: 30-114 -- Loss: 0.20013120770454407
train-epoch-step: 30-115 -- Loss: 0.16629460453987122
train-epoch-step: 30-116 -- Loss: 0.14201125502586365
train-epoch-step: 30-117 -- Loss: 0.12909089028835297
train-epoch-step: 30-118 -- Loss: 0.19421106576919556
train-epoch-step: 30-119 -- Loss: 0.15558405220508575
train-epoch-step: 30-120 -- Loss: 0.25033819675445557
train-epoch-step: 30-121 -- Loss: 0.23395700752735138
train-epoch-step: 30-122 -- Loss: 0.21975095570087433
train-epoch-step: 30-123 -- Loss: 0.2074565291404724
train-epoch-step: 30-124 -- Loss: 0.12765128910541534
train-epoch-step: 30-125 -- Loss: 0.15843944251537323
train-epoch-step: 30-126 -- Loss: 0.23045432567596436
train-epoch-step: 30-127 -- Loss: 0.17754831910133362
train-epoch-step: 30-128 -- Loss: 0.16967996954917908
train-epoch-step: 30-129 -- Loss: 0.1458553671836853
train-epoch-step: 30-130 -- Loss: 0.19052308797836304
train-epoch-step: 30-131 -- Loss: 0.13723458349704742
train-epoch-step: 30-132 -- Loss: 0.19951148331165314
train-epoch-step: 30-133 -- Loss: 0.12631186842918396
train-epoch-step: 30-134 -- Loss: 0.2169077843427658
train-epoch-step: 30-135 -- Loss: 0.14235177636146545
train-epoch-step: 30-136 -- Loss: 0.13378456234931946
train-epoch-step: 30-137 -- Loss: 0.2468959093093872
train-epoch-step: 30-138 -- Loss: 0.26879212260246277
train-epoch-step: 30-139 -- Loss: 0.13106828927993774
train-epoch-step: 30-140 -- Loss: 0.21282178163528442
train-epoch-step: 30-141 -- Loss: 0.24388566613197327
train-epoch-step: 30-142 -- Loss: 0.2080996036529541
train-epoch-step: 30-143 -- Loss: 0.18418237566947937
train-epoch-step: 30-144 -- Loss: 0.184624582529068
train-epoch-step: 30-145 -- Loss: 0.1405874341726303
train-epoch-step: 30-146 -- Loss: 0.18052619695663452
train-epoch-step: 30-147 -- Loss: 0.17316313087940216
train-epoch-step: 30-148 -- Loss: 0.1617117077112198
train-epoch-step: 30-149 -- Loss: 0.12714214622974396
train-epoch-step: 30-150 -- Loss: 0.19105173647403717
train-epoch-step: 30-151 -- Loss: 0.21905934810638428
train-epoch-step: 30-152 -- Loss: 0.1947592943906784
train-epoch-step: 30-153 -- Loss: 0.2723742425441742
train-epoch-step: 30-154 -- Loss: 0.13698187470436096
train-epoch-step: 30-155 -- Loss: 0.13578952848911285
train-epoch-step: 30-156 -- Loss: 0.11904256790876389
train-epoch-step: 30-157 -- Loss: 0.17262233793735504
train-epoch-step: 30-158 -- Loss: 0.17150187492370605
train-epoch-step: 30-159 -- Loss: 0.1805616021156311
train-epoch-step: 30-160 -- Loss: 0.23037612438201904
train-epoch-step: 30-161 -- Loss: 0.20874929428100586
train-epoch-step: 30-162 -- Loss: 0.21982839703559875
train-epoch-step: 30-163 -- Loss: 0.19082704186439514
train-epoch-step: 30-164 -- Loss: 0.19349601864814758
train-epoch-step: 30-165 -- Loss: 0.17822393774986267
train-epoch-step: 30-166 -- Loss: 0.12139400839805603
train-epoch-step: 30-167 -- Loss: 0.12664327025413513
train-epoch-step: 30-168 -- Loss: 0.20182080566883087
train-epoch-step: 30-169 -- Loss: 0.1494400054216385
train-epoch-step: 30-170 -- Loss: 0.2015075981616974
train-epoch-step: 30-171 -- Loss: 0.14800967276096344
train-epoch-step: 30-172 -- Loss: 0.2680817246437073
train-epoch-step: 30-173 -- Loss: 0.14433443546295166
train-epoch-step: 30-174 -- Loss: 0.2514689266681671
train-epoch-step: 30-175 -- Loss: 0.1871870458126068
train-epoch-step: 30-176 -- Loss: 0.14748303592205048
train-epoch-step: 30-177 -- Loss: 0.1847216933965683
train-epoch-step: 30-178 -- Loss: 0.18422876298427582
train-epoch-step: 30-179 -- Loss: 0.15260660648345947
train-epoch-step: 30-180 -- Loss: 0.16166849434375763
train-epoch-step: 30-181 -- Loss: 0.1694801300764084
train-epoch-step: 30-182 -- Loss: 0.18422657251358032
train-epoch-step: 30-183 -- Loss: 0.27428770065307617
train-epoch-step: 30-184 -- Loss: 0.14327995479106903
train-epoch-step: 30-185 -- Loss: 0.14105916023254395
train-epoch-step: 30-186 -- Loss: 0.19730783998966217
train-epoch-step: 30-187 -- Loss: 0.2105264961719513
train-epoch-step: 30-188 -- Loss: 0.17259235680103302
train-epoch-step: 30-189 -- Loss: 0.1106102392077446
train-epoch-step: 30-190 -- Loss: 0.18372966349124908
train-epoch-step: 30-191 -- Loss: 0.16311591863632202
train-epoch-step: 30-192 -- Loss: 0.23508675396442413
train-epoch-step: 30-193 -- Loss: 0.21409660577774048
train-epoch-step: 30-194 -- Loss: 0.19233985245227814
train-epoch-step: 30-195 -- Loss: 0.16802039742469788
train-epoch-step: 30-196 -- Loss: 0.1753970980644226
train-epoch-step: 30-197 -- Loss: 0.14135754108428955
train-epoch-step: 30-198 -- Loss: 0.1299646645784378
train-epoch-step: 30-199 -- Loss: 0.15389660000801086
train-epoch-step: 30-200 -- Loss: 0.1271013468503952
train-epoch-step: 30-201 -- Loss: 0.19579708576202393
train-epoch-step: 30-202 -- Loss: 0.13954268395900726
train-epoch-step: 30-203 -- Loss: 0.17836520075798035
train-epoch-step: 30-204 -- Loss: 0.1535128951072693
train-epoch-step: 30-205 -- Loss: 0.1911052167415619
train-epoch-step: 30-206 -- Loss: 0.20234151184558868
train-epoch-step: 30-207 -- Loss: 0.1379036009311676
train-epoch-step: 30-208 -- Loss: 0.17766927182674408
train-epoch-step: 30-209 -- Loss: 0.14509963989257812
train-epoch-step: 30-210 -- Loss: 0.1324051469564438
train-epoch-step: 30-211 -- Loss: 0.21200431883335114
train-epoch-step: 30-212 -- Loss: 0.20210625231266022
train-epoch-step: 30-213 -- Loss: 0.12858796119689941
train-epoch-step: 30-214 -- Loss: 0.14716403186321259
train-epoch-step: 30-215 -- Loss: 0.12753064930438995
train-epoch-step: 30-216 -- Loss: 0.20379503071308136
train-epoch-step: 30-217 -- Loss: 0.22341011464595795
train-epoch-step: 30-218 -- Loss: 0.1489202231168747
train-epoch-step: 30-219 -- Loss: 0.17019079625606537
train-epoch-step: 30-220 -- Loss: 0.13297772407531738
train-epoch-step: 30-221 -- Loss: 0.205522820353508
train-epoch-step: 30-222 -- Loss: 0.12045639008283615
train-epoch-step: 30-223 -- Loss: 0.17659953236579895
train-epoch-step: 30-224 -- Loss: 0.19981828331947327
train-epoch-step: 30-225 -- Loss: 0.27593711018562317
train-epoch-step: 30-226 -- Loss: 0.2084755301475525
train-epoch-step: 30-227 -- Loss: 0.22487308084964752
train-epoch-step: 30-228 -- Loss: 0.17660586535930634
train-epoch-step: 30-229 -- Loss: 0.17452454566955566
train-epoch-step: 30-230 -- Loss: 0.16304811835289001
train-epoch-step: 30-231 -- Loss: 0.1572180539369583
train-epoch-step: 30-232 -- Loss: 0.19320261478424072
train-epoch-step: 30-233 -- Loss: 0.08757642656564713
train-epoch-step: 30-234 -- Loss: 0.1747874766588211
train-epoch-step: 30-235 -- Loss: 0.1529845893383026
train-epoch-step: 30-236 -- Loss: 0.17783629894256592
train-epoch-step: 30-237 -- Loss: 0.24363228678703308
train-epoch-step: 30-238 -- Loss: 0.15828171372413635
train-epoch-step: 30-239 -- Loss: 0.12871718406677246
train-epoch-step: 30-240 -- Loss: 0.23037295043468475
train-epoch-step: 30-241 -- Loss: 0.1572134643793106
train-epoch-step: 30-242 -- Loss: 0.22205808758735657
train-epoch-step: 30-243 -- Loss: 0.23775525391101837
train-epoch-step: 30-244 -- Loss: 0.20382829010486603
train-epoch-step: 30-245 -- Loss: 0.21393659710884094
train-epoch-step: 30-246 -- Loss: 0.2287808656692505
train-epoch-step: 30-247 -- Loss: 0.21800239384174347
train-epoch-step: 30-248 -- Loss: 0.1854148656129837
train-epoch-step: 30-249 -- Loss: 0.1399085968732834
train-epoch-step: 30-250 -- Loss: 0.19972480833530426
train-epoch-step: 30-251 -- Loss: 0.10868909955024719
train-epoch-step: 30-252 -- Loss: 0.1984037309885025
train-epoch-step: 30-253 -- Loss: 0.13673797249794006
train-epoch-step: 30-254 -- Loss: 0.216232031583786
train-epoch-step: 30-255 -- Loss: 0.1493370682001114
train-epoch-step: 30-256 -- Loss: 0.15751492977142334
train-epoch-step: 30-257 -- Loss: 0.1919805407524109
train-epoch-step: 30-258 -- Loss: 0.1492667943239212
train-epoch-step: 30-259 -- Loss: 0.11296924948692322
train-epoch-step: 30-260 -- Loss: 0.20245704054832458
train-epoch-step: 30-261 -- Loss: 0.17582952976226807
train-epoch-step: 30-262 -- Loss: 0.2925666868686676
train-epoch-step: 30-263 -- Loss: 0.20261229574680328
train-epoch-step: 30-264 -- Loss: 0.17665155231952667
train-epoch-step: 30-265 -- Loss: 0.1277046650648117
train-epoch-step: 30-266 -- Loss: 0.15308406949043274
train-epoch-step: 30-267 -- Loss: 0.13011007010936737
train-epoch-step: 30-268 -- Loss: 0.12165646255016327
train-epoch-step: 30-269 -- Loss: 0.17676454782485962
train-epoch-step: 30-270 -- Loss: 0.10740098357200623
train-epoch-step: 30-271 -- Loss: 0.15153451263904572
train-epoch-step: 30-272 -- Loss: 0.11877346783876419
train-epoch-step: 30-273 -- Loss: 0.12427845597267151
train-epoch-step: 30-274 -- Loss: 0.18606087565422058
train-epoch-step: 30-275 -- Loss: 0.20095999538898468
train-epoch-step: 30-276 -- Loss: 0.15631143748760223
train-epoch-step: 30-277 -- Loss: 0.15648239850997925
train-epoch-step: 30-278 -- Loss: 0.14275698363780975
train-epoch-step: 30-279 -- Loss: 0.14457131922245026
train-epoch-step: 30-280 -- Loss: 0.22138135135173798
train-epoch-step: 30-281 -- Loss: 0.18144969642162323
train-epoch-step: 30-282 -- Loss: 0.14509150385856628
train-epoch-step: 30-283 -- Loss: 0.11889424920082092
train-epoch-step: 30-284 -- Loss: 0.1375100016593933
train-epoch-step: 30-285 -- Loss: 0.19969788193702698
train-epoch-step: 30-286 -- Loss: 0.15632176399230957
train-epoch-step: 30-287 -- Loss: 0.20883886516094208
train-epoch-step: 30-288 -- Loss: 0.09568503499031067
train-epoch-step: 30-289 -- Loss: 0.12281577289104462
train-epoch-step: 30-290 -- Loss: 0.18819259107112885
train-epoch-step: 30-291 -- Loss: 0.11899060010910034
train-epoch-step: 30-292 -- Loss: 0.15903089940547943
train-epoch-step: 30-293 -- Loss: 0.13931545615196228
train-epoch-step: 30-294 -- Loss: 0.16378049552440643
train-epoch-step: 30-295 -- Loss: 0.27719825506210327
train-epoch-step: 30-296 -- Loss: 0.15696962177753448
train-epoch-step: 30-297 -- Loss: 0.17714588344097137
train-epoch-step: 30-298 -- Loss: 0.2338457703590393
train-epoch-step: 30-299 -- Loss: 0.1465206742286682
train-epoch-step: 30-300 -- Loss: 0.1692553460597992
train-epoch-step: 30-301 -- Loss: 0.18245717883110046
train-epoch-step: 30-302 -- Loss: 0.21981601417064667
train-epoch-step: 30-303 -- Loss: 0.2055252492427826
train-epoch-step: 30-304 -- Loss: 0.12528857588768005
train-epoch-step: 30-305 -- Loss: 0.1455780267715454
train-epoch-step: 30-306 -- Loss: 0.23475101590156555
train-epoch-step: 30-307 -- Loss: 0.16289713978767395
train-epoch-step: 30-308 -- Loss: 0.22789613902568817
train-epoch-step: 30-309 -- Loss: 0.1580563336610794
train-epoch-step: 30-310 -- Loss: 0.1685103476047516
train-epoch-step: 30-311 -- Loss: 0.17174026370048523
train-epoch-step: 30-312 -- Loss: 0.20833101868629456
train-epoch-step: 30-313 -- Loss: 0.10278356075286865
train-epoch-step: 30-314 -- Loss: 0.19607293605804443
train-epoch-step: 30-315 -- Loss: 0.17266222834587097
train-epoch-step: 30-316 -- Loss: 0.1511208415031433
train-epoch-step: 30-317 -- Loss: 0.13966917991638184
train-epoch-step: 30-318 -- Loss: 0.16215692460536957
train-epoch-step: 30-319 -- Loss: 0.17943859100341797
train-epoch-step: 30-320 -- Loss: 0.12253088504076004
train-epoch-step: 30-321 -- Loss: 0.13680022954940796
train-epoch-step: 30-322 -- Loss: 0.21366561949253082
train-epoch-step: 30-323 -- Loss: 0.16628488898277283
train-epoch-step: 30-324 -- Loss: 0.26785701513290405
train-epoch-step: 30-325 -- Loss: 0.15635673701763153
train-epoch-step: 30-326 -- Loss: 0.17331315577030182
train-epoch-step: 30-327 -- Loss: 0.20771417021751404
train-epoch-step: 30-328 -- Loss: 0.20084528625011444
train-epoch-step: 30-329 -- Loss: 0.34355929493904114
train-epoch-step: 30-330 -- Loss: 0.36829692125320435
train-epoch-step: 30-331 -- Loss: 0.21118120849132538
train-epoch-step: 30-332 -- Loss: 0.10160230100154877
train-epoch-step: 30-333 -- Loss: 0.19175612926483154
train-epoch-step: 30-334 -- Loss: 0.15647199749946594
train-epoch-step: 30-335 -- Loss: 0.1815938502550125
train-epoch-step: 30-336 -- Loss: 0.15245871245861053
train-epoch-step: 30-337 -- Loss: 0.21282118558883667
train-epoch-step: 30-338 -- Loss: 0.16159217059612274
train-epoch-step: 30-339 -- Loss: 0.144134521484375
train-epoch-step: 30-340 -- Loss: 0.19828690588474274
train-epoch-step: 30-341 -- Loss: 0.14540216326713562
train-epoch-step: 30-342 -- Loss: 0.16773293912410736
train-epoch-step: 30-343 -- Loss: 0.15412981808185577
train-epoch-step: 30-344 -- Loss: 0.16767773032188416
train-epoch-step: 30-345 -- Loss: 0.1310463696718216
train-epoch-step: 30-346 -- Loss: 0.21617862582206726
train-epoch-step: 30-347 -- Loss: 0.1528463065624237
train-epoch-step: 30-348 -- Loss: 0.2049732506275177
train-epoch-step: 30-349 -- Loss: 0.21938645839691162
train-epoch-step: 30-350 -- Loss: 0.25581881403923035
train-epoch-step: 30-351 -- Loss: 0.1924062818288803
train-epoch-step: 30-352 -- Loss: 0.1278575360774994
train-epoch-step: 30-353 -- Loss: 0.19540591537952423
train-epoch-step: 30-354 -- Loss: 0.2915722131729126
train-epoch-step: 30-355 -- Loss: 0.11732932925224304
train-epoch-step: 30-356 -- Loss: 0.11841095238924026
train-epoch-step: 30-357 -- Loss: 0.194686159491539
train-epoch-step: 30-358 -- Loss: 0.1887286901473999
train-epoch-step: 30-359 -- Loss: 0.14371949434280396
train-epoch-step: 30-360 -- Loss: 0.12635797262191772
train-epoch-step: 30-361 -- Loss: 0.24452389776706696
train-epoch-step: 30-362 -- Loss: 0.17019781470298767
train-epoch-step: 30-363 -- Loss: 0.12118856608867645
train-epoch-step: 30-364 -- Loss: 0.18379393219947815
train-epoch-step: 30-365 -- Loss: 0.1758929342031479
train-epoch-step: 30-366 -- Loss: 0.21073463559150696
train-epoch-step: 30-367 -- Loss: 0.2331172078847885
train-epoch-step: 30-368 -- Loss: 0.2092239409685135
train-epoch-step: 30-369 -- Loss: 0.2845989763736725
train-epoch-step: 30-370 -- Loss: 0.1301230937242508
train-epoch-step: 30-371 -- Loss: 0.12442508339881897
train-epoch-step: 30-372 -- Loss: 0.1486293375492096
train-epoch-step: 30-373 -- Loss: 0.19158092141151428
train-epoch-step: 30-374 -- Loss: 0.15764205157756805
train-epoch-step: 30-375 -- Loss: 0.27301347255706787
train-epoch-step: 30-376 -- Loss: 0.16794265806674957
train-epoch-step: 30-377 -- Loss: 0.24281322956085205
train-epoch-step: 30-378 -- Loss: 0.19999364018440247
train-epoch-step: 30-379 -- Loss: 0.12555834650993347
train-epoch-step: 30-380 -- Loss: 0.09567313641309738
train-epoch-step: 30-381 -- Loss: 0.24858099222183228
train-epoch-step: 30-382 -- Loss: 0.23784895241260529
train-epoch-step: 30-383 -- Loss: 0.1852215975522995
train-epoch-step: 30-384 -- Loss: 0.24147933721542358
train-epoch-step: 30-385 -- Loss: 0.1930207461118698
train-epoch-step: 30-386 -- Loss: 0.1851779669523239
train-epoch-step: 30-387 -- Loss: 0.207991361618042
train-epoch-step: 30-388 -- Loss: 0.19638733565807343
train-epoch-step: 30-389 -- Loss: 0.16960987448692322
train-epoch-step: 30-390 -- Loss: 0.14810673892498016
train-epoch-step: 30-391 -- Loss: 0.14418412744998932
train-epoch-step: 30-392 -- Loss: 0.18520969152450562
train-epoch-step: 30-393 -- Loss: 0.1588105857372284
train-epoch-step: 30-394 -- Loss: 0.2106439471244812
train-epoch-step: 30-395 -- Loss: 0.16721433401107788
train-epoch-step: 30-396 -- Loss: 0.12959635257720947
train-epoch-step: 30-397 -- Loss: 0.12710990011692047
train-epoch-step: 30-398 -- Loss: 0.2032122164964676
train-epoch-step: 30-399 -- Loss: 0.18419398367404938
train-epoch-step: 30-400 -- Loss: 0.28074222803115845
train-epoch-step: 30-401 -- Loss: 0.12328743189573288
train-epoch-step: 30-402 -- Loss: 0.26020199060440063
train-epoch-step: 30-403 -- Loss: 0.15339064598083496
train-epoch-step: 30-404 -- Loss: 0.14183390140533447
train-epoch-step: 30-405 -- Loss: 0.15109285712242126
train-epoch-step: 30-406 -- Loss: 0.16862276196479797
train-epoch-step: 30-407 -- Loss: 0.11439782381057739
train-epoch-step: 30-408 -- Loss: 0.15904240310192108
train-epoch-step: 30-409 -- Loss: 0.17277228832244873
train-epoch-step: 30-410 -- Loss: 0.18326011300086975
train-epoch-step: 30-411 -- Loss: 0.2085481584072113
train-epoch-step: 30-412 -- Loss: 0.1329403519630432
train-epoch-step: 30-413 -- Loss: 0.1462155431509018
train-epoch-step: 30-414 -- Loss: 0.13529957830905914
train-epoch-step: 30-415 -- Loss: 0.13759826123714447
train-epoch-step: 30-416 -- Loss: 0.26726609468460083
train-epoch-step: 30-417 -- Loss: 0.19305983185768127
train-epoch-step: 30-418 -- Loss: 0.24240759015083313
train-epoch-step: 30-419 -- Loss: 0.1730067878961563
train-epoch-step: 30-420 -- Loss: 0.15895017981529236
train-epoch-step: 30-421 -- Loss: 0.1847454160451889
train-epoch-step: 30-422 -- Loss: 0.15198004245758057
train-epoch-step: 30-423 -- Loss: 0.18053370714187622
train-epoch-step: 30-424 -- Loss: 0.14232923090457916
train-epoch-step: 30-425 -- Loss: 0.1865018606185913
train-epoch-step: 30-426 -- Loss: 0.16511520743370056
train-epoch-step: 30-427 -- Loss: 0.13232123851776123
train-epoch-step: 30-428 -- Loss: 0.20248571038246155
train-epoch-step: 30-429 -- Loss: 0.17768371105194092
train-epoch-step: 30-430 -- Loss: 0.14810767769813538
train-epoch-step: 30-431 -- Loss: 0.1690451204776764
train-epoch-step: 30-432 -- Loss: 0.2383580207824707
train-epoch-step: 30-433 -- Loss: 0.15095798671245575
train-epoch-step: 30-434 -- Loss: 0.13373364508152008
train-epoch-step: 30-435 -- Loss: 0.15698103606700897
train-epoch-step: 30-436 -- Loss: 0.1591304987668991
train-epoch-step: 30-437 -- Loss: 0.13957172632217407
train-epoch-step: 30-438 -- Loss: 0.17302696406841278
train-epoch-step: 30-439 -- Loss: 0.2730756103992462
train-epoch-step: 30-440 -- Loss: 0.13715775310993195
train-epoch-step: 30-441 -- Loss: 0.20472505688667297
train-epoch-step: 30-442 -- Loss: 0.17699991166591644
train-epoch-step: 30-443 -- Loss: 0.15889723598957062
train-epoch-step: 30-444 -- Loss: 0.17493237555027008
train-epoch-step: 30-445 -- Loss: 0.18049265444278717
train-epoch-step: 30-446 -- Loss: 0.15871360898017883
train-epoch-step: 30-447 -- Loss: 0.1906900852918625
train-epoch-step: 30-448 -- Loss: 0.22808882594108582
train-epoch-step: 30-449 -- Loss: 0.19406628608703613
train-epoch-step: 30-450 -- Loss: 0.18846748769283295
train-epoch-step: 30-451 -- Loss: 0.14209222793579102
train-epoch-step: 30-452 -- Loss: 0.13659942150115967
train-epoch-step: 30-453 -- Loss: 0.0911395251750946
train-epoch-step: 30-454 -- Loss: 0.2313593327999115
train-epoch-step: 30-455 -- Loss: 0.12071295082569122
train-epoch-step: 30-456 -- Loss: 0.12191719561815262
train-epoch-step: 30-457 -- Loss: 0.2177693247795105
train-epoch-step: 30-458 -- Loss: 0.1590082049369812
train-epoch-step: 30-459 -- Loss: 0.21483781933784485
train-epoch-step: 30-460 -- Loss: 0.12877225875854492
train-epoch-step: 30-461 -- Loss: 0.13846446573734283
train-epoch-step: 30-462 -- Loss: 0.1667250394821167
train-epoch-step: 30-463 -- Loss: 0.13902533054351807
train-epoch-step: 30-464 -- Loss: 0.1639024317264557
train-epoch-step: 30-465 -- Loss: 0.24304261803627014
train-epoch-step: 30-466 -- Loss: 0.2001374512910843
train-epoch-step: 30-467 -- Loss: 0.11601212620735168
train-epoch-step: 30-468 -- Loss: 0.16956539452075958
train-epoch-step: 30-469 -- Loss: 0.21403631567955017
train-epoch-step: 30-470 -- Loss: 0.1780451536178589
train-epoch-step: 30-471 -- Loss: 0.16581517457962036
train-epoch-step: 30-472 -- Loss: 0.15919309854507446
train-epoch-step: 30-473 -- Loss: 0.15412753820419312
train-epoch-step: 30-474 -- Loss: 0.11956112831830978
train-epoch-step: 30-475 -- Loss: 0.11025752127170563
train-epoch-step: 30-476 -- Loss: 0.20322400331497192
train-epoch-step: 30-477 -- Loss: 0.1989627331495285
train-epoch-step: 30-478 -- Loss: 0.19851034879684448
train-epoch-step: 30-479 -- Loss: 0.14580298960208893
train-epoch-step: 30-480 -- Loss: 0.19755825400352478
train-epoch-step: 30-481 -- Loss: 0.2845357358455658
train-epoch-step: 30-482 -- Loss: 0.2637979984283447
train-epoch-step: 30-483 -- Loss: 0.18222454190254211
train-epoch-step: 30-484 -- Loss: 0.21336063742637634
train-epoch-step: 30-485 -- Loss: 0.12652131915092468
train-epoch-step: 30-486 -- Loss: 0.23543915152549744
train-epoch-step: 30-487 -- Loss: 0.2314663827419281
train-epoch-step: 30-488 -- Loss: 0.19877545535564423
train-epoch-step: 30-489 -- Loss: 0.2210833877325058
train-epoch-step: 30-490 -- Loss: 0.14080850780010223
train-epoch-step: 30-491 -- Loss: 0.1397906243801117
train-epoch-step: 30-492 -- Loss: 0.12624458968639374
train-epoch-step: 30-493 -- Loss: 0.20236548781394958
train-epoch-step: 30-494 -- Loss: 0.21188077330589294
train-epoch-step: 30-495 -- Loss: 0.20441289246082306
train-epoch-step: 30-496 -- Loss: 0.14223115146160126
train-epoch-step: 30-497 -- Loss: 0.19399872422218323
train-epoch-step: 30-498 -- Loss: 0.15747034549713135
train-epoch-step: 30-499 -- Loss: 0.16850046813488007
train-epoch-step: 30-500 -- Loss: 0.16349481046199799
train-epoch-step: 30-501 -- Loss: 0.21468695998191833
train-epoch-step: 30-502 -- Loss: 0.1583583503961563
train-epoch-step: 30-503 -- Loss: 0.2169162631034851
train-epoch-step: 30-504 -- Loss: 0.12222571671009064
train-epoch-step: 30-505 -- Loss: 0.1748640090227127
train-epoch-step: 30-506 -- Loss: 0.11632812023162842
train-epoch-step: 30-507 -- Loss: 0.18412111699581146
train-epoch-step: 30-508 -- Loss: 0.17693430185317993
train-epoch-step: 30-509 -- Loss: 0.17180092632770538
train-epoch-step: 30-510 -- Loss: 0.1283140927553177
train-epoch-step: 30-511 -- Loss: 0.21469563245773315
train-epoch-step: 30-512 -- Loss: 0.17737999558448792
train-epoch-step: 30-513 -- Loss: 0.19716772437095642
train-epoch-step: 30-514 -- Loss: 0.1484340876340866
train-epoch-step: 30-515 -- Loss: 0.1552174836397171
train-epoch-step: 30-516 -- Loss: 0.17548434436321259
train-epoch-step: 30-517 -- Loss: 0.17336952686309814
train-epoch-step: 30-518 -- Loss: 0.1414918154478073
train-epoch-step: 30-519 -- Loss: 0.13342607021331787
train-epoch-step: 30-520 -- Loss: 0.18689996004104614
train-epoch-step: 30-521 -- Loss: 0.22728024423122406
train-epoch-step: 30-522 -- Loss: 0.1754244714975357
train-epoch-step: 30-523 -- Loss: 0.1646837741136551
train-epoch-step: 30-524 -- Loss: 0.17030102014541626
train-epoch-step: 30-525 -- Loss: 0.18718557059764862
train-epoch-step: 30-526 -- Loss: 0.13065510988235474
train-epoch-step: 30-527 -- Loss: 0.1592160165309906
train-epoch-step: 30-528 -- Loss: 0.15612317621707916
train-epoch-step: 30-529 -- Loss: 0.16369523108005524
train-epoch-step: 30-530 -- Loss: 0.1687762290239334
train-epoch-step: 30-531 -- Loss: 0.19489851593971252
train-epoch-step: 30-532 -- Loss: 0.1729065179824829
train-epoch-step: 30-533 -- Loss: 0.17392605543136597
train-epoch-step: 30-534 -- Loss: 0.1352786421775818
train-epoch-step: 30-535 -- Loss: 0.2560684084892273
train-epoch-step: 30-536 -- Loss: 0.163050577044487
train-epoch-step: 30-537 -- Loss: 0.15179362893104553
train-epoch-step: 30-538 -- Loss: 0.11179767549037933
train-epoch-step: 30-539 -- Loss: 0.1831488162279129
train-epoch-step: 30-540 -- Loss: 0.13765186071395874
train-epoch-step: 30-541 -- Loss: 0.2132434844970703
train-epoch-step: 30-542 -- Loss: 0.2150498330593109
train-epoch-step: 30-543 -- Loss: 0.1698649674654007
train-epoch-step: 30-544 -- Loss: 0.23157332837581635
train-epoch-step: 30-545 -- Loss: 0.19647185504436493
train-epoch-step: 30-546 -- Loss: 0.21306125819683075
train-epoch-step: 30-547 -- Loss: 0.18058861792087555
train-epoch-step: 30-548 -- Loss: 0.09347488731145859
train-epoch-step: 30-549 -- Loss: 0.15103676915168762
train-epoch-step: 30-550 -- Loss: 0.20526953041553497
train-epoch-step: 30-551 -- Loss: 0.1552811712026596
train-epoch-step: 30-552 -- Loss: 0.13098426163196564
train-epoch-step: 30-553 -- Loss: 0.19206833839416504
train-epoch-step: 30-554 -- Loss: 0.18968787789344788
train-epoch-step: 30-555 -- Loss: 0.21567845344543457
train-epoch-step: 30-556 -- Loss: 0.1526682823896408
train-epoch-step: 30-557 -- Loss: 0.23889589309692383
train-epoch-step: 30-558 -- Loss: 0.22645799815654755
train-epoch-step: 30-559 -- Loss: 0.13994890451431274
train-epoch-step: 30-560 -- Loss: 0.21142269670963287
train-epoch-step: 30-561 -- Loss: 0.17877919971942902
train-epoch-step: 30-562 -- Loss: 0.16459845006465912
train-epoch-step: 30-563 -- Loss: 0.18790081143379211
train-epoch-step: 30-564 -- Loss: 0.10237082839012146
train-epoch-step: 30-565 -- Loss: 0.18436378240585327
train-epoch-step: 30-566 -- Loss: 0.1519569754600525
train-epoch-step: 30-567 -- Loss: 0.21520072221755981
train-epoch-step: 30-568 -- Loss: 0.15846267342567444
train-epoch-step: 30-569 -- Loss: 0.24221131205558777
train-epoch-step: 30-570 -- Loss: 0.173493430018425
train-epoch-step: 30-571 -- Loss: 0.21344272792339325
train-epoch-step: 30-572 -- Loss: 0.25007131695747375
train-epoch-step: 30-573 -- Loss: 0.2015751600265503
train-epoch-step: 30-574 -- Loss: 0.2471253126859665
train-epoch-step: 30-575 -- Loss: 0.2989603579044342
train-epoch-step: 30-576 -- Loss: 0.1212097778916359
train-epoch-step: 30-577 -- Loss: 0.16578665375709534
train-epoch-step: 30-578 -- Loss: 0.21798354387283325
train-epoch-step: 30-579 -- Loss: 0.16468320786952972
train-epoch-step: 30-580 -- Loss: 0.18075263500213623
train-epoch-step: 30-581 -- Loss: 0.14355185627937317
train-epoch-step: 30-582 -- Loss: 0.20383670926094055
train-epoch-step: 30-583 -- Loss: 0.22185981273651123
train-epoch-step: 30-584 -- Loss: 0.17014962434768677
train-epoch-step: 30-585 -- Loss: 0.19829854369163513
train-epoch-step: 30-586 -- Loss: 0.2568030059337616
train-epoch-step: 30-587 -- Loss: 0.16118723154067993
train-epoch-step: 30-588 -- Loss: 0.13095897436141968
val-epoch-step: 30-589 -- Loss: 0.21694298088550568
val-epoch-step: 30-590 -- Loss: 0.15218451619148254
val-epoch-step: 30-591 -- Loss: 0.23382391035556793
val-epoch-step: 30-592 -- Loss: 0.17646333575248718
val-epoch-step: 30-593 -- Loss: 0.15498070418834686
val-epoch-step: 30-594 -- Loss: 0.3818672001361847
val-epoch-step: 30-595 -- Loss: 0.18124380707740784
val-epoch-step: 30-596 -- Loss: 0.1947731077671051
val-epoch-step: 30-597 -- Loss: 0.1727093756198883
val-epoch-step: 30-598 -- Loss: 0.15014290809631348
val-epoch-step: 30-599 -- Loss: 0.18216079473495483
val-epoch-step: 30-600 -- Loss: 0.22523170709609985
val-epoch-step: 30-601 -- Loss: 0.15397009253501892
val-epoch-step: 30-602 -- Loss: 0.1373816728591919
val-epoch-step: 30-603 -- Loss: 0.19112032651901245
val-epoch-step: 30-604 -- Loss: 0.15121528506278992
val-epoch-step: 30-605 -- Loss: 0.14680854976177216
val-epoch-step: 30-606 -- Loss: 0.2672441899776459
val-epoch-step: 30-607 -- Loss: 0.13032583892345428
val-epoch-step: 30-608 -- Loss: 0.24312786757946014
val-epoch-step: 30-609 -- Loss: 0.16536767780780792
val-epoch-step: 30-610 -- Loss: 0.1816597580909729
val-epoch-step: 30-611 -- Loss: 0.1567048728466034
val-epoch-step: 30-612 -- Loss: 0.43098166584968567
val-epoch-step: 30-613 -- Loss: 0.17531967163085938
val-epoch-step: 30-614 -- Loss: 0.168533593416214
val-epoch-step: 30-615 -- Loss: 0.17609825730323792
val-epoch-step: 30-616 -- Loss: 0.14582958817481995
val-epoch-step: 30-617 -- Loss: 0.18534351885318756
val-epoch-step: 30-618 -- Loss: 0.18044668436050415
val-epoch-step: 30-619 -- Loss: 0.22202742099761963
val-epoch-step: 30-620 -- Loss: 0.1388128697872162
val-epoch-step: 30-621 -- Loss: 0.12858866155147552
val-epoch-step: 30-622 -- Loss: 0.14507676661014557
val-epoch-step: 30-623 -- Loss: 0.1527341902256012
val-epoch-step: 30-624 -- Loss: 0.1440356969833374
val-epoch-step: 30-625 -- Loss: 0.16150325536727905
val-epoch-step: 30-626 -- Loss: 0.15095154941082
val-epoch-step: 30-627 -- Loss: 0.18364697694778442
val-epoch-step: 30-628 -- Loss: 0.5755837559700012
val-epoch-step: 30-629 -- Loss: 0.19172333180904388
val-epoch-step: 30-630 -- Loss: 0.3432947099208832
val-epoch-step: 30-631 -- Loss: 0.1443818360567093
val-epoch-step: 30-632 -- Loss: 0.20905104279518127
val-epoch-step: 30-633 -- Loss: 0.15158158540725708
val-epoch-step: 30-634 -- Loss: 0.14688566327095032
val-epoch-step: 30-635 -- Loss: 0.11284515261650085
val-epoch-step: 30-636 -- Loss: 0.16787424683570862
val-epoch-step: 30-637 -- Loss: 0.1860433965921402
val-epoch-step: 30-638 -- Loss: 0.15237542986869812
val-epoch-step: 30-639 -- Loss: 0.27639394998550415
val-epoch-step: 30-640 -- Loss: 0.24828797578811646
val-epoch-step: 30-641 -- Loss: 0.12873348593711853
val-epoch-step: 30-642 -- Loss: 0.2017950713634491
val-epoch-step: 30-643 -- Loss: 0.20552629232406616
val-epoch-step: 30-644 -- Loss: 0.1675940752029419
val-epoch-step: 30-645 -- Loss: 0.21756452322006226
val-epoch-step: 30-646 -- Loss: 0.13477851450443268
val-epoch-step: 30-647 -- Loss: 0.13572277128696442
val-epoch-step: 30-648 -- Loss: 0.1539517641067505
val-epoch-step: 30-649 -- Loss: 0.2092028111219406
val-epoch-step: 30-650 -- Loss: 0.2502000033855438
val-epoch-step: 30-651 -- Loss: 0.14230114221572876
val-epoch-step: 30-652 -- Loss: 0.15602751076221466
val-epoch-step: 30-653 -- Loss: 0.2079770565032959
val-epoch-step: 30-654 -- Loss: 0.11659729480743408
Epoch: 30 -- Train Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 62.1 -- Val Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 62.1
                         Test Loss: 0.0 -- Test Acc: 62.1
train-epoch-step: 31-0 -- Loss: 0.2196994423866272
train-epoch-step: 31-1 -- Loss: 0.14841057360172272
train-epoch-step: 31-2 -- Loss: 0.19694550335407257
train-epoch-step: 31-3 -- Loss: 0.13979801535606384
train-epoch-step: 31-4 -- Loss: 0.16063642501831055
train-epoch-step: 31-5 -- Loss: 0.17814773321151733
train-epoch-step: 31-6 -- Loss: 0.21688474714756012
train-epoch-step: 31-7 -- Loss: 0.1701660007238388
train-epoch-step: 31-8 -- Loss: 0.1843644380569458
train-epoch-step: 31-9 -- Loss: 0.23934486508369446
train-epoch-step: 31-10 -- Loss: 0.19405396282672882
train-epoch-step: 31-11 -- Loss: 0.17542971670627594
train-epoch-step: 31-12 -- Loss: 0.15140268206596375
train-epoch-step: 31-13 -- Loss: 0.1830671727657318
train-epoch-step: 31-14 -- Loss: 0.165473073720932
train-epoch-step: 31-15 -- Loss: 0.1610776036977768
train-epoch-step: 31-16 -- Loss: 0.16345222294330597
train-epoch-step: 31-17 -- Loss: 0.2244378924369812
train-epoch-step: 31-18 -- Loss: 0.1957976073026657
train-epoch-step: 31-19 -- Loss: 0.13276052474975586
train-epoch-step: 31-20 -- Loss: 0.21863959729671478
train-epoch-step: 31-21 -- Loss: 0.2536565363407135
train-epoch-step: 31-22 -- Loss: 0.14708706736564636
train-epoch-step: 31-23 -- Loss: 0.14261189103126526
train-epoch-step: 31-24 -- Loss: 0.12669846415519714
train-epoch-step: 31-25 -- Loss: 0.23008248209953308
train-epoch-step: 31-26 -- Loss: 0.1912192702293396
train-epoch-step: 31-27 -- Loss: 0.22491657733917236
train-epoch-step: 31-28 -- Loss: 0.12607435882091522
train-epoch-step: 31-29 -- Loss: 0.2428414523601532
train-epoch-step: 31-30 -- Loss: 0.11042019724845886
train-epoch-step: 31-31 -- Loss: 0.13594619929790497
train-epoch-step: 31-32 -- Loss: 0.17210811376571655
train-epoch-step: 31-33 -- Loss: 0.27544113993644714
train-epoch-step: 31-34 -- Loss: 0.16963687539100647
train-epoch-step: 31-35 -- Loss: 0.23977839946746826
train-epoch-step: 31-36 -- Loss: 0.14365582168102264
train-epoch-step: 31-37 -- Loss: 0.1366930902004242
train-epoch-step: 31-38 -- Loss: 0.18124425411224365
train-epoch-step: 31-39 -- Loss: 0.21892715990543365
train-epoch-step: 31-40 -- Loss: 0.19442041218280792
train-epoch-step: 31-41 -- Loss: 0.2181820124387741
train-epoch-step: 31-42 -- Loss: 0.15189363062381744
train-epoch-step: 31-43 -- Loss: 0.2750856280326843
train-epoch-step: 31-44 -- Loss: 0.1256239265203476
train-epoch-step: 31-45 -- Loss: 0.11769571900367737
train-epoch-step: 31-46 -- Loss: 0.16748760640621185
train-epoch-step: 31-47 -- Loss: 0.205221027135849
train-epoch-step: 31-48 -- Loss: 0.15323041379451752
train-epoch-step: 31-49 -- Loss: 0.22492468357086182
train-epoch-step: 31-50 -- Loss: 0.11617034673690796
train-epoch-step: 31-51 -- Loss: 0.17864736914634705
train-epoch-step: 31-52 -- Loss: 0.15924574434757233
train-epoch-step: 31-53 -- Loss: 0.22157728672027588
train-epoch-step: 31-54 -- Loss: 0.28724533319473267
train-epoch-step: 31-55 -- Loss: 0.16529633104801178
train-epoch-step: 31-56 -- Loss: 0.17707791924476624
train-epoch-step: 31-57 -- Loss: 0.23399458825588226
train-epoch-step: 31-58 -- Loss: 0.2864534258842468
train-epoch-step: 31-59 -- Loss: 0.24354904890060425
train-epoch-step: 31-60 -- Loss: 0.13151822984218597
train-epoch-step: 31-61 -- Loss: 0.19986574351787567
train-epoch-step: 31-62 -- Loss: 0.18214258551597595
train-epoch-step: 31-63 -- Loss: 0.1385221630334854
train-epoch-step: 31-64 -- Loss: 0.14578191936016083
train-epoch-step: 31-65 -- Loss: 0.1866437792778015
train-epoch-step: 31-66 -- Loss: 0.10984952002763748
train-epoch-step: 31-67 -- Loss: 0.12614847719669342
train-epoch-step: 31-68 -- Loss: 0.21756872534751892
train-epoch-step: 31-69 -- Loss: 0.12820248305797577
train-epoch-step: 31-70 -- Loss: 0.22692227363586426
train-epoch-step: 31-71 -- Loss: 0.2640129029750824
train-epoch-step: 31-72 -- Loss: 0.17871777713298798
train-epoch-step: 31-73 -- Loss: 0.21123793721199036
train-epoch-step: 31-74 -- Loss: 0.09601160883903503
train-epoch-step: 31-75 -- Loss: 0.13765043020248413
train-epoch-step: 31-76 -- Loss: 0.15453079342842102
train-epoch-step: 31-77 -- Loss: 0.23137089610099792
train-epoch-step: 31-78 -- Loss: 0.25315600633621216
train-epoch-step: 31-79 -- Loss: 0.19166973233222961
train-epoch-step: 31-80 -- Loss: 0.2929200530052185
train-epoch-step: 31-81 -- Loss: 0.1271785944700241
train-epoch-step: 31-82 -- Loss: 0.2537795305252075
train-epoch-step: 31-83 -- Loss: 0.179005429148674
train-epoch-step: 31-84 -- Loss: 0.19993649423122406
train-epoch-step: 31-85 -- Loss: 0.17438675463199615
train-epoch-step: 31-86 -- Loss: 0.13472329080104828
train-epoch-step: 31-87 -- Loss: 0.21778467297554016
train-epoch-step: 31-88 -- Loss: 0.1431761085987091
train-epoch-step: 31-89 -- Loss: 0.1906193494796753
train-epoch-step: 31-90 -- Loss: 0.19365468621253967
train-epoch-step: 31-91 -- Loss: 0.2629280686378479
train-epoch-step: 31-92 -- Loss: 0.15614911913871765
train-epoch-step: 31-93 -- Loss: 0.16976657509803772
train-epoch-step: 31-94 -- Loss: 0.21674814820289612
train-epoch-step: 31-95 -- Loss: 0.1936827003955841
train-epoch-step: 31-96 -- Loss: 0.21778225898742676
train-epoch-step: 31-97 -- Loss: 0.18236351013183594
train-epoch-step: 31-98 -- Loss: 0.1537800282239914
train-epoch-step: 31-99 -- Loss: 0.1791936755180359
train-epoch-step: 31-100 -- Loss: 0.19286152720451355
train-epoch-step: 31-101 -- Loss: 0.27970150113105774
train-epoch-step: 31-102 -- Loss: 0.22741667926311493
train-epoch-step: 31-103 -- Loss: 0.1840166300535202
train-epoch-step: 31-104 -- Loss: 0.15075793862342834
train-epoch-step: 31-105 -- Loss: 0.29826003313064575
train-epoch-step: 31-106 -- Loss: 0.17348210513591766
train-epoch-step: 31-107 -- Loss: 0.19362938404083252
train-epoch-step: 31-108 -- Loss: 0.190731018781662
train-epoch-step: 31-109 -- Loss: 0.14711493253707886
train-epoch-step: 31-110 -- Loss: 0.18143217265605927
train-epoch-step: 31-111 -- Loss: 0.18238696455955505
train-epoch-step: 31-112 -- Loss: 0.17825116217136383
train-epoch-step: 31-113 -- Loss: 0.16123637557029724
train-epoch-step: 31-114 -- Loss: 0.1990368664264679
train-epoch-step: 31-115 -- Loss: 0.1645180881023407
train-epoch-step: 31-116 -- Loss: 0.13865895569324493
train-epoch-step: 31-117 -- Loss: 0.13388700783252716
train-epoch-step: 31-118 -- Loss: 0.19345508515834808
train-epoch-step: 31-119 -- Loss: 0.14757975935935974
train-epoch-step: 31-120 -- Loss: 0.25045549869537354
train-epoch-step: 31-121 -- Loss: 0.24119353294372559
train-epoch-step: 31-122 -- Loss: 0.21510916948318481
train-epoch-step: 31-123 -- Loss: 0.2113841474056244
train-epoch-step: 31-124 -- Loss: 0.13034261763095856
train-epoch-step: 31-125 -- Loss: 0.15658466517925262
train-epoch-step: 31-126 -- Loss: 0.2280660718679428
train-epoch-step: 31-127 -- Loss: 0.1761338710784912
train-epoch-step: 31-128 -- Loss: 0.173905611038208
train-epoch-step: 31-129 -- Loss: 0.1532585620880127
train-epoch-step: 31-130 -- Loss: 0.20124170184135437
train-epoch-step: 31-131 -- Loss: 0.1390744000673294
train-epoch-step: 31-132 -- Loss: 0.20504122972488403
train-epoch-step: 31-133 -- Loss: 0.11842583864927292
train-epoch-step: 31-134 -- Loss: 0.19704771041870117
train-epoch-step: 31-135 -- Loss: 0.13966067135334015
train-epoch-step: 31-136 -- Loss: 0.13388192653656006
train-epoch-step: 31-137 -- Loss: 0.24643459916114807
train-epoch-step: 31-138 -- Loss: 0.26516687870025635
train-epoch-step: 31-139 -- Loss: 0.13148944079875946
train-epoch-step: 31-140 -- Loss: 0.2073831409215927
train-epoch-step: 31-141 -- Loss: 0.22976437211036682
train-epoch-step: 31-142 -- Loss: 0.20210951566696167
train-epoch-step: 31-143 -- Loss: 0.17562122642993927
train-epoch-step: 31-144 -- Loss: 0.19269144535064697
train-epoch-step: 31-145 -- Loss: 0.13945257663726807
train-epoch-step: 31-146 -- Loss: 0.18184122443199158
train-epoch-step: 31-147 -- Loss: 0.17092375457286835
train-epoch-step: 31-148 -- Loss: 0.15916891396045685
train-epoch-step: 31-149 -- Loss: 0.12094785273075104
train-epoch-step: 31-150 -- Loss: 0.18223699927330017
train-epoch-step: 31-151 -- Loss: 0.19942854344844818
train-epoch-step: 31-152 -- Loss: 0.19134463369846344
train-epoch-step: 31-153 -- Loss: 0.27448004484176636
train-epoch-step: 31-154 -- Loss: 0.1335996389389038
train-epoch-step: 31-155 -- Loss: 0.1367877721786499
train-epoch-step: 31-156 -- Loss: 0.11921800673007965
train-epoch-step: 31-157 -- Loss: 0.16699811816215515
train-epoch-step: 31-158 -- Loss: 0.16568228602409363
train-epoch-step: 31-159 -- Loss: 0.17874905467033386
train-epoch-step: 31-160 -- Loss: 0.21720553934574127
train-epoch-step: 31-161 -- Loss: 0.20162585377693176
train-epoch-step: 31-162 -- Loss: 0.21178750693798065
train-epoch-step: 31-163 -- Loss: 0.1868150234222412
train-epoch-step: 31-164 -- Loss: 0.19598883390426636
train-epoch-step: 31-165 -- Loss: 0.16653552651405334
train-epoch-step: 31-166 -- Loss: 0.12255274504423141
train-epoch-step: 31-167 -- Loss: 0.12228354066610336
train-epoch-step: 31-168 -- Loss: 0.2019658088684082
train-epoch-step: 31-169 -- Loss: 0.13916829228401184
train-epoch-step: 31-170 -- Loss: 0.19988080859184265
train-epoch-step: 31-171 -- Loss: 0.1429571658372879
train-epoch-step: 31-172 -- Loss: 0.26249316334724426
train-epoch-step: 31-173 -- Loss: 0.1436609923839569
train-epoch-step: 31-174 -- Loss: 0.2512689232826233
train-epoch-step: 31-175 -- Loss: 0.18207788467407227
train-epoch-step: 31-176 -- Loss: 0.13656091690063477
train-epoch-step: 31-177 -- Loss: 0.17783278226852417
train-epoch-step: 31-178 -- Loss: 0.17902454733848572
train-epoch-step: 31-179 -- Loss: 0.15820220112800598
train-epoch-step: 31-180 -- Loss: 0.15078014135360718
train-epoch-step: 31-181 -- Loss: 0.17810148000717163
train-epoch-step: 31-182 -- Loss: 0.19065284729003906
train-epoch-step: 31-183 -- Loss: 0.27385514974594116
train-epoch-step: 31-184 -- Loss: 0.13727417588233948
train-epoch-step: 31-185 -- Loss: 0.14178548753261566
train-epoch-step: 31-186 -- Loss: 0.19450709223747253
train-epoch-step: 31-187 -- Loss: 0.2137274295091629
train-epoch-step: 31-188 -- Loss: 0.18308836221694946
train-epoch-step: 31-189 -- Loss: 0.10864678770303726
train-epoch-step: 31-190 -- Loss: 0.18347015976905823
train-epoch-step: 31-191 -- Loss: 0.16233468055725098
train-epoch-step: 31-192 -- Loss: 0.23108446598052979
train-epoch-step: 31-193 -- Loss: 0.20994503796100616
train-epoch-step: 31-194 -- Loss: 0.18490570783615112
train-epoch-step: 31-195 -- Loss: 0.16834351420402527
train-epoch-step: 31-196 -- Loss: 0.16743651032447815
train-epoch-step: 31-197 -- Loss: 0.13567166030406952
train-epoch-step: 31-198 -- Loss: 0.12605851888656616
train-epoch-step: 31-199 -- Loss: 0.15359146893024445
train-epoch-step: 31-200 -- Loss: 0.1294519156217575
train-epoch-step: 31-201 -- Loss: 0.19074568152427673
train-epoch-step: 31-202 -- Loss: 0.13808956742286682
train-epoch-step: 31-203 -- Loss: 0.1743469536304474
train-epoch-step: 31-204 -- Loss: 0.13605645298957825
train-epoch-step: 31-205 -- Loss: 0.18985356390476227
train-epoch-step: 31-206 -- Loss: 0.20174698531627655
train-epoch-step: 31-207 -- Loss: 0.13300517201423645
train-epoch-step: 31-208 -- Loss: 0.17797359824180603
train-epoch-step: 31-209 -- Loss: 0.14402063190937042
train-epoch-step: 31-210 -- Loss: 0.13500450551509857
train-epoch-step: 31-211 -- Loss: 0.20904755592346191
train-epoch-step: 31-212 -- Loss: 0.19882632791996002
train-epoch-step: 31-213 -- Loss: 0.127731055021286
train-epoch-step: 31-214 -- Loss: 0.15060476958751678
train-epoch-step: 31-215 -- Loss: 0.1328330785036087
train-epoch-step: 31-216 -- Loss: 0.20734664797782898
train-epoch-step: 31-217 -- Loss: 0.219559907913208
train-epoch-step: 31-218 -- Loss: 0.14857260882854462
train-epoch-step: 31-219 -- Loss: 0.18013378977775574
train-epoch-step: 31-220 -- Loss: 0.13270440697669983
train-epoch-step: 31-221 -- Loss: 0.20369762182235718
train-epoch-step: 31-222 -- Loss: 0.11711277067661285
train-epoch-step: 31-223 -- Loss: 0.17727729678153992
train-epoch-step: 31-224 -- Loss: 0.19046644866466522
train-epoch-step: 31-225 -- Loss: 0.29698947072029114
train-epoch-step: 31-226 -- Loss: 0.21343769133090973
train-epoch-step: 31-227 -- Loss: 0.22085076570510864
train-epoch-step: 31-228 -- Loss: 0.18088608980178833
train-epoch-step: 31-229 -- Loss: 0.17288434505462646
train-epoch-step: 31-230 -- Loss: 0.16834862530231476
train-epoch-step: 31-231 -- Loss: 0.15962938964366913
train-epoch-step: 31-232 -- Loss: 0.18774685263633728
train-epoch-step: 31-233 -- Loss: 0.08719934523105621
train-epoch-step: 31-234 -- Loss: 0.1873292624950409
train-epoch-step: 31-235 -- Loss: 0.14994674921035767
train-epoch-step: 31-236 -- Loss: 0.1806012988090515
train-epoch-step: 31-237 -- Loss: 0.24686573445796967
train-epoch-step: 31-238 -- Loss: 0.16128034889698029
train-epoch-step: 31-239 -- Loss: 0.12567438185214996
train-epoch-step: 31-240 -- Loss: 0.224473774433136
train-epoch-step: 31-241 -- Loss: 0.15845385193824768
train-epoch-step: 31-242 -- Loss: 0.22639545798301697
train-epoch-step: 31-243 -- Loss: 0.23993095755577087
train-epoch-step: 31-244 -- Loss: 0.2065112292766571
train-epoch-step: 31-245 -- Loss: 0.2093789279460907
train-epoch-step: 31-246 -- Loss: 0.23992834985256195
train-epoch-step: 31-247 -- Loss: 0.22726641595363617
train-epoch-step: 31-248 -- Loss: 0.18709877133369446
train-epoch-step: 31-249 -- Loss: 0.13763836026191711
train-epoch-step: 31-250 -- Loss: 0.2022855281829834
train-epoch-step: 31-251 -- Loss: 0.1109912320971489
train-epoch-step: 31-252 -- Loss: 0.20392510294914246
train-epoch-step: 31-253 -- Loss: 0.1390056312084198
train-epoch-step: 31-254 -- Loss: 0.21470724046230316
train-epoch-step: 31-255 -- Loss: 0.14821335673332214
train-epoch-step: 31-256 -- Loss: 0.1557994782924652
train-epoch-step: 31-257 -- Loss: 0.18793985247612
train-epoch-step: 31-258 -- Loss: 0.14837965369224548
train-epoch-step: 31-259 -- Loss: 0.12112289667129517
train-epoch-step: 31-260 -- Loss: 0.19945929944515228
train-epoch-step: 31-261 -- Loss: 0.1765991449356079
train-epoch-step: 31-262 -- Loss: 0.3117907643318176
train-epoch-step: 31-263 -- Loss: 0.20660990476608276
train-epoch-step: 31-264 -- Loss: 0.1754988431930542
train-epoch-step: 31-265 -- Loss: 0.14242322742938995
train-epoch-step: 31-266 -- Loss: 0.15796765685081482
train-epoch-step: 31-267 -- Loss: 0.12987208366394043
train-epoch-step: 31-268 -- Loss: 0.12783405184745789
train-epoch-step: 31-269 -- Loss: 0.19666096568107605
train-epoch-step: 31-270 -- Loss: 0.11013944447040558
train-epoch-step: 31-271 -- Loss: 0.1519174426794052
train-epoch-step: 31-272 -- Loss: 0.11859656870365143
train-epoch-step: 31-273 -- Loss: 0.12820258736610413
train-epoch-step: 31-274 -- Loss: 0.1907612681388855
train-epoch-step: 31-275 -- Loss: 0.20958691835403442
train-epoch-step: 31-276 -- Loss: 0.16453106701374054
train-epoch-step: 31-277 -- Loss: 0.16393738985061646
train-epoch-step: 31-278 -- Loss: 0.17782282829284668
train-epoch-step: 31-279 -- Loss: 0.15057235956192017
train-epoch-step: 31-280 -- Loss: 0.22754999995231628
train-epoch-step: 31-281 -- Loss: 0.18398843705654144
train-epoch-step: 31-282 -- Loss: 0.14332112669944763
train-epoch-step: 31-283 -- Loss: 0.11621715128421783
train-epoch-step: 31-284 -- Loss: 0.14195148646831512
train-epoch-step: 31-285 -- Loss: 0.19101732969284058
train-epoch-step: 31-286 -- Loss: 0.1583520472049713
train-epoch-step: 31-287 -- Loss: 0.21001094579696655
train-epoch-step: 31-288 -- Loss: 0.09971418976783752
train-epoch-step: 31-289 -- Loss: 0.12667612731456757
train-epoch-step: 31-290 -- Loss: 0.1904299259185791
train-epoch-step: 31-291 -- Loss: 0.12193216383457184
train-epoch-step: 31-292 -- Loss: 0.15979042649269104
train-epoch-step: 31-293 -- Loss: 0.14236752688884735
train-epoch-step: 31-294 -- Loss: 0.18312552571296692
train-epoch-step: 31-295 -- Loss: 0.26862862706184387
train-epoch-step: 31-296 -- Loss: 0.16320642828941345
train-epoch-step: 31-297 -- Loss: 0.1723184585571289
train-epoch-step: 31-298 -- Loss: 0.22938920557498932
train-epoch-step: 31-299 -- Loss: 0.1481110006570816
train-epoch-step: 31-300 -- Loss: 0.1659262329339981
train-epoch-step: 31-301 -- Loss: 0.1727265566587448
train-epoch-step: 31-302 -- Loss: 0.22816112637519836
train-epoch-step: 31-303 -- Loss: 0.20417913794517517
train-epoch-step: 31-304 -- Loss: 0.1312892735004425
train-epoch-step: 31-305 -- Loss: 0.14864665269851685
train-epoch-step: 31-306 -- Loss: 0.23445948958396912
train-epoch-step: 31-307 -- Loss: 0.17090174555778503
train-epoch-step: 31-308 -- Loss: 0.2388342320919037
train-epoch-step: 31-309 -- Loss: 0.15600496530532837
train-epoch-step: 31-310 -- Loss: 0.1730186641216278
train-epoch-step: 31-311 -- Loss: 0.1657240092754364
train-epoch-step: 31-312 -- Loss: 0.21010003983974457
train-epoch-step: 31-313 -- Loss: 0.09987150132656097
train-epoch-step: 31-314 -- Loss: 0.19778835773468018
train-epoch-step: 31-315 -- Loss: 0.1727951467037201
train-epoch-step: 31-316 -- Loss: 0.1534728705883026
train-epoch-step: 31-317 -- Loss: 0.148283451795578
train-epoch-step: 31-318 -- Loss: 0.15647460520267487
train-epoch-step: 31-319 -- Loss: 0.1721111536026001
train-epoch-step: 31-320 -- Loss: 0.11866495013237
train-epoch-step: 31-321 -- Loss: 0.14390622079372406
train-epoch-step: 31-322 -- Loss: 0.21325445175170898
train-epoch-step: 31-323 -- Loss: 0.16240113973617554
train-epoch-step: 31-324 -- Loss: 0.2583582401275635
train-epoch-step: 31-325 -- Loss: 0.15514551103115082
train-epoch-step: 31-326 -- Loss: 0.1863851696252823
train-epoch-step: 31-327 -- Loss: 0.20557746291160583
train-epoch-step: 31-328 -- Loss: 0.1950523406267166
train-epoch-step: 31-329 -- Loss: 0.3339693546295166
train-epoch-step: 31-330 -- Loss: 0.36238640546798706
train-epoch-step: 31-331 -- Loss: 0.21102994680404663
train-epoch-step: 31-332 -- Loss: 0.10007926821708679
train-epoch-step: 31-333 -- Loss: 0.19598925113677979
train-epoch-step: 31-334 -- Loss: 0.15675078332424164
train-epoch-step: 31-335 -- Loss: 0.18828371167182922
train-epoch-step: 31-336 -- Loss: 0.1501053422689438
train-epoch-step: 31-337 -- Loss: 0.20849093794822693
train-epoch-step: 31-338 -- Loss: 0.15942761301994324
train-epoch-step: 31-339 -- Loss: 0.144754558801651
train-epoch-step: 31-340 -- Loss: 0.20957975089550018
train-epoch-step: 31-341 -- Loss: 0.14132915437221527
train-epoch-step: 31-342 -- Loss: 0.17609041929244995
train-epoch-step: 31-343 -- Loss: 0.15848004817962646
train-epoch-step: 31-344 -- Loss: 0.17583048343658447
train-epoch-step: 31-345 -- Loss: 0.1290401965379715
train-epoch-step: 31-346 -- Loss: 0.21098022162914276
train-epoch-step: 31-347 -- Loss: 0.1562337577342987
train-epoch-step: 31-348 -- Loss: 0.20938366651535034
train-epoch-step: 31-349 -- Loss: 0.20714804530143738
train-epoch-step: 31-350 -- Loss: 0.25824958086013794
train-epoch-step: 31-351 -- Loss: 0.2069624364376068
train-epoch-step: 31-352 -- Loss: 0.12785188853740692
train-epoch-step: 31-353 -- Loss: 0.19805607199668884
train-epoch-step: 31-354 -- Loss: 0.29677969217300415
train-epoch-step: 31-355 -- Loss: 0.11716989427804947
train-epoch-step: 31-356 -- Loss: 0.116827592253685
train-epoch-step: 31-357 -- Loss: 0.19602620601654053
train-epoch-step: 31-358 -- Loss: 0.18534426391124725
train-epoch-step: 31-359 -- Loss: 0.14386600255966187
train-epoch-step: 31-360 -- Loss: 0.12331138551235199
train-epoch-step: 31-361 -- Loss: 0.24019238352775574
train-epoch-step: 31-362 -- Loss: 0.16984699666500092
train-epoch-step: 31-363 -- Loss: 0.10948298126459122
train-epoch-step: 31-364 -- Loss: 0.17985427379608154
train-epoch-step: 31-365 -- Loss: 0.1763920933008194
train-epoch-step: 31-366 -- Loss: 0.20861607789993286
train-epoch-step: 31-367 -- Loss: 0.2371883988380432
train-epoch-step: 31-368 -- Loss: 0.20665843784809113
train-epoch-step: 31-369 -- Loss: 0.286907821893692
train-epoch-step: 31-370 -- Loss: 0.12837223708629608
train-epoch-step: 31-371 -- Loss: 0.12574328482151031
train-epoch-step: 31-372 -- Loss: 0.14904263615608215
train-epoch-step: 31-373 -- Loss: 0.18969544768333435
train-epoch-step: 31-374 -- Loss: 0.1583555042743683
train-epoch-step: 31-375 -- Loss: 0.27427980303764343
train-epoch-step: 31-376 -- Loss: 0.16249920427799225
train-epoch-step: 31-377 -- Loss: 0.2323901653289795
train-epoch-step: 31-378 -- Loss: 0.20644044876098633
train-epoch-step: 31-379 -- Loss: 0.12534043192863464
train-epoch-step: 31-380 -- Loss: 0.09402857720851898
train-epoch-step: 31-381 -- Loss: 0.24925997853279114
train-epoch-step: 31-382 -- Loss: 0.23659726977348328
train-epoch-step: 31-383 -- Loss: 0.17356029152870178
train-epoch-step: 31-384 -- Loss: 0.2177574336528778
train-epoch-step: 31-385 -- Loss: 0.19352316856384277
train-epoch-step: 31-386 -- Loss: 0.18924152851104736
train-epoch-step: 31-387 -- Loss: 0.2043195515871048
train-epoch-step: 31-388 -- Loss: 0.19639886915683746
train-epoch-step: 31-389 -- Loss: 0.1655799150466919
train-epoch-step: 31-390 -- Loss: 0.14827176928520203
train-epoch-step: 31-391 -- Loss: 0.14481185376644135
train-epoch-step: 31-392 -- Loss: 0.1821603924036026
train-epoch-step: 31-393 -- Loss: 0.15511655807495117
train-epoch-step: 31-394 -- Loss: 0.2071998566389084
train-epoch-step: 31-395 -- Loss: 0.16126087307929993
train-epoch-step: 31-396 -- Loss: 0.12727658450603485
train-epoch-step: 31-397 -- Loss: 0.12563824653625488
train-epoch-step: 31-398 -- Loss: 0.19687588512897491
train-epoch-step: 31-399 -- Loss: 0.17773917317390442
train-epoch-step: 31-400 -- Loss: 0.27816811203956604
train-epoch-step: 31-401 -- Loss: 0.12447184324264526
train-epoch-step: 31-402 -- Loss: 0.2562364637851715
train-epoch-step: 31-403 -- Loss: 0.16230404376983643
train-epoch-step: 31-404 -- Loss: 0.14185725152492523
train-epoch-step: 31-405 -- Loss: 0.14426299929618835
train-epoch-step: 31-406 -- Loss: 0.178211510181427
train-epoch-step: 31-407 -- Loss: 0.11631174385547638
train-epoch-step: 31-408 -- Loss: 0.17667603492736816
train-epoch-step: 31-409 -- Loss: 0.1724223494529724
train-epoch-step: 31-410 -- Loss: 0.1809178590774536
train-epoch-step: 31-411 -- Loss: 0.20619961619377136
train-epoch-step: 31-412 -- Loss: 0.13141164183616638
train-epoch-step: 31-413 -- Loss: 0.14674536883831024
train-epoch-step: 31-414 -- Loss: 0.13331598043441772
train-epoch-step: 31-415 -- Loss: 0.13487502932548523
train-epoch-step: 31-416 -- Loss: 0.2674548923969269
train-epoch-step: 31-417 -- Loss: 0.2027791142463684
train-epoch-step: 31-418 -- Loss: 0.2403038591146469
train-epoch-step: 31-419 -- Loss: 0.17784830927848816
train-epoch-step: 31-420 -- Loss: 0.15014423429965973
train-epoch-step: 31-421 -- Loss: 0.18020647764205933
train-epoch-step: 31-422 -- Loss: 0.1491691917181015
train-epoch-step: 31-423 -- Loss: 0.18396538496017456
train-epoch-step: 31-424 -- Loss: 0.14302170276641846
train-epoch-step: 31-425 -- Loss: 0.18454454839229584
train-epoch-step: 31-426 -- Loss: 0.1628207117319107
train-epoch-step: 31-427 -- Loss: 0.12128469347953796
train-epoch-step: 31-428 -- Loss: 0.20174726843833923
train-epoch-step: 31-429 -- Loss: 0.1791413128376007
train-epoch-step: 31-430 -- Loss: 0.14543849229812622
train-epoch-step: 31-431 -- Loss: 0.16463758051395416
train-epoch-step: 31-432 -- Loss: 0.24001961946487427
train-epoch-step: 31-433 -- Loss: 0.13666269183158875
train-epoch-step: 31-434 -- Loss: 0.1351885050535202
train-epoch-step: 31-435 -- Loss: 0.1558007001876831
train-epoch-step: 31-436 -- Loss: 0.16028568148612976
train-epoch-step: 31-437 -- Loss: 0.131634920835495
train-epoch-step: 31-438 -- Loss: 0.1791648268699646
train-epoch-step: 31-439 -- Loss: 0.2658311128616333
train-epoch-step: 31-440 -- Loss: 0.13437405228614807
train-epoch-step: 31-441 -- Loss: 0.2099633663892746
train-epoch-step: 31-442 -- Loss: 0.18773803114891052
train-epoch-step: 31-443 -- Loss: 0.159927099943161
train-epoch-step: 31-444 -- Loss: 0.1779927760362625
train-epoch-step: 31-445 -- Loss: 0.17727360129356384
train-epoch-step: 31-446 -- Loss: 0.15163248777389526
train-epoch-step: 31-447 -- Loss: 0.1892421990633011
train-epoch-step: 31-448 -- Loss: 0.22594743967056274
train-epoch-step: 31-449 -- Loss: 0.19416554272174835
train-epoch-step: 31-450 -- Loss: 0.18814779818058014
train-epoch-step: 31-451 -- Loss: 0.14561448991298676
train-epoch-step: 31-452 -- Loss: 0.1320151537656784
train-epoch-step: 31-453 -- Loss: 0.09611115604639053
train-epoch-step: 31-454 -- Loss: 0.22534993290901184
train-epoch-step: 31-455 -- Loss: 0.12428747862577438
train-epoch-step: 31-456 -- Loss: 0.12727195024490356
train-epoch-step: 31-457 -- Loss: 0.2131071388721466
train-epoch-step: 31-458 -- Loss: 0.14716599881649017
train-epoch-step: 31-459 -- Loss: 0.2203703373670578
train-epoch-step: 31-460 -- Loss: 0.13489305973052979
train-epoch-step: 31-461 -- Loss: 0.13396352529525757
train-epoch-step: 31-462 -- Loss: 0.16738922894001007
train-epoch-step: 31-463 -- Loss: 0.13982535898685455
train-epoch-step: 31-464 -- Loss: 0.1635296642780304
train-epoch-step: 31-465 -- Loss: 0.23984482884407043
train-epoch-step: 31-466 -- Loss: 0.2033371925354004
train-epoch-step: 31-467 -- Loss: 0.11201899498701096
train-epoch-step: 31-468 -- Loss: 0.17386841773986816
train-epoch-step: 31-469 -- Loss: 0.22683511674404144
train-epoch-step: 31-470 -- Loss: 0.1716555953025818
train-epoch-step: 31-471 -- Loss: 0.16594906151294708
train-epoch-step: 31-472 -- Loss: 0.1598588079214096
train-epoch-step: 31-473 -- Loss: 0.157960906624794
train-epoch-step: 31-474 -- Loss: 0.12028750777244568
train-epoch-step: 31-475 -- Loss: 0.11199545860290527
train-epoch-step: 31-476 -- Loss: 0.2062932550907135
train-epoch-step: 31-477 -- Loss: 0.2108812779188156
train-epoch-step: 31-478 -- Loss: 0.1939121037721634
train-epoch-step: 31-479 -- Loss: 0.14050103724002838
train-epoch-step: 31-480 -- Loss: 0.19918298721313477
train-epoch-step: 31-481 -- Loss: 0.2811262011528015
train-epoch-step: 31-482 -- Loss: 0.2841338515281677
train-epoch-step: 31-483 -- Loss: 0.18542754650115967
train-epoch-step: 31-484 -- Loss: 0.23148950934410095
train-epoch-step: 31-485 -- Loss: 0.127680242061615
train-epoch-step: 31-486 -- Loss: 0.2327287495136261
train-epoch-step: 31-487 -- Loss: 0.23107874393463135
train-epoch-step: 31-488 -- Loss: 0.19719842076301575
train-epoch-step: 31-489 -- Loss: 0.23090267181396484
train-epoch-step: 31-490 -- Loss: 0.13912560045719147
train-epoch-step: 31-491 -- Loss: 0.14092694222927094
train-epoch-step: 31-492 -- Loss: 0.12894394993782043
train-epoch-step: 31-493 -- Loss: 0.22497829794883728
train-epoch-step: 31-494 -- Loss: 0.2091277688741684
train-epoch-step: 31-495 -- Loss: 0.20562031865119934
train-epoch-step: 31-496 -- Loss: 0.1418629288673401
train-epoch-step: 31-497 -- Loss: 0.18026451766490936
train-epoch-step: 31-498 -- Loss: 0.15147028863430023
train-epoch-step: 31-499 -- Loss: 0.181463360786438
train-epoch-step: 31-500 -- Loss: 0.15835368633270264
train-epoch-step: 31-501 -- Loss: 0.2402896285057068
train-epoch-step: 31-502 -- Loss: 0.18404477834701538
train-epoch-step: 31-503 -- Loss: 0.22328515350818634
train-epoch-step: 31-504 -- Loss: 0.12430913746356964
train-epoch-step: 31-505 -- Loss: 0.17715778946876526
train-epoch-step: 31-506 -- Loss: 0.11950846016407013
train-epoch-step: 31-507 -- Loss: 0.1876676380634308
train-epoch-step: 31-508 -- Loss: 0.17558741569519043
train-epoch-step: 31-509 -- Loss: 0.17198674380779266
train-epoch-step: 31-510 -- Loss: 0.13132181763648987
train-epoch-step: 31-511 -- Loss: 0.2543501853942871
train-epoch-step: 31-512 -- Loss: 0.18155282735824585
train-epoch-step: 31-513 -- Loss: 0.20222729444503784
train-epoch-step: 31-514 -- Loss: 0.14874395728111267
train-epoch-step: 31-515 -- Loss: 0.15857890248298645
train-epoch-step: 31-516 -- Loss: 0.17585837841033936
train-epoch-step: 31-517 -- Loss: 0.1787641942501068
train-epoch-step: 31-518 -- Loss: 0.15205860137939453
train-epoch-step: 31-519 -- Loss: 0.1453353613615036
train-epoch-step: 31-520 -- Loss: 0.19197282195091248
train-epoch-step: 31-521 -- Loss: 0.2617509067058563
train-epoch-step: 31-522 -- Loss: 0.18853168189525604
train-epoch-step: 31-523 -- Loss: 0.1723354011774063
train-epoch-step: 31-524 -- Loss: 0.17088477313518524
train-epoch-step: 31-525 -- Loss: 0.20948034524917603
train-epoch-step: 31-526 -- Loss: 0.13636504113674164
train-epoch-step: 31-527 -- Loss: 0.15271484851837158
train-epoch-step: 31-528 -- Loss: 0.15825140476226807
train-epoch-step: 31-529 -- Loss: 0.19067443907260895
train-epoch-step: 31-530 -- Loss: 0.17101076245307922
train-epoch-step: 31-531 -- Loss: 0.22477132081985474
train-epoch-step: 31-532 -- Loss: 0.1806361824274063
train-epoch-step: 31-533 -- Loss: 0.1746385097503662
train-epoch-step: 31-534 -- Loss: 0.13551726937294006
train-epoch-step: 31-535 -- Loss: 0.2709188461303711
train-epoch-step: 31-536 -- Loss: 0.1624574363231659
train-epoch-step: 31-537 -- Loss: 0.1457144021987915
train-epoch-step: 31-538 -- Loss: 0.10854878276586533
train-epoch-step: 31-539 -- Loss: 0.21122488379478455
train-epoch-step: 31-540 -- Loss: 0.13794714212417603
train-epoch-step: 31-541 -- Loss: 0.2203369140625
train-epoch-step: 31-542 -- Loss: 0.22839638590812683
train-epoch-step: 31-543 -- Loss: 0.17113420367240906
train-epoch-step: 31-544 -- Loss: 0.23246312141418457
train-epoch-step: 31-545 -- Loss: 0.19885680079460144
train-epoch-step: 31-546 -- Loss: 0.21676898002624512
train-epoch-step: 31-547 -- Loss: 0.1810227632522583
train-epoch-step: 31-548 -- Loss: 0.09618976712226868
train-epoch-step: 31-549 -- Loss: 0.16199317574501038
train-epoch-step: 31-550 -- Loss: 0.1996130347251892
train-epoch-step: 31-551 -- Loss: 0.15670189261436462
train-epoch-step: 31-552 -- Loss: 0.12706108391284943
train-epoch-step: 31-553 -- Loss: 0.1895896941423416
train-epoch-step: 31-554 -- Loss: 0.1881749927997589
train-epoch-step: 31-555 -- Loss: 0.22588106989860535
train-epoch-step: 31-556 -- Loss: 0.16705204546451569
train-epoch-step: 31-557 -- Loss: 0.23960402607917786
train-epoch-step: 31-558 -- Loss: 0.24706141650676727
train-epoch-step: 31-559 -- Loss: 0.13699033856391907
train-epoch-step: 31-560 -- Loss: 0.20560134947299957
train-epoch-step: 31-561 -- Loss: 0.1908111274242401
train-epoch-step: 31-562 -- Loss: 0.17287254333496094
train-epoch-step: 31-563 -- Loss: 0.19032925367355347
train-epoch-step: 31-564 -- Loss: 0.10154115408658981
train-epoch-step: 31-565 -- Loss: 0.18987855315208435
train-epoch-step: 31-566 -- Loss: 0.15825529396533966
train-epoch-step: 31-567 -- Loss: 0.21631395816802979
train-epoch-step: 31-568 -- Loss: 0.16389644145965576
train-epoch-step: 31-569 -- Loss: 0.24395616352558136
train-epoch-step: 31-570 -- Loss: 0.16742193698883057
train-epoch-step: 31-571 -- Loss: 0.21244339644908905
train-epoch-step: 31-572 -- Loss: 0.24452891945838928
train-epoch-step: 31-573 -- Loss: 0.20812678337097168
train-epoch-step: 31-574 -- Loss: 0.24785436689853668
train-epoch-step: 31-575 -- Loss: 0.2963912785053253
train-epoch-step: 31-576 -- Loss: 0.12010413408279419
train-epoch-step: 31-577 -- Loss: 0.1676996797323227
train-epoch-step: 31-578 -- Loss: 0.22258733212947845
train-epoch-step: 31-579 -- Loss: 0.16570912301540375
train-epoch-step: 31-580 -- Loss: 0.18394175171852112
train-epoch-step: 31-581 -- Loss: 0.1478431075811386
train-epoch-step: 31-582 -- Loss: 0.21257290244102478
train-epoch-step: 31-583 -- Loss: 0.22891107201576233
train-epoch-step: 31-584 -- Loss: 0.16853594779968262
train-epoch-step: 31-585 -- Loss: 0.1948339343070984
train-epoch-step: 31-586 -- Loss: 0.259900838136673
train-epoch-step: 31-587 -- Loss: 0.15792685747146606
train-epoch-step: 31-588 -- Loss: 0.12630799412727356
val-epoch-step: 31-589 -- Loss: 0.21724654734134674
val-epoch-step: 31-590 -- Loss: 0.1547422558069229
val-epoch-step: 31-591 -- Loss: 0.23938652873039246
val-epoch-step: 31-592 -- Loss: 0.17674757540225983
val-epoch-step: 31-593 -- Loss: 0.16492027044296265
val-epoch-step: 31-594 -- Loss: 0.3734952211380005
val-epoch-step: 31-595 -- Loss: 0.18572497367858887
val-epoch-step: 31-596 -- Loss: 0.20371600985527039
val-epoch-step: 31-597 -- Loss: 0.1858179122209549
val-epoch-step: 31-598 -- Loss: 0.15088486671447754
val-epoch-step: 31-599 -- Loss: 0.18538248538970947
val-epoch-step: 31-600 -- Loss: 0.19780518114566803
val-epoch-step: 31-601 -- Loss: 0.157944455742836
val-epoch-step: 31-602 -- Loss: 0.1401423215866089
val-epoch-step: 31-603 -- Loss: 0.21479471027851105
val-epoch-step: 31-604 -- Loss: 0.15170222520828247
val-epoch-step: 31-605 -- Loss: 0.14714382588863373
val-epoch-step: 31-606 -- Loss: 0.2690904438495636
val-epoch-step: 31-607 -- Loss: 0.13209909200668335
val-epoch-step: 31-608 -- Loss: 0.24899491667747498
val-epoch-step: 31-609 -- Loss: 0.16750547289848328
val-epoch-step: 31-610 -- Loss: 0.19382096827030182
val-epoch-step: 31-611 -- Loss: 0.15992304682731628
val-epoch-step: 31-612 -- Loss: 0.4047613739967346
val-epoch-step: 31-613 -- Loss: 0.18679580092430115
val-epoch-step: 31-614 -- Loss: 0.17025229334831238
val-epoch-step: 31-615 -- Loss: 0.1744827777147293
val-epoch-step: 31-616 -- Loss: 0.16897618770599365
val-epoch-step: 31-617 -- Loss: 0.18790093064308167
val-epoch-step: 31-618 -- Loss: 0.18204107880592346
val-epoch-step: 31-619 -- Loss: 0.22353897988796234
val-epoch-step: 31-620 -- Loss: 0.14786751568317413
val-epoch-step: 31-621 -- Loss: 0.12807604670524597
val-epoch-step: 31-622 -- Loss: 0.1458316445350647
val-epoch-step: 31-623 -- Loss: 0.15146037936210632
val-epoch-step: 31-624 -- Loss: 0.1483873724937439
val-epoch-step: 31-625 -- Loss: 0.15652203559875488
val-epoch-step: 31-626 -- Loss: 0.16181552410125732
val-epoch-step: 31-627 -- Loss: 0.18727681040763855
val-epoch-step: 31-628 -- Loss: 0.6484704613685608
val-epoch-step: 31-629 -- Loss: 0.21994982659816742
val-epoch-step: 31-630 -- Loss: 0.35629212856292725
val-epoch-step: 31-631 -- Loss: 0.14148028194904327
val-epoch-step: 31-632 -- Loss: 0.20406067371368408
val-epoch-step: 31-633 -- Loss: 0.16158512234687805
val-epoch-step: 31-634 -- Loss: 0.15322482585906982
val-epoch-step: 31-635 -- Loss: 0.1190272867679596
val-epoch-step: 31-636 -- Loss: 0.16666178405284882
val-epoch-step: 31-637 -- Loss: 0.18554677069187164
val-epoch-step: 31-638 -- Loss: 0.15002362430095673
val-epoch-step: 31-639 -- Loss: 0.25889405608177185
val-epoch-step: 31-640 -- Loss: 0.26285332441329956
val-epoch-step: 31-641 -- Loss: 0.12521488964557648
val-epoch-step: 31-642 -- Loss: 0.1864853948354721
val-epoch-step: 31-643 -- Loss: 0.2036907970905304
val-epoch-step: 31-644 -- Loss: 0.16786864399909973
val-epoch-step: 31-645 -- Loss: 0.2252737581729889
val-epoch-step: 31-646 -- Loss: 0.1330949366092682
val-epoch-step: 31-647 -- Loss: 0.13506290316581726
val-epoch-step: 31-648 -- Loss: 0.15765060484409332
val-epoch-step: 31-649 -- Loss: 0.21221919357776642
val-epoch-step: 31-650 -- Loss: 0.2586784064769745
val-epoch-step: 31-651 -- Loss: 0.14606493711471558
val-epoch-step: 31-652 -- Loss: 0.1596284806728363
val-epoch-step: 31-653 -- Loss: 0.23307442665100098
val-epoch-step: 31-654 -- Loss: 0.13365785777568817
Epoch: 31 -- Train Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 32-0 -- Loss: 0.22222402691841125
train-epoch-step: 32-1 -- Loss: 0.14946699142456055
train-epoch-step: 32-2 -- Loss: 0.20356284081935883
train-epoch-step: 32-3 -- Loss: 0.14485713839530945
train-epoch-step: 32-4 -- Loss: 0.1658376157283783
train-epoch-step: 32-5 -- Loss: 0.18872150778770447
train-epoch-step: 32-6 -- Loss: 0.22978633642196655
train-epoch-step: 32-7 -- Loss: 0.17111346125602722
train-epoch-step: 32-8 -- Loss: 0.19362975656986237
train-epoch-step: 32-9 -- Loss: 0.24063821136951447
train-epoch-step: 32-10 -- Loss: 0.19978225231170654
train-epoch-step: 32-11 -- Loss: 0.18379740417003632
train-epoch-step: 32-12 -- Loss: 0.14809906482696533
train-epoch-step: 32-13 -- Loss: 0.1865825355052948
train-epoch-step: 32-14 -- Loss: 0.1637469083070755
train-epoch-step: 32-15 -- Loss: 0.1589016616344452
train-epoch-step: 32-16 -- Loss: 0.1654709279537201
train-epoch-step: 32-17 -- Loss: 0.23802480101585388
train-epoch-step: 32-18 -- Loss: 0.19640704989433289
train-epoch-step: 32-19 -- Loss: 0.13194864988327026
train-epoch-step: 32-20 -- Loss: 0.21460171043872833
train-epoch-step: 32-21 -- Loss: 0.26706379652023315
train-epoch-step: 32-22 -- Loss: 0.14365465939044952
train-epoch-step: 32-23 -- Loss: 0.15897583961486816
train-epoch-step: 32-24 -- Loss: 0.12497319281101227
train-epoch-step: 32-25 -- Loss: 0.2416248321533203
train-epoch-step: 32-26 -- Loss: 0.195168137550354
train-epoch-step: 32-27 -- Loss: 0.24580693244934082
train-epoch-step: 32-28 -- Loss: 0.12973827123641968
train-epoch-step: 32-29 -- Loss: 0.24644716084003448
train-epoch-step: 32-30 -- Loss: 0.11227666586637497
train-epoch-step: 32-31 -- Loss: 0.13503070175647736
train-epoch-step: 32-32 -- Loss: 0.19831393659114838
train-epoch-step: 32-33 -- Loss: 0.27813786268234253
train-epoch-step: 32-34 -- Loss: 0.17439231276512146
train-epoch-step: 32-35 -- Loss: 0.24434515833854675
train-epoch-step: 32-36 -- Loss: 0.14360584318637848
train-epoch-step: 32-37 -- Loss: 0.1361846774816513
train-epoch-step: 32-38 -- Loss: 0.18294793367385864
train-epoch-step: 32-39 -- Loss: 0.22746312618255615
train-epoch-step: 32-40 -- Loss: 0.19089189171791077
train-epoch-step: 32-41 -- Loss: 0.21176543831825256
train-epoch-step: 32-42 -- Loss: 0.14717285335063934
train-epoch-step: 32-43 -- Loss: 0.2701033055782318
train-epoch-step: 32-44 -- Loss: 0.1247534453868866
train-epoch-step: 32-45 -- Loss: 0.11942581832408905
train-epoch-step: 32-46 -- Loss: 0.18384845554828644
train-epoch-step: 32-47 -- Loss: 0.20699992775917053
train-epoch-step: 32-48 -- Loss: 0.1556042730808258
train-epoch-step: 32-49 -- Loss: 0.22615881264209747
train-epoch-step: 32-50 -- Loss: 0.11366962641477585
train-epoch-step: 32-51 -- Loss: 0.17828229069709778
train-epoch-step: 32-52 -- Loss: 0.16491568088531494
train-epoch-step: 32-53 -- Loss: 0.21065226197242737
train-epoch-step: 32-54 -- Loss: 0.28938883543014526
train-epoch-step: 32-55 -- Loss: 0.16825328767299652
train-epoch-step: 32-56 -- Loss: 0.17854109406471252
train-epoch-step: 32-57 -- Loss: 0.23486679792404175
train-epoch-step: 32-58 -- Loss: 0.2832459509372711
train-epoch-step: 32-59 -- Loss: 0.23569998145103455
train-epoch-step: 32-60 -- Loss: 0.13241760432720184
train-epoch-step: 32-61 -- Loss: 0.2056296020746231
train-epoch-step: 32-62 -- Loss: 0.18706339597702026
train-epoch-step: 32-63 -- Loss: 0.13855214416980743
train-epoch-step: 32-64 -- Loss: 0.15409445762634277
train-epoch-step: 32-65 -- Loss: 0.18244250118732452
train-epoch-step: 32-66 -- Loss: 0.1103525161743164
train-epoch-step: 32-67 -- Loss: 0.12916657328605652
train-epoch-step: 32-68 -- Loss: 0.22170226275920868
train-epoch-step: 32-69 -- Loss: 0.12519191205501556
train-epoch-step: 32-70 -- Loss: 0.2200096845626831
train-epoch-step: 32-71 -- Loss: 0.2580786645412445
train-epoch-step: 32-72 -- Loss: 0.1757061779499054
train-epoch-step: 32-73 -- Loss: 0.21244072914123535
train-epoch-step: 32-74 -- Loss: 0.09868016839027405
train-epoch-step: 32-75 -- Loss: 0.1268780678510666
train-epoch-step: 32-76 -- Loss: 0.14584298431873322
train-epoch-step: 32-77 -- Loss: 0.23055601119995117
train-epoch-step: 32-78 -- Loss: 0.2545071244239807
train-epoch-step: 32-79 -- Loss: 0.18933549523353577
train-epoch-step: 32-80 -- Loss: 0.24744153022766113
train-epoch-step: 32-81 -- Loss: 0.12327639758586884
train-epoch-step: 32-82 -- Loss: 0.25188764929771423
train-epoch-step: 32-83 -- Loss: 0.18112260103225708
train-epoch-step: 32-84 -- Loss: 0.19554251432418823
train-epoch-step: 32-85 -- Loss: 0.17377126216888428
train-epoch-step: 32-86 -- Loss: 0.12285910546779633
train-epoch-step: 32-87 -- Loss: 0.21692731976509094
train-epoch-step: 32-88 -- Loss: 0.14510655403137207
train-epoch-step: 32-89 -- Loss: 0.18710994720458984
train-epoch-step: 32-90 -- Loss: 0.19421400129795074
train-epoch-step: 32-91 -- Loss: 0.24452437460422516
train-epoch-step: 32-92 -- Loss: 0.15806922316551208
train-epoch-step: 32-93 -- Loss: 0.17163652181625366
train-epoch-step: 32-94 -- Loss: 0.22031746804714203
train-epoch-step: 32-95 -- Loss: 0.1975136697292328
train-epoch-step: 32-96 -- Loss: 0.21281392872333527
train-epoch-step: 32-97 -- Loss: 0.18159687519073486
train-epoch-step: 32-98 -- Loss: 0.15626728534698486
train-epoch-step: 32-99 -- Loss: 0.20438475906848907
train-epoch-step: 32-100 -- Loss: 0.18615344166755676
train-epoch-step: 32-101 -- Loss: 0.2760319113731384
train-epoch-step: 32-102 -- Loss: 0.217824786901474
train-epoch-step: 32-103 -- Loss: 0.18363364040851593
train-epoch-step: 32-104 -- Loss: 0.1514391452074051
train-epoch-step: 32-105 -- Loss: 0.2813928425312042
train-epoch-step: 32-106 -- Loss: 0.17578572034835815
train-epoch-step: 32-107 -- Loss: 0.18960928916931152
train-epoch-step: 32-108 -- Loss: 0.18934571743011475
train-epoch-step: 32-109 -- Loss: 0.14476756751537323
train-epoch-step: 32-110 -- Loss: 0.18262334167957306
train-epoch-step: 32-111 -- Loss: 0.17957234382629395
train-epoch-step: 32-112 -- Loss: 0.1696346253156662
train-epoch-step: 32-113 -- Loss: 0.16163673996925354
train-epoch-step: 32-114 -- Loss: 0.20393021404743195
train-epoch-step: 32-115 -- Loss: 0.16705694794654846
train-epoch-step: 32-116 -- Loss: 0.13511532545089722
train-epoch-step: 32-117 -- Loss: 0.13118164241313934
train-epoch-step: 32-118 -- Loss: 0.1951088011264801
train-epoch-step: 32-119 -- Loss: 0.15773548185825348
train-epoch-step: 32-120 -- Loss: 0.24983279407024384
train-epoch-step: 32-121 -- Loss: 0.2428690642118454
train-epoch-step: 32-122 -- Loss: 0.21289190649986267
train-epoch-step: 32-123 -- Loss: 0.21144290268421173
train-epoch-step: 32-124 -- Loss: 0.12976108491420746
train-epoch-step: 32-125 -- Loss: 0.15508875250816345
train-epoch-step: 32-126 -- Loss: 0.23624971508979797
train-epoch-step: 32-127 -- Loss: 0.18911346793174744
train-epoch-step: 32-128 -- Loss: 0.17154012620449066
train-epoch-step: 32-129 -- Loss: 0.1490149199962616
train-epoch-step: 32-130 -- Loss: 0.19499239325523376
train-epoch-step: 32-131 -- Loss: 0.1419014036655426
train-epoch-step: 32-132 -- Loss: 0.19880172610282898
train-epoch-step: 32-133 -- Loss: 0.12009637802839279
train-epoch-step: 32-134 -- Loss: 0.21300186216831207
train-epoch-step: 32-135 -- Loss: 0.13977229595184326
train-epoch-step: 32-136 -- Loss: 0.12731003761291504
train-epoch-step: 32-137 -- Loss: 0.24372395873069763
train-epoch-step: 32-138 -- Loss: 0.26818856596946716
train-epoch-step: 32-139 -- Loss: 0.13023404777050018
train-epoch-step: 32-140 -- Loss: 0.21330176293849945
train-epoch-step: 32-141 -- Loss: 0.23347210884094238
train-epoch-step: 32-142 -- Loss: 0.20199066400527954
train-epoch-step: 32-143 -- Loss: 0.17844441533088684
train-epoch-step: 32-144 -- Loss: 0.18954598903656006
train-epoch-step: 32-145 -- Loss: 0.14508256316184998
train-epoch-step: 32-146 -- Loss: 0.19547323882579803
train-epoch-step: 32-147 -- Loss: 0.17012248933315277
train-epoch-step: 32-148 -- Loss: 0.1613449901342392
train-epoch-step: 32-149 -- Loss: 0.11934325098991394
train-epoch-step: 32-150 -- Loss: 0.18383680284023285
train-epoch-step: 32-151 -- Loss: 0.19223687052726746
train-epoch-step: 32-152 -- Loss: 0.18961182236671448
train-epoch-step: 32-153 -- Loss: 0.29647088050842285
train-epoch-step: 32-154 -- Loss: 0.13118228316307068
train-epoch-step: 32-155 -- Loss: 0.14224418997764587
train-epoch-step: 32-156 -- Loss: 0.11964401602745056
train-epoch-step: 32-157 -- Loss: 0.17657119035720825
train-epoch-step: 32-158 -- Loss: 0.16425028443336487
train-epoch-step: 32-159 -- Loss: 0.1852339804172516
train-epoch-step: 32-160 -- Loss: 0.22075408697128296
train-epoch-step: 32-161 -- Loss: 0.2081986665725708
train-epoch-step: 32-162 -- Loss: 0.2154124677181244
train-epoch-step: 32-163 -- Loss: 0.19005431234836578
train-epoch-step: 32-164 -- Loss: 0.1948896050453186
train-epoch-step: 32-165 -- Loss: 0.16561821103096008
train-epoch-step: 32-166 -- Loss: 0.126750186085701
train-epoch-step: 32-167 -- Loss: 0.13098973035812378
train-epoch-step: 32-168 -- Loss: 0.2031480371952057
train-epoch-step: 32-169 -- Loss: 0.13891209661960602
train-epoch-step: 32-170 -- Loss: 0.1990928053855896
train-epoch-step: 32-171 -- Loss: 0.14712484180927277
train-epoch-step: 32-172 -- Loss: 0.2650766968727112
train-epoch-step: 32-173 -- Loss: 0.14112764596939087
train-epoch-step: 32-174 -- Loss: 0.24858829379081726
train-epoch-step: 32-175 -- Loss: 0.18394270539283752
train-epoch-step: 32-176 -- Loss: 0.1370462328195572
train-epoch-step: 32-177 -- Loss: 0.181711345911026
train-epoch-step: 32-178 -- Loss: 0.17614972591400146
train-epoch-step: 32-179 -- Loss: 0.16332870721817017
train-epoch-step: 32-180 -- Loss: 0.1528235524892807
train-epoch-step: 32-181 -- Loss: 0.17181728780269623
train-epoch-step: 32-182 -- Loss: 0.18673905730247498
train-epoch-step: 32-183 -- Loss: 0.2671051621437073
train-epoch-step: 32-184 -- Loss: 0.13997986912727356
train-epoch-step: 32-185 -- Loss: 0.14021751284599304
train-epoch-step: 32-186 -- Loss: 0.19299310445785522
train-epoch-step: 32-187 -- Loss: 0.21509486436843872
train-epoch-step: 32-188 -- Loss: 0.17778632044792175
train-epoch-step: 32-189 -- Loss: 0.10846688598394394
train-epoch-step: 32-190 -- Loss: 0.1814364492893219
train-epoch-step: 32-191 -- Loss: 0.16232699155807495
train-epoch-step: 32-192 -- Loss: 0.23878562450408936
train-epoch-step: 32-193 -- Loss: 0.21217137575149536
train-epoch-step: 32-194 -- Loss: 0.18054772913455963
train-epoch-step: 32-195 -- Loss: 0.16374492645263672
train-epoch-step: 32-196 -- Loss: 0.1708633005619049
train-epoch-step: 32-197 -- Loss: 0.13125577569007874
train-epoch-step: 32-198 -- Loss: 0.12811727821826935
train-epoch-step: 32-199 -- Loss: 0.15029199421405792
train-epoch-step: 32-200 -- Loss: 0.12715698778629303
train-epoch-step: 32-201 -- Loss: 0.2014787346124649
train-epoch-step: 32-202 -- Loss: 0.1375904232263565
train-epoch-step: 32-203 -- Loss: 0.17854613065719604
train-epoch-step: 32-204 -- Loss: 0.13647937774658203
train-epoch-step: 32-205 -- Loss: 0.1818857491016388
train-epoch-step: 32-206 -- Loss: 0.2006455808877945
train-epoch-step: 32-207 -- Loss: 0.13094712793827057
train-epoch-step: 32-208 -- Loss: 0.18511100113391876
train-epoch-step: 32-209 -- Loss: 0.1439168006181717
train-epoch-step: 32-210 -- Loss: 0.1357874572277069
train-epoch-step: 32-211 -- Loss: 0.20391376316547394
train-epoch-step: 32-212 -- Loss: 0.20647069811820984
train-epoch-step: 32-213 -- Loss: 0.1311030089855194
train-epoch-step: 32-214 -- Loss: 0.15411987900733948
train-epoch-step: 32-215 -- Loss: 0.1301121711730957
train-epoch-step: 32-216 -- Loss: 0.2041284441947937
train-epoch-step: 32-217 -- Loss: 0.21821773052215576
train-epoch-step: 32-218 -- Loss: 0.14875350892543793
train-epoch-step: 32-219 -- Loss: 0.17799226939678192
train-epoch-step: 32-220 -- Loss: 0.13610614836215973
train-epoch-step: 32-221 -- Loss: 0.20530393719673157
train-epoch-step: 32-222 -- Loss: 0.11959495395421982
train-epoch-step: 32-223 -- Loss: 0.17620351910591125
train-epoch-step: 32-224 -- Loss: 0.18686772882938385
train-epoch-step: 32-225 -- Loss: 0.2705312967300415
train-epoch-step: 32-226 -- Loss: 0.20526446402072906
train-epoch-step: 32-227 -- Loss: 0.22044287621974945
train-epoch-step: 32-228 -- Loss: 0.17788103222846985
train-epoch-step: 32-229 -- Loss: 0.1755053699016571
train-epoch-step: 32-230 -- Loss: 0.16419005393981934
train-epoch-step: 32-231 -- Loss: 0.15539756417274475
train-epoch-step: 32-232 -- Loss: 0.1898047924041748
train-epoch-step: 32-233 -- Loss: 0.08848217129707336
train-epoch-step: 32-234 -- Loss: 0.17540839314460754
train-epoch-step: 32-235 -- Loss: 0.15063536167144775
train-epoch-step: 32-236 -- Loss: 0.1860855370759964
train-epoch-step: 32-237 -- Loss: 0.24262836575508118
train-epoch-step: 32-238 -- Loss: 0.1640463024377823
train-epoch-step: 32-239 -- Loss: 0.12979230284690857
train-epoch-step: 32-240 -- Loss: 0.22410666942596436
train-epoch-step: 32-241 -- Loss: 0.15632641315460205
train-epoch-step: 32-242 -- Loss: 0.22397011518478394
train-epoch-step: 32-243 -- Loss: 0.24025103449821472
train-epoch-step: 32-244 -- Loss: 0.21202999353408813
train-epoch-step: 32-245 -- Loss: 0.20874547958374023
train-epoch-step: 32-246 -- Loss: 0.22283756732940674
train-epoch-step: 32-247 -- Loss: 0.21085518598556519
train-epoch-step: 32-248 -- Loss: 0.18759077787399292
train-epoch-step: 32-249 -- Loss: 0.13770848512649536
train-epoch-step: 32-250 -- Loss: 0.19591447710990906
train-epoch-step: 32-251 -- Loss: 0.10776752233505249
train-epoch-step: 32-252 -- Loss: 0.19946357607841492
train-epoch-step: 32-253 -- Loss: 0.13705790042877197
train-epoch-step: 32-254 -- Loss: 0.21269522607326508
train-epoch-step: 32-255 -- Loss: 0.14553064107894897
train-epoch-step: 32-256 -- Loss: 0.15783891081809998
train-epoch-step: 32-257 -- Loss: 0.18554016947746277
train-epoch-step: 32-258 -- Loss: 0.14621636271476746
train-epoch-step: 32-259 -- Loss: 0.11286070197820663
train-epoch-step: 32-260 -- Loss: 0.2005109190940857
train-epoch-step: 32-261 -- Loss: 0.17452043294906616
train-epoch-step: 32-262 -- Loss: 0.3132324516773224
train-epoch-step: 32-263 -- Loss: 0.19897496700286865
train-epoch-step: 32-264 -- Loss: 0.17234928905963898
train-epoch-step: 32-265 -- Loss: 0.12525233626365662
train-epoch-step: 32-266 -- Loss: 0.15381678938865662
train-epoch-step: 32-267 -- Loss: 0.1278773695230484
train-epoch-step: 32-268 -- Loss: 0.1201612800359726
train-epoch-step: 32-269 -- Loss: 0.1746549904346466
train-epoch-step: 32-270 -- Loss: 0.10742976516485214
train-epoch-step: 32-271 -- Loss: 0.14639586210250854
train-epoch-step: 32-272 -- Loss: 0.11968948692083359
train-epoch-step: 32-273 -- Loss: 0.12647762894630432
train-epoch-step: 32-274 -- Loss: 0.1925780028104782
train-epoch-step: 32-275 -- Loss: 0.19983802735805511
train-epoch-step: 32-276 -- Loss: 0.15541528165340424
train-epoch-step: 32-277 -- Loss: 0.15838927030563354
train-epoch-step: 32-278 -- Loss: 0.1420474350452423
train-epoch-step: 32-279 -- Loss: 0.14711426198482513
train-epoch-step: 32-280 -- Loss: 0.22398336231708527
train-epoch-step: 32-281 -- Loss: 0.18079552054405212
train-epoch-step: 32-282 -- Loss: 0.13945132493972778
train-epoch-step: 32-283 -- Loss: 0.11590496450662613
train-epoch-step: 32-284 -- Loss: 0.191851407289505
train-epoch-step: 32-285 -- Loss: 0.18839243054389954
train-epoch-step: 32-286 -- Loss: 0.15419408679008484
train-epoch-step: 32-287 -- Loss: 0.2004917860031128
train-epoch-step: 32-288 -- Loss: 0.09644174575805664
train-epoch-step: 32-289 -- Loss: 0.12463349103927612
train-epoch-step: 32-290 -- Loss: 0.18668638169765472
train-epoch-step: 32-291 -- Loss: 0.11905410885810852
train-epoch-step: 32-292 -- Loss: 0.19060122966766357
train-epoch-step: 32-293 -- Loss: 0.14022225141525269
train-epoch-step: 32-294 -- Loss: 0.1753891408443451
train-epoch-step: 32-295 -- Loss: 0.40615731477737427
train-epoch-step: 32-296 -- Loss: 0.24444501101970673
train-epoch-step: 32-297 -- Loss: 0.18055197596549988
train-epoch-step: 32-298 -- Loss: 0.24340938031673431
train-epoch-step: 32-299 -- Loss: 0.1597341150045395
train-epoch-step: 32-300 -- Loss: 0.17576304078102112
train-epoch-step: 32-301 -- Loss: 0.18210332095623016
train-epoch-step: 32-302 -- Loss: 0.26482242345809937
train-epoch-step: 32-303 -- Loss: 0.24342484772205353
train-epoch-step: 32-304 -- Loss: 0.1934998631477356
train-epoch-step: 32-305 -- Loss: 0.14875119924545288
train-epoch-step: 32-306 -- Loss: 0.2755666971206665
train-epoch-step: 32-307 -- Loss: 0.18044066429138184
train-epoch-step: 32-308 -- Loss: 0.23880504071712494
train-epoch-step: 32-309 -- Loss: 0.16940414905548096
train-epoch-step: 32-310 -- Loss: 0.16921375691890717
train-epoch-step: 32-311 -- Loss: 0.17094752192497253
train-epoch-step: 32-312 -- Loss: 0.2951563596725464
train-epoch-step: 32-313 -- Loss: 0.11367474496364594
train-epoch-step: 32-314 -- Loss: 0.20765212178230286
train-epoch-step: 32-315 -- Loss: 0.18026910722255707
train-epoch-step: 32-316 -- Loss: 0.17438733577728271
train-epoch-step: 32-317 -- Loss: 0.16330057382583618
train-epoch-step: 32-318 -- Loss: 0.2086174190044403
train-epoch-step: 32-319 -- Loss: 0.1906987428665161
train-epoch-step: 32-320 -- Loss: 0.1254865825176239
train-epoch-step: 32-321 -- Loss: 0.14483587443828583
train-epoch-step: 32-322 -- Loss: 0.2251463532447815
train-epoch-step: 32-323 -- Loss: 0.17021822929382324
train-epoch-step: 32-324 -- Loss: 0.3257867991924286
train-epoch-step: 32-325 -- Loss: 0.16457267105579376
train-epoch-step: 32-326 -- Loss: 0.18446499109268188
train-epoch-step: 32-327 -- Loss: 0.21752268075942993
train-epoch-step: 32-328 -- Loss: 0.21186411380767822
train-epoch-step: 32-329 -- Loss: 0.3567195236682892
train-epoch-step: 32-330 -- Loss: 0.3843153119087219
train-epoch-step: 32-331 -- Loss: 0.22177910804748535
train-epoch-step: 32-332 -- Loss: 0.12036783993244171
train-epoch-step: 32-333 -- Loss: 0.19843260943889618
train-epoch-step: 32-334 -- Loss: 0.1589217185974121
train-epoch-step: 32-335 -- Loss: 0.18780548870563507
train-epoch-step: 32-336 -- Loss: 0.15791942179203033
train-epoch-step: 32-337 -- Loss: 0.21550364792346954
train-epoch-step: 32-338 -- Loss: 0.18448852002620697
train-epoch-step: 32-339 -- Loss: 0.1455727368593216
train-epoch-step: 32-340 -- Loss: 0.21066033840179443
train-epoch-step: 32-341 -- Loss: 0.1541808843612671
train-epoch-step: 32-342 -- Loss: 0.17345762252807617
train-epoch-step: 32-343 -- Loss: 0.165251225233078
train-epoch-step: 32-344 -- Loss: 0.1722533404827118
train-epoch-step: 32-345 -- Loss: 0.13182242214679718
train-epoch-step: 32-346 -- Loss: 0.2065749317407608
train-epoch-step: 32-347 -- Loss: 0.15777669847011566
train-epoch-step: 32-348 -- Loss: 0.2142561376094818
train-epoch-step: 32-349 -- Loss: 0.21592050790786743
train-epoch-step: 32-350 -- Loss: 0.27129071950912476
train-epoch-step: 32-351 -- Loss: 0.19963639974594116
train-epoch-step: 32-352 -- Loss: 0.1314874291419983
train-epoch-step: 32-353 -- Loss: 0.20226722955703735
train-epoch-step: 32-354 -- Loss: 0.29540711641311646
train-epoch-step: 32-355 -- Loss: 0.12264777719974518
train-epoch-step: 32-356 -- Loss: 0.12576904892921448
train-epoch-step: 32-357 -- Loss: 0.2041444331407547
train-epoch-step: 32-358 -- Loss: 0.1868993490934372
train-epoch-step: 32-359 -- Loss: 0.14229419827461243
train-epoch-step: 32-360 -- Loss: 0.12881049513816833
train-epoch-step: 32-361 -- Loss: 0.2496137022972107
train-epoch-step: 32-362 -- Loss: 0.17458125948905945
train-epoch-step: 32-363 -- Loss: 0.1150764673948288
train-epoch-step: 32-364 -- Loss: 0.18531231582164764
train-epoch-step: 32-365 -- Loss: 0.17637866735458374
train-epoch-step: 32-366 -- Loss: 0.207784503698349
train-epoch-step: 32-367 -- Loss: 0.23630279302597046
train-epoch-step: 32-368 -- Loss: 0.21080176532268524
train-epoch-step: 32-369 -- Loss: 0.2914484143257141
train-epoch-step: 32-370 -- Loss: 0.1283932626247406
train-epoch-step: 32-371 -- Loss: 0.12385503947734833
train-epoch-step: 32-372 -- Loss: 0.14774206280708313
train-epoch-step: 32-373 -- Loss: 0.19226881861686707
train-epoch-step: 32-374 -- Loss: 0.1559583842754364
train-epoch-step: 32-375 -- Loss: 0.274389386177063
train-epoch-step: 32-376 -- Loss: 0.17197304964065552
train-epoch-step: 32-377 -- Loss: 0.23585481941699982
train-epoch-step: 32-378 -- Loss: 0.20340338349342346
train-epoch-step: 32-379 -- Loss: 0.12181591242551804
train-epoch-step: 32-380 -- Loss: 0.09339376538991928
train-epoch-step: 32-381 -- Loss: 0.2494421899318695
train-epoch-step: 32-382 -- Loss: 0.24263930320739746
train-epoch-step: 32-383 -- Loss: 0.21986544132232666
train-epoch-step: 32-384 -- Loss: 0.22806011140346527
train-epoch-step: 32-385 -- Loss: 0.2110009491443634
train-epoch-step: 32-386 -- Loss: 0.27525588870048523
train-epoch-step: 32-387 -- Loss: 0.21137583255767822
train-epoch-step: 32-388 -- Loss: 0.2080346643924713
train-epoch-step: 32-389 -- Loss: 0.1765371710062027
train-epoch-step: 32-390 -- Loss: 0.1452692449092865
train-epoch-step: 32-391 -- Loss: 0.15521728992462158
train-epoch-step: 32-392 -- Loss: 0.19949714839458466
train-epoch-step: 32-393 -- Loss: 0.16420350968837738
train-epoch-step: 32-394 -- Loss: 0.2077765315771103
train-epoch-step: 32-395 -- Loss: 0.16625714302062988
train-epoch-step: 32-396 -- Loss: 0.12963664531707764
train-epoch-step: 32-397 -- Loss: 0.12953802943229675
train-epoch-step: 32-398 -- Loss: 0.20213870704174042
train-epoch-step: 32-399 -- Loss: 0.1814228892326355
train-epoch-step: 32-400 -- Loss: 0.2885735034942627
train-epoch-step: 32-401 -- Loss: 0.12241923809051514
train-epoch-step: 32-402 -- Loss: 0.26004040241241455
train-epoch-step: 32-403 -- Loss: 0.16973647475242615
train-epoch-step: 32-404 -- Loss: 0.13805028796195984
train-epoch-step: 32-405 -- Loss: 0.15059398114681244
train-epoch-step: 32-406 -- Loss: 0.1761571615934372
train-epoch-step: 32-407 -- Loss: 0.11493652313947678
train-epoch-step: 32-408 -- Loss: 0.16327276825904846
train-epoch-step: 32-409 -- Loss: 0.18031199276447296
train-epoch-step: 32-410 -- Loss: 0.17616023123264313
train-epoch-step: 32-411 -- Loss: 0.1959248185157776
train-epoch-step: 32-412 -- Loss: 0.13054446876049042
train-epoch-step: 32-413 -- Loss: 0.14786621928215027
train-epoch-step: 32-414 -- Loss: 0.13636016845703125
train-epoch-step: 32-415 -- Loss: 0.1389133334159851
train-epoch-step: 32-416 -- Loss: 0.2712933421134949
train-epoch-step: 32-417 -- Loss: 0.19606995582580566
train-epoch-step: 32-418 -- Loss: 0.23887096345424652
train-epoch-step: 32-419 -- Loss: 0.16636595129966736
train-epoch-step: 32-420 -- Loss: 0.1562599092721939
train-epoch-step: 32-421 -- Loss: 0.17943359911441803
train-epoch-step: 32-422 -- Loss: 0.1500871777534485
train-epoch-step: 32-423 -- Loss: 0.17125850915908813
train-epoch-step: 32-424 -- Loss: 0.14025115966796875
train-epoch-step: 32-425 -- Loss: 0.18719276785850525
train-epoch-step: 32-426 -- Loss: 0.16429033875465393
train-epoch-step: 32-427 -- Loss: 0.12847889959812164
train-epoch-step: 32-428 -- Loss: 0.20515188574790955
train-epoch-step: 32-429 -- Loss: 0.1818792223930359
train-epoch-step: 32-430 -- Loss: 0.14130517840385437
train-epoch-step: 32-431 -- Loss: 0.17067033052444458
train-epoch-step: 32-432 -- Loss: 0.2484806329011917
train-epoch-step: 32-433 -- Loss: 0.1371987760066986
train-epoch-step: 32-434 -- Loss: 0.13136635720729828
train-epoch-step: 32-435 -- Loss: 0.15428254008293152
train-epoch-step: 32-436 -- Loss: 0.15598666667938232
train-epoch-step: 32-437 -- Loss: 0.1363358050584793
train-epoch-step: 32-438 -- Loss: 0.17509952187538147
train-epoch-step: 32-439 -- Loss: 0.2681225836277008
train-epoch-step: 32-440 -- Loss: 0.1408325433731079
train-epoch-step: 32-441 -- Loss: 0.20535960793495178
train-epoch-step: 32-442 -- Loss: 0.18295855820178986
train-epoch-step: 32-443 -- Loss: 0.1550791710615158
train-epoch-step: 32-444 -- Loss: 0.2037094384431839
train-epoch-step: 32-445 -- Loss: 0.17965468764305115
train-epoch-step: 32-446 -- Loss: 0.1545124650001526
train-epoch-step: 32-447 -- Loss: 0.19617542624473572
train-epoch-step: 32-448 -- Loss: 0.23549674451351166
train-epoch-step: 32-449 -- Loss: 0.19528383016586304
train-epoch-step: 32-450 -- Loss: 0.1949702799320221
train-epoch-step: 32-451 -- Loss: 0.14519737660884857
train-epoch-step: 32-452 -- Loss: 0.13393662869930267
train-epoch-step: 32-453 -- Loss: 0.09653244912624359
train-epoch-step: 32-454 -- Loss: 0.23606741428375244
train-epoch-step: 32-455 -- Loss: 0.1298261284828186
train-epoch-step: 32-456 -- Loss: 0.12349726259708405
train-epoch-step: 32-457 -- Loss: 0.24793732166290283
train-epoch-step: 32-458 -- Loss: 0.15722814202308655
train-epoch-step: 32-459 -- Loss: 0.22414430975914001
train-epoch-step: 32-460 -- Loss: 0.12894342839717865
train-epoch-step: 32-461 -- Loss: 0.1346321403980255
train-epoch-step: 32-462 -- Loss: 0.16291432082653046
train-epoch-step: 32-463 -- Loss: 0.1404939591884613
train-epoch-step: 32-464 -- Loss: 0.16900362074375153
train-epoch-step: 32-465 -- Loss: 0.2528320848941803
train-epoch-step: 32-466 -- Loss: 0.2052292823791504
train-epoch-step: 32-467 -- Loss: 0.11638971418142319
train-epoch-step: 32-468 -- Loss: 0.17302978038787842
train-epoch-step: 32-469 -- Loss: 0.21884961426258087
train-epoch-step: 32-470 -- Loss: 0.17434050142765045
train-epoch-step: 32-471 -- Loss: 0.16642652451992035
train-epoch-step: 32-472 -- Loss: 0.1596773862838745
train-epoch-step: 32-473 -- Loss: 0.1731477677822113
train-epoch-step: 32-474 -- Loss: 0.12563157081604004
train-epoch-step: 32-475 -- Loss: 0.11081749945878983
train-epoch-step: 32-476 -- Loss: 0.20528341829776764
train-epoch-step: 32-477 -- Loss: 0.19875696301460266
train-epoch-step: 32-478 -- Loss: 0.19132000207901
train-epoch-step: 32-479 -- Loss: 0.1403997540473938
train-epoch-step: 32-480 -- Loss: 0.19238823652267456
train-epoch-step: 32-481 -- Loss: 0.2823261320590973
train-epoch-step: 32-482 -- Loss: 0.25622087717056274
train-epoch-step: 32-483 -- Loss: 0.18161919713020325
train-epoch-step: 32-484 -- Loss: 0.21507982909679413
train-epoch-step: 32-485 -- Loss: 0.1286221444606781
train-epoch-step: 32-486 -- Loss: 0.2374109923839569
train-epoch-step: 32-487 -- Loss: 0.231848806142807
train-epoch-step: 32-488 -- Loss: 0.18812352418899536
train-epoch-step: 32-489 -- Loss: 0.2279299795627594
train-epoch-step: 32-490 -- Loss: 0.1394270956516266
train-epoch-step: 32-491 -- Loss: 0.1430915743112564
train-epoch-step: 32-492 -- Loss: 0.12410517781972885
train-epoch-step: 32-493 -- Loss: 0.20171403884887695
train-epoch-step: 32-494 -- Loss: 0.20040009915828705
train-epoch-step: 32-495 -- Loss: 0.20097023248672485
train-epoch-step: 32-496 -- Loss: 0.14049449563026428
train-epoch-step: 32-497 -- Loss: 0.1873510330915451
train-epoch-step: 32-498 -- Loss: 0.15009310841560364
train-epoch-step: 32-499 -- Loss: 0.1721925586462021
train-epoch-step: 32-500 -- Loss: 0.15787234902381897
train-epoch-step: 32-501 -- Loss: 0.2153860330581665
train-epoch-step: 32-502 -- Loss: 0.16006684303283691
train-epoch-step: 32-503 -- Loss: 0.22261914610862732
train-epoch-step: 32-504 -- Loss: 0.11904146522283554
train-epoch-step: 32-505 -- Loss: 0.17204724252223969
train-epoch-step: 32-506 -- Loss: 0.11597584933042526
train-epoch-step: 32-507 -- Loss: 0.18780985474586487
train-epoch-step: 32-508 -- Loss: 0.18032658100128174
train-epoch-step: 32-509 -- Loss: 0.1760433465242386
train-epoch-step: 32-510 -- Loss: 0.12596920132637024
train-epoch-step: 32-511 -- Loss: 0.21831172704696655
train-epoch-step: 32-512 -- Loss: 0.1809045970439911
train-epoch-step: 32-513 -- Loss: 0.1941240280866623
train-epoch-step: 32-514 -- Loss: 0.1463238000869751
train-epoch-step: 32-515 -- Loss: 0.1610763520002365
train-epoch-step: 32-516 -- Loss: 0.17424917221069336
train-epoch-step: 32-517 -- Loss: 0.17343148589134216
train-epoch-step: 32-518 -- Loss: 0.1364642083644867
train-epoch-step: 32-519 -- Loss: 0.13502341508865356
train-epoch-step: 32-520 -- Loss: 0.1852659285068512
train-epoch-step: 32-521 -- Loss: 0.22967277467250824
train-epoch-step: 32-522 -- Loss: 0.17886509001255035
train-epoch-step: 32-523 -- Loss: 0.15498460829257965
train-epoch-step: 32-524 -- Loss: 0.16795219480991364
train-epoch-step: 32-525 -- Loss: 0.1977936327457428
train-epoch-step: 32-526 -- Loss: 0.12946169078350067
train-epoch-step: 32-527 -- Loss: 0.15444371104240417
train-epoch-step: 32-528 -- Loss: 0.15775376558303833
train-epoch-step: 32-529 -- Loss: 0.15512359142303467
train-epoch-step: 32-530 -- Loss: 0.16971080005168915
train-epoch-step: 32-531 -- Loss: 0.19934888184070587
train-epoch-step: 32-532 -- Loss: 0.17188723385334015
train-epoch-step: 32-533 -- Loss: 0.17481964826583862
train-epoch-step: 32-534 -- Loss: 0.13152801990509033
train-epoch-step: 32-535 -- Loss: 0.27478328347206116
train-epoch-step: 32-536 -- Loss: 0.16139212250709534
train-epoch-step: 32-537 -- Loss: 0.15121781826019287
train-epoch-step: 32-538 -- Loss: 0.10274996608495712
train-epoch-step: 32-539 -- Loss: 0.18169042468070984
train-epoch-step: 32-540 -- Loss: 0.1370772272348404
train-epoch-step: 32-541 -- Loss: 0.20725032687187195
train-epoch-step: 32-542 -- Loss: 0.2276798039674759
train-epoch-step: 32-543 -- Loss: 0.17575086653232574
train-epoch-step: 32-544 -- Loss: 0.2353491187095642
train-epoch-step: 32-545 -- Loss: 0.1931459903717041
train-epoch-step: 32-546 -- Loss: 0.2258983552455902
train-epoch-step: 32-547 -- Loss: 0.1838284730911255
train-epoch-step: 32-548 -- Loss: 0.09472581744194031
train-epoch-step: 32-549 -- Loss: 0.15207251906394958
train-epoch-step: 32-550 -- Loss: 0.2013624906539917
train-epoch-step: 32-551 -- Loss: 0.1576806604862213
train-epoch-step: 32-552 -- Loss: 0.12668266892433167
train-epoch-step: 32-553 -- Loss: 0.1869184970855713
train-epoch-step: 32-554 -- Loss: 0.18740183115005493
train-epoch-step: 32-555 -- Loss: 0.22422325611114502
train-epoch-step: 32-556 -- Loss: 0.15269258618354797
train-epoch-step: 32-557 -- Loss: 0.24495482444763184
train-epoch-step: 32-558 -- Loss: 0.22763343155384064
train-epoch-step: 32-559 -- Loss: 0.1387387216091156
train-epoch-step: 32-560 -- Loss: 0.20654083788394928
train-epoch-step: 32-561 -- Loss: 0.1848173439502716
train-epoch-step: 32-562 -- Loss: 0.1648913323879242
train-epoch-step: 32-563 -- Loss: 0.18261218070983887
train-epoch-step: 32-564 -- Loss: 0.09991033375263214
train-epoch-step: 32-565 -- Loss: 0.17952625453472137
train-epoch-step: 32-566 -- Loss: 0.14834780991077423
train-epoch-step: 32-567 -- Loss: 0.21588532626628876
train-epoch-step: 32-568 -- Loss: 0.16328482329845428
train-epoch-step: 32-569 -- Loss: 0.2391621172428131
train-epoch-step: 32-570 -- Loss: 0.1689794659614563
train-epoch-step: 32-571 -- Loss: 0.21284449100494385
train-epoch-step: 32-572 -- Loss: 0.23991477489471436
train-epoch-step: 32-573 -- Loss: 0.20152060687541962
train-epoch-step: 32-574 -- Loss: 0.2420860230922699
train-epoch-step: 32-575 -- Loss: 0.2909564971923828
train-epoch-step: 32-576 -- Loss: 0.11946956813335419
train-epoch-step: 32-577 -- Loss: 0.16464129090309143
train-epoch-step: 32-578 -- Loss: 0.21480000019073486
train-epoch-step: 32-579 -- Loss: 0.16387003660202026
train-epoch-step: 32-580 -- Loss: 0.1822206974029541
train-epoch-step: 32-581 -- Loss: 0.14047005772590637
train-epoch-step: 32-582 -- Loss: 0.2062469869852066
train-epoch-step: 32-583 -- Loss: 0.21911266446113586
train-epoch-step: 32-584 -- Loss: 0.16613534092903137
train-epoch-step: 32-585 -- Loss: 0.19350339472293854
train-epoch-step: 32-586 -- Loss: 0.25893452763557434
train-epoch-step: 32-587 -- Loss: 0.16072307527065277
train-epoch-step: 32-588 -- Loss: 0.1296379566192627
val-epoch-step: 32-589 -- Loss: 0.20508795976638794
val-epoch-step: 32-590 -- Loss: 0.15367695689201355
val-epoch-step: 32-591 -- Loss: 0.23039177060127258
val-epoch-step: 32-592 -- Loss: 0.17700980603694916
val-epoch-step: 32-593 -- Loss: 0.1676206886768341
val-epoch-step: 32-594 -- Loss: 0.41038963198661804
val-epoch-step: 32-595 -- Loss: 0.18909889459609985
val-epoch-step: 32-596 -- Loss: 0.19561131298542023
val-epoch-step: 32-597 -- Loss: 0.17170394957065582
val-epoch-step: 32-598 -- Loss: 0.14826947450637817
val-epoch-step: 32-599 -- Loss: 0.18405258655548096
val-epoch-step: 32-600 -- Loss: 0.23416808247566223
val-epoch-step: 32-601 -- Loss: 0.14992539584636688
val-epoch-step: 32-602 -- Loss: 0.1369641274213791
val-epoch-step: 32-603 -- Loss: 0.19212818145751953
val-epoch-step: 32-604 -- Loss: 0.1512279510498047
val-epoch-step: 32-605 -- Loss: 0.14633724093437195
val-epoch-step: 32-606 -- Loss: 0.2623368799686432
val-epoch-step: 32-607 -- Loss: 0.12947489321231842
val-epoch-step: 32-608 -- Loss: 0.2502349615097046
val-epoch-step: 32-609 -- Loss: 0.17236261069774628
val-epoch-step: 32-610 -- Loss: 0.18632324039936066
val-epoch-step: 32-611 -- Loss: 0.15648913383483887
val-epoch-step: 32-612 -- Loss: 0.405825138092041
val-epoch-step: 32-613 -- Loss: 0.17584329843521118
val-epoch-step: 32-614 -- Loss: 0.16110680997371674
val-epoch-step: 32-615 -- Loss: 0.177969291806221
val-epoch-step: 32-616 -- Loss: 0.14518532156944275
val-epoch-step: 32-617 -- Loss: 0.18578191101551056
val-epoch-step: 32-618 -- Loss: 0.18948325514793396
val-epoch-step: 32-619 -- Loss: 0.22735071182250977
val-epoch-step: 32-620 -- Loss: 0.1464844048023224
val-epoch-step: 32-621 -- Loss: 0.12683643400669098
val-epoch-step: 32-622 -- Loss: 0.14681608974933624
val-epoch-step: 32-623 -- Loss: 0.15535466372966766
val-epoch-step: 32-624 -- Loss: 0.14772623777389526
val-epoch-step: 32-625 -- Loss: 0.15804171562194824
val-epoch-step: 32-626 -- Loss: 0.1551722288131714
val-epoch-step: 32-627 -- Loss: 0.18756364285945892
val-epoch-step: 32-628 -- Loss: 0.7190893888473511
val-epoch-step: 32-629 -- Loss: 0.21131178736686707
val-epoch-step: 32-630 -- Loss: 0.3425050377845764
val-epoch-step: 32-631 -- Loss: 0.13984332978725433
val-epoch-step: 32-632 -- Loss: 0.21150609850883484
val-epoch-step: 32-633 -- Loss: 0.1547536998987198
val-epoch-step: 32-634 -- Loss: 0.1546025574207306
val-epoch-step: 32-635 -- Loss: 0.1141333132982254
val-epoch-step: 32-636 -- Loss: 0.16490815579891205
val-epoch-step: 32-637 -- Loss: 0.18107715249061584
val-epoch-step: 32-638 -- Loss: 0.1620994657278061
val-epoch-step: 32-639 -- Loss: 0.2638850212097168
val-epoch-step: 32-640 -- Loss: 0.256408154964447
val-epoch-step: 32-641 -- Loss: 0.12852264940738678
val-epoch-step: 32-642 -- Loss: 0.20161470770835876
val-epoch-step: 32-643 -- Loss: 0.19759920239448547
val-epoch-step: 32-644 -- Loss: 0.17002813518047333
val-epoch-step: 32-645 -- Loss: 0.21796095371246338
val-epoch-step: 32-646 -- Loss: 0.14119336009025574
val-epoch-step: 32-647 -- Loss: 0.13336464762687683
val-epoch-step: 32-648 -- Loss: 0.15956683456897736
val-epoch-step: 32-649 -- Loss: 0.21468015015125275
val-epoch-step: 32-650 -- Loss: 0.25234174728393555
val-epoch-step: 32-651 -- Loss: 0.15137824416160583
val-epoch-step: 32-652 -- Loss: 0.15499038994312286
val-epoch-step: 32-653 -- Loss: 0.20048415660858154
val-epoch-step: 32-654 -- Loss: 0.11135901510715485
Epoch: 32 -- Train Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 33-0 -- Loss: 0.2267645299434662
train-epoch-step: 33-1 -- Loss: 0.14561495184898376
train-epoch-step: 33-2 -- Loss: 0.19746163487434387
train-epoch-step: 33-3 -- Loss: 0.1605272889137268
train-epoch-step: 33-4 -- Loss: 0.15950974822044373
train-epoch-step: 33-5 -- Loss: 0.17683953046798706
train-epoch-step: 33-6 -- Loss: 0.21743911504745483
train-epoch-step: 33-7 -- Loss: 0.16526760160923004
train-epoch-step: 33-8 -- Loss: 0.18270978331565857
train-epoch-step: 33-9 -- Loss: 0.2272045910358429
train-epoch-step: 33-10 -- Loss: 0.1958255022764206
train-epoch-step: 33-11 -- Loss: 0.18744593858718872
train-epoch-step: 33-12 -- Loss: 0.15234245359897614
train-epoch-step: 33-13 -- Loss: 0.17831139266490936
train-epoch-step: 33-14 -- Loss: 0.16581761837005615
train-epoch-step: 33-15 -- Loss: 0.15786702930927277
train-epoch-step: 33-16 -- Loss: 0.16827331483364105
train-epoch-step: 33-17 -- Loss: 0.22076091170310974
train-epoch-step: 33-18 -- Loss: 0.1974220722913742
train-epoch-step: 33-19 -- Loss: 0.13561607897281647
train-epoch-step: 33-20 -- Loss: 0.21852128207683563
train-epoch-step: 33-21 -- Loss: 0.2557277977466583
train-epoch-step: 33-22 -- Loss: 0.13522139191627502
train-epoch-step: 33-23 -- Loss: 0.1472027450799942
train-epoch-step: 33-24 -- Loss: 0.12627515196800232
train-epoch-step: 33-25 -- Loss: 0.22960683703422546
train-epoch-step: 33-26 -- Loss: 0.20075249671936035
train-epoch-step: 33-27 -- Loss: 0.23990732431411743
train-epoch-step: 33-28 -- Loss: 0.12939965724945068
train-epoch-step: 33-29 -- Loss: 0.24516110122203827
train-epoch-step: 33-30 -- Loss: 0.10733724385499954
train-epoch-step: 33-31 -- Loss: 0.1401624083518982
train-epoch-step: 33-32 -- Loss: 0.17635035514831543
train-epoch-step: 33-33 -- Loss: 0.2763743996620178
train-epoch-step: 33-34 -- Loss: 0.1743660569190979
train-epoch-step: 33-35 -- Loss: 0.2614116668701172
train-epoch-step: 33-36 -- Loss: 0.13937047123908997
train-epoch-step: 33-37 -- Loss: 0.1375511735677719
train-epoch-step: 33-38 -- Loss: 0.18576280772686005
train-epoch-step: 33-39 -- Loss: 0.21898958086967468
train-epoch-step: 33-40 -- Loss: 0.19604116678237915
train-epoch-step: 33-41 -- Loss: 0.2169615775346756
train-epoch-step: 33-42 -- Loss: 0.1483815610408783
train-epoch-step: 33-43 -- Loss: 0.2713627517223358
train-epoch-step: 33-44 -- Loss: 0.12670141458511353
train-epoch-step: 33-45 -- Loss: 0.11872876435518265
train-epoch-step: 33-46 -- Loss: 0.1719512939453125
train-epoch-step: 33-47 -- Loss: 0.20628687739372253
train-epoch-step: 33-48 -- Loss: 0.15656796097755432
train-epoch-step: 33-49 -- Loss: 0.2318999171257019
train-epoch-step: 33-50 -- Loss: 0.10931327939033508
train-epoch-step: 33-51 -- Loss: 0.18131336569786072
train-epoch-step: 33-52 -- Loss: 0.1635741889476776
train-epoch-step: 33-53 -- Loss: 0.20586663484573364
train-epoch-step: 33-54 -- Loss: 0.28241080045700073
train-epoch-step: 33-55 -- Loss: 0.16471704840660095
train-epoch-step: 33-56 -- Loss: 0.17227762937545776
train-epoch-step: 33-57 -- Loss: 0.23665352165699005
train-epoch-step: 33-58 -- Loss: 0.28605130314826965
train-epoch-step: 33-59 -- Loss: 0.24537765979766846
train-epoch-step: 33-60 -- Loss: 0.13151666522026062
train-epoch-step: 33-61 -- Loss: 0.20718494057655334
train-epoch-step: 33-62 -- Loss: 0.1824922263622284
train-epoch-step: 33-63 -- Loss: 0.13766354322433472
train-epoch-step: 33-64 -- Loss: 0.14682072401046753
train-epoch-step: 33-65 -- Loss: 0.20068079233169556
train-epoch-step: 33-66 -- Loss: 0.1114015132188797
train-epoch-step: 33-67 -- Loss: 0.12640202045440674
train-epoch-step: 33-68 -- Loss: 0.22281506657600403
train-epoch-step: 33-69 -- Loss: 0.12443923205137253
train-epoch-step: 33-70 -- Loss: 0.22318312525749207
train-epoch-step: 33-71 -- Loss: 0.25722765922546387
train-epoch-step: 33-72 -- Loss: 0.18207822740077972
train-epoch-step: 33-73 -- Loss: 0.20640984177589417
train-epoch-step: 33-74 -- Loss: 0.09602980315685272
train-epoch-step: 33-75 -- Loss: 0.12684808671474457
train-epoch-step: 33-76 -- Loss: 0.14541220664978027
train-epoch-step: 33-77 -- Loss: 0.23084715008735657
train-epoch-step: 33-78 -- Loss: 0.2561289370059967
train-epoch-step: 33-79 -- Loss: 0.18967536091804504
train-epoch-step: 33-80 -- Loss: 0.2507491409778595
train-epoch-step: 33-81 -- Loss: 0.12696422636508942
train-epoch-step: 33-82 -- Loss: 0.25127410888671875
train-epoch-step: 33-83 -- Loss: 0.1844761222600937
train-epoch-step: 33-84 -- Loss: 0.18919068574905396
train-epoch-step: 33-85 -- Loss: 0.17789584398269653
train-epoch-step: 33-86 -- Loss: 0.11747462302446365
train-epoch-step: 33-87 -- Loss: 0.22048625349998474
train-epoch-step: 33-88 -- Loss: 0.13986025750637054
train-epoch-step: 33-89 -- Loss: 0.1842266023159027
train-epoch-step: 33-90 -- Loss: 0.19127030670642853
train-epoch-step: 33-91 -- Loss: 0.24672815203666687
train-epoch-step: 33-92 -- Loss: 0.15816298127174377
train-epoch-step: 33-93 -- Loss: 0.17037737369537354
train-epoch-step: 33-94 -- Loss: 0.22034215927124023
train-epoch-step: 33-95 -- Loss: 0.19002315402030945
train-epoch-step: 33-96 -- Loss: 0.2172241359949112
train-epoch-step: 33-97 -- Loss: 0.17626065015792847
train-epoch-step: 33-98 -- Loss: 0.15515899658203125
train-epoch-step: 33-99 -- Loss: 0.1794184446334839
train-epoch-step: 33-100 -- Loss: 0.1908777356147766
train-epoch-step: 33-101 -- Loss: 0.2718410789966583
train-epoch-step: 33-102 -- Loss: 0.21382007002830505
train-epoch-step: 33-103 -- Loss: 0.18353502452373505
train-epoch-step: 33-104 -- Loss: 0.14917531609535217
train-epoch-step: 33-105 -- Loss: 0.27349886298179626
train-epoch-step: 33-106 -- Loss: 0.1770949512720108
train-epoch-step: 33-107 -- Loss: 0.19344307482242584
train-epoch-step: 33-108 -- Loss: 0.18879161775112152
train-epoch-step: 33-109 -- Loss: 0.14733397960662842
train-epoch-step: 33-110 -- Loss: 0.18612223863601685
train-epoch-step: 33-111 -- Loss: 0.18987032771110535
train-epoch-step: 33-112 -- Loss: 0.16715341806411743
train-epoch-step: 33-113 -- Loss: 0.16344809532165527
train-epoch-step: 33-114 -- Loss: 0.20084387063980103
train-epoch-step: 33-115 -- Loss: 0.1618574857711792
train-epoch-step: 33-116 -- Loss: 0.14186452329158783
train-epoch-step: 33-117 -- Loss: 0.12576556205749512
train-epoch-step: 33-118 -- Loss: 0.19343338906764984
train-epoch-step: 33-119 -- Loss: 0.15782055258750916
train-epoch-step: 33-120 -- Loss: 0.25730910897254944
train-epoch-step: 33-121 -- Loss: 0.2422409951686859
train-epoch-step: 33-122 -- Loss: 0.22539828717708588
train-epoch-step: 33-123 -- Loss: 0.20447292923927307
train-epoch-step: 33-124 -- Loss: 0.12387298047542572
train-epoch-step: 33-125 -- Loss: 0.1561836451292038
train-epoch-step: 33-126 -- Loss: 0.23068341612815857
train-epoch-step: 33-127 -- Loss: 0.1813770979642868
train-epoch-step: 33-128 -- Loss: 0.171245276927948
train-epoch-step: 33-129 -- Loss: 0.14378505945205688
train-epoch-step: 33-130 -- Loss: 0.1967364102602005
train-epoch-step: 33-131 -- Loss: 0.13951316475868225
train-epoch-step: 33-132 -- Loss: 0.18875229358673096
train-epoch-step: 33-133 -- Loss: 0.11886434257030487
train-epoch-step: 33-134 -- Loss: 0.1990031599998474
train-epoch-step: 33-135 -- Loss: 0.14293712377548218
train-epoch-step: 33-136 -- Loss: 0.12828876078128815
train-epoch-step: 33-137 -- Loss: 0.24481213092803955
train-epoch-step: 33-138 -- Loss: 0.25381287932395935
train-epoch-step: 33-139 -- Loss: 0.135738804936409
train-epoch-step: 33-140 -- Loss: 0.20386114716529846
train-epoch-step: 33-141 -- Loss: 0.227793887257576
train-epoch-step: 33-142 -- Loss: 0.19932414591312408
train-epoch-step: 33-143 -- Loss: 0.16915856301784515
train-epoch-step: 33-144 -- Loss: 0.18664509057998657
train-epoch-step: 33-145 -- Loss: 0.14190462231636047
train-epoch-step: 33-146 -- Loss: 0.17847368121147156
train-epoch-step: 33-147 -- Loss: 0.16554461419582367
train-epoch-step: 33-148 -- Loss: 0.1590738594532013
train-epoch-step: 33-149 -- Loss: 0.12291165441274643
train-epoch-step: 33-150 -- Loss: 0.18415555357933044
train-epoch-step: 33-151 -- Loss: 0.19837847352027893
train-epoch-step: 33-152 -- Loss: 0.19179695844650269
train-epoch-step: 33-153 -- Loss: 0.26896020770072937
train-epoch-step: 33-154 -- Loss: 0.12920504808425903
train-epoch-step: 33-155 -- Loss: 0.1335681974887848
train-epoch-step: 33-156 -- Loss: 0.11875417083501816
train-epoch-step: 33-157 -- Loss: 0.16776864230632782
train-epoch-step: 33-158 -- Loss: 0.1663491576910019
train-epoch-step: 33-159 -- Loss: 0.17746391892433167
train-epoch-step: 33-160 -- Loss: 0.21999260783195496
train-epoch-step: 33-161 -- Loss: 0.21048706769943237
train-epoch-step: 33-162 -- Loss: 0.20617753267288208
train-epoch-step: 33-163 -- Loss: 0.1868562549352646
train-epoch-step: 33-164 -- Loss: 0.1948200911283493
train-epoch-step: 33-165 -- Loss: 0.17233017086982727
train-epoch-step: 33-166 -- Loss: 0.12954799830913544
train-epoch-step: 33-167 -- Loss: 0.12565995752811432
train-epoch-step: 33-168 -- Loss: 0.20568068325519562
train-epoch-step: 33-169 -- Loss: 0.13960745930671692
train-epoch-step: 33-170 -- Loss: 0.20310762524604797
train-epoch-step: 33-171 -- Loss: 0.14403870701789856
train-epoch-step: 33-172 -- Loss: 0.26626914739608765
train-epoch-step: 33-173 -- Loss: 0.1411745250225067
train-epoch-step: 33-174 -- Loss: 0.2538798451423645
train-epoch-step: 33-175 -- Loss: 0.1822081357240677
train-epoch-step: 33-176 -- Loss: 0.1365155726671219
train-epoch-step: 33-177 -- Loss: 0.183328315615654
train-epoch-step: 33-178 -- Loss: 0.17954842746257782
train-epoch-step: 33-179 -- Loss: 0.15661850571632385
train-epoch-step: 33-180 -- Loss: 0.15191249549388885
train-epoch-step: 33-181 -- Loss: 0.16589857637882233
train-epoch-step: 33-182 -- Loss: 0.18702414631843567
train-epoch-step: 33-183 -- Loss: 0.2645484209060669
train-epoch-step: 33-184 -- Loss: 0.13894023001194
train-epoch-step: 33-185 -- Loss: 0.14224618673324585
train-epoch-step: 33-186 -- Loss: 0.18854749202728271
train-epoch-step: 33-187 -- Loss: 0.21249593794345856
train-epoch-step: 33-188 -- Loss: 0.17636142671108246
train-epoch-step: 33-189 -- Loss: 0.10790054500102997
train-epoch-step: 33-190 -- Loss: 0.18652185797691345
train-epoch-step: 33-191 -- Loss: 0.15932217240333557
train-epoch-step: 33-192 -- Loss: 0.23299375176429749
train-epoch-step: 33-193 -- Loss: 0.21102523803710938
train-epoch-step: 33-194 -- Loss: 0.18382538855075836
train-epoch-step: 33-195 -- Loss: 0.16050255298614502
train-epoch-step: 33-196 -- Loss: 0.1692117303609848
train-epoch-step: 33-197 -- Loss: 0.13071149587631226
train-epoch-step: 33-198 -- Loss: 0.1270245611667633
train-epoch-step: 33-199 -- Loss: 0.15924182534217834
train-epoch-step: 33-200 -- Loss: 0.12313687801361084
train-epoch-step: 33-201 -- Loss: 0.19483481347560883
train-epoch-step: 33-202 -- Loss: 0.13565658032894135
train-epoch-step: 33-203 -- Loss: 0.17613932490348816
train-epoch-step: 33-204 -- Loss: 0.14201055467128754
train-epoch-step: 33-205 -- Loss: 0.19828712940216064
train-epoch-step: 33-206 -- Loss: 0.2065778374671936
train-epoch-step: 33-207 -- Loss: 0.15680214762687683
train-epoch-step: 33-208 -- Loss: 0.1785997599363327
train-epoch-step: 33-209 -- Loss: 0.1462976634502411
train-epoch-step: 33-210 -- Loss: 0.1410434991121292
train-epoch-step: 33-211 -- Loss: 0.20876231789588928
train-epoch-step: 33-212 -- Loss: 0.20054462552070618
train-epoch-step: 33-213 -- Loss: 0.12622521817684174
train-epoch-step: 33-214 -- Loss: 0.14593616127967834
train-epoch-step: 33-215 -- Loss: 0.12940506637096405
train-epoch-step: 33-216 -- Loss: 0.21717143058776855
train-epoch-step: 33-217 -- Loss: 0.24052433669567108
train-epoch-step: 33-218 -- Loss: 0.1433628797531128
train-epoch-step: 33-219 -- Loss: 0.1718638837337494
train-epoch-step: 33-220 -- Loss: 0.1343807876110077
train-epoch-step: 33-221 -- Loss: 0.21942083537578583
train-epoch-step: 33-222 -- Loss: 0.11933304369449615
train-epoch-step: 33-223 -- Loss: 0.1860456019639969
train-epoch-step: 33-224 -- Loss: 0.2085011601448059
train-epoch-step: 33-225 -- Loss: 0.27784669399261475
train-epoch-step: 33-226 -- Loss: 0.21291445195674896
train-epoch-step: 33-227 -- Loss: 0.22244256734848022
train-epoch-step: 33-228 -- Loss: 0.1786702424287796
train-epoch-step: 33-229 -- Loss: 0.17600730061531067
train-epoch-step: 33-230 -- Loss: 0.1662786900997162
train-epoch-step: 33-231 -- Loss: 0.15906265377998352
train-epoch-step: 33-232 -- Loss: 0.1939704716205597
train-epoch-step: 33-233 -- Loss: 0.08416316658258438
train-epoch-step: 33-234 -- Loss: 0.17925697565078735
train-epoch-step: 33-235 -- Loss: 0.15409979224205017
train-epoch-step: 33-236 -- Loss: 0.18228024244308472
train-epoch-step: 33-237 -- Loss: 0.2442929893732071
train-epoch-step: 33-238 -- Loss: 0.1550668329000473
train-epoch-step: 33-239 -- Loss: 0.13177147507667542
train-epoch-step: 33-240 -- Loss: 0.22747856378555298
train-epoch-step: 33-241 -- Loss: 0.15908432006835938
train-epoch-step: 33-242 -- Loss: 0.22174841165542603
train-epoch-step: 33-243 -- Loss: 0.2434069663286209
train-epoch-step: 33-244 -- Loss: 0.2081398069858551
train-epoch-step: 33-245 -- Loss: 0.21160198748111725
train-epoch-step: 33-246 -- Loss: 0.2210676521062851
train-epoch-step: 33-247 -- Loss: 0.21245917677879333
train-epoch-step: 33-248 -- Loss: 0.1911899447441101
train-epoch-step: 33-249 -- Loss: 0.1397186815738678
train-epoch-step: 33-250 -- Loss: 0.20130352675914764
train-epoch-step: 33-251 -- Loss: 0.10678528249263763
train-epoch-step: 33-252 -- Loss: 0.1997445821762085
train-epoch-step: 33-253 -- Loss: 0.13719670474529266
train-epoch-step: 33-254 -- Loss: 0.21541637182235718
train-epoch-step: 33-255 -- Loss: 0.14693136513233185
train-epoch-step: 33-256 -- Loss: 0.15512900054454803
train-epoch-step: 33-257 -- Loss: 0.19645729660987854
train-epoch-step: 33-258 -- Loss: 0.15497742593288422
train-epoch-step: 33-259 -- Loss: 0.11837659776210785
train-epoch-step: 33-260 -- Loss: 0.2010815143585205
train-epoch-step: 33-261 -- Loss: 0.1790253221988678
train-epoch-step: 33-262 -- Loss: 0.28742098808288574
train-epoch-step: 33-263 -- Loss: 0.20082975924015045
train-epoch-step: 33-264 -- Loss: 0.17616166174411774
train-epoch-step: 33-265 -- Loss: 0.1330374777317047
train-epoch-step: 33-266 -- Loss: 0.1538340151309967
train-epoch-step: 33-267 -- Loss: 0.1307847499847412
train-epoch-step: 33-268 -- Loss: 0.11963087320327759
train-epoch-step: 33-269 -- Loss: 0.17156296968460083
train-epoch-step: 33-270 -- Loss: 0.1081344485282898
train-epoch-step: 33-271 -- Loss: 0.14953482151031494
train-epoch-step: 33-272 -- Loss: 0.11887872219085693
train-epoch-step: 33-273 -- Loss: 0.12473637610673904
train-epoch-step: 33-274 -- Loss: 0.19196155667304993
train-epoch-step: 33-275 -- Loss: 0.1994783580303192
train-epoch-step: 33-276 -- Loss: 0.15851286053657532
train-epoch-step: 33-277 -- Loss: 0.15614226460456848
train-epoch-step: 33-278 -- Loss: 0.145265594124794
train-epoch-step: 33-279 -- Loss: 0.14059534668922424
train-epoch-step: 33-280 -- Loss: 0.21848466992378235
train-epoch-step: 33-281 -- Loss: 0.1775033324956894
train-epoch-step: 33-282 -- Loss: 0.14032191038131714
train-epoch-step: 33-283 -- Loss: 0.1170899048447609
train-epoch-step: 33-284 -- Loss: 0.13497845828533173
train-epoch-step: 33-285 -- Loss: 0.190058633685112
train-epoch-step: 33-286 -- Loss: 0.15944957733154297
train-epoch-step: 33-287 -- Loss: 0.20401130616664886
train-epoch-step: 33-288 -- Loss: 0.09381592273712158
train-epoch-step: 33-289 -- Loss: 0.1351030170917511
train-epoch-step: 33-290 -- Loss: 0.17861253023147583
train-epoch-step: 33-291 -- Loss: 0.1184997707605362
train-epoch-step: 33-292 -- Loss: 0.1528283953666687
train-epoch-step: 33-293 -- Loss: 0.1385657638311386
train-epoch-step: 33-294 -- Loss: 0.1632297784090042
train-epoch-step: 33-295 -- Loss: 0.26831990480422974
train-epoch-step: 33-296 -- Loss: 0.16039182245731354
train-epoch-step: 33-297 -- Loss: 0.17402462661266327
train-epoch-step: 33-298 -- Loss: 0.24339190125465393
train-epoch-step: 33-299 -- Loss: 0.14715266227722168
train-epoch-step: 33-300 -- Loss: 0.16667573153972626
train-epoch-step: 33-301 -- Loss: 0.17632371187210083
train-epoch-step: 33-302 -- Loss: 0.219031423330307
train-epoch-step: 33-303 -- Loss: 0.2027285099029541
train-epoch-step: 33-304 -- Loss: 0.13545970618724823
train-epoch-step: 33-305 -- Loss: 0.14505399763584137
train-epoch-step: 33-306 -- Loss: 0.2355467528104782
train-epoch-step: 33-307 -- Loss: 0.1645677387714386
train-epoch-step: 33-308 -- Loss: 0.21859557926654816
train-epoch-step: 33-309 -- Loss: 0.15465112030506134
train-epoch-step: 33-310 -- Loss: 0.16143864393234253
train-epoch-step: 33-311 -- Loss: 0.16121166944503784
train-epoch-step: 33-312 -- Loss: 0.2106017768383026
train-epoch-step: 33-313 -- Loss: 0.10131878405809402
train-epoch-step: 33-314 -- Loss: 0.1933491826057434
train-epoch-step: 33-315 -- Loss: 0.16759070754051208
train-epoch-step: 33-316 -- Loss: 0.1545681208372116
train-epoch-step: 33-317 -- Loss: 0.13678665459156036
train-epoch-step: 33-318 -- Loss: 0.16126050055027008
train-epoch-step: 33-319 -- Loss: 0.17267605662345886
train-epoch-step: 33-320 -- Loss: 0.11633690446615219
train-epoch-step: 33-321 -- Loss: 0.13292033970355988
train-epoch-step: 33-322 -- Loss: 0.21713736653327942
train-epoch-step: 33-323 -- Loss: 0.15718621015548706
train-epoch-step: 33-324 -- Loss: 0.25354039669036865
train-epoch-step: 33-325 -- Loss: 0.15956996381282806
train-epoch-step: 33-326 -- Loss: 0.171714186668396
train-epoch-step: 33-327 -- Loss: 0.2040373831987381
train-epoch-step: 33-328 -- Loss: 0.19818764925003052
train-epoch-step: 33-329 -- Loss: 0.33954596519470215
train-epoch-step: 33-330 -- Loss: 0.3620060086250305
train-epoch-step: 33-331 -- Loss: 0.21539531648159027
train-epoch-step: 33-332 -- Loss: 0.1022731363773346
train-epoch-step: 33-333 -- Loss: 0.18429802358150482
train-epoch-step: 33-334 -- Loss: 0.1574665904045105
train-epoch-step: 33-335 -- Loss: 0.17932894825935364
train-epoch-step: 33-336 -- Loss: 0.14970991015434265
train-epoch-step: 33-337 -- Loss: 0.20921045541763306
train-epoch-step: 33-338 -- Loss: 0.1604289710521698
train-epoch-step: 33-339 -- Loss: 0.14171567559242249
train-epoch-step: 33-340 -- Loss: 0.19657790660858154
train-epoch-step: 33-341 -- Loss: 0.1508827805519104
train-epoch-step: 33-342 -- Loss: 0.1672188937664032
train-epoch-step: 33-343 -- Loss: 0.1539832353591919
train-epoch-step: 33-344 -- Loss: 0.16721221804618835
train-epoch-step: 33-345 -- Loss: 0.12998951971530914
train-epoch-step: 33-346 -- Loss: 0.20411187410354614
train-epoch-step: 33-347 -- Loss: 0.15452709794044495
train-epoch-step: 33-348 -- Loss: 0.20656532049179077
train-epoch-step: 33-349 -- Loss: 0.20318904519081116
train-epoch-step: 33-350 -- Loss: 0.27000343799591064
train-epoch-step: 33-351 -- Loss: 0.1960260421037674
train-epoch-step: 33-352 -- Loss: 0.12129519134759903
train-epoch-step: 33-353 -- Loss: 0.19516263902187347
train-epoch-step: 33-354 -- Loss: 0.2797372341156006
train-epoch-step: 33-355 -- Loss: 0.11901119351387024
train-epoch-step: 33-356 -- Loss: 0.1188768669962883
train-epoch-step: 33-357 -- Loss: 0.19410468637943268
train-epoch-step: 33-358 -- Loss: 0.18635374307632446
train-epoch-step: 33-359 -- Loss: 0.14371193945407867
train-epoch-step: 33-360 -- Loss: 0.1211269274353981
train-epoch-step: 33-361 -- Loss: 0.23420298099517822
train-epoch-step: 33-362 -- Loss: 0.1681375652551651
train-epoch-step: 33-363 -- Loss: 0.12677031755447388
train-epoch-step: 33-364 -- Loss: 0.18076969683170319
train-epoch-step: 33-365 -- Loss: 0.17722156643867493
train-epoch-step: 33-366 -- Loss: 0.19983802735805511
train-epoch-step: 33-367 -- Loss: 0.23119516670703888
train-epoch-step: 33-368 -- Loss: 0.20151196420192719
train-epoch-step: 33-369 -- Loss: 0.281318336725235
train-epoch-step: 33-370 -- Loss: 0.12556374073028564
train-epoch-step: 33-371 -- Loss: 0.12242783606052399
train-epoch-step: 33-372 -- Loss: 0.14731226861476898
train-epoch-step: 33-373 -- Loss: 0.1880928874015808
train-epoch-step: 33-374 -- Loss: 0.15795940160751343
train-epoch-step: 33-375 -- Loss: 0.27192798256874084
train-epoch-step: 33-376 -- Loss: 0.1587355136871338
train-epoch-step: 33-377 -- Loss: 0.2288648635149002
train-epoch-step: 33-378 -- Loss: 0.21092182397842407
train-epoch-step: 33-379 -- Loss: 0.12103349715471268
train-epoch-step: 33-380 -- Loss: 0.09285178780555725
train-epoch-step: 33-381 -- Loss: 0.24648243188858032
train-epoch-step: 33-382 -- Loss: 0.23325635492801666
train-epoch-step: 33-383 -- Loss: 0.18129509687423706
train-epoch-step: 33-384 -- Loss: 0.22047238051891327
train-epoch-step: 33-385 -- Loss: 0.1975359171628952
train-epoch-step: 33-386 -- Loss: 0.19348230957984924
train-epoch-step: 33-387 -- Loss: 0.20375333726406097
train-epoch-step: 33-388 -- Loss: 0.1976967751979828
train-epoch-step: 33-389 -- Loss: 0.16749154031276703
train-epoch-step: 33-390 -- Loss: 0.15960350632667542
train-epoch-step: 33-391 -- Loss: 0.14756366610527039
train-epoch-step: 33-392 -- Loss: 0.18877193331718445
train-epoch-step: 33-393 -- Loss: 0.1596449911594391
train-epoch-step: 33-394 -- Loss: 0.2070176899433136
train-epoch-step: 33-395 -- Loss: 0.15419918298721313
train-epoch-step: 33-396 -- Loss: 0.12868158519268036
train-epoch-step: 33-397 -- Loss: 0.12246479094028473
train-epoch-step: 33-398 -- Loss: 0.19652894139289856
train-epoch-step: 33-399 -- Loss: 0.176415354013443
train-epoch-step: 33-400 -- Loss: 0.2794662415981293
train-epoch-step: 33-401 -- Loss: 0.12158751487731934
train-epoch-step: 33-402 -- Loss: 0.26459863781929016
train-epoch-step: 33-403 -- Loss: 0.1570415496826172
train-epoch-step: 33-404 -- Loss: 0.13826332986354828
train-epoch-step: 33-405 -- Loss: 0.14290297031402588
train-epoch-step: 33-406 -- Loss: 0.17512263357639313
train-epoch-step: 33-407 -- Loss: 0.11205089837312698
train-epoch-step: 33-408 -- Loss: 0.16124503314495087
train-epoch-step: 33-409 -- Loss: 0.16991381347179413
train-epoch-step: 33-410 -- Loss: 0.1765354424715042
train-epoch-step: 33-411 -- Loss: 0.20958638191223145
train-epoch-step: 33-412 -- Loss: 0.1347379982471466
train-epoch-step: 33-413 -- Loss: 0.14588716626167297
train-epoch-step: 33-414 -- Loss: 0.13146834075450897
train-epoch-step: 33-415 -- Loss: 0.14174672961235046
train-epoch-step: 33-416 -- Loss: 0.26458460092544556
train-epoch-step: 33-417 -- Loss: 0.1898147016763687
train-epoch-step: 33-418 -- Loss: 0.24064943194389343
train-epoch-step: 33-419 -- Loss: 0.16567887365818024
train-epoch-step: 33-420 -- Loss: 0.1544407308101654
train-epoch-step: 33-421 -- Loss: 0.17883530259132385
train-epoch-step: 33-422 -- Loss: 0.14686360955238342
train-epoch-step: 33-423 -- Loss: 0.17451557517051697
train-epoch-step: 33-424 -- Loss: 0.142446830868721
train-epoch-step: 33-425 -- Loss: 0.185566246509552
train-epoch-step: 33-426 -- Loss: 0.16208912432193756
train-epoch-step: 33-427 -- Loss: 0.12162540853023529
train-epoch-step: 33-428 -- Loss: 0.1937676966190338
train-epoch-step: 33-429 -- Loss: 0.17499330639839172
train-epoch-step: 33-430 -- Loss: 0.13998502492904663
train-epoch-step: 33-431 -- Loss: 0.1665884256362915
train-epoch-step: 33-432 -- Loss: 0.24803543090820312
train-epoch-step: 33-433 -- Loss: 0.14047585427761078
train-epoch-step: 33-434 -- Loss: 0.1308126598596573
train-epoch-step: 33-435 -- Loss: 0.15623727440834045
train-epoch-step: 33-436 -- Loss: 0.156476691365242
train-epoch-step: 33-437 -- Loss: 0.13700562715530396
train-epoch-step: 33-438 -- Loss: 0.17033714056015015
train-epoch-step: 33-439 -- Loss: 0.27301880717277527
train-epoch-step: 33-440 -- Loss: 0.13386183977127075
train-epoch-step: 33-441 -- Loss: 0.20654375851154327
train-epoch-step: 33-442 -- Loss: 0.17706570029258728
train-epoch-step: 33-443 -- Loss: 0.15122556686401367
train-epoch-step: 33-444 -- Loss: 0.18704549968242645
train-epoch-step: 33-445 -- Loss: 0.1784260869026184
train-epoch-step: 33-446 -- Loss: 0.1639680117368698
train-epoch-step: 33-447 -- Loss: 0.19183003902435303
train-epoch-step: 33-448 -- Loss: 0.2314823716878891
train-epoch-step: 33-449 -- Loss: 0.19244717061519623
train-epoch-step: 33-450 -- Loss: 0.19336949288845062
train-epoch-step: 33-451 -- Loss: 0.15010517835617065
train-epoch-step: 33-452 -- Loss: 0.13213568925857544
train-epoch-step: 33-453 -- Loss: 0.09281378984451294
train-epoch-step: 33-454 -- Loss: 0.23207789659500122
train-epoch-step: 33-455 -- Loss: 0.12868256866931915
train-epoch-step: 33-456 -- Loss: 0.12672998011112213
train-epoch-step: 33-457 -- Loss: 0.21662208437919617
train-epoch-step: 33-458 -- Loss: 0.158584326505661
train-epoch-step: 33-459 -- Loss: 0.21510805189609528
train-epoch-step: 33-460 -- Loss: 0.12912580370903015
train-epoch-step: 33-461 -- Loss: 0.13571348786354065
train-epoch-step: 33-462 -- Loss: 0.1631963551044464
train-epoch-step: 33-463 -- Loss: 0.13649103045463562
train-epoch-step: 33-464 -- Loss: 0.17398107051849365
train-epoch-step: 33-465 -- Loss: 0.2742580771446228
train-epoch-step: 33-466 -- Loss: 0.20964102447032928
train-epoch-step: 33-467 -- Loss: 0.1133684515953064
train-epoch-step: 33-468 -- Loss: 0.1727801412343979
train-epoch-step: 33-469 -- Loss: 0.21135087311267853
train-epoch-step: 33-470 -- Loss: 0.201925128698349
train-epoch-step: 33-471 -- Loss: 0.15930882096290588
train-epoch-step: 33-472 -- Loss: 0.15650589764118195
train-epoch-step: 33-473 -- Loss: 0.15882608294487
train-epoch-step: 33-474 -- Loss: 0.12310795485973358
train-epoch-step: 33-475 -- Loss: 0.11097186803817749
train-epoch-step: 33-476 -- Loss: 0.19978082180023193
train-epoch-step: 33-477 -- Loss: 0.2003614455461502
train-epoch-step: 33-478 -- Loss: 0.19994834065437317
train-epoch-step: 33-479 -- Loss: 0.14501260221004486
train-epoch-step: 33-480 -- Loss: 0.19577498733997345
train-epoch-step: 33-481 -- Loss: 0.2885435223579407
train-epoch-step: 33-482 -- Loss: 0.26248979568481445
train-epoch-step: 33-483 -- Loss: 0.1808677613735199
train-epoch-step: 33-484 -- Loss: 0.2134292721748352
train-epoch-step: 33-485 -- Loss: 0.13039107620716095
train-epoch-step: 33-486 -- Loss: 0.23894590139389038
train-epoch-step: 33-487 -- Loss: 0.24260959029197693
train-epoch-step: 33-488 -- Loss: 0.19707638025283813
train-epoch-step: 33-489 -- Loss: 0.22225075960159302
train-epoch-step: 33-490 -- Loss: 0.14060629904270172
train-epoch-step: 33-491 -- Loss: 0.14378949999809265
train-epoch-step: 33-492 -- Loss: 0.12803727388381958
train-epoch-step: 33-493 -- Loss: 0.2013092339038849
train-epoch-step: 33-494 -- Loss: 0.22273072600364685
train-epoch-step: 33-495 -- Loss: 0.20256006717681885
train-epoch-step: 33-496 -- Loss: 0.1399933099746704
train-epoch-step: 33-497 -- Loss: 0.18613658845424652
train-epoch-step: 33-498 -- Loss: 0.15250062942504883
train-epoch-step: 33-499 -- Loss: 0.17282800376415253
train-epoch-step: 33-500 -- Loss: 0.15583990514278412
train-epoch-step: 33-501 -- Loss: 0.21740826964378357
train-epoch-step: 33-502 -- Loss: 0.15800869464874268
train-epoch-step: 33-503 -- Loss: 0.21615688502788544
train-epoch-step: 33-504 -- Loss: 0.12224850058555603
train-epoch-step: 33-505 -- Loss: 0.17134080827236176
train-epoch-step: 33-506 -- Loss: 0.11648266017436981
train-epoch-step: 33-507 -- Loss: 0.18374545872211456
train-epoch-step: 33-508 -- Loss: 0.18598245084285736
train-epoch-step: 33-509 -- Loss: 0.17549440264701843
train-epoch-step: 33-510 -- Loss: 0.12774936854839325
train-epoch-step: 33-511 -- Loss: 0.21983617544174194
train-epoch-step: 33-512 -- Loss: 0.17421311140060425
train-epoch-step: 33-513 -- Loss: 0.1957123577594757
train-epoch-step: 33-514 -- Loss: 0.15327206254005432
train-epoch-step: 33-515 -- Loss: 0.15624414384365082
train-epoch-step: 33-516 -- Loss: 0.16772307455539703
train-epoch-step: 33-517 -- Loss: 0.17298665642738342
train-epoch-step: 33-518 -- Loss: 0.14270377159118652
train-epoch-step: 33-519 -- Loss: 0.1341472715139389
train-epoch-step: 33-520 -- Loss: 0.1829906553030014
train-epoch-step: 33-521 -- Loss: 0.2298925369977951
train-epoch-step: 33-522 -- Loss: 0.1857994645833969
train-epoch-step: 33-523 -- Loss: 0.15623603761196136
train-epoch-step: 33-524 -- Loss: 0.1806744635105133
train-epoch-step: 33-525 -- Loss: 0.19183605909347534
train-epoch-step: 33-526 -- Loss: 0.1287924200296402
train-epoch-step: 33-527 -- Loss: 0.15055322647094727
train-epoch-step: 33-528 -- Loss: 0.16054968535900116
train-epoch-step: 33-529 -- Loss: 0.16215762495994568
train-epoch-step: 33-530 -- Loss: 0.17077499628067017
train-epoch-step: 33-531 -- Loss: 0.20297560095787048
train-epoch-step: 33-532 -- Loss: 0.16804563999176025
train-epoch-step: 33-533 -- Loss: 0.17510348558425903
train-epoch-step: 33-534 -- Loss: 0.13093926012516022
train-epoch-step: 33-535 -- Loss: 0.2563028633594513
train-epoch-step: 33-536 -- Loss: 0.15430708229541779
train-epoch-step: 33-537 -- Loss: 0.14765654504299164
train-epoch-step: 33-538 -- Loss: 0.10421034693717957
train-epoch-step: 33-539 -- Loss: 0.1864403784275055
train-epoch-step: 33-540 -- Loss: 0.13982698321342468
train-epoch-step: 33-541 -- Loss: 0.20639415085315704
train-epoch-step: 33-542 -- Loss: 0.22398430109024048
train-epoch-step: 33-543 -- Loss: 0.16889582574367523
train-epoch-step: 33-544 -- Loss: 0.24253256618976593
train-epoch-step: 33-545 -- Loss: 0.19027698040008545
train-epoch-step: 33-546 -- Loss: 0.22038713097572327
train-epoch-step: 33-547 -- Loss: 0.1824566125869751
train-epoch-step: 33-548 -- Loss: 0.09517424553632736
train-epoch-step: 33-549 -- Loss: 0.14830338954925537
train-epoch-step: 33-550 -- Loss: 0.20159605145454407
train-epoch-step: 33-551 -- Loss: 0.1513221710920334
train-epoch-step: 33-552 -- Loss: 0.12414605915546417
train-epoch-step: 33-553 -- Loss: 0.18989142775535583
train-epoch-step: 33-554 -- Loss: 0.18894240260124207
train-epoch-step: 33-555 -- Loss: 0.22049295902252197
train-epoch-step: 33-556 -- Loss: 0.1556919813156128
train-epoch-step: 33-557 -- Loss: 0.256021112203598
train-epoch-step: 33-558 -- Loss: 0.23095178604125977
train-epoch-step: 33-559 -- Loss: 0.14149990677833557
train-epoch-step: 33-560 -- Loss: 0.2076846957206726
train-epoch-step: 33-561 -- Loss: 0.1813131868839264
train-epoch-step: 33-562 -- Loss: 0.16028907895088196
train-epoch-step: 33-563 -- Loss: 0.183623269200325
train-epoch-step: 33-564 -- Loss: 0.10031674057245255
train-epoch-step: 33-565 -- Loss: 0.18461699783802032
train-epoch-step: 33-566 -- Loss: 0.15015943348407745
train-epoch-step: 33-567 -- Loss: 0.21148094534873962
train-epoch-step: 33-568 -- Loss: 0.1644875556230545
train-epoch-step: 33-569 -- Loss: 0.24262556433677673
train-epoch-step: 33-570 -- Loss: 0.1695522964000702
train-epoch-step: 33-571 -- Loss: 0.2163732647895813
train-epoch-step: 33-572 -- Loss: 0.23951129615306854
train-epoch-step: 33-573 -- Loss: 0.1961619257926941
train-epoch-step: 33-574 -- Loss: 0.24605603516101837
train-epoch-step: 33-575 -- Loss: 0.30021247267723083
train-epoch-step: 33-576 -- Loss: 0.12184888124465942
train-epoch-step: 33-577 -- Loss: 0.16847023367881775
train-epoch-step: 33-578 -- Loss: 0.22687725722789764
train-epoch-step: 33-579 -- Loss: 0.16384677588939667
train-epoch-step: 33-580 -- Loss: 0.1729666292667389
train-epoch-step: 33-581 -- Loss: 0.13436195254325867
train-epoch-step: 33-582 -- Loss: 0.20401665568351746
train-epoch-step: 33-583 -- Loss: 0.21882572770118713
train-epoch-step: 33-584 -- Loss: 0.1649961918592453
train-epoch-step: 33-585 -- Loss: 0.1949477344751358
train-epoch-step: 33-586 -- Loss: 0.25245583057403564
train-epoch-step: 33-587 -- Loss: 0.16159115731716156
train-epoch-step: 33-588 -- Loss: 0.12573617696762085
val-epoch-step: 33-589 -- Loss: 0.21563680469989777
val-epoch-step: 33-590 -- Loss: 0.15732945501804352
val-epoch-step: 33-591 -- Loss: 0.2259080857038498
val-epoch-step: 33-592 -- Loss: 0.17680656909942627
val-epoch-step: 33-593 -- Loss: 0.18828213214874268
val-epoch-step: 33-594 -- Loss: 0.32786568999290466
val-epoch-step: 33-595 -- Loss: 0.18421140313148499
val-epoch-step: 33-596 -- Loss: 0.1979253590106964
val-epoch-step: 33-597 -- Loss: 0.17796486616134644
val-epoch-step: 33-598 -- Loss: 0.15129464864730835
val-epoch-step: 33-599 -- Loss: 0.18796499073505402
val-epoch-step: 33-600 -- Loss: 0.19801662862300873
val-epoch-step: 33-601 -- Loss: 0.15390244126319885
val-epoch-step: 33-602 -- Loss: 0.1427876353263855
val-epoch-step: 33-603 -- Loss: 0.1853141486644745
val-epoch-step: 33-604 -- Loss: 0.15558233857154846
val-epoch-step: 33-605 -- Loss: 0.14642947912216187
val-epoch-step: 33-606 -- Loss: 0.2592712342739105
val-epoch-step: 33-607 -- Loss: 0.12922200560569763
val-epoch-step: 33-608 -- Loss: 0.24767065048217773
val-epoch-step: 33-609 -- Loss: 0.15921127796173096
val-epoch-step: 33-610 -- Loss: 0.18120568990707397
val-epoch-step: 33-611 -- Loss: 0.16853423416614532
val-epoch-step: 33-612 -- Loss: 0.42956918478012085
val-epoch-step: 33-613 -- Loss: 0.1775514930486679
val-epoch-step: 33-614 -- Loss: 0.1734088659286499
val-epoch-step: 33-615 -- Loss: 0.17539191246032715
val-epoch-step: 33-616 -- Loss: 0.14920687675476074
val-epoch-step: 33-617 -- Loss: 0.19281978905200958
val-epoch-step: 33-618 -- Loss: 0.19568447768688202
val-epoch-step: 33-619 -- Loss: 0.2073025405406952
val-epoch-step: 33-620 -- Loss: 0.15702399611473083
val-epoch-step: 33-621 -- Loss: 0.129078209400177
val-epoch-step: 33-622 -- Loss: 0.14767900109291077
val-epoch-step: 33-623 -- Loss: 0.1533898115158081
val-epoch-step: 33-624 -- Loss: 0.1447843760251999
val-epoch-step: 33-625 -- Loss: 0.16400590538978577
val-epoch-step: 33-626 -- Loss: 0.15011519193649292
val-epoch-step: 33-627 -- Loss: 0.19312410056591034
val-epoch-step: 33-628 -- Loss: 0.6185447573661804
val-epoch-step: 33-629 -- Loss: 0.18837076425552368
val-epoch-step: 33-630 -- Loss: 0.35109248757362366
val-epoch-step: 33-631 -- Loss: 0.1448528915643692
val-epoch-step: 33-632 -- Loss: 0.19996829330921173
val-epoch-step: 33-633 -- Loss: 0.15142208337783813
val-epoch-step: 33-634 -- Loss: 0.15326370298862457
val-epoch-step: 33-635 -- Loss: 0.11781536787748337
val-epoch-step: 33-636 -- Loss: 0.1682097166776657
val-epoch-step: 33-637 -- Loss: 0.1837553083896637
val-epoch-step: 33-638 -- Loss: 0.14643283188343048
val-epoch-step: 33-639 -- Loss: 0.26064950227737427
val-epoch-step: 33-640 -- Loss: 0.26564961671829224
val-epoch-step: 33-641 -- Loss: 0.1270969659090042
val-epoch-step: 33-642 -- Loss: 0.1704104244709015
val-epoch-step: 33-643 -- Loss: 0.1976197063922882
val-epoch-step: 33-644 -- Loss: 0.1699514538049698
val-epoch-step: 33-645 -- Loss: 0.21844427287578583
val-epoch-step: 33-646 -- Loss: 0.13798454403877258
val-epoch-step: 33-647 -- Loss: 0.12797193229198456
val-epoch-step: 33-648 -- Loss: 0.1620413064956665
val-epoch-step: 33-649 -- Loss: 0.21048413217067719
val-epoch-step: 33-650 -- Loss: 0.2517639398574829
val-epoch-step: 33-651 -- Loss: 0.15160617232322693
val-epoch-step: 33-652 -- Loss: 0.15467648208141327
val-epoch-step: 33-653 -- Loss: 0.2155919373035431
val-epoch-step: 33-654 -- Loss: 0.11134975403547287
Epoch: 33 -- Train Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 34-0 -- Loss: 0.2354104220867157
train-epoch-step: 34-1 -- Loss: 0.14922454953193665
train-epoch-step: 34-2 -- Loss: 0.2111278474330902
train-epoch-step: 34-3 -- Loss: 0.14189115166664124
train-epoch-step: 34-4 -- Loss: 0.15978969633579254
train-epoch-step: 34-5 -- Loss: 0.18086804449558258
train-epoch-step: 34-6 -- Loss: 0.22454452514648438
train-epoch-step: 34-7 -- Loss: 0.1649436056613922
train-epoch-step: 34-8 -- Loss: 0.17886877059936523
train-epoch-step: 34-9 -- Loss: 0.22508813440799713
train-epoch-step: 34-10 -- Loss: 0.19306021928787231
train-epoch-step: 34-11 -- Loss: 0.17546623945236206
train-epoch-step: 34-12 -- Loss: 0.15208685398101807
train-epoch-step: 34-13 -- Loss: 0.17940840125083923
train-epoch-step: 34-14 -- Loss: 0.1733531951904297
train-epoch-step: 34-15 -- Loss: 0.16533368825912476
train-epoch-step: 34-16 -- Loss: 0.16670012474060059
train-epoch-step: 34-17 -- Loss: 0.22283971309661865
train-epoch-step: 34-18 -- Loss: 0.24317309260368347
train-epoch-step: 34-19 -- Loss: 0.1308906525373459
train-epoch-step: 34-20 -- Loss: 0.2395663559436798
train-epoch-step: 34-21 -- Loss: 0.2702462375164032
train-epoch-step: 34-22 -- Loss: 0.1398037075996399
train-epoch-step: 34-23 -- Loss: 0.1440839320421219
train-epoch-step: 34-24 -- Loss: 0.12768566608428955
train-epoch-step: 34-25 -- Loss: 0.22672507166862488
train-epoch-step: 34-26 -- Loss: 0.19235406816005707
train-epoch-step: 34-27 -- Loss: 0.2580210864543915
train-epoch-step: 34-28 -- Loss: 0.13054516911506653
train-epoch-step: 34-29 -- Loss: 0.2483024001121521
train-epoch-step: 34-30 -- Loss: 0.11886215209960938
train-epoch-step: 34-31 -- Loss: 0.14312690496444702
train-epoch-step: 34-32 -- Loss: 0.17744475603103638
train-epoch-step: 34-33 -- Loss: 0.2983335852622986
train-epoch-step: 34-34 -- Loss: 0.17239399254322052
train-epoch-step: 34-35 -- Loss: 0.24956755340099335
train-epoch-step: 34-36 -- Loss: 0.14044374227523804
train-epoch-step: 34-37 -- Loss: 0.14246389269828796
train-epoch-step: 34-38 -- Loss: 0.17758522927761078
train-epoch-step: 34-39 -- Loss: 0.23185671865940094
train-epoch-step: 34-40 -- Loss: 0.19335269927978516
train-epoch-step: 34-41 -- Loss: 0.2128409594297409
train-epoch-step: 34-42 -- Loss: 0.1495402753353119
train-epoch-step: 34-43 -- Loss: 0.2696760296821594
train-epoch-step: 34-44 -- Loss: 0.12663687765598297
train-epoch-step: 34-45 -- Loss: 0.11879390478134155
train-epoch-step: 34-46 -- Loss: 0.17685078084468842
train-epoch-step: 34-47 -- Loss: 0.20141232013702393
train-epoch-step: 34-48 -- Loss: 0.15405692160129547
train-epoch-step: 34-49 -- Loss: 0.22526390850543976
train-epoch-step: 34-50 -- Loss: 0.11710634082555771
train-epoch-step: 34-51 -- Loss: 0.17309217154979706
train-epoch-step: 34-52 -- Loss: 0.1659981608390808
train-epoch-step: 34-53 -- Loss: 0.2105836570262909
train-epoch-step: 34-54 -- Loss: 0.28638842701911926
train-epoch-step: 34-55 -- Loss: 0.1692674160003662
train-epoch-step: 34-56 -- Loss: 0.1773170530796051
train-epoch-step: 34-57 -- Loss: 0.23630952835083008
train-epoch-step: 34-58 -- Loss: 0.28416693210601807
train-epoch-step: 34-59 -- Loss: 0.24059782922267914
train-epoch-step: 34-60 -- Loss: 0.13255947828292847
train-epoch-step: 34-61 -- Loss: 0.19803830981254578
train-epoch-step: 34-62 -- Loss: 0.18340525031089783
train-epoch-step: 34-63 -- Loss: 0.1412057876586914
train-epoch-step: 34-64 -- Loss: 0.14886632561683655
train-epoch-step: 34-65 -- Loss: 0.1869119554758072
train-epoch-step: 34-66 -- Loss: 0.11069898307323456
train-epoch-step: 34-67 -- Loss: 0.12953823804855347
train-epoch-step: 34-68 -- Loss: 0.22224117815494537
train-epoch-step: 34-69 -- Loss: 0.12296457588672638
train-epoch-step: 34-70 -- Loss: 0.22002921998500824
train-epoch-step: 34-71 -- Loss: 0.2594594955444336
train-epoch-step: 34-72 -- Loss: 0.17437008023262024
train-epoch-step: 34-73 -- Loss: 0.21565045416355133
train-epoch-step: 34-74 -- Loss: 0.09483356773853302
train-epoch-step: 34-75 -- Loss: 0.12570860981941223
train-epoch-step: 34-76 -- Loss: 0.14670901000499725
train-epoch-step: 34-77 -- Loss: 0.23079034686088562
train-epoch-step: 34-78 -- Loss: 0.2512684464454651
train-epoch-step: 34-79 -- Loss: 0.19485196471214294
train-epoch-step: 34-80 -- Loss: 0.2563387155532837
train-epoch-step: 34-81 -- Loss: 0.12398166954517365
train-epoch-step: 34-82 -- Loss: 0.2474467158317566
train-epoch-step: 34-83 -- Loss: 0.1748742163181305
train-epoch-step: 34-84 -- Loss: 0.19415691494941711
train-epoch-step: 34-85 -- Loss: 0.17446786165237427
train-epoch-step: 34-86 -- Loss: 0.12096869945526123
train-epoch-step: 34-87 -- Loss: 0.21759456396102905
train-epoch-step: 34-88 -- Loss: 0.14343012869358063
train-epoch-step: 34-89 -- Loss: 0.18957030773162842
train-epoch-step: 34-90 -- Loss: 0.19136665761470795
train-epoch-step: 34-91 -- Loss: 0.24423879384994507
train-epoch-step: 34-92 -- Loss: 0.15548452734947205
train-epoch-step: 34-93 -- Loss: 0.17279544472694397
train-epoch-step: 34-94 -- Loss: 0.22386741638183594
train-epoch-step: 34-95 -- Loss: 0.19098907709121704
train-epoch-step: 34-96 -- Loss: 0.2130354344844818
train-epoch-step: 34-97 -- Loss: 0.17543862760066986
train-epoch-step: 34-98 -- Loss: 0.15386565029621124
train-epoch-step: 34-99 -- Loss: 0.1867915242910385
train-epoch-step: 34-100 -- Loss: 0.19378645718097687
train-epoch-step: 34-101 -- Loss: 0.2840428948402405
train-epoch-step: 34-102 -- Loss: 0.21741883456707
train-epoch-step: 34-103 -- Loss: 0.18248963356018066
train-epoch-step: 34-104 -- Loss: 0.14919458329677582
train-epoch-step: 34-105 -- Loss: 0.2667282223701477
train-epoch-step: 34-106 -- Loss: 0.17727123200893402
train-epoch-step: 34-107 -- Loss: 0.1890537142753601
train-epoch-step: 34-108 -- Loss: 0.18730948865413666
train-epoch-step: 34-109 -- Loss: 0.14745624363422394
train-epoch-step: 34-110 -- Loss: 0.18155653774738312
train-epoch-step: 34-111 -- Loss: 0.18024319410324097
train-epoch-step: 34-112 -- Loss: 0.17365071177482605
train-epoch-step: 34-113 -- Loss: 0.1646277755498886
train-epoch-step: 34-114 -- Loss: 0.19771842658519745
train-epoch-step: 34-115 -- Loss: 0.16121400892734528
train-epoch-step: 34-116 -- Loss: 0.1416809856891632
train-epoch-step: 34-117 -- Loss: 0.12759360671043396
train-epoch-step: 34-118 -- Loss: 0.19438430666923523
train-epoch-step: 34-119 -- Loss: 0.15458855032920837
train-epoch-step: 34-120 -- Loss: 0.24630002677440643
train-epoch-step: 34-121 -- Loss: 0.23661603033542633
train-epoch-step: 34-122 -- Loss: 0.2213830053806305
train-epoch-step: 34-123 -- Loss: 0.2025982141494751
train-epoch-step: 34-124 -- Loss: 0.12636762857437134
train-epoch-step: 34-125 -- Loss: 0.15560808777809143
train-epoch-step: 34-126 -- Loss: 0.22627246379852295
train-epoch-step: 34-127 -- Loss: 0.17730963230133057
train-epoch-step: 34-128 -- Loss: 0.1706792712211609
train-epoch-step: 34-129 -- Loss: 0.14685392379760742
train-epoch-step: 34-130 -- Loss: 0.18846428394317627
train-epoch-step: 34-131 -- Loss: 0.13702021539211273
train-epoch-step: 34-132 -- Loss: 0.19309084117412567
train-epoch-step: 34-133 -- Loss: 0.11640511453151703
train-epoch-step: 34-134 -- Loss: 0.19637811183929443
train-epoch-step: 34-135 -- Loss: 0.14097346365451813
train-epoch-step: 34-136 -- Loss: 0.12611770629882812
train-epoch-step: 34-137 -- Loss: 0.24712394177913666
train-epoch-step: 34-138 -- Loss: 0.256815105676651
train-epoch-step: 34-139 -- Loss: 0.13234570622444153
train-epoch-step: 34-140 -- Loss: 0.20424389839172363
train-epoch-step: 34-141 -- Loss: 0.22930854558944702
train-epoch-step: 34-142 -- Loss: 0.2006344497203827
train-epoch-step: 34-143 -- Loss: 0.1780727505683899
train-epoch-step: 34-144 -- Loss: 0.19141018390655518
train-epoch-step: 34-145 -- Loss: 0.14270703494548798
train-epoch-step: 34-146 -- Loss: 0.18232327699661255
train-epoch-step: 34-147 -- Loss: 0.16781210899353027
train-epoch-step: 34-148 -- Loss: 0.1656201183795929
train-epoch-step: 34-149 -- Loss: 0.11916328966617584
train-epoch-step: 34-150 -- Loss: 0.19051873683929443
train-epoch-step: 34-151 -- Loss: 0.19323766231536865
train-epoch-step: 34-152 -- Loss: 0.19204512238502502
train-epoch-step: 34-153 -- Loss: 0.2769531309604645
train-epoch-step: 34-154 -- Loss: 0.13693974912166595
train-epoch-step: 34-155 -- Loss: 0.13774125277996063
train-epoch-step: 34-156 -- Loss: 0.11831514537334442
train-epoch-step: 34-157 -- Loss: 0.17356346547603607
train-epoch-step: 34-158 -- Loss: 0.16510677337646484
train-epoch-step: 34-159 -- Loss: 0.1792466938495636
train-epoch-step: 34-160 -- Loss: 0.22276291251182556
train-epoch-step: 34-161 -- Loss: 0.2041359692811966
train-epoch-step: 34-162 -- Loss: 0.20957928895950317
train-epoch-step: 34-163 -- Loss: 0.19114923477172852
train-epoch-step: 34-164 -- Loss: 0.192238911986351
train-epoch-step: 34-165 -- Loss: 0.16248184442520142
train-epoch-step: 34-166 -- Loss: 0.1249179095029831
train-epoch-step: 34-167 -- Loss: 0.12524285912513733
train-epoch-step: 34-168 -- Loss: 0.20042219758033752
train-epoch-step: 34-169 -- Loss: 0.13679391145706177
train-epoch-step: 34-170 -- Loss: 0.19990035891532898
train-epoch-step: 34-171 -- Loss: 0.1466558426618576
train-epoch-step: 34-172 -- Loss: 0.2688596248626709
train-epoch-step: 34-173 -- Loss: 0.13991773128509521
train-epoch-step: 34-174 -- Loss: 0.24501365423202515
train-epoch-step: 34-175 -- Loss: 0.1868515908718109
train-epoch-step: 34-176 -- Loss: 0.13626138865947723
train-epoch-step: 34-177 -- Loss: 0.18324542045593262
train-epoch-step: 34-178 -- Loss: 0.17793181538581848
train-epoch-step: 34-179 -- Loss: 0.15779373049736023
train-epoch-step: 34-180 -- Loss: 0.15062470734119415
train-epoch-step: 34-181 -- Loss: 0.1704823076725006
train-epoch-step: 34-182 -- Loss: 0.17976641654968262
train-epoch-step: 34-183 -- Loss: 0.28159692883491516
train-epoch-step: 34-184 -- Loss: 0.14040130376815796
train-epoch-step: 34-185 -- Loss: 0.14445436000823975
train-epoch-step: 34-186 -- Loss: 0.18308047950267792
train-epoch-step: 34-187 -- Loss: 0.2090679407119751
train-epoch-step: 34-188 -- Loss: 0.17760446667671204
train-epoch-step: 34-189 -- Loss: 0.10682320594787598
train-epoch-step: 34-190 -- Loss: 0.18239188194274902
train-epoch-step: 34-191 -- Loss: 0.15989908576011658
train-epoch-step: 34-192 -- Loss: 0.23128728568553925
train-epoch-step: 34-193 -- Loss: 0.2037573903799057
train-epoch-step: 34-194 -- Loss: 0.18297114968299866
train-epoch-step: 34-195 -- Loss: 0.16342729330062866
train-epoch-step: 34-196 -- Loss: 0.17003893852233887
train-epoch-step: 34-197 -- Loss: 0.13380861282348633
train-epoch-step: 34-198 -- Loss: 0.12708525359630585
train-epoch-step: 34-199 -- Loss: 0.1526140421628952
train-epoch-step: 34-200 -- Loss: 0.12459671497344971
train-epoch-step: 34-201 -- Loss: 0.19425198435783386
train-epoch-step: 34-202 -- Loss: 0.13562411069869995
train-epoch-step: 34-203 -- Loss: 0.17244474589824677
train-epoch-step: 34-204 -- Loss: 0.13978572189807892
train-epoch-step: 34-205 -- Loss: 0.18328562378883362
train-epoch-step: 34-206 -- Loss: 0.2004447728395462
train-epoch-step: 34-207 -- Loss: 0.1315610110759735
train-epoch-step: 34-208 -- Loss: 0.17819693684577942
train-epoch-step: 34-209 -- Loss: 0.14215342700481415
train-epoch-step: 34-210 -- Loss: 0.13164332509040833
train-epoch-step: 34-211 -- Loss: 0.20732390880584717
train-epoch-step: 34-212 -- Loss: 0.19706517457962036
train-epoch-step: 34-213 -- Loss: 0.1271519958972931
train-epoch-step: 34-214 -- Loss: 0.14920468628406525
train-epoch-step: 34-215 -- Loss: 0.1259956955909729
train-epoch-step: 34-216 -- Loss: 0.2041262835264206
train-epoch-step: 34-217 -- Loss: 0.2144501954317093
train-epoch-step: 34-218 -- Loss: 0.1459406167268753
train-epoch-step: 34-219 -- Loss: 0.168258398771286
train-epoch-step: 34-220 -- Loss: 0.12947745621204376
train-epoch-step: 34-221 -- Loss: 0.20267914235591888
train-epoch-step: 34-222 -- Loss: 0.11620992422103882
train-epoch-step: 34-223 -- Loss: 0.1749442219734192
train-epoch-step: 34-224 -- Loss: 0.18576155602931976
train-epoch-step: 34-225 -- Loss: 0.2724730372428894
train-epoch-step: 34-226 -- Loss: 0.2029249668121338
train-epoch-step: 34-227 -- Loss: 0.22003623843193054
train-epoch-step: 34-228 -- Loss: 0.1786523461341858
train-epoch-step: 34-229 -- Loss: 0.17378848791122437
train-epoch-step: 34-230 -- Loss: 0.15986871719360352
train-epoch-step: 34-231 -- Loss: 0.15814107656478882
train-epoch-step: 34-232 -- Loss: 0.18727463483810425
train-epoch-step: 34-233 -- Loss: 0.08470513671636581
train-epoch-step: 34-234 -- Loss: 0.17603912949562073
train-epoch-step: 34-235 -- Loss: 0.1489729881286621
train-epoch-step: 34-236 -- Loss: 0.18398264050483704
train-epoch-step: 34-237 -- Loss: 0.23926585912704468
train-epoch-step: 34-238 -- Loss: 0.1531059592962265
train-epoch-step: 34-239 -- Loss: 0.12828600406646729
train-epoch-step: 34-240 -- Loss: 0.22000548243522644
train-epoch-step: 34-241 -- Loss: 0.15323831140995026
train-epoch-step: 34-242 -- Loss: 0.2250673770904541
train-epoch-step: 34-243 -- Loss: 0.23398256301879883
train-epoch-step: 34-244 -- Loss: 0.2030715048313141
train-epoch-step: 34-245 -- Loss: 0.20789296925067902
train-epoch-step: 34-246 -- Loss: 0.21692778170108795
train-epoch-step: 34-247 -- Loss: 0.20812062919139862
train-epoch-step: 34-248 -- Loss: 0.18735791742801666
train-epoch-step: 34-249 -- Loss: 0.13799594342708588
train-epoch-step: 34-250 -- Loss: 0.2012219876050949
train-epoch-step: 34-251 -- Loss: 0.11058765649795532
train-epoch-step: 34-252 -- Loss: 0.19264760613441467
train-epoch-step: 34-253 -- Loss: 0.13317430019378662
train-epoch-step: 34-254 -- Loss: 0.21646612882614136
train-epoch-step: 34-255 -- Loss: 0.14792093634605408
train-epoch-step: 34-256 -- Loss: 0.15377894043922424
train-epoch-step: 34-257 -- Loss: 0.20260852575302124
train-epoch-step: 34-258 -- Loss: 0.14453125
train-epoch-step: 34-259 -- Loss: 0.11334943771362305
train-epoch-step: 34-260 -- Loss: 0.20263539254665375
train-epoch-step: 34-261 -- Loss: 0.17096032202243805
train-epoch-step: 34-262 -- Loss: 0.29845160245895386
train-epoch-step: 34-263 -- Loss: 0.1964690387248993
train-epoch-step: 34-264 -- Loss: 0.17241868376731873
train-epoch-step: 34-265 -- Loss: 0.11110903322696686
train-epoch-step: 34-266 -- Loss: 0.15410110354423523
train-epoch-step: 34-267 -- Loss: 0.13081048429012299
train-epoch-step: 34-268 -- Loss: 0.1182008758187294
train-epoch-step: 34-269 -- Loss: 0.17262572050094604
train-epoch-step: 34-270 -- Loss: 0.10998077690601349
train-epoch-step: 34-271 -- Loss: 0.1669633686542511
train-epoch-step: 34-272 -- Loss: 0.11687003076076508
train-epoch-step: 34-273 -- Loss: 0.1273176223039627
train-epoch-step: 34-274 -- Loss: 0.1855548769235611
train-epoch-step: 34-275 -- Loss: 0.19415251910686493
train-epoch-step: 34-276 -- Loss: 0.1549028754234314
train-epoch-step: 34-277 -- Loss: 0.1570669710636139
train-epoch-step: 34-278 -- Loss: 0.13947084546089172
train-epoch-step: 34-279 -- Loss: 0.1457642912864685
train-epoch-step: 34-280 -- Loss: 0.2195117473602295
train-epoch-step: 34-281 -- Loss: 0.17555344104766846
train-epoch-step: 34-282 -- Loss: 0.14078831672668457
train-epoch-step: 34-283 -- Loss: 0.11546624451875687
train-epoch-step: 34-284 -- Loss: 0.13128073513507843
train-epoch-step: 34-285 -- Loss: 0.19422845542430878
train-epoch-step: 34-286 -- Loss: 0.154463991522789
train-epoch-step: 34-287 -- Loss: 0.20087389647960663
train-epoch-step: 34-288 -- Loss: 0.09329991042613983
train-epoch-step: 34-289 -- Loss: 0.12859421968460083
train-epoch-step: 34-290 -- Loss: 0.17725083231925964
train-epoch-step: 34-291 -- Loss: 0.1171829104423523
train-epoch-step: 34-292 -- Loss: 0.15629234910011292
train-epoch-step: 34-293 -- Loss: 0.13935919106006622
train-epoch-step: 34-294 -- Loss: 0.1629333794116974
train-epoch-step: 34-295 -- Loss: 0.27310910820961
train-epoch-step: 34-296 -- Loss: 0.15831302106380463
train-epoch-step: 34-297 -- Loss: 0.1733640879392624
train-epoch-step: 34-298 -- Loss: 0.2419586032629013
train-epoch-step: 34-299 -- Loss: 0.15300586819648743
train-epoch-step: 34-300 -- Loss: 0.15963251888751984
train-epoch-step: 34-301 -- Loss: 0.17940092086791992
train-epoch-step: 34-302 -- Loss: 0.21843165159225464
train-epoch-step: 34-303 -- Loss: 0.2041856348514557
train-epoch-step: 34-304 -- Loss: 0.12716001272201538
train-epoch-step: 34-305 -- Loss: 0.14508254826068878
train-epoch-step: 34-306 -- Loss: 0.23132680356502533
train-epoch-step: 34-307 -- Loss: 0.17050893604755402
train-epoch-step: 34-308 -- Loss: 0.21899880468845367
train-epoch-step: 34-309 -- Loss: 0.15541960299015045
train-epoch-step: 34-310 -- Loss: 0.1633845567703247
train-epoch-step: 34-311 -- Loss: 0.1579490453004837
train-epoch-step: 34-312 -- Loss: 0.20410209894180298
train-epoch-step: 34-313 -- Loss: 0.09859771281480789
train-epoch-step: 34-314 -- Loss: 0.19566936790943146
train-epoch-step: 34-315 -- Loss: 0.1675841510295868
train-epoch-step: 34-316 -- Loss: 0.15175960958003998
train-epoch-step: 34-317 -- Loss: 0.13718314468860626
train-epoch-step: 34-318 -- Loss: 0.16143366694450378
train-epoch-step: 34-319 -- Loss: 0.16560517251491547
train-epoch-step: 34-320 -- Loss: 0.115728460252285
train-epoch-step: 34-321 -- Loss: 0.1308428943157196
train-epoch-step: 34-322 -- Loss: 0.21597324311733246
train-epoch-step: 34-323 -- Loss: 0.15851007401943207
train-epoch-step: 34-324 -- Loss: 0.25758957862854004
train-epoch-step: 34-325 -- Loss: 0.15197095274925232
train-epoch-step: 34-326 -- Loss: 0.17464488744735718
train-epoch-step: 34-327 -- Loss: 0.21316522359848022
train-epoch-step: 34-328 -- Loss: 0.19799473881721497
train-epoch-step: 34-329 -- Loss: 0.34149277210235596
train-epoch-step: 34-330 -- Loss: 0.3623601794242859
train-epoch-step: 34-331 -- Loss: 0.21910911798477173
train-epoch-step: 34-332 -- Loss: 0.09901156276464462
train-epoch-step: 34-333 -- Loss: 0.18722398579120636
train-epoch-step: 34-334 -- Loss: 0.15538637340068817
train-epoch-step: 34-335 -- Loss: 0.17668525874614716
train-epoch-step: 34-336 -- Loss: 0.14909395575523376
train-epoch-step: 34-337 -- Loss: 0.20839737355709076
train-epoch-step: 34-338 -- Loss: 0.16276662051677704
train-epoch-step: 34-339 -- Loss: 0.14524346590042114
train-epoch-step: 34-340 -- Loss: 0.2025376409292221
train-epoch-step: 34-341 -- Loss: 0.14550372958183289
train-epoch-step: 34-342 -- Loss: 0.16822579503059387
train-epoch-step: 34-343 -- Loss: 0.15143640339374542
train-epoch-step: 34-344 -- Loss: 0.16760888695716858
train-epoch-step: 34-345 -- Loss: 0.13022904098033905
train-epoch-step: 34-346 -- Loss: 0.20043109357357025
train-epoch-step: 34-347 -- Loss: 0.15712358057498932
train-epoch-step: 34-348 -- Loss: 0.20417481660842896
train-epoch-step: 34-349 -- Loss: 0.20599916577339172
train-epoch-step: 34-350 -- Loss: 0.252956748008728
train-epoch-step: 34-351 -- Loss: 0.19118672609329224
train-epoch-step: 34-352 -- Loss: 0.12380661070346832
train-epoch-step: 34-353 -- Loss: 0.19872084259986877
train-epoch-step: 34-354 -- Loss: 0.28357937932014465
train-epoch-step: 34-355 -- Loss: 0.11634892225265503
train-epoch-step: 34-356 -- Loss: 0.11768545210361481
train-epoch-step: 34-357 -- Loss: 0.18831849098205566
train-epoch-step: 34-358 -- Loss: 0.18938866257667542
train-epoch-step: 34-359 -- Loss: 0.1403777003288269
train-epoch-step: 34-360 -- Loss: 0.12210012227296829
train-epoch-step: 34-361 -- Loss: 0.23824644088745117
train-epoch-step: 34-362 -- Loss: 0.16786065697669983
train-epoch-step: 34-363 -- Loss: 0.11061430722475052
train-epoch-step: 34-364 -- Loss: 0.18391236662864685
train-epoch-step: 34-365 -- Loss: 0.17583587765693665
train-epoch-step: 34-366 -- Loss: 0.20515616238117218
train-epoch-step: 34-367 -- Loss: 0.23307585716247559
train-epoch-step: 34-368 -- Loss: 0.20050887763500214
train-epoch-step: 34-369 -- Loss: 0.27645018696784973
train-epoch-step: 34-370 -- Loss: 0.12561622262001038
train-epoch-step: 34-371 -- Loss: 0.12186062335968018
train-epoch-step: 34-372 -- Loss: 0.146079882979393
train-epoch-step: 34-373 -- Loss: 0.1829271912574768
train-epoch-step: 34-374 -- Loss: 0.15584620833396912
train-epoch-step: 34-375 -- Loss: 0.2672775089740753
train-epoch-step: 34-376 -- Loss: 0.1657423973083496
train-epoch-step: 34-377 -- Loss: 0.23186556994915009
train-epoch-step: 34-378 -- Loss: 0.20351727306842804
train-epoch-step: 34-379 -- Loss: 0.11919155716896057
train-epoch-step: 34-380 -- Loss: 0.09185168892145157
train-epoch-step: 34-381 -- Loss: 0.2410041093826294
train-epoch-step: 34-382 -- Loss: 0.24127109348773956
train-epoch-step: 34-383 -- Loss: 0.17657259106636047
train-epoch-step: 34-384 -- Loss: 0.21806475520133972
train-epoch-step: 34-385 -- Loss: 0.1951688528060913
train-epoch-step: 34-386 -- Loss: 0.19204244017601013
train-epoch-step: 34-387 -- Loss: 0.20832650363445282
train-epoch-step: 34-388 -- Loss: 0.22252024710178375
train-epoch-step: 34-389 -- Loss: 0.1669691652059555
train-epoch-step: 34-390 -- Loss: 0.14531563222408295
train-epoch-step: 34-391 -- Loss: 0.14473086595535278
train-epoch-step: 34-392 -- Loss: 0.18314360082149506
train-epoch-step: 34-393 -- Loss: 0.15836411714553833
train-epoch-step: 34-394 -- Loss: 0.21729767322540283
train-epoch-step: 34-395 -- Loss: 0.1630905419588089
train-epoch-step: 34-396 -- Loss: 0.12692637741565704
train-epoch-step: 34-397 -- Loss: 0.1250801831483841
train-epoch-step: 34-398 -- Loss: 0.21375969052314758
train-epoch-step: 34-399 -- Loss: 0.18464818596839905
train-epoch-step: 34-400 -- Loss: 0.293129026889801
train-epoch-step: 34-401 -- Loss: 0.11809641122817993
train-epoch-step: 34-402 -- Loss: 0.25585323572158813
train-epoch-step: 34-403 -- Loss: 0.1535913646221161
train-epoch-step: 34-404 -- Loss: 0.14009538292884827
train-epoch-step: 34-405 -- Loss: 0.15081462264060974
train-epoch-step: 34-406 -- Loss: 0.16972598433494568
train-epoch-step: 34-407 -- Loss: 0.11525994539260864
train-epoch-step: 34-408 -- Loss: 0.16330605745315552
train-epoch-step: 34-409 -- Loss: 0.17256806790828705
train-epoch-step: 34-410 -- Loss: 0.1789831817150116
train-epoch-step: 34-411 -- Loss: 0.22221535444259644
train-epoch-step: 34-412 -- Loss: 0.130265012383461
train-epoch-step: 34-413 -- Loss: 0.1482088267803192
train-epoch-step: 34-414 -- Loss: 0.13332313299179077
train-epoch-step: 34-415 -- Loss: 0.1375439465045929
train-epoch-step: 34-416 -- Loss: 0.26808491349220276
train-epoch-step: 34-417 -- Loss: 0.1945907026529312
train-epoch-step: 34-418 -- Loss: 0.23161879181861877
train-epoch-step: 34-419 -- Loss: 0.16887567937374115
train-epoch-step: 34-420 -- Loss: 0.15609967708587646
train-epoch-step: 34-421 -- Loss: 0.17960679531097412
train-epoch-step: 34-422 -- Loss: 0.15194697678089142
train-epoch-step: 34-423 -- Loss: 0.1765652745962143
train-epoch-step: 34-424 -- Loss: 0.14190532267093658
train-epoch-step: 34-425 -- Loss: 0.1860676258802414
train-epoch-step: 34-426 -- Loss: 0.15988776087760925
train-epoch-step: 34-427 -- Loss: 0.1261255294084549
train-epoch-step: 34-428 -- Loss: 0.20325025916099548
train-epoch-step: 34-429 -- Loss: 0.18129107356071472
train-epoch-step: 34-430 -- Loss: 0.1451980471611023
train-epoch-step: 34-431 -- Loss: 0.16562335193157196
train-epoch-step: 34-432 -- Loss: 0.24800574779510498
train-epoch-step: 34-433 -- Loss: 0.13783691823482513
train-epoch-step: 34-434 -- Loss: 0.1270749270915985
train-epoch-step: 34-435 -- Loss: 0.1572313755750656
train-epoch-step: 34-436 -- Loss: 0.15343084931373596
train-epoch-step: 34-437 -- Loss: 0.1325129270553589
train-epoch-step: 34-438 -- Loss: 0.17166653275489807
train-epoch-step: 34-439 -- Loss: 0.2704329490661621
train-epoch-step: 34-440 -- Loss: 0.1332852691411972
train-epoch-step: 34-441 -- Loss: 0.20966488122940063
train-epoch-step: 34-442 -- Loss: 0.17824327945709229
train-epoch-step: 34-443 -- Loss: 0.15665754675865173
train-epoch-step: 34-444 -- Loss: 0.1737121045589447
train-epoch-step: 34-445 -- Loss: 0.18242940306663513
train-epoch-step: 34-446 -- Loss: 0.1494556963443756
train-epoch-step: 34-447 -- Loss: 0.19414621591567993
train-epoch-step: 34-448 -- Loss: 0.22350123524665833
train-epoch-step: 34-449 -- Loss: 0.1926729381084442
train-epoch-step: 34-450 -- Loss: 0.18343812227249146
train-epoch-step: 34-451 -- Loss: 0.14434918761253357
train-epoch-step: 34-452 -- Loss: 0.12908141314983368
train-epoch-step: 34-453 -- Loss: 0.09273561090230942
train-epoch-step: 34-454 -- Loss: 0.22991147637367249
train-epoch-step: 34-455 -- Loss: 0.12365025281906128
train-epoch-step: 34-456 -- Loss: 0.12111455202102661
train-epoch-step: 34-457 -- Loss: 0.22821682691574097
train-epoch-step: 34-458 -- Loss: 0.14981365203857422
train-epoch-step: 34-459 -- Loss: 0.21520450711250305
train-epoch-step: 34-460 -- Loss: 0.12637028098106384
train-epoch-step: 34-461 -- Loss: 0.1387183666229248
train-epoch-step: 34-462 -- Loss: 0.16179673373699188
train-epoch-step: 34-463 -- Loss: 0.1343485563993454
train-epoch-step: 34-464 -- Loss: 0.15762530267238617
train-epoch-step: 34-465 -- Loss: 0.2376103699207306
train-epoch-step: 34-466 -- Loss: 0.20062679052352905
train-epoch-step: 34-467 -- Loss: 0.11487200856208801
train-epoch-step: 34-468 -- Loss: 0.1719461977481842
train-epoch-step: 34-469 -- Loss: 0.21226391196250916
train-epoch-step: 34-470 -- Loss: 0.175561785697937
train-epoch-step: 34-471 -- Loss: 0.15650111436843872
train-epoch-step: 34-472 -- Loss: 0.1580546498298645
train-epoch-step: 34-473 -- Loss: 0.15423935651779175
train-epoch-step: 34-474 -- Loss: 0.12048022449016571
train-epoch-step: 34-475 -- Loss: 0.11178573220968246
train-epoch-step: 34-476 -- Loss: 0.19914604723453522
train-epoch-step: 34-477 -- Loss: 0.20296330749988556
train-epoch-step: 34-478 -- Loss: 0.18983519077301025
train-epoch-step: 34-479 -- Loss: 0.1376141905784607
train-epoch-step: 34-480 -- Loss: 0.1934421956539154
train-epoch-step: 34-481 -- Loss: 0.28933048248291016
train-epoch-step: 34-482 -- Loss: 0.25219959020614624
train-epoch-step: 34-483 -- Loss: 0.1787954866886139
train-epoch-step: 34-484 -- Loss: 0.2130151242017746
train-epoch-step: 34-485 -- Loss: 0.12886017560958862
train-epoch-step: 34-486 -- Loss: 0.2356240451335907
train-epoch-step: 34-487 -- Loss: 0.22904418408870697
train-epoch-step: 34-488 -- Loss: 0.1947271078824997
train-epoch-step: 34-489 -- Loss: 0.22007760405540466
train-epoch-step: 34-490 -- Loss: 0.1394881010055542
train-epoch-step: 34-491 -- Loss: 0.1382765769958496
train-epoch-step: 34-492 -- Loss: 0.12626266479492188
train-epoch-step: 34-493 -- Loss: 0.2023649364709854
train-epoch-step: 34-494 -- Loss: 0.20156575739383698
train-epoch-step: 34-495 -- Loss: 0.2014157921075821
train-epoch-step: 34-496 -- Loss: 0.13997963070869446
train-epoch-step: 34-497 -- Loss: 0.17955628037452698
train-epoch-step: 34-498 -- Loss: 0.1494096964597702
train-epoch-step: 34-499 -- Loss: 0.1643058806657791
train-epoch-step: 34-500 -- Loss: 0.15371915698051453
train-epoch-step: 34-501 -- Loss: 0.2157520055770874
train-epoch-step: 34-502 -- Loss: 0.1551424264907837
train-epoch-step: 34-503 -- Loss: 0.2246948778629303
train-epoch-step: 34-504 -- Loss: 0.12762153148651123
train-epoch-step: 34-505 -- Loss: 0.17208583652973175
train-epoch-step: 34-506 -- Loss: 0.11990100145339966
train-epoch-step: 34-507 -- Loss: 0.18577143549919128
train-epoch-step: 34-508 -- Loss: 0.17588156461715698
train-epoch-step: 34-509 -- Loss: 0.16661018133163452
train-epoch-step: 34-510 -- Loss: 0.12819695472717285
train-epoch-step: 34-511 -- Loss: 0.21369445323944092
train-epoch-step: 34-512 -- Loss: 0.17705506086349487
train-epoch-step: 34-513 -- Loss: 0.19744929671287537
train-epoch-step: 34-514 -- Loss: 0.15573838353157043
train-epoch-step: 34-515 -- Loss: 0.15434087812900543
train-epoch-step: 34-516 -- Loss: 0.1740119457244873
train-epoch-step: 34-517 -- Loss: 0.172305166721344
train-epoch-step: 34-518 -- Loss: 0.13879680633544922
train-epoch-step: 34-519 -- Loss: 0.1363043338060379
train-epoch-step: 34-520 -- Loss: 0.18813031911849976
train-epoch-step: 34-521 -- Loss: 0.23044723272323608
train-epoch-step: 34-522 -- Loss: 0.17961984872817993
train-epoch-step: 34-523 -- Loss: 0.15823636949062347
train-epoch-step: 34-524 -- Loss: 0.1721276044845581
train-epoch-step: 34-525 -- Loss: 0.18966202437877655
train-epoch-step: 34-526 -- Loss: 0.12804652750492096
train-epoch-step: 34-527 -- Loss: 0.1580553948879242
train-epoch-step: 34-528 -- Loss: 0.15556277334690094
train-epoch-step: 34-529 -- Loss: 0.15917454659938812
train-epoch-step: 34-530 -- Loss: 0.1649947613477707
train-epoch-step: 34-531 -- Loss: 0.1931888461112976
train-epoch-step: 34-532 -- Loss: 0.17535299062728882
train-epoch-step: 34-533 -- Loss: 0.173993781208992
train-epoch-step: 34-534 -- Loss: 0.13029953837394714
train-epoch-step: 34-535 -- Loss: 0.2531968951225281
train-epoch-step: 34-536 -- Loss: 0.16090910136699677
train-epoch-step: 34-537 -- Loss: 0.1456415057182312
train-epoch-step: 34-538 -- Loss: 0.10734421014785767
train-epoch-step: 34-539 -- Loss: 0.18676212430000305
train-epoch-step: 34-540 -- Loss: 0.1363801211118698
train-epoch-step: 34-541 -- Loss: 0.20713651180267334
train-epoch-step: 34-542 -- Loss: 0.21779344975948334
train-epoch-step: 34-543 -- Loss: 0.16776449978351593
train-epoch-step: 34-544 -- Loss: 0.23078465461730957
train-epoch-step: 34-545 -- Loss: 0.1969035118818283
train-epoch-step: 34-546 -- Loss: 0.20760424435138702
train-epoch-step: 34-547 -- Loss: 0.1783251166343689
train-epoch-step: 34-548 -- Loss: 0.09369156509637833
train-epoch-step: 34-549 -- Loss: 0.14952214062213898
train-epoch-step: 34-550 -- Loss: 0.19920818507671356
train-epoch-step: 34-551 -- Loss: 0.15869881212711334
train-epoch-step: 34-552 -- Loss: 0.12774141132831573
train-epoch-step: 34-553 -- Loss: 0.19045692682266235
train-epoch-step: 34-554 -- Loss: 0.18558409810066223
train-epoch-step: 34-555 -- Loss: 0.21387730538845062
train-epoch-step: 34-556 -- Loss: 0.14601147174835205
train-epoch-step: 34-557 -- Loss: 0.23664554953575134
train-epoch-step: 34-558 -- Loss: 0.22908169031143188
train-epoch-step: 34-559 -- Loss: 0.1490199863910675
train-epoch-step: 34-560 -- Loss: 0.20805123448371887
train-epoch-step: 34-561 -- Loss: 0.1793527603149414
train-epoch-step: 34-562 -- Loss: 0.16315564513206482
train-epoch-step: 34-563 -- Loss: 0.18670672178268433
train-epoch-step: 34-564 -- Loss: 0.10082568973302841
train-epoch-step: 34-565 -- Loss: 0.1884237825870514
train-epoch-step: 34-566 -- Loss: 0.14984270930290222
train-epoch-step: 34-567 -- Loss: 0.21120712161064148
train-epoch-step: 34-568 -- Loss: 0.16248810291290283
train-epoch-step: 34-569 -- Loss: 0.23946507275104523
train-epoch-step: 34-570 -- Loss: 0.16602790355682373
train-epoch-step: 34-571 -- Loss: 0.20874643325805664
train-epoch-step: 34-572 -- Loss: 0.24077846109867096
train-epoch-step: 34-573 -- Loss: 0.2018759399652481
train-epoch-step: 34-574 -- Loss: 0.2513190507888794
train-epoch-step: 34-575 -- Loss: 0.2933344542980194
train-epoch-step: 34-576 -- Loss: 0.12302875518798828
train-epoch-step: 34-577 -- Loss: 0.17238306999206543
train-epoch-step: 34-578 -- Loss: 0.21544037759304047
train-epoch-step: 34-579 -- Loss: 0.16330185532569885
train-epoch-step: 34-580 -- Loss: 0.1748673915863037
train-epoch-step: 34-581 -- Loss: 0.14035511016845703
train-epoch-step: 34-582 -- Loss: 0.20261019468307495
train-epoch-step: 34-583 -- Loss: 0.2164791226387024
train-epoch-step: 34-584 -- Loss: 0.1641114056110382
train-epoch-step: 34-585 -- Loss: 0.1956448256969452
train-epoch-step: 34-586 -- Loss: 0.2573346793651581
train-epoch-step: 34-587 -- Loss: 0.15988308191299438
train-epoch-step: 34-588 -- Loss: 0.12880636751651764
val-epoch-step: 34-589 -- Loss: 0.21867763996124268
val-epoch-step: 34-590 -- Loss: 0.15494726598262787
val-epoch-step: 34-591 -- Loss: 0.23659974336624146
val-epoch-step: 34-592 -- Loss: 0.17792168259620667
val-epoch-step: 34-593 -- Loss: 0.18340623378753662
val-epoch-step: 34-594 -- Loss: 0.3792862296104431
val-epoch-step: 34-595 -- Loss: 0.1925143003463745
val-epoch-step: 34-596 -- Loss: 0.1964365839958191
val-epoch-step: 34-597 -- Loss: 0.17081716656684875
val-epoch-step: 34-598 -- Loss: 0.14877700805664062
val-epoch-step: 34-599 -- Loss: 0.1884109079837799
val-epoch-step: 34-600 -- Loss: 0.22772350907325745
val-epoch-step: 34-601 -- Loss: 0.15540263056755066
val-epoch-step: 34-602 -- Loss: 0.1367952525615692
val-epoch-step: 34-603 -- Loss: 0.18627604842185974
val-epoch-step: 34-604 -- Loss: 0.1508377641439438
val-epoch-step: 34-605 -- Loss: 0.15162904560565948
val-epoch-step: 34-606 -- Loss: 0.2854071855545044
val-epoch-step: 34-607 -- Loss: 0.13222457468509674
val-epoch-step: 34-608 -- Loss: 0.24618573486804962
val-epoch-step: 34-609 -- Loss: 0.16763974726200104
val-epoch-step: 34-610 -- Loss: 0.18291610479354858
val-epoch-step: 34-611 -- Loss: 0.15735790133476257
val-epoch-step: 34-612 -- Loss: 0.3579280972480774
val-epoch-step: 34-613 -- Loss: 0.17329184710979462
val-epoch-step: 34-614 -- Loss: 0.1679641604423523
val-epoch-step: 34-615 -- Loss: 0.17822511494159698
val-epoch-step: 34-616 -- Loss: 0.1476980447769165
val-epoch-step: 34-617 -- Loss: 0.18481677770614624
val-epoch-step: 34-618 -- Loss: 0.18367712199687958
val-epoch-step: 34-619 -- Loss: 0.21417810022830963
val-epoch-step: 34-620 -- Loss: 0.13478073477745056
val-epoch-step: 34-621 -- Loss: 0.12633955478668213
val-epoch-step: 34-622 -- Loss: 0.14491555094718933
val-epoch-step: 34-623 -- Loss: 0.16394002735614777
val-epoch-step: 34-624 -- Loss: 0.1410895735025406
val-epoch-step: 34-625 -- Loss: 0.15874041616916656
val-epoch-step: 34-626 -- Loss: 0.14905640482902527
val-epoch-step: 34-627 -- Loss: 0.19151759147644043
val-epoch-step: 34-628 -- Loss: 0.5690484642982483
val-epoch-step: 34-629 -- Loss: 0.1930641233921051
val-epoch-step: 34-630 -- Loss: 0.3487541377544403
val-epoch-step: 34-631 -- Loss: 0.1420992761850357
val-epoch-step: 34-632 -- Loss: 0.20168159902095795
val-epoch-step: 34-633 -- Loss: 0.15140429139137268
val-epoch-step: 34-634 -- Loss: 0.1446172595024109
val-epoch-step: 34-635 -- Loss: 0.11973340064287186
val-epoch-step: 34-636 -- Loss: 0.16292662918567657
val-epoch-step: 34-637 -- Loss: 0.1856754720211029
val-epoch-step: 34-638 -- Loss: 0.14576877653598785
val-epoch-step: 34-639 -- Loss: 0.25396567583084106
val-epoch-step: 34-640 -- Loss: 0.2508336007595062
val-epoch-step: 34-641 -- Loss: 0.1268686205148697
val-epoch-step: 34-642 -- Loss: 0.1810777485370636
val-epoch-step: 34-643 -- Loss: 0.20451237261295319
val-epoch-step: 34-644 -- Loss: 0.1738574504852295
val-epoch-step: 34-645 -- Loss: 0.22022385895252228
val-epoch-step: 34-646 -- Loss: 0.1325874626636505
val-epoch-step: 34-647 -- Loss: 0.12970392405986786
val-epoch-step: 34-648 -- Loss: 0.1524208039045334
val-epoch-step: 34-649 -- Loss: 0.20668412744998932
val-epoch-step: 34-650 -- Loss: 0.2602006793022156
val-epoch-step: 34-651 -- Loss: 0.15385064482688904
val-epoch-step: 34-652 -- Loss: 0.15392141044139862
val-epoch-step: 34-653 -- Loss: 0.20553822815418243
val-epoch-step: 34-654 -- Loss: 0.1125669851899147
Epoch: 34 -- Train Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 35-0 -- Loss: 0.22120991349220276
train-epoch-step: 35-1 -- Loss: 0.14883168041706085
train-epoch-step: 35-2 -- Loss: 0.20205055177211761
train-epoch-step: 35-3 -- Loss: 0.1412469446659088
train-epoch-step: 35-4 -- Loss: 0.16133388876914978
train-epoch-step: 35-5 -- Loss: 0.1793750822544098
train-epoch-step: 35-6 -- Loss: 0.2187754064798355
train-epoch-step: 35-7 -- Loss: 0.17125201225280762
train-epoch-step: 35-8 -- Loss: 0.18051421642303467
train-epoch-step: 35-9 -- Loss: 0.2304989993572235
train-epoch-step: 35-10 -- Loss: 0.19708161056041718
train-epoch-step: 35-11 -- Loss: 0.17516463994979858
train-epoch-step: 35-12 -- Loss: 0.1487160623073578
train-epoch-step: 35-13 -- Loss: 0.18546941876411438
train-epoch-step: 35-14 -- Loss: 0.162327840924263
train-epoch-step: 35-15 -- Loss: 0.15946030616760254
train-epoch-step: 35-16 -- Loss: 0.16444937884807587
train-epoch-step: 35-17 -- Loss: 0.2190844863653183
train-epoch-step: 35-18 -- Loss: 0.20208315551280975
train-epoch-step: 35-19 -- Loss: 0.12887528538703918
train-epoch-step: 35-20 -- Loss: 0.2166207879781723
train-epoch-step: 35-21 -- Loss: 0.24679450690746307
train-epoch-step: 35-22 -- Loss: 0.13643445074558258
train-epoch-step: 35-23 -- Loss: 0.14523786306381226
train-epoch-step: 35-24 -- Loss: 0.12705622613430023
train-epoch-step: 35-25 -- Loss: 0.22715196013450623
train-epoch-step: 35-26 -- Loss: 0.19804343581199646
train-epoch-step: 35-27 -- Loss: 0.22817303240299225
train-epoch-step: 35-28 -- Loss: 0.1236312985420227
train-epoch-step: 35-29 -- Loss: 0.24826523661613464
train-epoch-step: 35-30 -- Loss: 0.10883203148841858
train-epoch-step: 35-31 -- Loss: 0.137401282787323
train-epoch-step: 35-32 -- Loss: 0.17331291735172272
train-epoch-step: 35-33 -- Loss: 0.27245035767555237
train-epoch-step: 35-34 -- Loss: 0.17177778482437134
train-epoch-step: 35-35 -- Loss: 0.24896195530891418
train-epoch-step: 35-36 -- Loss: 0.14090529084205627
train-epoch-step: 35-37 -- Loss: 0.14030498266220093
train-epoch-step: 35-38 -- Loss: 0.1765407919883728
train-epoch-step: 35-39 -- Loss: 0.21331040561199188
train-epoch-step: 35-40 -- Loss: 0.19308416545391083
train-epoch-step: 35-41 -- Loss: 0.21495456993579865
train-epoch-step: 35-42 -- Loss: 0.15050756931304932
train-epoch-step: 35-43 -- Loss: 0.26935315132141113
train-epoch-step: 35-44 -- Loss: 0.12550204992294312
train-epoch-step: 35-45 -- Loss: 0.12009945511817932
train-epoch-step: 35-46 -- Loss: 0.1648401916027069
train-epoch-step: 35-47 -- Loss: 0.21471025049686432
train-epoch-step: 35-48 -- Loss: 0.15461823344230652
train-epoch-step: 35-49 -- Loss: 0.2246500700712204
train-epoch-step: 35-50 -- Loss: 0.10893703252077103
train-epoch-step: 35-51 -- Loss: 0.17462588846683502
train-epoch-step: 35-52 -- Loss: 0.17132233083248138
train-epoch-step: 35-53 -- Loss: 0.20856279134750366
train-epoch-step: 35-54 -- Loss: 0.2833724319934845
train-epoch-step: 35-55 -- Loss: 0.16105498373508453
train-epoch-step: 35-56 -- Loss: 0.17764319479465485
train-epoch-step: 35-57 -- Loss: 0.2350267767906189
train-epoch-step: 35-58 -- Loss: 0.28169363737106323
train-epoch-step: 35-59 -- Loss: 0.235991433262825
train-epoch-step: 35-60 -- Loss: 0.13021810352802277
train-epoch-step: 35-61 -- Loss: 0.19885723292827606
train-epoch-step: 35-62 -- Loss: 0.18218253552913666
train-epoch-step: 35-63 -- Loss: 0.14406715333461761
train-epoch-step: 35-64 -- Loss: 0.13970132172107697
train-epoch-step: 35-65 -- Loss: 0.18111976981163025
train-epoch-step: 35-66 -- Loss: 0.10830338299274445
train-epoch-step: 35-67 -- Loss: 0.12539052963256836
train-epoch-step: 35-68 -- Loss: 0.21271544694900513
train-epoch-step: 35-69 -- Loss: 0.12398107349872589
train-epoch-step: 35-70 -- Loss: 0.22369621694087982
train-epoch-step: 35-71 -- Loss: 0.26416781544685364
train-epoch-step: 35-72 -- Loss: 0.1746109426021576
train-epoch-step: 35-73 -- Loss: 0.21663083136081696
train-epoch-step: 35-74 -- Loss: 0.09472688287496567
train-epoch-step: 35-75 -- Loss: 0.12574219703674316
train-epoch-step: 35-76 -- Loss: 0.14476975798606873
train-epoch-step: 35-77 -- Loss: 0.2260253131389618
train-epoch-step: 35-78 -- Loss: 0.24798646569252014
train-epoch-step: 35-79 -- Loss: 0.18991714715957642
train-epoch-step: 35-80 -- Loss: 0.24311506748199463
train-epoch-step: 35-81 -- Loss: 0.127015620470047
train-epoch-step: 35-82 -- Loss: 0.2449566125869751
train-epoch-step: 35-83 -- Loss: 0.18945570290088654
train-epoch-step: 35-84 -- Loss: 0.1902536302804947
train-epoch-step: 35-85 -- Loss: 0.1840345561504364
train-epoch-step: 35-86 -- Loss: 0.1220715343952179
train-epoch-step: 35-87 -- Loss: 0.21837225556373596
train-epoch-step: 35-88 -- Loss: 0.13950183987617493
train-epoch-step: 35-89 -- Loss: 0.18546134233474731
train-epoch-step: 35-90 -- Loss: 0.1905047744512558
train-epoch-step: 35-91 -- Loss: 0.24416235089302063
train-epoch-step: 35-92 -- Loss: 0.15513254702091217
train-epoch-step: 35-93 -- Loss: 0.1754089593887329
train-epoch-step: 35-94 -- Loss: 0.21826809644699097
train-epoch-step: 35-95 -- Loss: 0.18974348902702332
train-epoch-step: 35-96 -- Loss: 0.21519418060779572
train-epoch-step: 35-97 -- Loss: 0.17987608909606934
train-epoch-step: 35-98 -- Loss: 0.1538103073835373
train-epoch-step: 35-99 -- Loss: 0.1855728030204773
train-epoch-step: 35-100 -- Loss: 0.18786238133907318
train-epoch-step: 35-101 -- Loss: 0.26954716444015503
train-epoch-step: 35-102 -- Loss: 0.22298012673854828
train-epoch-step: 35-103 -- Loss: 0.18070939183235168
train-epoch-step: 35-104 -- Loss: 0.14756357669830322
train-epoch-step: 35-105 -- Loss: 0.27110329270362854
train-epoch-step: 35-106 -- Loss: 0.17552176117897034
train-epoch-step: 35-107 -- Loss: 0.18586497008800507
train-epoch-step: 35-108 -- Loss: 0.1862998902797699
train-epoch-step: 35-109 -- Loss: 0.14731360971927643
train-epoch-step: 35-110 -- Loss: 0.1883402317762375
train-epoch-step: 35-111 -- Loss: 0.17812496423721313
train-epoch-step: 35-112 -- Loss: 0.1664857268333435
train-epoch-step: 35-113 -- Loss: 0.16811835765838623
train-epoch-step: 35-114 -- Loss: 0.21904581785202026
train-epoch-step: 35-115 -- Loss: 0.16366168856620789
train-epoch-step: 35-116 -- Loss: 0.14172309637069702
train-epoch-step: 35-117 -- Loss: 0.12468889355659485
train-epoch-step: 35-118 -- Loss: 0.19262230396270752
train-epoch-step: 35-119 -- Loss: 0.15115012228488922
train-epoch-step: 35-120 -- Loss: 0.24894732236862183
train-epoch-step: 35-121 -- Loss: 0.2292623519897461
train-epoch-step: 35-122 -- Loss: 0.21860109269618988
train-epoch-step: 35-123 -- Loss: 0.2075614333152771
train-epoch-step: 35-124 -- Loss: 0.13493883609771729
train-epoch-step: 35-125 -- Loss: 0.15378788113594055
train-epoch-step: 35-126 -- Loss: 0.22461649775505066
train-epoch-step: 35-127 -- Loss: 0.17491959035396576
train-epoch-step: 35-128 -- Loss: 0.16894197463989258
train-epoch-step: 35-129 -- Loss: 0.14122779667377472
train-epoch-step: 35-130 -- Loss: 0.19096584618091583
train-epoch-step: 35-131 -- Loss: 0.13733705878257751
train-epoch-step: 35-132 -- Loss: 0.19208164513111115
train-epoch-step: 35-133 -- Loss: 0.12122765928506851
train-epoch-step: 35-134 -- Loss: 0.1940399706363678
train-epoch-step: 35-135 -- Loss: 0.1408928483724594
train-epoch-step: 35-136 -- Loss: 0.13102596998214722
train-epoch-step: 35-137 -- Loss: 0.24677345156669617
train-epoch-step: 35-138 -- Loss: 0.26386401057243347
train-epoch-step: 35-139 -- Loss: 0.13130444288253784
train-epoch-step: 35-140 -- Loss: 0.20969749987125397
train-epoch-step: 35-141 -- Loss: 0.22882595658302307
train-epoch-step: 35-142 -- Loss: 0.20316258072853088
train-epoch-step: 35-143 -- Loss: 0.17376381158828735
train-epoch-step: 35-144 -- Loss: 0.19382210075855255
train-epoch-step: 35-145 -- Loss: 0.139703169465065
train-epoch-step: 35-146 -- Loss: 0.18011406064033508
train-epoch-step: 35-147 -- Loss: 0.16651293635368347
train-epoch-step: 35-148 -- Loss: 0.15655294060707092
train-epoch-step: 35-149 -- Loss: 0.12684811651706696
train-epoch-step: 35-150 -- Loss: 0.1828353852033615
train-epoch-step: 35-151 -- Loss: 0.19762051105499268
train-epoch-step: 35-152 -- Loss: 0.19287914037704468
train-epoch-step: 35-153 -- Loss: 0.2635831832885742
train-epoch-step: 35-154 -- Loss: 0.13538603484630585
train-epoch-step: 35-155 -- Loss: 0.1342197060585022
train-epoch-step: 35-156 -- Loss: 0.11800708621740341
train-epoch-step: 35-157 -- Loss: 0.17173214256763458
train-epoch-step: 35-158 -- Loss: 0.1644691377878189
train-epoch-step: 35-159 -- Loss: 0.17681293189525604
train-epoch-step: 35-160 -- Loss: 0.21412283182144165
train-epoch-step: 35-161 -- Loss: 0.20336273312568665
train-epoch-step: 35-162 -- Loss: 0.20692652463912964
train-epoch-step: 35-163 -- Loss: 0.18513797223567963
train-epoch-step: 35-164 -- Loss: 0.18894390761852264
train-epoch-step: 35-165 -- Loss: 0.15961506962776184
train-epoch-step: 35-166 -- Loss: 0.12137145549058914
train-epoch-step: 35-167 -- Loss: 0.12224993109703064
train-epoch-step: 35-168 -- Loss: 0.20868933200836182
train-epoch-step: 35-169 -- Loss: 0.13959746062755585
train-epoch-step: 35-170 -- Loss: 0.2001047134399414
train-epoch-step: 35-171 -- Loss: 0.1428949534893036
train-epoch-step: 35-172 -- Loss: 0.26009389758110046
train-epoch-step: 35-173 -- Loss: 0.13210803270339966
train-epoch-step: 35-174 -- Loss: 0.2539656162261963
train-epoch-step: 35-175 -- Loss: 0.18627598881721497
train-epoch-step: 35-176 -- Loss: 0.13451027870178223
train-epoch-step: 35-177 -- Loss: 0.17910952866077423
train-epoch-step: 35-178 -- Loss: 0.17552226781845093
train-epoch-step: 35-179 -- Loss: 0.16250558197498322
train-epoch-step: 35-180 -- Loss: 0.15076574683189392
train-epoch-step: 35-181 -- Loss: 0.16796031594276428
train-epoch-step: 35-182 -- Loss: 0.1799396276473999
train-epoch-step: 35-183 -- Loss: 0.2712066173553467
train-epoch-step: 35-184 -- Loss: 0.14391328394412994
train-epoch-step: 35-185 -- Loss: 0.13883621990680695
train-epoch-step: 35-186 -- Loss: 0.18881691992282867
train-epoch-step: 35-187 -- Loss: 0.2143663913011551
train-epoch-step: 35-188 -- Loss: 0.18218322098255157
train-epoch-step: 35-189 -- Loss: 0.10529712587594986
train-epoch-step: 35-190 -- Loss: 0.1799084097146988
train-epoch-step: 35-191 -- Loss: 0.15928009152412415
train-epoch-step: 35-192 -- Loss: 0.23108510673046112
train-epoch-step: 35-193 -- Loss: 0.2040831595659256
train-epoch-step: 35-194 -- Loss: 0.18888331949710846
train-epoch-step: 35-195 -- Loss: 0.1660950481891632
train-epoch-step: 35-196 -- Loss: 0.16954666376113892
train-epoch-step: 35-197 -- Loss: 0.14595501124858856
train-epoch-step: 35-198 -- Loss: 0.13405609130859375
train-epoch-step: 35-199 -- Loss: 0.15192094445228577
train-epoch-step: 35-200 -- Loss: 0.12497332692146301
train-epoch-step: 35-201 -- Loss: 0.19907478988170624
train-epoch-step: 35-202 -- Loss: 0.13701464235782623
train-epoch-step: 35-203 -- Loss: 0.1783253401517868
train-epoch-step: 35-204 -- Loss: 0.1376449316740036
train-epoch-step: 35-205 -- Loss: 0.20077604055404663
train-epoch-step: 35-206 -- Loss: 0.20845046639442444
train-epoch-step: 35-207 -- Loss: 0.1381203532218933
train-epoch-step: 35-208 -- Loss: 0.18298304080963135
train-epoch-step: 35-209 -- Loss: 0.14099842309951782
train-epoch-step: 35-210 -- Loss: 0.13511133193969727
train-epoch-step: 35-211 -- Loss: 0.20125660300254822
train-epoch-step: 35-212 -- Loss: 0.20219773054122925
train-epoch-step: 35-213 -- Loss: 0.12964534759521484
train-epoch-step: 35-214 -- Loss: 0.1526850461959839
train-epoch-step: 35-215 -- Loss: 0.1445949375629425
train-epoch-step: 35-216 -- Loss: 0.20651604235172272
train-epoch-step: 35-217 -- Loss: 0.21395161747932434
train-epoch-step: 35-218 -- Loss: 0.14154332876205444
train-epoch-step: 35-219 -- Loss: 0.17817585170269012
train-epoch-step: 35-220 -- Loss: 0.13066351413726807
train-epoch-step: 35-221 -- Loss: 0.20045779645442963
train-epoch-step: 35-222 -- Loss: 0.11749063432216644
train-epoch-step: 35-223 -- Loss: 0.19110682606697083
train-epoch-step: 35-224 -- Loss: 0.19786980748176575
train-epoch-step: 35-225 -- Loss: 0.267442524433136
train-epoch-step: 35-226 -- Loss: 0.20520147681236267
train-epoch-step: 35-227 -- Loss: 0.22138583660125732
train-epoch-step: 35-228 -- Loss: 0.18225044012069702
train-epoch-step: 35-229 -- Loss: 0.1791273057460785
train-epoch-step: 35-230 -- Loss: 0.16237741708755493
train-epoch-step: 35-231 -- Loss: 0.160884827375412
train-epoch-step: 35-232 -- Loss: 0.18641750514507294
train-epoch-step: 35-233 -- Loss: 0.08466733247041702
train-epoch-step: 35-234 -- Loss: 0.17951127886772156
train-epoch-step: 35-235 -- Loss: 0.14668959379196167
train-epoch-step: 35-236 -- Loss: 0.18306417763233185
train-epoch-step: 35-237 -- Loss: 0.23759743571281433
train-epoch-step: 35-238 -- Loss: 0.1584489643573761
train-epoch-step: 35-239 -- Loss: 0.13133656978607178
train-epoch-step: 35-240 -- Loss: 0.22672055661678314
train-epoch-step: 35-241 -- Loss: 0.15215621888637543
train-epoch-step: 35-242 -- Loss: 0.22520175576210022
train-epoch-step: 35-243 -- Loss: 0.22807791829109192
train-epoch-step: 35-244 -- Loss: 0.20448432862758636
train-epoch-step: 35-245 -- Loss: 0.20829783380031586
train-epoch-step: 35-246 -- Loss: 0.22025784850120544
train-epoch-step: 35-247 -- Loss: 0.20702481269836426
train-epoch-step: 35-248 -- Loss: 0.18651559948921204
train-epoch-step: 35-249 -- Loss: 0.1382085084915161
train-epoch-step: 35-250 -- Loss: 0.20015621185302734
train-epoch-step: 35-251 -- Loss: 0.1094546839594841
train-epoch-step: 35-252 -- Loss: 0.2135024070739746
train-epoch-step: 35-253 -- Loss: 0.13858109712600708
train-epoch-step: 35-254 -- Loss: 0.21546876430511475
train-epoch-step: 35-255 -- Loss: 0.14806409180164337
train-epoch-step: 35-256 -- Loss: 0.17340579628944397
train-epoch-step: 35-257 -- Loss: 0.1907428801059723
train-epoch-step: 35-258 -- Loss: 0.14792202413082123
train-epoch-step: 35-259 -- Loss: 0.11528532207012177
train-epoch-step: 35-260 -- Loss: 0.20060423016548157
train-epoch-step: 35-261 -- Loss: 0.17060087621212006
train-epoch-step: 35-262 -- Loss: 0.301641047000885
train-epoch-step: 35-263 -- Loss: 0.20260605216026306
train-epoch-step: 35-264 -- Loss: 0.1749148666858673
train-epoch-step: 35-265 -- Loss: 0.13401666283607483
train-epoch-step: 35-266 -- Loss: 0.15870699286460876
train-epoch-step: 35-267 -- Loss: 0.12861187756061554
train-epoch-step: 35-268 -- Loss: 0.12228290736675262
train-epoch-step: 35-269 -- Loss: 0.17627471685409546
train-epoch-step: 35-270 -- Loss: 0.10578004270792007
train-epoch-step: 35-271 -- Loss: 0.14922991394996643
train-epoch-step: 35-272 -- Loss: 0.11682473123073578
train-epoch-step: 35-273 -- Loss: 0.1241711974143982
train-epoch-step: 35-274 -- Loss: 0.18160678446292877
train-epoch-step: 35-275 -- Loss: 0.2018466591835022
train-epoch-step: 35-276 -- Loss: 0.15443211793899536
train-epoch-step: 35-277 -- Loss: 0.15740995109081268
train-epoch-step: 35-278 -- Loss: 0.15242190659046173
train-epoch-step: 35-279 -- Loss: 0.14105500280857086
train-epoch-step: 35-280 -- Loss: 0.2223394513130188
train-epoch-step: 35-281 -- Loss: 0.17728635668754578
train-epoch-step: 35-282 -- Loss: 0.14295479655265808
train-epoch-step: 35-283 -- Loss: 0.11442145705223083
train-epoch-step: 35-284 -- Loss: 0.13819335401058197
train-epoch-step: 35-285 -- Loss: 0.1873789131641388
train-epoch-step: 35-286 -- Loss: 0.1530151069164276
train-epoch-step: 35-287 -- Loss: 0.20756816864013672
train-epoch-step: 35-288 -- Loss: 0.09765374660491943
train-epoch-step: 35-289 -- Loss: 0.12055102735757828
train-epoch-step: 35-290 -- Loss: 0.17715726792812347
train-epoch-step: 35-291 -- Loss: 0.11916051059961319
train-epoch-step: 35-292 -- Loss: 0.15711019933223724
train-epoch-step: 35-293 -- Loss: 0.13730451464653015
train-epoch-step: 35-294 -- Loss: 0.16631120443344116
train-epoch-step: 35-295 -- Loss: 0.2755647301673889
train-epoch-step: 35-296 -- Loss: 0.15953472256660461
train-epoch-step: 35-297 -- Loss: 0.1739349514245987
train-epoch-step: 35-298 -- Loss: 0.23189622163772583
train-epoch-step: 35-299 -- Loss: 0.147306889295578
train-epoch-step: 35-300 -- Loss: 0.17336417734622955
train-epoch-step: 35-301 -- Loss: 0.17729982733726501
train-epoch-step: 35-302 -- Loss: 0.22084681689739227
train-epoch-step: 35-303 -- Loss: 0.20361584424972534
train-epoch-step: 35-304 -- Loss: 0.12697483599185944
train-epoch-step: 35-305 -- Loss: 0.14477968215942383
train-epoch-step: 35-306 -- Loss: 0.2519156336784363
train-epoch-step: 35-307 -- Loss: 0.16802383959293365
train-epoch-step: 35-308 -- Loss: 0.21911633014678955
train-epoch-step: 35-309 -- Loss: 0.17564955353736877
train-epoch-step: 35-310 -- Loss: 0.163205087184906
train-epoch-step: 35-311 -- Loss: 0.1585375964641571
train-epoch-step: 35-312 -- Loss: 0.20692603290081024
train-epoch-step: 35-313 -- Loss: 0.10038717091083527
train-epoch-step: 35-314 -- Loss: 0.20143091678619385
train-epoch-step: 35-315 -- Loss: 0.16633158922195435
train-epoch-step: 35-316 -- Loss: 0.15523487329483032
train-epoch-step: 35-317 -- Loss: 0.16071674227714539
train-epoch-step: 35-318 -- Loss: 0.17115598917007446
train-epoch-step: 35-319 -- Loss: 0.17423146963119507
train-epoch-step: 35-320 -- Loss: 0.12930552661418915
train-epoch-step: 35-321 -- Loss: 0.13409467041492462
train-epoch-step: 35-322 -- Loss: 0.23212000727653503
train-epoch-step: 35-323 -- Loss: 0.17446020245552063
train-epoch-step: 35-324 -- Loss: 0.2534005343914032
train-epoch-step: 35-325 -- Loss: 0.15580575168132782
train-epoch-step: 35-326 -- Loss: 0.1692478358745575
train-epoch-step: 35-327 -- Loss: 0.21037495136260986
train-epoch-step: 35-328 -- Loss: 0.19700708985328674
train-epoch-step: 35-329 -- Loss: 0.3454069495201111
train-epoch-step: 35-330 -- Loss: 0.36757320165634155
train-epoch-step: 35-331 -- Loss: 0.21300745010375977
train-epoch-step: 35-332 -- Loss: 0.10599809885025024
train-epoch-step: 35-333 -- Loss: 0.2149796485900879
train-epoch-step: 35-334 -- Loss: 0.1649598479270935
train-epoch-step: 35-335 -- Loss: 0.1749432384967804
train-epoch-step: 35-336 -- Loss: 0.16202539205551147
train-epoch-step: 35-337 -- Loss: 0.22695571184158325
train-epoch-step: 35-338 -- Loss: 0.16107892990112305
train-epoch-step: 35-339 -- Loss: 0.1461821347475052
train-epoch-step: 35-340 -- Loss: 0.21170806884765625
train-epoch-step: 35-341 -- Loss: 0.15109515190124512
train-epoch-step: 35-342 -- Loss: 0.16505731642246246
train-epoch-step: 35-343 -- Loss: 0.15478914976119995
train-epoch-step: 35-344 -- Loss: 0.1689341813325882
train-epoch-step: 35-345 -- Loss: 0.1430162489414215
train-epoch-step: 35-346 -- Loss: 0.2163967490196228
train-epoch-step: 35-347 -- Loss: 0.15457507967948914
train-epoch-step: 35-348 -- Loss: 0.21351683139801025
train-epoch-step: 35-349 -- Loss: 0.21050651371479034
train-epoch-step: 35-350 -- Loss: 0.25938141345977783
train-epoch-step: 35-351 -- Loss: 0.1970791220664978
train-epoch-step: 35-352 -- Loss: 0.13029952347278595
train-epoch-step: 35-353 -- Loss: 0.19729074835777283
train-epoch-step: 35-354 -- Loss: 0.2822698652744293
train-epoch-step: 35-355 -- Loss: 0.11795294284820557
train-epoch-step: 35-356 -- Loss: 0.11525965481996536
train-epoch-step: 35-357 -- Loss: 0.19370469450950623
train-epoch-step: 35-358 -- Loss: 0.1818738430738449
train-epoch-step: 35-359 -- Loss: 0.14486846327781677
train-epoch-step: 35-360 -- Loss: 0.1258358508348465
train-epoch-step: 35-361 -- Loss: 0.23880165815353394
train-epoch-step: 35-362 -- Loss: 0.16867753863334656
train-epoch-step: 35-363 -- Loss: 0.1089421957731247
train-epoch-step: 35-364 -- Loss: 0.183615043759346
train-epoch-step: 35-365 -- Loss: 0.17487473785877228
train-epoch-step: 35-366 -- Loss: 0.2005957067012787
train-epoch-step: 35-367 -- Loss: 0.246047243475914
train-epoch-step: 35-368 -- Loss: 0.20822149515151978
train-epoch-step: 35-369 -- Loss: 0.2829408645629883
train-epoch-step: 35-370 -- Loss: 0.12510651350021362
train-epoch-step: 35-371 -- Loss: 0.12167758494615555
train-epoch-step: 35-372 -- Loss: 0.14743496477603912
train-epoch-step: 35-373 -- Loss: 0.20810189843177795
train-epoch-step: 35-374 -- Loss: 0.15498854219913483
train-epoch-step: 35-375 -- Loss: 0.2682309150695801
train-epoch-step: 35-376 -- Loss: 0.16410812735557556
train-epoch-step: 35-377 -- Loss: 0.2456715852022171
train-epoch-step: 35-378 -- Loss: 0.20276005566120148
train-epoch-step: 35-379 -- Loss: 0.12367938458919525
train-epoch-step: 35-380 -- Loss: 0.09214410930871964
train-epoch-step: 35-381 -- Loss: 0.2404513657093048
train-epoch-step: 35-382 -- Loss: 0.23486246168613434
train-epoch-step: 35-383 -- Loss: 0.17654985189437866
train-epoch-step: 35-384 -- Loss: 0.21764513850212097
train-epoch-step: 35-385 -- Loss: 0.18977537751197815
train-epoch-step: 35-386 -- Loss: 0.1908750832080841
train-epoch-step: 35-387 -- Loss: 0.2032168060541153
train-epoch-step: 35-388 -- Loss: 0.18912319839000702
train-epoch-step: 35-389 -- Loss: 0.16793739795684814
train-epoch-step: 35-390 -- Loss: 0.15508116781711578
train-epoch-step: 35-391 -- Loss: 0.1438516229391098
train-epoch-step: 35-392 -- Loss: 0.18199841678142548
train-epoch-step: 35-393 -- Loss: 0.15421436727046967
train-epoch-step: 35-394 -- Loss: 0.20475351810455322
train-epoch-step: 35-395 -- Loss: 0.16190379858016968
train-epoch-step: 35-396 -- Loss: 0.12678304314613342
train-epoch-step: 35-397 -- Loss: 0.12829937040805817
train-epoch-step: 35-398 -- Loss: 0.2004169076681137
train-epoch-step: 35-399 -- Loss: 0.17652621865272522
train-epoch-step: 35-400 -- Loss: 0.2845125198364258
train-epoch-step: 35-401 -- Loss: 0.12712408602237701
train-epoch-step: 35-402 -- Loss: 0.26302093267440796
train-epoch-step: 35-403 -- Loss: 0.1563265174627304
train-epoch-step: 35-404 -- Loss: 0.13713794946670532
train-epoch-step: 35-405 -- Loss: 0.14295469224452972
train-epoch-step: 35-406 -- Loss: 0.1648344099521637
train-epoch-step: 35-407 -- Loss: 0.11457681655883789
train-epoch-step: 35-408 -- Loss: 0.16088619828224182
train-epoch-step: 35-409 -- Loss: 0.17153452336788177
train-epoch-step: 35-410 -- Loss: 0.17532537877559662
train-epoch-step: 35-411 -- Loss: 0.20834429562091827
train-epoch-step: 35-412 -- Loss: 0.13341818749904633
train-epoch-step: 35-413 -- Loss: 0.14797696471214294
train-epoch-step: 35-414 -- Loss: 0.1324249804019928
train-epoch-step: 35-415 -- Loss: 0.13393843173980713
train-epoch-step: 35-416 -- Loss: 0.2624739706516266
train-epoch-step: 35-417 -- Loss: 0.1893487274646759
train-epoch-step: 35-418 -- Loss: 0.2596825957298279
train-epoch-step: 35-419 -- Loss: 0.17035676538944244
train-epoch-step: 35-420 -- Loss: 0.16513633728027344
train-epoch-step: 35-421 -- Loss: 0.20022490620613098
train-epoch-step: 35-422 -- Loss: 0.1493409425020218
train-epoch-step: 35-423 -- Loss: 0.19222208857536316
train-epoch-step: 35-424 -- Loss: 0.1403469443321228
train-epoch-step: 35-425 -- Loss: 0.2223367989063263
train-epoch-step: 35-426 -- Loss: 0.16241884231567383
train-epoch-step: 35-427 -- Loss: 0.12387983500957489
train-epoch-step: 35-428 -- Loss: 0.19929423928260803
train-epoch-step: 35-429 -- Loss: 0.17716935276985168
train-epoch-step: 35-430 -- Loss: 0.15748284757137299
train-epoch-step: 35-431 -- Loss: 0.1686106026172638
train-epoch-step: 35-432 -- Loss: 0.24575771391391754
train-epoch-step: 35-433 -- Loss: 0.1491415947675705
train-epoch-step: 35-434 -- Loss: 0.13680237531661987
train-epoch-step: 35-435 -- Loss: 0.15316718816757202
train-epoch-step: 35-436 -- Loss: 0.1638336479663849
train-epoch-step: 35-437 -- Loss: 0.13533879816532135
train-epoch-step: 35-438 -- Loss: 0.17577320337295532
train-epoch-step: 35-439 -- Loss: 0.27019697427749634
train-epoch-step: 35-440 -- Loss: 0.13300763070583344
train-epoch-step: 35-441 -- Loss: 0.2048024833202362
train-epoch-step: 35-442 -- Loss: 0.17758628726005554
train-epoch-step: 35-443 -- Loss: 0.1609402298927307
train-epoch-step: 35-444 -- Loss: 0.1929321438074112
train-epoch-step: 35-445 -- Loss: 0.17901919782161713
train-epoch-step: 35-446 -- Loss: 0.15612226724624634
train-epoch-step: 35-447 -- Loss: 0.19421210885047913
train-epoch-step: 35-448 -- Loss: 0.22562123835086823
train-epoch-step: 35-449 -- Loss: 0.19142334163188934
train-epoch-step: 35-450 -- Loss: 0.18356963992118835
train-epoch-step: 35-451 -- Loss: 0.1442842185497284
train-epoch-step: 35-452 -- Loss: 0.1285369098186493
train-epoch-step: 35-453 -- Loss: 0.09611829370260239
train-epoch-step: 35-454 -- Loss: 0.2334810197353363
train-epoch-step: 35-455 -- Loss: 0.12591269612312317
train-epoch-step: 35-456 -- Loss: 0.12050425261259079
train-epoch-step: 35-457 -- Loss: 0.21947497129440308
train-epoch-step: 35-458 -- Loss: 0.14525310695171356
train-epoch-step: 35-459 -- Loss: 0.21225735545158386
train-epoch-step: 35-460 -- Loss: 0.1321154534816742
train-epoch-step: 35-461 -- Loss: 0.13607856631278992
train-epoch-step: 35-462 -- Loss: 0.15506690740585327
train-epoch-step: 35-463 -- Loss: 0.13302187621593475
train-epoch-step: 35-464 -- Loss: 0.15964794158935547
train-epoch-step: 35-465 -- Loss: 0.24355687201023102
train-epoch-step: 35-466 -- Loss: 0.19913381338119507
train-epoch-step: 35-467 -- Loss: 0.11501571536064148
train-epoch-step: 35-468 -- Loss: 0.1683725118637085
train-epoch-step: 35-469 -- Loss: 0.22932711243629456
train-epoch-step: 35-470 -- Loss: 0.17535430192947388
train-epoch-step: 35-471 -- Loss: 0.1611132174730301
train-epoch-step: 35-472 -- Loss: 0.15631921589374542
train-epoch-step: 35-473 -- Loss: 0.16108228266239166
train-epoch-step: 35-474 -- Loss: 0.12170455604791641
train-epoch-step: 35-475 -- Loss: 0.11766313016414642
train-epoch-step: 35-476 -- Loss: 0.19835859537124634
train-epoch-step: 35-477 -- Loss: 0.21145765483379364
train-epoch-step: 35-478 -- Loss: 0.1993550956249237
train-epoch-step: 35-479 -- Loss: 0.1463836133480072
train-epoch-step: 35-480 -- Loss: 0.195946604013443
train-epoch-step: 35-481 -- Loss: 0.285695344209671
train-epoch-step: 35-482 -- Loss: 0.25620004534721375
train-epoch-step: 35-483 -- Loss: 0.18155615031719208
train-epoch-step: 35-484 -- Loss: 0.21512827277183533
train-epoch-step: 35-485 -- Loss: 0.1259089559316635
train-epoch-step: 35-486 -- Loss: 0.2309352457523346
train-epoch-step: 35-487 -- Loss: 0.227704256772995
train-epoch-step: 35-488 -- Loss: 0.19826211035251617
train-epoch-step: 35-489 -- Loss: 0.22386375069618225
train-epoch-step: 35-490 -- Loss: 0.14143435657024384
train-epoch-step: 35-491 -- Loss: 0.13681179285049438
train-epoch-step: 35-492 -- Loss: 0.1265830546617508
train-epoch-step: 35-493 -- Loss: 0.20614710450172424
train-epoch-step: 35-494 -- Loss: 0.203927144408226
train-epoch-step: 35-495 -- Loss: 0.201514333486557
train-epoch-step: 35-496 -- Loss: 0.14029482007026672
train-epoch-step: 35-497 -- Loss: 0.19356857240200043
train-epoch-step: 35-498 -- Loss: 0.1478806734085083
train-epoch-step: 35-499 -- Loss: 0.16977114975452423
train-epoch-step: 35-500 -- Loss: 0.154685378074646
train-epoch-step: 35-501 -- Loss: 0.21709361672401428
train-epoch-step: 35-502 -- Loss: 0.15822778642177582
train-epoch-step: 35-503 -- Loss: 0.21658088266849518
train-epoch-step: 35-504 -- Loss: 0.12201132625341415
train-epoch-step: 35-505 -- Loss: 0.1686517894268036
train-epoch-step: 35-506 -- Loss: 0.12184249609708786
train-epoch-step: 35-507 -- Loss: 0.18126264214515686
train-epoch-step: 35-508 -- Loss: 0.1733018308877945
train-epoch-step: 35-509 -- Loss: 0.17223504185676575
train-epoch-step: 35-510 -- Loss: 0.1273990273475647
train-epoch-step: 35-511 -- Loss: 0.21381913125514984
train-epoch-step: 35-512 -- Loss: 0.17586909234523773
train-epoch-step: 35-513 -- Loss: 0.19180354475975037
train-epoch-step: 35-514 -- Loss: 0.14720048010349274
train-epoch-step: 35-515 -- Loss: 0.16307033598423004
train-epoch-step: 35-516 -- Loss: 0.17517487704753876
train-epoch-step: 35-517 -- Loss: 0.1749255657196045
train-epoch-step: 35-518 -- Loss: 0.13472707569599152
train-epoch-step: 35-519 -- Loss: 0.1334124207496643
train-epoch-step: 35-520 -- Loss: 0.18517355620861053
train-epoch-step: 35-521 -- Loss: 0.2262980043888092
train-epoch-step: 35-522 -- Loss: 0.1782773733139038
train-epoch-step: 35-523 -- Loss: 0.15436603128910065
train-epoch-step: 35-524 -- Loss: 0.16893626749515533
train-epoch-step: 35-525 -- Loss: 0.19319617748260498
train-epoch-step: 35-526 -- Loss: 0.13405269384384155
train-epoch-step: 35-527 -- Loss: 0.15184268355369568
train-epoch-step: 35-528 -- Loss: 0.1567080318927765
train-epoch-step: 35-529 -- Loss: 0.15945792198181152
train-epoch-step: 35-530 -- Loss: 0.18706020712852478
train-epoch-step: 35-531 -- Loss: 0.19685810804367065
train-epoch-step: 35-532 -- Loss: 0.16896869242191315
train-epoch-step: 35-533 -- Loss: 0.1720699518918991
train-epoch-step: 35-534 -- Loss: 0.13164091110229492
train-epoch-step: 35-535 -- Loss: 0.2684921622276306
train-epoch-step: 35-536 -- Loss: 0.1629391759634018
train-epoch-step: 35-537 -- Loss: 0.14607907831668854
train-epoch-step: 35-538 -- Loss: 0.10557572543621063
train-epoch-step: 35-539 -- Loss: 0.18111515045166016
train-epoch-step: 35-540 -- Loss: 0.14001399278640747
train-epoch-step: 35-541 -- Loss: 0.20952050387859344
train-epoch-step: 35-542 -- Loss: 0.21988697350025177
train-epoch-step: 35-543 -- Loss: 0.1701263189315796
train-epoch-step: 35-544 -- Loss: 0.22270503640174866
train-epoch-step: 35-545 -- Loss: 0.19278374314308167
train-epoch-step: 35-546 -- Loss: 0.2063630074262619
train-epoch-step: 35-547 -- Loss: 0.1804056465625763
train-epoch-step: 35-548 -- Loss: 0.0951579287648201
train-epoch-step: 35-549 -- Loss: 0.15127834677696228
train-epoch-step: 35-550 -- Loss: 0.20158544182777405
train-epoch-step: 35-551 -- Loss: 0.15783123672008514
train-epoch-step: 35-552 -- Loss: 0.12735214829444885
train-epoch-step: 35-553 -- Loss: 0.18547968566417694
train-epoch-step: 35-554 -- Loss: 0.1895734965801239
train-epoch-step: 35-555 -- Loss: 0.2252429723739624
train-epoch-step: 35-556 -- Loss: 0.1493886411190033
train-epoch-step: 35-557 -- Loss: 0.2572380304336548
train-epoch-step: 35-558 -- Loss: 0.22506116330623627
train-epoch-step: 35-559 -- Loss: 0.14276549220085144
train-epoch-step: 35-560 -- Loss: 0.20348535478115082
train-epoch-step: 35-561 -- Loss: 0.18071341514587402
train-epoch-step: 35-562 -- Loss: 0.16509026288986206
train-epoch-step: 35-563 -- Loss: 0.18303140997886658
train-epoch-step: 35-564 -- Loss: 0.09897999465465546
train-epoch-step: 35-565 -- Loss: 0.17847084999084473
train-epoch-step: 35-566 -- Loss: 0.14392271637916565
train-epoch-step: 35-567 -- Loss: 0.2143513411283493
train-epoch-step: 35-568 -- Loss: 0.1654716581106186
train-epoch-step: 35-569 -- Loss: 0.2427895963191986
train-epoch-step: 35-570 -- Loss: 0.17231501638889313
train-epoch-step: 35-571 -- Loss: 0.21703845262527466
train-epoch-step: 35-572 -- Loss: 0.23441961407661438
train-epoch-step: 35-573 -- Loss: 0.20075756311416626
train-epoch-step: 35-574 -- Loss: 0.2403862178325653
train-epoch-step: 35-575 -- Loss: 0.29415732622146606
train-epoch-step: 35-576 -- Loss: 0.12011945992708206
train-epoch-step: 35-577 -- Loss: 0.16822683811187744
train-epoch-step: 35-578 -- Loss: 0.21353508532047272
train-epoch-step: 35-579 -- Loss: 0.17822211980819702
train-epoch-step: 35-580 -- Loss: 0.17578640580177307
train-epoch-step: 35-581 -- Loss: 0.1391352117061615
train-epoch-step: 35-582 -- Loss: 0.20320996642112732
train-epoch-step: 35-583 -- Loss: 0.21429914236068726
train-epoch-step: 35-584 -- Loss: 0.159552201628685
train-epoch-step: 35-585 -- Loss: 0.19139494001865387
train-epoch-step: 35-586 -- Loss: 0.2576489746570587
train-epoch-step: 35-587 -- Loss: 0.16066595911979675
train-epoch-step: 35-588 -- Loss: 0.12723462283611298
val-epoch-step: 35-589 -- Loss: 0.200400710105896
val-epoch-step: 35-590 -- Loss: 0.15394484996795654
val-epoch-step: 35-591 -- Loss: 0.22623741626739502
val-epoch-step: 35-592 -- Loss: 0.17839881777763367
val-epoch-step: 35-593 -- Loss: 0.17919766902923584
val-epoch-step: 35-594 -- Loss: 0.3859020471572876
val-epoch-step: 35-595 -- Loss: 0.1946665197610855
val-epoch-step: 35-596 -- Loss: 0.230628103017807
val-epoch-step: 35-597 -- Loss: 0.1789754033088684
val-epoch-step: 35-598 -- Loss: 0.14959697425365448
val-epoch-step: 35-599 -- Loss: 0.18351244926452637
val-epoch-step: 35-600 -- Loss: 0.24906255304813385
val-epoch-step: 35-601 -- Loss: 0.15492284297943115
val-epoch-step: 35-602 -- Loss: 0.13656190037727356
val-epoch-step: 35-603 -- Loss: 0.1887562870979309
val-epoch-step: 35-604 -- Loss: 0.1469157338142395
val-epoch-step: 35-605 -- Loss: 0.14592254161834717
val-epoch-step: 35-606 -- Loss: 0.2619391083717346
val-epoch-step: 35-607 -- Loss: 0.1276858001947403
val-epoch-step: 35-608 -- Loss: 0.24985522031784058
val-epoch-step: 35-609 -- Loss: 0.17967145144939423
val-epoch-step: 35-610 -- Loss: 0.17943687736988068
val-epoch-step: 35-611 -- Loss: 0.1598280966281891
val-epoch-step: 35-612 -- Loss: 0.43466514348983765
val-epoch-step: 35-613 -- Loss: 0.17667202651500702
val-epoch-step: 35-614 -- Loss: 0.18029478192329407
val-epoch-step: 35-615 -- Loss: 0.1748330295085907
val-epoch-step: 35-616 -- Loss: 0.14592775702476501
val-epoch-step: 35-617 -- Loss: 0.18295793235301971
val-epoch-step: 35-618 -- Loss: 0.18564292788505554
val-epoch-step: 35-619 -- Loss: 0.22066253423690796
val-epoch-step: 35-620 -- Loss: 0.1441141813993454
val-epoch-step: 35-621 -- Loss: 0.12860842049121857
val-epoch-step: 35-622 -- Loss: 0.14536498486995697
val-epoch-step: 35-623 -- Loss: 0.15047135949134827
val-epoch-step: 35-624 -- Loss: 0.14767470955848694
val-epoch-step: 35-625 -- Loss: 0.16401556134223938
val-epoch-step: 35-626 -- Loss: 0.14698833227157593
val-epoch-step: 35-627 -- Loss: 0.19384773075580597
val-epoch-step: 35-628 -- Loss: 0.6009443998336792
val-epoch-step: 35-629 -- Loss: 0.21943968534469604
val-epoch-step: 35-630 -- Loss: 0.3500464856624603
val-epoch-step: 35-631 -- Loss: 0.14135286211967468
val-epoch-step: 35-632 -- Loss: 0.20309342443943024
val-epoch-step: 35-633 -- Loss: 0.15264199674129486
val-epoch-step: 35-634 -- Loss: 0.13887345790863037
val-epoch-step: 35-635 -- Loss: 0.11813735961914062
val-epoch-step: 35-636 -- Loss: 0.20084786415100098
val-epoch-step: 35-637 -- Loss: 0.18309524655342102
val-epoch-step: 35-638 -- Loss: 0.16203635931015015
val-epoch-step: 35-639 -- Loss: 0.25914865732192993
val-epoch-step: 35-640 -- Loss: 0.25470513105392456
val-epoch-step: 35-641 -- Loss: 0.12463308870792389
val-epoch-step: 35-642 -- Loss: 0.21510279178619385
val-epoch-step: 35-643 -- Loss: 0.20361784100532532
val-epoch-step: 35-644 -- Loss: 0.16725431382656097
val-epoch-step: 35-645 -- Loss: 0.22226431965827942
val-epoch-step: 35-646 -- Loss: 0.13610689342021942
val-epoch-step: 35-647 -- Loss: 0.1279507577419281
val-epoch-step: 35-648 -- Loss: 0.16204845905303955
val-epoch-step: 35-649 -- Loss: 0.20601758360862732
val-epoch-step: 35-650 -- Loss: 0.2503472566604614
val-epoch-step: 35-651 -- Loss: 0.1411975622177124
val-epoch-step: 35-652 -- Loss: 0.15885081887245178
val-epoch-step: 35-653 -- Loss: 0.20936214923858643
val-epoch-step: 35-654 -- Loss: 0.1181374192237854
Epoch: 35 -- Train Loss: tensor(0.1422, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 36-0 -- Loss: 0.2194230854511261
train-epoch-step: 36-1 -- Loss: 0.14489427208900452
train-epoch-step: 36-2 -- Loss: 0.19840410351753235
train-epoch-step: 36-3 -- Loss: 0.14568868279457092
train-epoch-step: 36-4 -- Loss: 0.15965616703033447
train-epoch-step: 36-5 -- Loss: 0.18082819879055023
train-epoch-step: 36-6 -- Loss: 0.21918275952339172
train-epoch-step: 36-7 -- Loss: 0.1649184226989746
train-epoch-step: 36-8 -- Loss: 0.1793016493320465
train-epoch-step: 36-9 -- Loss: 0.23392534255981445
train-epoch-step: 36-10 -- Loss: 0.1922886073589325
train-epoch-step: 36-11 -- Loss: 0.19357827305793762
train-epoch-step: 36-12 -- Loss: 0.1513180136680603
train-epoch-step: 36-13 -- Loss: 0.1828252375125885
train-epoch-step: 36-14 -- Loss: 0.16592805087566376
train-epoch-step: 36-15 -- Loss: 0.15821334719657898
train-epoch-step: 36-16 -- Loss: 0.18355761468410492
train-epoch-step: 36-17 -- Loss: 0.224416121840477
train-epoch-step: 36-18 -- Loss: 0.19211037456989288
train-epoch-step: 36-19 -- Loss: 0.13168615102767944
train-epoch-step: 36-20 -- Loss: 0.21881666779518127
train-epoch-step: 36-21 -- Loss: 0.2692549228668213
train-epoch-step: 36-22 -- Loss: 0.14512816071510315
train-epoch-step: 36-23 -- Loss: 0.14367730915546417
train-epoch-step: 36-24 -- Loss: 0.12652170658111572
train-epoch-step: 36-25 -- Loss: 0.2367945909500122
train-epoch-step: 36-26 -- Loss: 0.19248534739017487
train-epoch-step: 36-27 -- Loss: 0.23079913854599
train-epoch-step: 36-28 -- Loss: 0.12263797223567963
train-epoch-step: 36-29 -- Loss: 0.24383926391601562
train-epoch-step: 36-30 -- Loss: 0.10926243662834167
train-epoch-step: 36-31 -- Loss: 0.1400769054889679
train-epoch-step: 36-32 -- Loss: 0.17587552964687347
train-epoch-step: 36-33 -- Loss: 0.27186319231987
train-epoch-step: 36-34 -- Loss: 0.17428438365459442
train-epoch-step: 36-35 -- Loss: 0.24897223711013794
train-epoch-step: 36-36 -- Loss: 0.14028409123420715
train-epoch-step: 36-37 -- Loss: 0.14251179993152618
train-epoch-step: 36-38 -- Loss: 0.1808139532804489
train-epoch-step: 36-39 -- Loss: 0.2238958775997162
train-epoch-step: 36-40 -- Loss: 0.20011259615421295
train-epoch-step: 36-41 -- Loss: 0.2208220660686493
train-epoch-step: 36-42 -- Loss: 0.15398535132408142
train-epoch-step: 36-43 -- Loss: 0.26847419142723083
train-epoch-step: 36-44 -- Loss: 0.1259487122297287
train-epoch-step: 36-45 -- Loss: 0.12130860239267349
train-epoch-step: 36-46 -- Loss: 0.17267653346061707
train-epoch-step: 36-47 -- Loss: 0.20353946089744568
train-epoch-step: 36-48 -- Loss: 0.15718893706798553
train-epoch-step: 36-49 -- Loss: 0.22155728936195374
train-epoch-step: 36-50 -- Loss: 0.11707168817520142
train-epoch-step: 36-51 -- Loss: 0.18588292598724365
train-epoch-step: 36-52 -- Loss: 0.1581767201423645
train-epoch-step: 36-53 -- Loss: 0.212998628616333
train-epoch-step: 36-54 -- Loss: 0.2826007604598999
train-epoch-step: 36-55 -- Loss: 0.1716623157262802
train-epoch-step: 36-56 -- Loss: 0.17217957973480225
train-epoch-step: 36-57 -- Loss: 0.23687595129013062
train-epoch-step: 36-58 -- Loss: 0.28716692328453064
train-epoch-step: 36-59 -- Loss: 0.2443711757659912
train-epoch-step: 36-60 -- Loss: 0.1268640160560608
train-epoch-step: 36-61 -- Loss: 0.206745445728302
train-epoch-step: 36-62 -- Loss: 0.18430301547050476
train-epoch-step: 36-63 -- Loss: 0.14352813363075256
train-epoch-step: 36-64 -- Loss: 0.14795388281345367
train-epoch-step: 36-65 -- Loss: 0.1801082342863083
train-epoch-step: 36-66 -- Loss: 0.10940824449062347
train-epoch-step: 36-67 -- Loss: 0.12723347544670105
train-epoch-step: 36-68 -- Loss: 0.2174154371023178
train-epoch-step: 36-69 -- Loss: 0.12350211292505264
train-epoch-step: 36-70 -- Loss: 0.22457098960876465
train-epoch-step: 36-71 -- Loss: 0.2643488347530365
train-epoch-step: 36-72 -- Loss: 0.17796698212623596
train-epoch-step: 36-73 -- Loss: 0.2070634812116623
train-epoch-step: 36-74 -- Loss: 0.09467663615942001
train-epoch-step: 36-75 -- Loss: 0.12902604043483734
train-epoch-step: 36-76 -- Loss: 0.14773988723754883
train-epoch-step: 36-77 -- Loss: 0.22774139046669006
train-epoch-step: 36-78 -- Loss: 0.26192522048950195
train-epoch-step: 36-79 -- Loss: 0.20092818140983582
train-epoch-step: 36-80 -- Loss: 0.2952169179916382
train-epoch-step: 36-81 -- Loss: 0.12289734184741974
train-epoch-step: 36-82 -- Loss: 0.24544396996498108
train-epoch-step: 36-83 -- Loss: 0.1767883151769638
train-epoch-step: 36-84 -- Loss: 0.19580847024917603
train-epoch-step: 36-85 -- Loss: 0.1767161786556244
train-epoch-step: 36-86 -- Loss: 0.13327111303806305
train-epoch-step: 36-87 -- Loss: 0.2190333902835846
train-epoch-step: 36-88 -- Loss: 0.14403916895389557
train-epoch-step: 36-89 -- Loss: 0.2318892478942871
train-epoch-step: 36-90 -- Loss: 0.1927625834941864
train-epoch-step: 36-91 -- Loss: 0.2591354250907898
train-epoch-step: 36-92 -- Loss: 0.15093746781349182
train-epoch-step: 36-93 -- Loss: 0.2007591724395752
train-epoch-step: 36-94 -- Loss: 0.22895900905132294
train-epoch-step: 36-95 -- Loss: 0.1927146166563034
train-epoch-step: 36-96 -- Loss: 0.2189810425043106
train-epoch-step: 36-97 -- Loss: 0.17835938930511475
train-epoch-step: 36-98 -- Loss: 0.1664014756679535
train-epoch-step: 36-99 -- Loss: 0.18965131044387817
train-epoch-step: 36-100 -- Loss: 0.19287841022014618
train-epoch-step: 36-101 -- Loss: 0.28331390023231506
train-epoch-step: 36-102 -- Loss: 0.23088327050209045
train-epoch-step: 36-103 -- Loss: 0.19193413853645325
train-epoch-step: 36-104 -- Loss: 0.15326270461082458
train-epoch-step: 36-105 -- Loss: 0.271098256111145
train-epoch-step: 36-106 -- Loss: 0.17368154227733612
train-epoch-step: 36-107 -- Loss: 0.18662381172180176
train-epoch-step: 36-108 -- Loss: 0.18730968236923218
train-epoch-step: 36-109 -- Loss: 0.1525881588459015
train-epoch-step: 36-110 -- Loss: 0.1869763433933258
train-epoch-step: 36-111 -- Loss: 0.18057525157928467
train-epoch-step: 36-112 -- Loss: 0.1705213189125061
train-epoch-step: 36-113 -- Loss: 0.16136029362678528
train-epoch-step: 36-114 -- Loss: 0.19859164953231812
train-epoch-step: 36-115 -- Loss: 0.16738586127758026
train-epoch-step: 36-116 -- Loss: 0.13977235555648804
train-epoch-step: 36-117 -- Loss: 0.12679335474967957
train-epoch-step: 36-118 -- Loss: 0.19155624508857727
train-epoch-step: 36-119 -- Loss: 0.15164263546466827
train-epoch-step: 36-120 -- Loss: 0.24812376499176025
train-epoch-step: 36-121 -- Loss: 0.2412506490945816
train-epoch-step: 36-122 -- Loss: 0.2174559086561203
train-epoch-step: 36-123 -- Loss: 0.2043747752904892
train-epoch-step: 36-124 -- Loss: 0.12431041896343231
train-epoch-step: 36-125 -- Loss: 0.1563037931919098
train-epoch-step: 36-126 -- Loss: 0.2277383804321289
train-epoch-step: 36-127 -- Loss: 0.17191916704177856
train-epoch-step: 36-128 -- Loss: 0.17482644319534302
train-epoch-step: 36-129 -- Loss: 0.15241950750350952
train-epoch-step: 36-130 -- Loss: 0.19772788882255554
train-epoch-step: 36-131 -- Loss: 0.13725827634334564
train-epoch-step: 36-132 -- Loss: 0.189775288105011
train-epoch-step: 36-133 -- Loss: 0.11657629162073135
train-epoch-step: 36-134 -- Loss: 0.19384193420410156
train-epoch-step: 36-135 -- Loss: 0.14101707935333252
train-epoch-step: 36-136 -- Loss: 0.1259816735982895
train-epoch-step: 36-137 -- Loss: 0.24254342913627625
train-epoch-step: 36-138 -- Loss: 0.26794707775115967
train-epoch-step: 36-139 -- Loss: 0.1293388307094574
train-epoch-step: 36-140 -- Loss: 0.20375683903694153
train-epoch-step: 36-141 -- Loss: 0.2301543951034546
train-epoch-step: 36-142 -- Loss: 0.20008069276809692
train-epoch-step: 36-143 -- Loss: 0.17661282420158386
train-epoch-step: 36-144 -- Loss: 0.18984533846378326
train-epoch-step: 36-145 -- Loss: 0.14372707903385162
train-epoch-step: 36-146 -- Loss: 0.1770903766155243
train-epoch-step: 36-147 -- Loss: 0.17316225171089172
train-epoch-step: 36-148 -- Loss: 0.16743116080760956
train-epoch-step: 36-149 -- Loss: 0.11886996775865555
train-epoch-step: 36-150 -- Loss: 0.1844077855348587
train-epoch-step: 36-151 -- Loss: 0.18887750804424286
train-epoch-step: 36-152 -- Loss: 0.19711031019687653
train-epoch-step: 36-153 -- Loss: 0.26427578926086426
train-epoch-step: 36-154 -- Loss: 0.12842027842998505
train-epoch-step: 36-155 -- Loss: 0.1424829661846161
train-epoch-step: 36-156 -- Loss: 0.11846562474966049
train-epoch-step: 36-157 -- Loss: 0.17267033457756042
train-epoch-step: 36-158 -- Loss: 0.16437774896621704
train-epoch-step: 36-159 -- Loss: 0.18483677506446838
train-epoch-step: 36-160 -- Loss: 0.21669356524944305
train-epoch-step: 36-161 -- Loss: 0.2089129388332367
train-epoch-step: 36-162 -- Loss: 0.2194032073020935
train-epoch-step: 36-163 -- Loss: 0.18912635743618011
train-epoch-step: 36-164 -- Loss: 0.1938508152961731
train-epoch-step: 36-165 -- Loss: 0.16551460325717926
train-epoch-step: 36-166 -- Loss: 0.12361958622932434
train-epoch-step: 36-167 -- Loss: 0.12226235866546631
train-epoch-step: 36-168 -- Loss: 0.20650075376033783
train-epoch-step: 36-169 -- Loss: 0.13545070588588715
train-epoch-step: 36-170 -- Loss: 0.20129826664924622
train-epoch-step: 36-171 -- Loss: 0.1467716544866562
train-epoch-step: 36-172 -- Loss: 0.2596825957298279
train-epoch-step: 36-173 -- Loss: 0.13226068019866943
train-epoch-step: 36-174 -- Loss: 0.2501608431339264
train-epoch-step: 36-175 -- Loss: 0.1829269379377365
train-epoch-step: 36-176 -- Loss: 0.13367050886154175
train-epoch-step: 36-177 -- Loss: 0.19331562519073486
train-epoch-step: 36-178 -- Loss: 0.18729999661445618
train-epoch-step: 36-179 -- Loss: 0.15278470516204834
train-epoch-step: 36-180 -- Loss: 0.16921651363372803
train-epoch-step: 36-181 -- Loss: 0.16817399859428406
train-epoch-step: 36-182 -- Loss: 0.1841418743133545
train-epoch-step: 36-183 -- Loss: 0.2715771198272705
train-epoch-step: 36-184 -- Loss: 0.1396728903055191
train-epoch-step: 36-185 -- Loss: 0.14146918058395386
train-epoch-step: 36-186 -- Loss: 0.18553780019283295
train-epoch-step: 36-187 -- Loss: 0.21230387687683105
train-epoch-step: 36-188 -- Loss: 0.16938690841197968
train-epoch-step: 36-189 -- Loss: 0.10599661618471146
train-epoch-step: 36-190 -- Loss: 0.1862516552209854
train-epoch-step: 36-191 -- Loss: 0.1607319712638855
train-epoch-step: 36-192 -- Loss: 0.23394504189491272
train-epoch-step: 36-193 -- Loss: 0.21030497550964355
train-epoch-step: 36-194 -- Loss: 0.18146437406539917
train-epoch-step: 36-195 -- Loss: 0.1709386110305786
train-epoch-step: 36-196 -- Loss: 0.16942736506462097
train-epoch-step: 36-197 -- Loss: 0.13205236196517944
train-epoch-step: 36-198 -- Loss: 0.12993627786636353
train-epoch-step: 36-199 -- Loss: 0.15415745973587036
train-epoch-step: 36-200 -- Loss: 0.12444642186164856
train-epoch-step: 36-201 -- Loss: 0.1882219910621643
train-epoch-step: 36-202 -- Loss: 0.13506296277046204
train-epoch-step: 36-203 -- Loss: 0.1795261800289154
train-epoch-step: 36-204 -- Loss: 0.14108674228191376
train-epoch-step: 36-205 -- Loss: 0.18001273274421692
train-epoch-step: 36-206 -- Loss: 0.20223963260650635
train-epoch-step: 36-207 -- Loss: 0.15031269192695618
train-epoch-step: 36-208 -- Loss: 0.17606733739376068
train-epoch-step: 36-209 -- Loss: 0.14326350390911102
train-epoch-step: 36-210 -- Loss: 0.13093745708465576
train-epoch-step: 36-211 -- Loss: 0.20501351356506348
train-epoch-step: 36-212 -- Loss: 0.20157013833522797
train-epoch-step: 36-213 -- Loss: 0.127283975481987
train-epoch-step: 36-214 -- Loss: 0.1466529369354248
train-epoch-step: 36-215 -- Loss: 0.12585920095443726
train-epoch-step: 36-216 -- Loss: 0.20423337817192078
train-epoch-step: 36-217 -- Loss: 0.2139310985803604
train-epoch-step: 36-218 -- Loss: 0.14512790739536285
train-epoch-step: 36-219 -- Loss: 0.1887926608324051
train-epoch-step: 36-220 -- Loss: 0.13022904098033905
train-epoch-step: 36-221 -- Loss: 0.20828847587108612
train-epoch-step: 36-222 -- Loss: 0.11653836816549301
train-epoch-step: 36-223 -- Loss: 0.173458069562912
train-epoch-step: 36-224 -- Loss: 0.1909806877374649
train-epoch-step: 36-225 -- Loss: 0.26926088333129883
train-epoch-step: 36-226 -- Loss: 0.20973101258277893
train-epoch-step: 36-227 -- Loss: 0.22054295241832733
train-epoch-step: 36-228 -- Loss: 0.17799441516399384
train-epoch-step: 36-229 -- Loss: 0.17438477277755737
train-epoch-step: 36-230 -- Loss: 0.16526077687740326
train-epoch-step: 36-231 -- Loss: 0.15536364912986755
train-epoch-step: 36-232 -- Loss: 0.1847163885831833
train-epoch-step: 36-233 -- Loss: 0.08305899798870087
train-epoch-step: 36-234 -- Loss: 0.1770947277545929
train-epoch-step: 36-235 -- Loss: 0.14601102471351624
train-epoch-step: 36-236 -- Loss: 0.177994042634964
train-epoch-step: 36-237 -- Loss: 0.23410381376743317
train-epoch-step: 36-238 -- Loss: 0.15973299741744995
train-epoch-step: 36-239 -- Loss: 0.12747794389724731
train-epoch-step: 36-240 -- Loss: 0.22512729465961456
train-epoch-step: 36-241 -- Loss: 0.1518995761871338
train-epoch-step: 36-242 -- Loss: 0.22013556957244873
train-epoch-step: 36-243 -- Loss: 0.23054757714271545
train-epoch-step: 36-244 -- Loss: 0.20382627844810486
train-epoch-step: 36-245 -- Loss: 0.20354609191417694
train-epoch-step: 36-246 -- Loss: 0.2132173478603363
train-epoch-step: 36-247 -- Loss: 0.2183549404144287
train-epoch-step: 36-248 -- Loss: 0.18042853474617004
train-epoch-step: 36-249 -- Loss: 0.13798248767852783
train-epoch-step: 36-250 -- Loss: 0.19593773782253265
train-epoch-step: 36-251 -- Loss: 0.1085851639509201
train-epoch-step: 36-252 -- Loss: 0.19548022747039795
train-epoch-step: 36-253 -- Loss: 0.13437598943710327
train-epoch-step: 36-254 -- Loss: 0.21840064227581024
train-epoch-step: 36-255 -- Loss: 0.145419642329216
train-epoch-step: 36-256 -- Loss: 0.1494070142507553
train-epoch-step: 36-257 -- Loss: 0.1887224316596985
train-epoch-step: 36-258 -- Loss: 0.14265076816082
train-epoch-step: 36-259 -- Loss: 0.11669425666332245
train-epoch-step: 36-260 -- Loss: 0.19892287254333496
train-epoch-step: 36-261 -- Loss: 0.1707521677017212
train-epoch-step: 36-262 -- Loss: 0.2853598892688751
train-epoch-step: 36-263 -- Loss: 0.19405128061771393
train-epoch-step: 36-264 -- Loss: 0.17405162751674652
train-epoch-step: 36-265 -- Loss: 0.13050222396850586
train-epoch-step: 36-266 -- Loss: 0.1527642160654068
train-epoch-step: 36-267 -- Loss: 0.12752968072891235
train-epoch-step: 36-268 -- Loss: 0.12277853488922119
train-epoch-step: 36-269 -- Loss: 0.17180849611759186
train-epoch-step: 36-270 -- Loss: 0.10672822594642639
train-epoch-step: 36-271 -- Loss: 0.1460402011871338
train-epoch-step: 36-272 -- Loss: 0.11761407554149628
train-epoch-step: 36-273 -- Loss: 0.12690705060958862
train-epoch-step: 36-274 -- Loss: 0.18171541392803192
train-epoch-step: 36-275 -- Loss: 0.19315840303897858
train-epoch-step: 36-276 -- Loss: 0.15500761568546295
train-epoch-step: 36-277 -- Loss: 0.15759843587875366
train-epoch-step: 36-278 -- Loss: 0.1371241956949234
train-epoch-step: 36-279 -- Loss: 0.13722288608551025
train-epoch-step: 36-280 -- Loss: 0.21966569125652313
train-epoch-step: 36-281 -- Loss: 0.1813422292470932
train-epoch-step: 36-282 -- Loss: 0.1417030543088913
train-epoch-step: 36-283 -- Loss: 0.11514177918434143
train-epoch-step: 36-284 -- Loss: 0.12841108441352844
train-epoch-step: 36-285 -- Loss: 0.1884462833404541
train-epoch-step: 36-286 -- Loss: 0.15527398884296417
train-epoch-step: 36-287 -- Loss: 0.20156113803386688
train-epoch-step: 36-288 -- Loss: 0.09252967685461044
train-epoch-step: 36-289 -- Loss: 0.11812777817249298
train-epoch-step: 36-290 -- Loss: 0.18129278719425201
train-epoch-step: 36-291 -- Loss: 0.11512498557567596
train-epoch-step: 36-292 -- Loss: 0.15486018359661102
train-epoch-step: 36-293 -- Loss: 0.13630202412605286
train-epoch-step: 36-294 -- Loss: 0.15941691398620605
train-epoch-step: 36-295 -- Loss: 0.26664668321609497
train-epoch-step: 36-296 -- Loss: 0.1569611132144928
train-epoch-step: 36-297 -- Loss: 0.1784418523311615
train-epoch-step: 36-298 -- Loss: 0.22996383905410767
train-epoch-step: 36-299 -- Loss: 0.14530086517333984
train-epoch-step: 36-300 -- Loss: 0.1629413664340973
train-epoch-step: 36-301 -- Loss: 0.1691286861896515
train-epoch-step: 36-302 -- Loss: 0.2188648283481598
train-epoch-step: 36-303 -- Loss: 0.1999395191669464
train-epoch-step: 36-304 -- Loss: 0.1263364553451538
train-epoch-step: 36-305 -- Loss: 0.14222076535224915
train-epoch-step: 36-306 -- Loss: 0.22699260711669922
train-epoch-step: 36-307 -- Loss: 0.16350442171096802
train-epoch-step: 36-308 -- Loss: 0.2247137874364853
train-epoch-step: 36-309 -- Loss: 0.1548079401254654
train-epoch-step: 36-310 -- Loss: 0.16133016347885132
train-epoch-step: 36-311 -- Loss: 0.16037026047706604
train-epoch-step: 36-312 -- Loss: 0.20195892453193665
train-epoch-step: 36-313 -- Loss: 0.09635180234909058
train-epoch-step: 36-314 -- Loss: 0.18936525285243988
train-epoch-step: 36-315 -- Loss: 0.1681286096572876
train-epoch-step: 36-316 -- Loss: 0.1520778238773346
train-epoch-step: 36-317 -- Loss: 0.14025290310382843
train-epoch-step: 36-318 -- Loss: 0.16148565709590912
train-epoch-step: 36-319 -- Loss: 0.17042946815490723
train-epoch-step: 36-320 -- Loss: 0.11698809266090393
train-epoch-step: 36-321 -- Loss: 0.1307961791753769
train-epoch-step: 36-322 -- Loss: 0.21019653975963593
train-epoch-step: 36-323 -- Loss: 0.16183984279632568
train-epoch-step: 36-324 -- Loss: 0.2523050904273987
train-epoch-step: 36-325 -- Loss: 0.15518683195114136
train-epoch-step: 36-326 -- Loss: 0.1681370735168457
train-epoch-step: 36-327 -- Loss: 0.20487192273139954
train-epoch-step: 36-328 -- Loss: 0.19263653457164764
train-epoch-step: 36-329 -- Loss: 0.3378791809082031
train-epoch-step: 36-330 -- Loss: 0.356544554233551
train-epoch-step: 36-331 -- Loss: 0.21067312359809875
train-epoch-step: 36-332 -- Loss: 0.10287322849035263
train-epoch-step: 36-333 -- Loss: 0.18156729638576508
train-epoch-step: 36-334 -- Loss: 0.15985515713691711
train-epoch-step: 36-335 -- Loss: 0.17653270065784454
train-epoch-step: 36-336 -- Loss: 0.14661633968353271
train-epoch-step: 36-337 -- Loss: 0.19989576935768127
train-epoch-step: 36-338 -- Loss: 0.15643219649791718
train-epoch-step: 36-339 -- Loss: 0.14189836382865906
train-epoch-step: 36-340 -- Loss: 0.19246388971805573
train-epoch-step: 36-341 -- Loss: 0.1397106647491455
train-epoch-step: 36-342 -- Loss: 0.1668122261762619
train-epoch-step: 36-343 -- Loss: 0.15320293605327606
train-epoch-step: 36-344 -- Loss: 0.1688532829284668
train-epoch-step: 36-345 -- Loss: 0.13271251320838928
train-epoch-step: 36-346 -- Loss: 0.1973820924758911
train-epoch-step: 36-347 -- Loss: 0.15015117824077606
train-epoch-step: 36-348 -- Loss: 0.20078438520431519
train-epoch-step: 36-349 -- Loss: 0.20812878012657166
train-epoch-step: 36-350 -- Loss: 0.24858376383781433
train-epoch-step: 36-351 -- Loss: 0.19068093597888947
train-epoch-step: 36-352 -- Loss: 0.12024028599262238
train-epoch-step: 36-353 -- Loss: 0.19681887328624725
train-epoch-step: 36-354 -- Loss: 0.28526175022125244
train-epoch-step: 36-355 -- Loss: 0.116758331656456
train-epoch-step: 36-356 -- Loss: 0.11632910370826721
train-epoch-step: 36-357 -- Loss: 0.19866597652435303
train-epoch-step: 36-358 -- Loss: 0.1842568814754486
train-epoch-step: 36-359 -- Loss: 0.1382748782634735
train-epoch-step: 36-360 -- Loss: 0.12275076657533646
train-epoch-step: 36-361 -- Loss: 0.2393878996372223
train-epoch-step: 36-362 -- Loss: 0.16682103276252747
train-epoch-step: 36-363 -- Loss: 0.11192695051431656
train-epoch-step: 36-364 -- Loss: 0.17878784239292145
train-epoch-step: 36-365 -- Loss: 0.17501980066299438
train-epoch-step: 36-366 -- Loss: 0.2021992802619934
train-epoch-step: 36-367 -- Loss: 0.23765631020069122
train-epoch-step: 36-368 -- Loss: 0.19666342437267303
train-epoch-step: 36-369 -- Loss: 0.2749714255332947
train-epoch-step: 36-370 -- Loss: 0.12779000401496887
train-epoch-step: 36-371 -- Loss: 0.11993838846683502
train-epoch-step: 36-372 -- Loss: 0.14409351348876953
train-epoch-step: 36-373 -- Loss: 0.19686108827590942
train-epoch-step: 36-374 -- Loss: 0.1535547375679016
train-epoch-step: 36-375 -- Loss: 0.2686084806919098
train-epoch-step: 36-376 -- Loss: 0.1596868634223938
train-epoch-step: 36-377 -- Loss: 0.2239435315132141
train-epoch-step: 36-378 -- Loss: 0.20214879512786865
train-epoch-step: 36-379 -- Loss: 0.1252625733613968
train-epoch-step: 36-380 -- Loss: 0.09032006561756134
train-epoch-step: 36-381 -- Loss: 0.245158851146698
train-epoch-step: 36-382 -- Loss: 0.23471739888191223
train-epoch-step: 36-383 -- Loss: 0.17183299362659454
train-epoch-step: 36-384 -- Loss: 0.21769759058952332
train-epoch-step: 36-385 -- Loss: 0.18930155038833618
train-epoch-step: 36-386 -- Loss: 0.18611060082912445
train-epoch-step: 36-387 -- Loss: 0.20094312727451324
train-epoch-step: 36-388 -- Loss: 0.19174428284168243
train-epoch-step: 36-389 -- Loss: 0.16568908095359802
train-epoch-step: 36-390 -- Loss: 0.14286649227142334
train-epoch-step: 36-391 -- Loss: 0.14608226716518402
train-epoch-step: 36-392 -- Loss: 0.18875545263290405
train-epoch-step: 36-393 -- Loss: 0.15563584864139557
train-epoch-step: 36-394 -- Loss: 0.19848574697971344
train-epoch-step: 36-395 -- Loss: 0.1582895815372467
train-epoch-step: 36-396 -- Loss: 0.12540048360824585
train-epoch-step: 36-397 -- Loss: 0.12657997012138367
train-epoch-step: 36-398 -- Loss: 0.19626151025295258
train-epoch-step: 36-399 -- Loss: 0.1871839016675949
train-epoch-step: 36-400 -- Loss: 0.28275835514068604
train-epoch-step: 36-401 -- Loss: 0.12217952311038971
train-epoch-step: 36-402 -- Loss: 0.2562086284160614
train-epoch-step: 36-403 -- Loss: 0.15172219276428223
train-epoch-step: 36-404 -- Loss: 0.13717488944530487
train-epoch-step: 36-405 -- Loss: 0.14473779499530792
train-epoch-step: 36-406 -- Loss: 0.16747966408729553
train-epoch-step: 36-407 -- Loss: 0.11291074007749557
train-epoch-step: 36-408 -- Loss: 0.15808303654193878
train-epoch-step: 36-409 -- Loss: 0.17003172636032104
train-epoch-step: 36-410 -- Loss: 0.17270849645137787
train-epoch-step: 36-411 -- Loss: 0.2010038197040558
train-epoch-step: 36-412 -- Loss: 0.13001574575901031
train-epoch-step: 36-413 -- Loss: 0.148781418800354
train-epoch-step: 36-414 -- Loss: 0.13394705951213837
train-epoch-step: 36-415 -- Loss: 0.13785913586616516
train-epoch-step: 36-416 -- Loss: 0.2678852677345276
train-epoch-step: 36-417 -- Loss: 0.19263452291488647
train-epoch-step: 36-418 -- Loss: 0.23627644777297974
train-epoch-step: 36-419 -- Loss: 0.16846147179603577
train-epoch-step: 36-420 -- Loss: 0.15408456325531006
train-epoch-step: 36-421 -- Loss: 0.17672421038150787
train-epoch-step: 36-422 -- Loss: 0.150098979473114
train-epoch-step: 36-423 -- Loss: 0.18246778845787048
train-epoch-step: 36-424 -- Loss: 0.13527745008468628
train-epoch-step: 36-425 -- Loss: 0.18648838996887207
train-epoch-step: 36-426 -- Loss: 0.16493266820907593
train-epoch-step: 36-427 -- Loss: 0.12111195176839828
train-epoch-step: 36-428 -- Loss: 0.20135582983493805
train-epoch-step: 36-429 -- Loss: 0.17333242297172546
train-epoch-step: 36-430 -- Loss: 0.14079397916793823
train-epoch-step: 36-431 -- Loss: 0.16226035356521606
train-epoch-step: 36-432 -- Loss: 0.24076321721076965
train-epoch-step: 36-433 -- Loss: 0.13565321266651154
train-epoch-step: 36-434 -- Loss: 0.1285843700170517
train-epoch-step: 36-435 -- Loss: 0.1595645695924759
train-epoch-step: 36-436 -- Loss: 0.15567761659622192
train-epoch-step: 36-437 -- Loss: 0.13316300511360168
train-epoch-step: 36-438 -- Loss: 0.1676475554704666
train-epoch-step: 36-439 -- Loss: 0.2673081159591675
train-epoch-step: 36-440 -- Loss: 0.13077229261398315
train-epoch-step: 36-441 -- Loss: 0.20418232679367065
train-epoch-step: 36-442 -- Loss: 0.17780393362045288
train-epoch-step: 36-443 -- Loss: 0.15774697065353394
train-epoch-step: 36-444 -- Loss: 0.17300646007061005
train-epoch-step: 36-445 -- Loss: 0.18035656213760376
train-epoch-step: 36-446 -- Loss: 0.151033416390419
train-epoch-step: 36-447 -- Loss: 0.19561509788036346
train-epoch-step: 36-448 -- Loss: 0.22484713792800903
train-epoch-step: 36-449 -- Loss: 0.19150754809379578
train-epoch-step: 36-450 -- Loss: 0.17913560569286346
train-epoch-step: 36-451 -- Loss: 0.1424476057291031
train-epoch-step: 36-452 -- Loss: 0.1281478852033615
train-epoch-step: 36-453 -- Loss: 0.09592021256685257
train-epoch-step: 36-454 -- Loss: 0.2292785942554474
train-epoch-step: 36-455 -- Loss: 0.12587295472621918
train-epoch-step: 36-456 -- Loss: 0.1187758520245552
train-epoch-step: 36-457 -- Loss: 0.2143944352865219
train-epoch-step: 36-458 -- Loss: 0.14757747948169708
train-epoch-step: 36-459 -- Loss: 0.21133707463741302
train-epoch-step: 36-460 -- Loss: 0.13087432086467743
train-epoch-step: 36-461 -- Loss: 0.13271592557430267
train-epoch-step: 36-462 -- Loss: 0.15930406749248505
train-epoch-step: 36-463 -- Loss: 0.13403348624706268
train-epoch-step: 36-464 -- Loss: 0.15729601681232452
train-epoch-step: 36-465 -- Loss: 0.2353648543357849
train-epoch-step: 36-466 -- Loss: 0.19920015335083008
train-epoch-step: 36-467 -- Loss: 0.12184129655361176
train-epoch-step: 36-468 -- Loss: 0.166364848613739
train-epoch-step: 36-469 -- Loss: 0.2186807543039322
train-epoch-step: 36-470 -- Loss: 0.1784767508506775
train-epoch-step: 36-471 -- Loss: 0.15528751909732819
train-epoch-step: 36-472 -- Loss: 0.1567932516336441
train-epoch-step: 36-473 -- Loss: 0.15621717274188995
train-epoch-step: 36-474 -- Loss: 0.11655036360025406
train-epoch-step: 36-475 -- Loss: 0.10719525814056396
train-epoch-step: 36-476 -- Loss: 0.20366764068603516
train-epoch-step: 36-477 -- Loss: 0.20662787556648254
train-epoch-step: 36-478 -- Loss: 0.2038845717906952
train-epoch-step: 36-479 -- Loss: 0.1575576364994049
train-epoch-step: 36-480 -- Loss: 0.20203475654125214
train-epoch-step: 36-481 -- Loss: 0.28269293904304504
train-epoch-step: 36-482 -- Loss: 0.2612771689891815
train-epoch-step: 36-483 -- Loss: 0.1836787611246109
train-epoch-step: 36-484 -- Loss: 0.21269215643405914
train-epoch-step: 36-485 -- Loss: 0.13670825958251953
train-epoch-step: 36-486 -- Loss: 0.24431319534778595
train-epoch-step: 36-487 -- Loss: 0.22677847743034363
train-epoch-step: 36-488 -- Loss: 0.20500530302524567
train-epoch-step: 36-489 -- Loss: 0.21760119497776031
train-epoch-step: 36-490 -- Loss: 0.13720008730888367
train-epoch-step: 36-491 -- Loss: 0.14805637300014496
train-epoch-step: 36-492 -- Loss: 0.12721554934978485
train-epoch-step: 36-493 -- Loss: 0.20416951179504395
train-epoch-step: 36-494 -- Loss: 0.20475813746452332
train-epoch-step: 36-495 -- Loss: 0.20766228437423706
train-epoch-step: 36-496 -- Loss: 0.1419815868139267
train-epoch-step: 36-497 -- Loss: 0.18621432781219482
train-epoch-step: 36-498 -- Loss: 0.1538851410150528
train-epoch-step: 36-499 -- Loss: 0.17239655554294586
train-epoch-step: 36-500 -- Loss: 0.15560197830200195
train-epoch-step: 36-501 -- Loss: 0.2246226966381073
train-epoch-step: 36-502 -- Loss: 0.15863466262817383
train-epoch-step: 36-503 -- Loss: 0.22415049374103546
train-epoch-step: 36-504 -- Loss: 0.12506292760372162
train-epoch-step: 36-505 -- Loss: 0.1730320006608963
train-epoch-step: 36-506 -- Loss: 0.11988215148448944
train-epoch-step: 36-507 -- Loss: 0.1835901439189911
train-epoch-step: 36-508 -- Loss: 0.1772361546754837
train-epoch-step: 36-509 -- Loss: 0.16641610860824585
train-epoch-step: 36-510 -- Loss: 0.1277093142271042
train-epoch-step: 36-511 -- Loss: 0.21940262615680695
train-epoch-step: 36-512 -- Loss: 0.18021413683891296
train-epoch-step: 36-513 -- Loss: 0.18855608999729156
train-epoch-step: 36-514 -- Loss: 0.14779064059257507
train-epoch-step: 36-515 -- Loss: 0.15529654920101166
train-epoch-step: 36-516 -- Loss: 0.16826187074184418
train-epoch-step: 36-517 -- Loss: 0.17187076807022095
train-epoch-step: 36-518 -- Loss: 0.14127413928508759
train-epoch-step: 36-519 -- Loss: 0.13798300921916962
train-epoch-step: 36-520 -- Loss: 0.187154158949852
train-epoch-step: 36-521 -- Loss: 0.22510962188243866
train-epoch-step: 36-522 -- Loss: 0.17633305490016937
train-epoch-step: 36-523 -- Loss: 0.15661178529262543
train-epoch-step: 36-524 -- Loss: 0.16851429641246796
train-epoch-step: 36-525 -- Loss: 0.19993171095848083
train-epoch-step: 36-526 -- Loss: 0.1301461011171341
train-epoch-step: 36-527 -- Loss: 0.1550329029560089
train-epoch-step: 36-528 -- Loss: 0.1578879952430725
train-epoch-step: 36-529 -- Loss: 0.15820705890655518
train-epoch-step: 36-530 -- Loss: 0.16910693049430847
train-epoch-step: 36-531 -- Loss: 0.2021527886390686
train-epoch-step: 36-532 -- Loss: 0.16794688999652863
train-epoch-step: 36-533 -- Loss: 0.17236819863319397
train-epoch-step: 36-534 -- Loss: 0.13195320963859558
train-epoch-step: 36-535 -- Loss: 0.258916437625885
train-epoch-step: 36-536 -- Loss: 0.16345401108264923
train-epoch-step: 36-537 -- Loss: 0.14457668364048004
train-epoch-step: 36-538 -- Loss: 0.10753345489501953
train-epoch-step: 36-539 -- Loss: 0.18107125163078308
train-epoch-step: 36-540 -- Loss: 0.134363055229187
train-epoch-step: 36-541 -- Loss: 0.2130305916070938
train-epoch-step: 36-542 -- Loss: 0.21632879972457886
train-epoch-step: 36-543 -- Loss: 0.16843147575855255
train-epoch-step: 36-544 -- Loss: 0.22501569986343384
train-epoch-step: 36-545 -- Loss: 0.19519951939582825
train-epoch-step: 36-546 -- Loss: 0.22301538288593292
train-epoch-step: 36-547 -- Loss: 0.1801956444978714
train-epoch-step: 36-548 -- Loss: 0.09442617744207382
train-epoch-step: 36-549 -- Loss: 0.14967313408851624
train-epoch-step: 36-550 -- Loss: 0.1967657208442688
train-epoch-step: 36-551 -- Loss: 0.15668009221553802
train-epoch-step: 36-552 -- Loss: 0.1245042160153389
train-epoch-step: 36-553 -- Loss: 0.18877236545085907
train-epoch-step: 36-554 -- Loss: 0.1903664916753769
train-epoch-step: 36-555 -- Loss: 0.22754910588264465
train-epoch-step: 36-556 -- Loss: 0.14831870794296265
train-epoch-step: 36-557 -- Loss: 0.2377399504184723
train-epoch-step: 36-558 -- Loss: 0.2276088297367096
train-epoch-step: 36-559 -- Loss: 0.14081302285194397
train-epoch-step: 36-560 -- Loss: 0.2043858766555786
train-epoch-step: 36-561 -- Loss: 0.1813420057296753
train-epoch-step: 36-562 -- Loss: 0.16298197209835052
train-epoch-step: 36-563 -- Loss: 0.1854201704263687
train-epoch-step: 36-564 -- Loss: 0.09882097691297531
train-epoch-step: 36-565 -- Loss: 0.18427184224128723
train-epoch-step: 36-566 -- Loss: 0.14684385061264038
train-epoch-step: 36-567 -- Loss: 0.21307691931724548
train-epoch-step: 36-568 -- Loss: 0.16300851106643677
train-epoch-step: 36-569 -- Loss: 0.2363322228193283
train-epoch-step: 36-570 -- Loss: 0.1669183373451233
train-epoch-step: 36-571 -- Loss: 0.21164390444755554
train-epoch-step: 36-572 -- Loss: 0.23657742142677307
train-epoch-step: 36-573 -- Loss: 0.194837749004364
train-epoch-step: 36-574 -- Loss: 0.25525060296058655
train-epoch-step: 36-575 -- Loss: 0.29614120721817017
train-epoch-step: 36-576 -- Loss: 0.11859948933124542
train-epoch-step: 36-577 -- Loss: 0.16828104853630066
train-epoch-step: 36-578 -- Loss: 0.2197350263595581
train-epoch-step: 36-579 -- Loss: 0.16393473744392395
train-epoch-step: 36-580 -- Loss: 0.17497342824935913
train-epoch-step: 36-581 -- Loss: 0.13352517783641815
train-epoch-step: 36-582 -- Loss: 0.20490336418151855
train-epoch-step: 36-583 -- Loss: 0.21027769148349762
train-epoch-step: 36-584 -- Loss: 0.16543349623680115
train-epoch-step: 36-585 -- Loss: 0.194959357380867
train-epoch-step: 36-586 -- Loss: 0.249494269490242
train-epoch-step: 36-587 -- Loss: 0.16362836956977844
train-epoch-step: 36-588 -- Loss: 0.12542834877967834
val-epoch-step: 36-589 -- Loss: 0.2008288949728012
val-epoch-step: 36-590 -- Loss: 0.153805211186409
val-epoch-step: 36-591 -- Loss: 0.22117875516414642
val-epoch-step: 36-592 -- Loss: 0.1762939989566803
val-epoch-step: 36-593 -- Loss: 0.15559107065200806
val-epoch-step: 36-594 -- Loss: 0.3165625035762787
val-epoch-step: 36-595 -- Loss: 0.20093901455402374
val-epoch-step: 36-596 -- Loss: 0.18868139386177063
val-epoch-step: 36-597 -- Loss: 0.17414696514606476
val-epoch-step: 36-598 -- Loss: 0.14969474077224731
val-epoch-step: 36-599 -- Loss: 0.1862814575433731
val-epoch-step: 36-600 -- Loss: 0.2228497564792633
val-epoch-step: 36-601 -- Loss: 0.1505853533744812
val-epoch-step: 36-602 -- Loss: 0.13943608105182648
val-epoch-step: 36-603 -- Loss: 0.20453977584838867
val-epoch-step: 36-604 -- Loss: 0.1478908360004425
val-epoch-step: 36-605 -- Loss: 0.14887547492980957
val-epoch-step: 36-606 -- Loss: 0.26213011145591736
val-epoch-step: 36-607 -- Loss: 0.12450230121612549
val-epoch-step: 36-608 -- Loss: 0.24418923258781433
val-epoch-step: 36-609 -- Loss: 0.17169398069381714
val-epoch-step: 36-610 -- Loss: 0.17844566702842712
val-epoch-step: 36-611 -- Loss: 0.18520590662956238
val-epoch-step: 36-612 -- Loss: 0.44505369663238525
val-epoch-step: 36-613 -- Loss: 0.17945334315299988
val-epoch-step: 36-614 -- Loss: 0.1660696119070053
val-epoch-step: 36-615 -- Loss: 0.17350366711616516
val-epoch-step: 36-616 -- Loss: 0.14064206182956696
val-epoch-step: 36-617 -- Loss: 0.19431966543197632
val-epoch-step: 36-618 -- Loss: 0.1714683175086975
val-epoch-step: 36-619 -- Loss: 0.206606924533844
val-epoch-step: 36-620 -- Loss: 0.14034979045391083
val-epoch-step: 36-621 -- Loss: 0.12930428981781006
val-epoch-step: 36-622 -- Loss: 0.14191874861717224
val-epoch-step: 36-623 -- Loss: 0.15131895244121552
val-epoch-step: 36-624 -- Loss: 0.14852605760097504
val-epoch-step: 36-625 -- Loss: 0.15698003768920898
val-epoch-step: 36-626 -- Loss: 0.14810152351856232
val-epoch-step: 36-627 -- Loss: 0.18288081884384155
val-epoch-step: 36-628 -- Loss: 0.6323972940444946
val-epoch-step: 36-629 -- Loss: 0.18369311094284058
val-epoch-step: 36-630 -- Loss: 0.3392934799194336
val-epoch-step: 36-631 -- Loss: 0.14462438225746155
val-epoch-step: 36-632 -- Loss: 0.2070826292037964
val-epoch-step: 36-633 -- Loss: 0.14941298961639404
val-epoch-step: 36-634 -- Loss: 0.1465095430612564
val-epoch-step: 36-635 -- Loss: 0.11810265481472015
val-epoch-step: 36-636 -- Loss: 0.16327033936977386
val-epoch-step: 36-637 -- Loss: 0.1786474734544754
val-epoch-step: 36-638 -- Loss: 0.15419217944145203
val-epoch-step: 36-639 -- Loss: 0.26039618253707886
val-epoch-step: 36-640 -- Loss: 0.2471499741077423
val-epoch-step: 36-641 -- Loss: 0.12883684039115906
val-epoch-step: 36-642 -- Loss: 0.18142901360988617
val-epoch-step: 36-643 -- Loss: 0.20699751377105713
val-epoch-step: 36-644 -- Loss: 0.16984856128692627
val-epoch-step: 36-645 -- Loss: 0.218284010887146
val-epoch-step: 36-646 -- Loss: 0.132423534989357
val-epoch-step: 36-647 -- Loss: 0.12670262157917023
val-epoch-step: 36-648 -- Loss: 0.15726125240325928
val-epoch-step: 36-649 -- Loss: 0.20047292113304138
val-epoch-step: 36-650 -- Loss: 0.25084009766578674
val-epoch-step: 36-651 -- Loss: 0.1464891880750656
val-epoch-step: 36-652 -- Loss: 0.15380990505218506
val-epoch-step: 36-653 -- Loss: 0.20914031565189362
val-epoch-step: 36-654 -- Loss: 0.1095893606543541
Epoch: 36 -- Train Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 37-0 -- Loss: 0.2274738848209381
train-epoch-step: 37-1 -- Loss: 0.14437536895275116
train-epoch-step: 37-2 -- Loss: 0.1944688856601715
train-epoch-step: 37-3 -- Loss: 0.14345556497573853
train-epoch-step: 37-4 -- Loss: 0.15722617506980896
train-epoch-step: 37-5 -- Loss: 0.18398866057395935
train-epoch-step: 37-6 -- Loss: 0.2132655531167984
train-epoch-step: 37-7 -- Loss: 0.16816353797912598
train-epoch-step: 37-8 -- Loss: 0.17415235936641693
train-epoch-step: 37-9 -- Loss: 0.22319456934928894
train-epoch-step: 37-10 -- Loss: 0.19155791401863098
train-epoch-step: 37-11 -- Loss: 0.17325326800346375
train-epoch-step: 37-12 -- Loss: 0.1511411964893341
train-epoch-step: 37-13 -- Loss: 0.1819523125886917
train-epoch-step: 37-14 -- Loss: 0.16159772872924805
train-epoch-step: 37-15 -- Loss: 0.1592579036951065
train-epoch-step: 37-16 -- Loss: 0.1648000180721283
train-epoch-step: 37-17 -- Loss: 0.21973922848701477
train-epoch-step: 37-18 -- Loss: 0.19174769520759583
train-epoch-step: 37-19 -- Loss: 0.13132132589817047
train-epoch-step: 37-20 -- Loss: 0.21248140931129456
train-epoch-step: 37-21 -- Loss: 0.24648845195770264
train-epoch-step: 37-22 -- Loss: 0.13854527473449707
train-epoch-step: 37-23 -- Loss: 0.14837007224559784
train-epoch-step: 37-24 -- Loss: 0.125674307346344
train-epoch-step: 37-25 -- Loss: 0.22359518706798553
train-epoch-step: 37-26 -- Loss: 0.18630318343639374
train-epoch-step: 37-27 -- Loss: 0.2342173159122467
train-epoch-step: 37-28 -- Loss: 0.12608137726783752
train-epoch-step: 37-29 -- Loss: 0.24409973621368408
train-epoch-step: 37-30 -- Loss: 0.11036202311515808
train-epoch-step: 37-31 -- Loss: 0.13474373519420624
train-epoch-step: 37-32 -- Loss: 0.17338654398918152
train-epoch-step: 37-33 -- Loss: 0.2766813635826111
train-epoch-step: 37-34 -- Loss: 0.16675661504268646
train-epoch-step: 37-35 -- Loss: 0.24035301804542542
train-epoch-step: 37-36 -- Loss: 0.1383916437625885
train-epoch-step: 37-37 -- Loss: 0.13941441476345062
train-epoch-step: 37-38 -- Loss: 0.18395783007144928
train-epoch-step: 37-39 -- Loss: 0.21681971848011017
train-epoch-step: 37-40 -- Loss: 0.19124391674995422
train-epoch-step: 37-41 -- Loss: 0.2149442732334137
train-epoch-step: 37-42 -- Loss: 0.14636081457138062
train-epoch-step: 37-43 -- Loss: 0.2609400749206543
train-epoch-step: 37-44 -- Loss: 0.12416552007198334
train-epoch-step: 37-45 -- Loss: 0.12125429511070251
train-epoch-step: 37-46 -- Loss: 0.1706685572862625
train-epoch-step: 37-47 -- Loss: 0.21890529990196228
train-epoch-step: 37-48 -- Loss: 0.15217387676239014
train-epoch-step: 37-49 -- Loss: 0.22842809557914734
train-epoch-step: 37-50 -- Loss: 0.10731075704097748
train-epoch-step: 37-51 -- Loss: 0.1890600323677063
train-epoch-step: 37-52 -- Loss: 0.15681079030036926
train-epoch-step: 37-53 -- Loss: 0.21133700013160706
train-epoch-step: 37-54 -- Loss: 0.28365764021873474
train-epoch-step: 37-55 -- Loss: 0.16906355321407318
train-epoch-step: 37-56 -- Loss: 0.1765180230140686
train-epoch-step: 37-57 -- Loss: 0.2352808713912964
train-epoch-step: 37-58 -- Loss: 0.28182533383369446
train-epoch-step: 37-59 -- Loss: 0.23454980552196503
train-epoch-step: 37-60 -- Loss: 0.13210073113441467
train-epoch-step: 37-61 -- Loss: 0.20946204662322998
train-epoch-step: 37-62 -- Loss: 0.18037907779216766
train-epoch-step: 37-63 -- Loss: 0.13524878025054932
train-epoch-step: 37-64 -- Loss: 0.14302870631217957
train-epoch-step: 37-65 -- Loss: 0.17920437455177307
train-epoch-step: 37-66 -- Loss: 0.11054281145334244
train-epoch-step: 37-67 -- Loss: 0.12412261217832565
train-epoch-step: 37-68 -- Loss: 0.21942684054374695
train-epoch-step: 37-69 -- Loss: 0.1218402311205864
train-epoch-step: 37-70 -- Loss: 0.22359177470207214
train-epoch-step: 37-71 -- Loss: 0.2540495991706848
train-epoch-step: 37-72 -- Loss: 0.1748296320438385
train-epoch-step: 37-73 -- Loss: 0.21280957758426666
train-epoch-step: 37-74 -- Loss: 0.09811997413635254
train-epoch-step: 37-75 -- Loss: 0.12648247182369232
train-epoch-step: 37-76 -- Loss: 0.14447236061096191
train-epoch-step: 37-77 -- Loss: 0.22844940423965454
train-epoch-step: 37-78 -- Loss: 0.25335776805877686
train-epoch-step: 37-79 -- Loss: 0.18986494839191437
train-epoch-step: 37-80 -- Loss: 0.26199132204055786
train-epoch-step: 37-81 -- Loss: 0.12801493704319
train-epoch-step: 37-82 -- Loss: 0.25096529722213745
train-epoch-step: 37-83 -- Loss: 0.1784944236278534
train-epoch-step: 37-84 -- Loss: 0.1887325793504715
train-epoch-step: 37-85 -- Loss: 0.17401883006095886
train-epoch-step: 37-86 -- Loss: 0.11820760369300842
train-epoch-step: 37-87 -- Loss: 0.20519845187664032
train-epoch-step: 37-88 -- Loss: 0.13884682953357697
train-epoch-step: 37-89 -- Loss: 0.18190687894821167
train-epoch-step: 37-90 -- Loss: 0.19124242663383484
train-epoch-step: 37-91 -- Loss: 0.2470502406358719
train-epoch-step: 37-92 -- Loss: 0.15636633336544037
train-epoch-step: 37-93 -- Loss: 0.1715599149465561
train-epoch-step: 37-94 -- Loss: 0.2194637954235077
train-epoch-step: 37-95 -- Loss: 0.18735656142234802
train-epoch-step: 37-96 -- Loss: 0.21337059140205383
train-epoch-step: 37-97 -- Loss: 0.17852546274662018
train-epoch-step: 37-98 -- Loss: 0.15675093233585358
train-epoch-step: 37-99 -- Loss: 0.18002185225486755
train-epoch-step: 37-100 -- Loss: 0.18713617324829102
train-epoch-step: 37-101 -- Loss: 0.26332440972328186
train-epoch-step: 37-102 -- Loss: 0.21748948097229004
train-epoch-step: 37-103 -- Loss: 0.1821262389421463
train-epoch-step: 37-104 -- Loss: 0.15017274022102356
train-epoch-step: 37-105 -- Loss: 0.26690903306007385
train-epoch-step: 37-106 -- Loss: 0.17448784410953522
train-epoch-step: 37-107 -- Loss: 0.18623408675193787
train-epoch-step: 37-108 -- Loss: 0.19395722448825836
train-epoch-step: 37-109 -- Loss: 0.1434026062488556
train-epoch-step: 37-110 -- Loss: 0.1792626529932022
train-epoch-step: 37-111 -- Loss: 0.17529550194740295
train-epoch-step: 37-112 -- Loss: 0.1683310717344284
train-epoch-step: 37-113 -- Loss: 0.15866930782794952
train-epoch-step: 37-114 -- Loss: 0.19716876745224
train-epoch-step: 37-115 -- Loss: 0.1578872948884964
train-epoch-step: 37-116 -- Loss: 0.1408887356519699
train-epoch-step: 37-117 -- Loss: 0.12802796065807343
train-epoch-step: 37-118 -- Loss: 0.1915210485458374
train-epoch-step: 37-119 -- Loss: 0.15292638540267944
train-epoch-step: 37-120 -- Loss: 0.25391557812690735
train-epoch-step: 37-121 -- Loss: 0.2320915013551712
train-epoch-step: 37-122 -- Loss: 0.21668647229671478
train-epoch-step: 37-123 -- Loss: 0.2068609744310379
train-epoch-step: 37-124 -- Loss: 0.12464798241853714
train-epoch-step: 37-125 -- Loss: 0.15527468919754028
train-epoch-step: 37-126 -- Loss: 0.2367512285709381
train-epoch-step: 37-127 -- Loss: 0.17236703634262085
train-epoch-step: 37-128 -- Loss: 0.1724797785282135
train-epoch-step: 37-129 -- Loss: 0.14024938642978668
train-epoch-step: 37-130 -- Loss: 0.1939697563648224
train-epoch-step: 37-131 -- Loss: 0.13572797179222107
train-epoch-step: 37-132 -- Loss: 0.18410667777061462
train-epoch-step: 37-133 -- Loss: 0.11632981896400452
train-epoch-step: 37-134 -- Loss: 0.1956273913383484
train-epoch-step: 37-135 -- Loss: 0.13834381103515625
train-epoch-step: 37-136 -- Loss: 0.12643985450267792
train-epoch-step: 37-137 -- Loss: 0.23965036869049072
train-epoch-step: 37-138 -- Loss: 0.2614865303039551
train-epoch-step: 37-139 -- Loss: 0.12890246510505676
train-epoch-step: 37-140 -- Loss: 0.20383203029632568
train-epoch-step: 37-141 -- Loss: 0.2257148176431656
train-epoch-step: 37-142 -- Loss: 0.19898605346679688
train-epoch-step: 37-143 -- Loss: 0.17380250990390778
train-epoch-step: 37-144 -- Loss: 0.19497710466384888
train-epoch-step: 37-145 -- Loss: 0.14454928040504456
train-epoch-step: 37-146 -- Loss: 0.17760667204856873
train-epoch-step: 37-147 -- Loss: 0.16872327029705048
train-epoch-step: 37-148 -- Loss: 0.15657904744148254
train-epoch-step: 37-149 -- Loss: 0.11651885509490967
train-epoch-step: 37-150 -- Loss: 0.18296591937541962
train-epoch-step: 37-151 -- Loss: 0.19551369547843933
train-epoch-step: 37-152 -- Loss: 0.18394409120082855
train-epoch-step: 37-153 -- Loss: 0.26324358582496643
train-epoch-step: 37-154 -- Loss: 0.12972106039524078
train-epoch-step: 37-155 -- Loss: 0.13765183091163635
train-epoch-step: 37-156 -- Loss: 0.11694426089525223
train-epoch-step: 37-157 -- Loss: 0.1635364145040512
train-epoch-step: 37-158 -- Loss: 0.1669016182422638
train-epoch-step: 37-159 -- Loss: 0.1746206283569336
train-epoch-step: 37-160 -- Loss: 0.21961958706378937
train-epoch-step: 37-161 -- Loss: 0.21019072830677032
train-epoch-step: 37-162 -- Loss: 0.21367375552654266
train-epoch-step: 37-163 -- Loss: 0.1863740235567093
train-epoch-step: 37-164 -- Loss: 0.19173818826675415
train-epoch-step: 37-165 -- Loss: 0.1622442901134491
train-epoch-step: 37-166 -- Loss: 0.12421054393053055
train-epoch-step: 37-167 -- Loss: 0.12359635531902313
train-epoch-step: 37-168 -- Loss: 0.2010999619960785
train-epoch-step: 37-169 -- Loss: 0.14007730782032013
train-epoch-step: 37-170 -- Loss: 0.19922985136508942
train-epoch-step: 37-171 -- Loss: 0.14426426589488983
train-epoch-step: 37-172 -- Loss: 0.261135458946228
train-epoch-step: 37-173 -- Loss: 0.1358989179134369
train-epoch-step: 37-174 -- Loss: 0.25413909554481506
train-epoch-step: 37-175 -- Loss: 0.18422435224056244
train-epoch-step: 37-176 -- Loss: 0.13951346278190613
train-epoch-step: 37-177 -- Loss: 0.17902901768684387
train-epoch-step: 37-178 -- Loss: 0.17674803733825684
train-epoch-step: 37-179 -- Loss: 0.15504619479179382
train-epoch-step: 37-180 -- Loss: 0.15205666422843933
train-epoch-step: 37-181 -- Loss: 0.17516127228736877
train-epoch-step: 37-182 -- Loss: 0.17865130305290222
train-epoch-step: 37-183 -- Loss: 0.2678910195827484
train-epoch-step: 37-184 -- Loss: 0.13936859369277954
train-epoch-step: 37-185 -- Loss: 0.1404174268245697
train-epoch-step: 37-186 -- Loss: 0.19393685460090637
train-epoch-step: 37-187 -- Loss: 0.21052688360214233
train-epoch-step: 37-188 -- Loss: 0.17433007061481476
train-epoch-step: 37-189 -- Loss: 0.10724970698356628
train-epoch-step: 37-190 -- Loss: 0.1851411908864975
train-epoch-step: 37-191 -- Loss: 0.15971897542476654
train-epoch-step: 37-192 -- Loss: 0.23167908191680908
train-epoch-step: 37-193 -- Loss: 0.23238927125930786
train-epoch-step: 37-194 -- Loss: 0.1814306378364563
train-epoch-step: 37-195 -- Loss: 0.16714759171009064
train-epoch-step: 37-196 -- Loss: 0.1702306568622589
train-epoch-step: 37-197 -- Loss: 0.1286763697862625
train-epoch-step: 37-198 -- Loss: 0.1270751804113388
train-epoch-step: 37-199 -- Loss: 0.14804880321025848
train-epoch-step: 37-200 -- Loss: 0.12852928042411804
train-epoch-step: 37-201 -- Loss: 0.19079098105430603
train-epoch-step: 37-202 -- Loss: 0.1372302770614624
train-epoch-step: 37-203 -- Loss: 0.1713092178106308
train-epoch-step: 37-204 -- Loss: 0.13536623120307922
train-epoch-step: 37-205 -- Loss: 0.18373984098434448
train-epoch-step: 37-206 -- Loss: 0.19825580716133118
train-epoch-step: 37-207 -- Loss: 0.1334238350391388
train-epoch-step: 37-208 -- Loss: 0.17728112637996674
train-epoch-step: 37-209 -- Loss: 0.14415906369686127
train-epoch-step: 37-210 -- Loss: 0.13300803303718567
train-epoch-step: 37-211 -- Loss: 0.21411168575286865
train-epoch-step: 37-212 -- Loss: 0.19934946298599243
train-epoch-step: 37-213 -- Loss: 0.12733934819698334
train-epoch-step: 37-214 -- Loss: 0.1487046331167221
train-epoch-step: 37-215 -- Loss: 0.13031132519245148
train-epoch-step: 37-216 -- Loss: 0.19924600422382355
train-epoch-step: 37-217 -- Loss: 0.21080438792705536
train-epoch-step: 37-218 -- Loss: 0.14340636134147644
train-epoch-step: 37-219 -- Loss: 0.17653504014015198
train-epoch-step: 37-220 -- Loss: 0.12995532155036926
train-epoch-step: 37-221 -- Loss: 0.2022552341222763
train-epoch-step: 37-222 -- Loss: 0.1161596029996872
train-epoch-step: 37-223 -- Loss: 0.17098665237426758
train-epoch-step: 37-224 -- Loss: 0.18751797080039978
train-epoch-step: 37-225 -- Loss: 0.2785031795501709
train-epoch-step: 37-226 -- Loss: 0.20791590213775635
train-epoch-step: 37-227 -- Loss: 0.21904675662517548
train-epoch-step: 37-228 -- Loss: 0.17942842841148376
train-epoch-step: 37-229 -- Loss: 0.17754483222961426
train-epoch-step: 37-230 -- Loss: 0.16135969758033752
train-epoch-step: 37-231 -- Loss: 0.15800811350345612
train-epoch-step: 37-232 -- Loss: 0.18483252823352814
train-epoch-step: 37-233 -- Loss: 0.08541690558195114
train-epoch-step: 37-234 -- Loss: 0.1816176176071167
train-epoch-step: 37-235 -- Loss: 0.14828762412071228
train-epoch-step: 37-236 -- Loss: 0.18102999031543732
train-epoch-step: 37-237 -- Loss: 0.23758628964424133
train-epoch-step: 37-238 -- Loss: 0.15671707689762115
train-epoch-step: 37-239 -- Loss: 0.12404601275920868
train-epoch-step: 37-240 -- Loss: 0.21897569298744202
train-epoch-step: 37-241 -- Loss: 0.1513298898935318
train-epoch-step: 37-242 -- Loss: 0.21836735308170319
train-epoch-step: 37-243 -- Loss: 0.2325930893421173
train-epoch-step: 37-244 -- Loss: 0.2027900069952011
train-epoch-step: 37-245 -- Loss: 0.20198845863342285
train-epoch-step: 37-246 -- Loss: 0.21975396573543549
train-epoch-step: 37-247 -- Loss: 0.21072819828987122
train-epoch-step: 37-248 -- Loss: 0.18069219589233398
train-epoch-step: 37-249 -- Loss: 0.13669881224632263
train-epoch-step: 37-250 -- Loss: 0.1944016069173813
train-epoch-step: 37-251 -- Loss: 0.1035890132188797
train-epoch-step: 37-252 -- Loss: 0.19612152874469757
train-epoch-step: 37-253 -- Loss: 0.13602358102798462
train-epoch-step: 37-254 -- Loss: 0.21057166159152985
train-epoch-step: 37-255 -- Loss: 0.14605826139450073
train-epoch-step: 37-256 -- Loss: 0.14819057285785675
train-epoch-step: 37-257 -- Loss: 0.18981166183948517
train-epoch-step: 37-258 -- Loss: 0.14331643283367157
train-epoch-step: 37-259 -- Loss: 0.11353737860918045
train-epoch-step: 37-260 -- Loss: 0.20146039128303528
train-epoch-step: 37-261 -- Loss: 0.17144180834293365
train-epoch-step: 37-262 -- Loss: 0.28234127163887024
train-epoch-step: 37-263 -- Loss: 0.20191191136837006
train-epoch-step: 37-264 -- Loss: 0.1741376370191574
train-epoch-step: 37-265 -- Loss: 0.11980295181274414
train-epoch-step: 37-266 -- Loss: 0.15434323251247406
train-epoch-step: 37-267 -- Loss: 0.12627319991588593
train-epoch-step: 37-268 -- Loss: 0.11443168669939041
train-epoch-step: 37-269 -- Loss: 0.17406781017780304
train-epoch-step: 37-270 -- Loss: 0.11005458235740662
train-epoch-step: 37-271 -- Loss: 0.15069489181041718
train-epoch-step: 37-272 -- Loss: 0.11383665353059769
train-epoch-step: 37-273 -- Loss: 0.12449303269386292
train-epoch-step: 37-274 -- Loss: 0.178656667470932
train-epoch-step: 37-275 -- Loss: 0.18692940473556519
train-epoch-step: 37-276 -- Loss: 0.16297589242458344
train-epoch-step: 37-277 -- Loss: 0.15913616120815277
train-epoch-step: 37-278 -- Loss: 0.13864493370056152
train-epoch-step: 37-279 -- Loss: 0.1399330049753189
train-epoch-step: 37-280 -- Loss: 0.21734540164470673
train-epoch-step: 37-281 -- Loss: 0.17855338752269745
train-epoch-step: 37-282 -- Loss: 0.13816972076892853
train-epoch-step: 37-283 -- Loss: 0.11668255925178528
train-epoch-step: 37-284 -- Loss: 0.1426626741886139
train-epoch-step: 37-285 -- Loss: 0.20321130752563477
train-epoch-step: 37-286 -- Loss: 0.15396228432655334
train-epoch-step: 37-287 -- Loss: 0.20057901740074158
train-epoch-step: 37-288 -- Loss: 0.09320970624685287
train-epoch-step: 37-289 -- Loss: 0.13147272169589996
train-epoch-step: 37-290 -- Loss: 0.1861339658498764
train-epoch-step: 37-291 -- Loss: 0.11544585973024368
train-epoch-step: 37-292 -- Loss: 0.15962044894695282
train-epoch-step: 37-293 -- Loss: 0.13765636086463928
train-epoch-step: 37-294 -- Loss: 0.16388747096061707
train-epoch-step: 37-295 -- Loss: 0.26369190216064453
train-epoch-step: 37-296 -- Loss: 0.16212508082389832
train-epoch-step: 37-297 -- Loss: 0.17139266431331635
train-epoch-step: 37-298 -- Loss: 0.2521906793117523
train-epoch-step: 37-299 -- Loss: 0.14514966309070587
train-epoch-step: 37-300 -- Loss: 0.17049923539161682
train-epoch-step: 37-301 -- Loss: 0.17846980690956116
train-epoch-step: 37-302 -- Loss: 0.2239951491355896
train-epoch-step: 37-303 -- Loss: 0.20867249369621277
train-epoch-step: 37-304 -- Loss: 0.13218069076538086
train-epoch-step: 37-305 -- Loss: 0.1439419537782669
train-epoch-step: 37-306 -- Loss: 0.21047355234622955
train-epoch-step: 37-307 -- Loss: 0.1634436398744583
train-epoch-step: 37-308 -- Loss: 0.2196095734834671
train-epoch-step: 37-309 -- Loss: 0.16189348697662354
train-epoch-step: 37-310 -- Loss: 0.163946270942688
train-epoch-step: 37-311 -- Loss: 0.1598089039325714
train-epoch-step: 37-312 -- Loss: 0.2001556158065796
train-epoch-step: 37-313 -- Loss: 0.10066111385822296
train-epoch-step: 37-314 -- Loss: 0.1951867938041687
train-epoch-step: 37-315 -- Loss: 0.17238874733448029
train-epoch-step: 37-316 -- Loss: 0.15200553834438324
train-epoch-step: 37-317 -- Loss: 0.13997916877269745
train-epoch-step: 37-318 -- Loss: 0.16117984056472778
train-epoch-step: 37-319 -- Loss: 0.20367449522018433
train-epoch-step: 37-320 -- Loss: 0.11699801683425903
train-epoch-step: 37-321 -- Loss: 0.13073015213012695
train-epoch-step: 37-322 -- Loss: 0.21898192167282104
train-epoch-step: 37-323 -- Loss: 0.15797308087348938
train-epoch-step: 37-324 -- Loss: 0.2556135058403015
train-epoch-step: 37-325 -- Loss: 0.16070814430713654
train-epoch-step: 37-326 -- Loss: 0.17033156752586365
train-epoch-step: 37-327 -- Loss: 0.2018803507089615
train-epoch-step: 37-328 -- Loss: 0.20008288323879242
train-epoch-step: 37-329 -- Loss: 0.3458501994609833
train-epoch-step: 37-330 -- Loss: 0.3702733814716339
train-epoch-step: 37-331 -- Loss: 0.2083246111869812
train-epoch-step: 37-332 -- Loss: 0.09917605668306351
train-epoch-step: 37-333 -- Loss: 0.18409207463264465
train-epoch-step: 37-334 -- Loss: 0.15322880446910858
train-epoch-step: 37-335 -- Loss: 0.17872241139411926
train-epoch-step: 37-336 -- Loss: 0.15247279405593872
train-epoch-step: 37-337 -- Loss: 0.2091197371482849
train-epoch-step: 37-338 -- Loss: 0.16061139106750488
train-epoch-step: 37-339 -- Loss: 0.14648579061031342
train-epoch-step: 37-340 -- Loss: 0.1936621516942978
train-epoch-step: 37-341 -- Loss: 0.13759464025497437
train-epoch-step: 37-342 -- Loss: 0.16406729817390442
train-epoch-step: 37-343 -- Loss: 0.1520465761423111
train-epoch-step: 37-344 -- Loss: 0.17233486473560333
train-epoch-step: 37-345 -- Loss: 0.12679177522659302
train-epoch-step: 37-346 -- Loss: 0.20461344718933105
train-epoch-step: 37-347 -- Loss: 0.15125562250614166
train-epoch-step: 37-348 -- Loss: 0.2043546885251999
train-epoch-step: 37-349 -- Loss: 0.2036958783864975
train-epoch-step: 37-350 -- Loss: 0.25446879863739014
train-epoch-step: 37-351 -- Loss: 0.1938214898109436
train-epoch-step: 37-352 -- Loss: 0.12672334909439087
train-epoch-step: 37-353 -- Loss: 0.19352097809314728
train-epoch-step: 37-354 -- Loss: 0.2822781801223755
train-epoch-step: 37-355 -- Loss: 0.11508640646934509
train-epoch-step: 37-356 -- Loss: 0.11909706890583038
train-epoch-step: 37-357 -- Loss: 0.19244743883609772
train-epoch-step: 37-358 -- Loss: 0.18473947048187256
train-epoch-step: 37-359 -- Loss: 0.140000119805336
train-epoch-step: 37-360 -- Loss: 0.12674438953399658
train-epoch-step: 37-361 -- Loss: 0.23532523214817047
train-epoch-step: 37-362 -- Loss: 0.16933783888816833
train-epoch-step: 37-363 -- Loss: 0.1069055050611496
train-epoch-step: 37-364 -- Loss: 0.18237781524658203
train-epoch-step: 37-365 -- Loss: 0.17226096987724304
train-epoch-step: 37-366 -- Loss: 0.1968386024236679
train-epoch-step: 37-367 -- Loss: 0.23415392637252808
train-epoch-step: 37-368 -- Loss: 0.19904646277427673
train-epoch-step: 37-369 -- Loss: 0.2725856900215149
train-epoch-step: 37-370 -- Loss: 0.12309102714061737
train-epoch-step: 37-371 -- Loss: 0.12043285369873047
train-epoch-step: 37-372 -- Loss: 0.1473575085401535
train-epoch-step: 37-373 -- Loss: 0.19181305170059204
train-epoch-step: 37-374 -- Loss: 0.15398645401000977
train-epoch-step: 37-375 -- Loss: 0.2662671208381653
train-epoch-step: 37-376 -- Loss: 0.15625956654548645
train-epoch-step: 37-377 -- Loss: 0.2304854393005371
train-epoch-step: 37-378 -- Loss: 0.19978731870651245
train-epoch-step: 37-379 -- Loss: 0.1193707212805748
train-epoch-step: 37-380 -- Loss: 0.09101486951112747
train-epoch-step: 37-381 -- Loss: 0.242174431681633
train-epoch-step: 37-382 -- Loss: 0.22849588096141815
train-epoch-step: 37-383 -- Loss: 0.17313241958618164
train-epoch-step: 37-384 -- Loss: 0.21742121875286102
train-epoch-step: 37-385 -- Loss: 0.18860605359077454
train-epoch-step: 37-386 -- Loss: 0.18469436466693878
train-epoch-step: 37-387 -- Loss: 0.19905661046504974
train-epoch-step: 37-388 -- Loss: 0.18813052773475647
train-epoch-step: 37-389 -- Loss: 0.16424454748630524
train-epoch-step: 37-390 -- Loss: 0.15030738711357117
train-epoch-step: 37-391 -- Loss: 0.14336028695106506
train-epoch-step: 37-392 -- Loss: 0.18392318487167358
train-epoch-step: 37-393 -- Loss: 0.15308885276317596
train-epoch-step: 37-394 -- Loss: 0.20718152821063995
train-epoch-step: 37-395 -- Loss: 0.15808890759944916
train-epoch-step: 37-396 -- Loss: 0.12917713820934296
train-epoch-step: 37-397 -- Loss: 0.12378058582544327
train-epoch-step: 37-398 -- Loss: 0.1965840756893158
train-epoch-step: 37-399 -- Loss: 0.17471195757389069
train-epoch-step: 37-400 -- Loss: 0.27576667070388794
train-epoch-step: 37-401 -- Loss: 0.1194763332605362
train-epoch-step: 37-402 -- Loss: 0.25357842445373535
train-epoch-step: 37-403 -- Loss: 0.15965336561203003
train-epoch-step: 37-404 -- Loss: 0.13572868704795837
train-epoch-step: 37-405 -- Loss: 0.14039383828639984
train-epoch-step: 37-406 -- Loss: 0.16862092912197113
train-epoch-step: 37-407 -- Loss: 0.1136048287153244
train-epoch-step: 37-408 -- Loss: 0.16139522194862366
train-epoch-step: 37-409 -- Loss: 0.16881561279296875
train-epoch-step: 37-410 -- Loss: 0.17379671335220337
train-epoch-step: 37-411 -- Loss: 0.1995493471622467
train-epoch-step: 37-412 -- Loss: 0.13127656280994415
train-epoch-step: 37-413 -- Loss: 0.14821584522724152
train-epoch-step: 37-414 -- Loss: 0.1330854892730713
train-epoch-step: 37-415 -- Loss: 0.13502137362957
train-epoch-step: 37-416 -- Loss: 0.2646598815917969
train-epoch-step: 37-417 -- Loss: 0.18921270966529846
train-epoch-step: 37-418 -- Loss: 0.22958752512931824
train-epoch-step: 37-419 -- Loss: 0.1650642454624176
train-epoch-step: 37-420 -- Loss: 0.14928388595581055
train-epoch-step: 37-421 -- Loss: 0.1753321886062622
train-epoch-step: 37-422 -- Loss: 0.14685678482055664
train-epoch-step: 37-423 -- Loss: 0.17655058205127716
train-epoch-step: 37-424 -- Loss: 0.13805122673511505
train-epoch-step: 37-425 -- Loss: 0.18093420565128326
train-epoch-step: 37-426 -- Loss: 0.16151903569698334
train-epoch-step: 37-427 -- Loss: 0.11914858222007751
train-epoch-step: 37-428 -- Loss: 0.19188261032104492
train-epoch-step: 37-429 -- Loss: 0.17509855329990387
train-epoch-step: 37-430 -- Loss: 0.13621366024017334
train-epoch-step: 37-431 -- Loss: 0.16465288400650024
train-epoch-step: 37-432 -- Loss: 0.236817866563797
train-epoch-step: 37-433 -- Loss: 0.13380907475948334
train-epoch-step: 37-434 -- Loss: 0.12981539964675903
train-epoch-step: 37-435 -- Loss: 0.15564708411693573
train-epoch-step: 37-436 -- Loss: 0.15710929036140442
train-epoch-step: 37-437 -- Loss: 0.13314026594161987
train-epoch-step: 37-438 -- Loss: 0.16751067340373993
train-epoch-step: 37-439 -- Loss: 0.257289320230484
train-epoch-step: 37-440 -- Loss: 0.13172635436058044
train-epoch-step: 37-441 -- Loss: 0.2004132717847824
train-epoch-step: 37-442 -- Loss: 0.1721315085887909
train-epoch-step: 37-443 -- Loss: 0.1512022614479065
train-epoch-step: 37-444 -- Loss: 0.17133910953998566
train-epoch-step: 37-445 -- Loss: 0.17691129446029663
train-epoch-step: 37-446 -- Loss: 0.15304812788963318
train-epoch-step: 37-447 -- Loss: 0.19125285744667053
train-epoch-step: 37-448 -- Loss: 0.22753629088401794
train-epoch-step: 37-449 -- Loss: 0.19242939352989197
train-epoch-step: 37-450 -- Loss: 0.17862831056118011
train-epoch-step: 37-451 -- Loss: 0.1416371911764145
train-epoch-step: 37-452 -- Loss: 0.12639163434505463
train-epoch-step: 37-453 -- Loss: 0.090760737657547
train-epoch-step: 37-454 -- Loss: 0.22231525182724
train-epoch-step: 37-455 -- Loss: 0.12053682655096054
train-epoch-step: 37-456 -- Loss: 0.12200799584388733
train-epoch-step: 37-457 -- Loss: 0.21550095081329346
train-epoch-step: 37-458 -- Loss: 0.14883553981781006
train-epoch-step: 37-459 -- Loss: 0.21028074622154236
train-epoch-step: 37-460 -- Loss: 0.1232963502407074
train-epoch-step: 37-461 -- Loss: 0.13301001489162445
train-epoch-step: 37-462 -- Loss: 0.15887311100959778
train-epoch-step: 37-463 -- Loss: 0.13368529081344604
train-epoch-step: 37-464 -- Loss: 0.16186681389808655
train-epoch-step: 37-465 -- Loss: 0.23357397317886353
train-epoch-step: 37-466 -- Loss: 0.19627554714679718
train-epoch-step: 37-467 -- Loss: 0.11229217052459717
train-epoch-step: 37-468 -- Loss: 0.16342216730117798
train-epoch-step: 37-469 -- Loss: 0.20719298720359802
train-epoch-step: 37-470 -- Loss: 0.17344629764556885
train-epoch-step: 37-471 -- Loss: 0.15760745108127594
train-epoch-step: 37-472 -- Loss: 0.1566944420337677
train-epoch-step: 37-473 -- Loss: 0.14873123168945312
train-epoch-step: 37-474 -- Loss: 0.11921902000904083
train-epoch-step: 37-475 -- Loss: 0.10683875530958176
train-epoch-step: 37-476 -- Loss: 0.19938407838344574
train-epoch-step: 37-477 -- Loss: 0.196945458650589
train-epoch-step: 37-478 -- Loss: 0.1951519101858139
train-epoch-step: 37-479 -- Loss: 0.1378355622291565
train-epoch-step: 37-480 -- Loss: 0.18939971923828125
train-epoch-step: 37-481 -- Loss: 0.27607861161231995
train-epoch-step: 37-482 -- Loss: 0.24967432022094727
train-epoch-step: 37-483 -- Loss: 0.1777619570493698
train-epoch-step: 37-484 -- Loss: 0.20578789710998535
train-epoch-step: 37-485 -- Loss: 0.12180527299642563
train-epoch-step: 37-486 -- Loss: 0.24609296023845673
train-epoch-step: 37-487 -- Loss: 0.25806695222854614
train-epoch-step: 37-488 -- Loss: 0.18836919963359833
train-epoch-step: 37-489 -- Loss: 0.21365612745285034
train-epoch-step: 37-490 -- Loss: 0.13788479566574097
train-epoch-step: 37-491 -- Loss: 0.13518257439136505
train-epoch-step: 37-492 -- Loss: 0.128066748380661
train-epoch-step: 37-493 -- Loss: 0.22277496755123138
train-epoch-step: 37-494 -- Loss: 0.25458231568336487
train-epoch-step: 37-495 -- Loss: 0.20268097519874573
train-epoch-step: 37-496 -- Loss: 0.13897205889225006
train-epoch-step: 37-497 -- Loss: 0.18861791491508484
train-epoch-step: 37-498 -- Loss: 0.14339804649353027
train-epoch-step: 37-499 -- Loss: 0.17459827661514282
train-epoch-step: 37-500 -- Loss: 0.15805163979530334
train-epoch-step: 37-501 -- Loss: 0.2156088650226593
train-epoch-step: 37-502 -- Loss: 0.1576848328113556
train-epoch-step: 37-503 -- Loss: 0.22287006676197052
train-epoch-step: 37-504 -- Loss: 0.1269199550151825
train-epoch-step: 37-505 -- Loss: 0.17138713598251343
train-epoch-step: 37-506 -- Loss: 0.11754779517650604
train-epoch-step: 37-507 -- Loss: 0.18040481209754944
train-epoch-step: 37-508 -- Loss: 0.17566658556461334
train-epoch-step: 37-509 -- Loss: 0.16488759219646454
train-epoch-step: 37-510 -- Loss: 0.12594683468341827
train-epoch-step: 37-511 -- Loss: 0.21341516077518463
train-epoch-step: 37-512 -- Loss: 0.17522481083869934
train-epoch-step: 37-513 -- Loss: 0.18985265493392944
train-epoch-step: 37-514 -- Loss: 0.14852744340896606
train-epoch-step: 37-515 -- Loss: 0.1521485596895218
train-epoch-step: 37-516 -- Loss: 0.16651393473148346
train-epoch-step: 37-517 -- Loss: 0.1730533093214035
train-epoch-step: 37-518 -- Loss: 0.13699007034301758
train-epoch-step: 37-519 -- Loss: 0.13983160257339478
train-epoch-step: 37-520 -- Loss: 0.18481892347335815
train-epoch-step: 37-521 -- Loss: 0.22521132230758667
train-epoch-step: 37-522 -- Loss: 0.1710265427827835
train-epoch-step: 37-523 -- Loss: 0.15804500877857208
train-epoch-step: 37-524 -- Loss: 0.17059309780597687
train-epoch-step: 37-525 -- Loss: 0.19138666987419128
train-epoch-step: 37-526 -- Loss: 0.1282273530960083
train-epoch-step: 37-527 -- Loss: 0.1482890546321869
train-epoch-step: 37-528 -- Loss: 0.1539199948310852
train-epoch-step: 37-529 -- Loss: 0.17581626772880554
train-epoch-step: 37-530 -- Loss: 0.17588083446025848
train-epoch-step: 37-531 -- Loss: 0.19584494829177856
train-epoch-step: 37-532 -- Loss: 0.16583430767059326
train-epoch-step: 37-533 -- Loss: 0.17345166206359863
train-epoch-step: 37-534 -- Loss: 0.12770000100135803
train-epoch-step: 37-535 -- Loss: 0.24825012683868408
train-epoch-step: 37-536 -- Loss: 0.17090150713920593
train-epoch-step: 37-537 -- Loss: 0.15626922249794006
train-epoch-step: 37-538 -- Loss: 0.10721547156572342
train-epoch-step: 37-539 -- Loss: 0.17657259106636047
train-epoch-step: 37-540 -- Loss: 0.13996505737304688
train-epoch-step: 37-541 -- Loss: 0.21035155653953552
train-epoch-step: 37-542 -- Loss: 0.2142154574394226
train-epoch-step: 37-543 -- Loss: 0.16717402637004852
train-epoch-step: 37-544 -- Loss: 0.22519132494926453
train-epoch-step: 37-545 -- Loss: 0.19047681987285614
train-epoch-step: 37-546 -- Loss: 0.20223745703697205
train-epoch-step: 37-547 -- Loss: 0.18196609616279602
train-epoch-step: 37-548 -- Loss: 0.0959896594285965
train-epoch-step: 37-549 -- Loss: 0.15364551544189453
train-epoch-step: 37-550 -- Loss: 0.19912955164909363
train-epoch-step: 37-551 -- Loss: 0.15535414218902588
train-epoch-step: 37-552 -- Loss: 0.12333647161722183
train-epoch-step: 37-553 -- Loss: 0.18685895204544067
train-epoch-step: 37-554 -- Loss: 0.18881547451019287
train-epoch-step: 37-555 -- Loss: 0.21765178442001343
train-epoch-step: 37-556 -- Loss: 0.15410733222961426
train-epoch-step: 37-557 -- Loss: 0.23604673147201538
train-epoch-step: 37-558 -- Loss: 0.22697338461875916
train-epoch-step: 37-559 -- Loss: 0.13436728715896606
train-epoch-step: 37-560 -- Loss: 0.2029811441898346
train-epoch-step: 37-561 -- Loss: 0.17304714024066925
train-epoch-step: 37-562 -- Loss: 0.1700129359960556
train-epoch-step: 37-563 -- Loss: 0.18205326795578003
train-epoch-step: 37-564 -- Loss: 0.0984424501657486
train-epoch-step: 37-565 -- Loss: 0.1816631406545639
train-epoch-step: 37-566 -- Loss: 0.15258561074733734
train-epoch-step: 37-567 -- Loss: 0.2150142639875412
train-epoch-step: 37-568 -- Loss: 0.16275352239608765
train-epoch-step: 37-569 -- Loss: 0.2457549124956131
train-epoch-step: 37-570 -- Loss: 0.1872735321521759
train-epoch-step: 37-571 -- Loss: 0.2153104692697525
train-epoch-step: 37-572 -- Loss: 0.23554925620555878
train-epoch-step: 37-573 -- Loss: 0.19941386580467224
train-epoch-step: 37-574 -- Loss: 0.24623149633407593
train-epoch-step: 37-575 -- Loss: 0.287767618894577
train-epoch-step: 37-576 -- Loss: 0.11651880294084549
train-epoch-step: 37-577 -- Loss: 0.16417552530765533
train-epoch-step: 37-578 -- Loss: 0.213373064994812
train-epoch-step: 37-579 -- Loss: 0.1653716266155243
train-epoch-step: 37-580 -- Loss: 0.1735847294330597
train-epoch-step: 37-581 -- Loss: 0.13919252157211304
train-epoch-step: 37-582 -- Loss: 0.20415452122688293
train-epoch-step: 37-583 -- Loss: 0.21364092826843262
train-epoch-step: 37-584 -- Loss: 0.16205114126205444
train-epoch-step: 37-585 -- Loss: 0.19183531403541565
train-epoch-step: 37-586 -- Loss: 0.25386694073677063
train-epoch-step: 37-587 -- Loss: 0.16048714518547058
train-epoch-step: 37-588 -- Loss: 0.12743374705314636
val-epoch-step: 37-589 -- Loss: 0.20213495194911957
val-epoch-step: 37-590 -- Loss: 0.1555739939212799
val-epoch-step: 37-591 -- Loss: 0.222732812166214
val-epoch-step: 37-592 -- Loss: 0.1785198450088501
val-epoch-step: 37-593 -- Loss: 0.16529040038585663
val-epoch-step: 37-594 -- Loss: 0.4000731110572815
val-epoch-step: 37-595 -- Loss: 0.19018691778182983
val-epoch-step: 37-596 -- Loss: 0.1973991096019745
val-epoch-step: 37-597 -- Loss: 0.17487524449825287
val-epoch-step: 37-598 -- Loss: 0.1513771414756775
val-epoch-step: 37-599 -- Loss: 0.18358711898326874
val-epoch-step: 37-600 -- Loss: 0.21436941623687744
val-epoch-step: 37-601 -- Loss: 0.15754708647727966
val-epoch-step: 37-602 -- Loss: 0.14453968405723572
val-epoch-step: 37-603 -- Loss: 0.227880597114563
val-epoch-step: 37-604 -- Loss: 0.1465625911951065
val-epoch-step: 37-605 -- Loss: 0.14557814598083496
val-epoch-step: 37-606 -- Loss: 0.25357842445373535
val-epoch-step: 37-607 -- Loss: 0.1285196840763092
val-epoch-step: 37-608 -- Loss: 0.25037869811058044
val-epoch-step: 37-609 -- Loss: 0.1672331988811493
val-epoch-step: 37-610 -- Loss: 0.1764826625585556
val-epoch-step: 37-611 -- Loss: 0.16417859494686127
val-epoch-step: 37-612 -- Loss: 0.45469528436660767
val-epoch-step: 37-613 -- Loss: 0.17075352370738983
val-epoch-step: 37-614 -- Loss: 0.17428258061408997
val-epoch-step: 37-615 -- Loss: 0.17504432797431946
val-epoch-step: 37-616 -- Loss: 0.14779208600521088
val-epoch-step: 37-617 -- Loss: 0.1882668137550354
val-epoch-step: 37-618 -- Loss: 0.19177506864070892
val-epoch-step: 37-619 -- Loss: 0.21274696290493011
val-epoch-step: 37-620 -- Loss: 0.14197847247123718
val-epoch-step: 37-621 -- Loss: 0.1282147318124771
val-epoch-step: 37-622 -- Loss: 0.14005619287490845
val-epoch-step: 37-623 -- Loss: 0.15201635658740997
val-epoch-step: 37-624 -- Loss: 0.14381393790245056
val-epoch-step: 37-625 -- Loss: 0.1592637300491333
val-epoch-step: 37-626 -- Loss: 0.1483231484889984
val-epoch-step: 37-627 -- Loss: 0.18514159321784973
val-epoch-step: 37-628 -- Loss: 0.6558042764663696
val-epoch-step: 37-629 -- Loss: 0.1925489455461502
val-epoch-step: 37-630 -- Loss: 0.34417784214019775
val-epoch-step: 37-631 -- Loss: 0.14333097636699677
val-epoch-step: 37-632 -- Loss: 0.21030409634113312
val-epoch-step: 37-633 -- Loss: 0.15299788117408752
val-epoch-step: 37-634 -- Loss: 0.15137164294719696
val-epoch-step: 37-635 -- Loss: 0.11352214217185974
val-epoch-step: 37-636 -- Loss: 0.17612484097480774
val-epoch-step: 37-637 -- Loss: 0.18208549916744232
val-epoch-step: 37-638 -- Loss: 0.1543906033039093
val-epoch-step: 37-639 -- Loss: 0.259864866733551
val-epoch-step: 37-640 -- Loss: 0.2661152184009552
val-epoch-step: 37-641 -- Loss: 0.13229556381702423
val-epoch-step: 37-642 -- Loss: 0.18283022940158844
val-epoch-step: 37-643 -- Loss: 0.2110699713230133
val-epoch-step: 37-644 -- Loss: 0.16871443390846252
val-epoch-step: 37-645 -- Loss: 0.21526488661766052
val-epoch-step: 37-646 -- Loss: 0.13059593737125397
val-epoch-step: 37-647 -- Loss: 0.13135933876037598
val-epoch-step: 37-648 -- Loss: 0.1562412530183792
val-epoch-step: 37-649 -- Loss: 0.20841635763645172
val-epoch-step: 37-650 -- Loss: 0.25477662682533264
val-epoch-step: 37-651 -- Loss: 0.15247224271297455
val-epoch-step: 37-652 -- Loss: 0.15521635115146637
val-epoch-step: 37-653 -- Loss: 0.207010418176651
val-epoch-step: 37-654 -- Loss: 0.11469799280166626
Epoch: 37 -- Train Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 38-0 -- Loss: 0.2257588803768158
train-epoch-step: 38-1 -- Loss: 0.14515507221221924
train-epoch-step: 38-2 -- Loss: 0.19904504716396332
train-epoch-step: 38-3 -- Loss: 0.14251096546649933
train-epoch-step: 38-4 -- Loss: 0.15956662595272064
train-epoch-step: 38-5 -- Loss: 0.180772066116333
train-epoch-step: 38-6 -- Loss: 0.20938655734062195
train-epoch-step: 38-7 -- Loss: 0.16708369553089142
train-epoch-step: 38-8 -- Loss: 0.18622806668281555
train-epoch-step: 38-9 -- Loss: 0.2229645699262619
train-epoch-step: 38-10 -- Loss: 0.19331848621368408
train-epoch-step: 38-11 -- Loss: 0.17589056491851807
train-epoch-step: 38-12 -- Loss: 0.1478554904460907
train-epoch-step: 38-13 -- Loss: 0.17583219707012177
train-epoch-step: 38-14 -- Loss: 0.1653427630662918
train-epoch-step: 38-15 -- Loss: 0.15949292480945587
train-epoch-step: 38-16 -- Loss: 0.16419154405593872
train-epoch-step: 38-17 -- Loss: 0.2232760787010193
train-epoch-step: 38-18 -- Loss: 0.1914534568786621
train-epoch-step: 38-19 -- Loss: 0.13474047183990479
train-epoch-step: 38-20 -- Loss: 0.21542662382125854
train-epoch-step: 38-21 -- Loss: 0.25637272000312805
train-epoch-step: 38-22 -- Loss: 0.13784010708332062
train-epoch-step: 38-23 -- Loss: 0.1452975869178772
train-epoch-step: 38-24 -- Loss: 0.12416519224643707
train-epoch-step: 38-25 -- Loss: 0.22680220007896423
train-epoch-step: 38-26 -- Loss: 0.19636407494544983
train-epoch-step: 38-27 -- Loss: 0.22678187489509583
train-epoch-step: 38-28 -- Loss: 0.12237972021102905
train-epoch-step: 38-29 -- Loss: 0.2391943633556366
train-epoch-step: 38-30 -- Loss: 0.10747095197439194
train-epoch-step: 38-31 -- Loss: 0.13257132470607758
train-epoch-step: 38-32 -- Loss: 0.17015036940574646
train-epoch-step: 38-33 -- Loss: 0.2732515335083008
train-epoch-step: 38-34 -- Loss: 0.17189104855060577
train-epoch-step: 38-35 -- Loss: 0.24774324893951416
train-epoch-step: 38-36 -- Loss: 0.1354009211063385
train-epoch-step: 38-37 -- Loss: 0.1372164636850357
train-epoch-step: 38-38 -- Loss: 0.18112577497959137
train-epoch-step: 38-39 -- Loss: 0.21707803010940552
train-epoch-step: 38-40 -- Loss: 0.19167011976242065
train-epoch-step: 38-41 -- Loss: 0.2161041498184204
train-epoch-step: 38-42 -- Loss: 0.14685678482055664
train-epoch-step: 38-43 -- Loss: 0.260917991399765
train-epoch-step: 38-44 -- Loss: 0.12538665533065796
train-epoch-step: 38-45 -- Loss: 0.11788995563983917
train-epoch-step: 38-46 -- Loss: 0.1613914668560028
train-epoch-step: 38-47 -- Loss: 0.205740287899971
train-epoch-step: 38-48 -- Loss: 0.1535114049911499
train-epoch-step: 38-49 -- Loss: 0.22057458758354187
train-epoch-step: 38-50 -- Loss: 0.10911308228969574
train-epoch-step: 38-51 -- Loss: 0.17320701479911804
train-epoch-step: 38-52 -- Loss: 0.16231054067611694
train-epoch-step: 38-53 -- Loss: 0.2142956554889679
train-epoch-step: 38-54 -- Loss: 0.2773992717266083
train-epoch-step: 38-55 -- Loss: 0.16243654489517212
train-epoch-step: 38-56 -- Loss: 0.1758124977350235
train-epoch-step: 38-57 -- Loss: 0.2325705736875534
train-epoch-step: 38-58 -- Loss: 0.28287649154663086
train-epoch-step: 38-59 -- Loss: 0.2308109849691391
train-epoch-step: 38-60 -- Loss: 0.1317460685968399
train-epoch-step: 38-61 -- Loss: 0.19923406839370728
train-epoch-step: 38-62 -- Loss: 0.1800839602947235
train-epoch-step: 38-63 -- Loss: 0.13895870745182037
train-epoch-step: 38-64 -- Loss: 0.14092591404914856
train-epoch-step: 38-65 -- Loss: 0.17602142691612244
train-epoch-step: 38-66 -- Loss: 0.10774118453264236
train-epoch-step: 38-67 -- Loss: 0.12969361245632172
train-epoch-step: 38-68 -- Loss: 0.2110850214958191
train-epoch-step: 38-69 -- Loss: 0.12163638323545456
train-epoch-step: 38-70 -- Loss: 0.2216092348098755
train-epoch-step: 38-71 -- Loss: 0.25778496265411377
train-epoch-step: 38-72 -- Loss: 0.18174070119857788
train-epoch-step: 38-73 -- Loss: 0.20547878742218018
train-epoch-step: 38-74 -- Loss: 0.09535963833332062
train-epoch-step: 38-75 -- Loss: 0.12746702134609222
train-epoch-step: 38-76 -- Loss: 0.14653193950653076
train-epoch-step: 38-77 -- Loss: 0.2334890514612198
train-epoch-step: 38-78 -- Loss: 0.2524774372577667
train-epoch-step: 38-79 -- Loss: 0.19179534912109375
train-epoch-step: 38-80 -- Loss: 0.27041131258010864
train-epoch-step: 38-81 -- Loss: 0.1300431191921234
train-epoch-step: 38-82 -- Loss: 0.252019464969635
train-epoch-step: 38-83 -- Loss: 0.1866294890642166
train-epoch-step: 38-84 -- Loss: 0.1971791386604309
train-epoch-step: 38-85 -- Loss: 0.18115657567977905
train-epoch-step: 38-86 -- Loss: 0.11723659932613373
train-epoch-step: 38-87 -- Loss: 0.21958425641059875
train-epoch-step: 38-88 -- Loss: 0.13843296468257904
train-epoch-step: 38-89 -- Loss: 0.18427176773548126
train-epoch-step: 38-90 -- Loss: 0.19276751577854156
train-epoch-step: 38-91 -- Loss: 0.24543632566928864
train-epoch-step: 38-92 -- Loss: 0.15504993498325348
train-epoch-step: 38-93 -- Loss: 0.17073166370391846
train-epoch-step: 38-94 -- Loss: 0.21521808207035065
train-epoch-step: 38-95 -- Loss: 0.18588438630104065
train-epoch-step: 38-96 -- Loss: 0.21126319468021393
train-epoch-step: 38-97 -- Loss: 0.17454347014427185
train-epoch-step: 38-98 -- Loss: 0.15325605869293213
train-epoch-step: 38-99 -- Loss: 0.1866891086101532
train-epoch-step: 38-100 -- Loss: 0.19116756319999695
train-epoch-step: 38-101 -- Loss: 0.27340543270111084
train-epoch-step: 38-102 -- Loss: 0.21589307487010956
train-epoch-step: 38-103 -- Loss: 0.18333184719085693
train-epoch-step: 38-104 -- Loss: 0.14863944053649902
train-epoch-step: 38-105 -- Loss: 0.26407158374786377
train-epoch-step: 38-106 -- Loss: 0.1741408407688141
train-epoch-step: 38-107 -- Loss: 0.1919163018465042
train-epoch-step: 38-108 -- Loss: 0.19001176953315735
train-epoch-step: 38-109 -- Loss: 0.15221790969371796
train-epoch-step: 38-110 -- Loss: 0.18586936593055725
train-epoch-step: 38-111 -- Loss: 0.17759498953819275
train-epoch-step: 38-112 -- Loss: 0.16156533360481262
train-epoch-step: 38-113 -- Loss: 0.15921169519424438
train-epoch-step: 38-114 -- Loss: 0.19457502663135529
train-epoch-step: 38-115 -- Loss: 0.1588754802942276
train-epoch-step: 38-116 -- Loss: 0.13790151476860046
train-epoch-step: 38-117 -- Loss: 0.12488380074501038
train-epoch-step: 38-118 -- Loss: 0.193584144115448
train-epoch-step: 38-119 -- Loss: 0.15125004947185516
train-epoch-step: 38-120 -- Loss: 0.2433662861585617
train-epoch-step: 38-121 -- Loss: 0.23638764023780823
train-epoch-step: 38-122 -- Loss: 0.21279913187026978
train-epoch-step: 38-123 -- Loss: 0.20483916997909546
train-epoch-step: 38-124 -- Loss: 0.12090440094470978
train-epoch-step: 38-125 -- Loss: 0.15318773686885834
train-epoch-step: 38-126 -- Loss: 0.23964089155197144
train-epoch-step: 38-127 -- Loss: 0.16848400235176086
train-epoch-step: 38-128 -- Loss: 0.17007720470428467
train-epoch-step: 38-129 -- Loss: 0.14129546284675598
train-epoch-step: 38-130 -- Loss: 0.19416168332099915
train-epoch-step: 38-131 -- Loss: 0.1362982839345932
train-epoch-step: 38-132 -- Loss: 0.18947868049144745
train-epoch-step: 38-133 -- Loss: 0.11648625135421753
train-epoch-step: 38-134 -- Loss: 0.19994285702705383
train-epoch-step: 38-135 -- Loss: 0.13396325707435608
train-epoch-step: 38-136 -- Loss: 0.12940455973148346
train-epoch-step: 38-137 -- Loss: 0.24406565725803375
train-epoch-step: 38-138 -- Loss: 0.26388460397720337
train-epoch-step: 38-139 -- Loss: 0.13061490654945374
train-epoch-step: 38-140 -- Loss: 0.2051265984773636
train-epoch-step: 38-141 -- Loss: 0.24012064933776855
train-epoch-step: 38-142 -- Loss: 0.19864019751548767
train-epoch-step: 38-143 -- Loss: 0.1683090776205063
train-epoch-step: 38-144 -- Loss: 0.18806111812591553
train-epoch-step: 38-145 -- Loss: 0.14235885441303253
train-epoch-step: 38-146 -- Loss: 0.17771045863628387
train-epoch-step: 38-147 -- Loss: 0.17226065695285797
train-epoch-step: 38-148 -- Loss: 0.16517111659049988
train-epoch-step: 38-149 -- Loss: 0.12087978422641754
train-epoch-step: 38-150 -- Loss: 0.1896805316209793
train-epoch-step: 38-151 -- Loss: 0.19011655449867249
train-epoch-step: 38-152 -- Loss: 0.18738789856433868
train-epoch-step: 38-153 -- Loss: 0.26204749941825867
train-epoch-step: 38-154 -- Loss: 0.12809202075004578
train-epoch-step: 38-155 -- Loss: 0.13381317257881165
train-epoch-step: 38-156 -- Loss: 0.11838334053754807
train-epoch-step: 38-157 -- Loss: 0.16551905870437622
train-epoch-step: 38-158 -- Loss: 0.16401706635951996
train-epoch-step: 38-159 -- Loss: 0.17687606811523438
train-epoch-step: 38-160 -- Loss: 0.21661177277565002
train-epoch-step: 38-161 -- Loss: 0.20689593255519867
train-epoch-step: 38-162 -- Loss: 0.21533864736557007
train-epoch-step: 38-163 -- Loss: 0.18641257286071777
train-epoch-step: 38-164 -- Loss: 0.19323208928108215
train-epoch-step: 38-165 -- Loss: 0.163263201713562
train-epoch-step: 38-166 -- Loss: 0.12286150455474854
train-epoch-step: 38-167 -- Loss: 0.12189096212387085
train-epoch-step: 38-168 -- Loss: 0.20049703121185303
train-epoch-step: 38-169 -- Loss: 0.13840946555137634
train-epoch-step: 38-170 -- Loss: 0.19831416010856628
train-epoch-step: 38-171 -- Loss: 0.14486607909202576
train-epoch-step: 38-172 -- Loss: 0.26037850975990295
train-epoch-step: 38-173 -- Loss: 0.13115090131759644
train-epoch-step: 38-174 -- Loss: 0.2492242157459259
train-epoch-step: 38-175 -- Loss: 0.186550572514534
train-epoch-step: 38-176 -- Loss: 0.13180574774742126
train-epoch-step: 38-177 -- Loss: 0.18160904943943024
train-epoch-step: 38-178 -- Loss: 0.1773761510848999
train-epoch-step: 38-179 -- Loss: 0.15224532783031464
train-epoch-step: 38-180 -- Loss: 0.15187808871269226
train-epoch-step: 38-181 -- Loss: 0.1687396764755249
train-epoch-step: 38-182 -- Loss: 0.18901973962783813
train-epoch-step: 38-183 -- Loss: 0.2683216631412506
train-epoch-step: 38-184 -- Loss: 0.1366109400987625
train-epoch-step: 38-185 -- Loss: 0.14128999412059784
train-epoch-step: 38-186 -- Loss: 0.18823730945587158
train-epoch-step: 38-187 -- Loss: 0.2102980613708496
train-epoch-step: 38-188 -- Loss: 0.17209427058696747
train-epoch-step: 38-189 -- Loss: 0.10368606448173523
train-epoch-step: 38-190 -- Loss: 0.18267962336540222
train-epoch-step: 38-191 -- Loss: 0.16079789400100708
train-epoch-step: 38-192 -- Loss: 0.23128929734230042
train-epoch-step: 38-193 -- Loss: 0.20959261059761047
train-epoch-step: 38-194 -- Loss: 0.18460237979888916
train-epoch-step: 38-195 -- Loss: 0.16409409046173096
train-epoch-step: 38-196 -- Loss: 0.16703133285045624
train-epoch-step: 38-197 -- Loss: 0.13269595801830292
train-epoch-step: 38-198 -- Loss: 0.12849505245685577
train-epoch-step: 38-199 -- Loss: 0.14986130595207214
train-epoch-step: 38-200 -- Loss: 0.12405836582183838
train-epoch-step: 38-201 -- Loss: 0.19036993384361267
train-epoch-step: 38-202 -- Loss: 0.13819757103919983
train-epoch-step: 38-203 -- Loss: 0.17789436876773834
train-epoch-step: 38-204 -- Loss: 0.14106866717338562
train-epoch-step: 38-205 -- Loss: 0.18254956603050232
train-epoch-step: 38-206 -- Loss: 0.2379952073097229
train-epoch-step: 38-207 -- Loss: 0.13007116317749023
train-epoch-step: 38-208 -- Loss: 0.17677155137062073
train-epoch-step: 38-209 -- Loss: 0.14500129222869873
train-epoch-step: 38-210 -- Loss: 0.13624262809753418
train-epoch-step: 38-211 -- Loss: 0.2068350613117218
train-epoch-step: 38-212 -- Loss: 0.20617523789405823
train-epoch-step: 38-213 -- Loss: 0.12715832889080048
train-epoch-step: 38-214 -- Loss: 0.14336037635803223
train-epoch-step: 38-215 -- Loss: 0.13601770997047424
train-epoch-step: 38-216 -- Loss: 0.20540305972099304
train-epoch-step: 38-217 -- Loss: 0.21297325193881989
train-epoch-step: 38-218 -- Loss: 0.14547666907310486
train-epoch-step: 38-219 -- Loss: 0.1701340526342392
train-epoch-step: 38-220 -- Loss: 0.13251736760139465
train-epoch-step: 38-221 -- Loss: 0.20521943271160126
train-epoch-step: 38-222 -- Loss: 0.11659678816795349
train-epoch-step: 38-223 -- Loss: 0.16997186839580536
train-epoch-step: 38-224 -- Loss: 0.1869257390499115
train-epoch-step: 38-225 -- Loss: 0.26794931292533875
train-epoch-step: 38-226 -- Loss: 0.2022475302219391
train-epoch-step: 38-227 -- Loss: 0.21899911761283875
train-epoch-step: 38-228 -- Loss: 0.17495416104793549
train-epoch-step: 38-229 -- Loss: 0.1742950677871704
train-epoch-step: 38-230 -- Loss: 0.15849964320659637
train-epoch-step: 38-231 -- Loss: 0.1591852903366089
train-epoch-step: 38-232 -- Loss: 0.18745660781860352
train-epoch-step: 38-233 -- Loss: 0.08429080247879028
train-epoch-step: 38-234 -- Loss: 0.18103349208831787
train-epoch-step: 38-235 -- Loss: 0.14645230770111084
train-epoch-step: 38-236 -- Loss: 0.17873325943946838
train-epoch-step: 38-237 -- Loss: 0.23496338725090027
train-epoch-step: 38-238 -- Loss: 0.1605566143989563
train-epoch-step: 38-239 -- Loss: 0.12740619480609894
train-epoch-step: 38-240 -- Loss: 0.2208997905254364
train-epoch-step: 38-241 -- Loss: 0.1522539108991623
train-epoch-step: 38-242 -- Loss: 0.22432854771614075
train-epoch-step: 38-243 -- Loss: 0.23596441745758057
train-epoch-step: 38-244 -- Loss: 0.20127686858177185
train-epoch-step: 38-245 -- Loss: 0.21235476434230804
train-epoch-step: 38-246 -- Loss: 0.21911633014678955
train-epoch-step: 38-247 -- Loss: 0.20971828699111938
train-epoch-step: 38-248 -- Loss: 0.18209120631217957
train-epoch-step: 38-249 -- Loss: 0.14124254882335663
train-epoch-step: 38-250 -- Loss: 0.19735227525234222
train-epoch-step: 38-251 -- Loss: 0.11144952476024628
train-epoch-step: 38-252 -- Loss: 0.20654582977294922
train-epoch-step: 38-253 -- Loss: 0.13686884939670563
train-epoch-step: 38-254 -- Loss: 0.21254287660121918
train-epoch-step: 38-255 -- Loss: 0.14324280619621277
train-epoch-step: 38-256 -- Loss: 0.1482963114976883
train-epoch-step: 38-257 -- Loss: 0.19218455255031586
train-epoch-step: 38-258 -- Loss: 0.14388220012187958
train-epoch-step: 38-259 -- Loss: 0.11565285921096802
train-epoch-step: 38-260 -- Loss: 0.199040025472641
train-epoch-step: 38-261 -- Loss: 0.16989219188690186
train-epoch-step: 38-262 -- Loss: 0.2881251275539398
train-epoch-step: 38-263 -- Loss: 0.24958395957946777
train-epoch-step: 38-264 -- Loss: 0.17468667030334473
train-epoch-step: 38-265 -- Loss: 0.12822405993938446
train-epoch-step: 38-266 -- Loss: 0.16778087615966797
train-epoch-step: 38-267 -- Loss: 0.16458679735660553
train-epoch-step: 38-268 -- Loss: 0.12510566413402557
train-epoch-step: 38-269 -- Loss: 0.17156153917312622
train-epoch-step: 38-270 -- Loss: 0.10944884270429611
train-epoch-step: 38-271 -- Loss: 0.15526963770389557
train-epoch-step: 38-272 -- Loss: 0.12456467747688293
train-epoch-step: 38-273 -- Loss: 0.1280704289674759
train-epoch-step: 38-274 -- Loss: 0.19084781408309937
train-epoch-step: 38-275 -- Loss: 0.2110554575920105
train-epoch-step: 38-276 -- Loss: 0.156948983669281
train-epoch-step: 38-277 -- Loss: 0.1662721335887909
train-epoch-step: 38-278 -- Loss: 0.14647573232650757
train-epoch-step: 38-279 -- Loss: 0.1460484266281128
train-epoch-step: 38-280 -- Loss: 0.2335141897201538
train-epoch-step: 38-281 -- Loss: 0.18037301301956177
train-epoch-step: 38-282 -- Loss: 0.14578300714492798
train-epoch-step: 38-283 -- Loss: 0.11646467447280884
train-epoch-step: 38-284 -- Loss: 0.16515778005123138
train-epoch-step: 38-285 -- Loss: 0.1940261721611023
train-epoch-step: 38-286 -- Loss: 0.15763014554977417
train-epoch-step: 38-287 -- Loss: 0.20564588904380798
train-epoch-step: 38-288 -- Loss: 0.09560222178697586
train-epoch-step: 38-289 -- Loss: 0.12459200620651245
train-epoch-step: 38-290 -- Loss: 0.19239120185375214
train-epoch-step: 38-291 -- Loss: 0.11814703792333603
train-epoch-step: 38-292 -- Loss: 0.16304700076580048
train-epoch-step: 38-293 -- Loss: 0.13786950707435608
train-epoch-step: 38-294 -- Loss: 0.16245275735855103
train-epoch-step: 38-295 -- Loss: 0.2619442045688629
train-epoch-step: 38-296 -- Loss: 0.16303196549415588
train-epoch-step: 38-297 -- Loss: 0.1769871860742569
train-epoch-step: 38-298 -- Loss: 0.22895656526088715
train-epoch-step: 38-299 -- Loss: 0.14750538766384125
train-epoch-step: 38-300 -- Loss: 0.16798877716064453
train-epoch-step: 38-301 -- Loss: 0.17471450567245483
train-epoch-step: 38-302 -- Loss: 0.2225218415260315
train-epoch-step: 38-303 -- Loss: 0.20646226406097412
train-epoch-step: 38-304 -- Loss: 0.13154573738574982
train-epoch-step: 38-305 -- Loss: 0.14518210291862488
train-epoch-step: 38-306 -- Loss: 0.23519101738929749
train-epoch-step: 38-307 -- Loss: 0.16564704477787018
train-epoch-step: 38-308 -- Loss: 0.22398577630519867
train-epoch-step: 38-309 -- Loss: 0.15463998913764954
train-epoch-step: 38-310 -- Loss: 0.16078495979309082
train-epoch-step: 38-311 -- Loss: 0.16343992948532104
train-epoch-step: 38-312 -- Loss: 0.2038182020187378
train-epoch-step: 38-313 -- Loss: 0.10258230566978455
train-epoch-step: 38-314 -- Loss: 0.19979839026927948
train-epoch-step: 38-315 -- Loss: 0.1731380820274353
train-epoch-step: 38-316 -- Loss: 0.15180209279060364
train-epoch-step: 38-317 -- Loss: 0.13935649394989014
train-epoch-step: 38-318 -- Loss: 0.16298465430736542
train-epoch-step: 38-319 -- Loss: 0.1685841679573059
train-epoch-step: 38-320 -- Loss: 0.11722712963819504
train-epoch-step: 38-321 -- Loss: 0.13496705889701843
train-epoch-step: 38-322 -- Loss: 0.22062420845031738
train-epoch-step: 38-323 -- Loss: 0.15930940210819244
train-epoch-step: 38-324 -- Loss: 0.25685766339302063
train-epoch-step: 38-325 -- Loss: 0.15980522334575653
train-epoch-step: 38-326 -- Loss: 0.16853484511375427
train-epoch-step: 38-327 -- Loss: 0.20637330412864685
train-epoch-step: 38-328 -- Loss: 0.1997511088848114
train-epoch-step: 38-329 -- Loss: 0.34377679228782654
train-epoch-step: 38-330 -- Loss: 0.36096400022506714
train-epoch-step: 38-331 -- Loss: 0.21130971610546112
train-epoch-step: 38-332 -- Loss: 0.10160370171070099
train-epoch-step: 38-333 -- Loss: 0.18496978282928467
train-epoch-step: 38-334 -- Loss: 0.1538776308298111
train-epoch-step: 38-335 -- Loss: 0.1845213770866394
train-epoch-step: 38-336 -- Loss: 0.14979515969753265
train-epoch-step: 38-337 -- Loss: 0.2112381011247635
train-epoch-step: 38-338 -- Loss: 0.1604793667793274
train-epoch-step: 38-339 -- Loss: 0.1440228968858719
train-epoch-step: 38-340 -- Loss: 0.19463171064853668
train-epoch-step: 38-341 -- Loss: 0.1405554860830307
train-epoch-step: 38-342 -- Loss: 0.1660696566104889
train-epoch-step: 38-343 -- Loss: 0.15497565269470215
train-epoch-step: 38-344 -- Loss: 0.16810637712478638
train-epoch-step: 38-345 -- Loss: 0.1263045370578766
train-epoch-step: 38-346 -- Loss: 0.21124546229839325
train-epoch-step: 38-347 -- Loss: 0.1542893499135971
train-epoch-step: 38-348 -- Loss: 0.21193867921829224
train-epoch-step: 38-349 -- Loss: 0.2028486132621765
train-epoch-step: 38-350 -- Loss: 0.2568054497241974
train-epoch-step: 38-351 -- Loss: 0.19392678141593933
train-epoch-step: 38-352 -- Loss: 0.1269340068101883
train-epoch-step: 38-353 -- Loss: 0.19029532372951508
train-epoch-step: 38-354 -- Loss: 0.28755444288253784
train-epoch-step: 38-355 -- Loss: 0.11621721088886261
train-epoch-step: 38-356 -- Loss: 0.11416584253311157
train-epoch-step: 38-357 -- Loss: 0.19009526073932648
train-epoch-step: 38-358 -- Loss: 0.1860865354537964
train-epoch-step: 38-359 -- Loss: 0.14632606506347656
train-epoch-step: 38-360 -- Loss: 0.12233161926269531
train-epoch-step: 38-361 -- Loss: 0.24190476536750793
train-epoch-step: 38-362 -- Loss: 0.1682201772928238
train-epoch-step: 38-363 -- Loss: 0.10983054339885712
train-epoch-step: 38-364 -- Loss: 0.1787768006324768
train-epoch-step: 38-365 -- Loss: 0.1731172651052475
train-epoch-step: 38-366 -- Loss: 0.20500588417053223
train-epoch-step: 38-367 -- Loss: 0.23149052262306213
train-epoch-step: 38-368 -- Loss: 0.21013842523097992
train-epoch-step: 38-369 -- Loss: 0.28180551528930664
train-epoch-step: 38-370 -- Loss: 0.1237160861492157
train-epoch-step: 38-371 -- Loss: 0.11954702436923981
train-epoch-step: 38-372 -- Loss: 0.14740943908691406
train-epoch-step: 38-373 -- Loss: 0.1895877569913864
train-epoch-step: 38-374 -- Loss: 0.1537957787513733
train-epoch-step: 38-375 -- Loss: 0.27073776721954346
train-epoch-step: 38-376 -- Loss: 0.1665695160627365
train-epoch-step: 38-377 -- Loss: 0.2276744544506073
train-epoch-step: 38-378 -- Loss: 0.19837063550949097
train-epoch-step: 38-379 -- Loss: 0.12083560228347778
train-epoch-step: 38-380 -- Loss: 0.09291444718837738
train-epoch-step: 38-381 -- Loss: 0.24499082565307617
train-epoch-step: 38-382 -- Loss: 0.23232708871364594
train-epoch-step: 38-383 -- Loss: 0.1750316321849823
train-epoch-step: 38-384 -- Loss: 0.21401795744895935
train-epoch-step: 38-385 -- Loss: 0.18749496340751648
train-epoch-step: 38-386 -- Loss: 0.17995575070381165
train-epoch-step: 38-387 -- Loss: 0.19837750494480133
train-epoch-step: 38-388 -- Loss: 0.1922321617603302
train-epoch-step: 38-389 -- Loss: 0.1708950251340866
train-epoch-step: 38-390 -- Loss: 0.15241216123104095
train-epoch-step: 38-391 -- Loss: 0.1465582549571991
train-epoch-step: 38-392 -- Loss: 0.18801462650299072
train-epoch-step: 38-393 -- Loss: 0.1555897295475006
train-epoch-step: 38-394 -- Loss: 0.19607296586036682
train-epoch-step: 38-395 -- Loss: 0.16408303380012512
train-epoch-step: 38-396 -- Loss: 0.1259893774986267
train-epoch-step: 38-397 -- Loss: 0.12216628342866898
train-epoch-step: 38-398 -- Loss: 0.19470809400081635
train-epoch-step: 38-399 -- Loss: 0.1751706600189209
train-epoch-step: 38-400 -- Loss: 0.2727341055870056
train-epoch-step: 38-401 -- Loss: 0.12030310928821564
train-epoch-step: 38-402 -- Loss: 0.2546606659889221
train-epoch-step: 38-403 -- Loss: 0.15421341359615326
train-epoch-step: 38-404 -- Loss: 0.1383088082075119
train-epoch-step: 38-405 -- Loss: 0.14553971588611603
train-epoch-step: 38-406 -- Loss: 0.16957396268844604
train-epoch-step: 38-407 -- Loss: 0.11345037072896957
train-epoch-step: 38-408 -- Loss: 0.16783060133457184
train-epoch-step: 38-409 -- Loss: 0.16992801427841187
train-epoch-step: 38-410 -- Loss: 0.17507652938365936
train-epoch-step: 38-411 -- Loss: 0.19794383645057678
train-epoch-step: 38-412 -- Loss: 0.12859411537647247
train-epoch-step: 38-413 -- Loss: 0.14490655064582825
train-epoch-step: 38-414 -- Loss: 0.14144691824913025
train-epoch-step: 38-415 -- Loss: 0.1404411345720291
train-epoch-step: 38-416 -- Loss: 0.26119011640548706
train-epoch-step: 38-417 -- Loss: 0.19693899154663086
train-epoch-step: 38-418 -- Loss: 0.2325005978345871
train-epoch-step: 38-419 -- Loss: 0.19709116220474243
train-epoch-step: 38-420 -- Loss: 0.1541920304298401
train-epoch-step: 38-421 -- Loss: 0.18603616952896118
train-epoch-step: 38-422 -- Loss: 0.14580069482326508
train-epoch-step: 38-423 -- Loss: 0.1749466210603714
train-epoch-step: 38-424 -- Loss: 0.13633406162261963
train-epoch-step: 38-425 -- Loss: 0.18564416468143463
train-epoch-step: 38-426 -- Loss: 0.16381576657295227
train-epoch-step: 38-427 -- Loss: 0.13244442641735077
train-epoch-step: 38-428 -- Loss: 0.1977095901966095
train-epoch-step: 38-429 -- Loss: 0.17435777187347412
train-epoch-step: 38-430 -- Loss: 0.14309608936309814
train-epoch-step: 38-431 -- Loss: 0.16064764559268951
train-epoch-step: 38-432 -- Loss: 0.24324187636375427
train-epoch-step: 38-433 -- Loss: 0.1467393934726715
train-epoch-step: 38-434 -- Loss: 0.12936867773532867
train-epoch-step: 38-435 -- Loss: 0.15844658017158508
train-epoch-step: 38-436 -- Loss: 0.15702074766159058
train-epoch-step: 38-437 -- Loss: 0.13491381704807281
train-epoch-step: 38-438 -- Loss: 0.17031219601631165
train-epoch-step: 38-439 -- Loss: 0.2689955532550812
train-epoch-step: 38-440 -- Loss: 0.1376952826976776
train-epoch-step: 38-441 -- Loss: 0.20495162904262543
train-epoch-step: 38-442 -- Loss: 0.17857563495635986
train-epoch-step: 38-443 -- Loss: 0.16280227899551392
train-epoch-step: 38-444 -- Loss: 0.17637017369270325
train-epoch-step: 38-445 -- Loss: 0.1814086139202118
train-epoch-step: 38-446 -- Loss: 0.16009296476840973
train-epoch-step: 38-447 -- Loss: 0.19058287143707275
train-epoch-step: 38-448 -- Loss: 0.2346983700990677
train-epoch-step: 38-449 -- Loss: 0.19660700857639313
train-epoch-step: 38-450 -- Loss: 0.1829575151205063
train-epoch-step: 38-451 -- Loss: 0.14290744066238403
train-epoch-step: 38-452 -- Loss: 0.1329147219657898
train-epoch-step: 38-453 -- Loss: 0.091600202023983
train-epoch-step: 38-454 -- Loss: 0.22717109322547913
train-epoch-step: 38-455 -- Loss: 0.12206657230854034
train-epoch-step: 38-456 -- Loss: 0.11939891427755356
train-epoch-step: 38-457 -- Loss: 0.21713149547576904
train-epoch-step: 38-458 -- Loss: 0.14809104800224304
train-epoch-step: 38-459 -- Loss: 0.215207040309906
train-epoch-step: 38-460 -- Loss: 0.12838581204414368
train-epoch-step: 38-461 -- Loss: 0.13414494693279266
train-epoch-step: 38-462 -- Loss: 0.15526072680950165
train-epoch-step: 38-463 -- Loss: 0.13653890788555145
train-epoch-step: 38-464 -- Loss: 0.16426490247249603
train-epoch-step: 38-465 -- Loss: 0.2328152358531952
train-epoch-step: 38-466 -- Loss: 0.200618714094162
train-epoch-step: 38-467 -- Loss: 0.11498154699802399
train-epoch-step: 38-468 -- Loss: 0.16827930510044098
train-epoch-step: 38-469 -- Loss: 0.21539334952831268
train-epoch-step: 38-470 -- Loss: 0.16988657414913177
train-epoch-step: 38-471 -- Loss: 0.1565544754266739
train-epoch-step: 38-472 -- Loss: 0.15695498883724213
train-epoch-step: 38-473 -- Loss: 0.1659366637468338
train-epoch-step: 38-474 -- Loss: 0.120808444917202
train-epoch-step: 38-475 -- Loss: 0.11002160608768463
train-epoch-step: 38-476 -- Loss: 0.2015981674194336
train-epoch-step: 38-477 -- Loss: 0.19951550662517548
train-epoch-step: 38-478 -- Loss: 0.1892032027244568
train-epoch-step: 38-479 -- Loss: 0.14131858944892883
train-epoch-step: 38-480 -- Loss: 0.18898314237594604
train-epoch-step: 38-481 -- Loss: 0.2783304452896118
train-epoch-step: 38-482 -- Loss: 0.25739750266075134
train-epoch-step: 38-483 -- Loss: 0.17841346561908722
train-epoch-step: 38-484 -- Loss: 0.20948810875415802
train-epoch-step: 38-485 -- Loss: 0.12584879994392395
train-epoch-step: 38-486 -- Loss: 0.23038113117218018
train-epoch-step: 38-487 -- Loss: 0.23962044715881348
train-epoch-step: 38-488 -- Loss: 0.18716998398303986
train-epoch-step: 38-489 -- Loss: 0.21607917547225952
train-epoch-step: 38-490 -- Loss: 0.13406045734882355
train-epoch-step: 38-491 -- Loss: 0.13316087424755096
train-epoch-step: 38-492 -- Loss: 0.12544360756874084
train-epoch-step: 38-493 -- Loss: 0.2002778798341751
train-epoch-step: 38-494 -- Loss: 0.19762888550758362
train-epoch-step: 38-495 -- Loss: 0.19986075162887573
train-epoch-step: 38-496 -- Loss: 0.13834552466869354
train-epoch-step: 38-497 -- Loss: 0.18747180700302124
train-epoch-step: 38-498 -- Loss: 0.14586515724658966
train-epoch-step: 38-499 -- Loss: 0.16682055592536926
train-epoch-step: 38-500 -- Loss: 0.15630404651165009
train-epoch-step: 38-501 -- Loss: 0.21354374289512634
train-epoch-step: 38-502 -- Loss: 0.15449413657188416
train-epoch-step: 38-503 -- Loss: 0.22071000933647156
train-epoch-step: 38-504 -- Loss: 0.1196117103099823
train-epoch-step: 38-505 -- Loss: 0.16778647899627686
train-epoch-step: 38-506 -- Loss: 0.12055712193250656
train-epoch-step: 38-507 -- Loss: 0.18631048500537872
train-epoch-step: 38-508 -- Loss: 0.17451781034469604
train-epoch-step: 38-509 -- Loss: 0.16655279695987701
train-epoch-step: 38-510 -- Loss: 0.1273646503686905
train-epoch-step: 38-511 -- Loss: 0.2188090831041336
train-epoch-step: 38-512 -- Loss: 0.17416884005069733
train-epoch-step: 38-513 -- Loss: 0.1985807716846466
train-epoch-step: 38-514 -- Loss: 0.15019601583480835
train-epoch-step: 38-515 -- Loss: 0.15481743216514587
train-epoch-step: 38-516 -- Loss: 0.17041920125484467
train-epoch-step: 38-517 -- Loss: 0.1706690639257431
train-epoch-step: 38-518 -- Loss: 0.13735917210578918
train-epoch-step: 38-519 -- Loss: 0.13575106859207153
train-epoch-step: 38-520 -- Loss: 0.18778294324874878
train-epoch-step: 38-521 -- Loss: 0.2304336130619049
train-epoch-step: 38-522 -- Loss: 0.16714787483215332
train-epoch-step: 38-523 -- Loss: 0.16040481626987457
train-epoch-step: 38-524 -- Loss: 0.1636597216129303
train-epoch-step: 38-525 -- Loss: 0.1903444528579712
train-epoch-step: 38-526 -- Loss: 0.12963707745075226
train-epoch-step: 38-527 -- Loss: 0.15641632676124573
train-epoch-step: 38-528 -- Loss: 0.15792834758758545
train-epoch-step: 38-529 -- Loss: 0.15678340196609497
train-epoch-step: 38-530 -- Loss: 0.16689273715019226
train-epoch-step: 38-531 -- Loss: 0.20102331042289734
train-epoch-step: 38-532 -- Loss: 0.17395687103271484
train-epoch-step: 38-533 -- Loss: 0.17352627217769623
train-epoch-step: 38-534 -- Loss: 0.1279815286397934
train-epoch-step: 38-535 -- Loss: 0.24563421308994293
train-epoch-step: 38-536 -- Loss: 0.15691934525966644
train-epoch-step: 38-537 -- Loss: 0.14708946645259857
train-epoch-step: 38-538 -- Loss: 0.10480928421020508
train-epoch-step: 38-539 -- Loss: 0.18512678146362305
train-epoch-step: 38-540 -- Loss: 0.13508623838424683
train-epoch-step: 38-541 -- Loss: 0.2043655961751938
train-epoch-step: 38-542 -- Loss: 0.2210736721754074
train-epoch-step: 38-543 -- Loss: 0.16880294680595398
train-epoch-step: 38-544 -- Loss: 0.22532963752746582
train-epoch-step: 38-545 -- Loss: 0.19148708879947662
train-epoch-step: 38-546 -- Loss: 0.21525053679943085
train-epoch-step: 38-547 -- Loss: 0.17786136269569397
train-epoch-step: 38-548 -- Loss: 0.09292474389076233
train-epoch-step: 38-549 -- Loss: 0.1520403027534485
train-epoch-step: 38-550 -- Loss: 0.19977805018424988
train-epoch-step: 38-551 -- Loss: 0.153045654296875
train-epoch-step: 38-552 -- Loss: 0.12783560156822205
train-epoch-step: 38-553 -- Loss: 0.19572320580482483
train-epoch-step: 38-554 -- Loss: 0.19268542528152466
train-epoch-step: 38-555 -- Loss: 0.22865045070648193
train-epoch-step: 38-556 -- Loss: 0.14293423295021057
train-epoch-step: 38-557 -- Loss: 0.2335212230682373
train-epoch-step: 38-558 -- Loss: 0.22681163251399994
train-epoch-step: 38-559 -- Loss: 0.13489998877048492
train-epoch-step: 38-560 -- Loss: 0.2128424048423767
train-epoch-step: 38-561 -- Loss: 0.17982111871242523
train-epoch-step: 38-562 -- Loss: 0.16224059462547302
train-epoch-step: 38-563 -- Loss: 0.18306288123130798
train-epoch-step: 38-564 -- Loss: 0.0983104556798935
train-epoch-step: 38-565 -- Loss: 0.184780091047287
train-epoch-step: 38-566 -- Loss: 0.1497783064842224
train-epoch-step: 38-567 -- Loss: 0.21899360418319702
train-epoch-step: 38-568 -- Loss: 0.1564069390296936
train-epoch-step: 38-569 -- Loss: 0.23840953409671783
train-epoch-step: 38-570 -- Loss: 0.1660335659980774
train-epoch-step: 38-571 -- Loss: 0.21372884511947632
train-epoch-step: 38-572 -- Loss: 0.23266512155532837
train-epoch-step: 38-573 -- Loss: 0.20162001252174377
train-epoch-step: 38-574 -- Loss: 0.23998641967773438
train-epoch-step: 38-575 -- Loss: 0.2989094853401184
train-epoch-step: 38-576 -- Loss: 0.12495405972003937
train-epoch-step: 38-577 -- Loss: 0.1649010181427002
train-epoch-step: 38-578 -- Loss: 0.21650615334510803
train-epoch-step: 38-579 -- Loss: 0.1685098111629486
train-epoch-step: 38-580 -- Loss: 0.17324388027191162
train-epoch-step: 38-581 -- Loss: 0.13353072106838226
train-epoch-step: 38-582 -- Loss: 0.20599398016929626
train-epoch-step: 38-583 -- Loss: 0.21179993450641632
train-epoch-step: 38-584 -- Loss: 0.1601949781179428
train-epoch-step: 38-585 -- Loss: 0.1922142058610916
train-epoch-step: 38-586 -- Loss: 0.2545963525772095
train-epoch-step: 38-587 -- Loss: 0.16013093292713165
train-epoch-step: 38-588 -- Loss: 0.12701110541820526
val-epoch-step: 38-589 -- Loss: 0.19761157035827637
val-epoch-step: 38-590 -- Loss: 0.1544889360666275
val-epoch-step: 38-591 -- Loss: 0.2281021773815155
val-epoch-step: 38-592 -- Loss: 0.17540760338306427
val-epoch-step: 38-593 -- Loss: 0.15868109464645386
val-epoch-step: 38-594 -- Loss: 0.44755715131759644
val-epoch-step: 38-595 -- Loss: 0.2315778285264969
val-epoch-step: 38-596 -- Loss: 0.2218385636806488
val-epoch-step: 38-597 -- Loss: 0.1800294667482376
val-epoch-step: 38-598 -- Loss: 0.15023192763328552
val-epoch-step: 38-599 -- Loss: 0.18193703889846802
val-epoch-step: 38-600 -- Loss: 0.19696089625358582
val-epoch-step: 38-601 -- Loss: 0.16078737378120422
val-epoch-step: 38-602 -- Loss: 0.13594605028629303
val-epoch-step: 38-603 -- Loss: 0.20204779505729675
val-epoch-step: 38-604 -- Loss: 0.1446325182914734
val-epoch-step: 38-605 -- Loss: 0.14581584930419922
val-epoch-step: 38-606 -- Loss: 0.2613047957420349
val-epoch-step: 38-607 -- Loss: 0.12953689694404602
val-epoch-step: 38-608 -- Loss: 0.2514267861843109
val-epoch-step: 38-609 -- Loss: 0.1627161204814911
val-epoch-step: 38-610 -- Loss: 0.18823301792144775
val-epoch-step: 38-611 -- Loss: 0.16250106692314148
val-epoch-step: 38-612 -- Loss: 0.3950712978839874
val-epoch-step: 38-613 -- Loss: 0.17507965862751007
val-epoch-step: 38-614 -- Loss: 0.17378312349319458
val-epoch-step: 38-615 -- Loss: 0.17287054657936096
val-epoch-step: 38-616 -- Loss: 0.16030524671077728
val-epoch-step: 38-617 -- Loss: 0.18324321508407593
val-epoch-step: 38-618 -- Loss: 0.18700288236141205
val-epoch-step: 38-619 -- Loss: 0.21963045001029968
val-epoch-step: 38-620 -- Loss: 0.1442793309688568
val-epoch-step: 38-621 -- Loss: 0.12823206186294556
val-epoch-step: 38-622 -- Loss: 0.14270499348640442
val-epoch-step: 38-623 -- Loss: 0.15052449703216553
val-epoch-step: 38-624 -- Loss: 0.14283934235572815
val-epoch-step: 38-625 -- Loss: 0.15320630371570587
val-epoch-step: 38-626 -- Loss: 0.1497325897216797
val-epoch-step: 38-627 -- Loss: 0.18080207705497742
val-epoch-step: 38-628 -- Loss: 0.6609585881233215
val-epoch-step: 38-629 -- Loss: 0.22241035103797913
val-epoch-step: 38-630 -- Loss: 0.3418121635913849
val-epoch-step: 38-631 -- Loss: 0.14209239184856415
val-epoch-step: 38-632 -- Loss: 0.20633840560913086
val-epoch-step: 38-633 -- Loss: 0.1487949639558792
val-epoch-step: 38-634 -- Loss: 0.1494113802909851
val-epoch-step: 38-635 -- Loss: 0.11116020381450653
val-epoch-step: 38-636 -- Loss: 0.16619102656841278
val-epoch-step: 38-637 -- Loss: 0.18651390075683594
val-epoch-step: 38-638 -- Loss: 0.14667481184005737
val-epoch-step: 38-639 -- Loss: 0.2617250084877014
val-epoch-step: 38-640 -- Loss: 0.2480718195438385
val-epoch-step: 38-641 -- Loss: 0.12205810099840164
val-epoch-step: 38-642 -- Loss: 0.20981460809707642
val-epoch-step: 38-643 -- Loss: 0.21355798840522766
val-epoch-step: 38-644 -- Loss: 0.16725043952465057
val-epoch-step: 38-645 -- Loss: 0.22152328491210938
val-epoch-step: 38-646 -- Loss: 0.13323600590229034
val-epoch-step: 38-647 -- Loss: 0.13270877301692963
val-epoch-step: 38-648 -- Loss: 0.15782314538955688
val-epoch-step: 38-649 -- Loss: 0.2129567563533783
val-epoch-step: 38-650 -- Loss: 0.24478140473365784
val-epoch-step: 38-651 -- Loss: 0.14533604681491852
val-epoch-step: 38-652 -- Loss: 0.16350039839744568
val-epoch-step: 38-653 -- Loss: 0.20340809226036072
val-epoch-step: 38-654 -- Loss: 0.12733004987239838
Epoch: 38 -- Train Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 39-0 -- Loss: 0.21943902969360352
train-epoch-step: 39-1 -- Loss: 0.1534871757030487
train-epoch-step: 39-2 -- Loss: 0.1934148520231247
train-epoch-step: 39-3 -- Loss: 0.1395060122013092
train-epoch-step: 39-4 -- Loss: 0.15629838407039642
train-epoch-step: 39-5 -- Loss: 0.1786540001630783
train-epoch-step: 39-6 -- Loss: 0.21509698033332825
train-epoch-step: 39-7 -- Loss: 0.16588015854358673
train-epoch-step: 39-8 -- Loss: 0.18022938072681427
train-epoch-step: 39-9 -- Loss: 0.23833604156970978
train-epoch-step: 39-10 -- Loss: 0.20334208011627197
train-epoch-step: 39-11 -- Loss: 0.1750095933675766
train-epoch-step: 39-12 -- Loss: 0.15372009575366974
train-epoch-step: 39-13 -- Loss: 0.1820782870054245
train-epoch-step: 39-14 -- Loss: 0.16413730382919312
train-epoch-step: 39-15 -- Loss: 0.16738227009773254
train-epoch-step: 39-16 -- Loss: 0.1616327464580536
train-epoch-step: 39-17 -- Loss: 0.21330095827579498
train-epoch-step: 39-18 -- Loss: 0.2384788691997528
train-epoch-step: 39-19 -- Loss: 0.13576021790504456
train-epoch-step: 39-20 -- Loss: 0.21393728256225586
train-epoch-step: 39-21 -- Loss: 0.253079354763031
train-epoch-step: 39-22 -- Loss: 0.13957422971725464
train-epoch-step: 39-23 -- Loss: 0.1425044983625412
train-epoch-step: 39-24 -- Loss: 0.12484367191791534
train-epoch-step: 39-25 -- Loss: 0.22047606110572815
train-epoch-step: 39-26 -- Loss: 0.19507844746112823
train-epoch-step: 39-27 -- Loss: 0.23687419295310974
train-epoch-step: 39-28 -- Loss: 0.12339672446250916
train-epoch-step: 39-29 -- Loss: 0.2471005618572235
train-epoch-step: 39-30 -- Loss: 0.11750306934118271
train-epoch-step: 39-31 -- Loss: 0.15015432238578796
train-epoch-step: 39-32 -- Loss: 0.1717953234910965
train-epoch-step: 39-33 -- Loss: 0.2729886770248413
train-epoch-step: 39-34 -- Loss: 0.16645404696464539
train-epoch-step: 39-35 -- Loss: 0.23723211884498596
train-epoch-step: 39-36 -- Loss: 0.136478990316391
train-epoch-step: 39-37 -- Loss: 0.13969802856445312
train-epoch-step: 39-38 -- Loss: 0.18223696947097778
train-epoch-step: 39-39 -- Loss: 0.2137155830860138
train-epoch-step: 39-40 -- Loss: 0.18725457787513733
train-epoch-step: 39-41 -- Loss: 0.21439117193222046
train-epoch-step: 39-42 -- Loss: 0.14574244618415833
train-epoch-step: 39-43 -- Loss: 0.2823810577392578
train-epoch-step: 39-44 -- Loss: 0.1299363374710083
train-epoch-step: 39-45 -- Loss: 0.11365264654159546
train-epoch-step: 39-46 -- Loss: 0.16842472553253174
train-epoch-step: 39-47 -- Loss: 0.2115279734134674
train-epoch-step: 39-48 -- Loss: 0.1524827480316162
train-epoch-step: 39-49 -- Loss: 0.23106779158115387
train-epoch-step: 39-50 -- Loss: 0.11574144661426544
train-epoch-step: 39-51 -- Loss: 0.1832519769668579
train-epoch-step: 39-52 -- Loss: 0.15716445446014404
train-epoch-step: 39-53 -- Loss: 0.20902690291404724
train-epoch-step: 39-54 -- Loss: 0.2902771234512329
train-epoch-step: 39-55 -- Loss: 0.1665460169315338
train-epoch-step: 39-56 -- Loss: 0.17762860655784607
train-epoch-step: 39-57 -- Loss: 0.23804539442062378
train-epoch-step: 39-58 -- Loss: 0.2835529148578644
train-epoch-step: 39-59 -- Loss: 0.2591552138328552
train-epoch-step: 39-60 -- Loss: 0.13030387461185455
train-epoch-step: 39-61 -- Loss: 0.20229344069957733
train-epoch-step: 39-62 -- Loss: 0.18251219391822815
train-epoch-step: 39-63 -- Loss: 0.1467141956090927
train-epoch-step: 39-64 -- Loss: 0.14739081263542175
train-epoch-step: 39-65 -- Loss: 0.17903104424476624
train-epoch-step: 39-66 -- Loss: 0.10738198459148407
train-epoch-step: 39-67 -- Loss: 0.12649086117744446
train-epoch-step: 39-68 -- Loss: 0.20768392086029053
train-epoch-step: 39-69 -- Loss: 0.12171857804059982
train-epoch-step: 39-70 -- Loss: 0.22881028056144714
train-epoch-step: 39-71 -- Loss: 0.2605111002922058
train-epoch-step: 39-72 -- Loss: 0.18575581908226013
train-epoch-step: 39-73 -- Loss: 0.2150503396987915
train-epoch-step: 39-74 -- Loss: 0.09663070738315582
train-epoch-step: 39-75 -- Loss: 0.1288166493177414
train-epoch-step: 39-76 -- Loss: 0.16019544005393982
train-epoch-step: 39-77 -- Loss: 0.2286568582057953
train-epoch-step: 39-78 -- Loss: 0.25959697365760803
train-epoch-step: 39-79 -- Loss: 0.19772887229919434
train-epoch-step: 39-80 -- Loss: 0.24142391979694366
train-epoch-step: 39-81 -- Loss: 0.12245392799377441
train-epoch-step: 39-82 -- Loss: 0.25231146812438965
train-epoch-step: 39-83 -- Loss: 0.17806854844093323
train-epoch-step: 39-84 -- Loss: 0.19081738591194153
train-epoch-step: 39-85 -- Loss: 0.17673496901988983
train-epoch-step: 39-86 -- Loss: 0.11797722429037094
train-epoch-step: 39-87 -- Loss: 0.21039395034313202
train-epoch-step: 39-88 -- Loss: 0.13809248805046082
train-epoch-step: 39-89 -- Loss: 0.18493245542049408
train-epoch-step: 39-90 -- Loss: 0.1922813206911087
train-epoch-step: 39-91 -- Loss: 0.24497154355049133
train-epoch-step: 39-92 -- Loss: 0.15738527476787567
train-epoch-step: 39-93 -- Loss: 0.17345759272575378
train-epoch-step: 39-94 -- Loss: 0.22253210842609406
train-epoch-step: 39-95 -- Loss: 0.19625158607959747
train-epoch-step: 39-96 -- Loss: 0.2156851887702942
train-epoch-step: 39-97 -- Loss: 0.17858344316482544
train-epoch-step: 39-98 -- Loss: 0.1914501041173935
train-epoch-step: 39-99 -- Loss: 0.1858968585729599
train-epoch-step: 39-100 -- Loss: 0.18450170755386353
train-epoch-step: 39-101 -- Loss: 0.26421892642974854
train-epoch-step: 39-102 -- Loss: 0.21657022833824158
train-epoch-step: 39-103 -- Loss: 0.18525376915931702
train-epoch-step: 39-104 -- Loss: 0.15000714361667633
train-epoch-step: 39-105 -- Loss: 0.30731087923049927
train-epoch-step: 39-106 -- Loss: 0.17463496327400208
train-epoch-step: 39-107 -- Loss: 0.192697674036026
train-epoch-step: 39-108 -- Loss: 0.19623354077339172
train-epoch-step: 39-109 -- Loss: 0.14703722298145294
train-epoch-step: 39-110 -- Loss: 0.18292397260665894
train-epoch-step: 39-111 -- Loss: 0.17989207804203033
train-epoch-step: 39-112 -- Loss: 0.16775481402873993
train-epoch-step: 39-113 -- Loss: 0.16088268160820007
train-epoch-step: 39-114 -- Loss: 0.19882839918136597
train-epoch-step: 39-115 -- Loss: 0.16353854537010193
train-epoch-step: 39-116 -- Loss: 0.14302533864974976
train-epoch-step: 39-117 -- Loss: 0.13286860287189484
train-epoch-step: 39-118 -- Loss: 0.2023966908454895
train-epoch-step: 39-119 -- Loss: 0.149190753698349
train-epoch-step: 39-120 -- Loss: 0.24922454357147217
train-epoch-step: 39-121 -- Loss: 0.2678670287132263
train-epoch-step: 39-122 -- Loss: 0.21798385679721832
train-epoch-step: 39-123 -- Loss: 0.2033274918794632
train-epoch-step: 39-124 -- Loss: 0.12914597988128662
train-epoch-step: 39-125 -- Loss: 0.16170191764831543
train-epoch-step: 39-126 -- Loss: 0.23135697841644287
train-epoch-step: 39-127 -- Loss: 0.1819826364517212
train-epoch-step: 39-128 -- Loss: 0.1710841953754425
train-epoch-step: 39-129 -- Loss: 0.14280734956264496
train-epoch-step: 39-130 -- Loss: 0.19218876957893372
train-epoch-step: 39-131 -- Loss: 0.13899821043014526
train-epoch-step: 39-132 -- Loss: 0.1879885196685791
train-epoch-step: 39-133 -- Loss: 0.11787939816713333
train-epoch-step: 39-134 -- Loss: 0.18868082761764526
train-epoch-step: 39-135 -- Loss: 0.14280059933662415
train-epoch-step: 39-136 -- Loss: 0.13261568546295166
train-epoch-step: 39-137 -- Loss: 0.24173864722251892
train-epoch-step: 39-138 -- Loss: 0.2710472643375397
train-epoch-step: 39-139 -- Loss: 0.13059338927268982
train-epoch-step: 39-140 -- Loss: 0.20878617465496063
train-epoch-step: 39-141 -- Loss: 0.24565017223358154
train-epoch-step: 39-142 -- Loss: 0.2033742070198059
train-epoch-step: 39-143 -- Loss: 0.17627555131912231
train-epoch-step: 39-144 -- Loss: 0.18745259940624237
train-epoch-step: 39-145 -- Loss: 0.1380329728126526
train-epoch-step: 39-146 -- Loss: 0.17824169993400574
train-epoch-step: 39-147 -- Loss: 0.17241555452346802
train-epoch-step: 39-148 -- Loss: 0.1575634628534317
train-epoch-step: 39-149 -- Loss: 0.12230274826288223
train-epoch-step: 39-150 -- Loss: 0.19105088710784912
train-epoch-step: 39-151 -- Loss: 0.18541072309017181
train-epoch-step: 39-152 -- Loss: 0.18735137581825256
train-epoch-step: 39-153 -- Loss: 0.26834332942962646
train-epoch-step: 39-154 -- Loss: 0.13030515611171722
train-epoch-step: 39-155 -- Loss: 0.1319849044084549
train-epoch-step: 39-156 -- Loss: 0.11611096560955048
train-epoch-step: 39-157 -- Loss: 0.1642138510942459
train-epoch-step: 39-158 -- Loss: 0.16626453399658203
train-epoch-step: 39-159 -- Loss: 0.17890611290931702
train-epoch-step: 39-160 -- Loss: 0.21002602577209473
train-epoch-step: 39-161 -- Loss: 0.20396476984024048
train-epoch-step: 39-162 -- Loss: 0.21403801441192627
train-epoch-step: 39-163 -- Loss: 0.18644049763679504
train-epoch-step: 39-164 -- Loss: 0.19325704872608185
train-epoch-step: 39-165 -- Loss: 0.16920356452465057
train-epoch-step: 39-166 -- Loss: 0.12499305605888367
train-epoch-step: 39-167 -- Loss: 0.12257781624794006
train-epoch-step: 39-168 -- Loss: 0.19617803394794464
train-epoch-step: 39-169 -- Loss: 0.13864749670028687
train-epoch-step: 39-170 -- Loss: 0.20095311105251312
train-epoch-step: 39-171 -- Loss: 0.14304637908935547
train-epoch-step: 39-172 -- Loss: 0.2631668448448181
train-epoch-step: 39-173 -- Loss: 0.13328777253627777
train-epoch-step: 39-174 -- Loss: 0.2479720115661621
train-epoch-step: 39-175 -- Loss: 0.18635046482086182
train-epoch-step: 39-176 -- Loss: 0.13158763945102692
train-epoch-step: 39-177 -- Loss: 0.17572715878486633
train-epoch-step: 39-178 -- Loss: 0.18567639589309692
train-epoch-step: 39-179 -- Loss: 0.15641425549983978
train-epoch-step: 39-180 -- Loss: 0.14850616455078125
train-epoch-step: 39-181 -- Loss: 0.16804561018943787
train-epoch-step: 39-182 -- Loss: 0.1861492395401001
train-epoch-step: 39-183 -- Loss: 0.26803722977638245
train-epoch-step: 39-184 -- Loss: 0.1376100778579712
train-epoch-step: 39-185 -- Loss: 0.1427280306816101
train-epoch-step: 39-186 -- Loss: 0.18910904228687286
train-epoch-step: 39-187 -- Loss: 0.2062755823135376
train-epoch-step: 39-188 -- Loss: 0.17447297275066376
train-epoch-step: 39-189 -- Loss: 0.10578624904155731
train-epoch-step: 39-190 -- Loss: 0.17959977686405182
train-epoch-step: 39-191 -- Loss: 0.15822435915470123
train-epoch-step: 39-192 -- Loss: 0.22523939609527588
train-epoch-step: 39-193 -- Loss: 0.21319767832756042
train-epoch-step: 39-194 -- Loss: 0.17940516769886017
train-epoch-step: 39-195 -- Loss: 0.16389362514019012
train-epoch-step: 39-196 -- Loss: 0.16751164197921753
train-epoch-step: 39-197 -- Loss: 0.12726305425167084
train-epoch-step: 39-198 -- Loss: 0.12539130449295044
train-epoch-step: 39-199 -- Loss: 0.15044893324375153
train-epoch-step: 39-200 -- Loss: 0.12255935370922089
train-epoch-step: 39-201 -- Loss: 0.18757662177085876
train-epoch-step: 39-202 -- Loss: 0.1344515085220337
train-epoch-step: 39-203 -- Loss: 0.17196431756019592
train-epoch-step: 39-204 -- Loss: 0.13989736139774323
train-epoch-step: 39-205 -- Loss: 0.18516093492507935
train-epoch-step: 39-206 -- Loss: 0.19606773555278778
train-epoch-step: 39-207 -- Loss: 0.1311395764350891
train-epoch-step: 39-208 -- Loss: 0.17705750465393066
train-epoch-step: 39-209 -- Loss: 0.14343558251857758
train-epoch-step: 39-210 -- Loss: 0.13059884309768677
train-epoch-step: 39-211 -- Loss: 0.2053239941596985
train-epoch-step: 39-212 -- Loss: 0.19629420340061188
train-epoch-step: 39-213 -- Loss: 0.12696781754493713
train-epoch-step: 39-214 -- Loss: 0.14511573314666748
train-epoch-step: 39-215 -- Loss: 0.12621667981147766
train-epoch-step: 39-216 -- Loss: 0.2042658030986786
train-epoch-step: 39-217 -- Loss: 0.21544249355793
train-epoch-step: 39-218 -- Loss: 0.14578485488891602
train-epoch-step: 39-219 -- Loss: 0.17179130017757416
train-epoch-step: 39-220 -- Loss: 0.12898245453834534
train-epoch-step: 39-221 -- Loss: 0.2054498791694641
train-epoch-step: 39-222 -- Loss: 0.11439338326454163
train-epoch-step: 39-223 -- Loss: 0.1774786114692688
train-epoch-step: 39-224 -- Loss: 0.18485133349895477
train-epoch-step: 39-225 -- Loss: 0.2699715793132782
train-epoch-step: 39-226 -- Loss: 0.2075662463903427
train-epoch-step: 39-227 -- Loss: 0.21964499354362488
train-epoch-step: 39-228 -- Loss: 0.1760317087173462
train-epoch-step: 39-229 -- Loss: 0.17226606607437134
train-epoch-step: 39-230 -- Loss: 0.16478927433490753
train-epoch-step: 39-231 -- Loss: 0.1541493833065033
train-epoch-step: 39-232 -- Loss: 0.18367978930473328
train-epoch-step: 39-233 -- Loss: 0.08696737140417099
train-epoch-step: 39-234 -- Loss: 0.17562657594680786
train-epoch-step: 39-235 -- Loss: 0.1503528654575348
train-epoch-step: 39-236 -- Loss: 0.17595496773719788
train-epoch-step: 39-237 -- Loss: 0.23867923021316528
train-epoch-step: 39-238 -- Loss: 0.156823992729187
train-epoch-step: 39-239 -- Loss: 0.1245933473110199
train-epoch-step: 39-240 -- Loss: 0.21912750601768494
train-epoch-step: 39-241 -- Loss: 0.15208664536476135
train-epoch-step: 39-242 -- Loss: 0.22171933948993683
train-epoch-step: 39-243 -- Loss: 0.23824447393417358
train-epoch-step: 39-244 -- Loss: 0.20559751987457275
train-epoch-step: 39-245 -- Loss: 0.20954160392284393
train-epoch-step: 39-246 -- Loss: 0.21320460736751556
train-epoch-step: 39-247 -- Loss: 0.21075184643268585
train-epoch-step: 39-248 -- Loss: 0.18512137234210968
train-epoch-step: 39-249 -- Loss: 0.1366911679506302
train-epoch-step: 39-250 -- Loss: 0.19577941298484802
train-epoch-step: 39-251 -- Loss: 0.10844030231237411
train-epoch-step: 39-252 -- Loss: 0.19908881187438965
train-epoch-step: 39-253 -- Loss: 0.13475726544857025
train-epoch-step: 39-254 -- Loss: 0.2154756486415863
train-epoch-step: 39-255 -- Loss: 0.1419898271560669
train-epoch-step: 39-256 -- Loss: 0.1481451690196991
train-epoch-step: 39-257 -- Loss: 0.1870017945766449
train-epoch-step: 39-258 -- Loss: 0.14468777179718018
train-epoch-step: 39-259 -- Loss: 0.11456575244665146
train-epoch-step: 39-260 -- Loss: 0.19847124814987183
train-epoch-step: 39-261 -- Loss: 0.18792007863521576
train-epoch-step: 39-262 -- Loss: 0.3003469705581665
train-epoch-step: 39-263 -- Loss: 0.19719968736171722
train-epoch-step: 39-264 -- Loss: 0.17104215919971466
train-epoch-step: 39-265 -- Loss: 0.12490200996398926
train-epoch-step: 39-266 -- Loss: 0.15575304627418518
train-epoch-step: 39-267 -- Loss: 0.12955242395401
train-epoch-step: 39-268 -- Loss: 0.11583227664232254
train-epoch-step: 39-269 -- Loss: 0.16985714435577393
train-epoch-step: 39-270 -- Loss: 0.10497923195362091
train-epoch-step: 39-271 -- Loss: 0.1464330404996872
train-epoch-step: 39-272 -- Loss: 0.11536610871553421
train-epoch-step: 39-273 -- Loss: 0.12762106955051422
train-epoch-step: 39-274 -- Loss: 0.17984670400619507
train-epoch-step: 39-275 -- Loss: 0.2028643637895584
train-epoch-step: 39-276 -- Loss: 0.15617378056049347
train-epoch-step: 39-277 -- Loss: 0.15499645471572876
train-epoch-step: 39-278 -- Loss: 0.1411266177892685
train-epoch-step: 39-279 -- Loss: 0.14096125960350037
train-epoch-step: 39-280 -- Loss: 0.2202911674976349
train-epoch-step: 39-281 -- Loss: 0.17669370770454407
train-epoch-step: 39-282 -- Loss: 0.1411728858947754
train-epoch-step: 39-283 -- Loss: 0.11730843782424927
train-epoch-step: 39-284 -- Loss: 0.1324811726808548
train-epoch-step: 39-285 -- Loss: 0.18797826766967773
train-epoch-step: 39-286 -- Loss: 0.15321269631385803
train-epoch-step: 39-287 -- Loss: 0.20064178109169006
train-epoch-step: 39-288 -- Loss: 0.09477654099464417
train-epoch-step: 39-289 -- Loss: 0.12388195097446442
train-epoch-step: 39-290 -- Loss: 0.17904029786586761
train-epoch-step: 39-291 -- Loss: 0.11584360897541046
train-epoch-step: 39-292 -- Loss: 0.15476934611797333
train-epoch-step: 39-293 -- Loss: 0.13476820290088654
train-epoch-step: 39-294 -- Loss: 0.15892799198627472
train-epoch-step: 39-295 -- Loss: 0.2619360089302063
train-epoch-step: 39-296 -- Loss: 0.16008876264095306
train-epoch-step: 39-297 -- Loss: 0.17391741275787354
train-epoch-step: 39-298 -- Loss: 0.2273198962211609
train-epoch-step: 39-299 -- Loss: 0.14810068905353546
train-epoch-step: 39-300 -- Loss: 0.15859061479568481
train-epoch-step: 39-301 -- Loss: 0.17369608581066132
train-epoch-step: 39-302 -- Loss: 0.21789813041687012
train-epoch-step: 39-303 -- Loss: 0.2015116661787033
train-epoch-step: 39-304 -- Loss: 0.12156404554843903
train-epoch-step: 39-305 -- Loss: 0.139953151345253
train-epoch-step: 39-306 -- Loss: 0.21064795553684235
train-epoch-step: 39-307 -- Loss: 0.1642788052558899
train-epoch-step: 39-308 -- Loss: 0.21707427501678467
train-epoch-step: 39-309 -- Loss: 0.15851707756519318
train-epoch-step: 39-310 -- Loss: 0.16417500376701355
train-epoch-step: 39-311 -- Loss: 0.15897032618522644
train-epoch-step: 39-312 -- Loss: 0.20429693162441254
train-epoch-step: 39-313 -- Loss: 0.09845956414937973
train-epoch-step: 39-314 -- Loss: 0.1883230358362198
train-epoch-step: 39-315 -- Loss: 0.16789165139198303
train-epoch-step: 39-316 -- Loss: 0.1519000381231308
train-epoch-step: 39-317 -- Loss: 0.13983893394470215
train-epoch-step: 39-318 -- Loss: 0.16513292491436005
train-epoch-step: 39-319 -- Loss: 0.1649254858493805
train-epoch-step: 39-320 -- Loss: 0.11796525120735168
train-epoch-step: 39-321 -- Loss: 0.13042999804019928
train-epoch-step: 39-322 -- Loss: 0.2161838710308075
train-epoch-step: 39-323 -- Loss: 0.1575383096933365
train-epoch-step: 39-324 -- Loss: 0.25101780891418457
train-epoch-step: 39-325 -- Loss: 0.15158411860466003
train-epoch-step: 39-326 -- Loss: 0.1680910885334015
train-epoch-step: 39-327 -- Loss: 0.2040008157491684
train-epoch-step: 39-328 -- Loss: 0.19197863340377808
train-epoch-step: 39-329 -- Loss: 0.34775856137275696
train-epoch-step: 39-330 -- Loss: 0.3602961301803589
train-epoch-step: 39-331 -- Loss: 0.21099214255809784
train-epoch-step: 39-332 -- Loss: 0.09961038827896118
train-epoch-step: 39-333 -- Loss: 0.17767897248268127
train-epoch-step: 39-334 -- Loss: 0.1519203782081604
train-epoch-step: 39-335 -- Loss: 0.17469298839569092
train-epoch-step: 39-336 -- Loss: 0.1467021107673645
train-epoch-step: 39-337 -- Loss: 0.2092418223619461
train-epoch-step: 39-338 -- Loss: 0.16021178662776947
train-epoch-step: 39-339 -- Loss: 0.14236916601657867
train-epoch-step: 39-340 -- Loss: 0.19374805688858032
train-epoch-step: 39-341 -- Loss: 0.141474649310112
train-epoch-step: 39-342 -- Loss: 0.16320131719112396
train-epoch-step: 39-343 -- Loss: 0.15203909575939178
train-epoch-step: 39-344 -- Loss: 0.17038749158382416
train-epoch-step: 39-345 -- Loss: 0.12889693677425385
train-epoch-step: 39-346 -- Loss: 0.19827890396118164
train-epoch-step: 39-347 -- Loss: 0.1535419523715973
train-epoch-step: 39-348 -- Loss: 0.20009416341781616
train-epoch-step: 39-349 -- Loss: 0.2080778032541275
train-epoch-step: 39-350 -- Loss: 0.25237852334976196
train-epoch-step: 39-351 -- Loss: 0.19464914500713348
train-epoch-step: 39-352 -- Loss: 0.12656250596046448
train-epoch-step: 39-353 -- Loss: 0.1924484372138977
train-epoch-step: 39-354 -- Loss: 0.2916419804096222
train-epoch-step: 39-355 -- Loss: 0.11728431284427643
train-epoch-step: 39-356 -- Loss: 0.11842776834964752
train-epoch-step: 39-357 -- Loss: 0.1876835823059082
train-epoch-step: 39-358 -- Loss: 0.18516239523887634
train-epoch-step: 39-359 -- Loss: 0.1374296247959137
train-epoch-step: 39-360 -- Loss: 0.12265157699584961
train-epoch-step: 39-361 -- Loss: 0.23318257927894592
train-epoch-step: 39-362 -- Loss: 0.1677127182483673
train-epoch-step: 39-363 -- Loss: 0.11034417152404785
train-epoch-step: 39-364 -- Loss: 0.18004855513572693
train-epoch-step: 39-365 -- Loss: 0.16537031531333923
train-epoch-step: 39-366 -- Loss: 0.2148742377758026
train-epoch-step: 39-367 -- Loss: 0.2276366949081421
train-epoch-step: 39-368 -- Loss: 0.2000143676996231
train-epoch-step: 39-369 -- Loss: 0.2779845595359802
train-epoch-step: 39-370 -- Loss: 0.12537088990211487
train-epoch-step: 39-371 -- Loss: 0.12399988621473312
train-epoch-step: 39-372 -- Loss: 0.14850910007953644
train-epoch-step: 39-373 -- Loss: 0.20550945401191711
train-epoch-step: 39-374 -- Loss: 0.15785537660121918
train-epoch-step: 39-375 -- Loss: 0.2698349356651306
train-epoch-step: 39-376 -- Loss: 0.1570412814617157
train-epoch-step: 39-377 -- Loss: 0.22825103998184204
train-epoch-step: 39-378 -- Loss: 0.20132744312286377
train-epoch-step: 39-379 -- Loss: 0.12172918021678925
train-epoch-step: 39-380 -- Loss: 0.09028491377830505
train-epoch-step: 39-381 -- Loss: 0.2424139678478241
train-epoch-step: 39-382 -- Loss: 0.24565954506397247
train-epoch-step: 39-383 -- Loss: 0.17711147665977478
train-epoch-step: 39-384 -- Loss: 0.2381029725074768
train-epoch-step: 39-385 -- Loss: 0.18915940821170807
train-epoch-step: 39-386 -- Loss: 0.18624863028526306
train-epoch-step: 39-387 -- Loss: 0.21347208321094513
train-epoch-step: 39-388 -- Loss: 0.1932281106710434
train-epoch-step: 39-389 -- Loss: 0.17217323184013367
train-epoch-step: 39-390 -- Loss: 0.16621139645576477
train-epoch-step: 39-391 -- Loss: 0.1441439986228943
train-epoch-step: 39-392 -- Loss: 0.18490825593471527
train-epoch-step: 39-393 -- Loss: 0.15546686947345734
train-epoch-step: 39-394 -- Loss: 0.20008409023284912
train-epoch-step: 39-395 -- Loss: 0.1670929193496704
train-epoch-step: 39-396 -- Loss: 0.12786906957626343
train-epoch-step: 39-397 -- Loss: 0.12570348381996155
train-epoch-step: 39-398 -- Loss: 0.20982450246810913
train-epoch-step: 39-399 -- Loss: 0.17576873302459717
train-epoch-step: 39-400 -- Loss: 0.29444587230682373
train-epoch-step: 39-401 -- Loss: 0.11768883466720581
train-epoch-step: 39-402 -- Loss: 0.25924238562583923
train-epoch-step: 39-403 -- Loss: 0.15584903955459595
train-epoch-step: 39-404 -- Loss: 0.13606421649456024
train-epoch-step: 39-405 -- Loss: 0.14494626224040985
train-epoch-step: 39-406 -- Loss: 0.16931265592575073
train-epoch-step: 39-407 -- Loss: 0.11683633923530579
train-epoch-step: 39-408 -- Loss: 0.16429930925369263
train-epoch-step: 39-409 -- Loss: 0.18283474445343018
train-epoch-step: 39-410 -- Loss: 0.1756604164838791
train-epoch-step: 39-411 -- Loss: 0.20853571593761444
train-epoch-step: 39-412 -- Loss: 0.12938034534454346
train-epoch-step: 39-413 -- Loss: 0.1467447280883789
train-epoch-step: 39-414 -- Loss: 0.13691245019435883
train-epoch-step: 39-415 -- Loss: 0.1344960480928421
train-epoch-step: 39-416 -- Loss: 0.26662835478782654
train-epoch-step: 39-417 -- Loss: 0.18760880827903748
train-epoch-step: 39-418 -- Loss: 0.23179380595684052
train-epoch-step: 39-419 -- Loss: 0.16992664337158203
train-epoch-step: 39-420 -- Loss: 0.1532328575849533
train-epoch-step: 39-421 -- Loss: 0.19080998003482819
train-epoch-step: 39-422 -- Loss: 0.1508810967206955
train-epoch-step: 39-423 -- Loss: 0.17484891414642334
train-epoch-step: 39-424 -- Loss: 0.14097410440444946
train-epoch-step: 39-425 -- Loss: 0.18597732484340668
train-epoch-step: 39-426 -- Loss: 0.16280202567577362
train-epoch-step: 39-427 -- Loss: 0.12171349674463272
train-epoch-step: 39-428 -- Loss: 0.2002730816602707
train-epoch-step: 39-429 -- Loss: 0.17614635825157166
train-epoch-step: 39-430 -- Loss: 0.13943609595298767
train-epoch-step: 39-431 -- Loss: 0.1627780795097351
train-epoch-step: 39-432 -- Loss: 0.24698024988174438
train-epoch-step: 39-433 -- Loss: 0.13526146113872528
train-epoch-step: 39-434 -- Loss: 0.13550658524036407
train-epoch-step: 39-435 -- Loss: 0.15662787854671478
train-epoch-step: 39-436 -- Loss: 0.15753546357154846
train-epoch-step: 39-437 -- Loss: 0.1325961947441101
train-epoch-step: 39-438 -- Loss: 0.1657850295305252
train-epoch-step: 39-439 -- Loss: 0.2672470510005951
train-epoch-step: 39-440 -- Loss: 0.1300518959760666
train-epoch-step: 39-441 -- Loss: 0.21142011880874634
train-epoch-step: 39-442 -- Loss: 0.17864909768104553
train-epoch-step: 39-443 -- Loss: 0.14938683807849884
train-epoch-step: 39-444 -- Loss: 0.17767807841300964
train-epoch-step: 39-445 -- Loss: 0.180159330368042
train-epoch-step: 39-446 -- Loss: 0.15404321253299713
train-epoch-step: 39-447 -- Loss: 0.19227714836597443
train-epoch-step: 39-448 -- Loss: 0.2274964302778244
train-epoch-step: 39-449 -- Loss: 0.18967574834823608
train-epoch-step: 39-450 -- Loss: 0.1804516762495041
train-epoch-step: 39-451 -- Loss: 0.14431391656398773
train-epoch-step: 39-452 -- Loss: 0.12949949502944946
train-epoch-step: 39-453 -- Loss: 0.09160404652357101
train-epoch-step: 39-454 -- Loss: 0.22914926707744598
train-epoch-step: 39-455 -- Loss: 0.12486084550619125
train-epoch-step: 39-456 -- Loss: 0.11778141558170319
train-epoch-step: 39-457 -- Loss: 0.21530286967754364
train-epoch-step: 39-458 -- Loss: 0.15072502195835114
train-epoch-step: 39-459 -- Loss: 0.21546947956085205
train-epoch-step: 39-460 -- Loss: 0.12993931770324707
train-epoch-step: 39-461 -- Loss: 0.13210177421569824
train-epoch-step: 39-462 -- Loss: 0.16201937198638916
train-epoch-step: 39-463 -- Loss: 0.13316401839256287
train-epoch-step: 39-464 -- Loss: 0.16101433336734772
train-epoch-step: 39-465 -- Loss: 0.23547159135341644
train-epoch-step: 39-466 -- Loss: 0.19887883961200714
train-epoch-step: 39-467 -- Loss: 0.11349974572658539
train-epoch-step: 39-468 -- Loss: 0.16745693981647491
train-epoch-step: 39-469 -- Loss: 0.21092680096626282
train-epoch-step: 39-470 -- Loss: 0.17078828811645508
train-epoch-step: 39-471 -- Loss: 0.16268253326416016
train-epoch-step: 39-472 -- Loss: 0.15994566679000854
train-epoch-step: 39-473 -- Loss: 0.1482832133769989
train-epoch-step: 39-474 -- Loss: 0.11436961591243744
train-epoch-step: 39-475 -- Loss: 0.10923045873641968
train-epoch-step: 39-476 -- Loss: 0.19877533614635468
train-epoch-step: 39-477 -- Loss: 0.19941802322864532
train-epoch-step: 39-478 -- Loss: 0.18616646528244019
train-epoch-step: 39-479 -- Loss: 0.13809867203235626
train-epoch-step: 39-480 -- Loss: 0.19740493595600128
train-epoch-step: 39-481 -- Loss: 0.283224880695343
train-epoch-step: 39-482 -- Loss: 0.24946945905685425
train-epoch-step: 39-483 -- Loss: 0.17402642965316772
train-epoch-step: 39-484 -- Loss: 0.21152833104133606
train-epoch-step: 39-485 -- Loss: 0.12627413868904114
train-epoch-step: 39-486 -- Loss: 0.22863321006298065
train-epoch-step: 39-487 -- Loss: 0.23115287721157074
train-epoch-step: 39-488 -- Loss: 0.1969759166240692
train-epoch-step: 39-489 -- Loss: 0.21762877702713013
train-epoch-step: 39-490 -- Loss: 0.1342548429965973
train-epoch-step: 39-491 -- Loss: 0.13408082723617554
train-epoch-step: 39-492 -- Loss: 0.12299426645040512
train-epoch-step: 39-493 -- Loss: 0.1993497610092163
train-epoch-step: 39-494 -- Loss: 0.1986178755760193
train-epoch-step: 39-495 -- Loss: 0.20139378309249878
train-epoch-step: 39-496 -- Loss: 0.13906066119670868
train-epoch-step: 39-497 -- Loss: 0.18048620223999023
train-epoch-step: 39-498 -- Loss: 0.14355991780757904
train-epoch-step: 39-499 -- Loss: 0.16574645042419434
train-epoch-step: 39-500 -- Loss: 0.15520593523979187
train-epoch-step: 39-501 -- Loss: 0.21420133113861084
train-epoch-step: 39-502 -- Loss: 0.1581149846315384
train-epoch-step: 39-503 -- Loss: 0.21318486332893372
train-epoch-step: 39-504 -- Loss: 0.11671744287014008
train-epoch-step: 39-505 -- Loss: 0.16938132047653198
train-epoch-step: 39-506 -- Loss: 0.11507300287485123
train-epoch-step: 39-507 -- Loss: 0.17817577719688416
train-epoch-step: 39-508 -- Loss: 0.17196869850158691
train-epoch-step: 39-509 -- Loss: 0.16987159848213196
train-epoch-step: 39-510 -- Loss: 0.12493649870157242
train-epoch-step: 39-511 -- Loss: 0.21287521719932556
train-epoch-step: 39-512 -- Loss: 0.17537902295589447
train-epoch-step: 39-513 -- Loss: 0.18165791034698486
train-epoch-step: 39-514 -- Loss: 0.1457851529121399
train-epoch-step: 39-515 -- Loss: 0.1528923064470291
train-epoch-step: 39-516 -- Loss: 0.16939479112625122
train-epoch-step: 39-517 -- Loss: 0.17241862416267395
train-epoch-step: 39-518 -- Loss: 0.13771596550941467
train-epoch-step: 39-519 -- Loss: 0.13585837185382843
train-epoch-step: 39-520 -- Loss: 0.1817464679479599
train-epoch-step: 39-521 -- Loss: 0.22665521502494812
train-epoch-step: 39-522 -- Loss: 0.1808909773826599
train-epoch-step: 39-523 -- Loss: 0.15693189203739166
train-epoch-step: 39-524 -- Loss: 0.16846129298210144
train-epoch-step: 39-525 -- Loss: 0.1853911578655243
train-epoch-step: 39-526 -- Loss: 0.12755349278450012
train-epoch-step: 39-527 -- Loss: 0.15005291998386383
train-epoch-step: 39-528 -- Loss: 0.1562766134738922
train-epoch-step: 39-529 -- Loss: 0.15653322637081146
train-epoch-step: 39-530 -- Loss: 0.16445206105709076
train-epoch-step: 39-531 -- Loss: 0.19938015937805176
train-epoch-step: 39-532 -- Loss: 0.1661112755537033
train-epoch-step: 39-533 -- Loss: 0.17471688985824585
train-epoch-step: 39-534 -- Loss: 0.12787434458732605
train-epoch-step: 39-535 -- Loss: 0.2555167078971863
train-epoch-step: 39-536 -- Loss: 0.1555626392364502
train-epoch-step: 39-537 -- Loss: 0.14519034326076508
train-epoch-step: 39-538 -- Loss: 0.10601916909217834
train-epoch-step: 39-539 -- Loss: 0.18325895071029663
train-epoch-step: 39-540 -- Loss: 0.1466274857521057
train-epoch-step: 39-541 -- Loss: 0.20897749066352844
train-epoch-step: 39-542 -- Loss: 0.2163510024547577
train-epoch-step: 39-543 -- Loss: 0.1675986796617508
train-epoch-step: 39-544 -- Loss: 0.227634996175766
train-epoch-step: 39-545 -- Loss: 0.19673967361450195
train-epoch-step: 39-546 -- Loss: 0.21308386325836182
train-epoch-step: 39-547 -- Loss: 0.17651396989822388
train-epoch-step: 39-548 -- Loss: 0.09538544714450836
train-epoch-step: 39-549 -- Loss: 0.1538657248020172
train-epoch-step: 39-550 -- Loss: 0.20362421870231628
train-epoch-step: 39-551 -- Loss: 0.1558331400156021
train-epoch-step: 39-552 -- Loss: 0.12263378500938416
train-epoch-step: 39-553 -- Loss: 0.18757706880569458
train-epoch-step: 39-554 -- Loss: 0.18409046530723572
train-epoch-step: 39-555 -- Loss: 0.2103266417980194
train-epoch-step: 39-556 -- Loss: 0.14194701611995697
train-epoch-step: 39-557 -- Loss: 0.23721234500408173
train-epoch-step: 39-558 -- Loss: 0.227471262216568
train-epoch-step: 39-559 -- Loss: 0.13806268572807312
train-epoch-step: 39-560 -- Loss: 0.20322401821613312
train-epoch-step: 39-561 -- Loss: 0.18462589383125305
train-epoch-step: 39-562 -- Loss: 0.16302886605262756
train-epoch-step: 39-563 -- Loss: 0.18335671722888947
train-epoch-step: 39-564 -- Loss: 0.10115957260131836
train-epoch-step: 39-565 -- Loss: 0.18310749530792236
train-epoch-step: 39-566 -- Loss: 0.14934274554252625
train-epoch-step: 39-567 -- Loss: 0.20947903394699097
train-epoch-step: 39-568 -- Loss: 0.15988461673259735
train-epoch-step: 39-569 -- Loss: 0.2377275824546814
train-epoch-step: 39-570 -- Loss: 0.16257113218307495
train-epoch-step: 39-571 -- Loss: 0.2106788456439972
train-epoch-step: 39-572 -- Loss: 0.23020000755786896
train-epoch-step: 39-573 -- Loss: 0.19544506072998047
train-epoch-step: 39-574 -- Loss: 0.2495819628238678
train-epoch-step: 39-575 -- Loss: 0.28725606203079224
train-epoch-step: 39-576 -- Loss: 0.11794150620698929
train-epoch-step: 39-577 -- Loss: 0.167608380317688
train-epoch-step: 39-578 -- Loss: 0.21624816954135895
train-epoch-step: 39-579 -- Loss: 0.16042183339595795
train-epoch-step: 39-580 -- Loss: 0.1794251948595047
train-epoch-step: 39-581 -- Loss: 0.1501394361257553
train-epoch-step: 39-582 -- Loss: 0.20422889292240143
train-epoch-step: 39-583 -- Loss: 0.21089106798171997
train-epoch-step: 39-584 -- Loss: 0.1617678701877594
train-epoch-step: 39-585 -- Loss: 0.19044016301631927
train-epoch-step: 39-586 -- Loss: 0.2535337805747986
train-epoch-step: 39-587 -- Loss: 0.15844416618347168
train-epoch-step: 39-588 -- Loss: 0.12875378131866455
val-epoch-step: 39-589 -- Loss: 0.1977805644273758
val-epoch-step: 39-590 -- Loss: 0.15237389504909515
val-epoch-step: 39-591 -- Loss: 0.22644010186195374
val-epoch-step: 39-592 -- Loss: 0.17855289578437805
val-epoch-step: 39-593 -- Loss: 0.17090362310409546
val-epoch-step: 39-594 -- Loss: 0.3822963833808899
val-epoch-step: 39-595 -- Loss: 0.17947085201740265
val-epoch-step: 39-596 -- Loss: 0.19247333705425262
val-epoch-step: 39-597 -- Loss: 0.17599010467529297
val-epoch-step: 39-598 -- Loss: 0.14825235307216644
val-epoch-step: 39-599 -- Loss: 0.19504638016223907
val-epoch-step: 39-600 -- Loss: 0.23843324184417725
val-epoch-step: 39-601 -- Loss: 0.15908695757389069
val-epoch-step: 39-602 -- Loss: 0.13574668765068054
val-epoch-step: 39-603 -- Loss: 0.18454940617084503
val-epoch-step: 39-604 -- Loss: 0.1430572271347046
val-epoch-step: 39-605 -- Loss: 0.14366298913955688
val-epoch-step: 39-606 -- Loss: 0.2691659927368164
val-epoch-step: 39-607 -- Loss: 0.13006532192230225
val-epoch-step: 39-608 -- Loss: 0.24428075551986694
val-epoch-step: 39-609 -- Loss: 0.16610297560691833
val-epoch-step: 39-610 -- Loss: 0.1819147765636444
val-epoch-step: 39-611 -- Loss: 0.17267832159996033
val-epoch-step: 39-612 -- Loss: 0.48416388034820557
val-epoch-step: 39-613 -- Loss: 0.1757725328207016
val-epoch-step: 39-614 -- Loss: 0.1672597974538803
val-epoch-step: 39-615 -- Loss: 0.17623376846313477
val-epoch-step: 39-616 -- Loss: 0.15290893614292145
val-epoch-step: 39-617 -- Loss: 0.1823319047689438
val-epoch-step: 39-618 -- Loss: 0.18442770838737488
val-epoch-step: 39-619 -- Loss: 0.22022196650505066
val-epoch-step: 39-620 -- Loss: 0.13855968415737152
val-epoch-step: 39-621 -- Loss: 0.12471188604831696
val-epoch-step: 39-622 -- Loss: 0.14150379598140717
val-epoch-step: 39-623 -- Loss: 0.14784634113311768
val-epoch-step: 39-624 -- Loss: 0.1394980400800705
val-epoch-step: 39-625 -- Loss: 0.15291425585746765
val-epoch-step: 39-626 -- Loss: 0.14716565608978271
val-epoch-step: 39-627 -- Loss: 0.18125224113464355
val-epoch-step: 39-628 -- Loss: 0.646399736404419
val-epoch-step: 39-629 -- Loss: 0.20362582802772522
val-epoch-step: 39-630 -- Loss: 0.3451415002346039
val-epoch-step: 39-631 -- Loss: 0.14336560666561127
val-epoch-step: 39-632 -- Loss: 0.2191380113363266
val-epoch-step: 39-633 -- Loss: 0.14901778101921082
val-epoch-step: 39-634 -- Loss: 0.1562289595603943
val-epoch-step: 39-635 -- Loss: 0.11468370258808136
val-epoch-step: 39-636 -- Loss: 0.16793882846832275
val-epoch-step: 39-637 -- Loss: 0.17754417657852173
val-epoch-step: 39-638 -- Loss: 0.1444002091884613
val-epoch-step: 39-639 -- Loss: 0.2511993646621704
val-epoch-step: 39-640 -- Loss: 0.25130510330200195
val-epoch-step: 39-641 -- Loss: 0.1242847889661789
val-epoch-step: 39-642 -- Loss: 0.18338653445243835
val-epoch-step: 39-643 -- Loss: 0.21174311637878418
val-epoch-step: 39-644 -- Loss: 0.16869640350341797
val-epoch-step: 39-645 -- Loss: 0.22079752385616302
val-epoch-step: 39-646 -- Loss: 0.13440702855587006
val-epoch-step: 39-647 -- Loss: 0.13365566730499268
val-epoch-step: 39-648 -- Loss: 0.15654967725276947
val-epoch-step: 39-649 -- Loss: 0.20502081513404846
val-epoch-step: 39-650 -- Loss: 0.25075942277908325
val-epoch-step: 39-651 -- Loss: 0.14532195031642914
val-epoch-step: 39-652 -- Loss: 0.15540970861911774
val-epoch-step: 39-653 -- Loss: 0.20816519856452942
val-epoch-step: 39-654 -- Loss: 0.11574997007846832
Epoch: 39 -- Train Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 40-0 -- Loss: 0.21906830370426178
train-epoch-step: 40-1 -- Loss: 0.13920322060585022
train-epoch-step: 40-2 -- Loss: 0.2002267837524414
train-epoch-step: 40-3 -- Loss: 0.14821872115135193
train-epoch-step: 40-4 -- Loss: 0.15954314172267914
train-epoch-step: 40-5 -- Loss: 0.1771751344203949
train-epoch-step: 40-6 -- Loss: 0.22025077044963837
train-epoch-step: 40-7 -- Loss: 0.1622936874628067
train-epoch-step: 40-8 -- Loss: 0.17856955528259277
train-epoch-step: 40-9 -- Loss: 0.22694014012813568
train-epoch-step: 40-10 -- Loss: 0.189809650182724
train-epoch-step: 40-11 -- Loss: 0.17384570837020874
train-epoch-step: 40-12 -- Loss: 0.14970728754997253
train-epoch-step: 40-13 -- Loss: 0.17543236911296844
train-epoch-step: 40-14 -- Loss: 0.1604306995868683
train-epoch-step: 40-15 -- Loss: 0.15775896608829498
train-epoch-step: 40-16 -- Loss: 0.1635403335094452
train-epoch-step: 40-17 -- Loss: 0.21442432701587677
train-epoch-step: 40-18 -- Loss: 0.19080960750579834
train-epoch-step: 40-19 -- Loss: 0.13244330883026123
train-epoch-step: 40-20 -- Loss: 0.21116825938224792
train-epoch-step: 40-21 -- Loss: 0.24911794066429138
train-epoch-step: 40-22 -- Loss: 0.13591443002223969
train-epoch-step: 40-23 -- Loss: 0.1437031775712967
train-epoch-step: 40-24 -- Loss: 0.12690062820911407
train-epoch-step: 40-25 -- Loss: 0.22062216699123383
train-epoch-step: 40-26 -- Loss: 0.19131368398666382
train-epoch-step: 40-27 -- Loss: 0.22797814011573792
train-epoch-step: 40-28 -- Loss: 0.12204572558403015
train-epoch-step: 40-29 -- Loss: 0.2470366209745407
train-epoch-step: 40-30 -- Loss: 0.10712428390979767
train-epoch-step: 40-31 -- Loss: 0.13604730367660522
train-epoch-step: 40-32 -- Loss: 0.17059673368930817
train-epoch-step: 40-33 -- Loss: 0.26559996604919434
train-epoch-step: 40-34 -- Loss: 0.16391311585903168
train-epoch-step: 40-35 -- Loss: 0.23819881677627563
train-epoch-step: 40-36 -- Loss: 0.13689035177230835
train-epoch-step: 40-37 -- Loss: 0.14033180475234985
train-epoch-step: 40-38 -- Loss: 0.16914933919906616
train-epoch-step: 40-39 -- Loss: 0.21783053874969482
train-epoch-step: 40-40 -- Loss: 0.1958845853805542
train-epoch-step: 40-41 -- Loss: 0.21445205807685852
train-epoch-step: 40-42 -- Loss: 0.14352595806121826
train-epoch-step: 40-43 -- Loss: 0.2554396688938141
train-epoch-step: 40-44 -- Loss: 0.12192581593990326
train-epoch-step: 40-45 -- Loss: 0.1260223090648651
train-epoch-step: 40-46 -- Loss: 0.16989006102085114
train-epoch-step: 40-47 -- Loss: 0.20924115180969238
train-epoch-step: 40-48 -- Loss: 0.15311361849308014
train-epoch-step: 40-49 -- Loss: 0.22321808338165283
train-epoch-step: 40-50 -- Loss: 0.11052077263593674
train-epoch-step: 40-51 -- Loss: 0.17246438562870026
train-epoch-step: 40-52 -- Loss: 0.1537781059741974
train-epoch-step: 40-53 -- Loss: 0.20904994010925293
train-epoch-step: 40-54 -- Loss: 0.2806263864040375
train-epoch-step: 40-55 -- Loss: 0.17222252488136292
train-epoch-step: 40-56 -- Loss: 0.1716402918100357
train-epoch-step: 40-57 -- Loss: 0.24052411317825317
train-epoch-step: 40-58 -- Loss: 0.29511767625808716
train-epoch-step: 40-59 -- Loss: 0.2711543142795563
train-epoch-step: 40-60 -- Loss: 0.1279209554195404
train-epoch-step: 40-61 -- Loss: 0.19857998192310333
train-epoch-step: 40-62 -- Loss: 0.1820286512374878
train-epoch-step: 40-63 -- Loss: 0.13912056386470795
train-epoch-step: 40-64 -- Loss: 0.14803750813007355
train-epoch-step: 40-65 -- Loss: 0.1827937662601471
train-epoch-step: 40-66 -- Loss: 0.11210892349481583
train-epoch-step: 40-67 -- Loss: 0.12840932607650757
train-epoch-step: 40-68 -- Loss: 0.21844974160194397
train-epoch-step: 40-69 -- Loss: 0.12246197462081909
train-epoch-step: 40-70 -- Loss: 0.22859397530555725
train-epoch-step: 40-71 -- Loss: 0.26245006918907166
train-epoch-step: 40-72 -- Loss: 0.17211639881134033
train-epoch-step: 40-73 -- Loss: 0.21085089445114136
train-epoch-step: 40-74 -- Loss: 0.09577752649784088
train-epoch-step: 40-75 -- Loss: 0.12800289690494537
train-epoch-step: 40-76 -- Loss: 0.14475789666175842
train-epoch-step: 40-77 -- Loss: 0.22403882443904877
train-epoch-step: 40-78 -- Loss: 0.2557280361652374
train-epoch-step: 40-79 -- Loss: 0.18748432397842407
train-epoch-step: 40-80 -- Loss: 0.2511384189128876
train-epoch-step: 40-81 -- Loss: 0.12619498372077942
train-epoch-step: 40-82 -- Loss: 0.24863700568675995
train-epoch-step: 40-83 -- Loss: 0.17837178707122803
train-epoch-step: 40-84 -- Loss: 0.18742410838603973
train-epoch-step: 40-85 -- Loss: 0.1803330034017563
train-epoch-step: 40-86 -- Loss: 0.1163221225142479
train-epoch-step: 40-87 -- Loss: 0.20963209867477417
train-epoch-step: 40-88 -- Loss: 0.1384095847606659
train-epoch-step: 40-89 -- Loss: 0.18557623028755188
train-epoch-step: 40-90 -- Loss: 0.1898052990436554
train-epoch-step: 40-91 -- Loss: 0.24542202055454254
train-epoch-step: 40-92 -- Loss: 0.15472325682640076
train-epoch-step: 40-93 -- Loss: 0.16823908686637878
train-epoch-step: 40-94 -- Loss: 0.21563483774662018
train-epoch-step: 40-95 -- Loss: 0.18327969312667847
train-epoch-step: 40-96 -- Loss: 0.21353287994861603
train-epoch-step: 40-97 -- Loss: 0.1776500940322876
train-epoch-step: 40-98 -- Loss: 0.1537041962146759
train-epoch-step: 40-99 -- Loss: 0.17876295745372772
train-epoch-step: 40-100 -- Loss: 0.18716932833194733
train-epoch-step: 40-101 -- Loss: 0.27690714597702026
train-epoch-step: 40-102 -- Loss: 0.22206132113933563
train-epoch-step: 40-103 -- Loss: 0.18373489379882812
train-epoch-step: 40-104 -- Loss: 0.1482325941324234
train-epoch-step: 40-105 -- Loss: 0.25861817598342896
train-epoch-step: 40-106 -- Loss: 0.17128045856952667
train-epoch-step: 40-107 -- Loss: 0.18322409689426422
train-epoch-step: 40-108 -- Loss: 0.18866464495658875
train-epoch-step: 40-109 -- Loss: 0.15457552671432495
train-epoch-step: 40-110 -- Loss: 0.17863264679908752
train-epoch-step: 40-111 -- Loss: 0.1752624809741974
train-epoch-step: 40-112 -- Loss: 0.15875530242919922
train-epoch-step: 40-113 -- Loss: 0.1611887812614441
train-epoch-step: 40-114 -- Loss: 0.19613595306873322
train-epoch-step: 40-115 -- Loss: 0.16361263394355774
train-epoch-step: 40-116 -- Loss: 0.13931703567504883
train-epoch-step: 40-117 -- Loss: 0.12531453371047974
train-epoch-step: 40-118 -- Loss: 0.1930762231349945
train-epoch-step: 40-119 -- Loss: 0.15053004026412964
train-epoch-step: 40-120 -- Loss: 0.24499541521072388
train-epoch-step: 40-121 -- Loss: 0.24533583223819733
train-epoch-step: 40-122 -- Loss: 0.21762125194072723
train-epoch-step: 40-123 -- Loss: 0.19681525230407715
train-epoch-step: 40-124 -- Loss: 0.12086242437362671
train-epoch-step: 40-125 -- Loss: 0.16097459197044373
train-epoch-step: 40-126 -- Loss: 0.22522519528865814
train-epoch-step: 40-127 -- Loss: 0.174640491604805
train-epoch-step: 40-128 -- Loss: 0.16996873915195465
train-epoch-step: 40-129 -- Loss: 0.14308208227157593
train-epoch-step: 40-130 -- Loss: 0.18467099964618683
train-epoch-step: 40-131 -- Loss: 0.1363404095172882
train-epoch-step: 40-132 -- Loss: 0.18772457540035248
train-epoch-step: 40-133 -- Loss: 0.1134568527340889
train-epoch-step: 40-134 -- Loss: 0.19270621240139008
train-epoch-step: 40-135 -- Loss: 0.1327301561832428
train-epoch-step: 40-136 -- Loss: 0.12777741253376007
train-epoch-step: 40-137 -- Loss: 0.23972934484481812
train-epoch-step: 40-138 -- Loss: 0.26652979850769043
train-epoch-step: 40-139 -- Loss: 0.1284390091896057
train-epoch-step: 40-140 -- Loss: 0.20876619219779968
train-epoch-step: 40-141 -- Loss: 0.22952687740325928
train-epoch-step: 40-142 -- Loss: 0.20277968049049377
train-epoch-step: 40-143 -- Loss: 0.17156405746936798
train-epoch-step: 40-144 -- Loss: 0.19042611122131348
train-epoch-step: 40-145 -- Loss: 0.1402105838060379
train-epoch-step: 40-146 -- Loss: 0.17785707116127014
train-epoch-step: 40-147 -- Loss: 0.16944684088230133
train-epoch-step: 40-148 -- Loss: 0.15439154207706451
train-epoch-step: 40-149 -- Loss: 0.11868017166852951
train-epoch-step: 40-150 -- Loss: 0.18037505447864532
train-epoch-step: 40-151 -- Loss: 0.206048384308815
train-epoch-step: 40-152 -- Loss: 0.18697313964366913
train-epoch-step: 40-153 -- Loss: 0.2707480490207672
train-epoch-step: 40-154 -- Loss: 0.1300702840089798
train-epoch-step: 40-155 -- Loss: 0.1329803466796875
train-epoch-step: 40-156 -- Loss: 0.11576583981513977
train-epoch-step: 40-157 -- Loss: 0.19246363639831543
train-epoch-step: 40-158 -- Loss: 0.16468282043933868
train-epoch-step: 40-159 -- Loss: 0.17926762998104095
train-epoch-step: 40-160 -- Loss: 0.21465575695037842
train-epoch-step: 40-161 -- Loss: 0.20247013866901398
train-epoch-step: 40-162 -- Loss: 0.206034317612648
train-epoch-step: 40-163 -- Loss: 0.18754084408283234
train-epoch-step: 40-164 -- Loss: 0.19127097725868225
train-epoch-step: 40-165 -- Loss: 0.1624714434146881
train-epoch-step: 40-166 -- Loss: 0.12166193127632141
train-epoch-step: 40-167 -- Loss: 0.12938225269317627
train-epoch-step: 40-168 -- Loss: 0.20210479199886322
train-epoch-step: 40-169 -- Loss: 0.13554394245147705
train-epoch-step: 40-170 -- Loss: 0.1976255625486374
train-epoch-step: 40-171 -- Loss: 0.1437932848930359
train-epoch-step: 40-172 -- Loss: 0.2542088031768799
train-epoch-step: 40-173 -- Loss: 0.14185047149658203
train-epoch-step: 40-174 -- Loss: 0.25733309984207153
train-epoch-step: 40-175 -- Loss: 0.18671736121177673
train-epoch-step: 40-176 -- Loss: 0.12836366891860962
train-epoch-step: 40-177 -- Loss: 0.18092601001262665
train-epoch-step: 40-178 -- Loss: 0.1755702644586563
train-epoch-step: 40-179 -- Loss: 0.1494850069284439
train-epoch-step: 40-180 -- Loss: 0.15548445284366608
train-epoch-step: 40-181 -- Loss: 0.16531144082546234
train-epoch-step: 40-182 -- Loss: 0.1772187352180481
train-epoch-step: 40-183 -- Loss: 0.26813986897468567
train-epoch-step: 40-184 -- Loss: 0.13705962896347046
train-epoch-step: 40-185 -- Loss: 0.14226341247558594
train-epoch-step: 40-186 -- Loss: 0.18881675601005554
train-epoch-step: 40-187 -- Loss: 0.20787544548511505
train-epoch-step: 40-188 -- Loss: 0.17764556407928467
train-epoch-step: 40-189 -- Loss: 0.1048223152756691
train-epoch-step: 40-190 -- Loss: 0.1809944361448288
train-epoch-step: 40-191 -- Loss: 0.16151270270347595
train-epoch-step: 40-192 -- Loss: 0.23391428589820862
train-epoch-step: 40-193 -- Loss: 0.2028503119945526
train-epoch-step: 40-194 -- Loss: 0.18346919119358063
train-epoch-step: 40-195 -- Loss: 0.1645985096693039
train-epoch-step: 40-196 -- Loss: 0.16569359600543976
train-epoch-step: 40-197 -- Loss: 0.13059723377227783
train-epoch-step: 40-198 -- Loss: 0.1254652738571167
train-epoch-step: 40-199 -- Loss: 0.1460403949022293
train-epoch-step: 40-200 -- Loss: 0.12206175923347473
train-epoch-step: 40-201 -- Loss: 0.1898798942565918
train-epoch-step: 40-202 -- Loss: 0.1361304074525833
train-epoch-step: 40-203 -- Loss: 0.1728484183549881
train-epoch-step: 40-204 -- Loss: 0.13649050891399384
train-epoch-step: 40-205 -- Loss: 0.18323354423046112
train-epoch-step: 40-206 -- Loss: 0.199560284614563
train-epoch-step: 40-207 -- Loss: 0.13262765109539032
train-epoch-step: 40-208 -- Loss: 0.1729140728712082
train-epoch-step: 40-209 -- Loss: 0.14556020498275757
train-epoch-step: 40-210 -- Loss: 0.13419266045093536
train-epoch-step: 40-211 -- Loss: 0.20601044595241547
train-epoch-step: 40-212 -- Loss: 0.20108841359615326
train-epoch-step: 40-213 -- Loss: 0.12673160433769226
train-epoch-step: 40-214 -- Loss: 0.1498514711856842
train-epoch-step: 40-215 -- Loss: 0.12719354033470154
train-epoch-step: 40-216 -- Loss: 0.20739266276359558
train-epoch-step: 40-217 -- Loss: 0.20876756310462952
train-epoch-step: 40-218 -- Loss: 0.1453566998243332
train-epoch-step: 40-219 -- Loss: 0.17166820168495178
train-epoch-step: 40-220 -- Loss: 0.12777096033096313
train-epoch-step: 40-221 -- Loss: 0.20617739856243134
train-epoch-step: 40-222 -- Loss: 0.11662157624959946
train-epoch-step: 40-223 -- Loss: 0.17562951147556305
train-epoch-step: 40-224 -- Loss: 0.19282463192939758
train-epoch-step: 40-225 -- Loss: 0.29016345739364624
train-epoch-step: 40-226 -- Loss: 0.20728237926959991
train-epoch-step: 40-227 -- Loss: 0.22299127280712128
train-epoch-step: 40-228 -- Loss: 0.17864163219928741
train-epoch-step: 40-229 -- Loss: 0.17315170168876648
train-epoch-step: 40-230 -- Loss: 0.16486549377441406
train-epoch-step: 40-231 -- Loss: 0.15674495697021484
train-epoch-step: 40-232 -- Loss: 0.18947406113147736
train-epoch-step: 40-233 -- Loss: 0.09070253372192383
train-epoch-step: 40-234 -- Loss: 0.17265412211418152
train-epoch-step: 40-235 -- Loss: 0.154403418302536
train-epoch-step: 40-236 -- Loss: 0.18368561565876007
train-epoch-step: 40-237 -- Loss: 0.24164360761642456
train-epoch-step: 40-238 -- Loss: 0.16011202335357666
train-epoch-step: 40-239 -- Loss: 0.1269250512123108
train-epoch-step: 40-240 -- Loss: 0.2202882319688797
train-epoch-step: 40-241 -- Loss: 0.15135982632637024
train-epoch-step: 40-242 -- Loss: 0.2211344987154007
train-epoch-step: 40-243 -- Loss: 0.23445016145706177
train-epoch-step: 40-244 -- Loss: 0.2039310336112976
train-epoch-step: 40-245 -- Loss: 0.21305304765701294
train-epoch-step: 40-246 -- Loss: 0.22283679246902466
train-epoch-step: 40-247 -- Loss: 0.2160501629114151
train-epoch-step: 40-248 -- Loss: 0.18342968821525574
train-epoch-step: 40-249 -- Loss: 0.1380988359451294
train-epoch-step: 40-250 -- Loss: 0.20162644982337952
train-epoch-step: 40-251 -- Loss: 0.10648512840270996
train-epoch-step: 40-252 -- Loss: 0.19227969646453857
train-epoch-step: 40-253 -- Loss: 0.13714344799518585
train-epoch-step: 40-254 -- Loss: 0.21286089718341827
train-epoch-step: 40-255 -- Loss: 0.146589994430542
train-epoch-step: 40-256 -- Loss: 0.1442517638206482
train-epoch-step: 40-257 -- Loss: 0.1920073926448822
train-epoch-step: 40-258 -- Loss: 0.1427949070930481
train-epoch-step: 40-259 -- Loss: 0.11353293061256409
train-epoch-step: 40-260 -- Loss: 0.21012218296527863
train-epoch-step: 40-261 -- Loss: 0.16733431816101074
train-epoch-step: 40-262 -- Loss: 0.30660831928253174
train-epoch-step: 40-263 -- Loss: 0.1950913667678833
train-epoch-step: 40-264 -- Loss: 0.16923758387565613
train-epoch-step: 40-265 -- Loss: 0.12041278183460236
train-epoch-step: 40-266 -- Loss: 0.15665143728256226
train-epoch-step: 40-267 -- Loss: 0.13339467346668243
train-epoch-step: 40-268 -- Loss: 0.11644607037305832
train-epoch-step: 40-269 -- Loss: 0.16863858699798584
train-epoch-step: 40-270 -- Loss: 0.1069241464138031
train-epoch-step: 40-271 -- Loss: 0.16959863901138306
train-epoch-step: 40-272 -- Loss: 0.11989407241344452
train-epoch-step: 40-273 -- Loss: 0.12619507312774658
train-epoch-step: 40-274 -- Loss: 0.18417444825172424
train-epoch-step: 40-275 -- Loss: 0.19725412130355835
train-epoch-step: 40-276 -- Loss: 0.15774738788604736
train-epoch-step: 40-277 -- Loss: 0.15773889422416687
train-epoch-step: 40-278 -- Loss: 0.13816465437412262
train-epoch-step: 40-279 -- Loss: 0.14360575377941132
train-epoch-step: 40-280 -- Loss: 0.21501269936561584
train-epoch-step: 40-281 -- Loss: 0.17797093093395233
train-epoch-step: 40-282 -- Loss: 0.14149081707000732
train-epoch-step: 40-283 -- Loss: 0.12107126414775848
train-epoch-step: 40-284 -- Loss: 0.13735820353031158
train-epoch-step: 40-285 -- Loss: 0.20111989974975586
train-epoch-step: 40-286 -- Loss: 0.15441855788230896
train-epoch-step: 40-287 -- Loss: 0.2014998197555542
train-epoch-step: 40-288 -- Loss: 0.0947037786245346
train-epoch-step: 40-289 -- Loss: 0.11955121159553528
train-epoch-step: 40-290 -- Loss: 0.17701713740825653
train-epoch-step: 40-291 -- Loss: 0.11711757630109787
train-epoch-step: 40-292 -- Loss: 0.15416082739830017
train-epoch-step: 40-293 -- Loss: 0.14013049006462097
train-epoch-step: 40-294 -- Loss: 0.16021728515625
train-epoch-step: 40-295 -- Loss: 0.262409508228302
train-epoch-step: 40-296 -- Loss: 0.15741728246212006
train-epoch-step: 40-297 -- Loss: 0.16978417336940765
train-epoch-step: 40-298 -- Loss: 0.23016315698623657
train-epoch-step: 40-299 -- Loss: 0.14857614040374756
train-epoch-step: 40-300 -- Loss: 0.1798909306526184
train-epoch-step: 40-301 -- Loss: 0.1761753261089325
train-epoch-step: 40-302 -- Loss: 0.2152177393436432
train-epoch-step: 40-303 -- Loss: 0.203303262591362
train-epoch-step: 40-304 -- Loss: 0.1284923553466797
train-epoch-step: 40-305 -- Loss: 0.1481015980243683
train-epoch-step: 40-306 -- Loss: 0.22017428278923035
train-epoch-step: 40-307 -- Loss: 0.17116554081439972
train-epoch-step: 40-308 -- Loss: 0.21655403077602386
train-epoch-step: 40-309 -- Loss: 0.15515650808811188
train-epoch-step: 40-310 -- Loss: 0.16229179501533508
train-epoch-step: 40-311 -- Loss: 0.1612146645784378
train-epoch-step: 40-312 -- Loss: 0.20128561556339264
train-epoch-step: 40-313 -- Loss: 0.09460677951574326
train-epoch-step: 40-314 -- Loss: 0.19075366854667664
train-epoch-step: 40-315 -- Loss: 0.16435600817203522
train-epoch-step: 40-316 -- Loss: 0.15248557925224304
train-epoch-step: 40-317 -- Loss: 0.1399325579404831
train-epoch-step: 40-318 -- Loss: 0.15872514247894287
train-epoch-step: 40-319 -- Loss: 0.16614852845668793
train-epoch-step: 40-320 -- Loss: 0.1268709897994995
train-epoch-step: 40-321 -- Loss: 0.12812042236328125
train-epoch-step: 40-322 -- Loss: 0.20848077535629272
train-epoch-step: 40-323 -- Loss: 0.15828242897987366
train-epoch-step: 40-324 -- Loss: 0.2563956379890442
train-epoch-step: 40-325 -- Loss: 0.15145869553089142
train-epoch-step: 40-326 -- Loss: 0.16965532302856445
train-epoch-step: 40-327 -- Loss: 0.20358316600322723
train-epoch-step: 40-328 -- Loss: 0.19147706031799316
train-epoch-step: 40-329 -- Loss: 0.33635348081588745
train-epoch-step: 40-330 -- Loss: 0.35685017704963684
train-epoch-step: 40-331 -- Loss: 0.21045520901679993
train-epoch-step: 40-332 -- Loss: 0.09980832785367966
train-epoch-step: 40-333 -- Loss: 0.1937929391860962
train-epoch-step: 40-334 -- Loss: 0.15611305832862854
train-epoch-step: 40-335 -- Loss: 0.17966562509536743
train-epoch-step: 40-336 -- Loss: 0.15449386835098267
train-epoch-step: 40-337 -- Loss: 0.20641003549098969
train-epoch-step: 40-338 -- Loss: 0.15759029984474182
train-epoch-step: 40-339 -- Loss: 0.14232608675956726
train-epoch-step: 40-340 -- Loss: 0.19853772222995758
train-epoch-step: 40-341 -- Loss: 0.13834744691848755
train-epoch-step: 40-342 -- Loss: 0.16532255709171295
train-epoch-step: 40-343 -- Loss: 0.1548200100660324
train-epoch-step: 40-344 -- Loss: 0.1693834811449051
train-epoch-step: 40-345 -- Loss: 0.12294067442417145
train-epoch-step: 40-346 -- Loss: 0.20034807920455933
train-epoch-step: 40-347 -- Loss: 0.15594600141048431
train-epoch-step: 40-348 -- Loss: 0.20395667850971222
train-epoch-step: 40-349 -- Loss: 0.2041441649198532
train-epoch-step: 40-350 -- Loss: 0.2610556483268738
train-epoch-step: 40-351 -- Loss: 0.19066345691680908
train-epoch-step: 40-352 -- Loss: 0.12546266615390778
train-epoch-step: 40-353 -- Loss: 0.18826301395893097
train-epoch-step: 40-354 -- Loss: 0.28682300448417664
train-epoch-step: 40-355 -- Loss: 0.11784122884273529
train-epoch-step: 40-356 -- Loss: 0.11727164685726166
train-epoch-step: 40-357 -- Loss: 0.18533658981323242
train-epoch-step: 40-358 -- Loss: 0.18370220065116882
train-epoch-step: 40-359 -- Loss: 0.14022371172904968
train-epoch-step: 40-360 -- Loss: 0.12367841601371765
train-epoch-step: 40-361 -- Loss: 0.23638920485973358
train-epoch-step: 40-362 -- Loss: 0.16592107713222504
train-epoch-step: 40-363 -- Loss: 0.10940760374069214
train-epoch-step: 40-364 -- Loss: 0.17855261266231537
train-epoch-step: 40-365 -- Loss: 0.16911910474300385
train-epoch-step: 40-366 -- Loss: 0.20316073298454285
train-epoch-step: 40-367 -- Loss: 0.22594301402568817
train-epoch-step: 40-368 -- Loss: 0.2012399435043335
train-epoch-step: 40-369 -- Loss: 0.2736605107784271
train-epoch-step: 40-370 -- Loss: 0.12167461961507797
train-epoch-step: 40-371 -- Loss: 0.12139802426099777
train-epoch-step: 40-372 -- Loss: 0.14389055967330933
train-epoch-step: 40-373 -- Loss: 0.18710243701934814
train-epoch-step: 40-374 -- Loss: 0.15640312433242798
train-epoch-step: 40-375 -- Loss: 0.26801151037216187
train-epoch-step: 40-376 -- Loss: 0.16378886997699738
train-epoch-step: 40-377 -- Loss: 0.22878393530845642
train-epoch-step: 40-378 -- Loss: 0.20606793463230133
train-epoch-step: 40-379 -- Loss: 0.11706408858299255
train-epoch-step: 40-380 -- Loss: 0.09114886820316315
train-epoch-step: 40-381 -- Loss: 0.2421635389328003
train-epoch-step: 40-382 -- Loss: 0.23125116527080536
train-epoch-step: 40-383 -- Loss: 0.17309227585792542
train-epoch-step: 40-384 -- Loss: 0.22458016872406006
train-epoch-step: 40-385 -- Loss: 0.1886807382106781
train-epoch-step: 40-386 -- Loss: 0.18152505159378052
train-epoch-step: 40-387 -- Loss: 0.1974194049835205
train-epoch-step: 40-388 -- Loss: 0.1878001093864441
train-epoch-step: 40-389 -- Loss: 0.1672154664993286
train-epoch-step: 40-390 -- Loss: 0.13975489139556885
train-epoch-step: 40-391 -- Loss: 0.14489266276359558
train-epoch-step: 40-392 -- Loss: 0.1836891621351242
train-epoch-step: 40-393 -- Loss: 0.1537168323993683
train-epoch-step: 40-394 -- Loss: 0.22041462361812592
train-epoch-step: 40-395 -- Loss: 0.15623022615909576
train-epoch-step: 40-396 -- Loss: 0.125238835811615
train-epoch-step: 40-397 -- Loss: 0.1272207349538803
train-epoch-step: 40-398 -- Loss: 0.21181292831897736
train-epoch-step: 40-399 -- Loss: 0.17816975712776184
train-epoch-step: 40-400 -- Loss: 0.3061782419681549
train-epoch-step: 40-401 -- Loss: 0.12188008427619934
train-epoch-step: 40-402 -- Loss: 0.25157853960990906
train-epoch-step: 40-403 -- Loss: 0.1535971462726593
train-epoch-step: 40-404 -- Loss: 0.13938361406326294
train-epoch-step: 40-405 -- Loss: 0.141106978058815
train-epoch-step: 40-406 -- Loss: 0.16280817985534668
train-epoch-step: 40-407 -- Loss: 0.11442222446203232
train-epoch-step: 40-408 -- Loss: 0.1575821340084076
train-epoch-step: 40-409 -- Loss: 0.16840851306915283
train-epoch-step: 40-410 -- Loss: 0.17879639565944672
train-epoch-step: 40-411 -- Loss: 0.2017354518175125
train-epoch-step: 40-412 -- Loss: 0.12900370359420776
train-epoch-step: 40-413 -- Loss: 0.1481202244758606
train-epoch-step: 40-414 -- Loss: 0.13264620304107666
train-epoch-step: 40-415 -- Loss: 0.13315993547439575
train-epoch-step: 40-416 -- Loss: 0.26534098386764526
train-epoch-step: 40-417 -- Loss: 0.19277141988277435
train-epoch-step: 40-418 -- Loss: 0.2309698611497879
train-epoch-step: 40-419 -- Loss: 0.17007170617580414
train-epoch-step: 40-420 -- Loss: 0.1513228565454483
train-epoch-step: 40-421 -- Loss: 0.18643619120121002
train-epoch-step: 40-422 -- Loss: 0.1490563452243805
train-epoch-step: 40-423 -- Loss: 0.17569847404956818
train-epoch-step: 40-424 -- Loss: 0.1385773867368698
train-epoch-step: 40-425 -- Loss: 0.18239346146583557
train-epoch-step: 40-426 -- Loss: 0.1625726819038391
train-epoch-step: 40-427 -- Loss: 0.12146300077438354
train-epoch-step: 40-428 -- Loss: 0.19237497448921204
train-epoch-step: 40-429 -- Loss: 0.17392171919345856
train-epoch-step: 40-430 -- Loss: 0.14374208450317383
train-epoch-step: 40-431 -- Loss: 0.16230617463588715
train-epoch-step: 40-432 -- Loss: 0.24206678569316864
train-epoch-step: 40-433 -- Loss: 0.13764652609825134
train-epoch-step: 40-434 -- Loss: 0.1284841150045395
train-epoch-step: 40-435 -- Loss: 0.1594204157590866
train-epoch-step: 40-436 -- Loss: 0.15594230592250824
train-epoch-step: 40-437 -- Loss: 0.13275279104709625
train-epoch-step: 40-438 -- Loss: 0.1724914014339447
train-epoch-step: 40-439 -- Loss: 0.25486427545547485
train-epoch-step: 40-440 -- Loss: 0.13556984066963196
train-epoch-step: 40-441 -- Loss: 0.19780701398849487
train-epoch-step: 40-442 -- Loss: 0.1872667372226715
train-epoch-step: 40-443 -- Loss: 0.151056706905365
train-epoch-step: 40-444 -- Loss: 0.187358096241951
train-epoch-step: 40-445 -- Loss: 0.18106408417224884
train-epoch-step: 40-446 -- Loss: 0.15470492839813232
train-epoch-step: 40-447 -- Loss: 0.1927529275417328
train-epoch-step: 40-448 -- Loss: 0.22371192276477814
train-epoch-step: 40-449 -- Loss: 0.1928805261850357
train-epoch-step: 40-450 -- Loss: 0.18379564583301544
train-epoch-step: 40-451 -- Loss: 0.14514018595218658
train-epoch-step: 40-452 -- Loss: 0.13174688816070557
train-epoch-step: 40-453 -- Loss: 0.0941937044262886
train-epoch-step: 40-454 -- Loss: 0.23381206393241882
train-epoch-step: 40-455 -- Loss: 0.12350612878799438
train-epoch-step: 40-456 -- Loss: 0.12409034371376038
train-epoch-step: 40-457 -- Loss: 0.21385134756565094
train-epoch-step: 40-458 -- Loss: 0.1617618054151535
train-epoch-step: 40-459 -- Loss: 0.22460515797138214
train-epoch-step: 40-460 -- Loss: 0.1344965100288391
train-epoch-step: 40-461 -- Loss: 0.13705676794052124
train-epoch-step: 40-462 -- Loss: 0.1598263531923294
train-epoch-step: 40-463 -- Loss: 0.13377171754837036
train-epoch-step: 40-464 -- Loss: 0.16340704262256622
train-epoch-step: 40-465 -- Loss: 0.24165596067905426
train-epoch-step: 40-466 -- Loss: 0.19881342351436615
train-epoch-step: 40-467 -- Loss: 0.11166870594024658
train-epoch-step: 40-468 -- Loss: 0.1647370457649231
train-epoch-step: 40-469 -- Loss: 0.2100953757762909
train-epoch-step: 40-470 -- Loss: 0.17422977089881897
train-epoch-step: 40-471 -- Loss: 0.1549299955368042
train-epoch-step: 40-472 -- Loss: 0.15528395771980286
train-epoch-step: 40-473 -- Loss: 0.15946997702121735
train-epoch-step: 40-474 -- Loss: 0.11960787326097488
train-epoch-step: 40-475 -- Loss: 0.1124638095498085
train-epoch-step: 40-476 -- Loss: 0.1977124810218811
train-epoch-step: 40-477 -- Loss: 0.20161379873752594
train-epoch-step: 40-478 -- Loss: 0.1943223923444748
train-epoch-step: 40-479 -- Loss: 0.13772644102573395
train-epoch-step: 40-480 -- Loss: 0.18824559450149536
train-epoch-step: 40-481 -- Loss: 0.2898752689361572
train-epoch-step: 40-482 -- Loss: 0.24032849073410034
train-epoch-step: 40-483 -- Loss: 0.180988147854805
train-epoch-step: 40-484 -- Loss: 0.2119891494512558
train-epoch-step: 40-485 -- Loss: 0.12480354309082031
train-epoch-step: 40-486 -- Loss: 0.22803258895874023
train-epoch-step: 40-487 -- Loss: 0.2265636920928955
train-epoch-step: 40-488 -- Loss: 0.18793997168540955
train-epoch-step: 40-489 -- Loss: 0.21615219116210938
train-epoch-step: 40-490 -- Loss: 0.13478639721870422
train-epoch-step: 40-491 -- Loss: 0.1382862776517868
train-epoch-step: 40-492 -- Loss: 0.13037435710430145
train-epoch-step: 40-493 -- Loss: 0.19742509722709656
train-epoch-step: 40-494 -- Loss: 0.20197144150733948
train-epoch-step: 40-495 -- Loss: 0.19817563891410828
train-epoch-step: 40-496 -- Loss: 0.14156238734722137
train-epoch-step: 40-497 -- Loss: 0.18150046467781067
train-epoch-step: 40-498 -- Loss: 0.15106645226478577
train-epoch-step: 40-499 -- Loss: 0.1692328006029129
train-epoch-step: 40-500 -- Loss: 0.16173456609249115
train-epoch-step: 40-501 -- Loss: 0.2089414894580841
train-epoch-step: 40-502 -- Loss: 0.16670362651348114
train-epoch-step: 40-503 -- Loss: 0.22432437539100647
train-epoch-step: 40-504 -- Loss: 0.11758260428905487
train-epoch-step: 40-505 -- Loss: 0.16819849610328674
train-epoch-step: 40-506 -- Loss: 0.11344993859529495
train-epoch-step: 40-507 -- Loss: 0.17712198197841644
train-epoch-step: 40-508 -- Loss: 0.16833551228046417
train-epoch-step: 40-509 -- Loss: 0.16597680747509003
train-epoch-step: 40-510 -- Loss: 0.12513300776481628
train-epoch-step: 40-511 -- Loss: 0.2190820276737213
train-epoch-step: 40-512 -- Loss: 0.17177580296993256
train-epoch-step: 40-513 -- Loss: 0.19144585728645325
train-epoch-step: 40-514 -- Loss: 0.14609837532043457
train-epoch-step: 40-515 -- Loss: 0.1560596227645874
train-epoch-step: 40-516 -- Loss: 0.16787412762641907
train-epoch-step: 40-517 -- Loss: 0.17349959909915924
train-epoch-step: 40-518 -- Loss: 0.13500070571899414
train-epoch-step: 40-519 -- Loss: 0.12968827784061432
train-epoch-step: 40-520 -- Loss: 0.18422798812389374
train-epoch-step: 40-521 -- Loss: 0.22860075533390045
train-epoch-step: 40-522 -- Loss: 0.17467597126960754
train-epoch-step: 40-523 -- Loss: 0.15495094656944275
train-epoch-step: 40-524 -- Loss: 0.1635853350162506
train-epoch-step: 40-525 -- Loss: 0.19162553548812866
train-epoch-step: 40-526 -- Loss: 0.1278199702501297
train-epoch-step: 40-527 -- Loss: 0.14921319484710693
train-epoch-step: 40-528 -- Loss: 0.15936137735843658
train-epoch-step: 40-529 -- Loss: 0.1616792380809784
train-epoch-step: 40-530 -- Loss: 0.1932644546031952
train-epoch-step: 40-531 -- Loss: 0.20078612864017487
train-epoch-step: 40-532 -- Loss: 0.168503075838089
train-epoch-step: 40-533 -- Loss: 0.17115546762943268
train-epoch-step: 40-534 -- Loss: 0.13054881989955902
train-epoch-step: 40-535 -- Loss: 0.24811823666095734
train-epoch-step: 40-536 -- Loss: 0.15470340847969055
train-epoch-step: 40-537 -- Loss: 0.14620071649551392
train-epoch-step: 40-538 -- Loss: 0.10537472367286682
train-epoch-step: 40-539 -- Loss: 0.18386626243591309
train-epoch-step: 40-540 -- Loss: 0.14059840142726898
train-epoch-step: 40-541 -- Loss: 0.2049104869365692
train-epoch-step: 40-542 -- Loss: 0.22207771241664886
train-epoch-step: 40-543 -- Loss: 0.16680942475795746
train-epoch-step: 40-544 -- Loss: 0.22973594069480896
train-epoch-step: 40-545 -- Loss: 0.191804438829422
train-epoch-step: 40-546 -- Loss: 0.2002774477005005
train-epoch-step: 40-547 -- Loss: 0.18379592895507812
train-epoch-step: 40-548 -- Loss: 0.09372496604919434
train-epoch-step: 40-549 -- Loss: 0.14940065145492554
train-epoch-step: 40-550 -- Loss: 0.19381405413150787
train-epoch-step: 40-551 -- Loss: 0.14911413192749023
train-epoch-step: 40-552 -- Loss: 0.12522701919078827
train-epoch-step: 40-553 -- Loss: 0.18175168335437775
train-epoch-step: 40-554 -- Loss: 0.17943288385868073
train-epoch-step: 40-555 -- Loss: 0.20888651907444
train-epoch-step: 40-556 -- Loss: 0.14671443402767181
train-epoch-step: 40-557 -- Loss: 0.22740033268928528
train-epoch-step: 40-558 -- Loss: 0.22424164414405823
train-epoch-step: 40-559 -- Loss: 0.1459471434354782
train-epoch-step: 40-560 -- Loss: 0.20541247725486755
train-epoch-step: 40-561 -- Loss: 0.17721273005008698
train-epoch-step: 40-562 -- Loss: 0.16075968742370605
train-epoch-step: 40-563 -- Loss: 0.18790726363658905
train-epoch-step: 40-564 -- Loss: 0.10072323679924011
train-epoch-step: 40-565 -- Loss: 0.1819387972354889
train-epoch-step: 40-566 -- Loss: 0.1464298963546753
train-epoch-step: 40-567 -- Loss: 0.21603593230247498
train-epoch-step: 40-568 -- Loss: 0.1573759913444519
train-epoch-step: 40-569 -- Loss: 0.23809537291526794
train-epoch-step: 40-570 -- Loss: 0.16205622255802155
train-epoch-step: 40-571 -- Loss: 0.2212117612361908
train-epoch-step: 40-572 -- Loss: 0.23435460031032562
train-epoch-step: 40-573 -- Loss: 0.20060499012470245
train-epoch-step: 40-574 -- Loss: 0.24493734538555145
train-epoch-step: 40-575 -- Loss: 0.2873545289039612
train-epoch-step: 40-576 -- Loss: 0.11750270426273346
train-epoch-step: 40-577 -- Loss: 0.16666685044765472
train-epoch-step: 40-578 -- Loss: 0.2113189697265625
train-epoch-step: 40-579 -- Loss: 0.15987782180309296
train-epoch-step: 40-580 -- Loss: 0.17245645821094513
train-epoch-step: 40-581 -- Loss: 0.1335761696100235
train-epoch-step: 40-582 -- Loss: 0.20543047785758972
train-epoch-step: 40-583 -- Loss: 0.20938734710216522
train-epoch-step: 40-584 -- Loss: 0.16618679463863373
train-epoch-step: 40-585 -- Loss: 0.1923820972442627
train-epoch-step: 40-586 -- Loss: 0.2515471577644348
train-epoch-step: 40-587 -- Loss: 0.1630709171295166
train-epoch-step: 40-588 -- Loss: 0.12331557273864746
val-epoch-step: 40-589 -- Loss: 0.21610921621322632
val-epoch-step: 40-590 -- Loss: 0.15195657312870026
val-epoch-step: 40-591 -- Loss: 0.22458195686340332
val-epoch-step: 40-592 -- Loss: 0.17409314215183258
val-epoch-step: 40-593 -- Loss: 0.16366128623485565
val-epoch-step: 40-594 -- Loss: 0.4308530390262604
val-epoch-step: 40-595 -- Loss: 0.21136042475700378
val-epoch-step: 40-596 -- Loss: 0.19395677745342255
val-epoch-step: 40-597 -- Loss: 0.16621902585029602
val-epoch-step: 40-598 -- Loss: 0.15014079213142395
val-epoch-step: 40-599 -- Loss: 0.18387925624847412
val-epoch-step: 40-600 -- Loss: 0.194701686501503
val-epoch-step: 40-601 -- Loss: 0.15879450738430023
val-epoch-step: 40-602 -- Loss: 0.13690271973609924
val-epoch-step: 40-603 -- Loss: 0.1963941752910614
val-epoch-step: 40-604 -- Loss: 0.14188998937606812
val-epoch-step: 40-605 -- Loss: 0.14665403962135315
val-epoch-step: 40-606 -- Loss: 0.26217836141586304
val-epoch-step: 40-607 -- Loss: 0.12822243571281433
val-epoch-step: 40-608 -- Loss: 0.24985536932945251
val-epoch-step: 40-609 -- Loss: 0.1698645055294037
val-epoch-step: 40-610 -- Loss: 0.1791534125804901
val-epoch-step: 40-611 -- Loss: 0.16372662782669067
val-epoch-step: 40-612 -- Loss: 0.4645618796348572
val-epoch-step: 40-613 -- Loss: 0.1780981719493866
val-epoch-step: 40-614 -- Loss: 0.16908271610736847
val-epoch-step: 40-615 -- Loss: 0.17290064692497253
val-epoch-step: 40-616 -- Loss: 0.15342558920383453
val-epoch-step: 40-617 -- Loss: 0.19149664044380188
val-epoch-step: 40-618 -- Loss: 0.17722339928150177
val-epoch-step: 40-619 -- Loss: 0.224777489900589
val-epoch-step: 40-620 -- Loss: 0.14487284421920776
val-epoch-step: 40-621 -- Loss: 0.12439803034067154
val-epoch-step: 40-622 -- Loss: 0.14271581172943115
val-epoch-step: 40-623 -- Loss: 0.1493031084537506
val-epoch-step: 40-624 -- Loss: 0.14511887729167938
val-epoch-step: 40-625 -- Loss: 0.1554199755191803
val-epoch-step: 40-626 -- Loss: 0.14675332605838776
val-epoch-step: 40-627 -- Loss: 0.18261826038360596
val-epoch-step: 40-628 -- Loss: 0.6162282824516296
val-epoch-step: 40-629 -- Loss: 0.22142019867897034
val-epoch-step: 40-630 -- Loss: 0.3474768102169037
val-epoch-step: 40-631 -- Loss: 0.13552503287792206
val-epoch-step: 40-632 -- Loss: 0.20093753933906555
val-epoch-step: 40-633 -- Loss: 0.1516498327255249
val-epoch-step: 40-634 -- Loss: 0.1456950455904007
val-epoch-step: 40-635 -- Loss: 0.11549864709377289
val-epoch-step: 40-636 -- Loss: 0.1673920452594757
val-epoch-step: 40-637 -- Loss: 0.17737245559692383
val-epoch-step: 40-638 -- Loss: 0.1697385609149933
val-epoch-step: 40-639 -- Loss: 0.26432913541793823
val-epoch-step: 40-640 -- Loss: 0.2569691836833954
val-epoch-step: 40-641 -- Loss: 0.12184326350688934
val-epoch-step: 40-642 -- Loss: 0.18128985166549683
val-epoch-step: 40-643 -- Loss: 0.2096995711326599
val-epoch-step: 40-644 -- Loss: 0.1653575897216797
val-epoch-step: 40-645 -- Loss: 0.21622727811336517
val-epoch-step: 40-646 -- Loss: 0.13510072231292725
val-epoch-step: 40-647 -- Loss: 0.1252039670944214
val-epoch-step: 40-648 -- Loss: 0.15294496715068817
val-epoch-step: 40-649 -- Loss: 0.21590130031108856
val-epoch-step: 40-650 -- Loss: 0.2529754340648651
val-epoch-step: 40-651 -- Loss: 0.14488409459590912
val-epoch-step: 40-652 -- Loss: 0.15423069894313812
val-epoch-step: 40-653 -- Loss: 0.21435511112213135
val-epoch-step: 40-654 -- Loss: 0.10711485147476196
Epoch: 40 -- Train Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.94 -- Val Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.94
                         Test Loss: 0.0 -- Test Acc: 71.94
train-epoch-step: 41-0 -- Loss: 0.21856902539730072
train-epoch-step: 41-1 -- Loss: 0.14005127549171448
train-epoch-step: 41-2 -- Loss: 0.20197543501853943
train-epoch-step: 41-3 -- Loss: 0.13858793675899506
train-epoch-step: 41-4 -- Loss: 0.15626148879528046
train-epoch-step: 41-5 -- Loss: 0.18443572521209717
train-epoch-step: 41-6 -- Loss: 0.21085813641548157
train-epoch-step: 41-7 -- Loss: 0.17125044763088226
train-epoch-step: 41-8 -- Loss: 0.17215612530708313
train-epoch-step: 41-9 -- Loss: 0.2205810546875
train-epoch-step: 41-10 -- Loss: 0.18938584625720978
train-epoch-step: 41-11 -- Loss: 0.17453303933143616
train-epoch-step: 41-12 -- Loss: 0.1470935046672821
train-epoch-step: 41-13 -- Loss: 0.17115411162376404
train-epoch-step: 41-14 -- Loss: 0.1594020426273346
train-epoch-step: 41-15 -- Loss: 0.1609364151954651
train-epoch-step: 41-16 -- Loss: 0.16820675134658813
train-epoch-step: 41-17 -- Loss: 0.22190362215042114
train-epoch-step: 41-18 -- Loss: 0.19144800305366516
train-epoch-step: 41-19 -- Loss: 0.12984226644039154
train-epoch-step: 41-20 -- Loss: 0.21616686880588531
train-epoch-step: 41-21 -- Loss: 0.24108214676380157
train-epoch-step: 41-22 -- Loss: 0.1385088711977005
train-epoch-step: 41-23 -- Loss: 0.13945718109607697
train-epoch-step: 41-24 -- Loss: 0.12651251256465912
train-epoch-step: 41-25 -- Loss: 0.22428633272647858
train-epoch-step: 41-26 -- Loss: 0.19390134513378143
train-epoch-step: 41-27 -- Loss: 0.23690180480480194
train-epoch-step: 41-28 -- Loss: 0.124936543405056
train-epoch-step: 41-29 -- Loss: 0.23858597874641418
train-epoch-step: 41-30 -- Loss: 0.10643186420202255
train-epoch-step: 41-31 -- Loss: 0.1340705156326294
train-epoch-step: 41-32 -- Loss: 0.17552399635314941
train-epoch-step: 41-33 -- Loss: 0.27341997623443604
train-epoch-step: 41-34 -- Loss: 0.18527361750602722
train-epoch-step: 41-35 -- Loss: 0.2422129362821579
train-epoch-step: 41-36 -- Loss: 0.13539278507232666
train-epoch-step: 41-37 -- Loss: 0.13713890314102173
train-epoch-step: 41-38 -- Loss: 0.1795911192893982
train-epoch-step: 41-39 -- Loss: 0.21747437119483948
train-epoch-step: 41-40 -- Loss: 0.19036534428596497
train-epoch-step: 41-41 -- Loss: 0.21580176055431366
train-epoch-step: 41-42 -- Loss: 0.14564770460128784
train-epoch-step: 41-43 -- Loss: 0.2650352716445923
train-epoch-step: 41-44 -- Loss: 0.12559303641319275
train-epoch-step: 41-45 -- Loss: 0.12136588990688324
train-epoch-step: 41-46 -- Loss: 0.17147041857242584
train-epoch-step: 41-47 -- Loss: 0.19636434316635132
train-epoch-step: 41-48 -- Loss: 0.15240304172039032
train-epoch-step: 41-49 -- Loss: 0.21912427246570587
train-epoch-step: 41-50 -- Loss: 0.10716255009174347
train-epoch-step: 41-51 -- Loss: 0.17262649536132812
train-epoch-step: 41-52 -- Loss: 0.158333882689476
train-epoch-step: 41-53 -- Loss: 0.206223726272583
train-epoch-step: 41-54 -- Loss: 0.2970847487449646
train-epoch-step: 41-55 -- Loss: 0.16385279595851898
train-epoch-step: 41-56 -- Loss: 0.17512692511081696
train-epoch-step: 41-57 -- Loss: 0.239362895488739
train-epoch-step: 41-58 -- Loss: 0.29884523153305054
train-epoch-step: 41-59 -- Loss: 0.25146105885505676
train-epoch-step: 41-60 -- Loss: 0.13475401699543
train-epoch-step: 41-61 -- Loss: 0.19831806421279907
train-epoch-step: 41-62 -- Loss: 0.1868135631084442
train-epoch-step: 41-63 -- Loss: 0.15488164126873016
train-epoch-step: 41-64 -- Loss: 0.14094647765159607
train-epoch-step: 41-65 -- Loss: 0.18286921083927155
train-epoch-step: 41-66 -- Loss: 0.11534720659255981
train-epoch-step: 41-67 -- Loss: 0.13320839405059814
train-epoch-step: 41-68 -- Loss: 0.21105195581912994
train-epoch-step: 41-69 -- Loss: 0.12235844880342484
train-epoch-step: 41-70 -- Loss: 0.22095969319343567
train-epoch-step: 41-71 -- Loss: 0.25341084599494934
train-epoch-step: 41-72 -- Loss: 0.17568640410900116
train-epoch-step: 41-73 -- Loss: 0.2082141935825348
train-epoch-step: 41-74 -- Loss: 0.09525781124830246
train-epoch-step: 41-75 -- Loss: 0.13335421681404114
train-epoch-step: 41-76 -- Loss: 0.14732062816619873
train-epoch-step: 41-77 -- Loss: 0.23027366399765015
train-epoch-step: 41-78 -- Loss: 0.2575087547302246
train-epoch-step: 41-79 -- Loss: 0.19487550854682922
train-epoch-step: 41-80 -- Loss: 0.2551310658454895
train-epoch-step: 41-81 -- Loss: 0.12623049318790436
train-epoch-step: 41-82 -- Loss: 0.2521153688430786
train-epoch-step: 41-83 -- Loss: 0.1859220713376999
train-epoch-step: 41-84 -- Loss: 0.18877528607845306
train-epoch-step: 41-85 -- Loss: 0.17354437708854675
train-epoch-step: 41-86 -- Loss: 0.11973882466554642
train-epoch-step: 41-87 -- Loss: 0.2079043984413147
train-epoch-step: 41-88 -- Loss: 0.13914790749549866
train-epoch-step: 41-89 -- Loss: 0.19215358793735504
train-epoch-step: 41-90 -- Loss: 0.19126087427139282
train-epoch-step: 41-91 -- Loss: 0.2385667860507965
train-epoch-step: 41-92 -- Loss: 0.15514402091503143
train-epoch-step: 41-93 -- Loss: 0.18751826882362366
train-epoch-step: 41-94 -- Loss: 0.21962767839431763
train-epoch-step: 41-95 -- Loss: 0.18523597717285156
train-epoch-step: 41-96 -- Loss: 0.21528245508670807
train-epoch-step: 41-97 -- Loss: 0.17543458938598633
train-epoch-step: 41-98 -- Loss: 0.15677358210086823
train-epoch-step: 41-99 -- Loss: 0.18706755340099335
train-epoch-step: 41-100 -- Loss: 0.2032327950000763
train-epoch-step: 41-101 -- Loss: 0.256290465593338
train-epoch-step: 41-102 -- Loss: 0.20986118912696838
train-epoch-step: 41-103 -- Loss: 0.1839418262243271
train-epoch-step: 41-104 -- Loss: 0.14637930691242218
train-epoch-step: 41-105 -- Loss: 0.2608400881290436
train-epoch-step: 41-106 -- Loss: 0.17107552289962769
train-epoch-step: 41-107 -- Loss: 0.18846753239631653
train-epoch-step: 41-108 -- Loss: 0.19410055875778198
train-epoch-step: 41-109 -- Loss: 0.15018929541110992
train-epoch-step: 41-110 -- Loss: 0.18468138575553894
train-epoch-step: 41-111 -- Loss: 0.1819991171360016
train-epoch-step: 41-112 -- Loss: 0.16116349399089813
train-epoch-step: 41-113 -- Loss: 0.15938425064086914
train-epoch-step: 41-114 -- Loss: 0.20037958025932312
train-epoch-step: 41-115 -- Loss: 0.16078904271125793
train-epoch-step: 41-116 -- Loss: 0.13558904826641083
train-epoch-step: 41-117 -- Loss: 0.12373779714107513
train-epoch-step: 41-118 -- Loss: 0.19210517406463623
train-epoch-step: 41-119 -- Loss: 0.14725279808044434
train-epoch-step: 41-120 -- Loss: 0.24944627285003662
train-epoch-step: 41-121 -- Loss: 0.22885964810848236
train-epoch-step: 41-122 -- Loss: 0.21375365555286407
train-epoch-step: 41-123 -- Loss: 0.20275598764419556
train-epoch-step: 41-124 -- Loss: 0.12480589747428894
train-epoch-step: 41-125 -- Loss: 0.15280857682228088
train-epoch-step: 41-126 -- Loss: 0.22870789468288422
train-epoch-step: 41-127 -- Loss: 0.17818120121955872
train-epoch-step: 41-128 -- Loss: 0.16988742351531982
train-epoch-step: 41-129 -- Loss: 0.1451762169599533
train-epoch-step: 41-130 -- Loss: 0.19750116765499115
train-epoch-step: 41-131 -- Loss: 0.1318524032831192
train-epoch-step: 41-132 -- Loss: 0.1859102100133896
train-epoch-step: 41-133 -- Loss: 0.11312152445316315
train-epoch-step: 41-134 -- Loss: 0.1978614181280136
train-epoch-step: 41-135 -- Loss: 0.13564656674861908
train-epoch-step: 41-136 -- Loss: 0.1329469084739685
train-epoch-step: 41-137 -- Loss: 0.23995546996593475
train-epoch-step: 41-138 -- Loss: 0.25406065583229065
train-epoch-step: 41-139 -- Loss: 0.1311841905117035
train-epoch-step: 41-140 -- Loss: 0.20726501941680908
train-epoch-step: 41-141 -- Loss: 0.22354993224143982
train-epoch-step: 41-142 -- Loss: 0.20183537900447845
train-epoch-step: 41-143 -- Loss: 0.1724526584148407
train-epoch-step: 41-144 -- Loss: 0.18798235058784485
train-epoch-step: 41-145 -- Loss: 0.1421070694923401
train-epoch-step: 41-146 -- Loss: 0.17886820435523987
train-epoch-step: 41-147 -- Loss: 0.16787292063236237
train-epoch-step: 41-148 -- Loss: 0.15562774240970612
train-epoch-step: 41-149 -- Loss: 0.11966631561517715
train-epoch-step: 41-150 -- Loss: 0.17910829186439514
train-epoch-step: 41-151 -- Loss: 0.1859213262796402
train-epoch-step: 41-152 -- Loss: 0.19775566458702087
train-epoch-step: 41-153 -- Loss: 0.2575652003288269
train-epoch-step: 41-154 -- Loss: 0.12840065360069275
train-epoch-step: 41-155 -- Loss: 0.13494212925434113
train-epoch-step: 41-156 -- Loss: 0.11884596943855286
train-epoch-step: 41-157 -- Loss: 0.17037442326545715
train-epoch-step: 41-158 -- Loss: 0.16257238388061523
train-epoch-step: 41-159 -- Loss: 0.17551523447036743
train-epoch-step: 41-160 -- Loss: 0.2160956710577011
train-epoch-step: 41-161 -- Loss: 0.204343780875206
train-epoch-step: 41-162 -- Loss: 0.20874567329883575
train-epoch-step: 41-163 -- Loss: 0.18898436427116394
train-epoch-step: 41-164 -- Loss: 0.19150501489639282
train-epoch-step: 41-165 -- Loss: 0.16189992427825928
train-epoch-step: 41-166 -- Loss: 0.12295843660831451
train-epoch-step: 41-167 -- Loss: 0.1263282746076584
train-epoch-step: 41-168 -- Loss: 0.1987008899450302
train-epoch-step: 41-169 -- Loss: 0.14045250415802002
train-epoch-step: 41-170 -- Loss: 0.19944941997528076
train-epoch-step: 41-171 -- Loss: 0.14131779968738556
train-epoch-step: 41-172 -- Loss: 0.2586606740951538
train-epoch-step: 41-173 -- Loss: 0.13194206357002258
train-epoch-step: 41-174 -- Loss: 0.24622344970703125
train-epoch-step: 41-175 -- Loss: 0.18690451979637146
train-epoch-step: 41-176 -- Loss: 0.12879586219787598
train-epoch-step: 41-177 -- Loss: 0.17395463585853577
train-epoch-step: 41-178 -- Loss: 0.17483395338058472
train-epoch-step: 41-179 -- Loss: 0.15553995966911316
train-epoch-step: 41-180 -- Loss: 0.15064741671085358
train-epoch-step: 41-181 -- Loss: 0.17078383266925812
train-epoch-step: 41-182 -- Loss: 0.18598246574401855
train-epoch-step: 41-183 -- Loss: 0.27698999643325806
train-epoch-step: 41-184 -- Loss: 0.13694597780704498
train-epoch-step: 41-185 -- Loss: 0.13778525590896606
train-epoch-step: 41-186 -- Loss: 0.18564294278621674
train-epoch-step: 41-187 -- Loss: 0.20379206538200378
train-epoch-step: 41-188 -- Loss: 0.1703847050666809
train-epoch-step: 41-189 -- Loss: 0.10466469824314117
train-epoch-step: 41-190 -- Loss: 0.17809167504310608
train-epoch-step: 41-191 -- Loss: 0.15788614749908447
train-epoch-step: 41-192 -- Loss: 0.233117014169693
train-epoch-step: 41-193 -- Loss: 0.2031775712966919
train-epoch-step: 41-194 -- Loss: 0.18258677423000336
train-epoch-step: 41-195 -- Loss: 0.16543807089328766
train-epoch-step: 41-196 -- Loss: 0.16958490014076233
train-epoch-step: 41-197 -- Loss: 0.12458944320678711
train-epoch-step: 41-198 -- Loss: 0.12517507374286652
train-epoch-step: 41-199 -- Loss: 0.15102605521678925
train-epoch-step: 41-200 -- Loss: 0.12436336278915405
train-epoch-step: 41-201 -- Loss: 0.1926732063293457
train-epoch-step: 41-202 -- Loss: 0.13645599782466888
train-epoch-step: 41-203 -- Loss: 0.17441119253635406
train-epoch-step: 41-204 -- Loss: 0.1385478526353836
train-epoch-step: 41-205 -- Loss: 0.18330755829811096
train-epoch-step: 41-206 -- Loss: 0.19743800163269043
train-epoch-step: 41-207 -- Loss: 0.13388337194919586
train-epoch-step: 41-208 -- Loss: 0.1755628138780594
train-epoch-step: 41-209 -- Loss: 0.13832050561904907
train-epoch-step: 41-210 -- Loss: 0.13054035604000092
train-epoch-step: 41-211 -- Loss: 0.20601044595241547
train-epoch-step: 41-212 -- Loss: 0.19461698830127716
train-epoch-step: 41-213 -- Loss: 0.12824365496635437
train-epoch-step: 41-214 -- Loss: 0.14281684160232544
train-epoch-step: 41-215 -- Loss: 0.12594406306743622
train-epoch-step: 41-216 -- Loss: 0.20281557738780975
train-epoch-step: 41-217 -- Loss: 0.2344687581062317
train-epoch-step: 41-218 -- Loss: 0.14572057127952576
train-epoch-step: 41-219 -- Loss: 0.16651380062103271
train-epoch-step: 41-220 -- Loss: 0.12875066697597504
train-epoch-step: 41-221 -- Loss: 0.20184917747974396
train-epoch-step: 41-222 -- Loss: 0.11426260322332382
train-epoch-step: 41-223 -- Loss: 0.17445027828216553
train-epoch-step: 41-224 -- Loss: 0.19269491732120514
train-epoch-step: 41-225 -- Loss: 0.26188844442367554
train-epoch-step: 41-226 -- Loss: 0.20773017406463623
train-epoch-step: 41-227 -- Loss: 0.22145019471645355
train-epoch-step: 41-228 -- Loss: 0.17507480084896088
train-epoch-step: 41-229 -- Loss: 0.16851288080215454
train-epoch-step: 41-230 -- Loss: 0.16382518410682678
train-epoch-step: 41-231 -- Loss: 0.2065763622522354
train-epoch-step: 41-232 -- Loss: 0.18846312165260315
train-epoch-step: 41-233 -- Loss: 0.08326093852519989
train-epoch-step: 41-234 -- Loss: 0.16575630009174347
train-epoch-step: 41-235 -- Loss: 0.13946637511253357
train-epoch-step: 41-236 -- Loss: 0.18542571365833282
train-epoch-step: 41-237 -- Loss: 0.2372857928276062
train-epoch-step: 41-238 -- Loss: 0.1625572144985199
train-epoch-step: 41-239 -- Loss: 0.12475702911615372
train-epoch-step: 41-240 -- Loss: 0.24931004643440247
train-epoch-step: 41-241 -- Loss: 0.15412169694900513
train-epoch-step: 41-242 -- Loss: 0.22874027490615845
train-epoch-step: 41-243 -- Loss: 0.24278204143047333
train-epoch-step: 41-244 -- Loss: 0.2111109495162964
train-epoch-step: 41-245 -- Loss: 0.21328401565551758
train-epoch-step: 41-246 -- Loss: 0.22459086775779724
train-epoch-step: 41-247 -- Loss: 0.2181389182806015
train-epoch-step: 41-248 -- Loss: 0.20520831644535065
train-epoch-step: 41-249 -- Loss: 0.1418272703886032
train-epoch-step: 41-250 -- Loss: 0.21657530963420868
train-epoch-step: 41-251 -- Loss: 0.10832393169403076
train-epoch-step: 41-252 -- Loss: 0.19559383392333984
train-epoch-step: 41-253 -- Loss: 0.14046402275562286
train-epoch-step: 41-254 -- Loss: 0.2156991809606552
train-epoch-step: 41-255 -- Loss: 0.14237573742866516
train-epoch-step: 41-256 -- Loss: 0.15007144212722778
train-epoch-step: 41-257 -- Loss: 0.18517127633094788
train-epoch-step: 41-258 -- Loss: 0.14625424146652222
train-epoch-step: 41-259 -- Loss: 0.11286555230617523
train-epoch-step: 41-260 -- Loss: 0.20135414600372314
train-epoch-step: 41-261 -- Loss: 0.1708008199930191
train-epoch-step: 41-262 -- Loss: 0.2909244894981384
train-epoch-step: 41-263 -- Loss: 0.20863942801952362
train-epoch-step: 41-264 -- Loss: 0.17215342819690704
train-epoch-step: 41-265 -- Loss: 0.11508283019065857
train-epoch-step: 41-266 -- Loss: 0.15235038101673126
train-epoch-step: 41-267 -- Loss: 0.12782569229602814
train-epoch-step: 41-268 -- Loss: 0.12242412567138672
train-epoch-step: 41-269 -- Loss: 0.17196914553642273
train-epoch-step: 41-270 -- Loss: 0.1056964173913002
train-epoch-step: 41-271 -- Loss: 0.14774593710899353
train-epoch-step: 41-272 -- Loss: 0.11529738456010818
train-epoch-step: 41-273 -- Loss: 0.12647747993469238
train-epoch-step: 41-274 -- Loss: 0.18289197981357574
train-epoch-step: 41-275 -- Loss: 0.18884797394275665
train-epoch-step: 41-276 -- Loss: 0.1544039100408554
train-epoch-step: 41-277 -- Loss: 0.1570201963186264
train-epoch-step: 41-278 -- Loss: 0.13985618948936462
train-epoch-step: 41-279 -- Loss: 0.13990917801856995
train-epoch-step: 41-280 -- Loss: 0.21870912611484528
train-epoch-step: 41-281 -- Loss: 0.17229360342025757
train-epoch-step: 41-282 -- Loss: 0.1400202512741089
train-epoch-step: 41-283 -- Loss: 0.11455310136079788
train-epoch-step: 41-284 -- Loss: 0.13553008437156677
train-epoch-step: 41-285 -- Loss: 0.19732362031936646
train-epoch-step: 41-286 -- Loss: 0.15054866671562195
train-epoch-step: 41-287 -- Loss: 0.19860076904296875
train-epoch-step: 41-288 -- Loss: 0.09597232937812805
train-epoch-step: 41-289 -- Loss: 0.11940208822488785
train-epoch-step: 41-290 -- Loss: 0.17951299250125885
train-epoch-step: 41-291 -- Loss: 0.11806224286556244
train-epoch-step: 41-292 -- Loss: 0.15488077700138092
train-epoch-step: 41-293 -- Loss: 0.14157414436340332
train-epoch-step: 41-294 -- Loss: 0.1546686887741089
train-epoch-step: 41-295 -- Loss: 0.26460587978363037
train-epoch-step: 41-296 -- Loss: 0.1567332148551941
train-epoch-step: 41-297 -- Loss: 0.17196372151374817
train-epoch-step: 41-298 -- Loss: 0.22816678881645203
train-epoch-step: 41-299 -- Loss: 0.1482659876346588
train-epoch-step: 41-300 -- Loss: 0.16057413816452026
train-epoch-step: 41-301 -- Loss: 0.1694161295890808
train-epoch-step: 41-302 -- Loss: 0.21976764500141144
train-epoch-step: 41-303 -- Loss: 0.20279645919799805
train-epoch-step: 41-304 -- Loss: 0.1253925859928131
train-epoch-step: 41-305 -- Loss: 0.145787313580513
train-epoch-step: 41-306 -- Loss: 0.21915611624717712
train-epoch-step: 41-307 -- Loss: 0.16692620515823364
train-epoch-step: 41-308 -- Loss: 0.21865519881248474
train-epoch-step: 41-309 -- Loss: 0.16185805201530457
train-epoch-step: 41-310 -- Loss: 0.1644268035888672
train-epoch-step: 41-311 -- Loss: 0.1590801477432251
train-epoch-step: 41-312 -- Loss: 0.20508798956871033
train-epoch-step: 41-313 -- Loss: 0.10165286064147949
train-epoch-step: 41-314 -- Loss: 0.19005408883094788
train-epoch-step: 41-315 -- Loss: 0.1660792976617813
train-epoch-step: 41-316 -- Loss: 0.15490281581878662
train-epoch-step: 41-317 -- Loss: 0.13993655145168304
train-epoch-step: 41-318 -- Loss: 0.15942387282848358
train-epoch-step: 41-319 -- Loss: 0.17043985426425934
train-epoch-step: 41-320 -- Loss: 0.11639395356178284
train-epoch-step: 41-321 -- Loss: 0.1337803602218628
train-epoch-step: 41-322 -- Loss: 0.21151228249073029
train-epoch-step: 41-323 -- Loss: 0.15521493554115295
train-epoch-step: 41-324 -- Loss: 0.2510993182659149
train-epoch-step: 41-325 -- Loss: 0.15405796468257904
train-epoch-step: 41-326 -- Loss: 0.16748470067977905
train-epoch-step: 41-327 -- Loss: 0.20146296918392181
train-epoch-step: 41-328 -- Loss: 0.19996041059494019
train-epoch-step: 41-329 -- Loss: 0.34094083309173584
train-epoch-step: 41-330 -- Loss: 0.3606988191604614
train-epoch-step: 41-331 -- Loss: 0.20894823968410492
train-epoch-step: 41-332 -- Loss: 0.09922830760478973
train-epoch-step: 41-333 -- Loss: 0.1811905950307846
train-epoch-step: 41-334 -- Loss: 0.1549295336008072
train-epoch-step: 41-335 -- Loss: 0.17080003023147583
train-epoch-step: 41-336 -- Loss: 0.14757481217384338
train-epoch-step: 41-337 -- Loss: 0.20221763849258423
train-epoch-step: 41-338 -- Loss: 0.15773583948612213
train-epoch-step: 41-339 -- Loss: 0.14167381823062897
train-epoch-step: 41-340 -- Loss: 0.19279511272907257
train-epoch-step: 41-341 -- Loss: 0.13700026273727417
train-epoch-step: 41-342 -- Loss: 0.16061928868293762
train-epoch-step: 41-343 -- Loss: 0.15184345841407776
train-epoch-step: 41-344 -- Loss: 0.16590149700641632
train-epoch-step: 41-345 -- Loss: 0.1284281313419342
train-epoch-step: 41-346 -- Loss: 0.2035134732723236
train-epoch-step: 41-347 -- Loss: 0.1508677899837494
train-epoch-step: 41-348 -- Loss: 0.1987222135066986
train-epoch-step: 41-349 -- Loss: 0.20469892024993896
train-epoch-step: 41-350 -- Loss: 0.2547386884689331
train-epoch-step: 41-351 -- Loss: 0.1917465776205063
train-epoch-step: 41-352 -- Loss: 0.125326007604599
train-epoch-step: 41-353 -- Loss: 0.1906982958316803
train-epoch-step: 41-354 -- Loss: 0.28665146231651306
train-epoch-step: 41-355 -- Loss: 0.11613205820322037
train-epoch-step: 41-356 -- Loss: 0.11610350012779236
train-epoch-step: 41-357 -- Loss: 0.19052085280418396
train-epoch-step: 41-358 -- Loss: 0.18603210151195526
train-epoch-step: 41-359 -- Loss: 0.14112310111522675
train-epoch-step: 41-360 -- Loss: 0.12250611186027527
train-epoch-step: 41-361 -- Loss: 0.23755618929862976
train-epoch-step: 41-362 -- Loss: 0.16729208827018738
train-epoch-step: 41-363 -- Loss: 0.10987254232168198
train-epoch-step: 41-364 -- Loss: 0.17485982179641724
train-epoch-step: 41-365 -- Loss: 0.16992592811584473
train-epoch-step: 41-366 -- Loss: 0.20064033567905426
train-epoch-step: 41-367 -- Loss: 0.2320476472377777
train-epoch-step: 41-368 -- Loss: 0.2019282430410385
train-epoch-step: 41-369 -- Loss: 0.2738201916217804
train-epoch-step: 41-370 -- Loss: 0.1235797256231308
train-epoch-step: 41-371 -- Loss: 0.12085119634866714
train-epoch-step: 41-372 -- Loss: 0.14328359067440033
train-epoch-step: 41-373 -- Loss: 0.18736104667186737
train-epoch-step: 41-374 -- Loss: 0.1526307761669159
train-epoch-step: 41-375 -- Loss: 0.2612398862838745
train-epoch-step: 41-376 -- Loss: 0.16494323313236237
train-epoch-step: 41-377 -- Loss: 0.22450652718544006
train-epoch-step: 41-378 -- Loss: 0.19611342251300812
train-epoch-step: 41-379 -- Loss: 0.11684465408325195
train-epoch-step: 41-380 -- Loss: 0.0903380960226059
train-epoch-step: 41-381 -- Loss: 0.24000006914138794
train-epoch-step: 41-382 -- Loss: 0.22720956802368164
train-epoch-step: 41-383 -- Loss: 0.17946553230285645
train-epoch-step: 41-384 -- Loss: 0.20985183119773865
train-epoch-step: 41-385 -- Loss: 0.1865774244070053
train-epoch-step: 41-386 -- Loss: 0.1861097812652588
train-epoch-step: 41-387 -- Loss: 0.19571852684020996
train-epoch-step: 41-388 -- Loss: 0.19097301363945007
train-epoch-step: 41-389 -- Loss: 0.16655881702899933
train-epoch-step: 41-390 -- Loss: 0.13846231997013092
train-epoch-step: 41-391 -- Loss: 0.14196167886257172
train-epoch-step: 41-392 -- Loss: 0.1832544356584549
train-epoch-step: 41-393 -- Loss: 0.15409275889396667
train-epoch-step: 41-394 -- Loss: 0.19750165939331055
train-epoch-step: 41-395 -- Loss: 0.15853124856948853
train-epoch-step: 41-396 -- Loss: 0.12458398938179016
train-epoch-step: 41-397 -- Loss: 0.12182866036891937
train-epoch-step: 41-398 -- Loss: 0.1936367154121399
train-epoch-step: 41-399 -- Loss: 0.1713169664144516
train-epoch-step: 41-400 -- Loss: 0.2745722532272339
train-epoch-step: 41-401 -- Loss: 0.11910068243741989
train-epoch-step: 41-402 -- Loss: 0.25086086988449097
train-epoch-step: 41-403 -- Loss: 0.1514482945203781
train-epoch-step: 41-404 -- Loss: 0.1435299515724182
train-epoch-step: 41-405 -- Loss: 0.1406109631061554
train-epoch-step: 41-406 -- Loss: 0.16546955704689026
train-epoch-step: 41-407 -- Loss: 0.11176761239767075
train-epoch-step: 41-408 -- Loss: 0.15724386274814606
train-epoch-step: 41-409 -- Loss: 0.16807562112808228
train-epoch-step: 41-410 -- Loss: 0.1784639060497284
train-epoch-step: 41-411 -- Loss: 0.20276756584644318
train-epoch-step: 41-412 -- Loss: 0.12894307076931
train-epoch-step: 41-413 -- Loss: 0.14290620386600494
train-epoch-step: 41-414 -- Loss: 0.13175053894519806
train-epoch-step: 41-415 -- Loss: 0.13236092031002045
train-epoch-step: 41-416 -- Loss: 0.26049870252609253
train-epoch-step: 41-417 -- Loss: 0.18730387091636658
train-epoch-step: 41-418 -- Loss: 0.22668899595737457
train-epoch-step: 41-419 -- Loss: 0.1650785654783249
train-epoch-step: 41-420 -- Loss: 0.15090392529964447
train-epoch-step: 41-421 -- Loss: 0.1738729178905487
train-epoch-step: 41-422 -- Loss: 0.14604508876800537
train-epoch-step: 41-423 -- Loss: 0.17378577589988708
train-epoch-step: 41-424 -- Loss: 0.13604874908924103
train-epoch-step: 41-425 -- Loss: 0.18345996737480164
train-epoch-step: 41-426 -- Loss: 0.16469505429267883
train-epoch-step: 41-427 -- Loss: 0.12344367057085037
train-epoch-step: 41-428 -- Loss: 0.20664644241333008
train-epoch-step: 41-429 -- Loss: 0.17190811038017273
train-epoch-step: 41-430 -- Loss: 0.1367378532886505
train-epoch-step: 41-431 -- Loss: 0.16522009670734406
train-epoch-step: 41-432 -- Loss: 0.23874415457248688
train-epoch-step: 41-433 -- Loss: 0.1378912776708603
train-epoch-step: 41-434 -- Loss: 0.13547147810459137
train-epoch-step: 41-435 -- Loss: 0.15252310037612915
train-epoch-step: 41-436 -- Loss: 0.15698949992656708
train-epoch-step: 41-437 -- Loss: 0.13041818141937256
train-epoch-step: 41-438 -- Loss: 0.1673334538936615
train-epoch-step: 41-439 -- Loss: 0.25904732942581177
train-epoch-step: 41-440 -- Loss: 0.13177290558815002
train-epoch-step: 41-441 -- Loss: 0.20456071197986603
train-epoch-step: 41-442 -- Loss: 0.18175974488258362
train-epoch-step: 41-443 -- Loss: 0.15009652078151703
train-epoch-step: 41-444 -- Loss: 0.16972847282886505
train-epoch-step: 41-445 -- Loss: 0.17653344571590424
train-epoch-step: 41-446 -- Loss: 0.15363973379135132
train-epoch-step: 41-447 -- Loss: 0.18704572319984436
train-epoch-step: 41-448 -- Loss: 0.22686254978179932
train-epoch-step: 41-449 -- Loss: 0.18424870073795319
train-epoch-step: 41-450 -- Loss: 0.1786995828151703
train-epoch-step: 41-451 -- Loss: 0.13969086110591888
train-epoch-step: 41-452 -- Loss: 0.13243260979652405
train-epoch-step: 41-453 -- Loss: 0.08982924371957779
train-epoch-step: 41-454 -- Loss: 0.22750365734100342
train-epoch-step: 41-455 -- Loss: 0.12547878921031952
train-epoch-step: 41-456 -- Loss: 0.11629258841276169
train-epoch-step: 41-457 -- Loss: 0.21277692914009094
train-epoch-step: 41-458 -- Loss: 0.14208370447158813
train-epoch-step: 41-459 -- Loss: 0.21510963141918182
train-epoch-step: 41-460 -- Loss: 0.12266194820404053
train-epoch-step: 41-461 -- Loss: 0.13192005455493927
train-epoch-step: 41-462 -- Loss: 0.1637301743030548
train-epoch-step: 41-463 -- Loss: 0.13246333599090576
train-epoch-step: 41-464 -- Loss: 0.16247311234474182
train-epoch-step: 41-465 -- Loss: 0.23594143986701965
train-epoch-step: 41-466 -- Loss: 0.19757211208343506
train-epoch-step: 41-467 -- Loss: 0.1125900149345398
train-epoch-step: 41-468 -- Loss: 0.16693848371505737
train-epoch-step: 41-469 -- Loss: 0.20857158303260803
train-epoch-step: 41-470 -- Loss: 0.17140279710292816
train-epoch-step: 41-471 -- Loss: 0.15934143960475922
train-epoch-step: 41-472 -- Loss: 0.15495501458644867
train-epoch-step: 41-473 -- Loss: 0.1606387048959732
train-epoch-step: 41-474 -- Loss: 0.11691480875015259
train-epoch-step: 41-475 -- Loss: 0.10799070447683334
train-epoch-step: 41-476 -- Loss: 0.1966431885957718
train-epoch-step: 41-477 -- Loss: 0.19795338809490204
train-epoch-step: 41-478 -- Loss: 0.1895558089017868
train-epoch-step: 41-479 -- Loss: 0.13967114686965942
train-epoch-step: 41-480 -- Loss: 0.19375252723693848
train-epoch-step: 41-481 -- Loss: 0.27838820219039917
train-epoch-step: 41-482 -- Loss: 0.24865269660949707
train-epoch-step: 41-483 -- Loss: 0.1779104769229889
train-epoch-step: 41-484 -- Loss: 0.20921418070793152
train-epoch-step: 41-485 -- Loss: 0.1249656230211258
train-epoch-step: 41-486 -- Loss: 0.23174071311950684
train-epoch-step: 41-487 -- Loss: 0.23109914362430573
train-epoch-step: 41-488 -- Loss: 0.18882162868976593
train-epoch-step: 41-489 -- Loss: 0.21384772658348083
train-epoch-step: 41-490 -- Loss: 0.1353103667497635
train-epoch-step: 41-491 -- Loss: 0.13238942623138428
train-epoch-step: 41-492 -- Loss: 0.12798359990119934
train-epoch-step: 41-493 -- Loss: 0.19603799283504486
train-epoch-step: 41-494 -- Loss: 0.2020101696252823
train-epoch-step: 41-495 -- Loss: 0.20087285339832306
train-epoch-step: 41-496 -- Loss: 0.13769204914569855
train-epoch-step: 41-497 -- Loss: 0.17879195511341095
train-epoch-step: 41-498 -- Loss: 0.1457749754190445
train-epoch-step: 41-499 -- Loss: 0.16300879418849945
train-epoch-step: 41-500 -- Loss: 0.15333500504493713
train-epoch-step: 41-501 -- Loss: 0.2186281979084015
train-epoch-step: 41-502 -- Loss: 0.1583077311515808
train-epoch-step: 41-503 -- Loss: 0.2124093770980835
train-epoch-step: 41-504 -- Loss: 0.11785253882408142
train-epoch-step: 41-505 -- Loss: 0.16980132460594177
train-epoch-step: 41-506 -- Loss: 0.1131487637758255
train-epoch-step: 41-507 -- Loss: 0.17828641831874847
train-epoch-step: 41-508 -- Loss: 0.17328332364559174
train-epoch-step: 41-509 -- Loss: 0.17324060201644897
train-epoch-step: 41-510 -- Loss: 0.12267415225505829
train-epoch-step: 41-511 -- Loss: 0.2164560854434967
train-epoch-step: 41-512 -- Loss: 0.1764722764492035
train-epoch-step: 41-513 -- Loss: 0.1851864457130432
train-epoch-step: 41-514 -- Loss: 0.14379630982875824
train-epoch-step: 41-515 -- Loss: 0.1526961624622345
train-epoch-step: 41-516 -- Loss: 0.1682855784893036
train-epoch-step: 41-517 -- Loss: 0.17038600146770477
train-epoch-step: 41-518 -- Loss: 0.13323655724525452
train-epoch-step: 41-519 -- Loss: 0.13133622705936432
train-epoch-step: 41-520 -- Loss: 0.18346786499023438
train-epoch-step: 41-521 -- Loss: 0.22878074645996094
train-epoch-step: 41-522 -- Loss: 0.17504334449768066
train-epoch-step: 41-523 -- Loss: 0.15817731618881226
train-epoch-step: 41-524 -- Loss: 0.17042885720729828
train-epoch-step: 41-525 -- Loss: 0.19488872587680817
train-epoch-step: 41-526 -- Loss: 0.1285375952720642
train-epoch-step: 41-527 -- Loss: 0.15046527981758118
train-epoch-step: 41-528 -- Loss: 0.15625719726085663
train-epoch-step: 41-529 -- Loss: 0.1559605449438095
train-epoch-step: 41-530 -- Loss: 0.17306619882583618
train-epoch-step: 41-531 -- Loss: 0.19810698926448822
train-epoch-step: 41-532 -- Loss: 0.16785553097724915
train-epoch-step: 41-533 -- Loss: 0.17111077904701233
train-epoch-step: 41-534 -- Loss: 0.13492600619792938
train-epoch-step: 41-535 -- Loss: 0.2528236210346222
train-epoch-step: 41-536 -- Loss: 0.17302164435386658
train-epoch-step: 41-537 -- Loss: 0.14343102276325226
train-epoch-step: 41-538 -- Loss: 0.10350418835878372
train-epoch-step: 41-539 -- Loss: 0.18218141794204712
train-epoch-step: 41-540 -- Loss: 0.1338614523410797
train-epoch-step: 41-541 -- Loss: 0.20736655592918396
train-epoch-step: 41-542 -- Loss: 0.21742257475852966
train-epoch-step: 41-543 -- Loss: 0.16741423308849335
train-epoch-step: 41-544 -- Loss: 0.22880849242210388
train-epoch-step: 41-545 -- Loss: 0.191707044839859
train-epoch-step: 41-546 -- Loss: 0.21124757826328278
train-epoch-step: 41-547 -- Loss: 0.17562317848205566
train-epoch-step: 41-548 -- Loss: 0.0948096364736557
train-epoch-step: 41-549 -- Loss: 0.1576259583234787
train-epoch-step: 41-550 -- Loss: 0.19711564481258392
train-epoch-step: 41-551 -- Loss: 0.1530231088399887
train-epoch-step: 41-552 -- Loss: 0.12483607232570648
train-epoch-step: 41-553 -- Loss: 0.18599441647529602
train-epoch-step: 41-554 -- Loss: 0.18641814589500427
train-epoch-step: 41-555 -- Loss: 0.210299551486969
train-epoch-step: 41-556 -- Loss: 0.14689412713050842
train-epoch-step: 41-557 -- Loss: 0.2261119931936264
train-epoch-step: 41-558 -- Loss: 0.22064384818077087
train-epoch-step: 41-559 -- Loss: 0.1415022313594818
train-epoch-step: 41-560 -- Loss: 0.20595932006835938
train-epoch-step: 41-561 -- Loss: 0.1778595745563507
train-epoch-step: 41-562 -- Loss: 0.1645333170890808
train-epoch-step: 41-563 -- Loss: 0.1786762773990631
train-epoch-step: 41-564 -- Loss: 0.0997207760810852
train-epoch-step: 41-565 -- Loss: 0.17984449863433838
train-epoch-step: 41-566 -- Loss: 0.14605918526649475
train-epoch-step: 41-567 -- Loss: 0.2133772075176239
train-epoch-step: 41-568 -- Loss: 0.15633772313594818
train-epoch-step: 41-569 -- Loss: 0.23437322676181793
train-epoch-step: 41-570 -- Loss: 0.1677027940750122
train-epoch-step: 41-571 -- Loss: 0.21690553426742554
train-epoch-step: 41-572 -- Loss: 0.23131808638572693
train-epoch-step: 41-573 -- Loss: 0.1966048777103424
train-epoch-step: 41-574 -- Loss: 0.24251489341259003
train-epoch-step: 41-575 -- Loss: 0.28761547803878784
train-epoch-step: 41-576 -- Loss: 0.11884574592113495
train-epoch-step: 41-577 -- Loss: 0.16378656029701233
train-epoch-step: 41-578 -- Loss: 0.21146266162395477
train-epoch-step: 41-579 -- Loss: 0.1620062291622162
train-epoch-step: 41-580 -- Loss: 0.1665026694536209
train-epoch-step: 41-581 -- Loss: 0.13689088821411133
train-epoch-step: 41-582 -- Loss: 0.2041405737400055
train-epoch-step: 41-583 -- Loss: 0.21122919023036957
train-epoch-step: 41-584 -- Loss: 0.16127954423427582
train-epoch-step: 41-585 -- Loss: 0.18848781287670135
train-epoch-step: 41-586 -- Loss: 0.25166183710098267
train-epoch-step: 41-587 -- Loss: 0.15587547421455383
train-epoch-step: 41-588 -- Loss: 0.12426786869764328
val-epoch-step: 41-589 -- Loss: 0.1957140415906906
val-epoch-step: 41-590 -- Loss: 0.15217019617557526
val-epoch-step: 41-591 -- Loss: 0.2290405035018921
val-epoch-step: 41-592 -- Loss: 0.17307449877262115
val-epoch-step: 41-593 -- Loss: 0.17253512144088745
val-epoch-step: 41-594 -- Loss: 0.34810248017311096
val-epoch-step: 41-595 -- Loss: 0.20318759977817535
val-epoch-step: 41-596 -- Loss: 0.18928010761737823
val-epoch-step: 41-597 -- Loss: 0.17253999412059784
val-epoch-step: 41-598 -- Loss: 0.14905504882335663
val-epoch-step: 41-599 -- Loss: 0.1798906922340393
val-epoch-step: 41-600 -- Loss: 0.1860055923461914
val-epoch-step: 41-601 -- Loss: 0.15619322657585144
val-epoch-step: 41-602 -- Loss: 0.13804031908512115
val-epoch-step: 41-603 -- Loss: 0.19620028138160706
val-epoch-step: 41-604 -- Loss: 0.15362852811813354
val-epoch-step: 41-605 -- Loss: 0.14619393646717072
val-epoch-step: 41-606 -- Loss: 0.24936407804489136
val-epoch-step: 41-607 -- Loss: 0.1243823692202568
val-epoch-step: 41-608 -- Loss: 0.24788221716880798
val-epoch-step: 41-609 -- Loss: 0.17307332158088684
val-epoch-step: 41-610 -- Loss: 0.178590789437294
val-epoch-step: 41-611 -- Loss: 0.15555596351623535
val-epoch-step: 41-612 -- Loss: 0.4694031774997711
val-epoch-step: 41-613 -- Loss: 0.17394781112670898
val-epoch-step: 41-614 -- Loss: 0.1799791306257248
val-epoch-step: 41-615 -- Loss: 0.17521803081035614
val-epoch-step: 41-616 -- Loss: 0.14749987423419952
val-epoch-step: 41-617 -- Loss: 0.1939978003501892
val-epoch-step: 41-618 -- Loss: 0.1843937337398529
val-epoch-step: 41-619 -- Loss: 0.20517870783805847
val-epoch-step: 41-620 -- Loss: 0.13377606868743896
val-epoch-step: 41-621 -- Loss: 0.12073148041963577
val-epoch-step: 41-622 -- Loss: 0.14469991624355316
val-epoch-step: 41-623 -- Loss: 0.1566864401102066
val-epoch-step: 41-624 -- Loss: 0.14140522480010986
val-epoch-step: 41-625 -- Loss: 0.16763758659362793
val-epoch-step: 41-626 -- Loss: 0.14587236940860748
val-epoch-step: 41-627 -- Loss: 0.19212329387664795
val-epoch-step: 41-628 -- Loss: 0.6226252913475037
val-epoch-step: 41-629 -- Loss: 0.2004692256450653
val-epoch-step: 41-630 -- Loss: 0.3460066020488739
val-epoch-step: 41-631 -- Loss: 0.13902151584625244
val-epoch-step: 41-632 -- Loss: 0.21117086708545685
val-epoch-step: 41-633 -- Loss: 0.1491706371307373
val-epoch-step: 41-634 -- Loss: 0.14033089578151703
val-epoch-step: 41-635 -- Loss: 0.11225196719169617
val-epoch-step: 41-636 -- Loss: 0.16217228770256042
val-epoch-step: 41-637 -- Loss: 0.18457315862178802
val-epoch-step: 41-638 -- Loss: 0.15072640776634216
val-epoch-step: 41-639 -- Loss: 0.25156062841415405
val-epoch-step: 41-640 -- Loss: 0.2545677125453949
val-epoch-step: 41-641 -- Loss: 0.12792383134365082
val-epoch-step: 41-642 -- Loss: 0.1793491095304489
val-epoch-step: 41-643 -- Loss: 0.20059499144554138
val-epoch-step: 41-644 -- Loss: 0.16681277751922607
val-epoch-step: 41-645 -- Loss: 0.21633584797382355
val-epoch-step: 41-646 -- Loss: 0.13049665093421936
val-epoch-step: 41-647 -- Loss: 0.13013726472854614
val-epoch-step: 41-648 -- Loss: 0.15760575234889984
val-epoch-step: 41-649 -- Loss: 0.2109999656677246
val-epoch-step: 41-650 -- Loss: 0.2512955963611603
val-epoch-step: 41-651 -- Loss: 0.1441434770822525
val-epoch-step: 41-652 -- Loss: 0.14981336891651154
val-epoch-step: 41-653 -- Loss: 0.20189571380615234
val-epoch-step: 41-654 -- Loss: 0.10916157811880112
Epoch: 41 -- Train Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 42-0 -- Loss: 0.22754041850566864
train-epoch-step: 42-1 -- Loss: 0.1435500532388687
train-epoch-step: 42-2 -- Loss: 0.1918453723192215
train-epoch-step: 42-3 -- Loss: 0.13821621239185333
train-epoch-step: 42-4 -- Loss: 0.15345484018325806
train-epoch-step: 42-5 -- Loss: 0.18034668266773224
train-epoch-step: 42-6 -- Loss: 0.21351978182792664
train-epoch-step: 42-7 -- Loss: 0.16776622831821442
train-epoch-step: 42-8 -- Loss: 0.18084204196929932
train-epoch-step: 42-9 -- Loss: 0.21766053140163422
train-epoch-step: 42-10 -- Loss: 0.19086438417434692
train-epoch-step: 42-11 -- Loss: 0.1724451184272766
train-epoch-step: 42-12 -- Loss: 0.14679574966430664
train-epoch-step: 42-13 -- Loss: 0.1758759319782257
train-epoch-step: 42-14 -- Loss: 0.15581974387168884
train-epoch-step: 42-15 -- Loss: 0.15958121418952942
train-epoch-step: 42-16 -- Loss: 0.17088180780410767
train-epoch-step: 42-17 -- Loss: 0.2161647379398346
train-epoch-step: 42-18 -- Loss: 0.18923969566822052
train-epoch-step: 42-19 -- Loss: 0.12874296307563782
train-epoch-step: 42-20 -- Loss: 0.21331092715263367
train-epoch-step: 42-21 -- Loss: 0.24044637382030487
train-epoch-step: 42-22 -- Loss: 0.13801103830337524
train-epoch-step: 42-23 -- Loss: 0.13783815503120422
train-epoch-step: 42-24 -- Loss: 0.12683865427970886
train-epoch-step: 42-25 -- Loss: 0.2465749830007553
train-epoch-step: 42-26 -- Loss: 0.2007240355014801
train-epoch-step: 42-27 -- Loss: 0.22311028838157654
train-epoch-step: 42-28 -- Loss: 0.12353626638650894
train-epoch-step: 42-29 -- Loss: 0.23916266858577728
train-epoch-step: 42-30 -- Loss: 0.11227357387542725
train-epoch-step: 42-31 -- Loss: 0.13900607824325562
train-epoch-step: 42-32 -- Loss: 0.16979818046092987
train-epoch-step: 42-33 -- Loss: 0.2684769034385681
train-epoch-step: 42-34 -- Loss: 0.1692480891942978
train-epoch-step: 42-35 -- Loss: 0.24585239589214325
train-epoch-step: 42-36 -- Loss: 0.13362710177898407
train-epoch-step: 42-37 -- Loss: 0.13727232813835144
train-epoch-step: 42-38 -- Loss: 0.1750633716583252
train-epoch-step: 42-39 -- Loss: 0.21817100048065186
train-epoch-step: 42-40 -- Loss: 0.1893177330493927
train-epoch-step: 42-41 -- Loss: 0.21612904965877533
train-epoch-step: 42-42 -- Loss: 0.1473148912191391
train-epoch-step: 42-43 -- Loss: 0.2617628276348114
train-epoch-step: 42-44 -- Loss: 0.12408377975225449
train-epoch-step: 42-45 -- Loss: 0.11541241407394409
train-epoch-step: 42-46 -- Loss: 0.16651250422000885
train-epoch-step: 42-47 -- Loss: 0.2032167911529541
train-epoch-step: 42-48 -- Loss: 0.1539689600467682
train-epoch-step: 42-49 -- Loss: 0.23015451431274414
train-epoch-step: 42-50 -- Loss: 0.11082097887992859
train-epoch-step: 42-51 -- Loss: 0.1746322363615036
train-epoch-step: 42-52 -- Loss: 0.15754616260528564
train-epoch-step: 42-53 -- Loss: 0.20209071040153503
train-epoch-step: 42-54 -- Loss: 0.28081363439559937
train-epoch-step: 42-55 -- Loss: 0.16457128524780273
train-epoch-step: 42-56 -- Loss: 0.17663654685020447
train-epoch-step: 42-57 -- Loss: 0.22874760627746582
train-epoch-step: 42-58 -- Loss: 0.283832311630249
train-epoch-step: 42-59 -- Loss: 0.23478883504867554
train-epoch-step: 42-60 -- Loss: 0.12817786633968353
train-epoch-step: 42-61 -- Loss: 0.19759570062160492
train-epoch-step: 42-62 -- Loss: 0.18303637206554413
train-epoch-step: 42-63 -- Loss: 0.1369221955537796
train-epoch-step: 42-64 -- Loss: 0.14079704880714417
train-epoch-step: 42-65 -- Loss: 0.18186573684215546
train-epoch-step: 42-66 -- Loss: 0.11025810241699219
train-epoch-step: 42-67 -- Loss: 0.12325511127710342
train-epoch-step: 42-68 -- Loss: 0.21091152727603912
train-epoch-step: 42-69 -- Loss: 0.12064236402511597
train-epoch-step: 42-70 -- Loss: 0.21858496963977814
train-epoch-step: 42-71 -- Loss: 0.2608753740787506
train-epoch-step: 42-72 -- Loss: 0.17528927326202393
train-epoch-step: 42-73 -- Loss: 0.21473579108715057
train-epoch-step: 42-74 -- Loss: 0.09476999193429947
train-epoch-step: 42-75 -- Loss: 0.12732315063476562
train-epoch-step: 42-76 -- Loss: 0.14634016156196594
train-epoch-step: 42-77 -- Loss: 0.23004040122032166
train-epoch-step: 42-78 -- Loss: 0.2584066092967987
train-epoch-step: 42-79 -- Loss: 0.19114364683628082
train-epoch-step: 42-80 -- Loss: 0.2531914710998535
train-epoch-step: 42-81 -- Loss: 0.12272454798221588
train-epoch-step: 42-82 -- Loss: 0.2461467683315277
train-epoch-step: 42-83 -- Loss: 0.17726019024848938
train-epoch-step: 42-84 -- Loss: 0.18498703837394714
train-epoch-step: 42-85 -- Loss: 0.17726360261440277
train-epoch-step: 42-86 -- Loss: 0.11884288489818573
train-epoch-step: 42-87 -- Loss: 0.21061429381370544
train-epoch-step: 42-88 -- Loss: 0.1399301439523697
train-epoch-step: 42-89 -- Loss: 0.18619345128536224
train-epoch-step: 42-90 -- Loss: 0.19024796783924103
train-epoch-step: 42-91 -- Loss: 0.24299389123916626
train-epoch-step: 42-92 -- Loss: 0.15225157141685486
train-epoch-step: 42-93 -- Loss: 0.16931675374507904
train-epoch-step: 42-94 -- Loss: 0.2282259613275528
train-epoch-step: 42-95 -- Loss: 0.1925055980682373
train-epoch-step: 42-96 -- Loss: 0.21168357133865356
train-epoch-step: 42-97 -- Loss: 0.17486704885959625
train-epoch-step: 42-98 -- Loss: 0.15848006308078766
train-epoch-step: 42-99 -- Loss: 0.17998668551445007
train-epoch-step: 42-100 -- Loss: 0.1857224851846695
train-epoch-step: 42-101 -- Loss: 0.25700879096984863
train-epoch-step: 42-102 -- Loss: 0.2154792845249176
train-epoch-step: 42-103 -- Loss: 0.18070803582668304
train-epoch-step: 42-104 -- Loss: 0.14848142862319946
train-epoch-step: 42-105 -- Loss: 0.26456743478775024
train-epoch-step: 42-106 -- Loss: 0.1737472116947174
train-epoch-step: 42-107 -- Loss: 0.18356868624687195
train-epoch-step: 42-108 -- Loss: 0.18405023217201233
train-epoch-step: 42-109 -- Loss: 0.14616619050502777
train-epoch-step: 42-110 -- Loss: 0.18504095077514648
train-epoch-step: 42-111 -- Loss: 0.17841777205467224
train-epoch-step: 42-112 -- Loss: 0.16388416290283203
train-epoch-step: 42-113 -- Loss: 0.15889514982700348
train-epoch-step: 42-114 -- Loss: 0.20048943161964417
train-epoch-step: 42-115 -- Loss: 0.1581798493862152
train-epoch-step: 42-116 -- Loss: 0.13796697556972504
train-epoch-step: 42-117 -- Loss: 0.1257161647081375
train-epoch-step: 42-118 -- Loss: 0.19361917674541473
train-epoch-step: 42-119 -- Loss: 0.1508314311504364
train-epoch-step: 42-120 -- Loss: 0.24531202018260956
train-epoch-step: 42-121 -- Loss: 0.22759732604026794
train-epoch-step: 42-122 -- Loss: 0.21390016376972198
train-epoch-step: 42-123 -- Loss: 0.20206910371780396
train-epoch-step: 42-124 -- Loss: 0.12024425715208054
train-epoch-step: 42-125 -- Loss: 0.15352556109428406
train-epoch-step: 42-126 -- Loss: 0.22750067710876465
train-epoch-step: 42-127 -- Loss: 0.1624028980731964
train-epoch-step: 42-128 -- Loss: 0.1683807224035263
train-epoch-step: 42-129 -- Loss: 0.14144669473171234
train-epoch-step: 42-130 -- Loss: 0.18532975018024445
train-epoch-step: 42-131 -- Loss: 0.13841751217842102
train-epoch-step: 42-132 -- Loss: 0.18917503952980042
train-epoch-step: 42-133 -- Loss: 0.11650669574737549
train-epoch-step: 42-134 -- Loss: 0.18903309106826782
train-epoch-step: 42-135 -- Loss: 0.13385529816150665
train-epoch-step: 42-136 -- Loss: 0.12755130231380463
train-epoch-step: 42-137 -- Loss: 0.23549580574035645
train-epoch-step: 42-138 -- Loss: 0.25225013494491577
train-epoch-step: 42-139 -- Loss: 0.13137485086917877
train-epoch-step: 42-140 -- Loss: 0.2036762237548828
train-epoch-step: 42-141 -- Loss: 0.22965390980243683
train-epoch-step: 42-142 -- Loss: 0.20001444220542908
train-epoch-step: 42-143 -- Loss: 0.18491974472999573
train-epoch-step: 42-144 -- Loss: 0.18319642543792725
train-epoch-step: 42-145 -- Loss: 0.13945090770721436
train-epoch-step: 42-146 -- Loss: 0.17698952555656433
train-epoch-step: 42-147 -- Loss: 0.1746990978717804
train-epoch-step: 42-148 -- Loss: 0.15981563925743103
train-epoch-step: 42-149 -- Loss: 0.1255425661802292
train-epoch-step: 42-150 -- Loss: 0.18089736998081207
train-epoch-step: 42-151 -- Loss: 0.1865784227848053
train-epoch-step: 42-152 -- Loss: 0.19517095386981964
train-epoch-step: 42-153 -- Loss: 0.26176583766937256
train-epoch-step: 42-154 -- Loss: 0.13003171980381012
train-epoch-step: 42-155 -- Loss: 0.13470377027988434
train-epoch-step: 42-156 -- Loss: 0.11825931817293167
train-epoch-step: 42-157 -- Loss: 0.16457325220108032
train-epoch-step: 42-158 -- Loss: 0.1682227998971939
train-epoch-step: 42-159 -- Loss: 0.17564955353736877
train-epoch-step: 42-160 -- Loss: 0.21432755887508392
train-epoch-step: 42-161 -- Loss: 0.19191531836986542
train-epoch-step: 42-162 -- Loss: 0.20872072875499725
train-epoch-step: 42-163 -- Loss: 0.18461079895496368
train-epoch-step: 42-164 -- Loss: 0.18920056521892548
train-epoch-step: 42-165 -- Loss: 0.1610783338546753
train-epoch-step: 42-166 -- Loss: 0.12206844985485077
train-epoch-step: 42-167 -- Loss: 0.12146003544330597
train-epoch-step: 42-168 -- Loss: 0.20121005177497864
train-epoch-step: 42-169 -- Loss: 0.13898633420467377
train-epoch-step: 42-170 -- Loss: 0.19354410469532013
train-epoch-step: 42-171 -- Loss: 0.14655038714408875
train-epoch-step: 42-172 -- Loss: 0.2598881423473358
train-epoch-step: 42-173 -- Loss: 0.133839949965477
train-epoch-step: 42-174 -- Loss: 0.24784432351589203
train-epoch-step: 42-175 -- Loss: 0.18309426307678223
train-epoch-step: 42-176 -- Loss: 0.12752074003219604
train-epoch-step: 42-177 -- Loss: 0.18284478783607483
train-epoch-step: 42-178 -- Loss: 0.1768786460161209
train-epoch-step: 42-179 -- Loss: 0.1428575962781906
train-epoch-step: 42-180 -- Loss: 0.14981767535209656
train-epoch-step: 42-181 -- Loss: 0.16620419919490814
train-epoch-step: 42-182 -- Loss: 0.18987220525741577
train-epoch-step: 42-183 -- Loss: 0.26501893997192383
train-epoch-step: 42-184 -- Loss: 0.13796676695346832
train-epoch-step: 42-185 -- Loss: 0.13946588337421417
train-epoch-step: 42-186 -- Loss: 0.18251430988311768
train-epoch-step: 42-187 -- Loss: 0.20632290840148926
train-epoch-step: 42-188 -- Loss: 0.1740713268518448
train-epoch-step: 42-189 -- Loss: 0.10559938848018646
train-epoch-step: 42-190 -- Loss: 0.1783783733844757
train-epoch-step: 42-191 -- Loss: 0.1534135639667511
train-epoch-step: 42-192 -- Loss: 0.2263379693031311
train-epoch-step: 42-193 -- Loss: 0.19734130799770355
train-epoch-step: 42-194 -- Loss: 0.1847696453332901
train-epoch-step: 42-195 -- Loss: 0.16487780213356018
train-epoch-step: 42-196 -- Loss: 0.1657997965812683
train-epoch-step: 42-197 -- Loss: 0.12178436666727066
train-epoch-step: 42-198 -- Loss: 0.12496484816074371
train-epoch-step: 42-199 -- Loss: 0.15936587750911713
train-epoch-step: 42-200 -- Loss: 0.12891581654548645
train-epoch-step: 42-201 -- Loss: 0.18425363302230835
train-epoch-step: 42-202 -- Loss: 0.13409097492694855
train-epoch-step: 42-203 -- Loss: 0.17053332924842834
train-epoch-step: 42-204 -- Loss: 0.13388359546661377
train-epoch-step: 42-205 -- Loss: 0.1964779794216156
train-epoch-step: 42-206 -- Loss: 0.19770361483097076
train-epoch-step: 42-207 -- Loss: 0.13154108822345734
train-epoch-step: 42-208 -- Loss: 0.2121734321117401
train-epoch-step: 42-209 -- Loss: 0.13872215151786804
train-epoch-step: 42-210 -- Loss: 0.13091157376766205
train-epoch-step: 42-211 -- Loss: 0.2019316554069519
train-epoch-step: 42-212 -- Loss: 0.2008732259273529
train-epoch-step: 42-213 -- Loss: 0.12455132603645325
train-epoch-step: 42-214 -- Loss: 0.15163859724998474
train-epoch-step: 42-215 -- Loss: 0.12867115437984467
train-epoch-step: 42-216 -- Loss: 0.20499414205551147
train-epoch-step: 42-217 -- Loss: 0.21348553895950317
train-epoch-step: 42-218 -- Loss: 0.14354299008846283
train-epoch-step: 42-219 -- Loss: 0.17183363437652588
train-epoch-step: 42-220 -- Loss: 0.1296243965625763
train-epoch-step: 42-221 -- Loss: 0.20151618123054504
train-epoch-step: 42-222 -- Loss: 0.11632728576660156
train-epoch-step: 42-223 -- Loss: 0.17002612352371216
train-epoch-step: 42-224 -- Loss: 0.18623274564743042
train-epoch-step: 42-225 -- Loss: 0.263520747423172
train-epoch-step: 42-226 -- Loss: 0.20306025445461273
train-epoch-step: 42-227 -- Loss: 0.22019870579242706
train-epoch-step: 42-228 -- Loss: 0.19431310892105103
train-epoch-step: 42-229 -- Loss: 0.17352402210235596
train-epoch-step: 42-230 -- Loss: 0.1655457317829132
train-epoch-step: 42-231 -- Loss: 0.15511995553970337
train-epoch-step: 42-232 -- Loss: 0.1977674663066864
train-epoch-step: 42-233 -- Loss: 0.08264998346567154
train-epoch-step: 42-234 -- Loss: 0.1735174059867859
train-epoch-step: 42-235 -- Loss: 0.13881957530975342
train-epoch-step: 42-236 -- Loss: 0.18523761630058289
train-epoch-step: 42-237 -- Loss: 0.23379862308502197
train-epoch-step: 42-238 -- Loss: 0.16576901078224182
train-epoch-step: 42-239 -- Loss: 0.1258973926305771
train-epoch-step: 42-240 -- Loss: 0.2174348086118698
train-epoch-step: 42-241 -- Loss: 0.1551269292831421
train-epoch-step: 42-242 -- Loss: 0.22037458419799805
train-epoch-step: 42-243 -- Loss: 0.23230218887329102
train-epoch-step: 42-244 -- Loss: 0.2036498486995697
train-epoch-step: 42-245 -- Loss: 0.21006308495998383
train-epoch-step: 42-246 -- Loss: 0.21667617559432983
train-epoch-step: 42-247 -- Loss: 0.23071709275245667
train-epoch-step: 42-248 -- Loss: 0.1834818720817566
train-epoch-step: 42-249 -- Loss: 0.13926799595355988
train-epoch-step: 42-250 -- Loss: 0.20456039905548096
train-epoch-step: 42-251 -- Loss: 0.10663219541311264
train-epoch-step: 42-252 -- Loss: 0.18934644758701324
train-epoch-step: 42-253 -- Loss: 0.13338398933410645
train-epoch-step: 42-254 -- Loss: 0.2145310789346695
train-epoch-step: 42-255 -- Loss: 0.1427541971206665
train-epoch-step: 42-256 -- Loss: 0.14428161084651947
train-epoch-step: 42-257 -- Loss: 0.18746694922447205
train-epoch-step: 42-258 -- Loss: 0.1434478908777237
train-epoch-step: 42-259 -- Loss: 0.11175868660211563
train-epoch-step: 42-260 -- Loss: 0.19680346548557281
train-epoch-step: 42-261 -- Loss: 0.17046107351779938
train-epoch-step: 42-262 -- Loss: 0.2833501398563385
train-epoch-step: 42-263 -- Loss: 0.1945374608039856
train-epoch-step: 42-264 -- Loss: 0.17218948900699615
train-epoch-step: 42-265 -- Loss: 0.12005969136953354
train-epoch-step: 42-266 -- Loss: 0.15431156754493713
train-epoch-step: 42-267 -- Loss: 0.12837065756320953
train-epoch-step: 42-268 -- Loss: 0.11664021015167236
train-epoch-step: 42-269 -- Loss: 0.1691524088382721
train-epoch-step: 42-270 -- Loss: 0.1065184473991394
train-epoch-step: 42-271 -- Loss: 0.14396342635154724
train-epoch-step: 42-272 -- Loss: 0.11816181987524033
train-epoch-step: 42-273 -- Loss: 0.12414997071027756
train-epoch-step: 42-274 -- Loss: 0.18051530420780182
train-epoch-step: 42-275 -- Loss: 0.1921577900648117
train-epoch-step: 42-276 -- Loss: 0.15431061387062073
train-epoch-step: 42-277 -- Loss: 0.1532856523990631
train-epoch-step: 42-278 -- Loss: 0.13919253647327423
train-epoch-step: 42-279 -- Loss: 0.13526278734207153
train-epoch-step: 42-280 -- Loss: 0.21278207004070282
train-epoch-step: 42-281 -- Loss: 0.17137861251831055
train-epoch-step: 42-282 -- Loss: 0.14255817234516144
train-epoch-step: 42-283 -- Loss: 0.11352898180484772
train-epoch-step: 42-284 -- Loss: 0.13149327039718628
train-epoch-step: 42-285 -- Loss: 0.18843410909175873
train-epoch-step: 42-286 -- Loss: 0.15384195744991302
train-epoch-step: 42-287 -- Loss: 0.20501253008842468
train-epoch-step: 42-288 -- Loss: 0.09288234263658524
train-epoch-step: 42-289 -- Loss: 0.12296207249164581
train-epoch-step: 42-290 -- Loss: 0.18283431231975555
train-epoch-step: 42-291 -- Loss: 0.115663081407547
train-epoch-step: 42-292 -- Loss: 0.15571622550487518
train-epoch-step: 42-293 -- Loss: 0.13664935529232025
train-epoch-step: 42-294 -- Loss: 0.16486646234989166
train-epoch-step: 42-295 -- Loss: 0.26302698254585266
train-epoch-step: 42-296 -- Loss: 0.15507732331752777
train-epoch-step: 42-297 -- Loss: 0.17263007164001465
train-epoch-step: 42-298 -- Loss: 0.23163320124149323
train-epoch-step: 42-299 -- Loss: 0.15541291236877441
train-epoch-step: 42-300 -- Loss: 0.1620655357837677
train-epoch-step: 42-301 -- Loss: 0.17235536873340607
train-epoch-step: 42-302 -- Loss: 0.22001801431179047
train-epoch-step: 42-303 -- Loss: 0.2041759490966797
train-epoch-step: 42-304 -- Loss: 0.12655386328697205
train-epoch-step: 42-305 -- Loss: 0.14251884818077087
train-epoch-step: 42-306 -- Loss: 0.2125828117132187
train-epoch-step: 42-307 -- Loss: 0.16766011714935303
train-epoch-step: 42-308 -- Loss: 0.21558701992034912
train-epoch-step: 42-309 -- Loss: 0.15079034864902496
train-epoch-step: 42-310 -- Loss: 0.15893498063087463
train-epoch-step: 42-311 -- Loss: 0.1595204770565033
train-epoch-step: 42-312 -- Loss: 0.2042332887649536
train-epoch-step: 42-313 -- Loss: 0.0991099402308464
train-epoch-step: 42-314 -- Loss: 0.18849441409111023
train-epoch-step: 42-315 -- Loss: 0.1677614152431488
train-epoch-step: 42-316 -- Loss: 0.1501818299293518
train-epoch-step: 42-317 -- Loss: 0.13680195808410645
train-epoch-step: 42-318 -- Loss: 0.1601562798023224
train-epoch-step: 42-319 -- Loss: 0.18426957726478577
train-epoch-step: 42-320 -- Loss: 0.11586141586303711
train-epoch-step: 42-321 -- Loss: 0.13132667541503906
train-epoch-step: 42-322 -- Loss: 0.2102154791355133
train-epoch-step: 42-323 -- Loss: 0.16001571714878082
train-epoch-step: 42-324 -- Loss: 0.24895991384983063
train-epoch-step: 42-325 -- Loss: 0.15026013553142548
train-epoch-step: 42-326 -- Loss: 0.1788986325263977
train-epoch-step: 42-327 -- Loss: 0.2090461254119873
train-epoch-step: 42-328 -- Loss: 0.19599176943302155
train-epoch-step: 42-329 -- Loss: 0.3327973186969757
train-epoch-step: 42-330 -- Loss: 0.3543318212032318
train-epoch-step: 42-331 -- Loss: 0.2058660089969635
train-epoch-step: 42-332 -- Loss: 0.09644586592912674
train-epoch-step: 42-333 -- Loss: 0.18568062782287598
train-epoch-step: 42-334 -- Loss: 0.15839064121246338
train-epoch-step: 42-335 -- Loss: 0.17979571223258972
train-epoch-step: 42-336 -- Loss: 0.14712272584438324
train-epoch-step: 42-337 -- Loss: 0.19914744794368744
train-epoch-step: 42-338 -- Loss: 0.15570971369743347
train-epoch-step: 42-339 -- Loss: 0.14090970158576965
train-epoch-step: 42-340 -- Loss: 0.19644612073898315
train-epoch-step: 42-341 -- Loss: 0.13817834854125977
train-epoch-step: 42-342 -- Loss: 0.1635696291923523
train-epoch-step: 42-343 -- Loss: 0.15120337903499603
train-epoch-step: 42-344 -- Loss: 0.16748081147670746
train-epoch-step: 42-345 -- Loss: 0.12793458998203278
train-epoch-step: 42-346 -- Loss: 0.19834771752357483
train-epoch-step: 42-347 -- Loss: 0.1511627584695816
train-epoch-step: 42-348 -- Loss: 0.20305848121643066
train-epoch-step: 42-349 -- Loss: 0.20518597960472107
train-epoch-step: 42-350 -- Loss: 0.24705839157104492
train-epoch-step: 42-351 -- Loss: 0.1935787945985794
train-epoch-step: 42-352 -- Loss: 0.12090946733951569
train-epoch-step: 42-353 -- Loss: 0.19374340772628784
train-epoch-step: 42-354 -- Loss: 0.2836494445800781
train-epoch-step: 42-355 -- Loss: 0.11758451908826828
train-epoch-step: 42-356 -- Loss: 0.11529406905174255
train-epoch-step: 42-357 -- Loss: 0.19496504962444305
train-epoch-step: 42-358 -- Loss: 0.18055786192417145
train-epoch-step: 42-359 -- Loss: 0.13804779946804047
train-epoch-step: 42-360 -- Loss: 0.12265224754810333
train-epoch-step: 42-361 -- Loss: 0.2343645840883255
train-epoch-step: 42-362 -- Loss: 0.17596639692783356
train-epoch-step: 42-363 -- Loss: 0.10975196957588196
train-epoch-step: 42-364 -- Loss: 0.1778893768787384
train-epoch-step: 42-365 -- Loss: 0.1642020046710968
train-epoch-step: 42-366 -- Loss: 0.1961357593536377
train-epoch-step: 42-367 -- Loss: 0.22828108072280884
train-epoch-step: 42-368 -- Loss: 0.20042282342910767
train-epoch-step: 42-369 -- Loss: 0.2785237431526184
train-epoch-step: 42-370 -- Loss: 0.12386951595544815
train-epoch-step: 42-371 -- Loss: 0.12006938457489014
train-epoch-step: 42-372 -- Loss: 0.14708416163921356
train-epoch-step: 42-373 -- Loss: 0.18849194049835205
train-epoch-step: 42-374 -- Loss: 0.15305982530117035
train-epoch-step: 42-375 -- Loss: 0.26469993591308594
train-epoch-step: 42-376 -- Loss: 0.16267795860767365
train-epoch-step: 42-377 -- Loss: 0.22615715861320496
train-epoch-step: 42-378 -- Loss: 0.1980539858341217
train-epoch-step: 42-379 -- Loss: 0.11751985549926758
train-epoch-step: 42-380 -- Loss: 0.09052345901727676
train-epoch-step: 42-381 -- Loss: 0.24553029239177704
train-epoch-step: 42-382 -- Loss: 0.23756611347198486
train-epoch-step: 42-383 -- Loss: 0.17856158316135406
train-epoch-step: 42-384 -- Loss: 0.2162659466266632
train-epoch-step: 42-385 -- Loss: 0.19052883982658386
train-epoch-step: 42-386 -- Loss: 0.18225930631160736
train-epoch-step: 42-387 -- Loss: 0.2024727761745453
train-epoch-step: 42-388 -- Loss: 0.1834249496459961
train-epoch-step: 42-389 -- Loss: 0.162980854511261
train-epoch-step: 42-390 -- Loss: 0.14371520280838013
train-epoch-step: 42-391 -- Loss: 0.1461745798587799
train-epoch-step: 42-392 -- Loss: 0.1810504049062729
train-epoch-step: 42-393 -- Loss: 0.15512794256210327
train-epoch-step: 42-394 -- Loss: 0.19335681200027466
train-epoch-step: 42-395 -- Loss: 0.157730370759964
train-epoch-step: 42-396 -- Loss: 0.12699250876903534
train-epoch-step: 42-397 -- Loss: 0.12372830510139465
train-epoch-step: 42-398 -- Loss: 0.19279785454273224
train-epoch-step: 42-399 -- Loss: 0.1771456003189087
train-epoch-step: 42-400 -- Loss: 0.27637386322021484
train-epoch-step: 42-401 -- Loss: 0.11921939253807068
train-epoch-step: 42-402 -- Loss: 0.2548374533653259
train-epoch-step: 42-403 -- Loss: 0.15029507875442505
train-epoch-step: 42-404 -- Loss: 0.1344764530658722
train-epoch-step: 42-405 -- Loss: 0.14359945058822632
train-epoch-step: 42-406 -- Loss: 0.16774004697799683
train-epoch-step: 42-407 -- Loss: 0.11052414029836655
train-epoch-step: 42-408 -- Loss: 0.15854708850383759
train-epoch-step: 42-409 -- Loss: 0.1658492088317871
train-epoch-step: 42-410 -- Loss: 0.16915306448936462
train-epoch-step: 42-411 -- Loss: 0.20892857015132904
train-epoch-step: 42-412 -- Loss: 0.12883548438549042
train-epoch-step: 42-413 -- Loss: 0.14452794194221497
train-epoch-step: 42-414 -- Loss: 0.13304048776626587
train-epoch-step: 42-415 -- Loss: 0.1385490447282791
train-epoch-step: 42-416 -- Loss: 0.2652698755264282
train-epoch-step: 42-417 -- Loss: 0.18609528243541718
train-epoch-step: 42-418 -- Loss: 0.2328660935163498
train-epoch-step: 42-419 -- Loss: 0.1701475977897644
train-epoch-step: 42-420 -- Loss: 0.14803189039230347
train-epoch-step: 42-421 -- Loss: 0.17646388709545135
train-epoch-step: 42-422 -- Loss: 0.14716406166553497
train-epoch-step: 42-423 -- Loss: 0.17854467034339905
train-epoch-step: 42-424 -- Loss: 0.1385471671819687
train-epoch-step: 42-425 -- Loss: 0.18301208317279816
train-epoch-step: 42-426 -- Loss: 0.16027837991714478
train-epoch-step: 42-427 -- Loss: 0.11985401809215546
train-epoch-step: 42-428 -- Loss: 0.19205442070960999
train-epoch-step: 42-429 -- Loss: 0.17269176244735718
train-epoch-step: 42-430 -- Loss: 0.1393498182296753
train-epoch-step: 42-431 -- Loss: 0.16529743373394012
train-epoch-step: 42-432 -- Loss: 0.24081501364707947
train-epoch-step: 42-433 -- Loss: 0.132798969745636
train-epoch-step: 42-434 -- Loss: 0.12936699390411377
train-epoch-step: 42-435 -- Loss: 0.1594642698764801
train-epoch-step: 42-436 -- Loss: 0.15634526312351227
train-epoch-step: 42-437 -- Loss: 0.13165228068828583
train-epoch-step: 42-438 -- Loss: 0.16359223425388336
train-epoch-step: 42-439 -- Loss: 0.2591426372528076
train-epoch-step: 42-440 -- Loss: 0.12937942147254944
train-epoch-step: 42-441 -- Loss: 0.19570684432983398
train-epoch-step: 42-442 -- Loss: 0.17308875918388367
train-epoch-step: 42-443 -- Loss: 0.1491726040840149
train-epoch-step: 42-444 -- Loss: 0.17061147093772888
train-epoch-step: 42-445 -- Loss: 0.17991381883621216
train-epoch-step: 42-446 -- Loss: 0.15310832858085632
train-epoch-step: 42-447 -- Loss: 0.19221892952919006
train-epoch-step: 42-448 -- Loss: 0.2185618281364441
train-epoch-step: 42-449 -- Loss: 0.18674345314502716
train-epoch-step: 42-450 -- Loss: 0.1814892590045929
train-epoch-step: 42-451 -- Loss: 0.14644455909729004
train-epoch-step: 42-452 -- Loss: 0.1262732595205307
train-epoch-step: 42-453 -- Loss: 0.09079381078481674
train-epoch-step: 42-454 -- Loss: 0.2247493863105774
train-epoch-step: 42-455 -- Loss: 0.12181338667869568
train-epoch-step: 42-456 -- Loss: 0.12719683349132538
train-epoch-step: 42-457 -- Loss: 0.21229413151741028
train-epoch-step: 42-458 -- Loss: 0.1450197696685791
train-epoch-step: 42-459 -- Loss: 0.21931499242782593
train-epoch-step: 42-460 -- Loss: 0.12438838183879852
train-epoch-step: 42-461 -- Loss: 0.13431593775749207
train-epoch-step: 42-462 -- Loss: 0.1597021222114563
train-epoch-step: 42-463 -- Loss: 0.1327497512102127
train-epoch-step: 42-464 -- Loss: 0.1572718620300293
train-epoch-step: 42-465 -- Loss: 0.23952989280223846
train-epoch-step: 42-466 -- Loss: 0.1933790147304535
train-epoch-step: 42-467 -- Loss: 0.11019240319728851
train-epoch-step: 42-468 -- Loss: 0.16201314330101013
train-epoch-step: 42-469 -- Loss: 0.20489710569381714
train-epoch-step: 42-470 -- Loss: 0.16933193802833557
train-epoch-step: 42-471 -- Loss: 0.16045859456062317
train-epoch-step: 42-472 -- Loss: 0.1556786447763443
train-epoch-step: 42-473 -- Loss: 0.15732097625732422
train-epoch-step: 42-474 -- Loss: 0.11340507864952087
train-epoch-step: 42-475 -- Loss: 0.10884226858615875
train-epoch-step: 42-476 -- Loss: 0.19663593173027039
train-epoch-step: 42-477 -- Loss: 0.19494396448135376
train-epoch-step: 42-478 -- Loss: 0.19125458598136902
train-epoch-step: 42-479 -- Loss: 0.13970544934272766
train-epoch-step: 42-480 -- Loss: 0.19524800777435303
train-epoch-step: 42-481 -- Loss: 0.27556315064430237
train-epoch-step: 42-482 -- Loss: 0.2512040138244629
train-epoch-step: 42-483 -- Loss: 0.17635051906108856
train-epoch-step: 42-484 -- Loss: 0.2111140638589859
train-epoch-step: 42-485 -- Loss: 0.12324966490268707
train-epoch-step: 42-486 -- Loss: 0.2342764288187027
train-epoch-step: 42-487 -- Loss: 0.23029929399490356
train-epoch-step: 42-488 -- Loss: 0.18472585082054138
train-epoch-step: 42-489 -- Loss: 0.21532829105854034
train-epoch-step: 42-490 -- Loss: 0.14940565824508667
train-epoch-step: 42-491 -- Loss: 0.1335587352514267
train-epoch-step: 42-492 -- Loss: 0.1255018711090088
train-epoch-step: 42-493 -- Loss: 0.20165413618087769
train-epoch-step: 42-494 -- Loss: 0.2032780796289444
train-epoch-step: 42-495 -- Loss: 0.202843576669693
train-epoch-step: 42-496 -- Loss: 0.1377565711736679
train-epoch-step: 42-497 -- Loss: 0.17756378650665283
train-epoch-step: 42-498 -- Loss: 0.144642174243927
train-epoch-step: 42-499 -- Loss: 0.16324736177921295
train-epoch-step: 42-500 -- Loss: 0.15413261950016022
train-epoch-step: 42-501 -- Loss: 0.20857197046279907
train-epoch-step: 42-502 -- Loss: 0.15654902160167694
train-epoch-step: 42-503 -- Loss: 0.21053743362426758
train-epoch-step: 42-504 -- Loss: 0.11935640871524811
train-epoch-step: 42-505 -- Loss: 0.17778654396533966
train-epoch-step: 42-506 -- Loss: 0.11477240175008774
train-epoch-step: 42-507 -- Loss: 0.17362670600414276
train-epoch-step: 42-508 -- Loss: 0.17528927326202393
train-epoch-step: 42-509 -- Loss: 0.16819319128990173
train-epoch-step: 42-510 -- Loss: 0.12540407478809357
train-epoch-step: 42-511 -- Loss: 0.20942120254039764
train-epoch-step: 42-512 -- Loss: 0.1676613688468933
train-epoch-step: 42-513 -- Loss: 0.18762356042861938
train-epoch-step: 42-514 -- Loss: 0.14098116755485535
train-epoch-step: 42-515 -- Loss: 0.15643936395645142
train-epoch-step: 42-516 -- Loss: 0.1655057668685913
train-epoch-step: 42-517 -- Loss: 0.17262203991413116
train-epoch-step: 42-518 -- Loss: 0.13603448867797852
train-epoch-step: 42-519 -- Loss: 0.13253457844257355
train-epoch-step: 42-520 -- Loss: 0.1881164014339447
train-epoch-step: 42-521 -- Loss: 0.2308632880449295
train-epoch-step: 42-522 -- Loss: 0.1729397177696228
train-epoch-step: 42-523 -- Loss: 0.15578995645046234
train-epoch-step: 42-524 -- Loss: 0.16285699605941772
train-epoch-step: 42-525 -- Loss: 0.19398486614227295
train-epoch-step: 42-526 -- Loss: 0.1261047124862671
train-epoch-step: 42-527 -- Loss: 0.15243037045001984
train-epoch-step: 42-528 -- Loss: 0.15807323157787323
train-epoch-step: 42-529 -- Loss: 0.15602365136146545
train-epoch-step: 42-530 -- Loss: 0.1685246080160141
train-epoch-step: 42-531 -- Loss: 0.19404296576976776
train-epoch-step: 42-532 -- Loss: 0.1663474589586258
train-epoch-step: 42-533 -- Loss: 0.17034277319908142
train-epoch-step: 42-534 -- Loss: 0.13321198523044586
train-epoch-step: 42-535 -- Loss: 0.24337786436080933
train-epoch-step: 42-536 -- Loss: 0.15740108489990234
train-epoch-step: 42-537 -- Loss: 0.1478847712278366
train-epoch-step: 42-538 -- Loss: 0.10178326815366745
train-epoch-step: 42-539 -- Loss: 0.1789587140083313
train-epoch-step: 42-540 -- Loss: 0.13495491445064545
train-epoch-step: 42-541 -- Loss: 0.20779113471508026
train-epoch-step: 42-542 -- Loss: 0.21082332730293274
train-epoch-step: 42-543 -- Loss: 0.1644946038722992
train-epoch-step: 42-544 -- Loss: 0.2268308401107788
train-epoch-step: 42-545 -- Loss: 0.19054506719112396
train-epoch-step: 42-546 -- Loss: 0.20589804649353027
train-epoch-step: 42-547 -- Loss: 0.17859777808189392
train-epoch-step: 42-548 -- Loss: 0.0946035236120224
train-epoch-step: 42-549 -- Loss: 0.14706513285636902
train-epoch-step: 42-550 -- Loss: 0.19776539504528046
train-epoch-step: 42-551 -- Loss: 0.15346987545490265
train-epoch-step: 42-552 -- Loss: 0.12283451110124588
train-epoch-step: 42-553 -- Loss: 0.1888190656900406
train-epoch-step: 42-554 -- Loss: 0.18438264727592468
train-epoch-step: 42-555 -- Loss: 0.2150449901819229
train-epoch-step: 42-556 -- Loss: 0.14277383685112
train-epoch-step: 42-557 -- Loss: 0.2436012625694275
train-epoch-step: 42-558 -- Loss: 0.22282646596431732
train-epoch-step: 42-559 -- Loss: 0.13705767691135406
train-epoch-step: 42-560 -- Loss: 0.20164242386817932
train-epoch-step: 42-561 -- Loss: 0.1760932356119156
train-epoch-step: 42-562 -- Loss: 0.15974609553813934
train-epoch-step: 42-563 -- Loss: 0.18023763597011566
train-epoch-step: 42-564 -- Loss: 0.09787186980247498
train-epoch-step: 42-565 -- Loss: 0.179040789604187
train-epoch-step: 42-566 -- Loss: 0.15313223004341125
train-epoch-step: 42-567 -- Loss: 0.2102629840373993
train-epoch-step: 42-568 -- Loss: 0.15329302847385406
train-epoch-step: 42-569 -- Loss: 0.23880106210708618
train-epoch-step: 42-570 -- Loss: 0.1629902422428131
train-epoch-step: 42-571 -- Loss: 0.21443741023540497
train-epoch-step: 42-572 -- Loss: 0.25119584798812866
train-epoch-step: 42-573 -- Loss: 0.19692403078079224
train-epoch-step: 42-574 -- Loss: 0.2437019944190979
train-epoch-step: 42-575 -- Loss: 0.28999704122543335
train-epoch-step: 42-576 -- Loss: 0.11648013442754745
train-epoch-step: 42-577 -- Loss: 0.1641673892736435
train-epoch-step: 42-578 -- Loss: 0.21282967925071716
train-epoch-step: 42-579 -- Loss: 0.16381129622459412
train-epoch-step: 42-580 -- Loss: 0.17302675545215607
train-epoch-step: 42-581 -- Loss: 0.13233515620231628
train-epoch-step: 42-582 -- Loss: 0.20833709836006165
train-epoch-step: 42-583 -- Loss: 0.21477368474006653
train-epoch-step: 42-584 -- Loss: 0.1586444079875946
train-epoch-step: 42-585 -- Loss: 0.19179287552833557
train-epoch-step: 42-586 -- Loss: 0.255681574344635
train-epoch-step: 42-587 -- Loss: 0.1570357382297516
train-epoch-step: 42-588 -- Loss: 0.12471608072519302
val-epoch-step: 42-589 -- Loss: 0.2204677015542984
val-epoch-step: 42-590 -- Loss: 0.1566283106803894
val-epoch-step: 42-591 -- Loss: 0.23500269651412964
val-epoch-step: 42-592 -- Loss: 0.1745823472738266
val-epoch-step: 42-593 -- Loss: 0.16391189396381378
val-epoch-step: 42-594 -- Loss: 0.40180301666259766
val-epoch-step: 42-595 -- Loss: 0.23402352631092072
val-epoch-step: 42-596 -- Loss: 0.22290737926959991
val-epoch-step: 42-597 -- Loss: 0.17226776480674744
val-epoch-step: 42-598 -- Loss: 0.15122535824775696
val-epoch-step: 42-599 -- Loss: 0.18515953421592712
val-epoch-step: 42-600 -- Loss: 0.2412223070859909
val-epoch-step: 42-601 -- Loss: 0.16383802890777588
val-epoch-step: 42-602 -- Loss: 0.1376294493675232
val-epoch-step: 42-603 -- Loss: 0.18812131881713867
val-epoch-step: 42-604 -- Loss: 0.14860178530216217
val-epoch-step: 42-605 -- Loss: 0.147255539894104
val-epoch-step: 42-606 -- Loss: 0.2577276825904846
val-epoch-step: 42-607 -- Loss: 0.13090215623378754
val-epoch-step: 42-608 -- Loss: 0.25911763310432434
val-epoch-step: 42-609 -- Loss: 0.19487923383712769
val-epoch-step: 42-610 -- Loss: 0.17809680104255676
val-epoch-step: 42-611 -- Loss: 0.16358795762062073
val-epoch-step: 42-612 -- Loss: 0.4575999081134796
val-epoch-step: 42-613 -- Loss: 0.1802513748407364
val-epoch-step: 42-614 -- Loss: 0.16456133127212524
val-epoch-step: 42-615 -- Loss: 0.17030945420265198
val-epoch-step: 42-616 -- Loss: 0.1742943525314331
val-epoch-step: 42-617 -- Loss: 0.19522574543952942
val-epoch-step: 42-618 -- Loss: 0.18294674158096313
val-epoch-step: 42-619 -- Loss: 0.2167811095714569
val-epoch-step: 42-620 -- Loss: 0.15338705480098724
val-epoch-step: 42-621 -- Loss: 0.12386523187160492
val-epoch-step: 42-622 -- Loss: 0.1443227231502533
val-epoch-step: 42-623 -- Loss: 0.15063995122909546
val-epoch-step: 42-624 -- Loss: 0.14756645262241364
val-epoch-step: 42-625 -- Loss: 0.1639951914548874
val-epoch-step: 42-626 -- Loss: 0.14916494488716125
val-epoch-step: 42-627 -- Loss: 0.18043622374534607
val-epoch-step: 42-628 -- Loss: 0.612212061882019
val-epoch-step: 42-629 -- Loss: 0.1892107129096985
val-epoch-step: 42-630 -- Loss: 0.3459719121456146
val-epoch-step: 42-631 -- Loss: 0.13980206847190857
val-epoch-step: 42-632 -- Loss: 0.20965507626533508
val-epoch-step: 42-633 -- Loss: 0.15094180405139923
val-epoch-step: 42-634 -- Loss: 0.13819926977157593
val-epoch-step: 42-635 -- Loss: 0.11850883811712265
val-epoch-step: 42-636 -- Loss: 0.16563653945922852
val-epoch-step: 42-637 -- Loss: 0.17828959226608276
val-epoch-step: 42-638 -- Loss: 0.16226983070373535
val-epoch-step: 42-639 -- Loss: 0.2728978395462036
val-epoch-step: 42-640 -- Loss: 0.26735225319862366
val-epoch-step: 42-641 -- Loss: 0.12526871263980865
val-epoch-step: 42-642 -- Loss: 0.1819361001253128
val-epoch-step: 42-643 -- Loss: 0.19813010096549988
val-epoch-step: 42-644 -- Loss: 0.16985245048999786
val-epoch-step: 42-645 -- Loss: 0.22118565440177917
val-epoch-step: 42-646 -- Loss: 0.13410809636116028
val-epoch-step: 42-647 -- Loss: 0.13568362593650818
val-epoch-step: 42-648 -- Loss: 0.1631222814321518
val-epoch-step: 42-649 -- Loss: 0.21251390874385834
val-epoch-step: 42-650 -- Loss: 0.24800431728363037
val-epoch-step: 42-651 -- Loss: 0.14333367347717285
val-epoch-step: 42-652 -- Loss: 0.16697970032691956
val-epoch-step: 42-653 -- Loss: 0.1941910982131958
val-epoch-step: 42-654 -- Loss: 0.11922899633646011
Epoch: 42 -- Train Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1434, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 43-0 -- Loss: 0.22033338248729706
train-epoch-step: 43-1 -- Loss: 0.14739273488521576
train-epoch-step: 43-2 -- Loss: 0.19646234810352325
train-epoch-step: 43-3 -- Loss: 0.1494244635105133
train-epoch-step: 43-4 -- Loss: 0.1579180508852005
train-epoch-step: 43-5 -- Loss: 0.1777113676071167
train-epoch-step: 43-6 -- Loss: 0.20972111821174622
train-epoch-step: 43-7 -- Loss: 0.16793249547481537
train-epoch-step: 43-8 -- Loss: 0.18141692876815796
train-epoch-step: 43-9 -- Loss: 0.22547227144241333
train-epoch-step: 43-10 -- Loss: 0.19373035430908203
train-epoch-step: 43-11 -- Loss: 0.1938941925764084
train-epoch-step: 43-12 -- Loss: 0.14963741600513458
train-epoch-step: 43-13 -- Loss: 0.17496958374977112
train-epoch-step: 43-14 -- Loss: 0.16345243155956268
train-epoch-step: 43-15 -- Loss: 0.15676450729370117
train-epoch-step: 43-16 -- Loss: 0.16724082827568054
train-epoch-step: 43-17 -- Loss: 0.21229279041290283
train-epoch-step: 43-18 -- Loss: 0.19614507257938385
train-epoch-step: 43-19 -- Loss: 0.13050878047943115
train-epoch-step: 43-20 -- Loss: 0.21421927213668823
train-epoch-step: 43-21 -- Loss: 0.24611259996891022
train-epoch-step: 43-22 -- Loss: 0.138259619474411
train-epoch-step: 43-23 -- Loss: 0.14175330102443695
train-epoch-step: 43-24 -- Loss: 0.12168727070093155
train-epoch-step: 43-25 -- Loss: 0.21971596777439117
train-epoch-step: 43-26 -- Loss: 0.18730822205543518
train-epoch-step: 43-27 -- Loss: 0.2276078462600708
train-epoch-step: 43-28 -- Loss: 0.12388041615486145
train-epoch-step: 43-29 -- Loss: 0.23905368149280548
train-epoch-step: 43-30 -- Loss: 0.11018380522727966
train-epoch-step: 43-31 -- Loss: 0.1337302327156067
train-epoch-step: 43-32 -- Loss: 0.17105400562286377
train-epoch-step: 43-33 -- Loss: 0.2699566185474396
train-epoch-step: 43-34 -- Loss: 0.16968396306037903
train-epoch-step: 43-35 -- Loss: 0.2456541806459427
train-epoch-step: 43-36 -- Loss: 0.13865217566490173
train-epoch-step: 43-37 -- Loss: 0.14242225885391235
train-epoch-step: 43-38 -- Loss: 0.17367145419120789
train-epoch-step: 43-39 -- Loss: 0.21259328722953796
train-epoch-step: 43-40 -- Loss: 0.18950223922729492
train-epoch-step: 43-41 -- Loss: 0.2117615044116974
train-epoch-step: 43-42 -- Loss: 0.14831729233264923
train-epoch-step: 43-43 -- Loss: 0.271608829498291
train-epoch-step: 43-44 -- Loss: 0.12598222494125366
train-epoch-step: 43-45 -- Loss: 0.11519124358892441
train-epoch-step: 43-46 -- Loss: 0.16521106660366058
train-epoch-step: 43-47 -- Loss: 0.1985471546649933
train-epoch-step: 43-48 -- Loss: 0.15406347811222076
train-epoch-step: 43-49 -- Loss: 0.23093681037425995
train-epoch-step: 43-50 -- Loss: 0.11124739050865173
train-epoch-step: 43-51 -- Loss: 0.1745801568031311
train-epoch-step: 43-52 -- Loss: 0.1564377248287201
train-epoch-step: 43-53 -- Loss: 0.2034229040145874
train-epoch-step: 43-54 -- Loss: 0.28574180603027344
train-epoch-step: 43-55 -- Loss: 0.1624825894832611
train-epoch-step: 43-56 -- Loss: 0.17528703808784485
train-epoch-step: 43-57 -- Loss: 0.2289973795413971
train-epoch-step: 43-58 -- Loss: 0.27961888909339905
train-epoch-step: 43-59 -- Loss: 0.2337798774242401
train-epoch-step: 43-60 -- Loss: 0.1277768611907959
train-epoch-step: 43-61 -- Loss: 0.20086294412612915
train-epoch-step: 43-62 -- Loss: 0.17972303926944733
train-epoch-step: 43-63 -- Loss: 0.14490482211112976
train-epoch-step: 43-64 -- Loss: 0.1445397138595581
train-epoch-step: 43-65 -- Loss: 0.17933259904384613
train-epoch-step: 43-66 -- Loss: 0.11075283586978912
train-epoch-step: 43-67 -- Loss: 0.12420932948589325
train-epoch-step: 43-68 -- Loss: 0.2099354863166809
train-epoch-step: 43-69 -- Loss: 0.12135696411132812
train-epoch-step: 43-70 -- Loss: 0.2178143560886383
train-epoch-step: 43-71 -- Loss: 0.26282191276550293
train-epoch-step: 43-72 -- Loss: 0.17189203202724457
train-epoch-step: 43-73 -- Loss: 0.20845821499824524
train-epoch-step: 43-74 -- Loss: 0.09493812173604965
train-epoch-step: 43-75 -- Loss: 0.12626974284648895
train-epoch-step: 43-76 -- Loss: 0.14462921023368835
train-epoch-step: 43-77 -- Loss: 0.22739632427692413
train-epoch-step: 43-78 -- Loss: 0.2543630003929138
train-epoch-step: 43-79 -- Loss: 0.19560140371322632
train-epoch-step: 43-80 -- Loss: 0.24458855390548706
train-epoch-step: 43-81 -- Loss: 0.1240660548210144
train-epoch-step: 43-82 -- Loss: 0.2471209019422531
train-epoch-step: 43-83 -- Loss: 0.17364461719989777
train-epoch-step: 43-84 -- Loss: 0.1888890564441681
train-epoch-step: 43-85 -- Loss: 0.1740117222070694
train-epoch-step: 43-86 -- Loss: 0.11793064326047897
train-epoch-step: 43-87 -- Loss: 0.20510154962539673
train-epoch-step: 43-88 -- Loss: 0.142512708902359
train-epoch-step: 43-89 -- Loss: 0.18347887694835663
train-epoch-step: 43-90 -- Loss: 0.19089874625205994
train-epoch-step: 43-91 -- Loss: 0.24662187695503235
train-epoch-step: 43-92 -- Loss: 0.15300098061561584
train-epoch-step: 43-93 -- Loss: 0.16979195177555084
train-epoch-step: 43-94 -- Loss: 0.21858298778533936
train-epoch-step: 43-95 -- Loss: 0.18871213495731354
train-epoch-step: 43-96 -- Loss: 0.21196313202381134
train-epoch-step: 43-97 -- Loss: 0.1704106479883194
train-epoch-step: 43-98 -- Loss: 0.152016744017601
train-epoch-step: 43-99 -- Loss: 0.17615491151809692
train-epoch-step: 43-100 -- Loss: 0.18555507063865662
train-epoch-step: 43-101 -- Loss: 0.25780171155929565
train-epoch-step: 43-102 -- Loss: 0.21683399379253387
train-epoch-step: 43-103 -- Loss: 0.18532809615135193
train-epoch-step: 43-104 -- Loss: 0.1459452211856842
train-epoch-step: 43-105 -- Loss: 0.2678333818912506
train-epoch-step: 43-106 -- Loss: 0.17543381452560425
train-epoch-step: 43-107 -- Loss: 0.18038398027420044
train-epoch-step: 43-108 -- Loss: 0.1844351887702942
train-epoch-step: 43-109 -- Loss: 0.1409415900707245
train-epoch-step: 43-110 -- Loss: 0.17922315001487732
train-epoch-step: 43-111 -- Loss: 0.17258602380752563
train-epoch-step: 43-112 -- Loss: 0.16171249747276306
train-epoch-step: 43-113 -- Loss: 0.1570204645395279
train-epoch-step: 43-114 -- Loss: 0.19322696328163147
train-epoch-step: 43-115 -- Loss: 0.1564159244298935
train-epoch-step: 43-116 -- Loss: 0.13426437973976135
train-epoch-step: 43-117 -- Loss: 0.12736979126930237
train-epoch-step: 43-118 -- Loss: 0.18703332543373108
train-epoch-step: 43-119 -- Loss: 0.14680597186088562
train-epoch-step: 43-120 -- Loss: 0.244206964969635
train-epoch-step: 43-121 -- Loss: 0.23559199273586273
train-epoch-step: 43-122 -- Loss: 0.21143770217895508
train-epoch-step: 43-123 -- Loss: 0.2002577781677246
train-epoch-step: 43-124 -- Loss: 0.1207195371389389
train-epoch-step: 43-125 -- Loss: 0.15065476298332214
train-epoch-step: 43-126 -- Loss: 0.22971823811531067
train-epoch-step: 43-127 -- Loss: 0.17027348279953003
train-epoch-step: 43-128 -- Loss: 0.16704799234867096
train-epoch-step: 43-129 -- Loss: 0.14064672589302063
train-epoch-step: 43-130 -- Loss: 0.1895715743303299
train-epoch-step: 43-131 -- Loss: 0.13353140652179718
train-epoch-step: 43-132 -- Loss: 0.18586647510528564
train-epoch-step: 43-133 -- Loss: 0.11231135576963425
train-epoch-step: 43-134 -- Loss: 0.18885231018066406
train-epoch-step: 43-135 -- Loss: 0.1312793642282486
train-epoch-step: 43-136 -- Loss: 0.12435472011566162
train-epoch-step: 43-137 -- Loss: 0.23912328481674194
train-epoch-step: 43-138 -- Loss: 0.2544552683830261
train-epoch-step: 43-139 -- Loss: 0.13135749101638794
train-epoch-step: 43-140 -- Loss: 0.2035045176744461
train-epoch-step: 43-141 -- Loss: 0.22569352388381958
train-epoch-step: 43-142 -- Loss: 0.19953256845474243
train-epoch-step: 43-143 -- Loss: 0.16811245679855347
train-epoch-step: 43-144 -- Loss: 0.19047436118125916
train-epoch-step: 43-145 -- Loss: 0.13833743333816528
train-epoch-step: 43-146 -- Loss: 0.17838002741336823
train-epoch-step: 43-147 -- Loss: 0.17423279583454132
train-epoch-step: 43-148 -- Loss: 0.15869194269180298
train-epoch-step: 43-149 -- Loss: 0.11843208968639374
train-epoch-step: 43-150 -- Loss: 0.18348078429698944
train-epoch-step: 43-151 -- Loss: 0.1888585090637207
train-epoch-step: 43-152 -- Loss: 0.18339338898658752
train-epoch-step: 43-153 -- Loss: 0.26153048872947693
train-epoch-step: 43-154 -- Loss: 0.12978309392929077
train-epoch-step: 43-155 -- Loss: 0.13465741276741028
train-epoch-step: 43-156 -- Loss: 0.11794761568307877
train-epoch-step: 43-157 -- Loss: 0.16197878122329712
train-epoch-step: 43-158 -- Loss: 0.1645505577325821
train-epoch-step: 43-159 -- Loss: 0.17798775434494019
train-epoch-step: 43-160 -- Loss: 0.20820793509483337
train-epoch-step: 43-161 -- Loss: 0.200913667678833
train-epoch-step: 43-162 -- Loss: 0.2074466347694397
train-epoch-step: 43-163 -- Loss: 0.18648844957351685
train-epoch-step: 43-164 -- Loss: 0.19151444733142853
train-epoch-step: 43-165 -- Loss: 0.16241662204265594
train-epoch-step: 43-166 -- Loss: 0.12092253565788269
train-epoch-step: 43-167 -- Loss: 0.12366656959056854
train-epoch-step: 43-168 -- Loss: 0.19796626269817352
train-epoch-step: 43-169 -- Loss: 0.13465535640716553
train-epoch-step: 43-170 -- Loss: 0.1959220916032791
train-epoch-step: 43-171 -- Loss: 0.14047406613826752
train-epoch-step: 43-172 -- Loss: 0.2584258019924164
train-epoch-step: 43-173 -- Loss: 0.1304520070552826
train-epoch-step: 43-174 -- Loss: 0.24972641468048096
train-epoch-step: 43-175 -- Loss: 0.18603172898292542
train-epoch-step: 43-176 -- Loss: 0.13184396922588348
train-epoch-step: 43-177 -- Loss: 0.18035034835338593
train-epoch-step: 43-178 -- Loss: 0.17544010281562805
train-epoch-step: 43-179 -- Loss: 0.14870761334896088
train-epoch-step: 43-180 -- Loss: 0.15281760692596436
train-epoch-step: 43-181 -- Loss: 0.16832517087459564
train-epoch-step: 43-182 -- Loss: 0.1775496006011963
train-epoch-step: 43-183 -- Loss: 0.26198214292526245
train-epoch-step: 43-184 -- Loss: 0.13655968010425568
train-epoch-step: 43-185 -- Loss: 0.14190493524074554
train-epoch-step: 43-186 -- Loss: 0.18272340297698975
train-epoch-step: 43-187 -- Loss: 0.20307330787181854
train-epoch-step: 43-188 -- Loss: 0.1696421355009079
train-epoch-step: 43-189 -- Loss: 0.10396773368120193
train-epoch-step: 43-190 -- Loss: 0.18137280642986298
train-epoch-step: 43-191 -- Loss: 0.15680071711540222
train-epoch-step: 43-192 -- Loss: 0.2261391431093216
train-epoch-step: 43-193 -- Loss: 0.20473812520503998
train-epoch-step: 43-194 -- Loss: 0.18120421469211578
train-epoch-step: 43-195 -- Loss: 0.16194100677967072
train-epoch-step: 43-196 -- Loss: 0.1648901104927063
train-epoch-step: 43-197 -- Loss: 0.12357410043478012
train-epoch-step: 43-198 -- Loss: 0.12723024189472198
train-epoch-step: 43-199 -- Loss: 0.1485683023929596
train-epoch-step: 43-200 -- Loss: 0.12297700345516205
train-epoch-step: 43-201 -- Loss: 0.1996508538722992
train-epoch-step: 43-202 -- Loss: 0.13166911900043488
train-epoch-step: 43-203 -- Loss: 0.16846609115600586
train-epoch-step: 43-204 -- Loss: 0.13458387553691864
train-epoch-step: 43-205 -- Loss: 0.18547029793262482
train-epoch-step: 43-206 -- Loss: 0.20080988109111786
train-epoch-step: 43-207 -- Loss: 0.13672298192977905
train-epoch-step: 43-208 -- Loss: 0.17525115609169006
train-epoch-step: 43-209 -- Loss: 0.14326319098472595
train-epoch-step: 43-210 -- Loss: 0.13609647750854492
train-epoch-step: 43-211 -- Loss: 0.20383165776729584
train-epoch-step: 43-212 -- Loss: 0.19391793012619019
train-epoch-step: 43-213 -- Loss: 0.13327355682849884
train-epoch-step: 43-214 -- Loss: 0.14718006551265717
train-epoch-step: 43-215 -- Loss: 0.1266891211271286
train-epoch-step: 43-216 -- Loss: 0.1984986960887909
train-epoch-step: 43-217 -- Loss: 0.20603972673416138
train-epoch-step: 43-218 -- Loss: 0.141005277633667
train-epoch-step: 43-219 -- Loss: 0.1685400903224945
train-epoch-step: 43-220 -- Loss: 0.12759490311145782
train-epoch-step: 43-221 -- Loss: 0.19965267181396484
train-epoch-step: 43-222 -- Loss: 0.11763697862625122
train-epoch-step: 43-223 -- Loss: 0.17183402180671692
train-epoch-step: 43-224 -- Loss: 0.18307223916053772
train-epoch-step: 43-225 -- Loss: 0.2665153443813324
train-epoch-step: 43-226 -- Loss: 0.20293517410755157
train-epoch-step: 43-227 -- Loss: 0.21384325623512268
train-epoch-step: 43-228 -- Loss: 0.17193494737148285
train-epoch-step: 43-229 -- Loss: 0.1715082973241806
train-epoch-step: 43-230 -- Loss: 0.1585424542427063
train-epoch-step: 43-231 -- Loss: 0.1560114473104477
train-epoch-step: 43-232 -- Loss: 0.18766702711582184
train-epoch-step: 43-233 -- Loss: 0.08099140226840973
train-epoch-step: 43-234 -- Loss: 0.1717224270105362
train-epoch-step: 43-235 -- Loss: 0.14305362105369568
train-epoch-step: 43-236 -- Loss: 0.18787959218025208
train-epoch-step: 43-237 -- Loss: 0.2346411645412445
train-epoch-step: 43-238 -- Loss: 0.15801188349723816
train-epoch-step: 43-239 -- Loss: 0.12651702761650085
train-epoch-step: 43-240 -- Loss: 0.22653283178806305
train-epoch-step: 43-241 -- Loss: 0.15262654423713684
train-epoch-step: 43-242 -- Loss: 0.21731270849704742
train-epoch-step: 43-243 -- Loss: 0.23267021775245667
train-epoch-step: 43-244 -- Loss: 0.20113645493984222
train-epoch-step: 43-245 -- Loss: 0.207988902926445
train-epoch-step: 43-246 -- Loss: 0.2204502671957016
train-epoch-step: 43-247 -- Loss: 0.20703332126140594
train-epoch-step: 43-248 -- Loss: 0.1859724521636963
train-epoch-step: 43-249 -- Loss: 0.13574816286563873
train-epoch-step: 43-250 -- Loss: 0.19873622059822083
train-epoch-step: 43-251 -- Loss: 0.10398102551698685
train-epoch-step: 43-252 -- Loss: 0.18870368599891663
train-epoch-step: 43-253 -- Loss: 0.134208083152771
train-epoch-step: 43-254 -- Loss: 0.21192966401576996
train-epoch-step: 43-255 -- Loss: 0.14308249950408936
train-epoch-step: 43-256 -- Loss: 0.14701566100120544
train-epoch-step: 43-257 -- Loss: 0.18435627222061157
train-epoch-step: 43-258 -- Loss: 0.142690047621727
train-epoch-step: 43-259 -- Loss: 0.14077937602996826
train-epoch-step: 43-260 -- Loss: 0.2019789218902588
train-epoch-step: 43-261 -- Loss: 0.17098459601402283
train-epoch-step: 43-262 -- Loss: 0.30030933022499084
train-epoch-step: 43-263 -- Loss: 0.1944427639245987
train-epoch-step: 43-264 -- Loss: 0.17330509424209595
train-epoch-step: 43-265 -- Loss: 0.11508456617593765
train-epoch-step: 43-266 -- Loss: 0.15675082802772522
train-epoch-step: 43-267 -- Loss: 0.1295022964477539
train-epoch-step: 43-268 -- Loss: 0.11500144004821777
train-epoch-step: 43-269 -- Loss: 0.17782996594905853
train-epoch-step: 43-270 -- Loss: 0.10559587925672531
train-epoch-step: 43-271 -- Loss: 0.14875005185604095
train-epoch-step: 43-272 -- Loss: 0.1164177730679512
train-epoch-step: 43-273 -- Loss: 0.13075390458106995
train-epoch-step: 43-274 -- Loss: 0.23313860595226288
train-epoch-step: 43-275 -- Loss: 0.1913263201713562
train-epoch-step: 43-276 -- Loss: 0.1575385183095932
train-epoch-step: 43-277 -- Loss: 0.1579156070947647
train-epoch-step: 43-278 -- Loss: 0.1386764645576477
train-epoch-step: 43-279 -- Loss: 0.14274315536022186
train-epoch-step: 43-280 -- Loss: 0.2165490686893463
train-epoch-step: 43-281 -- Loss: 0.17476312816143036
train-epoch-step: 43-282 -- Loss: 0.14452359080314636
train-epoch-step: 43-283 -- Loss: 0.11823958158493042
train-epoch-step: 43-284 -- Loss: 0.12898260354995728
train-epoch-step: 43-285 -- Loss: 0.20084165036678314
train-epoch-step: 43-286 -- Loss: 0.1515042930841446
train-epoch-step: 43-287 -- Loss: 0.20041382312774658
train-epoch-step: 43-288 -- Loss: 0.09329566359519958
train-epoch-step: 43-289 -- Loss: 0.11553527414798737
train-epoch-step: 43-290 -- Loss: 0.1816321611404419
train-epoch-step: 43-291 -- Loss: 0.11560989916324615
train-epoch-step: 43-292 -- Loss: 0.15877333283424377
train-epoch-step: 43-293 -- Loss: 0.13652586936950684
train-epoch-step: 43-294 -- Loss: 0.1574339121580124
train-epoch-step: 43-295 -- Loss: 0.2697307765483856
train-epoch-step: 43-296 -- Loss: 0.1592673361301422
train-epoch-step: 43-297 -- Loss: 0.16960293054580688
train-epoch-step: 43-298 -- Loss: 0.23611217737197876
train-epoch-step: 43-299 -- Loss: 0.1448107212781906
train-epoch-step: 43-300 -- Loss: 0.16042323410511017
train-epoch-step: 43-301 -- Loss: 0.17062391340732574
train-epoch-step: 43-302 -- Loss: 0.2198343575000763
train-epoch-step: 43-303 -- Loss: 0.2074495106935501
train-epoch-step: 43-304 -- Loss: 0.1293349266052246
train-epoch-step: 43-305 -- Loss: 0.15000829100608826
train-epoch-step: 43-306 -- Loss: 0.2379053831100464
train-epoch-step: 43-307 -- Loss: 0.16399617493152618
train-epoch-step: 43-308 -- Loss: 0.21974286437034607
train-epoch-step: 43-309 -- Loss: 0.164241224527359
train-epoch-step: 43-310 -- Loss: 0.17329058051109314
train-epoch-step: 43-311 -- Loss: 0.15954041481018066
train-epoch-step: 43-312 -- Loss: 0.20257103443145752
train-epoch-step: 43-313 -- Loss: 0.0978129655122757
train-epoch-step: 43-314 -- Loss: 0.18974046409130096
train-epoch-step: 43-315 -- Loss: 0.17266835272312164
train-epoch-step: 43-316 -- Loss: 0.15131592750549316
train-epoch-step: 43-317 -- Loss: 0.14034795761108398
train-epoch-step: 43-318 -- Loss: 0.1575351059436798
train-epoch-step: 43-319 -- Loss: 0.16866494715213776
train-epoch-step: 43-320 -- Loss: 0.11888694763183594
train-epoch-step: 43-321 -- Loss: 0.1299225091934204
train-epoch-step: 43-322 -- Loss: 0.21221163868904114
train-epoch-step: 43-323 -- Loss: 0.16069301962852478
train-epoch-step: 43-324 -- Loss: 0.25491249561309814
train-epoch-step: 43-325 -- Loss: 0.15401199460029602
train-epoch-step: 43-326 -- Loss: 0.17546722292900085
train-epoch-step: 43-327 -- Loss: 0.20663462579250336
train-epoch-step: 43-328 -- Loss: 0.19473090767860413
train-epoch-step: 43-329 -- Loss: 0.3446088433265686
train-epoch-step: 43-330 -- Loss: 0.3592706620693207
train-epoch-step: 43-331 -- Loss: 0.20466402173042297
train-epoch-step: 43-332 -- Loss: 0.09599058330059052
train-epoch-step: 43-333 -- Loss: 0.1828683763742447
train-epoch-step: 43-334 -- Loss: 0.15366603434085846
train-epoch-step: 43-335 -- Loss: 0.17221900820732117
train-epoch-step: 43-336 -- Loss: 0.14792825281620026
train-epoch-step: 43-337 -- Loss: 0.20293903350830078
train-epoch-step: 43-338 -- Loss: 0.15795999765396118
train-epoch-step: 43-339 -- Loss: 0.14141711592674255
train-epoch-step: 43-340 -- Loss: 0.19683702290058136
train-epoch-step: 43-341 -- Loss: 0.14391495287418365
train-epoch-step: 43-342 -- Loss: 0.1613616645336151
train-epoch-step: 43-343 -- Loss: 0.15529491007328033
train-epoch-step: 43-344 -- Loss: 0.1697784662246704
train-epoch-step: 43-345 -- Loss: 0.12490430474281311
train-epoch-step: 43-346 -- Loss: 0.20211327075958252
train-epoch-step: 43-347 -- Loss: 0.1513238251209259
train-epoch-step: 43-348 -- Loss: 0.20345304906368256
train-epoch-step: 43-349 -- Loss: 0.20336557924747467
train-epoch-step: 43-350 -- Loss: 0.24977359175682068
train-epoch-step: 43-351 -- Loss: 0.19037273526191711
train-epoch-step: 43-352 -- Loss: 0.12502247095108032
train-epoch-step: 43-353 -- Loss: 0.19283875823020935
train-epoch-step: 43-354 -- Loss: 0.2819043695926666
train-epoch-step: 43-355 -- Loss: 0.11638356745243073
train-epoch-step: 43-356 -- Loss: 0.11887389421463013
train-epoch-step: 43-357 -- Loss: 0.1853880137205124
train-epoch-step: 43-358 -- Loss: 0.1839846670627594
train-epoch-step: 43-359 -- Loss: 0.13875968754291534
train-epoch-step: 43-360 -- Loss: 0.1213759183883667
train-epoch-step: 43-361 -- Loss: 0.23628143966197968
train-epoch-step: 43-362 -- Loss: 0.1710268259048462
train-epoch-step: 43-363 -- Loss: 0.1090819388628006
train-epoch-step: 43-364 -- Loss: 0.17684486508369446
train-epoch-step: 43-365 -- Loss: 0.16331741213798523
train-epoch-step: 43-366 -- Loss: 0.20248033106327057
train-epoch-step: 43-367 -- Loss: 0.2257959246635437
train-epoch-step: 43-368 -- Loss: 0.19752871990203857
train-epoch-step: 43-369 -- Loss: 0.2745208442211151
train-epoch-step: 43-370 -- Loss: 0.12281715124845505
train-epoch-step: 43-371 -- Loss: 0.12151796370744705
train-epoch-step: 43-372 -- Loss: 0.14855945110321045
train-epoch-step: 43-373 -- Loss: 0.19498872756958008
train-epoch-step: 43-374 -- Loss: 0.15423491597175598
train-epoch-step: 43-375 -- Loss: 0.2657090425491333
train-epoch-step: 43-376 -- Loss: 0.16251502931118011
train-epoch-step: 43-377 -- Loss: 0.22836464643478394
train-epoch-step: 43-378 -- Loss: 0.19533616304397583
train-epoch-step: 43-379 -- Loss: 0.11606444418430328
train-epoch-step: 43-380 -- Loss: 0.09032153338193893
train-epoch-step: 43-381 -- Loss: 0.24625709652900696
train-epoch-step: 43-382 -- Loss: 0.22893384099006653
train-epoch-step: 43-383 -- Loss: 0.17278504371643066
train-epoch-step: 43-384 -- Loss: 0.21737945079803467
train-epoch-step: 43-385 -- Loss: 0.20541206002235413
train-epoch-step: 43-386 -- Loss: 0.19341905415058136
train-epoch-step: 43-387 -- Loss: 0.2021721750497818
train-epoch-step: 43-388 -- Loss: 0.19639357924461365
train-epoch-step: 43-389 -- Loss: 0.16290515661239624
train-epoch-step: 43-390 -- Loss: 0.14860108494758606
train-epoch-step: 43-391 -- Loss: 0.1428576558828354
train-epoch-step: 43-392 -- Loss: 0.18594270944595337
train-epoch-step: 43-393 -- Loss: 0.15701259672641754
train-epoch-step: 43-394 -- Loss: 0.2212848663330078
train-epoch-step: 43-395 -- Loss: 0.15755346417427063
train-epoch-step: 43-396 -- Loss: 0.1258281171321869
train-epoch-step: 43-397 -- Loss: 0.12366454303264618
train-epoch-step: 43-398 -- Loss: 0.2090834528207779
train-epoch-step: 43-399 -- Loss: 0.17547321319580078
train-epoch-step: 43-400 -- Loss: 0.28304654359817505
train-epoch-step: 43-401 -- Loss: 0.11752205342054367
train-epoch-step: 43-402 -- Loss: 0.2563621699810028
train-epoch-step: 43-403 -- Loss: 0.15911293029785156
train-epoch-step: 43-404 -- Loss: 0.14000317454338074
train-epoch-step: 43-405 -- Loss: 0.14866454899311066
train-epoch-step: 43-406 -- Loss: 0.16489394009113312
train-epoch-step: 43-407 -- Loss: 0.11555212736129761
train-epoch-step: 43-408 -- Loss: 0.1613689810037613
train-epoch-step: 43-409 -- Loss: 0.16923454403877258
train-epoch-step: 43-410 -- Loss: 0.17471683025360107
train-epoch-step: 43-411 -- Loss: 0.2023332417011261
train-epoch-step: 43-412 -- Loss: 0.13028061389923096
train-epoch-step: 43-413 -- Loss: 0.14448320865631104
train-epoch-step: 43-414 -- Loss: 0.13273130357265472
train-epoch-step: 43-415 -- Loss: 0.13339494168758392
train-epoch-step: 43-416 -- Loss: 0.26019486784935
train-epoch-step: 43-417 -- Loss: 0.1907673180103302
train-epoch-step: 43-418 -- Loss: 0.2297828495502472
train-epoch-step: 43-419 -- Loss: 0.17287413775920868
train-epoch-step: 43-420 -- Loss: 0.15212154388427734
train-epoch-step: 43-421 -- Loss: 0.20225057005882263
train-epoch-step: 43-422 -- Loss: 0.1903650462627411
train-epoch-step: 43-423 -- Loss: 0.18101239204406738
train-epoch-step: 43-424 -- Loss: 0.14249855279922485
train-epoch-step: 43-425 -- Loss: 0.18011853098869324
train-epoch-step: 43-426 -- Loss: 0.16639752686023712
train-epoch-step: 43-427 -- Loss: 0.12340953946113586
train-epoch-step: 43-428 -- Loss: 0.21608024835586548
train-epoch-step: 43-429 -- Loss: 0.17922712862491608
train-epoch-step: 43-430 -- Loss: 0.14091508090496063
train-epoch-step: 43-431 -- Loss: 0.1699230968952179
train-epoch-step: 43-432 -- Loss: 0.25171715021133423
train-epoch-step: 43-433 -- Loss: 0.13918372988700867
train-epoch-step: 43-434 -- Loss: 0.134606271982193
train-epoch-step: 43-435 -- Loss: 0.16300415992736816
train-epoch-step: 43-436 -- Loss: 0.1624060869216919
train-epoch-step: 43-437 -- Loss: 0.1307784616947174
train-epoch-step: 43-438 -- Loss: 0.18935240805149078
train-epoch-step: 43-439 -- Loss: 0.2646622061729431
train-epoch-step: 43-440 -- Loss: 0.13425461947917938
train-epoch-step: 43-441 -- Loss: 0.21100261807441711
train-epoch-step: 43-442 -- Loss: 0.1761053055524826
train-epoch-step: 43-443 -- Loss: 0.1634204387664795
train-epoch-step: 43-444 -- Loss: 0.18025274574756622
train-epoch-step: 43-445 -- Loss: 0.17793264985084534
train-epoch-step: 43-446 -- Loss: 0.1533220112323761
train-epoch-step: 43-447 -- Loss: 0.19184818863868713
train-epoch-step: 43-448 -- Loss: 0.23684285581111908
train-epoch-step: 43-449 -- Loss: 0.21708843111991882
train-epoch-step: 43-450 -- Loss: 0.19105876982212067
train-epoch-step: 43-451 -- Loss: 0.1509380340576172
train-epoch-step: 43-452 -- Loss: 0.12864963710308075
train-epoch-step: 43-453 -- Loss: 0.1088600903749466
train-epoch-step: 43-454 -- Loss: 0.22931799292564392
train-epoch-step: 43-455 -- Loss: 0.1628144383430481
train-epoch-step: 43-456 -- Loss: 0.12347757816314697
train-epoch-step: 43-457 -- Loss: 0.2296815812587738
train-epoch-step: 43-458 -- Loss: 0.18308228254318237
train-epoch-step: 43-459 -- Loss: 0.22090233862400055
train-epoch-step: 43-460 -- Loss: 0.13801367580890656
train-epoch-step: 43-461 -- Loss: 0.1359482705593109
train-epoch-step: 43-462 -- Loss: 0.16764670610427856
train-epoch-step: 43-463 -- Loss: 0.1408727765083313
train-epoch-step: 43-464 -- Loss: 0.16902120411396027
train-epoch-step: 43-465 -- Loss: 0.24300333857536316
train-epoch-step: 43-466 -- Loss: 0.20543552935123444
train-epoch-step: 43-467 -- Loss: 0.11883147060871124
train-epoch-step: 43-468 -- Loss: 0.1768830120563507
train-epoch-step: 43-469 -- Loss: 0.22301700711250305
train-epoch-step: 43-470 -- Loss: 0.19585932791233063
train-epoch-step: 43-471 -- Loss: 0.16216909885406494
train-epoch-step: 43-472 -- Loss: 0.15776175260543823
train-epoch-step: 43-473 -- Loss: 0.15781719982624054
train-epoch-step: 43-474 -- Loss: 0.13107118010520935
train-epoch-step: 43-475 -- Loss: 0.11347098648548126
train-epoch-step: 43-476 -- Loss: 0.20669788122177124
train-epoch-step: 43-477 -- Loss: 0.2035476416349411
train-epoch-step: 43-478 -- Loss: 0.192240908741951
train-epoch-step: 43-479 -- Loss: 0.13616609573364258
train-epoch-step: 43-480 -- Loss: 0.19225247204303741
train-epoch-step: 43-481 -- Loss: 0.28490978479385376
train-epoch-step: 43-482 -- Loss: 0.25710228085517883
train-epoch-step: 43-483 -- Loss: 0.18489277362823486
train-epoch-step: 43-484 -- Loss: 0.20946340262889862
train-epoch-step: 43-485 -- Loss: 0.13352897763252258
train-epoch-step: 43-486 -- Loss: 0.23194050788879395
train-epoch-step: 43-487 -- Loss: 0.23764115571975708
train-epoch-step: 43-488 -- Loss: 0.18747900426387787
train-epoch-step: 43-489 -- Loss: 0.2257729023694992
train-epoch-step: 43-490 -- Loss: 0.13664866983890533
train-epoch-step: 43-491 -- Loss: 0.1443924903869629
train-epoch-step: 43-492 -- Loss: 0.12498105317354202
train-epoch-step: 43-493 -- Loss: 0.19472499191761017
train-epoch-step: 43-494 -- Loss: 0.2063359022140503
train-epoch-step: 43-495 -- Loss: 0.20633839070796967
train-epoch-step: 43-496 -- Loss: 0.14178889989852905
train-epoch-step: 43-497 -- Loss: 0.1910523921251297
train-epoch-step: 43-498 -- Loss: 0.14921537041664124
train-epoch-step: 43-499 -- Loss: 0.165831059217453
train-epoch-step: 43-500 -- Loss: 0.1546284407377243
train-epoch-step: 43-501 -- Loss: 0.21951216459274292
train-epoch-step: 43-502 -- Loss: 0.1564716398715973
train-epoch-step: 43-503 -- Loss: 0.21344496309757233
train-epoch-step: 43-504 -- Loss: 0.12269621342420578
train-epoch-step: 43-505 -- Loss: 0.16834616661071777
train-epoch-step: 43-506 -- Loss: 0.11496162414550781
train-epoch-step: 43-507 -- Loss: 0.17786739766597748
train-epoch-step: 43-508 -- Loss: 0.1723930388689041
train-epoch-step: 43-509 -- Loss: 0.17083942890167236
train-epoch-step: 43-510 -- Loss: 0.12465880066156387
train-epoch-step: 43-511 -- Loss: 0.2149682193994522
train-epoch-step: 43-512 -- Loss: 0.17674210667610168
train-epoch-step: 43-513 -- Loss: 0.19755563139915466
train-epoch-step: 43-514 -- Loss: 0.15215031802654266
train-epoch-step: 43-515 -- Loss: 0.15126751363277435
train-epoch-step: 43-516 -- Loss: 0.17353548109531403
train-epoch-step: 43-517 -- Loss: 0.1723993569612503
train-epoch-step: 43-518 -- Loss: 0.14198088645935059
train-epoch-step: 43-519 -- Loss: 0.13476848602294922
train-epoch-step: 43-520 -- Loss: 0.18139666318893433
train-epoch-step: 43-521 -- Loss: 0.22194001078605652
train-epoch-step: 43-522 -- Loss: 0.17376407980918884
train-epoch-step: 43-523 -- Loss: 0.15451110899448395
train-epoch-step: 43-524 -- Loss: 0.16583406925201416
train-epoch-step: 43-525 -- Loss: 0.1871335357427597
train-epoch-step: 43-526 -- Loss: 0.1285424828529358
train-epoch-step: 43-527 -- Loss: 0.14946547150611877
train-epoch-step: 43-528 -- Loss: 0.15323083102703094
train-epoch-step: 43-529 -- Loss: 0.1559469997882843
train-epoch-step: 43-530 -- Loss: 0.17098277807235718
train-epoch-step: 43-531 -- Loss: 0.19115127623081207
train-epoch-step: 43-532 -- Loss: 0.16763003170490265
train-epoch-step: 43-533 -- Loss: 0.17006002366542816
train-epoch-step: 43-534 -- Loss: 0.12819218635559082
train-epoch-step: 43-535 -- Loss: 0.2595679759979248
train-epoch-step: 43-536 -- Loss: 0.15844805538654327
train-epoch-step: 43-537 -- Loss: 0.14516353607177734
train-epoch-step: 43-538 -- Loss: 0.102374367415905
train-epoch-step: 43-539 -- Loss: 0.17662164568901062
train-epoch-step: 43-540 -- Loss: 0.1358516961336136
train-epoch-step: 43-541 -- Loss: 0.20880594849586487
train-epoch-step: 43-542 -- Loss: 0.2263159155845642
train-epoch-step: 43-543 -- Loss: 0.180487722158432
train-epoch-step: 43-544 -- Loss: 0.22303013503551483
train-epoch-step: 43-545 -- Loss: 0.19076278805732727
train-epoch-step: 43-546 -- Loss: 0.21926598250865936
train-epoch-step: 43-547 -- Loss: 0.17519977688789368
train-epoch-step: 43-548 -- Loss: 0.0935792624950409
train-epoch-step: 43-549 -- Loss: 0.15466909110546112
train-epoch-step: 43-550 -- Loss: 0.19881974160671234
train-epoch-step: 43-551 -- Loss: 0.14949168264865875
train-epoch-step: 43-552 -- Loss: 0.13535550236701965
train-epoch-step: 43-553 -- Loss: 0.18996401131153107
train-epoch-step: 43-554 -- Loss: 0.18508115410804749
train-epoch-step: 43-555 -- Loss: 0.21337750554084778
train-epoch-step: 43-556 -- Loss: 0.14725399017333984
train-epoch-step: 43-557 -- Loss: 0.2469390630722046
train-epoch-step: 43-558 -- Loss: 0.2244453877210617
train-epoch-step: 43-559 -- Loss: 0.1367630958557129
train-epoch-step: 43-560 -- Loss: 0.2033671736717224
train-epoch-step: 43-561 -- Loss: 0.1752471923828125
train-epoch-step: 43-562 -- Loss: 0.16441258788108826
train-epoch-step: 43-563 -- Loss: 0.19238732755184174
train-epoch-step: 43-564 -- Loss: 0.09888191521167755
train-epoch-step: 43-565 -- Loss: 0.17851130664348602
train-epoch-step: 43-566 -- Loss: 0.14637742936611176
train-epoch-step: 43-567 -- Loss: 0.2085074782371521
train-epoch-step: 43-568 -- Loss: 0.15703381597995758
train-epoch-step: 43-569 -- Loss: 0.2370881587266922
train-epoch-step: 43-570 -- Loss: 0.16702069342136383
train-epoch-step: 43-571 -- Loss: 0.21329858899116516
train-epoch-step: 43-572 -- Loss: 0.24840177595615387
train-epoch-step: 43-573 -- Loss: 0.19608193635940552
train-epoch-step: 43-574 -- Loss: 0.24018943309783936
train-epoch-step: 43-575 -- Loss: 0.29516202211380005
train-epoch-step: 43-576 -- Loss: 0.1182985007762909
train-epoch-step: 43-577 -- Loss: 0.17320959270000458
train-epoch-step: 43-578 -- Loss: 0.21290290355682373
train-epoch-step: 43-579 -- Loss: 0.1696716845035553
train-epoch-step: 43-580 -- Loss: 0.17365169525146484
train-epoch-step: 43-581 -- Loss: 0.14017394185066223
train-epoch-step: 43-582 -- Loss: 0.2071407586336136
train-epoch-step: 43-583 -- Loss: 0.22292569279670715
train-epoch-step: 43-584 -- Loss: 0.1664186716079712
train-epoch-step: 43-585 -- Loss: 0.19338606297969818
train-epoch-step: 43-586 -- Loss: 0.2531018555164337
train-epoch-step: 43-587 -- Loss: 0.15479572117328644
train-epoch-step: 43-588 -- Loss: 0.12981943786144257
val-epoch-step: 43-589 -- Loss: 0.20650941133499146
val-epoch-step: 43-590 -- Loss: 0.1535194218158722
val-epoch-step: 43-591 -- Loss: 0.22519923746585846
val-epoch-step: 43-592 -- Loss: 0.17676280438899994
val-epoch-step: 43-593 -- Loss: 0.1642911434173584
val-epoch-step: 43-594 -- Loss: 0.4384062588214874
val-epoch-step: 43-595 -- Loss: 0.2051364779472351
val-epoch-step: 43-596 -- Loss: 0.2006457895040512
val-epoch-step: 43-597 -- Loss: 0.18115806579589844
val-epoch-step: 43-598 -- Loss: 0.1553768664598465
val-epoch-step: 43-599 -- Loss: 0.18695321679115295
val-epoch-step: 43-600 -- Loss: 0.21355865895748138
val-epoch-step: 43-601 -- Loss: 0.15500429272651672
val-epoch-step: 43-602 -- Loss: 0.13513989746570587
val-epoch-step: 43-603 -- Loss: 0.1966809183359146
val-epoch-step: 43-604 -- Loss: 0.149664044380188
val-epoch-step: 43-605 -- Loss: 0.15189644694328308
val-epoch-step: 43-606 -- Loss: 0.26499131321907043
val-epoch-step: 43-607 -- Loss: 0.1333235204219818
val-epoch-step: 43-608 -- Loss: 0.2531454265117645
val-epoch-step: 43-609 -- Loss: 0.16354084014892578
val-epoch-step: 43-610 -- Loss: 0.17919307947158813
val-epoch-step: 43-611 -- Loss: 0.16882659494876862
val-epoch-step: 43-612 -- Loss: 0.42437100410461426
val-epoch-step: 43-613 -- Loss: 0.1820807009935379
val-epoch-step: 43-614 -- Loss: 0.1845836639404297
val-epoch-step: 43-615 -- Loss: 0.17310380935668945
val-epoch-step: 43-616 -- Loss: 0.15016613900661469
val-epoch-step: 43-617 -- Loss: 0.1937294900417328
val-epoch-step: 43-618 -- Loss: 0.18058066070079803
val-epoch-step: 43-619 -- Loss: 0.2100694626569748
val-epoch-step: 43-620 -- Loss: 0.14722800254821777
val-epoch-step: 43-621 -- Loss: 0.13453654944896698
val-epoch-step: 43-622 -- Loss: 0.14686931669712067
val-epoch-step: 43-623 -- Loss: 0.15053443610668182
val-epoch-step: 43-624 -- Loss: 0.15022586286067963
val-epoch-step: 43-625 -- Loss: 0.15553241968154907
val-epoch-step: 43-626 -- Loss: 0.1492728590965271
val-epoch-step: 43-627 -- Loss: 0.1834639608860016
val-epoch-step: 43-628 -- Loss: 0.6248384714126587
val-epoch-step: 43-629 -- Loss: 0.20791684091091156
val-epoch-step: 43-630 -- Loss: 0.34235745668411255
val-epoch-step: 43-631 -- Loss: 0.15050190687179565
val-epoch-step: 43-632 -- Loss: 0.20186229050159454
val-epoch-step: 43-633 -- Loss: 0.14920926094055176
val-epoch-step: 43-634 -- Loss: 0.14284394681453705
val-epoch-step: 43-635 -- Loss: 0.11597922444343567
val-epoch-step: 43-636 -- Loss: 0.1596326231956482
val-epoch-step: 43-637 -- Loss: 0.1907908320426941
val-epoch-step: 43-638 -- Loss: 0.163372203707695
val-epoch-step: 43-639 -- Loss: 0.26400017738342285
val-epoch-step: 43-640 -- Loss: 0.2563439905643463
val-epoch-step: 43-641 -- Loss: 0.12443792819976807
val-epoch-step: 43-642 -- Loss: 0.21431180834770203
val-epoch-step: 43-643 -- Loss: 0.20707181096076965
val-epoch-step: 43-644 -- Loss: 0.17762666940689087
val-epoch-step: 43-645 -- Loss: 0.22359104454517365
val-epoch-step: 43-646 -- Loss: 0.15845495462417603
val-epoch-step: 43-647 -- Loss: 0.13146544992923737
val-epoch-step: 43-648 -- Loss: 0.1553885042667389
val-epoch-step: 43-649 -- Loss: 0.22002361714839935
val-epoch-step: 43-650 -- Loss: 0.25561708211898804
val-epoch-step: 43-651 -- Loss: 0.14804673194885254
val-epoch-step: 43-652 -- Loss: 0.15701323747634888
val-epoch-step: 43-653 -- Loss: 0.25023961067199707
val-epoch-step: 43-654 -- Loss: 0.12668806314468384
Epoch: 43 -- Train Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1427, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 44-0 -- Loss: 0.2287781834602356
train-epoch-step: 44-1 -- Loss: 0.14566852152347565
train-epoch-step: 44-2 -- Loss: 0.193091481924057
train-epoch-step: 44-3 -- Loss: 0.1446256786584854
train-epoch-step: 44-4 -- Loss: 0.157075896859169
train-epoch-step: 44-5 -- Loss: 0.18667586147785187
train-epoch-step: 44-6 -- Loss: 0.2117810994386673
train-epoch-step: 44-7 -- Loss: 0.1614757478237152
train-epoch-step: 44-8 -- Loss: 0.17936529219150543
train-epoch-step: 44-9 -- Loss: 0.22153371572494507
train-epoch-step: 44-10 -- Loss: 0.2096019983291626
train-epoch-step: 44-11 -- Loss: 0.17932385206222534
train-epoch-step: 44-12 -- Loss: 0.15505044162273407
train-epoch-step: 44-13 -- Loss: 0.17901161313056946
train-epoch-step: 44-14 -- Loss: 0.1654781550168991
train-epoch-step: 44-15 -- Loss: 0.16053031384944916
train-epoch-step: 44-16 -- Loss: 0.1627034842967987
train-epoch-step: 44-17 -- Loss: 0.22171533107757568
train-epoch-step: 44-18 -- Loss: 0.19110079109668732
train-epoch-step: 44-19 -- Loss: 0.12907302379608154
train-epoch-step: 44-20 -- Loss: 0.2118084877729416
train-epoch-step: 44-21 -- Loss: 0.29179835319519043
train-epoch-step: 44-22 -- Loss: 0.13912513852119446
train-epoch-step: 44-23 -- Loss: 0.14122623205184937
train-epoch-step: 44-24 -- Loss: 0.12476500123739243
train-epoch-step: 44-25 -- Loss: 0.225350022315979
train-epoch-step: 44-26 -- Loss: 0.19352129101753235
train-epoch-step: 44-27 -- Loss: 0.3436605930328369
train-epoch-step: 44-28 -- Loss: 0.12282037734985352
train-epoch-step: 44-29 -- Loss: 0.2548646330833435
train-epoch-step: 44-30 -- Loss: 0.10969304293394089
train-epoch-step: 44-31 -- Loss: 0.13531768321990967
train-epoch-step: 44-32 -- Loss: 0.17071624100208282
train-epoch-step: 44-33 -- Loss: 0.2802009880542755
train-epoch-step: 44-34 -- Loss: 0.1759973168373108
train-epoch-step: 44-35 -- Loss: 0.24755804240703583
train-epoch-step: 44-36 -- Loss: 0.13959074020385742
train-epoch-step: 44-37 -- Loss: 0.14424185454845428
train-epoch-step: 44-38 -- Loss: 0.23537665605545044
train-epoch-step: 44-39 -- Loss: 0.24218302965164185
train-epoch-step: 44-40 -- Loss: 0.21360290050506592
train-epoch-step: 44-41 -- Loss: 0.21834135055541992
train-epoch-step: 44-42 -- Loss: 0.1514306217432022
train-epoch-step: 44-43 -- Loss: 0.27570924162864685
train-epoch-step: 44-44 -- Loss: 0.129837766289711
train-epoch-step: 44-45 -- Loss: 0.1383344531059265
train-epoch-step: 44-46 -- Loss: 0.17999470233917236
train-epoch-step: 44-47 -- Loss: 0.24844637513160706
train-epoch-step: 44-48 -- Loss: 0.16796401143074036
train-epoch-step: 44-49 -- Loss: 0.2369937151670456
train-epoch-step: 44-50 -- Loss: 0.1114131361246109
train-epoch-step: 44-51 -- Loss: 0.18693557381629944
train-epoch-step: 44-52 -- Loss: 0.16111209988594055
train-epoch-step: 44-53 -- Loss: 0.22465728223323822
train-epoch-step: 44-54 -- Loss: 0.28789597749710083
train-epoch-step: 44-55 -- Loss: 0.18413633108139038
train-epoch-step: 44-56 -- Loss: 0.1795419305562973
train-epoch-step: 44-57 -- Loss: 0.2452305406332016
train-epoch-step: 44-58 -- Loss: 0.28195711970329285
train-epoch-step: 44-59 -- Loss: 0.2506629228591919
train-epoch-step: 44-60 -- Loss: 0.137183278799057
train-epoch-step: 44-61 -- Loss: 0.19911208748817444
train-epoch-step: 44-62 -- Loss: 0.1903093457221985
train-epoch-step: 44-63 -- Loss: 0.13675400614738464
train-epoch-step: 44-64 -- Loss: 0.14739952981472015
train-epoch-step: 44-65 -- Loss: 0.17937669157981873
train-epoch-step: 44-66 -- Loss: 0.1116415485739708
train-epoch-step: 44-67 -- Loss: 0.12727752327919006
train-epoch-step: 44-68 -- Loss: 0.21785204112529755
train-epoch-step: 44-69 -- Loss: 0.12241321802139282
train-epoch-step: 44-70 -- Loss: 0.240850567817688
train-epoch-step: 44-71 -- Loss: 0.25264155864715576
train-epoch-step: 44-72 -- Loss: 0.17358213663101196
train-epoch-step: 44-73 -- Loss: 0.21294887363910675
train-epoch-step: 44-74 -- Loss: 0.09852774441242218
train-epoch-step: 44-75 -- Loss: 0.13067111372947693
train-epoch-step: 44-76 -- Loss: 0.14261695742607117
train-epoch-step: 44-77 -- Loss: 0.22685210406780243
train-epoch-step: 44-78 -- Loss: 0.2575806677341461
train-epoch-step: 44-79 -- Loss: 0.1912674754858017
train-epoch-step: 44-80 -- Loss: 0.2531713843345642
train-epoch-step: 44-81 -- Loss: 0.12415274977684021
train-epoch-step: 44-82 -- Loss: 0.25980767607688904
train-epoch-step: 44-83 -- Loss: 0.20177873969078064
train-epoch-step: 44-84 -- Loss: 0.19268494844436646
train-epoch-step: 44-85 -- Loss: 0.17131048440933228
train-epoch-step: 44-86 -- Loss: 0.131733238697052
train-epoch-step: 44-87 -- Loss: 0.2156190574169159
train-epoch-step: 44-88 -- Loss: 0.14370611310005188
train-epoch-step: 44-89 -- Loss: 0.18816909193992615
train-epoch-step: 44-90 -- Loss: 0.1917518824338913
train-epoch-step: 44-91 -- Loss: 0.2503596246242523
train-epoch-step: 44-92 -- Loss: 0.17314377427101135
train-epoch-step: 44-93 -- Loss: 0.1718079149723053
train-epoch-step: 44-94 -- Loss: 0.21960555016994476
train-epoch-step: 44-95 -- Loss: 0.1984039843082428
train-epoch-step: 44-96 -- Loss: 0.21702753007411957
train-epoch-step: 44-97 -- Loss: 0.17239674925804138
train-epoch-step: 44-98 -- Loss: 0.1543826162815094
train-epoch-step: 44-99 -- Loss: 0.18828195333480835
train-epoch-step: 44-100 -- Loss: 0.1953100860118866
train-epoch-step: 44-101 -- Loss: 0.2745760679244995
train-epoch-step: 44-102 -- Loss: 0.22592486441135406
train-epoch-step: 44-103 -- Loss: 0.1852419376373291
train-epoch-step: 44-104 -- Loss: 0.14762240648269653
train-epoch-step: 44-105 -- Loss: 0.2726818323135376
train-epoch-step: 44-106 -- Loss: 0.1942102313041687
train-epoch-step: 44-107 -- Loss: 0.19397063553333282
train-epoch-step: 44-108 -- Loss: 0.18928267061710358
train-epoch-step: 44-109 -- Loss: 0.145669624209404
train-epoch-step: 44-110 -- Loss: 0.1858375519514084
train-epoch-step: 44-111 -- Loss: 0.1797560751438141
train-epoch-step: 44-112 -- Loss: 0.1640927940607071
train-epoch-step: 44-113 -- Loss: 0.15922893583774567
train-epoch-step: 44-114 -- Loss: 0.19928660988807678
train-epoch-step: 44-115 -- Loss: 0.16204313933849335
train-epoch-step: 44-116 -- Loss: 0.13917545974254608
train-epoch-step: 44-117 -- Loss: 0.1251390278339386
train-epoch-step: 44-118 -- Loss: 0.24922877550125122
train-epoch-step: 44-119 -- Loss: 0.1512211114168167
train-epoch-step: 44-120 -- Loss: 0.2542235255241394
train-epoch-step: 44-121 -- Loss: 0.23245051503181458
train-epoch-step: 44-122 -- Loss: 0.22753027081489563
train-epoch-step: 44-123 -- Loss: 0.20483464002609253
train-epoch-step: 44-124 -- Loss: 0.12116268277168274
train-epoch-step: 44-125 -- Loss: 0.15643565356731415
train-epoch-step: 44-126 -- Loss: 0.23747067153453827
train-epoch-step: 44-127 -- Loss: 0.17482976615428925
train-epoch-step: 44-128 -- Loss: 0.17207567393779755
train-epoch-step: 44-129 -- Loss: 0.14730001986026764
train-epoch-step: 44-130 -- Loss: 0.19640174508094788
train-epoch-step: 44-131 -- Loss: 0.1397642195224762
train-epoch-step: 44-132 -- Loss: 0.22043459117412567
train-epoch-step: 44-133 -- Loss: 0.12507565319538116
train-epoch-step: 44-134 -- Loss: 0.19705164432525635
train-epoch-step: 44-135 -- Loss: 0.13659971952438354
train-epoch-step: 44-136 -- Loss: 0.12824514508247375
train-epoch-step: 44-137 -- Loss: 0.24579909443855286
train-epoch-step: 44-138 -- Loss: 0.25721871852874756
train-epoch-step: 44-139 -- Loss: 0.140419140458107
train-epoch-step: 44-140 -- Loss: 0.20701977610588074
train-epoch-step: 44-141 -- Loss: 0.2372104525566101
train-epoch-step: 44-142 -- Loss: 0.2022310197353363
train-epoch-step: 44-143 -- Loss: 0.17625544965267181
train-epoch-step: 44-144 -- Loss: 0.18569456040859222
train-epoch-step: 44-145 -- Loss: 0.1408243179321289
train-epoch-step: 44-146 -- Loss: 0.18278688192367554
train-epoch-step: 44-147 -- Loss: 0.1728762686252594
train-epoch-step: 44-148 -- Loss: 0.1587318331003189
train-epoch-step: 44-149 -- Loss: 0.1212327629327774
train-epoch-step: 44-150 -- Loss: 0.18232643604278564
train-epoch-step: 44-151 -- Loss: 0.18994629383087158
train-epoch-step: 44-152 -- Loss: 0.18961529433727264
train-epoch-step: 44-153 -- Loss: 0.2740742266178131
train-epoch-step: 44-154 -- Loss: 0.12990061938762665
train-epoch-step: 44-155 -- Loss: 0.1343596875667572
train-epoch-step: 44-156 -- Loss: 0.11729776114225388
train-epoch-step: 44-157 -- Loss: 0.1671207696199417
train-epoch-step: 44-158 -- Loss: 0.16349534690380096
train-epoch-step: 44-159 -- Loss: 0.1793835312128067
train-epoch-step: 44-160 -- Loss: 0.21970710158348083
train-epoch-step: 44-161 -- Loss: 0.2067781388759613
train-epoch-step: 44-162 -- Loss: 0.21271532773971558
train-epoch-step: 44-163 -- Loss: 0.18607547879219055
train-epoch-step: 44-164 -- Loss: 0.1892116665840149
train-epoch-step: 44-165 -- Loss: 0.16506756842136383
train-epoch-step: 44-166 -- Loss: 0.12398006021976471
train-epoch-step: 44-167 -- Loss: 0.12879203259944916
train-epoch-step: 44-168 -- Loss: 0.2075026035308838
train-epoch-step: 44-169 -- Loss: 0.14457671344280243
train-epoch-step: 44-170 -- Loss: 0.1948482096195221
train-epoch-step: 44-171 -- Loss: 0.1426990032196045
train-epoch-step: 44-172 -- Loss: 0.2637697458267212
train-epoch-step: 44-173 -- Loss: 0.129716157913208
train-epoch-step: 44-174 -- Loss: 0.250596821308136
train-epoch-step: 44-175 -- Loss: 0.18655143678188324
train-epoch-step: 44-176 -- Loss: 0.1397296041250229
train-epoch-step: 44-177 -- Loss: 0.17662392556667328
train-epoch-step: 44-178 -- Loss: 0.17801052331924438
train-epoch-step: 44-179 -- Loss: 0.16247907280921936
train-epoch-step: 44-180 -- Loss: 0.14857099950313568
train-epoch-step: 44-181 -- Loss: 0.16520409286022186
train-epoch-step: 44-182 -- Loss: 0.18069428205490112
train-epoch-step: 44-183 -- Loss: 0.26566943526268005
train-epoch-step: 44-184 -- Loss: 0.13484600186347961
train-epoch-step: 44-185 -- Loss: 0.14341437816619873
train-epoch-step: 44-186 -- Loss: 0.19377624988555908
train-epoch-step: 44-187 -- Loss: 0.2187509536743164
train-epoch-step: 44-188 -- Loss: 0.1687275469303131
train-epoch-step: 44-189 -- Loss: 0.10283094644546509
train-epoch-step: 44-190 -- Loss: 0.1781594604253769
train-epoch-step: 44-191 -- Loss: 0.15871475636959076
train-epoch-step: 44-192 -- Loss: 0.228671133518219
train-epoch-step: 44-193 -- Loss: 0.21373514831066132
train-epoch-step: 44-194 -- Loss: 0.18075953423976898
train-epoch-step: 44-195 -- Loss: 0.16338983178138733
train-epoch-step: 44-196 -- Loss: 0.16675524413585663
train-epoch-step: 44-197 -- Loss: 0.126692533493042
train-epoch-step: 44-198 -- Loss: 0.12633755803108215
train-epoch-step: 44-199 -- Loss: 0.14568409323692322
train-epoch-step: 44-200 -- Loss: 0.12215691804885864
train-epoch-step: 44-201 -- Loss: 0.19618584215641022
train-epoch-step: 44-202 -- Loss: 0.13503976166248322
train-epoch-step: 44-203 -- Loss: 0.1709187924861908
train-epoch-step: 44-204 -- Loss: 0.13353262841701508
train-epoch-step: 44-205 -- Loss: 0.1848258376121521
train-epoch-step: 44-206 -- Loss: 0.1975698620080948
train-epoch-step: 44-207 -- Loss: 0.14944913983345032
train-epoch-step: 44-208 -- Loss: 0.17310917377471924
train-epoch-step: 44-209 -- Loss: 0.1407921016216278
train-epoch-step: 44-210 -- Loss: 0.1346912980079651
train-epoch-step: 44-211 -- Loss: 0.2050567865371704
train-epoch-step: 44-212 -- Loss: 0.19438575208187103
train-epoch-step: 44-213 -- Loss: 0.12375932931900024
train-epoch-step: 44-214 -- Loss: 0.1474299430847168
train-epoch-step: 44-215 -- Loss: 0.12657079100608826
train-epoch-step: 44-216 -- Loss: 0.20703817903995514
train-epoch-step: 44-217 -- Loss: 0.21251998841762543
train-epoch-step: 44-218 -- Loss: 0.13997215032577515
train-epoch-step: 44-219 -- Loss: 0.1737644374370575
train-epoch-step: 44-220 -- Loss: 0.13106712698936462
train-epoch-step: 44-221 -- Loss: 0.20538470149040222
train-epoch-step: 44-222 -- Loss: 0.11471972614526749
train-epoch-step: 44-223 -- Loss: 0.17070534825325012
train-epoch-step: 44-224 -- Loss: 0.18869972229003906
train-epoch-step: 44-225 -- Loss: 0.26681703329086304
train-epoch-step: 44-226 -- Loss: 0.20444855093955994
train-epoch-step: 44-227 -- Loss: 0.22106046974658966
train-epoch-step: 44-228 -- Loss: 0.177248015999794
train-epoch-step: 44-229 -- Loss: 0.171587735414505
train-epoch-step: 44-230 -- Loss: 0.16294147074222565
train-epoch-step: 44-231 -- Loss: 0.15332277119159698
train-epoch-step: 44-232 -- Loss: 0.18490958213806152
train-epoch-step: 44-233 -- Loss: 0.08896462619304657
train-epoch-step: 44-234 -- Loss: 0.17285913228988647
train-epoch-step: 44-235 -- Loss: 0.15601512789726257
train-epoch-step: 44-236 -- Loss: 0.178806334733963
train-epoch-step: 44-237 -- Loss: 0.2315388023853302
train-epoch-step: 44-238 -- Loss: 0.1530177891254425
train-epoch-step: 44-239 -- Loss: 0.12428802996873856
train-epoch-step: 44-240 -- Loss: 0.21851783990859985
train-epoch-step: 44-241 -- Loss: 0.151284858584404
train-epoch-step: 44-242 -- Loss: 0.2204006165266037
train-epoch-step: 44-243 -- Loss: 0.23139603435993195
train-epoch-step: 44-244 -- Loss: 0.20586895942687988
train-epoch-step: 44-245 -- Loss: 0.20507070422172546
train-epoch-step: 44-246 -- Loss: 0.21551461517810822
train-epoch-step: 44-247 -- Loss: 0.20659036934375763
train-epoch-step: 44-248 -- Loss: 0.1829787939786911
train-epoch-step: 44-249 -- Loss: 0.13586564362049103
train-epoch-step: 44-250 -- Loss: 0.2000463604927063
train-epoch-step: 44-251 -- Loss: 0.10631538182497025
train-epoch-step: 44-252 -- Loss: 0.1880737990140915
train-epoch-step: 44-253 -- Loss: 0.1391325443983078
train-epoch-step: 44-254 -- Loss: 0.2110801339149475
train-epoch-step: 44-255 -- Loss: 0.14339864253997803
train-epoch-step: 44-256 -- Loss: 0.14858117699623108
train-epoch-step: 44-257 -- Loss: 0.1874895542860031
train-epoch-step: 44-258 -- Loss: 0.1452733278274536
train-epoch-step: 44-259 -- Loss: 0.11814793199300766
train-epoch-step: 44-260 -- Loss: 0.1946999430656433
train-epoch-step: 44-261 -- Loss: 0.18168002367019653
train-epoch-step: 44-262 -- Loss: 0.2963069677352905
train-epoch-step: 44-263 -- Loss: 0.20180264115333557
train-epoch-step: 44-264 -- Loss: 0.17230558395385742
train-epoch-step: 44-265 -- Loss: 0.10706721246242523
train-epoch-step: 44-266 -- Loss: 0.15539227426052094
train-epoch-step: 44-267 -- Loss: 0.1267244666814804
train-epoch-step: 44-268 -- Loss: 0.11478417366743088
train-epoch-step: 44-269 -- Loss: 0.1686745584011078
train-epoch-step: 44-270 -- Loss: 0.10429399460554123
train-epoch-step: 44-271 -- Loss: 0.14587236940860748
train-epoch-step: 44-272 -- Loss: 0.11210416257381439
train-epoch-step: 44-273 -- Loss: 0.1235889121890068
train-epoch-step: 44-274 -- Loss: 0.17763328552246094
train-epoch-step: 44-275 -- Loss: 0.19912438094615936
train-epoch-step: 44-276 -- Loss: 0.15681955218315125
train-epoch-step: 44-277 -- Loss: 0.15229745209217072
train-epoch-step: 44-278 -- Loss: 0.13596853613853455
train-epoch-step: 44-279 -- Loss: 0.14025577902793884
train-epoch-step: 44-280 -- Loss: 0.21449510753154755
train-epoch-step: 44-281 -- Loss: 0.17351418733596802
train-epoch-step: 44-282 -- Loss: 0.14122626185417175
train-epoch-step: 44-283 -- Loss: 0.11366435885429382
train-epoch-step: 44-284 -- Loss: 0.13656875491142273
train-epoch-step: 44-285 -- Loss: 0.1885511726140976
train-epoch-step: 44-286 -- Loss: 0.15407279133796692
train-epoch-step: 44-287 -- Loss: 0.20022644102573395
train-epoch-step: 44-288 -- Loss: 0.0956139862537384
train-epoch-step: 44-289 -- Loss: 0.11898207664489746
train-epoch-step: 44-290 -- Loss: 0.17767970263957977
train-epoch-step: 44-291 -- Loss: 0.11408663541078568
train-epoch-step: 44-292 -- Loss: 0.15433159470558167
train-epoch-step: 44-293 -- Loss: 0.1356547325849533
train-epoch-step: 44-294 -- Loss: 0.17098571360111237
train-epoch-step: 44-295 -- Loss: 0.267423152923584
train-epoch-step: 44-296 -- Loss: 0.1576617807149887
train-epoch-step: 44-297 -- Loss: 0.17119163274765015
train-epoch-step: 44-298 -- Loss: 0.22467957437038422
train-epoch-step: 44-299 -- Loss: 0.1421903669834137
train-epoch-step: 44-300 -- Loss: 0.17447814345359802
train-epoch-step: 44-301 -- Loss: 0.1658822000026703
train-epoch-step: 44-302 -- Loss: 0.21238644421100616
train-epoch-step: 44-303 -- Loss: 0.20084792375564575
train-epoch-step: 44-304 -- Loss: 0.12606629729270935
train-epoch-step: 44-305 -- Loss: 0.14282669126987457
train-epoch-step: 44-306 -- Loss: 0.21967482566833496
train-epoch-step: 44-307 -- Loss: 0.16230808198451996
train-epoch-step: 44-308 -- Loss: 0.21532930433750153
train-epoch-step: 44-309 -- Loss: 0.15345771610736847
train-epoch-step: 44-310 -- Loss: 0.1600044071674347
train-epoch-step: 44-311 -- Loss: 0.15732812881469727
train-epoch-step: 44-312 -- Loss: 0.19950447976589203
train-epoch-step: 44-313 -- Loss: 0.09655173122882843
train-epoch-step: 44-314 -- Loss: 0.18741992115974426
train-epoch-step: 44-315 -- Loss: 0.16679680347442627
train-epoch-step: 44-316 -- Loss: 0.1526949256658554
train-epoch-step: 44-317 -- Loss: 0.14075659215450287
train-epoch-step: 44-318 -- Loss: 0.16466966271400452
train-epoch-step: 44-319 -- Loss: 0.1659754067659378
train-epoch-step: 44-320 -- Loss: 0.11691498011350632
train-epoch-step: 44-321 -- Loss: 0.13049116730690002
train-epoch-step: 44-322 -- Loss: 0.20936502516269684
train-epoch-step: 44-323 -- Loss: 0.16119372844696045
train-epoch-step: 44-324 -- Loss: 0.2508358657360077
train-epoch-step: 44-325 -- Loss: 0.15284711122512817
train-epoch-step: 44-326 -- Loss: 0.17222841084003448
train-epoch-step: 44-327 -- Loss: 0.2056960016489029
train-epoch-step: 44-328 -- Loss: 0.19305992126464844
train-epoch-step: 44-329 -- Loss: 0.3384942412376404
train-epoch-step: 44-330 -- Loss: 0.3576669692993164
train-epoch-step: 44-331 -- Loss: 0.202972412109375
train-epoch-step: 44-332 -- Loss: 0.09921278804540634
train-epoch-step: 44-333 -- Loss: 0.18401400744915009
train-epoch-step: 44-334 -- Loss: 0.15035395324230194
train-epoch-step: 44-335 -- Loss: 0.1704101860523224
train-epoch-step: 44-336 -- Loss: 0.1460084468126297
train-epoch-step: 44-337 -- Loss: 0.20430313050746918
train-epoch-step: 44-338 -- Loss: 0.16112804412841797
train-epoch-step: 44-339 -- Loss: 0.14197784662246704
train-epoch-step: 44-340 -- Loss: 0.19792935252189636
train-epoch-step: 44-341 -- Loss: 0.13963839411735535
train-epoch-step: 44-342 -- Loss: 0.16414140164852142
train-epoch-step: 44-343 -- Loss: 0.15592357516288757
train-epoch-step: 44-344 -- Loss: 0.16629908978939056
train-epoch-step: 44-345 -- Loss: 0.12700657546520233
train-epoch-step: 44-346 -- Loss: 0.20452913641929626
train-epoch-step: 44-347 -- Loss: 0.15076473355293274
train-epoch-step: 44-348 -- Loss: 0.1968512237071991
train-epoch-step: 44-349 -- Loss: 0.20393574237823486
train-epoch-step: 44-350 -- Loss: 0.2518143951892853
train-epoch-step: 44-351 -- Loss: 0.19184111058712006
train-epoch-step: 44-352 -- Loss: 0.12154430150985718
train-epoch-step: 44-353 -- Loss: 0.18841342628002167
train-epoch-step: 44-354 -- Loss: 0.2750144898891449
train-epoch-step: 44-355 -- Loss: 0.11646021157503128
train-epoch-step: 44-356 -- Loss: 0.11389094591140747
train-epoch-step: 44-357 -- Loss: 0.18638576567173004
train-epoch-step: 44-358 -- Loss: 0.18619826436042786
train-epoch-step: 44-359 -- Loss: 0.13770143687725067
train-epoch-step: 44-360 -- Loss: 0.12046519666910172
train-epoch-step: 44-361 -- Loss: 0.23218636214733124
train-epoch-step: 44-362 -- Loss: 0.1666485220193863
train-epoch-step: 44-363 -- Loss: 0.10849202424287796
train-epoch-step: 44-364 -- Loss: 0.17881400883197784
train-epoch-step: 44-365 -- Loss: 0.17147201299667358
train-epoch-step: 44-366 -- Loss: 0.1971348524093628
train-epoch-step: 44-367 -- Loss: 0.2277376800775528
train-epoch-step: 44-368 -- Loss: 0.20128342509269714
train-epoch-step: 44-369 -- Loss: 0.2717171013355255
train-epoch-step: 44-370 -- Loss: 0.12205202132463455
train-epoch-step: 44-371 -- Loss: 0.11956153064966202
train-epoch-step: 44-372 -- Loss: 0.14420188963413239
train-epoch-step: 44-373 -- Loss: 0.19259464740753174
train-epoch-step: 44-374 -- Loss: 0.14986208081245422
train-epoch-step: 44-375 -- Loss: 0.26895928382873535
train-epoch-step: 44-376 -- Loss: 0.1623280644416809
train-epoch-step: 44-377 -- Loss: 0.22666767239570618
train-epoch-step: 44-378 -- Loss: 0.19649609923362732
train-epoch-step: 44-379 -- Loss: 0.11621920764446259
train-epoch-step: 44-380 -- Loss: 0.09086421132087708
train-epoch-step: 44-381 -- Loss: 0.24094857275485992
train-epoch-step: 44-382 -- Loss: 0.23349086940288544
train-epoch-step: 44-383 -- Loss: 0.17274421453475952
train-epoch-step: 44-384 -- Loss: 0.21406644582748413
train-epoch-step: 44-385 -- Loss: 0.19192390143871307
train-epoch-step: 44-386 -- Loss: 0.179581880569458
train-epoch-step: 44-387 -- Loss: 0.19880907237529755
train-epoch-step: 44-388 -- Loss: 0.18952560424804688
train-epoch-step: 44-389 -- Loss: 0.17298878729343414
train-epoch-step: 44-390 -- Loss: 0.1410047709941864
train-epoch-step: 44-391 -- Loss: 0.14427897334098816
train-epoch-step: 44-392 -- Loss: 0.18404005467891693
train-epoch-step: 44-393 -- Loss: 0.1563769429922104
train-epoch-step: 44-394 -- Loss: 0.19690042734146118
train-epoch-step: 44-395 -- Loss: 0.15042562782764435
train-epoch-step: 44-396 -- Loss: 0.12384214997291565
train-epoch-step: 44-397 -- Loss: 0.12421292811632156
train-epoch-step: 44-398 -- Loss: 0.191569522023201
train-epoch-step: 44-399 -- Loss: 0.17036235332489014
train-epoch-step: 44-400 -- Loss: 0.2702840268611908
train-epoch-step: 44-401 -- Loss: 0.119998499751091
train-epoch-step: 44-402 -- Loss: 0.25354573130607605
train-epoch-step: 44-403 -- Loss: 0.1529691368341446
train-epoch-step: 44-404 -- Loss: 0.1342511624097824
train-epoch-step: 44-405 -- Loss: 0.14037999510765076
train-epoch-step: 44-406 -- Loss: 0.1636449694633484
train-epoch-step: 44-407 -- Loss: 0.11111295968294144
train-epoch-step: 44-408 -- Loss: 0.1591334193944931
train-epoch-step: 44-409 -- Loss: 0.16577449440956116
train-epoch-step: 44-410 -- Loss: 0.17591628432273865
train-epoch-step: 44-411 -- Loss: 0.19479899108409882
train-epoch-step: 44-412 -- Loss: 0.12508438527584076
train-epoch-step: 44-413 -- Loss: 0.14212340116500854
train-epoch-step: 44-414 -- Loss: 0.1313684731721878
train-epoch-step: 44-415 -- Loss: 0.13319861888885498
train-epoch-step: 44-416 -- Loss: 0.25881773233413696
train-epoch-step: 44-417 -- Loss: 0.18607012927532196
train-epoch-step: 44-418 -- Loss: 0.22543351352214813
train-epoch-step: 44-419 -- Loss: 0.1631743162870407
train-epoch-step: 44-420 -- Loss: 0.15157389640808105
train-epoch-step: 44-421 -- Loss: 0.1769760549068451
train-epoch-step: 44-422 -- Loss: 0.14904794096946716
train-epoch-step: 44-423 -- Loss: 0.17874759435653687
train-epoch-step: 44-424 -- Loss: 0.13559789955615997
train-epoch-step: 44-425 -- Loss: 0.1806562840938568
train-epoch-step: 44-426 -- Loss: 0.16413871943950653
train-epoch-step: 44-427 -- Loss: 0.11915332078933716
train-epoch-step: 44-428 -- Loss: 0.18948864936828613
train-epoch-step: 44-429 -- Loss: 0.17404881119728088
train-epoch-step: 44-430 -- Loss: 0.14086568355560303
train-epoch-step: 44-431 -- Loss: 0.16034196317195892
train-epoch-step: 44-432 -- Loss: 0.23199692368507385
train-epoch-step: 44-433 -- Loss: 0.13520342111587524
train-epoch-step: 44-434 -- Loss: 0.12883912026882172
train-epoch-step: 44-435 -- Loss: 0.15265870094299316
train-epoch-step: 44-436 -- Loss: 0.15361012518405914
train-epoch-step: 44-437 -- Loss: 0.12945540249347687
train-epoch-step: 44-438 -- Loss: 0.16530899703502655
train-epoch-step: 44-439 -- Loss: 0.25761112570762634
train-epoch-step: 44-440 -- Loss: 0.12978482246398926
train-epoch-step: 44-441 -- Loss: 0.1972450613975525
train-epoch-step: 44-442 -- Loss: 0.17211207747459412
train-epoch-step: 44-443 -- Loss: 0.1529426872730255
train-epoch-step: 44-444 -- Loss: 0.17059123516082764
train-epoch-step: 44-445 -- Loss: 0.1724727749824524
train-epoch-step: 44-446 -- Loss: 0.15344306826591492
train-epoch-step: 44-447 -- Loss: 0.19462169706821442
train-epoch-step: 44-448 -- Loss: 0.22209839522838593
train-epoch-step: 44-449 -- Loss: 0.18702581524848938
train-epoch-step: 44-450 -- Loss: 0.18242119252681732
train-epoch-step: 44-451 -- Loss: 0.14145782589912415
train-epoch-step: 44-452 -- Loss: 0.1275959014892578
train-epoch-step: 44-453 -- Loss: 0.0893591046333313
train-epoch-step: 44-454 -- Loss: 0.23259775340557098
train-epoch-step: 44-455 -- Loss: 0.12115990370512009
train-epoch-step: 44-456 -- Loss: 0.11553128808736801
train-epoch-step: 44-457 -- Loss: 0.2119467705488205
train-epoch-step: 44-458 -- Loss: 0.14555931091308594
train-epoch-step: 44-459 -- Loss: 0.2114787995815277
train-epoch-step: 44-460 -- Loss: 0.12402566522359848
train-epoch-step: 44-461 -- Loss: 0.1302715688943863
train-epoch-step: 44-462 -- Loss: 0.15281754732131958
train-epoch-step: 44-463 -- Loss: 0.13149650394916534
train-epoch-step: 44-464 -- Loss: 0.1630209982395172
train-epoch-step: 44-465 -- Loss: 0.23713061213493347
train-epoch-step: 44-466 -- Loss: 0.2053048312664032
train-epoch-step: 44-467 -- Loss: 0.11148732155561447
train-epoch-step: 44-468 -- Loss: 0.16371330618858337
train-epoch-step: 44-469 -- Loss: 0.20617501437664032
train-epoch-step: 44-470 -- Loss: 0.16823704540729523
train-epoch-step: 44-471 -- Loss: 0.15726260840892792
train-epoch-step: 44-472 -- Loss: 0.1541026085615158
train-epoch-step: 44-473 -- Loss: 0.1492646038532257
train-epoch-step: 44-474 -- Loss: 0.11851447075605392
train-epoch-step: 44-475 -- Loss: 0.10718317329883575
train-epoch-step: 44-476 -- Loss: 0.1956976056098938
train-epoch-step: 44-477 -- Loss: 0.19307971000671387
train-epoch-step: 44-478 -- Loss: 0.19216462969779968
train-epoch-step: 44-479 -- Loss: 0.13922327756881714
train-epoch-step: 44-480 -- Loss: 0.1903214156627655
train-epoch-step: 44-481 -- Loss: 0.2755610942840576
train-epoch-step: 44-482 -- Loss: 0.2426605373620987
train-epoch-step: 44-483 -- Loss: 0.17462506890296936
train-epoch-step: 44-484 -- Loss: 0.20739971101284027
train-epoch-step: 44-485 -- Loss: 0.12395334988832474
train-epoch-step: 44-486 -- Loss: 0.2257082164287567
train-epoch-step: 44-487 -- Loss: 0.23113104701042175
train-epoch-step: 44-488 -- Loss: 0.21494874358177185
train-epoch-step: 44-489 -- Loss: 0.21430785953998566
train-epoch-step: 44-490 -- Loss: 0.1388799250125885
train-epoch-step: 44-491 -- Loss: 0.14446300268173218
train-epoch-step: 44-492 -- Loss: 0.12719988822937012
train-epoch-step: 44-493 -- Loss: 0.19458235800266266
train-epoch-step: 44-494 -- Loss: 0.20524515211582184
train-epoch-step: 44-495 -- Loss: 0.19530585408210754
train-epoch-step: 44-496 -- Loss: 0.13883067667484283
train-epoch-step: 44-497 -- Loss: 0.18189308047294617
train-epoch-step: 44-498 -- Loss: 0.1452954262495041
train-epoch-step: 44-499 -- Loss: 0.16568225622177124
train-epoch-step: 44-500 -- Loss: 0.1533709466457367
train-epoch-step: 44-501 -- Loss: 0.2133374810218811
train-epoch-step: 44-502 -- Loss: 0.15380144119262695
train-epoch-step: 44-503 -- Loss: 0.21543912589550018
train-epoch-step: 44-504 -- Loss: 0.1166745200753212
train-epoch-step: 44-505 -- Loss: 0.16840754449367523
train-epoch-step: 44-506 -- Loss: 0.11452368646860123
train-epoch-step: 44-507 -- Loss: 0.1744595170021057
train-epoch-step: 44-508 -- Loss: 0.1695072203874588
train-epoch-step: 44-509 -- Loss: 0.16535508632659912
train-epoch-step: 44-510 -- Loss: 0.1251470297574997
train-epoch-step: 44-511 -- Loss: 0.21766135096549988
train-epoch-step: 44-512 -- Loss: 0.17427751421928406
train-epoch-step: 44-513 -- Loss: 0.17980995774269104
train-epoch-step: 44-514 -- Loss: 0.1424073874950409
train-epoch-step: 44-515 -- Loss: 0.15111681818962097
train-epoch-step: 44-516 -- Loss: 0.16979114711284637
train-epoch-step: 44-517 -- Loss: 0.17217589914798737
train-epoch-step: 44-518 -- Loss: 0.13575607538223267
train-epoch-step: 44-519 -- Loss: 0.13182492554187775
train-epoch-step: 44-520 -- Loss: 0.18003901839256287
train-epoch-step: 44-521 -- Loss: 0.22554737329483032
train-epoch-step: 44-522 -- Loss: 0.17662902176380157
train-epoch-step: 44-523 -- Loss: 0.15284736454486847
train-epoch-step: 44-524 -- Loss: 0.16218149662017822
train-epoch-step: 44-525 -- Loss: 0.18757842481136322
train-epoch-step: 44-526 -- Loss: 0.1261969804763794
train-epoch-step: 44-527 -- Loss: 0.14935223758220673
train-epoch-step: 44-528 -- Loss: 0.15574072301387787
train-epoch-step: 44-529 -- Loss: 0.1510915756225586
train-epoch-step: 44-530 -- Loss: 0.16715961694717407
train-epoch-step: 44-531 -- Loss: 0.1918218433856964
train-epoch-step: 44-532 -- Loss: 0.1647399216890335
train-epoch-step: 44-533 -- Loss: 0.17176973819732666
train-epoch-step: 44-534 -- Loss: 0.1256464272737503
train-epoch-step: 44-535 -- Loss: 0.24279989302158356
train-epoch-step: 44-536 -- Loss: 0.15169034898281097
train-epoch-step: 44-537 -- Loss: 0.14488378167152405
train-epoch-step: 44-538 -- Loss: 0.10207441449165344
train-epoch-step: 44-539 -- Loss: 0.17672716081142426
train-epoch-step: 44-540 -- Loss: 0.13119997084140778
train-epoch-step: 44-541 -- Loss: 0.20025599002838135
train-epoch-step: 44-542 -- Loss: 0.21766558289527893
train-epoch-step: 44-543 -- Loss: 0.1691027730703354
train-epoch-step: 44-544 -- Loss: 0.21733418107032776
train-epoch-step: 44-545 -- Loss: 0.18874230980873108
train-epoch-step: 44-546 -- Loss: 0.20851722359657288
train-epoch-step: 44-547 -- Loss: 0.1829814612865448
train-epoch-step: 44-548 -- Loss: 0.09029598534107208
train-epoch-step: 44-549 -- Loss: 0.14503300189971924
train-epoch-step: 44-550 -- Loss: 0.1926174759864807
train-epoch-step: 44-551 -- Loss: 0.15576279163360596
train-epoch-step: 44-552 -- Loss: 0.12308471649885178
train-epoch-step: 44-553 -- Loss: 0.18744677305221558
train-epoch-step: 44-554 -- Loss: 0.18079251050949097
train-epoch-step: 44-555 -- Loss: 0.21537169814109802
train-epoch-step: 44-556 -- Loss: 0.14951804280281067
train-epoch-step: 44-557 -- Loss: 0.23575317859649658
train-epoch-step: 44-558 -- Loss: 0.22154532372951508
train-epoch-step: 44-559 -- Loss: 0.13765282928943634
train-epoch-step: 44-560 -- Loss: 0.19978909194469452
train-epoch-step: 44-561 -- Loss: 0.17463979125022888
train-epoch-step: 44-562 -- Loss: 0.16194380819797516
train-epoch-step: 44-563 -- Loss: 0.18603113293647766
train-epoch-step: 44-564 -- Loss: 0.09851384162902832
train-epoch-step: 44-565 -- Loss: 0.17808477580547333
train-epoch-step: 44-566 -- Loss: 0.1450524628162384
train-epoch-step: 44-567 -- Loss: 0.20688794553279877
train-epoch-step: 44-568 -- Loss: 0.16066265106201172
train-epoch-step: 44-569 -- Loss: 0.23693327605724335
train-epoch-step: 44-570 -- Loss: 0.15990711748600006
train-epoch-step: 44-571 -- Loss: 0.20893633365631104
train-epoch-step: 44-572 -- Loss: 0.2308385968208313
train-epoch-step: 44-573 -- Loss: 0.19587185978889465
train-epoch-step: 44-574 -- Loss: 0.23783409595489502
train-epoch-step: 44-575 -- Loss: 0.2866578698158264
train-epoch-step: 44-576 -- Loss: 0.11479929089546204
train-epoch-step: 44-577 -- Loss: 0.17753979563713074
train-epoch-step: 44-578 -- Loss: 0.21373312175273895
train-epoch-step: 44-579 -- Loss: 0.16113710403442383
train-epoch-step: 44-580 -- Loss: 0.17073066532611847
train-epoch-step: 44-581 -- Loss: 0.1353166550397873
train-epoch-step: 44-582 -- Loss: 0.201468363404274
train-epoch-step: 44-583 -- Loss: 0.20660413801670074
train-epoch-step: 44-584 -- Loss: 0.15845157206058502
train-epoch-step: 44-585 -- Loss: 0.19021938741207123
train-epoch-step: 44-586 -- Loss: 0.25406765937805176
train-epoch-step: 44-587 -- Loss: 0.15750652551651
train-epoch-step: 44-588 -- Loss: 0.12217152118682861
val-epoch-step: 44-589 -- Loss: 0.19538602232933044
val-epoch-step: 44-590 -- Loss: 0.15427014231681824
val-epoch-step: 44-591 -- Loss: 0.24566826224327087
val-epoch-step: 44-592 -- Loss: 0.1718367636203766
val-epoch-step: 44-593 -- Loss: 0.14955678582191467
val-epoch-step: 44-594 -- Loss: 0.3555600047111511
val-epoch-step: 44-595 -- Loss: 0.20270642638206482
val-epoch-step: 44-596 -- Loss: 0.18996548652648926
val-epoch-step: 44-597 -- Loss: 0.1721489131450653
val-epoch-step: 44-598 -- Loss: 0.14608168601989746
val-epoch-step: 44-599 -- Loss: 0.18637686967849731
val-epoch-step: 44-600 -- Loss: 0.21455365419387817
val-epoch-step: 44-601 -- Loss: 0.16007989645004272
val-epoch-step: 44-602 -- Loss: 0.13492392003536224
val-epoch-step: 44-603 -- Loss: 0.20467831194400787
val-epoch-step: 44-604 -- Loss: 0.1444663405418396
val-epoch-step: 44-605 -- Loss: 0.1478429138660431
val-epoch-step: 44-606 -- Loss: 0.26246148347854614
val-epoch-step: 44-607 -- Loss: 0.12216128408908844
val-epoch-step: 44-608 -- Loss: 0.24946054816246033
val-epoch-step: 44-609 -- Loss: 0.16208942234516144
val-epoch-step: 44-610 -- Loss: 0.17610913515090942
val-epoch-step: 44-611 -- Loss: 0.17370706796646118
val-epoch-step: 44-612 -- Loss: 0.390687495470047
val-epoch-step: 44-613 -- Loss: 0.17265494167804718
val-epoch-step: 44-614 -- Loss: 0.17608334124088287
val-epoch-step: 44-615 -- Loss: 0.171773761510849
val-epoch-step: 44-616 -- Loss: 0.14345642924308777
val-epoch-step: 44-617 -- Loss: 0.18299168348312378
val-epoch-step: 44-618 -- Loss: 0.1797465980052948
val-epoch-step: 44-619 -- Loss: 0.2252468317747116
val-epoch-step: 44-620 -- Loss: 0.13550212979316711
val-epoch-step: 44-621 -- Loss: 0.12298163026571274
val-epoch-step: 44-622 -- Loss: 0.13950930535793304
val-epoch-step: 44-623 -- Loss: 0.149918794631958
val-epoch-step: 44-624 -- Loss: 0.15151596069335938
val-epoch-step: 44-625 -- Loss: 0.15599553287029266
val-epoch-step: 44-626 -- Loss: 0.14319247007369995
val-epoch-step: 44-627 -- Loss: 0.17905206978321075
val-epoch-step: 44-628 -- Loss: 0.6091353893280029
val-epoch-step: 44-629 -- Loss: 0.19000332057476044
val-epoch-step: 44-630 -- Loss: 0.33349525928497314
val-epoch-step: 44-631 -- Loss: 0.13988012075424194
val-epoch-step: 44-632 -- Loss: 0.21454985439777374
val-epoch-step: 44-633 -- Loss: 0.15049846470355988
val-epoch-step: 44-634 -- Loss: 0.15722064673900604
val-epoch-step: 44-635 -- Loss: 0.11311854422092438
val-epoch-step: 44-636 -- Loss: 0.1601659208536148
val-epoch-step: 44-637 -- Loss: 0.18466594815254211
val-epoch-step: 44-638 -- Loss: 0.1574396789073944
val-epoch-step: 44-639 -- Loss: 0.25293755531311035
val-epoch-step: 44-640 -- Loss: 0.2525242269039154
val-epoch-step: 44-641 -- Loss: 0.1265493929386139
val-epoch-step: 44-642 -- Loss: 0.18357670307159424
val-epoch-step: 44-643 -- Loss: 0.20717626810073853
val-epoch-step: 44-644 -- Loss: 0.16662001609802246
val-epoch-step: 44-645 -- Loss: 0.21824336051940918
val-epoch-step: 44-646 -- Loss: 0.12983635067939758
val-epoch-step: 44-647 -- Loss: 0.12882483005523682
val-epoch-step: 44-648 -- Loss: 0.15207189321517944
val-epoch-step: 44-649 -- Loss: 0.21376819908618927
val-epoch-step: 44-650 -- Loss: 0.24893690645694733
val-epoch-step: 44-651 -- Loss: 0.14228938519954681
val-epoch-step: 44-652 -- Loss: 0.15168142318725586
val-epoch-step: 44-653 -- Loss: 0.21785414218902588
val-epoch-step: 44-654 -- Loss: 0.11401715129613876
Epoch: 44 -- Train Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 45-0 -- Loss: 0.22367781400680542
train-epoch-step: 45-1 -- Loss: 0.14078979194164276
train-epoch-step: 45-2 -- Loss: 0.1980476677417755
train-epoch-step: 45-3 -- Loss: 0.1386193335056305
train-epoch-step: 45-4 -- Loss: 0.15232469141483307
train-epoch-step: 45-5 -- Loss: 0.17747826874256134
train-epoch-step: 45-6 -- Loss: 0.21351651847362518
train-epoch-step: 45-7 -- Loss: 0.16397856175899506
train-epoch-step: 45-8 -- Loss: 0.17669716477394104
train-epoch-step: 45-9 -- Loss: 0.22139693796634674
train-epoch-step: 45-10 -- Loss: 0.18959388136863708
train-epoch-step: 45-11 -- Loss: 0.17566370964050293
train-epoch-step: 45-12 -- Loss: 0.14924827218055725
train-epoch-step: 45-13 -- Loss: 0.17678870260715485
train-epoch-step: 45-14 -- Loss: 0.16109012067317963
train-epoch-step: 45-15 -- Loss: 0.15660692751407623
train-epoch-step: 45-16 -- Loss: 0.16086530685424805
train-epoch-step: 45-17 -- Loss: 0.21916109323501587
train-epoch-step: 45-18 -- Loss: 0.18497569859027863
train-epoch-step: 45-19 -- Loss: 0.12959058582782745
train-epoch-step: 45-20 -- Loss: 0.21120613813400269
train-epoch-step: 45-21 -- Loss: 0.24478717148303986
train-epoch-step: 45-22 -- Loss: 0.13628439605236053
train-epoch-step: 45-23 -- Loss: 0.1412830948829651
train-epoch-step: 45-24 -- Loss: 0.12496410310268402
train-epoch-step: 45-25 -- Loss: 0.22223737835884094
train-epoch-step: 45-26 -- Loss: 0.19182434678077698
train-epoch-step: 45-27 -- Loss: 0.22986820340156555
train-epoch-step: 45-28 -- Loss: 0.12549340724945068
train-epoch-step: 45-29 -- Loss: 0.23769575357437134
train-epoch-step: 45-30 -- Loss: 0.10585828125476837
train-epoch-step: 45-31 -- Loss: 0.13567528128623962
train-epoch-step: 45-32 -- Loss: 0.1699088215827942
train-epoch-step: 45-33 -- Loss: 0.2693788409233093
train-epoch-step: 45-34 -- Loss: 0.16253753006458282
train-epoch-step: 45-35 -- Loss: 0.24089346826076508
train-epoch-step: 45-36 -- Loss: 0.13635866343975067
train-epoch-step: 45-37 -- Loss: 0.13527996838092804
train-epoch-step: 45-38 -- Loss: 0.17253559827804565
train-epoch-step: 45-39 -- Loss: 0.21410736441612244
train-epoch-step: 45-40 -- Loss: 0.18890997767448425
train-epoch-step: 45-41 -- Loss: 0.21136677265167236
train-epoch-step: 45-42 -- Loss: 0.14376558363437653
train-epoch-step: 45-43 -- Loss: 0.2589039206504822
train-epoch-step: 45-44 -- Loss: 0.12222971767187119
train-epoch-step: 45-45 -- Loss: 0.11229977011680603
train-epoch-step: 45-46 -- Loss: 0.16210134327411652
train-epoch-step: 45-47 -- Loss: 0.20059698820114136
train-epoch-step: 45-48 -- Loss: 0.15341123938560486
train-epoch-step: 45-49 -- Loss: 0.22082780301570892
train-epoch-step: 45-50 -- Loss: 0.10872454941272736
train-epoch-step: 45-51 -- Loss: 0.1697777509689331
train-epoch-step: 45-52 -- Loss: 0.15635055303573608
train-epoch-step: 45-53 -- Loss: 0.20187686383724213
train-epoch-step: 45-54 -- Loss: 0.2769795358181
train-epoch-step: 45-55 -- Loss: 0.17320877313613892
train-epoch-step: 45-56 -- Loss: 0.1714293658733368
train-epoch-step: 45-57 -- Loss: 0.22759634256362915
train-epoch-step: 45-58 -- Loss: 0.27324455976486206
train-epoch-step: 45-59 -- Loss: 0.22691209614276886
train-epoch-step: 45-60 -- Loss: 0.13699033856391907
train-epoch-step: 45-61 -- Loss: 0.19957464933395386
train-epoch-step: 45-62 -- Loss: 0.17859064042568207
train-epoch-step: 45-63 -- Loss: 0.1304417997598648
train-epoch-step: 45-64 -- Loss: 0.14367765188217163
train-epoch-step: 45-65 -- Loss: 0.17662739753723145
train-epoch-step: 45-66 -- Loss: 0.10858795046806335
train-epoch-step: 45-67 -- Loss: 0.12673074007034302
train-epoch-step: 45-68 -- Loss: 0.2094341665506363
train-epoch-step: 45-69 -- Loss: 0.11786606162786484
train-epoch-step: 45-70 -- Loss: 0.2161218822002411
train-epoch-step: 45-71 -- Loss: 0.2523607611656189
train-epoch-step: 45-72 -- Loss: 0.17072021961212158
train-epoch-step: 45-73 -- Loss: 0.20419633388519287
train-epoch-step: 45-74 -- Loss: 0.0934215784072876
train-epoch-step: 45-75 -- Loss: 0.13798508048057556
train-epoch-step: 45-76 -- Loss: 0.1424686759710312
train-epoch-step: 45-77 -- Loss: 0.22379669547080994
train-epoch-step: 45-78 -- Loss: 0.2471650093793869
train-epoch-step: 45-79 -- Loss: 0.18729935586452484
train-epoch-step: 45-80 -- Loss: 0.23563379049301147
train-epoch-step: 45-81 -- Loss: 0.12295469641685486
train-epoch-step: 45-82 -- Loss: 0.24733811616897583
train-epoch-step: 45-83 -- Loss: 0.1740441620349884
train-epoch-step: 45-84 -- Loss: 0.18671372532844543
train-epoch-step: 45-85 -- Loss: 0.17068162560462952
train-epoch-step: 45-86 -- Loss: 0.11997200548648834
train-epoch-step: 45-87 -- Loss: 0.2125026285648346
train-epoch-step: 45-88 -- Loss: 0.13566721975803375
train-epoch-step: 45-89 -- Loss: 0.18269875645637512
train-epoch-step: 45-90 -- Loss: 0.18701580166816711
train-epoch-step: 45-91 -- Loss: 0.23502501845359802
train-epoch-step: 45-92 -- Loss: 0.15283264219760895
train-epoch-step: 45-93 -- Loss: 0.1688528209924698
train-epoch-step: 45-94 -- Loss: 0.21180593967437744
train-epoch-step: 45-95 -- Loss: 0.18637606501579285
train-epoch-step: 45-96 -- Loss: 0.21139806509017944
train-epoch-step: 45-97 -- Loss: 0.17429661750793457
train-epoch-step: 45-98 -- Loss: 0.15132610499858856
train-epoch-step: 45-99 -- Loss: 0.1817248910665512
train-epoch-step: 45-100 -- Loss: 0.18636541068553925
train-epoch-step: 45-101 -- Loss: 0.2629457414150238
train-epoch-step: 45-102 -- Loss: 0.21870052814483643
train-epoch-step: 45-103 -- Loss: 0.18089108169078827
train-epoch-step: 45-104 -- Loss: 0.1435183435678482
train-epoch-step: 45-105 -- Loss: 0.2600869834423065
train-epoch-step: 45-106 -- Loss: 0.1777952015399933
train-epoch-step: 45-107 -- Loss: 0.18452098965644836
train-epoch-step: 45-108 -- Loss: 0.18448913097381592
train-epoch-step: 45-109 -- Loss: 0.1466745138168335
train-epoch-step: 45-110 -- Loss: 0.1784551739692688
train-epoch-step: 45-111 -- Loss: 0.18014837801456451
train-epoch-step: 45-112 -- Loss: 0.16281501948833466
train-epoch-step: 45-113 -- Loss: 0.15921403467655182
train-epoch-step: 45-114 -- Loss: 0.19931912422180176
train-epoch-step: 45-115 -- Loss: 0.1588183343410492
train-epoch-step: 45-116 -- Loss: 0.13483783602714539
train-epoch-step: 45-117 -- Loss: 0.12603551149368286
train-epoch-step: 45-118 -- Loss: 0.19046247005462646
train-epoch-step: 45-119 -- Loss: 0.14993888139724731
train-epoch-step: 45-120 -- Loss: 0.24188588559627533
train-epoch-step: 45-121 -- Loss: 0.24441196024417877
train-epoch-step: 45-122 -- Loss: 0.22447936236858368
train-epoch-step: 45-123 -- Loss: 0.20337937772274017
train-epoch-step: 45-124 -- Loss: 0.1196618601679802
train-epoch-step: 45-125 -- Loss: 0.15091222524642944
train-epoch-step: 45-126 -- Loss: 0.2235872745513916
train-epoch-step: 45-127 -- Loss: 0.17185242474079132
train-epoch-step: 45-128 -- Loss: 0.1689176857471466
train-epoch-step: 45-129 -- Loss: 0.1444350630044937
train-epoch-step: 45-130 -- Loss: 0.19036032259464264
train-epoch-step: 45-131 -- Loss: 0.13732506334781647
train-epoch-step: 45-132 -- Loss: 0.1838352382183075
train-epoch-step: 45-133 -- Loss: 0.11328334361314774
train-epoch-step: 45-134 -- Loss: 0.19387488067150116
train-epoch-step: 45-135 -- Loss: 0.1317804455757141
train-epoch-step: 45-136 -- Loss: 0.12512342631816864
train-epoch-step: 45-137 -- Loss: 0.25328055024147034
train-epoch-step: 45-138 -- Loss: 0.2567577362060547
train-epoch-step: 45-139 -- Loss: 0.12802846729755402
train-epoch-step: 45-140 -- Loss: 0.20590242743492126
train-epoch-step: 45-141 -- Loss: 0.23025229573249817
train-epoch-step: 45-142 -- Loss: 0.20117656886577606
train-epoch-step: 45-143 -- Loss: 0.1763659417629242
train-epoch-step: 45-144 -- Loss: 0.18366797268390656
train-epoch-step: 45-145 -- Loss: 0.1379760205745697
train-epoch-step: 45-146 -- Loss: 0.17998185753822327
train-epoch-step: 45-147 -- Loss: 0.17454864084720612
train-epoch-step: 45-148 -- Loss: 0.15272782742977142
train-epoch-step: 45-149 -- Loss: 0.12515336275100708
train-epoch-step: 45-150 -- Loss: 0.1815069019794464
train-epoch-step: 45-151 -- Loss: 0.18257980048656464
train-epoch-step: 45-152 -- Loss: 0.18534094095230103
train-epoch-step: 45-153 -- Loss: 0.263821005821228
train-epoch-step: 45-154 -- Loss: 0.13104960322380066
train-epoch-step: 45-155 -- Loss: 0.16339850425720215
train-epoch-step: 45-156 -- Loss: 0.11614556610584259
train-epoch-step: 45-157 -- Loss: 0.16799533367156982
train-epoch-step: 45-158 -- Loss: 0.16277004778385162
train-epoch-step: 45-159 -- Loss: 0.17397987842559814
train-epoch-step: 45-160 -- Loss: 0.20897671580314636
train-epoch-step: 45-161 -- Loss: 0.2031533122062683
train-epoch-step: 45-162 -- Loss: 0.21238815784454346
train-epoch-step: 45-163 -- Loss: 0.18865106999874115
train-epoch-step: 45-164 -- Loss: 0.19092446565628052
train-epoch-step: 45-165 -- Loss: 0.16262108087539673
train-epoch-step: 45-166 -- Loss: 0.12560562789440155
train-epoch-step: 45-167 -- Loss: 0.12850378453731537
train-epoch-step: 45-168 -- Loss: 0.2005605697631836
train-epoch-step: 45-169 -- Loss: 0.14112915098667145
train-epoch-step: 45-170 -- Loss: 0.19790267944335938
train-epoch-step: 45-171 -- Loss: 0.1436028629541397
train-epoch-step: 45-172 -- Loss: 0.2587321400642395
train-epoch-step: 45-173 -- Loss: 0.13295994699001312
train-epoch-step: 45-174 -- Loss: 0.2504729628562927
train-epoch-step: 45-175 -- Loss: 0.1793285310268402
train-epoch-step: 45-176 -- Loss: 0.1324772983789444
train-epoch-step: 45-177 -- Loss: 0.17551106214523315
train-epoch-step: 45-178 -- Loss: 0.1759919822216034
train-epoch-step: 45-179 -- Loss: 0.14778152108192444
train-epoch-step: 45-180 -- Loss: 0.1540171355009079
train-epoch-step: 45-181 -- Loss: 0.17641055583953857
train-epoch-step: 45-182 -- Loss: 0.18232300877571106
train-epoch-step: 45-183 -- Loss: 0.26265472173690796
train-epoch-step: 45-184 -- Loss: 0.13695557415485382
train-epoch-step: 45-185 -- Loss: 0.14862236380577087
train-epoch-step: 45-186 -- Loss: 0.1809154599905014
train-epoch-step: 45-187 -- Loss: 0.2141566276550293
train-epoch-step: 45-188 -- Loss: 0.17441760003566742
train-epoch-step: 45-189 -- Loss: 0.104598768055439
train-epoch-step: 45-190 -- Loss: 0.1799747347831726
train-epoch-step: 45-191 -- Loss: 0.1623784899711609
train-epoch-step: 45-192 -- Loss: 0.24567782878875732
train-epoch-step: 45-193 -- Loss: 0.21156296133995056
train-epoch-step: 45-194 -- Loss: 0.18321283161640167
train-epoch-step: 45-195 -- Loss: 0.16290675103664398
train-epoch-step: 45-196 -- Loss: 0.16687393188476562
train-epoch-step: 45-197 -- Loss: 0.12506845593452454
train-epoch-step: 45-198 -- Loss: 0.12966042757034302
train-epoch-step: 45-199 -- Loss: 0.15091872215270996
train-epoch-step: 45-200 -- Loss: 0.12520746886730194
train-epoch-step: 45-201 -- Loss: 0.1861937940120697
train-epoch-step: 45-202 -- Loss: 0.13443385064601898
train-epoch-step: 45-203 -- Loss: 0.17612873017787933
train-epoch-step: 45-204 -- Loss: 0.14148679375648499
train-epoch-step: 45-205 -- Loss: 0.21160158514976501
train-epoch-step: 45-206 -- Loss: 0.19541698694229126
train-epoch-step: 45-207 -- Loss: 0.13273228704929352
train-epoch-step: 45-208 -- Loss: 0.17536519467830658
train-epoch-step: 45-209 -- Loss: 0.13783422112464905
train-epoch-step: 45-210 -- Loss: 0.13979095220565796
train-epoch-step: 45-211 -- Loss: 0.21470928192138672
train-epoch-step: 45-212 -- Loss: 0.1957479864358902
train-epoch-step: 45-213 -- Loss: 0.12682044506072998
train-epoch-step: 45-214 -- Loss: 0.1459360122680664
train-epoch-step: 45-215 -- Loss: 0.1284865289926529
train-epoch-step: 45-216 -- Loss: 0.19338947534561157
train-epoch-step: 45-217 -- Loss: 0.20867061614990234
train-epoch-step: 45-218 -- Loss: 0.14299844205379486
train-epoch-step: 45-219 -- Loss: 0.16939981281757355
train-epoch-step: 45-220 -- Loss: 0.12758785486221313
train-epoch-step: 45-221 -- Loss: 0.20372970402240753
train-epoch-step: 45-222 -- Loss: 0.11540026217699051
train-epoch-step: 45-223 -- Loss: 0.17558860778808594
train-epoch-step: 45-224 -- Loss: 0.18782711029052734
train-epoch-step: 45-225 -- Loss: 0.2632451355457306
train-epoch-step: 45-226 -- Loss: 0.20488490164279938
train-epoch-step: 45-227 -- Loss: 0.21860209107398987
train-epoch-step: 45-228 -- Loss: 0.17481818795204163
train-epoch-step: 45-229 -- Loss: 0.17314034700393677
train-epoch-step: 45-230 -- Loss: 0.16464172303676605
train-epoch-step: 45-231 -- Loss: 0.1539440155029297
train-epoch-step: 45-232 -- Loss: 0.18408438563346863
train-epoch-step: 45-233 -- Loss: 0.08223608881235123
train-epoch-step: 45-234 -- Loss: 0.17148716747760773
train-epoch-step: 45-235 -- Loss: 0.14425435662269592
train-epoch-step: 45-236 -- Loss: 0.180283322930336
train-epoch-step: 45-237 -- Loss: 0.23228970170021057
train-epoch-step: 45-238 -- Loss: 0.1543467491865158
train-epoch-step: 45-239 -- Loss: 0.12433533370494843
train-epoch-step: 45-240 -- Loss: 0.2198154181241989
train-epoch-step: 45-241 -- Loss: 0.14864873886108398
train-epoch-step: 45-242 -- Loss: 0.21575099229812622
train-epoch-step: 45-243 -- Loss: 0.2346150279045105
train-epoch-step: 45-244 -- Loss: 0.2033470869064331
train-epoch-step: 45-245 -- Loss: 0.20319341123104095
train-epoch-step: 45-246 -- Loss: 0.21696822345256805
train-epoch-step: 45-247 -- Loss: 0.20248334109783173
train-epoch-step: 45-248 -- Loss: 0.18299353122711182
train-epoch-step: 45-249 -- Loss: 0.13668543100357056
train-epoch-step: 45-250 -- Loss: 0.1982952207326889
train-epoch-step: 45-251 -- Loss: 0.10547705739736557
train-epoch-step: 45-252 -- Loss: 0.19982501864433289
train-epoch-step: 45-253 -- Loss: 0.13386493921279907
train-epoch-step: 45-254 -- Loss: 0.20471258461475372
train-epoch-step: 45-255 -- Loss: 0.14412949979305267
train-epoch-step: 45-256 -- Loss: 0.1502028852701187
train-epoch-step: 45-257 -- Loss: 0.18635177612304688
train-epoch-step: 45-258 -- Loss: 0.14705181121826172
train-epoch-step: 45-259 -- Loss: 0.11284173280000687
train-epoch-step: 45-260 -- Loss: 0.19751602411270142
train-epoch-step: 45-261 -- Loss: 0.1690787672996521
train-epoch-step: 45-262 -- Loss: 0.2929413914680481
train-epoch-step: 45-263 -- Loss: 0.19881635904312134
train-epoch-step: 45-264 -- Loss: 0.1709139049053192
train-epoch-step: 45-265 -- Loss: 0.10622268170118332
train-epoch-step: 45-266 -- Loss: 0.15227200090885162
train-epoch-step: 45-267 -- Loss: 0.12539774179458618
train-epoch-step: 45-268 -- Loss: 0.11667811125516891
train-epoch-step: 45-269 -- Loss: 0.16882430016994476
train-epoch-step: 45-270 -- Loss: 0.10655802488327026
train-epoch-step: 45-271 -- Loss: 0.14779230952262878
train-epoch-step: 45-272 -- Loss: 0.11501088738441467
train-epoch-step: 45-273 -- Loss: 0.1249682605266571
train-epoch-step: 45-274 -- Loss: 0.18657326698303223
train-epoch-step: 45-275 -- Loss: 0.1921384036540985
train-epoch-step: 45-276 -- Loss: 0.15598195791244507
train-epoch-step: 45-277 -- Loss: 0.15585412085056305
train-epoch-step: 45-278 -- Loss: 0.13551601767539978
train-epoch-step: 45-279 -- Loss: 0.14187917113304138
train-epoch-step: 45-280 -- Loss: 0.2212364375591278
train-epoch-step: 45-281 -- Loss: 0.17087382078170776
train-epoch-step: 45-282 -- Loss: 0.14058184623718262
train-epoch-step: 45-283 -- Loss: 0.11412177979946136
train-epoch-step: 45-284 -- Loss: 0.12907740473747253
train-epoch-step: 45-285 -- Loss: 0.18796853721141815
train-epoch-step: 45-286 -- Loss: 0.15246625244617462
train-epoch-step: 45-287 -- Loss: 0.2016957402229309
train-epoch-step: 45-288 -- Loss: 0.09213743358850479
train-epoch-step: 45-289 -- Loss: 0.11832478642463684
train-epoch-step: 45-290 -- Loss: 0.17852075397968292
train-epoch-step: 45-291 -- Loss: 0.11557825654745102
train-epoch-step: 45-292 -- Loss: 0.1532980054616928
train-epoch-step: 45-293 -- Loss: 0.13664279878139496
train-epoch-step: 45-294 -- Loss: 0.15719075500965118
train-epoch-step: 45-295 -- Loss: 0.2630205750465393
train-epoch-step: 45-296 -- Loss: 0.15381914377212524
train-epoch-step: 45-297 -- Loss: 0.17268308997154236
train-epoch-step: 45-298 -- Loss: 0.22901342809200287
train-epoch-step: 45-299 -- Loss: 0.14249402284622192
train-epoch-step: 45-300 -- Loss: 0.16103190183639526
train-epoch-step: 45-301 -- Loss: 0.17879557609558105
train-epoch-step: 45-302 -- Loss: 0.21802666783332825
train-epoch-step: 45-303 -- Loss: 0.2049723118543625
train-epoch-step: 45-304 -- Loss: 0.12394000589847565
train-epoch-step: 45-305 -- Loss: 0.1457146555185318
train-epoch-step: 45-306 -- Loss: 0.21216093003749847
train-epoch-step: 45-307 -- Loss: 0.16281534731388092
train-epoch-step: 45-308 -- Loss: 0.21542951464653015
train-epoch-step: 45-309 -- Loss: 0.15579545497894287
train-epoch-step: 45-310 -- Loss: 0.16130366921424866
train-epoch-step: 45-311 -- Loss: 0.15606479346752167
train-epoch-step: 45-312 -- Loss: 0.2023017257452011
train-epoch-step: 45-313 -- Loss: 0.09626410156488419
train-epoch-step: 45-314 -- Loss: 0.18963274359703064
train-epoch-step: 45-315 -- Loss: 0.16671526432037354
train-epoch-step: 45-316 -- Loss: 0.15033113956451416
train-epoch-step: 45-317 -- Loss: 0.13711270689964294
train-epoch-step: 45-318 -- Loss: 0.17084096372127533
train-epoch-step: 45-319 -- Loss: 0.1675538420677185
train-epoch-step: 45-320 -- Loss: 0.12011174857616425
train-epoch-step: 45-321 -- Loss: 0.1327383667230606
train-epoch-step: 45-322 -- Loss: 0.21632838249206543
train-epoch-step: 45-323 -- Loss: 0.15454046428203583
train-epoch-step: 45-324 -- Loss: 0.25293204188346863
train-epoch-step: 45-325 -- Loss: 0.15268564224243164
train-epoch-step: 45-326 -- Loss: 0.1838667094707489
train-epoch-step: 45-327 -- Loss: 0.2024880200624466
train-epoch-step: 45-328 -- Loss: 0.19569066166877747
train-epoch-step: 45-329 -- Loss: 0.3434339761734009
train-epoch-step: 45-330 -- Loss: 0.35963115096092224
train-epoch-step: 45-331 -- Loss: 0.20609797537326813
train-epoch-step: 45-332 -- Loss: 0.10046696662902832
train-epoch-step: 45-333 -- Loss: 0.19862106442451477
train-epoch-step: 45-334 -- Loss: 0.1576746255159378
train-epoch-step: 45-335 -- Loss: 0.17089128494262695
train-epoch-step: 45-336 -- Loss: 0.14874017238616943
train-epoch-step: 45-337 -- Loss: 0.2025899589061737
train-epoch-step: 45-338 -- Loss: 0.1606229543685913
train-epoch-step: 45-339 -- Loss: 0.14860159158706665
train-epoch-step: 45-340 -- Loss: 0.19427341222763062
train-epoch-step: 45-341 -- Loss: 0.13948442041873932
train-epoch-step: 45-342 -- Loss: 0.1603395938873291
train-epoch-step: 45-343 -- Loss: 0.14944787323474884
train-epoch-step: 45-344 -- Loss: 0.16626796126365662
train-epoch-step: 45-345 -- Loss: 0.12729158997535706
train-epoch-step: 45-346 -- Loss: 0.2060830295085907
train-epoch-step: 45-347 -- Loss: 0.1512906551361084
train-epoch-step: 45-348 -- Loss: 0.19882042706012726
train-epoch-step: 45-349 -- Loss: 0.19974155724048615
train-epoch-step: 45-350 -- Loss: 0.2533521056175232
train-epoch-step: 45-351 -- Loss: 0.19725294411182404
train-epoch-step: 45-352 -- Loss: 0.12031536549329758
train-epoch-step: 45-353 -- Loss: 0.19011253118515015
train-epoch-step: 45-354 -- Loss: 0.2800794839859009
train-epoch-step: 45-355 -- Loss: 0.11739489436149597
train-epoch-step: 45-356 -- Loss: 0.11680819094181061
train-epoch-step: 45-357 -- Loss: 0.1872139275074005
train-epoch-step: 45-358 -- Loss: 0.18501633405685425
train-epoch-step: 45-359 -- Loss: 0.13556642830371857
train-epoch-step: 45-360 -- Loss: 0.12136096507310867
train-epoch-step: 45-361 -- Loss: 0.23567822575569153
train-epoch-step: 45-362 -- Loss: 0.1648278683423996
train-epoch-step: 45-363 -- Loss: 0.10857371985912323
train-epoch-step: 45-364 -- Loss: 0.17815005779266357
train-epoch-step: 45-365 -- Loss: 0.16804389655590057
train-epoch-step: 45-366 -- Loss: 0.2026260793209076
train-epoch-step: 45-367 -- Loss: 0.23182961344718933
train-epoch-step: 45-368 -- Loss: 0.19720490276813507
train-epoch-step: 45-369 -- Loss: 0.27327173948287964
train-epoch-step: 45-370 -- Loss: 0.1250939518213272
train-epoch-step: 45-371 -- Loss: 0.12013286352157593
train-epoch-step: 45-372 -- Loss: 0.1455686241388321
train-epoch-step: 45-373 -- Loss: 0.18626442551612854
train-epoch-step: 45-374 -- Loss: 0.1499945968389511
train-epoch-step: 45-375 -- Loss: 0.2682254910469055
train-epoch-step: 45-376 -- Loss: 0.1524689793586731
train-epoch-step: 45-377 -- Loss: 0.22326821088790894
train-epoch-step: 45-378 -- Loss: 0.19610735774040222
train-epoch-step: 45-379 -- Loss: 0.11944068223237991
train-epoch-step: 45-380 -- Loss: 0.08983557671308517
train-epoch-step: 45-381 -- Loss: 0.24016235768795013
train-epoch-step: 45-382 -- Loss: 0.22659064829349518
train-epoch-step: 45-383 -- Loss: 0.17670324444770813
train-epoch-step: 45-384 -- Loss: 0.2079160064458847
train-epoch-step: 45-385 -- Loss: 0.1878926157951355
train-epoch-step: 45-386 -- Loss: 0.1839960217475891
train-epoch-step: 45-387 -- Loss: 0.1960078626871109
train-epoch-step: 45-388 -- Loss: 0.17976891994476318
train-epoch-step: 45-389 -- Loss: 0.16469049453735352
train-epoch-step: 45-390 -- Loss: 0.14390689134597778
train-epoch-step: 45-391 -- Loss: 0.15045924484729767
train-epoch-step: 45-392 -- Loss: 0.1805220991373062
train-epoch-step: 45-393 -- Loss: 0.15099146962165833
train-epoch-step: 45-394 -- Loss: 0.19714224338531494
train-epoch-step: 45-395 -- Loss: 0.15466222167015076
train-epoch-step: 45-396 -- Loss: 0.12435740977525711
train-epoch-step: 45-397 -- Loss: 0.12351007759571075
train-epoch-step: 45-398 -- Loss: 0.19188956916332245
train-epoch-step: 45-399 -- Loss: 0.1779801845550537
train-epoch-step: 45-400 -- Loss: 0.26876020431518555
train-epoch-step: 45-401 -- Loss: 0.11548671871423721
train-epoch-step: 45-402 -- Loss: 0.25033965706825256
train-epoch-step: 45-403 -- Loss: 0.15121829509735107
train-epoch-step: 45-404 -- Loss: 0.13528631627559662
train-epoch-step: 45-405 -- Loss: 0.13810089230537415
train-epoch-step: 45-406 -- Loss: 0.16412538290023804
train-epoch-step: 45-407 -- Loss: 0.11187265068292618
train-epoch-step: 45-408 -- Loss: 0.15836086869239807
train-epoch-step: 45-409 -- Loss: 0.18514437973499298
train-epoch-step: 45-410 -- Loss: 0.1724676489830017
train-epoch-step: 45-411 -- Loss: 0.19296522438526154
train-epoch-step: 45-412 -- Loss: 0.12881557643413544
train-epoch-step: 45-413 -- Loss: 0.14492389559745789
train-epoch-step: 45-414 -- Loss: 0.1328529268503189
train-epoch-step: 45-415 -- Loss: 0.13577501475811005
train-epoch-step: 45-416 -- Loss: 0.2584284543991089
train-epoch-step: 45-417 -- Loss: 0.1891126185655594
train-epoch-step: 45-418 -- Loss: 0.23286578059196472
train-epoch-step: 45-419 -- Loss: 0.16548551619052887
train-epoch-step: 45-420 -- Loss: 0.14864546060562134
train-epoch-step: 45-421 -- Loss: 0.17461074888706207
train-epoch-step: 45-422 -- Loss: 0.14517544209957123
train-epoch-step: 45-423 -- Loss: 0.17341311275959015
train-epoch-step: 45-424 -- Loss: 0.13565267622470856
train-epoch-step: 45-425 -- Loss: 0.18153664469718933
train-epoch-step: 45-426 -- Loss: 0.16164718568325043
train-epoch-step: 45-427 -- Loss: 0.13125470280647278
train-epoch-step: 45-428 -- Loss: 0.19026458263397217
train-epoch-step: 45-429 -- Loss: 0.1724756509065628
train-epoch-step: 45-430 -- Loss: 0.13636095821857452
train-epoch-step: 45-431 -- Loss: 0.16232220828533173
train-epoch-step: 45-432 -- Loss: 0.23638859391212463
train-epoch-step: 45-433 -- Loss: 0.1348251849412918
train-epoch-step: 45-434 -- Loss: 0.12759263813495636
train-epoch-step: 45-435 -- Loss: 0.14868173003196716
train-epoch-step: 45-436 -- Loss: 0.1555059403181076
train-epoch-step: 45-437 -- Loss: 0.129106342792511
train-epoch-step: 45-438 -- Loss: 0.16869686543941498
train-epoch-step: 45-439 -- Loss: 0.2636197805404663
train-epoch-step: 45-440 -- Loss: 0.1290455162525177
train-epoch-step: 45-441 -- Loss: 0.1968049257993698
train-epoch-step: 45-442 -- Loss: 0.1739768385887146
train-epoch-step: 45-443 -- Loss: 0.152369886636734
train-epoch-step: 45-444 -- Loss: 0.1744079291820526
train-epoch-step: 45-445 -- Loss: 0.17797493934631348
train-epoch-step: 45-446 -- Loss: 0.14693672955036163
train-epoch-step: 45-447 -- Loss: 0.19065730273723602
train-epoch-step: 45-448 -- Loss: 0.2227964699268341
train-epoch-step: 45-449 -- Loss: 0.18725281953811646
train-epoch-step: 45-450 -- Loss: 0.18037831783294678
train-epoch-step: 45-451 -- Loss: 0.14061836898326874
train-epoch-step: 45-452 -- Loss: 0.12798543274402618
train-epoch-step: 45-453 -- Loss: 0.08933991938829422
train-epoch-step: 45-454 -- Loss: 0.2270953357219696
train-epoch-step: 45-455 -- Loss: 0.11893875151872635
train-epoch-step: 45-456 -- Loss: 0.11662719398736954
train-epoch-step: 45-457 -- Loss: 0.2105846405029297
train-epoch-step: 45-458 -- Loss: 0.14089003205299377
train-epoch-step: 45-459 -- Loss: 0.21217456459999084
train-epoch-step: 45-460 -- Loss: 0.1251789629459381
train-epoch-step: 45-461 -- Loss: 0.1334807276725769
train-epoch-step: 45-462 -- Loss: 0.14946714043617249
train-epoch-step: 45-463 -- Loss: 0.13389979302883148
train-epoch-step: 45-464 -- Loss: 0.16191817820072174
train-epoch-step: 45-465 -- Loss: 0.23186691105365753
train-epoch-step: 45-466 -- Loss: 0.20061835646629333
train-epoch-step: 45-467 -- Loss: 0.11014503240585327
train-epoch-step: 45-468 -- Loss: 0.16510431468486786
train-epoch-step: 45-469 -- Loss: 0.20597253739833832
train-epoch-step: 45-470 -- Loss: 0.1716141700744629
train-epoch-step: 45-471 -- Loss: 0.15724687278270721
train-epoch-step: 45-472 -- Loss: 0.15680575370788574
train-epoch-step: 45-473 -- Loss: 0.15113598108291626
train-epoch-step: 45-474 -- Loss: 0.11531006544828415
train-epoch-step: 45-475 -- Loss: 0.10810428857803345
train-epoch-step: 45-476 -- Loss: 0.19725342094898224
train-epoch-step: 45-477 -- Loss: 0.19822879135608673
train-epoch-step: 45-478 -- Loss: 0.19236992299556732
train-epoch-step: 45-479 -- Loss: 0.14157021045684814
train-epoch-step: 45-480 -- Loss: 0.18989068269729614
train-epoch-step: 45-481 -- Loss: 0.2804444134235382
train-epoch-step: 45-482 -- Loss: 0.2472139298915863
train-epoch-step: 45-483 -- Loss: 0.1845678836107254
train-epoch-step: 45-484 -- Loss: 0.20862573385238647
train-epoch-step: 45-485 -- Loss: 0.12923647463321686
train-epoch-step: 45-486 -- Loss: 0.22961995005607605
train-epoch-step: 45-487 -- Loss: 0.22361953556537628
train-epoch-step: 45-488 -- Loss: 0.18623512983322144
train-epoch-step: 45-489 -- Loss: 0.2165304720401764
train-epoch-step: 45-490 -- Loss: 0.1339978575706482
train-epoch-step: 45-491 -- Loss: 0.13472367823123932
train-epoch-step: 45-492 -- Loss: 0.12330034375190735
train-epoch-step: 45-493 -- Loss: 0.20024797320365906
train-epoch-step: 45-494 -- Loss: 0.20098035037517548
train-epoch-step: 45-495 -- Loss: 0.19874051213264465
train-epoch-step: 45-496 -- Loss: 0.13712581992149353
train-epoch-step: 45-497 -- Loss: 0.18020620942115784
train-epoch-step: 45-498 -- Loss: 0.14457233250141144
train-epoch-step: 45-499 -- Loss: 0.16201898455619812
train-epoch-step: 45-500 -- Loss: 0.15333591401576996
train-epoch-step: 45-501 -- Loss: 0.2115987092256546
train-epoch-step: 45-502 -- Loss: 0.15496699512004852
train-epoch-step: 45-503 -- Loss: 0.21652650833129883
train-epoch-step: 45-504 -- Loss: 0.11729602515697479
train-epoch-step: 45-505 -- Loss: 0.16516831517219543
train-epoch-step: 45-506 -- Loss: 0.11401177942752838
train-epoch-step: 45-507 -- Loss: 0.18880698084831238
train-epoch-step: 45-508 -- Loss: 0.16952654719352722
train-epoch-step: 45-509 -- Loss: 0.1674342155456543
train-epoch-step: 45-510 -- Loss: 0.1272382289171219
train-epoch-step: 45-511 -- Loss: 0.20995277166366577
train-epoch-step: 45-512 -- Loss: 0.17495201528072357
train-epoch-step: 45-513 -- Loss: 0.1846136897802353
train-epoch-step: 45-514 -- Loss: 0.14425504207611084
train-epoch-step: 45-515 -- Loss: 0.1517636924982071
train-epoch-step: 45-516 -- Loss: 0.16637085378170013
train-epoch-step: 45-517 -- Loss: 0.1722281128168106
train-epoch-step: 45-518 -- Loss: 0.13519026339054108
train-epoch-step: 45-519 -- Loss: 0.13300232589244843
train-epoch-step: 45-520 -- Loss: 0.18089403212070465
train-epoch-step: 45-521 -- Loss: 0.22373494505882263
train-epoch-step: 45-522 -- Loss: 0.18601369857788086
train-epoch-step: 45-523 -- Loss: 0.1515568494796753
train-epoch-step: 45-524 -- Loss: 0.1627570241689682
train-epoch-step: 45-525 -- Loss: 0.1858070194721222
train-epoch-step: 45-526 -- Loss: 0.12493406236171722
train-epoch-step: 45-527 -- Loss: 0.14586202800273895
train-epoch-step: 45-528 -- Loss: 0.15128189325332642
train-epoch-step: 45-529 -- Loss: 0.15843696892261505
train-epoch-step: 45-530 -- Loss: 0.1663924753665924
train-epoch-step: 45-531 -- Loss: 0.19587638974189758
train-epoch-step: 45-532 -- Loss: 0.16625531017780304
train-epoch-step: 45-533 -- Loss: 0.170821413397789
train-epoch-step: 45-534 -- Loss: 0.12704935669898987
train-epoch-step: 45-535 -- Loss: 0.24501606822013855
train-epoch-step: 45-536 -- Loss: 0.15056759119033813
train-epoch-step: 45-537 -- Loss: 0.1474631130695343
train-epoch-step: 45-538 -- Loss: 0.09917237609624863
train-epoch-step: 45-539 -- Loss: 0.17538270354270935
train-epoch-step: 45-540 -- Loss: 0.13829971849918365
train-epoch-step: 45-541 -- Loss: 0.20417824387550354
train-epoch-step: 45-542 -- Loss: 0.219619020819664
train-epoch-step: 45-543 -- Loss: 0.16766083240509033
train-epoch-step: 45-544 -- Loss: 0.22237667441368103
train-epoch-step: 45-545 -- Loss: 0.18865393102169037
train-epoch-step: 45-546 -- Loss: 0.20854546129703522
train-epoch-step: 45-547 -- Loss: 0.17461399734020233
train-epoch-step: 45-548 -- Loss: 0.09239683300256729
train-epoch-step: 45-549 -- Loss: 0.14899854362010956
train-epoch-step: 45-550 -- Loss: 0.19824419915676117
train-epoch-step: 45-551 -- Loss: 0.15069103240966797
train-epoch-step: 45-552 -- Loss: 0.12011763453483582
train-epoch-step: 45-553 -- Loss: 0.18626892566680908
train-epoch-step: 45-554 -- Loss: 0.18031877279281616
train-epoch-step: 45-555 -- Loss: 0.21014051139354706
train-epoch-step: 45-556 -- Loss: 0.14258204400539398
train-epoch-step: 45-557 -- Loss: 0.23260679841041565
train-epoch-step: 45-558 -- Loss: 0.22555236518383026
train-epoch-step: 45-559 -- Loss: 0.13270322978496552
train-epoch-step: 45-560 -- Loss: 0.1993316411972046
train-epoch-step: 45-561 -- Loss: 0.17578883469104767
train-epoch-step: 45-562 -- Loss: 0.16052867472171783
train-epoch-step: 45-563 -- Loss: 0.18460232019424438
train-epoch-step: 45-564 -- Loss: 0.09880093485116959
train-epoch-step: 45-565 -- Loss: 0.17760035395622253
train-epoch-step: 45-566 -- Loss: 0.1482383906841278
train-epoch-step: 45-567 -- Loss: 0.2053920030593872
train-epoch-step: 45-568 -- Loss: 0.1586214154958725
train-epoch-step: 45-569 -- Loss: 0.2385430932044983
train-epoch-step: 45-570 -- Loss: 0.16072876751422882
train-epoch-step: 45-571 -- Loss: 0.20874108374118805
train-epoch-step: 45-572 -- Loss: 0.22851623594760895
train-epoch-step: 45-573 -- Loss: 0.1982484757900238
train-epoch-step: 45-574 -- Loss: 0.2376580387353897
train-epoch-step: 45-575 -- Loss: 0.3015935719013214
train-epoch-step: 45-576 -- Loss: 0.11722004413604736
train-epoch-step: 45-577 -- Loss: 0.15877053141593933
train-epoch-step: 45-578 -- Loss: 0.21056705713272095
train-epoch-step: 45-579 -- Loss: 0.17705084383487701
train-epoch-step: 45-580 -- Loss: 0.1739741861820221
train-epoch-step: 45-581 -- Loss: 0.1347355842590332
train-epoch-step: 45-582 -- Loss: 0.20979177951812744
train-epoch-step: 45-583 -- Loss: 0.21301569044589996
train-epoch-step: 45-584 -- Loss: 0.16197603940963745
train-epoch-step: 45-585 -- Loss: 0.19028037786483765
train-epoch-step: 45-586 -- Loss: 0.246722012758255
train-epoch-step: 45-587 -- Loss: 0.15528015792369843
train-epoch-step: 45-588 -- Loss: 0.12542828917503357
val-epoch-step: 45-589 -- Loss: 0.21549180150032043
val-epoch-step: 45-590 -- Loss: 0.15703323483467102
val-epoch-step: 45-591 -- Loss: 0.22853678464889526
val-epoch-step: 45-592 -- Loss: 0.17212554812431335
val-epoch-step: 45-593 -- Loss: 0.1588921844959259
val-epoch-step: 45-594 -- Loss: 0.37594735622406006
val-epoch-step: 45-595 -- Loss: 0.194227397441864
val-epoch-step: 45-596 -- Loss: 0.1936500370502472
val-epoch-step: 45-597 -- Loss: 0.17630207538604736
val-epoch-step: 45-598 -- Loss: 0.14663460850715637
val-epoch-step: 45-599 -- Loss: 0.1837051510810852
val-epoch-step: 45-600 -- Loss: 0.16279330849647522
val-epoch-step: 45-601 -- Loss: 0.15445923805236816
val-epoch-step: 45-602 -- Loss: 0.13336527347564697
val-epoch-step: 45-603 -- Loss: 0.20387867093086243
val-epoch-step: 45-604 -- Loss: 0.143843412399292
val-epoch-step: 45-605 -- Loss: 0.1484820395708084
val-epoch-step: 45-606 -- Loss: 0.29206863045692444
val-epoch-step: 45-607 -- Loss: 0.12590916454792023
val-epoch-step: 45-608 -- Loss: 0.24595694243907928
val-epoch-step: 45-609 -- Loss: 0.16228117048740387
val-epoch-step: 45-610 -- Loss: 0.17767386138439178
val-epoch-step: 45-611 -- Loss: 0.15900199115276337
val-epoch-step: 45-612 -- Loss: 0.3724759817123413
val-epoch-step: 45-613 -- Loss: 0.18540334701538086
val-epoch-step: 45-614 -- Loss: 0.17355072498321533
val-epoch-step: 45-615 -- Loss: 0.1737871915102005
val-epoch-step: 45-616 -- Loss: 0.1435374766588211
val-epoch-step: 45-617 -- Loss: 0.1873222440481186
val-epoch-step: 45-618 -- Loss: 0.17903131246566772
val-epoch-step: 45-619 -- Loss: 0.21481798589229584
val-epoch-step: 45-620 -- Loss: 0.13253435492515564
val-epoch-step: 45-621 -- Loss: 0.12584421038627625
val-epoch-step: 45-622 -- Loss: 0.14207515120506287
val-epoch-step: 45-623 -- Loss: 0.15375784039497375
val-epoch-step: 45-624 -- Loss: 0.14251703023910522
val-epoch-step: 45-625 -- Loss: 0.15510937571525574
val-epoch-step: 45-626 -- Loss: 0.14715948700904846
val-epoch-step: 45-627 -- Loss: 0.19063353538513184
val-epoch-step: 45-628 -- Loss: 0.5957468748092651
val-epoch-step: 45-629 -- Loss: 0.18212030827999115
val-epoch-step: 45-630 -- Loss: 0.3384856581687927
val-epoch-step: 45-631 -- Loss: 0.1477726250886917
val-epoch-step: 45-632 -- Loss: 0.19987305998802185
val-epoch-step: 45-633 -- Loss: 0.1499546617269516
val-epoch-step: 45-634 -- Loss: 0.15860515832901
val-epoch-step: 45-635 -- Loss: 0.11606922000646591
val-epoch-step: 45-636 -- Loss: 0.16525845229625702
val-epoch-step: 45-637 -- Loss: 0.1852502077817917
val-epoch-step: 45-638 -- Loss: 0.1453164517879486
val-epoch-step: 45-639 -- Loss: 0.2581455707550049
val-epoch-step: 45-640 -- Loss: 0.25126832723617554
val-epoch-step: 45-641 -- Loss: 0.12582166492938995
val-epoch-step: 45-642 -- Loss: 0.1747889518737793
val-epoch-step: 45-643 -- Loss: 0.20072047412395477
val-epoch-step: 45-644 -- Loss: 0.16283616423606873
val-epoch-step: 45-645 -- Loss: 0.21993319690227509
val-epoch-step: 45-646 -- Loss: 0.1357067972421646
val-epoch-step: 45-647 -- Loss: 0.12753066420555115
val-epoch-step: 45-648 -- Loss: 0.15394052863121033
val-epoch-step: 45-649 -- Loss: 0.2043372392654419
val-epoch-step: 45-650 -- Loss: 0.24948319792747498
val-epoch-step: 45-651 -- Loss: 0.1471177339553833
val-epoch-step: 45-652 -- Loss: 0.1537642925977707
val-epoch-step: 45-653 -- Loss: 0.1965092122554779
val-epoch-step: 45-654 -- Loss: 0.11252381652593613
Epoch: 45 -- Train Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 46-0 -- Loss: 0.22112491726875305
train-epoch-step: 46-1 -- Loss: 0.14267396926879883
train-epoch-step: 46-2 -- Loss: 0.19951480627059937
train-epoch-step: 46-3 -- Loss: 0.1462489664554596
train-epoch-step: 46-4 -- Loss: 0.16100336611270905
train-epoch-step: 46-5 -- Loss: 0.17385558784008026
train-epoch-step: 46-6 -- Loss: 0.20668049156665802
train-epoch-step: 46-7 -- Loss: 0.16277238726615906
train-epoch-step: 46-8 -- Loss: 0.17679396271705627
train-epoch-step: 46-9 -- Loss: 0.21867279708385468
train-epoch-step: 46-10 -- Loss: 0.2023838758468628
train-epoch-step: 46-11 -- Loss: 0.1800786554813385
train-epoch-step: 46-12 -- Loss: 0.14871931076049805
train-epoch-step: 46-13 -- Loss: 0.172760471701622
train-epoch-step: 46-14 -- Loss: 0.16216260194778442
train-epoch-step: 46-15 -- Loss: 0.1607368439435959
train-epoch-step: 46-16 -- Loss: 0.1613762527704239
train-epoch-step: 46-17 -- Loss: 0.21358007192611694
train-epoch-step: 46-18 -- Loss: 0.19575849175453186
train-epoch-step: 46-19 -- Loss: 0.12962444126605988
train-epoch-step: 46-20 -- Loss: 0.21166637539863586
train-epoch-step: 46-21 -- Loss: 0.24542351067066193
train-epoch-step: 46-22 -- Loss: 0.13397648930549622
train-epoch-step: 46-23 -- Loss: 0.1397537738084793
train-epoch-step: 46-24 -- Loss: 0.12556689977645874
train-epoch-step: 46-25 -- Loss: 0.2296421229839325
train-epoch-step: 46-26 -- Loss: 0.20385882258415222
train-epoch-step: 46-27 -- Loss: 0.23553982377052307
train-epoch-step: 46-28 -- Loss: 0.12143149971961975
train-epoch-step: 46-29 -- Loss: 0.23956720530986786
train-epoch-step: 46-30 -- Loss: 0.10737437754869461
train-epoch-step: 46-31 -- Loss: 0.13414426147937775
train-epoch-step: 46-32 -- Loss: 0.17061248421669006
train-epoch-step: 46-33 -- Loss: 0.2724129855632782
train-epoch-step: 46-34 -- Loss: 0.17069494724273682
train-epoch-step: 46-35 -- Loss: 0.23900268971920013
train-epoch-step: 46-36 -- Loss: 0.13413676619529724
train-epoch-step: 46-37 -- Loss: 0.1367267519235611
train-epoch-step: 46-38 -- Loss: 0.17638838291168213
train-epoch-step: 46-39 -- Loss: 0.21681928634643555
train-epoch-step: 46-40 -- Loss: 0.18991604447364807
train-epoch-step: 46-41 -- Loss: 0.21128058433532715
train-epoch-step: 46-42 -- Loss: 0.1431131809949875
train-epoch-step: 46-43 -- Loss: 0.2569397985935211
train-epoch-step: 46-44 -- Loss: 0.12350419163703918
train-epoch-step: 46-45 -- Loss: 0.11627931892871857
train-epoch-step: 46-46 -- Loss: 0.16691216826438904
train-epoch-step: 46-47 -- Loss: 0.19781099259853363
train-epoch-step: 46-48 -- Loss: 0.15195217728614807
train-epoch-step: 46-49 -- Loss: 0.21876952052116394
train-epoch-step: 46-50 -- Loss: 0.11116781830787659
train-epoch-step: 46-51 -- Loss: 0.17661356925964355
train-epoch-step: 46-52 -- Loss: 0.15488675236701965
train-epoch-step: 46-53 -- Loss: 0.203504741191864
train-epoch-step: 46-54 -- Loss: 0.2766587734222412
train-epoch-step: 46-55 -- Loss: 0.16579127311706543
train-epoch-step: 46-56 -- Loss: 0.17217382788658142
train-epoch-step: 46-57 -- Loss: 0.2326367199420929
train-epoch-step: 46-58 -- Loss: 0.284066379070282
train-epoch-step: 46-59 -- Loss: 0.2274765968322754
train-epoch-step: 46-60 -- Loss: 0.12825053930282593
train-epoch-step: 46-61 -- Loss: 0.19691479206085205
train-epoch-step: 46-62 -- Loss: 0.181551992893219
train-epoch-step: 46-63 -- Loss: 0.13317064940929413
train-epoch-step: 46-64 -- Loss: 0.14118362963199615
train-epoch-step: 46-65 -- Loss: 0.1746198534965515
train-epoch-step: 46-66 -- Loss: 0.10543942451477051
train-epoch-step: 46-67 -- Loss: 0.1268826425075531
train-epoch-step: 46-68 -- Loss: 0.2071431428194046
train-epoch-step: 46-69 -- Loss: 0.11977570503950119
train-epoch-step: 46-70 -- Loss: 0.2211610972881317
train-epoch-step: 46-71 -- Loss: 0.25506791472435
train-epoch-step: 46-72 -- Loss: 0.16897320747375488
train-epoch-step: 46-73 -- Loss: 0.20283380150794983
train-epoch-step: 46-74 -- Loss: 0.0946727842092514
train-epoch-step: 46-75 -- Loss: 0.12310678511857986
train-epoch-step: 46-76 -- Loss: 0.1453298032283783
train-epoch-step: 46-77 -- Loss: 0.2258685976266861
train-epoch-step: 46-78 -- Loss: 0.26043272018432617
train-epoch-step: 46-79 -- Loss: 0.18477904796600342
train-epoch-step: 46-80 -- Loss: 0.24819952249526978
train-epoch-step: 46-81 -- Loss: 0.12266723811626434
train-epoch-step: 46-82 -- Loss: 0.24429598450660706
train-epoch-step: 46-83 -- Loss: 0.17180265486240387
train-epoch-step: 46-84 -- Loss: 0.1900348961353302
train-epoch-step: 46-85 -- Loss: 0.16992661356925964
train-epoch-step: 46-86 -- Loss: 0.1171027347445488
train-epoch-step: 46-87 -- Loss: 0.21216543018817902
train-epoch-step: 46-88 -- Loss: 0.13488204777240753
train-epoch-step: 46-89 -- Loss: 0.18542960286140442
train-epoch-step: 46-90 -- Loss: 0.18767403066158295
train-epoch-step: 46-91 -- Loss: 0.2459716796875
train-epoch-step: 46-92 -- Loss: 0.15377867221832275
train-epoch-step: 46-93 -- Loss: 0.17201223969459534
train-epoch-step: 46-94 -- Loss: 0.20920421183109283
train-epoch-step: 46-95 -- Loss: 0.185857892036438
train-epoch-step: 46-96 -- Loss: 0.21220484375953674
train-epoch-step: 46-97 -- Loss: 0.17248034477233887
train-epoch-step: 46-98 -- Loss: 0.15535587072372437
train-epoch-step: 46-99 -- Loss: 0.1783681958913803
train-epoch-step: 46-100 -- Loss: 0.18920084834098816
train-epoch-step: 46-101 -- Loss: 0.2582235336303711
train-epoch-step: 46-102 -- Loss: 0.2137211561203003
train-epoch-step: 46-103 -- Loss: 0.1800910085439682
train-epoch-step: 46-104 -- Loss: 0.15036079287528992
train-epoch-step: 46-105 -- Loss: 0.26364943385124207
train-epoch-step: 46-106 -- Loss: 0.17228692770004272
train-epoch-step: 46-107 -- Loss: 0.1835789680480957
train-epoch-step: 46-108 -- Loss: 0.19130750000476837
train-epoch-step: 46-109 -- Loss: 0.14666014909744263
train-epoch-step: 46-110 -- Loss: 0.18095041811466217
train-epoch-step: 46-111 -- Loss: 0.1790153682231903
train-epoch-step: 46-112 -- Loss: 0.15797318518161774
train-epoch-step: 46-113 -- Loss: 0.15397131443023682
train-epoch-step: 46-114 -- Loss: 0.19190660119056702
train-epoch-step: 46-115 -- Loss: 0.15974768996238708
train-epoch-step: 46-116 -- Loss: 0.1353474259376526
train-epoch-step: 46-117 -- Loss: 0.1253422349691391
train-epoch-step: 46-118 -- Loss: 0.18604470789432526
train-epoch-step: 46-119 -- Loss: 0.15177588164806366
train-epoch-step: 46-120 -- Loss: 0.24393494427204132
train-epoch-step: 46-121 -- Loss: 0.22599755227565765
train-epoch-step: 46-122 -- Loss: 0.2129185050725937
train-epoch-step: 46-123 -- Loss: 0.2001899778842926
train-epoch-step: 46-124 -- Loss: 0.11927513778209686
train-epoch-step: 46-125 -- Loss: 0.15095025300979614
train-epoch-step: 46-126 -- Loss: 0.22757716476917267
train-epoch-step: 46-127 -- Loss: 0.1637060046195984
train-epoch-step: 46-128 -- Loss: 0.16853183507919312
train-epoch-step: 46-129 -- Loss: 0.14222152531147003
train-epoch-step: 46-130 -- Loss: 0.18855784833431244
train-epoch-step: 46-131 -- Loss: 0.1340174376964569
train-epoch-step: 46-132 -- Loss: 0.18626606464385986
train-epoch-step: 46-133 -- Loss: 0.11360527575016022
train-epoch-step: 46-134 -- Loss: 0.18488392233848572
train-epoch-step: 46-135 -- Loss: 0.13325020670890808
train-epoch-step: 46-136 -- Loss: 0.12798437476158142
train-epoch-step: 46-137 -- Loss: 0.2516348958015442
train-epoch-step: 46-138 -- Loss: 0.25395023822784424
train-epoch-step: 46-139 -- Loss: 0.136836975812912
train-epoch-step: 46-140 -- Loss: 0.19839787483215332
train-epoch-step: 46-141 -- Loss: 0.2267684042453766
train-epoch-step: 46-142 -- Loss: 0.20299594104290009
train-epoch-step: 46-143 -- Loss: 0.1682300567626953
train-epoch-step: 46-144 -- Loss: 0.19810613989830017
train-epoch-step: 46-145 -- Loss: 0.13885252177715302
train-epoch-step: 46-146 -- Loss: 0.1769024282693863
train-epoch-step: 46-147 -- Loss: 0.1678720861673355
train-epoch-step: 46-148 -- Loss: 0.16151143610477448
train-epoch-step: 46-149 -- Loss: 0.11957015097141266
train-epoch-step: 46-150 -- Loss: 0.18437036871910095
train-epoch-step: 46-151 -- Loss: 0.18955601751804352
train-epoch-step: 46-152 -- Loss: 0.18582835793495178
train-epoch-step: 46-153 -- Loss: 0.2636469602584839
train-epoch-step: 46-154 -- Loss: 0.12834259867668152
train-epoch-step: 46-155 -- Loss: 0.13220064342021942
train-epoch-step: 46-156 -- Loss: 0.11453403532505035
train-epoch-step: 46-157 -- Loss: 0.16434496641159058
train-epoch-step: 46-158 -- Loss: 0.16493621468544006
train-epoch-step: 46-159 -- Loss: 0.1710416078567505
train-epoch-step: 46-160 -- Loss: 0.2077505886554718
train-epoch-step: 46-161 -- Loss: 0.20199719071388245
train-epoch-step: 46-162 -- Loss: 0.20742501318454742
train-epoch-step: 46-163 -- Loss: 0.1844395101070404
train-epoch-step: 46-164 -- Loss: 0.18944677710533142
train-epoch-step: 46-165 -- Loss: 0.1637057065963745
train-epoch-step: 46-166 -- Loss: 0.12008273601531982
train-epoch-step: 46-167 -- Loss: 0.11951656639575958
train-epoch-step: 46-168 -- Loss: 0.19769524037837982
train-epoch-step: 46-169 -- Loss: 0.13512952625751495
train-epoch-step: 46-170 -- Loss: 0.19426347315311432
train-epoch-step: 46-171 -- Loss: 0.1402323991060257
train-epoch-step: 46-172 -- Loss: 0.25375258922576904
train-epoch-step: 46-173 -- Loss: 0.12742477655410767
train-epoch-step: 46-174 -- Loss: 0.24456164240837097
train-epoch-step: 46-175 -- Loss: 0.18448211252689362
train-epoch-step: 46-176 -- Loss: 0.1281750202178955
train-epoch-step: 46-177 -- Loss: 0.1742551624774933
train-epoch-step: 46-178 -- Loss: 0.1743817776441574
train-epoch-step: 46-179 -- Loss: 0.15813776850700378
train-epoch-step: 46-180 -- Loss: 0.14778226613998413
train-epoch-step: 46-181 -- Loss: 0.17223098874092102
train-epoch-step: 46-182 -- Loss: 0.17677365243434906
train-epoch-step: 46-183 -- Loss: 0.26955342292785645
train-epoch-step: 46-184 -- Loss: 0.13512355089187622
train-epoch-step: 46-185 -- Loss: 0.13845966756343842
train-epoch-step: 46-186 -- Loss: 0.19059769809246063
train-epoch-step: 46-187 -- Loss: 0.20355121791362762
train-epoch-step: 46-188 -- Loss: 0.18675503134727478
train-epoch-step: 46-189 -- Loss: 0.10692676901817322
train-epoch-step: 46-190 -- Loss: 0.18239983916282654
train-epoch-step: 46-191 -- Loss: 0.1567378044128418
train-epoch-step: 46-192 -- Loss: 0.22457173466682434
train-epoch-step: 46-193 -- Loss: 0.19942471385002136
train-epoch-step: 46-194 -- Loss: 0.17836152017116547
train-epoch-step: 46-195 -- Loss: 0.16238446533679962
train-epoch-step: 46-196 -- Loss: 0.16246828436851501
train-epoch-step: 46-197 -- Loss: 0.12825843691825867
train-epoch-step: 46-198 -- Loss: 0.13532860577106476
train-epoch-step: 46-199 -- Loss: 0.14408054947853088
train-epoch-step: 46-200 -- Loss: 0.12103301286697388
train-epoch-step: 46-201 -- Loss: 0.18712322413921356
train-epoch-step: 46-202 -- Loss: 0.13233284652233124
train-epoch-step: 46-203 -- Loss: 0.18868258595466614
train-epoch-step: 46-204 -- Loss: 0.1495736539363861
train-epoch-step: 46-205 -- Loss: 0.18965792655944824
train-epoch-step: 46-206 -- Loss: 0.19867941737174988
train-epoch-step: 46-207 -- Loss: 0.13020087778568268
train-epoch-step: 46-208 -- Loss: 0.1841728538274765
train-epoch-step: 46-209 -- Loss: 0.14414682984352112
train-epoch-step: 46-210 -- Loss: 0.13338011503219604
train-epoch-step: 46-211 -- Loss: 0.21134454011917114
train-epoch-step: 46-212 -- Loss: 0.1960257887840271
train-epoch-step: 46-213 -- Loss: 0.14008155465126038
train-epoch-step: 46-214 -- Loss: 0.14522728323936462
train-epoch-step: 46-215 -- Loss: 0.1250823587179184
train-epoch-step: 46-216 -- Loss: 0.19755902886390686
train-epoch-step: 46-217 -- Loss: 0.20789189636707306
train-epoch-step: 46-218 -- Loss: 0.14691762626171112
train-epoch-step: 46-219 -- Loss: 0.16889892518520355
train-epoch-step: 46-220 -- Loss: 0.1278114914894104
train-epoch-step: 46-221 -- Loss: 0.2013693004846573
train-epoch-step: 46-222 -- Loss: 0.12039564549922943
train-epoch-step: 46-223 -- Loss: 0.17194147408008575
train-epoch-step: 46-224 -- Loss: 0.182550311088562
train-epoch-step: 46-225 -- Loss: 0.2628495991230011
train-epoch-step: 46-226 -- Loss: 0.2046002447605133
train-epoch-step: 46-227 -- Loss: 0.2550107538700104
train-epoch-step: 46-228 -- Loss: 0.188211590051651
train-epoch-step: 46-229 -- Loss: 0.16866424679756165
train-epoch-step: 46-230 -- Loss: 0.16302122175693512
train-epoch-step: 46-231 -- Loss: 0.1608986109495163
train-epoch-step: 46-232 -- Loss: 0.18585717678070068
train-epoch-step: 46-233 -- Loss: 0.08425700664520264
train-epoch-step: 46-234 -- Loss: 0.17560338973999023
train-epoch-step: 46-235 -- Loss: 0.14093470573425293
train-epoch-step: 46-236 -- Loss: 0.24548682570457458
train-epoch-step: 46-237 -- Loss: 0.23308923840522766
train-epoch-step: 46-238 -- Loss: 0.15646842122077942
train-epoch-step: 46-239 -- Loss: 0.1255156695842743
train-epoch-step: 46-240 -- Loss: 0.24120348691940308
train-epoch-step: 46-241 -- Loss: 0.15846922993659973
train-epoch-step: 46-242 -- Loss: 0.23187969624996185
train-epoch-step: 46-243 -- Loss: 0.2406603991985321
train-epoch-step: 46-244 -- Loss: 0.20345228910446167
train-epoch-step: 46-245 -- Loss: 0.20931828022003174
train-epoch-step: 46-246 -- Loss: 0.2185947597026825
train-epoch-step: 46-247 -- Loss: 0.22084978222846985
train-epoch-step: 46-248 -- Loss: 0.185557559132576
train-epoch-step: 46-249 -- Loss: 0.13508516550064087
train-epoch-step: 46-250 -- Loss: 0.1974293291568756
train-epoch-step: 46-251 -- Loss: 0.10587974637746811
train-epoch-step: 46-252 -- Loss: 0.21973532438278198
train-epoch-step: 46-253 -- Loss: 0.13568684458732605
train-epoch-step: 46-254 -- Loss: 0.20705677568912506
train-epoch-step: 46-255 -- Loss: 0.1444159895181656
train-epoch-step: 46-256 -- Loss: 0.1449543982744217
train-epoch-step: 46-257 -- Loss: 0.1854337453842163
train-epoch-step: 46-258 -- Loss: 0.14296500384807587
train-epoch-step: 46-259 -- Loss: 0.11201436072587967
train-epoch-step: 46-260 -- Loss: 0.2063904106616974
train-epoch-step: 46-261 -- Loss: 0.17406094074249268
train-epoch-step: 46-262 -- Loss: 0.2966587543487549
train-epoch-step: 46-263 -- Loss: 0.19679667055606842
train-epoch-step: 46-264 -- Loss: 0.17244303226470947
train-epoch-step: 46-265 -- Loss: 0.11058032512664795
train-epoch-step: 46-266 -- Loss: 0.15322144329547882
train-epoch-step: 46-267 -- Loss: 0.1310441642999649
train-epoch-step: 46-268 -- Loss: 0.11587463319301605
train-epoch-step: 46-269 -- Loss: 0.20442995429039001
train-epoch-step: 46-270 -- Loss: 0.10579180717468262
train-epoch-step: 46-271 -- Loss: 0.1480827033519745
train-epoch-step: 46-272 -- Loss: 0.11754943430423737
train-epoch-step: 46-273 -- Loss: 0.12806817889213562
train-epoch-step: 46-274 -- Loss: 0.22672994434833527
train-epoch-step: 46-275 -- Loss: 0.21042166650295258
train-epoch-step: 46-276 -- Loss: 0.18292349576950073
train-epoch-step: 46-277 -- Loss: 0.15823599696159363
train-epoch-step: 46-278 -- Loss: 0.14225482940673828
train-epoch-step: 46-279 -- Loss: 0.14028693735599518
train-epoch-step: 46-280 -- Loss: 0.2316160947084427
train-epoch-step: 46-281 -- Loss: 0.19921502470970154
train-epoch-step: 46-282 -- Loss: 0.14100977778434753
train-epoch-step: 46-283 -- Loss: 0.13005101680755615
train-epoch-step: 46-284 -- Loss: 0.15277352929115295
train-epoch-step: 46-285 -- Loss: 0.19566616415977478
train-epoch-step: 46-286 -- Loss: 0.15249915421009064
train-epoch-step: 46-287 -- Loss: 0.2057531774044037
train-epoch-step: 46-288 -- Loss: 0.09421743452548981
train-epoch-step: 46-289 -- Loss: 0.11860009282827377
train-epoch-step: 46-290 -- Loss: 0.18364031612873077
train-epoch-step: 46-291 -- Loss: 0.11911649256944656
train-epoch-step: 46-292 -- Loss: 0.15585730969905853
train-epoch-step: 46-293 -- Loss: 0.1386181116104126
train-epoch-step: 46-294 -- Loss: 0.15387791395187378
train-epoch-step: 46-295 -- Loss: 0.27475255727767944
train-epoch-step: 46-296 -- Loss: 0.15868543088436127
train-epoch-step: 46-297 -- Loss: 0.17390672862529755
train-epoch-step: 46-298 -- Loss: 0.23544466495513916
train-epoch-step: 46-299 -- Loss: 0.14695309102535248
train-epoch-step: 46-300 -- Loss: 0.1625191867351532
train-epoch-step: 46-301 -- Loss: 0.16610358655452728
train-epoch-step: 46-302 -- Loss: 0.22952209413051605
train-epoch-step: 46-303 -- Loss: 0.20170201361179352
train-epoch-step: 46-304 -- Loss: 0.13026389479637146
train-epoch-step: 46-305 -- Loss: 0.1471572369337082
train-epoch-step: 46-306 -- Loss: 0.22997921705245972
train-epoch-step: 46-307 -- Loss: 0.1695176362991333
train-epoch-step: 46-308 -- Loss: 0.225122332572937
train-epoch-step: 46-309 -- Loss: 0.15494796633720398
train-epoch-step: 46-310 -- Loss: 0.17145508527755737
train-epoch-step: 46-311 -- Loss: 0.1661851853132248
train-epoch-step: 46-312 -- Loss: 0.21221579611301422
train-epoch-step: 46-313 -- Loss: 0.09987528622150421
train-epoch-step: 46-314 -- Loss: 0.18824495375156403
train-epoch-step: 46-315 -- Loss: 0.16743718087673187
train-epoch-step: 46-316 -- Loss: 0.15184569358825684
train-epoch-step: 46-317 -- Loss: 0.14155389368534088
train-epoch-step: 46-318 -- Loss: 0.16113503277301788
train-epoch-step: 46-319 -- Loss: 0.1755402684211731
train-epoch-step: 46-320 -- Loss: 0.11962991952896118
train-epoch-step: 46-321 -- Loss: 0.13073715567588806
train-epoch-step: 46-322 -- Loss: 0.23324328660964966
train-epoch-step: 46-323 -- Loss: 0.1552198976278305
train-epoch-step: 46-324 -- Loss: 0.25711750984191895
train-epoch-step: 46-325 -- Loss: 0.15217730402946472
train-epoch-step: 46-326 -- Loss: 0.17169371247291565
train-epoch-step: 46-327 -- Loss: 0.2048286646604538
train-epoch-step: 46-328 -- Loss: 0.198516383767128
train-epoch-step: 46-329 -- Loss: 0.3345014452934265
train-epoch-step: 46-330 -- Loss: 0.36145690083503723
train-epoch-step: 46-331 -- Loss: 0.2118614912033081
train-epoch-step: 46-332 -- Loss: 0.0976419597864151
train-epoch-step: 46-333 -- Loss: 0.1871456801891327
train-epoch-step: 46-334 -- Loss: 0.15413591265678406
train-epoch-step: 46-335 -- Loss: 0.1766006350517273
train-epoch-step: 46-336 -- Loss: 0.14912474155426025
train-epoch-step: 46-337 -- Loss: 0.20951806008815765
train-epoch-step: 46-338 -- Loss: 0.15678133070468903
train-epoch-step: 46-339 -- Loss: 0.139536514878273
train-epoch-step: 46-340 -- Loss: 0.19624094665050507
train-epoch-step: 46-341 -- Loss: 0.14457206428050995
train-epoch-step: 46-342 -- Loss: 0.1675180345773697
train-epoch-step: 46-343 -- Loss: 0.1496061384677887
train-epoch-step: 46-344 -- Loss: 0.1627507209777832
train-epoch-step: 46-345 -- Loss: 0.1295406073331833
train-epoch-step: 46-346 -- Loss: 0.19639718532562256
train-epoch-step: 46-347 -- Loss: 0.1552884876728058
train-epoch-step: 46-348 -- Loss: 0.20145565271377563
train-epoch-step: 46-349 -- Loss: 0.20546752214431763
train-epoch-step: 46-350 -- Loss: 0.25497910380363464
train-epoch-step: 46-351 -- Loss: 0.19121332466602325
train-epoch-step: 46-352 -- Loss: 0.12569040060043335
train-epoch-step: 46-353 -- Loss: 0.19709359109401703
train-epoch-step: 46-354 -- Loss: 0.2840183973312378
train-epoch-step: 46-355 -- Loss: 0.11583493649959564
train-epoch-step: 46-356 -- Loss: 0.11336284130811691
train-epoch-step: 46-357 -- Loss: 0.20199060440063477
train-epoch-step: 46-358 -- Loss: 0.18483096361160278
train-epoch-step: 46-359 -- Loss: 0.14198680222034454
train-epoch-step: 46-360 -- Loss: 0.12225547432899475
train-epoch-step: 46-361 -- Loss: 0.23360994458198547
train-epoch-step: 46-362 -- Loss: 0.16671164333820343
train-epoch-step: 46-363 -- Loss: 0.12155091762542725
train-epoch-step: 46-364 -- Loss: 0.18147802352905273
train-epoch-step: 46-365 -- Loss: 0.17097251117229462
train-epoch-step: 46-366 -- Loss: 0.20116031169891357
train-epoch-step: 46-367 -- Loss: 0.23133885860443115
train-epoch-step: 46-368 -- Loss: 0.2030593752861023
train-epoch-step: 46-369 -- Loss: 0.2784806191921234
train-epoch-step: 46-370 -- Loss: 0.12375916540622711
train-epoch-step: 46-371 -- Loss: 0.12299185991287231
train-epoch-step: 46-372 -- Loss: 0.1455058604478836
train-epoch-step: 46-373 -- Loss: 0.18805044889450073
train-epoch-step: 46-374 -- Loss: 0.15199123322963715
train-epoch-step: 46-375 -- Loss: 0.26798051595687866
train-epoch-step: 46-376 -- Loss: 0.17446894943714142
train-epoch-step: 46-377 -- Loss: 0.2278643548488617
train-epoch-step: 46-378 -- Loss: 0.20082049071788788
train-epoch-step: 46-379 -- Loss: 0.11745816469192505
train-epoch-step: 46-380 -- Loss: 0.0933556854724884
train-epoch-step: 46-381 -- Loss: 0.23989377915859222
train-epoch-step: 46-382 -- Loss: 0.22905205190181732
train-epoch-step: 46-383 -- Loss: 0.17255349457263947
train-epoch-step: 46-384 -- Loss: 0.22041356563568115
train-epoch-step: 46-385 -- Loss: 0.19234563410282135
train-epoch-step: 46-386 -- Loss: 0.1872609406709671
train-epoch-step: 46-387 -- Loss: 0.1954120397567749
train-epoch-step: 46-388 -- Loss: 0.179761603474617
train-epoch-step: 46-389 -- Loss: 0.16589605808258057
train-epoch-step: 46-390 -- Loss: 0.14650607109069824
train-epoch-step: 46-391 -- Loss: 0.14434517920017242
train-epoch-step: 46-392 -- Loss: 0.18367935717105865
train-epoch-step: 46-393 -- Loss: 0.15181031823158264
train-epoch-step: 46-394 -- Loss: 0.1941390186548233
train-epoch-step: 46-395 -- Loss: 0.1540156900882721
train-epoch-step: 46-396 -- Loss: 0.1240965723991394
train-epoch-step: 46-397 -- Loss: 0.1211499571800232
train-epoch-step: 46-398 -- Loss: 0.1958787441253662
train-epoch-step: 46-399 -- Loss: 0.17811711132526398
train-epoch-step: 46-400 -- Loss: 0.2741636633872986
train-epoch-step: 46-401 -- Loss: 0.1194792091846466
train-epoch-step: 46-402 -- Loss: 0.2582125663757324
train-epoch-step: 46-403 -- Loss: 0.15266872942447662
train-epoch-step: 46-404 -- Loss: 0.13934673368930817
train-epoch-step: 46-405 -- Loss: 0.14089006185531616
train-epoch-step: 46-406 -- Loss: 0.16464641690254211
train-epoch-step: 46-407 -- Loss: 0.11194278299808502
train-epoch-step: 46-408 -- Loss: 0.15862464904785156
train-epoch-step: 46-409 -- Loss: 0.1690978705883026
train-epoch-step: 46-410 -- Loss: 0.17837278544902802
train-epoch-step: 46-411 -- Loss: 0.19689369201660156
train-epoch-step: 46-412 -- Loss: 0.1246880441904068
train-epoch-step: 46-413 -- Loss: 0.14407604932785034
train-epoch-step: 46-414 -- Loss: 0.13272157311439514
train-epoch-step: 46-415 -- Loss: 0.13306574523448944
train-epoch-step: 46-416 -- Loss: 0.26161617040634155
train-epoch-step: 46-417 -- Loss: 0.18749010562896729
train-epoch-step: 46-418 -- Loss: 0.23191693425178528
train-epoch-step: 46-419 -- Loss: 0.164497971534729
train-epoch-step: 46-420 -- Loss: 0.15160682797431946
train-epoch-step: 46-421 -- Loss: 0.17503699660301208
train-epoch-step: 46-422 -- Loss: 0.14774391055107117
train-epoch-step: 46-423 -- Loss: 0.17072539031505585
train-epoch-step: 46-424 -- Loss: 0.13447551429271698
train-epoch-step: 46-425 -- Loss: 0.1804109513759613
train-epoch-step: 46-426 -- Loss: 0.16132575273513794
train-epoch-step: 46-427 -- Loss: 0.11911389231681824
train-epoch-step: 46-428 -- Loss: 0.19288474321365356
train-epoch-step: 46-429 -- Loss: 0.17297975718975067
train-epoch-step: 46-430 -- Loss: 0.13997076451778412
train-epoch-step: 46-431 -- Loss: 0.15996557474136353
train-epoch-step: 46-432 -- Loss: 0.23494373261928558
train-epoch-step: 46-433 -- Loss: 0.13485850393772125
train-epoch-step: 46-434 -- Loss: 0.12665200233459473
train-epoch-step: 46-435 -- Loss: 0.14880473911762238
train-epoch-step: 46-436 -- Loss: 0.1477392613887787
train-epoch-step: 46-437 -- Loss: 0.1284211128950119
train-epoch-step: 46-438 -- Loss: 0.1655168980360031
train-epoch-step: 46-439 -- Loss: 0.2630544900894165
train-epoch-step: 46-440 -- Loss: 0.12897761166095734
train-epoch-step: 46-441 -- Loss: 0.20132893323898315
train-epoch-step: 46-442 -- Loss: 0.17314958572387695
train-epoch-step: 46-443 -- Loss: 0.15524698793888092
train-epoch-step: 46-444 -- Loss: 0.1711258590221405
train-epoch-step: 46-445 -- Loss: 0.17406852543354034
train-epoch-step: 46-446 -- Loss: 0.15155741572380066
train-epoch-step: 46-447 -- Loss: 0.18989624083042145
train-epoch-step: 46-448 -- Loss: 0.22237402200698853
train-epoch-step: 46-449 -- Loss: 0.18735715746879578
train-epoch-step: 46-450 -- Loss: 0.17974115908145905
train-epoch-step: 46-451 -- Loss: 0.13842152059078217
train-epoch-step: 46-452 -- Loss: 0.12760476768016815
train-epoch-step: 46-453 -- Loss: 0.09219160676002502
train-epoch-step: 46-454 -- Loss: 0.2245616912841797
train-epoch-step: 46-455 -- Loss: 0.11866813898086548
train-epoch-step: 46-456 -- Loss: 0.11620239168405533
train-epoch-step: 46-457 -- Loss: 0.20796258747577667
train-epoch-step: 46-458 -- Loss: 0.14359673857688904
train-epoch-step: 46-459 -- Loss: 0.2119562178850174
train-epoch-step: 46-460 -- Loss: 0.12397055327892303
train-epoch-step: 46-461 -- Loss: 0.13272221386432648
train-epoch-step: 46-462 -- Loss: 0.15336038172245026
train-epoch-step: 46-463 -- Loss: 0.1325065791606903
train-epoch-step: 46-464 -- Loss: 0.15990768373012543
train-epoch-step: 46-465 -- Loss: 0.2402733564376831
train-epoch-step: 46-466 -- Loss: 0.1968972235918045
train-epoch-step: 46-467 -- Loss: 0.10906589031219482
train-epoch-step: 46-468 -- Loss: 0.16467592120170593
train-epoch-step: 46-469 -- Loss: 0.21151822805404663
train-epoch-step: 46-470 -- Loss: 0.17023001611232758
train-epoch-step: 46-471 -- Loss: 0.1602610945701599
train-epoch-step: 46-472 -- Loss: 0.1544816792011261
train-epoch-step: 46-473 -- Loss: 0.15001985430717468
train-epoch-step: 46-474 -- Loss: 0.11820133775472641
train-epoch-step: 46-475 -- Loss: 0.10597845911979675
train-epoch-step: 46-476 -- Loss: 0.19177520275115967
train-epoch-step: 46-477 -- Loss: 0.20712068676948547
train-epoch-step: 46-478 -- Loss: 0.18579304218292236
train-epoch-step: 46-479 -- Loss: 0.1350935399532318
train-epoch-step: 46-480 -- Loss: 0.19381679594516754
train-epoch-step: 46-481 -- Loss: 0.2859741747379303
train-epoch-step: 46-482 -- Loss: 0.24908961355686188
train-epoch-step: 46-483 -- Loss: 0.17669203877449036
train-epoch-step: 46-484 -- Loss: 0.20692194998264313
train-epoch-step: 46-485 -- Loss: 0.12436471879482269
train-epoch-step: 46-486 -- Loss: 0.23464074730873108
train-epoch-step: 46-487 -- Loss: 0.2298157811164856
train-epoch-step: 46-488 -- Loss: 0.18248705565929413
train-epoch-step: 46-489 -- Loss: 0.22118811309337616
train-epoch-step: 46-490 -- Loss: 0.1317513883113861
train-epoch-step: 46-491 -- Loss: 0.13407760858535767
train-epoch-step: 46-492 -- Loss: 0.12420566380023956
train-epoch-step: 46-493 -- Loss: 0.19365465641021729
train-epoch-step: 46-494 -- Loss: 0.20538747310638428
train-epoch-step: 46-495 -- Loss: 0.20112597942352295
train-epoch-step: 46-496 -- Loss: 0.13748390972614288
train-epoch-step: 46-497 -- Loss: 0.18457168340682983
train-epoch-step: 46-498 -- Loss: 0.15084078907966614
train-epoch-step: 46-499 -- Loss: 0.16428802907466888
train-epoch-step: 46-500 -- Loss: 0.1523759514093399
train-epoch-step: 46-501 -- Loss: 0.22092753648757935
train-epoch-step: 46-502 -- Loss: 0.15578296780586243
train-epoch-step: 46-503 -- Loss: 0.21221134066581726
train-epoch-step: 46-504 -- Loss: 0.11787205934524536
train-epoch-step: 46-505 -- Loss: 0.16777628660202026
train-epoch-step: 46-506 -- Loss: 0.11382172256708145
train-epoch-step: 46-507 -- Loss: 0.17328135669231415
train-epoch-step: 46-508 -- Loss: 0.16692113876342773
train-epoch-step: 46-509 -- Loss: 0.16601704061031342
train-epoch-step: 46-510 -- Loss: 0.12326794862747192
train-epoch-step: 46-511 -- Loss: 0.2115575671195984
train-epoch-step: 46-512 -- Loss: 0.1701507717370987
train-epoch-step: 46-513 -- Loss: 0.1830199509859085
train-epoch-step: 46-514 -- Loss: 0.14449824392795563
train-epoch-step: 46-515 -- Loss: 0.15630848705768585
train-epoch-step: 46-516 -- Loss: 0.17327696084976196
train-epoch-step: 46-517 -- Loss: 0.1738770604133606
train-epoch-step: 46-518 -- Loss: 0.13528451323509216
train-epoch-step: 46-519 -- Loss: 0.13277621567249298
train-epoch-step: 46-520 -- Loss: 0.18299710750579834
train-epoch-step: 46-521 -- Loss: 0.22441862523555756
train-epoch-step: 46-522 -- Loss: 0.17515771090984344
train-epoch-step: 46-523 -- Loss: 0.1554710865020752
train-epoch-step: 46-524 -- Loss: 0.1675478219985962
train-epoch-step: 46-525 -- Loss: 0.18679988384246826
train-epoch-step: 46-526 -- Loss: 0.12674105167388916
train-epoch-step: 46-527 -- Loss: 0.14934438467025757
train-epoch-step: 46-528 -- Loss: 0.153304323554039
train-epoch-step: 46-529 -- Loss: 0.15180020034313202
train-epoch-step: 46-530 -- Loss: 0.1655658632516861
train-epoch-step: 46-531 -- Loss: 0.1923210471868515
train-epoch-step: 46-532 -- Loss: 0.16602014005184174
train-epoch-step: 46-533 -- Loss: 0.16863206028938293
train-epoch-step: 46-534 -- Loss: 0.1276123821735382
train-epoch-step: 46-535 -- Loss: 0.25030583143234253
train-epoch-step: 46-536 -- Loss: 0.16037242114543915
train-epoch-step: 46-537 -- Loss: 0.14178842306137085
train-epoch-step: 46-538 -- Loss: 0.10292519629001617
train-epoch-step: 46-539 -- Loss: 0.17674198746681213
train-epoch-step: 46-540 -- Loss: 0.13908341526985168
train-epoch-step: 46-541 -- Loss: 0.20299126207828522
train-epoch-step: 46-542 -- Loss: 0.21412086486816406
train-epoch-step: 46-543 -- Loss: 0.1649501770734787
train-epoch-step: 46-544 -- Loss: 0.22898587584495544
train-epoch-step: 46-545 -- Loss: 0.1912870705127716
train-epoch-step: 46-546 -- Loss: 0.2066931426525116
train-epoch-step: 46-547 -- Loss: 0.1759120225906372
train-epoch-step: 46-548 -- Loss: 0.0935700386762619
train-epoch-step: 46-549 -- Loss: 0.14925634860992432
train-epoch-step: 46-550 -- Loss: 0.19816939532756805
train-epoch-step: 46-551 -- Loss: 0.1530836522579193
train-epoch-step: 46-552 -- Loss: 0.1246146708726883
train-epoch-step: 46-553 -- Loss: 0.1858198642730713
train-epoch-step: 46-554 -- Loss: 0.1812620311975479
train-epoch-step: 46-555 -- Loss: 0.2076093554496765
train-epoch-step: 46-556 -- Loss: 0.14232033491134644
train-epoch-step: 46-557 -- Loss: 0.24108535051345825
train-epoch-step: 46-558 -- Loss: 0.22190415859222412
train-epoch-step: 46-559 -- Loss: 0.1372612714767456
train-epoch-step: 46-560 -- Loss: 0.2006804645061493
train-epoch-step: 46-561 -- Loss: 0.17537638545036316
train-epoch-step: 46-562 -- Loss: 0.15999479591846466
train-epoch-step: 46-563 -- Loss: 0.18057985603809357
train-epoch-step: 46-564 -- Loss: 0.09743914753198624
train-epoch-step: 46-565 -- Loss: 0.180827334523201
train-epoch-step: 46-566 -- Loss: 0.14404097199440002
train-epoch-step: 46-567 -- Loss: 0.20923100411891937
train-epoch-step: 46-568 -- Loss: 0.16581010818481445
train-epoch-step: 46-569 -- Loss: 0.23731842637062073
train-epoch-step: 46-570 -- Loss: 0.16272114217281342
train-epoch-step: 46-571 -- Loss: 0.2060021609067917
train-epoch-step: 46-572 -- Loss: 0.2331283986568451
train-epoch-step: 46-573 -- Loss: 0.19399498403072357
train-epoch-step: 46-574 -- Loss: 0.24006372690200806
train-epoch-step: 46-575 -- Loss: 0.28999975323677063
train-epoch-step: 46-576 -- Loss: 0.11500953137874603
train-epoch-step: 46-577 -- Loss: 0.16223189234733582
train-epoch-step: 46-578 -- Loss: 0.2137155830860138
train-epoch-step: 46-579 -- Loss: 0.1612851321697235
train-epoch-step: 46-580 -- Loss: 0.1690138578414917
train-epoch-step: 46-581 -- Loss: 0.13711345195770264
train-epoch-step: 46-582 -- Loss: 0.1995861977338791
train-epoch-step: 46-583 -- Loss: 0.21320855617523193
train-epoch-step: 46-584 -- Loss: 0.16208700835704803
train-epoch-step: 46-585 -- Loss: 0.1916227489709854
train-epoch-step: 46-586 -- Loss: 0.25814908742904663
train-epoch-step: 46-587 -- Loss: 0.1593562364578247
train-epoch-step: 46-588 -- Loss: 0.12617672979831696
val-epoch-step: 46-589 -- Loss: 0.20431621372699738
val-epoch-step: 46-590 -- Loss: 0.1528264433145523
val-epoch-step: 46-591 -- Loss: 0.21992804110050201
val-epoch-step: 46-592 -- Loss: 0.17292281985282898
val-epoch-step: 46-593 -- Loss: 0.16853174567222595
val-epoch-step: 46-594 -- Loss: 0.3724362254142761
val-epoch-step: 46-595 -- Loss: 0.18186143040657043
val-epoch-step: 46-596 -- Loss: 0.21661581099033356
val-epoch-step: 46-597 -- Loss: 0.1771286576986313
val-epoch-step: 46-598 -- Loss: 0.15442726016044617
val-epoch-step: 46-599 -- Loss: 0.183477982878685
val-epoch-step: 46-600 -- Loss: 0.22839860618114471
val-epoch-step: 46-601 -- Loss: 0.15484462678432465
val-epoch-step: 46-602 -- Loss: 0.13482923805713654
val-epoch-step: 46-603 -- Loss: 0.2002652883529663
val-epoch-step: 46-604 -- Loss: 0.1468079835176468
val-epoch-step: 46-605 -- Loss: 0.1472206562757492
val-epoch-step: 46-606 -- Loss: 0.25546860694885254
val-epoch-step: 46-607 -- Loss: 0.12451072037220001
val-epoch-step: 46-608 -- Loss: 0.24907925724983215
val-epoch-step: 46-609 -- Loss: 0.16063064336776733
val-epoch-step: 46-610 -- Loss: 0.17706668376922607
val-epoch-step: 46-611 -- Loss: 0.15955707430839539
val-epoch-step: 46-612 -- Loss: 0.3797203004360199
val-epoch-step: 46-613 -- Loss: 0.17071294784545898
val-epoch-step: 46-614 -- Loss: 0.19490846991539001
val-epoch-step: 46-615 -- Loss: 0.17152154445648193
val-epoch-step: 46-616 -- Loss: 0.15317703783512115
val-epoch-step: 46-617 -- Loss: 0.19873586297035217
val-epoch-step: 46-618 -- Loss: 0.18160855770111084
val-epoch-step: 46-619 -- Loss: 0.2305995672941208
val-epoch-step: 46-620 -- Loss: 0.14075307548046112
val-epoch-step: 46-621 -- Loss: 0.12674538791179657
val-epoch-step: 46-622 -- Loss: 0.14469526708126068
val-epoch-step: 46-623 -- Loss: 0.15136206150054932
val-epoch-step: 46-624 -- Loss: 0.14451244473457336
val-epoch-step: 46-625 -- Loss: 0.1573580503463745
val-epoch-step: 46-626 -- Loss: 0.14518436789512634
val-epoch-step: 46-627 -- Loss: 0.17503657937049866
val-epoch-step: 46-628 -- Loss: 0.6514595746994019
val-epoch-step: 46-629 -- Loss: 0.20737610757350922
val-epoch-step: 46-630 -- Loss: 0.3382054567337036
val-epoch-step: 46-631 -- Loss: 0.1407579481601715
val-epoch-step: 46-632 -- Loss: 0.2020534873008728
val-epoch-step: 46-633 -- Loss: 0.15982723236083984
val-epoch-step: 46-634 -- Loss: 0.14894947409629822
val-epoch-step: 46-635 -- Loss: 0.10867443680763245
val-epoch-step: 46-636 -- Loss: 0.16456684470176697
val-epoch-step: 46-637 -- Loss: 0.1811385452747345
val-epoch-step: 46-638 -- Loss: 0.14875288307666779
val-epoch-step: 46-639 -- Loss: 0.24832548201084137
val-epoch-step: 46-640 -- Loss: 0.2547144889831543
val-epoch-step: 46-641 -- Loss: 0.12314518541097641
val-epoch-step: 46-642 -- Loss: 0.20642608404159546
val-epoch-step: 46-643 -- Loss: 0.21142370998859406
val-epoch-step: 46-644 -- Loss: 0.16284823417663574
val-epoch-step: 46-645 -- Loss: 0.223868727684021
val-epoch-step: 46-646 -- Loss: 0.13863709568977356
val-epoch-step: 46-647 -- Loss: 0.13394786417484283
val-epoch-step: 46-648 -- Loss: 0.15830637514591217
val-epoch-step: 46-649 -- Loss: 0.20285607874393463
val-epoch-step: 46-650 -- Loss: 0.24477837979793549
val-epoch-step: 46-651 -- Loss: 0.1564200073480606
val-epoch-step: 46-652 -- Loss: 0.15181812644004822
val-epoch-step: 46-653 -- Loss: 0.20678506791591644
val-epoch-step: 46-654 -- Loss: 0.11669101566076279
Epoch: 46 -- Train Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 47-0 -- Loss: 0.2197818160057068
train-epoch-step: 47-1 -- Loss: 0.13880938291549683
train-epoch-step: 47-2 -- Loss: 0.1977633833885193
train-epoch-step: 47-3 -- Loss: 0.13915158808231354
train-epoch-step: 47-4 -- Loss: 0.15096457302570343
train-epoch-step: 47-5 -- Loss: 0.17934076488018036
train-epoch-step: 47-6 -- Loss: 0.2172565758228302
train-epoch-step: 47-7 -- Loss: 0.1656775027513504
train-epoch-step: 47-8 -- Loss: 0.17736540734767914
train-epoch-step: 47-9 -- Loss: 0.21974408626556396
train-epoch-step: 47-10 -- Loss: 0.19490724802017212
train-epoch-step: 47-11 -- Loss: 0.17405131459236145
train-epoch-step: 47-12 -- Loss: 0.14861837029457092
train-epoch-step: 47-13 -- Loss: 0.17385335266590118
train-epoch-step: 47-14 -- Loss: 0.1586705446243286
train-epoch-step: 47-15 -- Loss: 0.15924033522605896
train-epoch-step: 47-16 -- Loss: 0.1622755378484726
train-epoch-step: 47-17 -- Loss: 0.2112089991569519
train-epoch-step: 47-18 -- Loss: 0.19273032248020172
train-epoch-step: 47-19 -- Loss: 0.12786273658275604
train-epoch-step: 47-20 -- Loss: 0.20647463202476501
train-epoch-step: 47-21 -- Loss: 0.2527373433113098
train-epoch-step: 47-22 -- Loss: 0.1378135085105896
train-epoch-step: 47-23 -- Loss: 0.142276331782341
train-epoch-step: 47-24 -- Loss: 0.1238972395658493
train-epoch-step: 47-25 -- Loss: 0.22596879303455353
train-epoch-step: 47-26 -- Loss: 0.1882810890674591
train-epoch-step: 47-27 -- Loss: 0.2232426106929779
train-epoch-step: 47-28 -- Loss: 0.12168869376182556
train-epoch-step: 47-29 -- Loss: 0.24168971180915833
train-epoch-step: 47-30 -- Loss: 0.10716293007135391
train-epoch-step: 47-31 -- Loss: 0.13361933827400208
train-epoch-step: 47-32 -- Loss: 0.18327440321445465
train-epoch-step: 47-33 -- Loss: 0.2677195966243744
train-epoch-step: 47-34 -- Loss: 0.16494329273700714
train-epoch-step: 47-35 -- Loss: 0.23956066370010376
train-epoch-step: 47-36 -- Loss: 0.1354624181985855
train-epoch-step: 47-37 -- Loss: 0.13419915735721588
train-epoch-step: 47-38 -- Loss: 0.175252303481102
train-epoch-step: 47-39 -- Loss: 0.22103077173233032
train-epoch-step: 47-40 -- Loss: 0.1886390894651413
train-epoch-step: 47-41 -- Loss: 0.21435576677322388
train-epoch-step: 47-42 -- Loss: 0.14975988864898682
train-epoch-step: 47-43 -- Loss: 0.2569916248321533
train-epoch-step: 47-44 -- Loss: 0.12338767945766449
train-epoch-step: 47-45 -- Loss: 0.12197556346654892
train-epoch-step: 47-46 -- Loss: 0.16673612594604492
train-epoch-step: 47-47 -- Loss: 0.19497549533843994
train-epoch-step: 47-48 -- Loss: 0.15109547972679138
train-epoch-step: 47-49 -- Loss: 0.22348889708518982
train-epoch-step: 47-50 -- Loss: 0.11599740386009216
train-epoch-step: 47-51 -- Loss: 0.1848260760307312
train-epoch-step: 47-52 -- Loss: 0.1584322154521942
train-epoch-step: 47-53 -- Loss: 0.20915581285953522
train-epoch-step: 47-54 -- Loss: 0.2803800106048584
train-epoch-step: 47-55 -- Loss: 0.1666150987148285
train-epoch-step: 47-56 -- Loss: 0.17044402658939362
train-epoch-step: 47-57 -- Loss: 0.22870182991027832
train-epoch-step: 47-58 -- Loss: 0.2787899076938629
train-epoch-step: 47-59 -- Loss: 0.23343771696090698
train-epoch-step: 47-60 -- Loss: 0.12913939356803894
train-epoch-step: 47-61 -- Loss: 0.1973264217376709
train-epoch-step: 47-62 -- Loss: 0.18430420756340027
train-epoch-step: 47-63 -- Loss: 0.1334952861070633
train-epoch-step: 47-64 -- Loss: 0.1431407332420349
train-epoch-step: 47-65 -- Loss: 0.17929796874523163
train-epoch-step: 47-66 -- Loss: 0.10632853209972382
train-epoch-step: 47-67 -- Loss: 0.12416538596153259
train-epoch-step: 47-68 -- Loss: 0.2056267112493515
train-epoch-step: 47-69 -- Loss: 0.11641929298639297
train-epoch-step: 47-70 -- Loss: 0.2171173393726349
train-epoch-step: 47-71 -- Loss: 0.2537532150745392
train-epoch-step: 47-72 -- Loss: 0.1713053435087204
train-epoch-step: 47-73 -- Loss: 0.20119546353816986
train-epoch-step: 47-74 -- Loss: 0.09302501380443573
train-epoch-step: 47-75 -- Loss: 0.12697970867156982
train-epoch-step: 47-76 -- Loss: 0.14556534588336945
train-epoch-step: 47-77 -- Loss: 0.22309428453445435
train-epoch-step: 47-78 -- Loss: 0.2484828382730484
train-epoch-step: 47-79 -- Loss: 0.187298983335495
train-epoch-step: 47-80 -- Loss: 0.23558594286441803
train-epoch-step: 47-81 -- Loss: 0.11856986582279205
train-epoch-step: 47-82 -- Loss: 0.2481316775083542
train-epoch-step: 47-83 -- Loss: 0.17046253383159637
train-epoch-step: 47-84 -- Loss: 0.18382784724235535
train-epoch-step: 47-85 -- Loss: 0.17801615595817566
train-epoch-step: 47-86 -- Loss: 0.11746324598789215
train-epoch-step: 47-87 -- Loss: 0.2116812914609909
train-epoch-step: 47-88 -- Loss: 0.13685938715934753
train-epoch-step: 47-89 -- Loss: 0.18166063725948334
train-epoch-step: 47-90 -- Loss: 0.189681738615036
train-epoch-step: 47-91 -- Loss: 0.24338139593601227
train-epoch-step: 47-92 -- Loss: 0.15257491171360016
train-epoch-step: 47-93 -- Loss: 0.17363272607326508
train-epoch-step: 47-94 -- Loss: 0.21585817635059357
train-epoch-step: 47-95 -- Loss: 0.18411247432231903
train-epoch-step: 47-96 -- Loss: 0.2110135555267334
train-epoch-step: 47-97 -- Loss: 0.1747932732105255
train-epoch-step: 47-98 -- Loss: 0.1531626433134079
train-epoch-step: 47-99 -- Loss: 0.17687688767910004
train-epoch-step: 47-100 -- Loss: 0.1858293116092682
train-epoch-step: 47-101 -- Loss: 0.26979419589042664
train-epoch-step: 47-102 -- Loss: 0.21356229484081268
train-epoch-step: 47-103 -- Loss: 0.17924028635025024
train-epoch-step: 47-104 -- Loss: 0.14434827864170074
train-epoch-step: 47-105 -- Loss: 0.2668886184692383
train-epoch-step: 47-106 -- Loss: 0.17456941306591034
train-epoch-step: 47-107 -- Loss: 0.18714375793933868
train-epoch-step: 47-108 -- Loss: 0.18624362349510193
train-epoch-step: 47-109 -- Loss: 0.1408306509256363
train-epoch-step: 47-110 -- Loss: 0.17821934819221497
train-epoch-step: 47-111 -- Loss: 0.17254148423671722
train-epoch-step: 47-112 -- Loss: 0.1620502769947052
train-epoch-step: 47-113 -- Loss: 0.15781494975090027
train-epoch-step: 47-114 -- Loss: 0.2012033760547638
train-epoch-step: 47-115 -- Loss: 0.15615448355674744
train-epoch-step: 47-116 -- Loss: 0.1346675306558609
train-epoch-step: 47-117 -- Loss: 0.13135208189487457
train-epoch-step: 47-118 -- Loss: 0.1899217814207077
train-epoch-step: 47-119 -- Loss: 0.1547776311635971
train-epoch-step: 47-120 -- Loss: 0.24420522153377533
train-epoch-step: 47-121 -- Loss: 0.23170115053653717
train-epoch-step: 47-122 -- Loss: 0.2085919976234436
train-epoch-step: 47-123 -- Loss: 0.20055922865867615
train-epoch-step: 47-124 -- Loss: 0.12416063249111176
train-epoch-step: 47-125 -- Loss: 0.1556064784526825
train-epoch-step: 47-126 -- Loss: 0.2260623425245285
train-epoch-step: 47-127 -- Loss: 0.16490072011947632
train-epoch-step: 47-128 -- Loss: 0.1690417379140854
train-epoch-step: 47-129 -- Loss: 0.14353054761886597
train-epoch-step: 47-130 -- Loss: 0.1843966245651245
train-epoch-step: 47-131 -- Loss: 0.13370193541049957
train-epoch-step: 47-132 -- Loss: 0.18754905462265015
train-epoch-step: 47-133 -- Loss: 0.1133357435464859
train-epoch-step: 47-134 -- Loss: 0.1957954466342926
train-epoch-step: 47-135 -- Loss: 0.13041818141937256
train-epoch-step: 47-136 -- Loss: 0.12316618859767914
train-epoch-step: 47-137 -- Loss: 0.23451447486877441
train-epoch-step: 47-138 -- Loss: 0.25168296694755554
train-epoch-step: 47-139 -- Loss: 0.12810739874839783
train-epoch-step: 47-140 -- Loss: 0.20085492730140686
train-epoch-step: 47-141 -- Loss: 0.22427679598331451
train-epoch-step: 47-142 -- Loss: 0.19571906328201294
train-epoch-step: 47-143 -- Loss: 0.16718226671218872
train-epoch-step: 47-144 -- Loss: 0.1800154447555542
train-epoch-step: 47-145 -- Loss: 0.13697609305381775
train-epoch-step: 47-146 -- Loss: 0.17469021677970886
train-epoch-step: 47-147 -- Loss: 0.1684921681880951
train-epoch-step: 47-148 -- Loss: 0.15433134138584137
train-epoch-step: 47-149 -- Loss: 0.12733104825019836
train-epoch-step: 47-150 -- Loss: 0.17805659770965576
train-epoch-step: 47-151 -- Loss: 0.18889302015304565
train-epoch-step: 47-152 -- Loss: 0.18621119856834412
train-epoch-step: 47-153 -- Loss: 0.2576555609703064
train-epoch-step: 47-154 -- Loss: 0.1259322166442871
train-epoch-step: 47-155 -- Loss: 0.13406550884246826
train-epoch-step: 47-156 -- Loss: 0.1146714985370636
train-epoch-step: 47-157 -- Loss: 0.1585475206375122
train-epoch-step: 47-158 -- Loss: 0.16015255451202393
train-epoch-step: 47-159 -- Loss: 0.1746642142534256
train-epoch-step: 47-160 -- Loss: 0.21573197841644287
train-epoch-step: 47-161 -- Loss: 0.20237469673156738
train-epoch-step: 47-162 -- Loss: 0.2131199687719345
train-epoch-step: 47-163 -- Loss: 0.18398119509220123
train-epoch-step: 47-164 -- Loss: 0.18813584744930267
train-epoch-step: 47-165 -- Loss: 0.160073921084404
train-epoch-step: 47-166 -- Loss: 0.11845165491104126
train-epoch-step: 47-167 -- Loss: 0.12549638748168945
train-epoch-step: 47-168 -- Loss: 0.1927715390920639
train-epoch-step: 47-169 -- Loss: 0.1333623081445694
train-epoch-step: 47-170 -- Loss: 0.19678135216236115
train-epoch-step: 47-171 -- Loss: 0.1413363367319107
train-epoch-step: 47-172 -- Loss: 0.2524499297142029
train-epoch-step: 47-173 -- Loss: 0.13211847841739655
train-epoch-step: 47-174 -- Loss: 0.241204172372818
train-epoch-step: 47-175 -- Loss: 0.1860242784023285
train-epoch-step: 47-176 -- Loss: 0.12587308883666992
train-epoch-step: 47-177 -- Loss: 0.17481133341789246
train-epoch-step: 47-178 -- Loss: 0.17224381864070892
train-epoch-step: 47-179 -- Loss: 0.1430741399526596
train-epoch-step: 47-180 -- Loss: 0.14998425543308258
train-epoch-step: 47-181 -- Loss: 0.163835808634758
train-epoch-step: 47-182 -- Loss: 0.17826323211193085
train-epoch-step: 47-183 -- Loss: 0.2702871561050415
train-epoch-step: 47-184 -- Loss: 0.13511785864830017
train-epoch-step: 47-185 -- Loss: 0.14196208119392395
train-epoch-step: 47-186 -- Loss: 0.1877230405807495
train-epoch-step: 47-187 -- Loss: 0.20446759462356567
train-epoch-step: 47-188 -- Loss: 0.17063333094120026
train-epoch-step: 47-189 -- Loss: 0.10375633835792542
train-epoch-step: 47-190 -- Loss: 0.18598616123199463
train-epoch-step: 47-191 -- Loss: 0.15666258335113525
train-epoch-step: 47-192 -- Loss: 0.22557276487350464
train-epoch-step: 47-193 -- Loss: 0.19375763833522797
train-epoch-step: 47-194 -- Loss: 0.1801699846982956
train-epoch-step: 47-195 -- Loss: 0.16475439071655273
train-epoch-step: 47-196 -- Loss: 0.16383405029773712
train-epoch-step: 47-197 -- Loss: 0.12490945309400558
train-epoch-step: 47-198 -- Loss: 0.12407810240983963
train-epoch-step: 47-199 -- Loss: 0.14174193143844604
train-epoch-step: 47-200 -- Loss: 0.1234508752822876
train-epoch-step: 47-201 -- Loss: 0.1844143569469452
train-epoch-step: 47-202 -- Loss: 0.13435454666614532
train-epoch-step: 47-203 -- Loss: 0.16893404722213745
train-epoch-step: 47-204 -- Loss: 0.13286928832530975
train-epoch-step: 47-205 -- Loss: 0.18419703841209412
train-epoch-step: 47-206 -- Loss: 0.1970013827085495
train-epoch-step: 47-207 -- Loss: 0.12913189828395844
train-epoch-step: 47-208 -- Loss: 0.173110231757164
train-epoch-step: 47-209 -- Loss: 0.1409711241722107
train-epoch-step: 47-210 -- Loss: 0.12917380034923553
train-epoch-step: 47-211 -- Loss: 0.20453417301177979
train-epoch-step: 47-212 -- Loss: 0.19512014091014862
train-epoch-step: 47-213 -- Loss: 0.12461590766906738
train-epoch-step: 47-214 -- Loss: 0.1451890468597412
train-epoch-step: 47-215 -- Loss: 0.12739309668540955
train-epoch-step: 47-216 -- Loss: 0.20769460499286652
train-epoch-step: 47-217 -- Loss: 0.20989832282066345
train-epoch-step: 47-218 -- Loss: 0.1445118933916092
train-epoch-step: 47-219 -- Loss: 0.16390565037727356
train-epoch-step: 47-220 -- Loss: 0.12878109514713287
train-epoch-step: 47-221 -- Loss: 0.19648489356040955
train-epoch-step: 47-222 -- Loss: 0.11286110430955887
train-epoch-step: 47-223 -- Loss: 0.16602596640586853
train-epoch-step: 47-224 -- Loss: 0.18829098343849182
train-epoch-step: 47-225 -- Loss: 0.26523932814598083
train-epoch-step: 47-226 -- Loss: 0.2011204957962036
train-epoch-step: 47-227 -- Loss: 0.2177816927433014
train-epoch-step: 47-228 -- Loss: 0.17514371871948242
train-epoch-step: 47-229 -- Loss: 0.16845488548278809
train-epoch-step: 47-230 -- Loss: 0.16300025582313538
train-epoch-step: 47-231 -- Loss: 0.15582701563835144
train-epoch-step: 47-232 -- Loss: 0.18272905051708221
train-epoch-step: 47-233 -- Loss: 0.0814240351319313
train-epoch-step: 47-234 -- Loss: 0.1669618785381317
train-epoch-step: 47-235 -- Loss: 0.14505673944950104
train-epoch-step: 47-236 -- Loss: 0.18042898178100586
train-epoch-step: 47-237 -- Loss: 0.23068207502365112
train-epoch-step: 47-238 -- Loss: 0.15382009744644165
train-epoch-step: 47-239 -- Loss: 0.12634232640266418
train-epoch-step: 47-240 -- Loss: 0.2230239361524582
train-epoch-step: 47-241 -- Loss: 0.1473361700773239
train-epoch-step: 47-242 -- Loss: 0.215871661901474
train-epoch-step: 47-243 -- Loss: 0.22826728224754333
train-epoch-step: 47-244 -- Loss: 0.20395731925964355
train-epoch-step: 47-245 -- Loss: 0.20140206813812256
train-epoch-step: 47-246 -- Loss: 0.22050204873085022
train-epoch-step: 47-247 -- Loss: 0.2018662393093109
train-epoch-step: 47-248 -- Loss: 0.1829124391078949
train-epoch-step: 47-249 -- Loss: 0.13161398470401764
train-epoch-step: 47-250 -- Loss: 0.19507066905498505
train-epoch-step: 47-251 -- Loss: 0.10506681352853775
train-epoch-step: 47-252 -- Loss: 0.18716835975646973
train-epoch-step: 47-253 -- Loss: 0.138180673122406
train-epoch-step: 47-254 -- Loss: 0.2079019695520401
train-epoch-step: 47-255 -- Loss: 0.14305537939071655
train-epoch-step: 47-256 -- Loss: 0.14694373309612274
train-epoch-step: 47-257 -- Loss: 0.1822289526462555
train-epoch-step: 47-258 -- Loss: 0.14097410440444946
train-epoch-step: 47-259 -- Loss: 0.10871053487062454
train-epoch-step: 47-260 -- Loss: 0.19966544210910797
train-epoch-step: 47-261 -- Loss: 0.17043842375278473
train-epoch-step: 47-262 -- Loss: 0.28401339054107666
train-epoch-step: 47-263 -- Loss: 0.2041555792093277
train-epoch-step: 47-264 -- Loss: 0.16954287886619568
train-epoch-step: 47-265 -- Loss: 0.10806246846914291
train-epoch-step: 47-266 -- Loss: 0.15381284058094025
train-epoch-step: 47-267 -- Loss: 0.12921126186847687
train-epoch-step: 47-268 -- Loss: 0.11563996225595474
train-epoch-step: 47-269 -- Loss: 0.16835108399391174
train-epoch-step: 47-270 -- Loss: 0.10441835224628448
train-epoch-step: 47-271 -- Loss: 0.15079978108406067
train-epoch-step: 47-272 -- Loss: 0.11410805583000183
train-epoch-step: 47-273 -- Loss: 0.12353882193565369
train-epoch-step: 47-274 -- Loss: 0.17808747291564941
train-epoch-step: 47-275 -- Loss: 0.1892198622226715
train-epoch-step: 47-276 -- Loss: 0.15548205375671387
train-epoch-step: 47-277 -- Loss: 0.16561223566532135
train-epoch-step: 47-278 -- Loss: 0.1367032527923584
train-epoch-step: 47-279 -- Loss: 0.14012905955314636
train-epoch-step: 47-280 -- Loss: 0.211751788854599
train-epoch-step: 47-281 -- Loss: 0.17328301072120667
train-epoch-step: 47-282 -- Loss: 0.14134357869625092
train-epoch-step: 47-283 -- Loss: 0.11219905316829681
train-epoch-step: 47-284 -- Loss: 0.13788829743862152
train-epoch-step: 47-285 -- Loss: 0.19459620118141174
train-epoch-step: 47-286 -- Loss: 0.1494591385126114
train-epoch-step: 47-287 -- Loss: 0.19967025518417358
train-epoch-step: 47-288 -- Loss: 0.09411294013261795
train-epoch-step: 47-289 -- Loss: 0.11919831484556198
train-epoch-step: 47-290 -- Loss: 0.17910932004451752
train-epoch-step: 47-291 -- Loss: 0.11339530348777771
train-epoch-step: 47-292 -- Loss: 0.15368865430355072
train-epoch-step: 47-293 -- Loss: 0.13607414066791534
train-epoch-step: 47-294 -- Loss: 0.1682664006948471
train-epoch-step: 47-295 -- Loss: 0.25927427411079407
train-epoch-step: 47-296 -- Loss: 0.1564876139163971
train-epoch-step: 47-297 -- Loss: 0.16777385771274567
train-epoch-step: 47-298 -- Loss: 0.22493839263916016
train-epoch-step: 47-299 -- Loss: 0.142038494348526
train-epoch-step: 47-300 -- Loss: 0.15884658694267273
train-epoch-step: 47-301 -- Loss: 0.1634603589773178
train-epoch-step: 47-302 -- Loss: 0.23074908554553986
train-epoch-step: 47-303 -- Loss: 0.1980086863040924
train-epoch-step: 47-304 -- Loss: 0.12885314226150513
train-epoch-step: 47-305 -- Loss: 0.13801495730876923
train-epoch-step: 47-306 -- Loss: 0.20672693848609924
train-epoch-step: 47-307 -- Loss: 0.1633518636226654
train-epoch-step: 47-308 -- Loss: 0.2081035077571869
train-epoch-step: 47-309 -- Loss: 0.16033807396888733
train-epoch-step: 47-310 -- Loss: 0.158172145485878
train-epoch-step: 47-311 -- Loss: 0.15544763207435608
train-epoch-step: 47-312 -- Loss: 0.20261825621128082
train-epoch-step: 47-313 -- Loss: 0.09574166685342789
train-epoch-step: 47-314 -- Loss: 0.18885573744773865
train-epoch-step: 47-315 -- Loss: 0.1663730889558792
train-epoch-step: 47-316 -- Loss: 0.15424945950508118
train-epoch-step: 47-317 -- Loss: 0.14789405465126038
train-epoch-step: 47-318 -- Loss: 0.15804199874401093
train-epoch-step: 47-319 -- Loss: 0.16664187610149384
train-epoch-step: 47-320 -- Loss: 0.11483430862426758
train-epoch-step: 47-321 -- Loss: 0.13275711238384247
train-epoch-step: 47-322 -- Loss: 0.20793096721172333
train-epoch-step: 47-323 -- Loss: 0.15891900658607483
train-epoch-step: 47-324 -- Loss: 0.2520957291126251
train-epoch-step: 47-325 -- Loss: 0.15172484517097473
train-epoch-step: 47-326 -- Loss: 0.16970473527908325
train-epoch-step: 47-327 -- Loss: 0.19782514870166779
train-epoch-step: 47-328 -- Loss: 0.1907067596912384
train-epoch-step: 47-329 -- Loss: 0.3304728865623474
train-epoch-step: 47-330 -- Loss: 0.3505578935146332
train-epoch-step: 47-331 -- Loss: 0.20503303408622742
train-epoch-step: 47-332 -- Loss: 0.09688538312911987
train-epoch-step: 47-333 -- Loss: 0.18106026947498322
train-epoch-step: 47-334 -- Loss: 0.15492713451385498
train-epoch-step: 47-335 -- Loss: 0.17267438769340515
train-epoch-step: 47-336 -- Loss: 0.14816050231456757
train-epoch-step: 47-337 -- Loss: 0.199139803647995
train-epoch-step: 47-338 -- Loss: 0.16112203896045685
train-epoch-step: 47-339 -- Loss: 0.14972379803657532
train-epoch-step: 47-340 -- Loss: 0.19150303304195404
train-epoch-step: 47-341 -- Loss: 0.136715367436409
train-epoch-step: 47-342 -- Loss: 0.16226060688495636
train-epoch-step: 47-343 -- Loss: 0.15007805824279785
train-epoch-step: 47-344 -- Loss: 0.16332486271858215
train-epoch-step: 47-345 -- Loss: 0.12455275654792786
train-epoch-step: 47-346 -- Loss: 0.20636488497257233
train-epoch-step: 47-347 -- Loss: 0.15052440762519836
train-epoch-step: 47-348 -- Loss: 0.20639999210834503
train-epoch-step: 47-349 -- Loss: 0.19805315136909485
train-epoch-step: 47-350 -- Loss: 0.25292131304740906
train-epoch-step: 47-351 -- Loss: 0.18526813387870789
train-epoch-step: 47-352 -- Loss: 0.11813190579414368
train-epoch-step: 47-353 -- Loss: 0.1922949254512787
train-epoch-step: 47-354 -- Loss: 0.27860742807388306
train-epoch-step: 47-355 -- Loss: 0.11622633785009384
train-epoch-step: 47-356 -- Loss: 0.11545336991548538
train-epoch-step: 47-357 -- Loss: 0.18633802235126495
train-epoch-step: 47-358 -- Loss: 0.17933279275894165
train-epoch-step: 47-359 -- Loss: 0.1371382176876068
train-epoch-step: 47-360 -- Loss: 0.12300138175487518
train-epoch-step: 47-361 -- Loss: 0.22954130172729492
train-epoch-step: 47-362 -- Loss: 0.16459336876869202
train-epoch-step: 47-363 -- Loss: 0.10695129632949829
train-epoch-step: 47-364 -- Loss: 0.1777508705854416
train-epoch-step: 47-365 -- Loss: 0.16820791363716125
train-epoch-step: 47-366 -- Loss: 0.1944994330406189
train-epoch-step: 47-367 -- Loss: 0.22502675652503967
train-epoch-step: 47-368 -- Loss: 0.20074523985385895
train-epoch-step: 47-369 -- Loss: 0.27117812633514404
train-epoch-step: 47-370 -- Loss: 0.12427566945552826
train-epoch-step: 47-371 -- Loss: 0.11860456317663193
train-epoch-step: 47-372 -- Loss: 0.14379847049713135
train-epoch-step: 47-373 -- Loss: 0.18165487051010132
train-epoch-step: 47-374 -- Loss: 0.15317986905574799
train-epoch-step: 47-375 -- Loss: 0.2615044414997101
train-epoch-step: 47-376 -- Loss: 0.1592068076133728
train-epoch-step: 47-377 -- Loss: 0.22608636319637299
train-epoch-step: 47-378 -- Loss: 0.1967124044895172
train-epoch-step: 47-379 -- Loss: 0.11699649691581726
train-epoch-step: 47-380 -- Loss: 0.08857716619968414
train-epoch-step: 47-381 -- Loss: 0.23805522918701172
train-epoch-step: 47-382 -- Loss: 0.22894540429115295
train-epoch-step: 47-383 -- Loss: 0.17592287063598633
train-epoch-step: 47-384 -- Loss: 0.210449680685997
train-epoch-step: 47-385 -- Loss: 0.1864606738090515
train-epoch-step: 47-386 -- Loss: 0.1841713786125183
train-epoch-step: 47-387 -- Loss: 0.1981004774570465
train-epoch-step: 47-388 -- Loss: 0.17940828204154968
train-epoch-step: 47-389 -- Loss: 0.16318555176258087
train-epoch-step: 47-390 -- Loss: 0.14040234684944153
train-epoch-step: 47-391 -- Loss: 0.14180880784988403
train-epoch-step: 47-392 -- Loss: 0.18180124461650848
train-epoch-step: 47-393 -- Loss: 0.1560031622648239
train-epoch-step: 47-394 -- Loss: 0.19764889776706696
train-epoch-step: 47-395 -- Loss: 0.1550273299217224
train-epoch-step: 47-396 -- Loss: 0.1243816465139389
train-epoch-step: 47-397 -- Loss: 0.1212402731180191
train-epoch-step: 47-398 -- Loss: 0.1960526406764984
train-epoch-step: 47-399 -- Loss: 0.17061170935630798
train-epoch-step: 47-400 -- Loss: 0.2734852135181427
train-epoch-step: 47-401 -- Loss: 0.11864505708217621
train-epoch-step: 47-402 -- Loss: 0.25087571144104004
train-epoch-step: 47-403 -- Loss: 0.1508653163909912
train-epoch-step: 47-404 -- Loss: 0.13470648229122162
train-epoch-step: 47-405 -- Loss: 0.1406712830066681
train-epoch-step: 47-406 -- Loss: 0.16393215954303741
train-epoch-step: 47-407 -- Loss: 0.11027733981609344
train-epoch-step: 47-408 -- Loss: 0.1590755730867386
train-epoch-step: 47-409 -- Loss: 0.1688566505908966
train-epoch-step: 47-410 -- Loss: 0.17019881308078766
train-epoch-step: 47-411 -- Loss: 0.20448307693004608
train-epoch-step: 47-412 -- Loss: 0.12657758593559265
train-epoch-step: 47-413 -- Loss: 0.1442711055278778
train-epoch-step: 47-414 -- Loss: 0.13312286138534546
train-epoch-step: 47-415 -- Loss: 0.1314830332994461
train-epoch-step: 47-416 -- Loss: 0.2582581639289856
train-epoch-step: 47-417 -- Loss: 0.19038483500480652
train-epoch-step: 47-418 -- Loss: 0.22322344779968262
train-epoch-step: 47-419 -- Loss: 0.1625431478023529
train-epoch-step: 47-420 -- Loss: 0.1469511091709137
train-epoch-step: 47-421 -- Loss: 0.17278693616390228
train-epoch-step: 47-422 -- Loss: 0.1425694227218628
train-epoch-step: 47-423 -- Loss: 0.17313739657402039
train-epoch-step: 47-424 -- Loss: 0.13354144990444183
train-epoch-step: 47-425 -- Loss: 0.17652538418769836
train-epoch-step: 47-426 -- Loss: 0.15731775760650635
train-epoch-step: 47-427 -- Loss: 0.11823141574859619
train-epoch-step: 47-428 -- Loss: 0.19686217606067657
train-epoch-step: 47-429 -- Loss: 0.17037756741046906
train-epoch-step: 47-430 -- Loss: 0.1349954605102539
train-epoch-step: 47-431 -- Loss: 0.16125769913196564
train-epoch-step: 47-432 -- Loss: 0.23653994500637054
train-epoch-step: 47-433 -- Loss: 0.1347324550151825
train-epoch-step: 47-434 -- Loss: 0.13047842681407928
train-epoch-step: 47-435 -- Loss: 0.1531764417886734
train-epoch-step: 47-436 -- Loss: 0.15540987253189087
train-epoch-step: 47-437 -- Loss: 0.12999272346496582
train-epoch-step: 47-438 -- Loss: 0.16725575923919678
train-epoch-step: 47-439 -- Loss: 0.26055455207824707
train-epoch-step: 47-440 -- Loss: 0.13088390231132507
train-epoch-step: 47-441 -- Loss: 0.20242798328399658
train-epoch-step: 47-442 -- Loss: 0.17868450284004211
train-epoch-step: 47-443 -- Loss: 0.14934515953063965
train-epoch-step: 47-444 -- Loss: 0.17021140456199646
train-epoch-step: 47-445 -- Loss: 0.17681504786014557
train-epoch-step: 47-446 -- Loss: 0.15323778986930847
train-epoch-step: 47-447 -- Loss: 0.19517093896865845
train-epoch-step: 47-448 -- Loss: 0.22888769209384918
train-epoch-step: 47-449 -- Loss: 0.18793252110481262
train-epoch-step: 47-450 -- Loss: 0.18017694354057312
train-epoch-step: 47-451 -- Loss: 0.14018063247203827
train-epoch-step: 47-452 -- Loss: 0.12528018653392792
train-epoch-step: 47-453 -- Loss: 0.09101393818855286
train-epoch-step: 47-454 -- Loss: 0.2280707061290741
train-epoch-step: 47-455 -- Loss: 0.11919382214546204
train-epoch-step: 47-456 -- Loss: 0.11793333292007446
train-epoch-step: 47-457 -- Loss: 0.2105603665113449
train-epoch-step: 47-458 -- Loss: 0.14004197716712952
train-epoch-step: 47-459 -- Loss: 0.21416394412517548
train-epoch-step: 47-460 -- Loss: 0.12161723524332047
train-epoch-step: 47-461 -- Loss: 0.1330496072769165
train-epoch-step: 47-462 -- Loss: 0.15454620122909546
train-epoch-step: 47-463 -- Loss: 0.13490107655525208
train-epoch-step: 47-464 -- Loss: 0.1629018485546112
train-epoch-step: 47-465 -- Loss: 0.23147991299629211
train-epoch-step: 47-466 -- Loss: 0.2010178118944168
train-epoch-step: 47-467 -- Loss: 0.11276410520076752
train-epoch-step: 47-468 -- Loss: 0.16003504395484924
train-epoch-step: 47-469 -- Loss: 0.2091330587863922
train-epoch-step: 47-470 -- Loss: 0.16640152037143707
train-epoch-step: 47-471 -- Loss: 0.1590571403503418
train-epoch-step: 47-472 -- Loss: 0.15395520627498627
train-epoch-step: 47-473 -- Loss: 0.15219344198703766
train-epoch-step: 47-474 -- Loss: 0.1158747673034668
train-epoch-step: 47-475 -- Loss: 0.10794495046138763
train-epoch-step: 47-476 -- Loss: 0.194678395986557
train-epoch-step: 47-477 -- Loss: 0.21858692169189453
train-epoch-step: 47-478 -- Loss: 0.1825125515460968
train-epoch-step: 47-479 -- Loss: 0.13413211703300476
train-epoch-step: 47-480 -- Loss: 0.1896640509366989
train-epoch-step: 47-481 -- Loss: 0.2785119116306305
train-epoch-step: 47-482 -- Loss: 0.24730974435806274
train-epoch-step: 47-483 -- Loss: 0.17361247539520264
train-epoch-step: 47-484 -- Loss: 0.21052893996238708
train-epoch-step: 47-485 -- Loss: 0.12416975200176239
train-epoch-step: 47-486 -- Loss: 0.2334292232990265
train-epoch-step: 47-487 -- Loss: 0.22967824339866638
train-epoch-step: 47-488 -- Loss: 0.1984560787677765
train-epoch-step: 47-489 -- Loss: 0.2140268087387085
train-epoch-step: 47-490 -- Loss: 0.1388917863368988
train-epoch-step: 47-491 -- Loss: 0.1333070993423462
train-epoch-step: 47-492 -- Loss: 0.12297628819942474
train-epoch-step: 47-493 -- Loss: 0.19748717546463013
train-epoch-step: 47-494 -- Loss: 0.20516622066497803
train-epoch-step: 47-495 -- Loss: 0.20148144662380219
train-epoch-step: 47-496 -- Loss: 0.13839443027973175
train-epoch-step: 47-497 -- Loss: 0.17949321866035461
train-epoch-step: 47-498 -- Loss: 0.1436479240655899
train-epoch-step: 47-499 -- Loss: 0.16350607573986053
train-epoch-step: 47-500 -- Loss: 0.1525791883468628
train-epoch-step: 47-501 -- Loss: 0.20890942215919495
train-epoch-step: 47-502 -- Loss: 0.1539909988641739
train-epoch-step: 47-503 -- Loss: 0.21182642877101898
train-epoch-step: 47-504 -- Loss: 0.11481977999210358
train-epoch-step: 47-505 -- Loss: 0.17008543014526367
train-epoch-step: 47-506 -- Loss: 0.11536819487810135
train-epoch-step: 47-507 -- Loss: 0.18161578476428986
train-epoch-step: 47-508 -- Loss: 0.17157307267189026
train-epoch-step: 47-509 -- Loss: 0.16160234808921814
train-epoch-step: 47-510 -- Loss: 0.12372642010450363
train-epoch-step: 47-511 -- Loss: 0.21429169178009033
train-epoch-step: 47-512 -- Loss: 0.17380040884017944
train-epoch-step: 47-513 -- Loss: 0.18921317160129547
train-epoch-step: 47-514 -- Loss: 0.14620785415172577
train-epoch-step: 47-515 -- Loss: 0.15500615537166595
train-epoch-step: 47-516 -- Loss: 0.16995660960674286
train-epoch-step: 47-517 -- Loss: 0.17096185684204102
train-epoch-step: 47-518 -- Loss: 0.13291366398334503
train-epoch-step: 47-519 -- Loss: 0.12998323142528534
train-epoch-step: 47-520 -- Loss: 0.18380597233772278
train-epoch-step: 47-521 -- Loss: 0.2242727279663086
train-epoch-step: 47-522 -- Loss: 0.1702987402677536
train-epoch-step: 47-523 -- Loss: 0.15449225902557373
train-epoch-step: 47-524 -- Loss: 0.16156825423240662
train-epoch-step: 47-525 -- Loss: 0.18496918678283691
train-epoch-step: 47-526 -- Loss: 0.12936288118362427
train-epoch-step: 47-527 -- Loss: 0.14740830659866333
train-epoch-step: 47-528 -- Loss: 0.15091517567634583
train-epoch-step: 47-529 -- Loss: 0.15653011202812195
train-epoch-step: 47-530 -- Loss: 0.1646711379289627
train-epoch-step: 47-531 -- Loss: 0.18989607691764832
train-epoch-step: 47-532 -- Loss: 0.1673646718263626
train-epoch-step: 47-533 -- Loss: 0.1726343333721161
train-epoch-step: 47-534 -- Loss: 0.127655029296875
train-epoch-step: 47-535 -- Loss: 0.2530873119831085
train-epoch-step: 47-536 -- Loss: 0.15303899347782135
train-epoch-step: 47-537 -- Loss: 0.14720456302165985
train-epoch-step: 47-538 -- Loss: 0.10022340714931488
train-epoch-step: 47-539 -- Loss: 0.174313023686409
train-epoch-step: 47-540 -- Loss: 0.14029449224472046
train-epoch-step: 47-541 -- Loss: 0.2026173174381256
train-epoch-step: 47-542 -- Loss: 0.21878762543201447
train-epoch-step: 47-543 -- Loss: 0.16705092787742615
train-epoch-step: 47-544 -- Loss: 0.22143538296222687
train-epoch-step: 47-545 -- Loss: 0.19406509399414062
train-epoch-step: 47-546 -- Loss: 0.21461880207061768
train-epoch-step: 47-547 -- Loss: 0.17972548305988312
train-epoch-step: 47-548 -- Loss: 0.09486540406942368
train-epoch-step: 47-549 -- Loss: 0.14929251372814178
train-epoch-step: 47-550 -- Loss: 0.19400939345359802
train-epoch-step: 47-551 -- Loss: 0.14930562674999237
train-epoch-step: 47-552 -- Loss: 0.12175252288579941
train-epoch-step: 47-553 -- Loss: 0.18362413346767426
train-epoch-step: 47-554 -- Loss: 0.19166085124015808
train-epoch-step: 47-555 -- Loss: 0.2075624167919159
train-epoch-step: 47-556 -- Loss: 0.14750096201896667
train-epoch-step: 47-557 -- Loss: 0.2330983281135559
train-epoch-step: 47-558 -- Loss: 0.22239655256271362
train-epoch-step: 47-559 -- Loss: 0.14259782433509827
train-epoch-step: 47-560 -- Loss: 0.20318061113357544
train-epoch-step: 47-561 -- Loss: 0.17843180894851685
train-epoch-step: 47-562 -- Loss: 0.162684828042984
train-epoch-step: 47-563 -- Loss: 0.18907418847084045
train-epoch-step: 47-564 -- Loss: 0.09888006746768951
train-epoch-step: 47-565 -- Loss: 0.1814744770526886
train-epoch-step: 47-566 -- Loss: 0.1445690393447876
train-epoch-step: 47-567 -- Loss: 0.20820708572864532
train-epoch-step: 47-568 -- Loss: 0.15560483932495117
train-epoch-step: 47-569 -- Loss: 0.24173754453659058
train-epoch-step: 47-570 -- Loss: 0.17222484946250916
train-epoch-step: 47-571 -- Loss: 0.21267834305763245
train-epoch-step: 47-572 -- Loss: 0.23631325364112854
train-epoch-step: 47-573 -- Loss: 0.20133069157600403
train-epoch-step: 47-574 -- Loss: 0.2392737865447998
train-epoch-step: 47-575 -- Loss: 0.2918611168861389
train-epoch-step: 47-576 -- Loss: 0.11908477544784546
train-epoch-step: 47-577 -- Loss: 0.16094422340393066
train-epoch-step: 47-578 -- Loss: 0.2129579782485962
train-epoch-step: 47-579 -- Loss: 0.16306379437446594
train-epoch-step: 47-580 -- Loss: 0.16997718811035156
train-epoch-step: 47-581 -- Loss: 0.13504411280155182
train-epoch-step: 47-582 -- Loss: 0.20453938841819763
train-epoch-step: 47-583 -- Loss: 0.2091677337884903
train-epoch-step: 47-584 -- Loss: 0.16427883505821228
train-epoch-step: 47-585 -- Loss: 0.1923435479402542
train-epoch-step: 47-586 -- Loss: 0.2494295835494995
train-epoch-step: 47-587 -- Loss: 0.1590958684682846
train-epoch-step: 47-588 -- Loss: 0.1256704181432724
val-epoch-step: 47-589 -- Loss: 0.19902463257312775
val-epoch-step: 47-590 -- Loss: 0.15235809981822968
val-epoch-step: 47-591 -- Loss: 0.2334417849779129
val-epoch-step: 47-592 -- Loss: 0.16939786076545715
val-epoch-step: 47-593 -- Loss: 0.18194806575775146
val-epoch-step: 47-594 -- Loss: 0.3909173905849457
val-epoch-step: 47-595 -- Loss: 0.17144674062728882
val-epoch-step: 47-596 -- Loss: 0.20282573997974396
val-epoch-step: 47-597 -- Loss: 0.17553551495075226
val-epoch-step: 47-598 -- Loss: 0.14492639899253845
val-epoch-step: 47-599 -- Loss: 0.18706052005290985
val-epoch-step: 47-600 -- Loss: 0.21509860455989838
val-epoch-step: 47-601 -- Loss: 0.15748170018196106
val-epoch-step: 47-602 -- Loss: 0.13179711997509003
val-epoch-step: 47-603 -- Loss: 0.21933269500732422
val-epoch-step: 47-604 -- Loss: 0.14756999909877777
val-epoch-step: 47-605 -- Loss: 0.1446887105703354
val-epoch-step: 47-606 -- Loss: 0.2865128219127655
val-epoch-step: 47-607 -- Loss: 0.1316641867160797
val-epoch-step: 47-608 -- Loss: 0.24815338850021362
val-epoch-step: 47-609 -- Loss: 0.1648542881011963
val-epoch-step: 47-610 -- Loss: 0.1773860901594162
val-epoch-step: 47-611 -- Loss: 0.16091111302375793
val-epoch-step: 47-612 -- Loss: 0.4527224898338318
val-epoch-step: 47-613 -- Loss: 0.1719789206981659
val-epoch-step: 47-614 -- Loss: 0.15993697941303253
val-epoch-step: 47-615 -- Loss: 0.17050008475780487
val-epoch-step: 47-616 -- Loss: 0.144057035446167
val-epoch-step: 47-617 -- Loss: 0.18350663781166077
val-epoch-step: 47-618 -- Loss: 0.19790485501289368
val-epoch-step: 47-619 -- Loss: 0.20841971039772034
val-epoch-step: 47-620 -- Loss: 0.13684223592281342
val-epoch-step: 47-621 -- Loss: 0.12580829858779907
val-epoch-step: 47-622 -- Loss: 0.14465254545211792
val-epoch-step: 47-623 -- Loss: 0.1510818749666214
val-epoch-step: 47-624 -- Loss: 0.14217256009578705
val-epoch-step: 47-625 -- Loss: 0.15745261311531067
val-epoch-step: 47-626 -- Loss: 0.14790204167366028
val-epoch-step: 47-627 -- Loss: 0.18206341564655304
val-epoch-step: 47-628 -- Loss: 0.6959789395332336
val-epoch-step: 47-629 -- Loss: 0.1903645396232605
val-epoch-step: 47-630 -- Loss: 0.34061193466186523
val-epoch-step: 47-631 -- Loss: 0.14530663192272186
val-epoch-step: 47-632 -- Loss: 0.2031402587890625
val-epoch-step: 47-633 -- Loss: 0.15091675519943237
val-epoch-step: 47-634 -- Loss: 0.16864806413650513
val-epoch-step: 47-635 -- Loss: 0.11344031989574432
val-epoch-step: 47-636 -- Loss: 0.1621091067790985
val-epoch-step: 47-637 -- Loss: 0.18612778186798096
val-epoch-step: 47-638 -- Loss: 0.1448325663805008
val-epoch-step: 47-639 -- Loss: 0.2593708634376526
val-epoch-step: 47-640 -- Loss: 0.2529473602771759
val-epoch-step: 47-641 -- Loss: 0.12246911227703094
val-epoch-step: 47-642 -- Loss: 0.17770133912563324
val-epoch-step: 47-643 -- Loss: 0.20874200761318207
val-epoch-step: 47-644 -- Loss: 0.16274772584438324
val-epoch-step: 47-645 -- Loss: 0.21926596760749817
val-epoch-step: 47-646 -- Loss: 0.13436314463615417
val-epoch-step: 47-647 -- Loss: 0.12775924801826477
val-epoch-step: 47-648 -- Loss: 0.15672078728675842
val-epoch-step: 47-649 -- Loss: 0.207719087600708
val-epoch-step: 47-650 -- Loss: 0.24907083809375763
val-epoch-step: 47-651 -- Loss: 0.1467776596546173
val-epoch-step: 47-652 -- Loss: 0.15656238794326782
val-epoch-step: 47-653 -- Loss: 0.20404726266860962
val-epoch-step: 47-654 -- Loss: 0.1143953874707222
Epoch: 47 -- Train Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 48-0 -- Loss: 0.22117546200752258
train-epoch-step: 48-1 -- Loss: 0.14028671383857727
train-epoch-step: 48-2 -- Loss: 0.19406558573246002
train-epoch-step: 48-3 -- Loss: 0.14098870754241943
train-epoch-step: 48-4 -- Loss: 0.15115320682525635
train-epoch-step: 48-5 -- Loss: 0.1803855448961258
train-epoch-step: 48-6 -- Loss: 0.21107910573482513
train-epoch-step: 48-7 -- Loss: 0.16714641451835632
train-epoch-step: 48-8 -- Loss: 0.176727294921875
train-epoch-step: 48-9 -- Loss: 0.215836763381958
train-epoch-step: 48-10 -- Loss: 0.20279034972190857
train-epoch-step: 48-11 -- Loss: 0.17423276603221893
train-epoch-step: 48-12 -- Loss: 0.14690758287906647
train-epoch-step: 48-13 -- Loss: 0.17219822108745575
train-epoch-step: 48-14 -- Loss: 0.16427496075630188
train-epoch-step: 48-15 -- Loss: 0.16093342006206512
train-epoch-step: 48-16 -- Loss: 0.1624932885169983
train-epoch-step: 48-17 -- Loss: 0.21671725809574127
train-epoch-step: 48-18 -- Loss: 0.19171717762947083
train-epoch-step: 48-19 -- Loss: 0.12968799471855164
train-epoch-step: 48-20 -- Loss: 0.21334578096866608
train-epoch-step: 48-21 -- Loss: 0.24720029532909393
train-epoch-step: 48-22 -- Loss: 0.13850094377994537
train-epoch-step: 48-23 -- Loss: 0.13825684785842896
train-epoch-step: 48-24 -- Loss: 0.12437070906162262
train-epoch-step: 48-25 -- Loss: 0.21621271967887878
train-epoch-step: 48-26 -- Loss: 0.18835094571113586
train-epoch-step: 48-27 -- Loss: 0.22587838768959045
train-epoch-step: 48-28 -- Loss: 0.12110110372304916
train-epoch-step: 48-29 -- Loss: 0.23943975567817688
train-epoch-step: 48-30 -- Loss: 0.11146797984838486
train-epoch-step: 48-31 -- Loss: 0.13079290091991425
train-epoch-step: 48-32 -- Loss: 0.1695970743894577
train-epoch-step: 48-33 -- Loss: 0.26225337386131287
train-epoch-step: 48-34 -- Loss: 0.16323024034500122
train-epoch-step: 48-35 -- Loss: 0.2317078709602356
train-epoch-step: 48-36 -- Loss: 0.13353268802165985
train-epoch-step: 48-37 -- Loss: 0.1354418247938156
train-epoch-step: 48-38 -- Loss: 0.16817304491996765
train-epoch-step: 48-39 -- Loss: 0.21632224321365356
train-epoch-step: 48-40 -- Loss: 0.19737961888313293
train-epoch-step: 48-41 -- Loss: 0.20738238096237183
train-epoch-step: 48-42 -- Loss: 0.1453237235546112
train-epoch-step: 48-43 -- Loss: 0.25949448347091675
train-epoch-step: 48-44 -- Loss: 0.1228005439043045
train-epoch-step: 48-45 -- Loss: 0.11316794157028198
train-epoch-step: 48-46 -- Loss: 0.16914823651313782
train-epoch-step: 48-47 -- Loss: 0.1987558901309967
train-epoch-step: 48-48 -- Loss: 0.15084874629974365
train-epoch-step: 48-49 -- Loss: 0.21630126237869263
train-epoch-step: 48-50 -- Loss: 0.10831733047962189
train-epoch-step: 48-51 -- Loss: 0.1787312626838684
train-epoch-step: 48-52 -- Loss: 0.15589234232902527
train-epoch-step: 48-53 -- Loss: 0.20410670340061188
train-epoch-step: 48-54 -- Loss: 0.2852902114391327
train-epoch-step: 48-55 -- Loss: 0.16480126976966858
train-epoch-step: 48-56 -- Loss: 0.17252182960510254
train-epoch-step: 48-57 -- Loss: 0.23030339181423187
train-epoch-step: 48-58 -- Loss: 0.2770511209964752
train-epoch-step: 48-59 -- Loss: 0.22811725735664368
train-epoch-step: 48-60 -- Loss: 0.12571746110916138
train-epoch-step: 48-61 -- Loss: 0.19336476922035217
train-epoch-step: 48-62 -- Loss: 0.18078017234802246
train-epoch-step: 48-63 -- Loss: 0.13940833508968353
train-epoch-step: 48-64 -- Loss: 0.1374286413192749
train-epoch-step: 48-65 -- Loss: 0.18038839101791382
train-epoch-step: 48-66 -- Loss: 0.10585829615592957
train-epoch-step: 48-67 -- Loss: 0.12226902693510056
train-epoch-step: 48-68 -- Loss: 0.21146106719970703
train-epoch-step: 48-69 -- Loss: 0.12120260298252106
train-epoch-step: 48-70 -- Loss: 0.2203495353460312
train-epoch-step: 48-71 -- Loss: 0.25392213463783264
train-epoch-step: 48-72 -- Loss: 0.1714642345905304
train-epoch-step: 48-73 -- Loss: 0.20354971289634705
train-epoch-step: 48-74 -- Loss: 0.09406866878271103
train-epoch-step: 48-75 -- Loss: 0.12346826493740082
train-epoch-step: 48-76 -- Loss: 0.1469508409500122
train-epoch-step: 48-77 -- Loss: 0.2224498987197876
train-epoch-step: 48-78 -- Loss: 0.24775180220603943
train-epoch-step: 48-79 -- Loss: 0.18478591740131378
train-epoch-step: 48-80 -- Loss: 0.25728410482406616
train-epoch-step: 48-81 -- Loss: 0.12579476833343506
train-epoch-step: 48-82 -- Loss: 0.24787630140781403
train-epoch-step: 48-83 -- Loss: 0.174555703997612
train-epoch-step: 48-84 -- Loss: 0.19281157851219177
train-epoch-step: 48-85 -- Loss: 0.17474402487277985
train-epoch-step: 48-86 -- Loss: 0.11857379972934723
train-epoch-step: 48-87 -- Loss: 0.21345075964927673
train-epoch-step: 48-88 -- Loss: 0.13682401180267334
train-epoch-step: 48-89 -- Loss: 0.1814134418964386
train-epoch-step: 48-90 -- Loss: 0.18878784775733948
train-epoch-step: 48-91 -- Loss: 0.23997126519680023
train-epoch-step: 48-92 -- Loss: 0.15130352973937988
train-epoch-step: 48-93 -- Loss: 0.1699417680501938
train-epoch-step: 48-94 -- Loss: 0.2174576371908188
train-epoch-step: 48-95 -- Loss: 0.18920481204986572
train-epoch-step: 48-96 -- Loss: 0.21312083303928375
train-epoch-step: 48-97 -- Loss: 0.1755237877368927
train-epoch-step: 48-98 -- Loss: 0.15271523594856262
train-epoch-step: 48-99 -- Loss: 0.17996664345264435
train-epoch-step: 48-100 -- Loss: 0.18588130176067352
train-epoch-step: 48-101 -- Loss: 0.25585511326789856
train-epoch-step: 48-102 -- Loss: 0.21925675868988037
train-epoch-step: 48-103 -- Loss: 0.18323731422424316
train-epoch-step: 48-104 -- Loss: 0.14823082089424133
train-epoch-step: 48-105 -- Loss: 0.26355376839637756
train-epoch-step: 48-106 -- Loss: 0.17690818011760712
train-epoch-step: 48-107 -- Loss: 0.18646469712257385
train-epoch-step: 48-108 -- Loss: 0.18210431933403015
train-epoch-step: 48-109 -- Loss: 0.1406097412109375
train-epoch-step: 48-110 -- Loss: 0.17828907072544098
train-epoch-step: 48-111 -- Loss: 0.17725175619125366
train-epoch-step: 48-112 -- Loss: 0.16163313388824463
train-epoch-step: 48-113 -- Loss: 0.15725429356098175
train-epoch-step: 48-114 -- Loss: 0.19315555691719055
train-epoch-step: 48-115 -- Loss: 0.1566951870918274
train-epoch-step: 48-116 -- Loss: 0.1391059309244156
train-epoch-step: 48-117 -- Loss: 0.12721459567546844
train-epoch-step: 48-118 -- Loss: 0.19153423607349396
train-epoch-step: 48-119 -- Loss: 0.1490030437707901
train-epoch-step: 48-120 -- Loss: 0.24219998717308044
train-epoch-step: 48-121 -- Loss: 0.23172251880168915
train-epoch-step: 48-122 -- Loss: 0.20624172687530518
train-epoch-step: 48-123 -- Loss: 0.202264204621315
train-epoch-step: 48-124 -- Loss: 0.12131613492965698
train-epoch-step: 48-125 -- Loss: 0.15261289477348328
train-epoch-step: 48-126 -- Loss: 0.2197333723306656
train-epoch-step: 48-127 -- Loss: 0.16601616144180298
train-epoch-step: 48-128 -- Loss: 0.16645438969135284
train-epoch-step: 48-129 -- Loss: 0.13731378316879272
train-epoch-step: 48-130 -- Loss: 0.18665000796318054
train-epoch-step: 48-131 -- Loss: 0.13399769365787506
train-epoch-step: 48-132 -- Loss: 0.1836307942867279
train-epoch-step: 48-133 -- Loss: 0.11070495843887329
train-epoch-step: 48-134 -- Loss: 0.19041074812412262
train-epoch-step: 48-135 -- Loss: 0.13007521629333496
train-epoch-step: 48-136 -- Loss: 0.12217660248279572
train-epoch-step: 48-137 -- Loss: 0.2386743277311325
train-epoch-step: 48-138 -- Loss: 0.25012725591659546
train-epoch-step: 48-139 -- Loss: 0.12736093997955322
train-epoch-step: 48-140 -- Loss: 0.20287258923053741
train-epoch-step: 48-141 -- Loss: 0.21856464445590973
train-epoch-step: 48-142 -- Loss: 0.19632607698440552
train-epoch-step: 48-143 -- Loss: 0.16785749793052673
train-epoch-step: 48-144 -- Loss: 0.18379110097885132
train-epoch-step: 48-145 -- Loss: 0.13584575057029724
train-epoch-step: 48-146 -- Loss: 0.17791062593460083
train-epoch-step: 48-147 -- Loss: 0.16451069712638855
train-epoch-step: 48-148 -- Loss: 0.15353812277317047
train-epoch-step: 48-149 -- Loss: 0.11732157319784164
train-epoch-step: 48-150 -- Loss: 0.18211710453033447
train-epoch-step: 48-151 -- Loss: 0.18613086640834808
train-epoch-step: 48-152 -- Loss: 0.18665975332260132
train-epoch-step: 48-153 -- Loss: 0.2658624053001404
train-epoch-step: 48-154 -- Loss: 0.12896664440631866
train-epoch-step: 48-155 -- Loss: 0.13418808579444885
train-epoch-step: 48-156 -- Loss: 0.11522823572158813
train-epoch-step: 48-157 -- Loss: 0.16247716546058655
train-epoch-step: 48-158 -- Loss: 0.16322316229343414
train-epoch-step: 48-159 -- Loss: 0.1734049767255783
train-epoch-step: 48-160 -- Loss: 0.20487914979457855
train-epoch-step: 48-161 -- Loss: 0.20451276004314423
train-epoch-step: 48-162 -- Loss: 0.20858082175254822
train-epoch-step: 48-163 -- Loss: 0.18296514451503754
train-epoch-step: 48-164 -- Loss: 0.18857210874557495
train-epoch-step: 48-165 -- Loss: 0.15976940095424652
train-epoch-step: 48-166 -- Loss: 0.11699403077363968
train-epoch-step: 48-167 -- Loss: 0.12171894311904907
train-epoch-step: 48-168 -- Loss: 0.1941118985414505
train-epoch-step: 48-169 -- Loss: 0.13326393067836761
train-epoch-step: 48-170 -- Loss: 0.2004726678133011
train-epoch-step: 48-171 -- Loss: 0.1398368775844574
train-epoch-step: 48-172 -- Loss: 0.25597870349884033
train-epoch-step: 48-173 -- Loss: 0.12444864958524704
train-epoch-step: 48-174 -- Loss: 0.24007266759872437
train-epoch-step: 48-175 -- Loss: 0.18546119332313538
train-epoch-step: 48-176 -- Loss: 0.12909185886383057
train-epoch-step: 48-177 -- Loss: 0.17858342826366425
train-epoch-step: 48-178 -- Loss: 0.17364130914211273
train-epoch-step: 48-179 -- Loss: 0.1492467224597931
train-epoch-step: 48-180 -- Loss: 0.14718709886074066
train-epoch-step: 48-181 -- Loss: 0.1650688350200653
train-epoch-step: 48-182 -- Loss: 0.1797165721654892
train-epoch-step: 48-183 -- Loss: 0.26509565114974976
train-epoch-step: 48-184 -- Loss: 0.13714699447155
train-epoch-step: 48-185 -- Loss: 0.14149530231952667
train-epoch-step: 48-186 -- Loss: 0.18105334043502808
train-epoch-step: 48-187 -- Loss: 0.2027977705001831
train-epoch-step: 48-188 -- Loss: 0.17022624611854553
train-epoch-step: 48-189 -- Loss: 0.10161574184894562
train-epoch-step: 48-190 -- Loss: 0.1768539547920227
train-epoch-step: 48-191 -- Loss: 0.15194377303123474
train-epoch-step: 48-192 -- Loss: 0.2256809026002884
train-epoch-step: 48-193 -- Loss: 0.19532936811447144
train-epoch-step: 48-194 -- Loss: 0.17967742681503296
train-epoch-step: 48-195 -- Loss: 0.16210849583148956
train-epoch-step: 48-196 -- Loss: 0.16457244753837585
train-epoch-step: 48-197 -- Loss: 0.12225930392742157
train-epoch-step: 48-198 -- Loss: 0.12551215291023254
train-epoch-step: 48-199 -- Loss: 0.14641492068767548
train-epoch-step: 48-200 -- Loss: 0.12317802011966705
train-epoch-step: 48-201 -- Loss: 0.18504826724529266
train-epoch-step: 48-202 -- Loss: 0.13340851664543152
train-epoch-step: 48-203 -- Loss: 0.17038489878177643
train-epoch-step: 48-204 -- Loss: 0.13244888186454773
train-epoch-step: 48-205 -- Loss: 0.17838838696479797
train-epoch-step: 48-206 -- Loss: 0.19549356400966644
train-epoch-step: 48-207 -- Loss: 0.12875767052173615
train-epoch-step: 48-208 -- Loss: 0.1752847135066986
train-epoch-step: 48-209 -- Loss: 0.14072808623313904
train-epoch-step: 48-210 -- Loss: 0.12718753516674042
train-epoch-step: 48-211 -- Loss: 0.20355600118637085
train-epoch-step: 48-212 -- Loss: 0.18929782509803772
train-epoch-step: 48-213 -- Loss: 0.12691538035869598
train-epoch-step: 48-214 -- Loss: 0.14293493330478668
train-epoch-step: 48-215 -- Loss: 0.12605364620685577
train-epoch-step: 48-216 -- Loss: 0.20096461474895477
train-epoch-step: 48-217 -- Loss: 0.21057479083538055
train-epoch-step: 48-218 -- Loss: 0.14381413161754608
train-epoch-step: 48-219 -- Loss: 0.1700381189584732
train-epoch-step: 48-220 -- Loss: 0.1274329423904419
train-epoch-step: 48-221 -- Loss: 0.199778214097023
train-epoch-step: 48-222 -- Loss: 0.11705712974071503
train-epoch-step: 48-223 -- Loss: 0.16775622963905334
train-epoch-step: 48-224 -- Loss: 0.18099075555801392
train-epoch-step: 48-225 -- Loss: 0.26337435841560364
train-epoch-step: 48-226 -- Loss: 0.20656663179397583
train-epoch-step: 48-227 -- Loss: 0.21653738617897034
train-epoch-step: 48-228 -- Loss: 0.17565608024597168
train-epoch-step: 48-229 -- Loss: 0.16753599047660828
train-epoch-step: 48-230 -- Loss: 0.1638018786907196
train-epoch-step: 48-231 -- Loss: 0.1523190140724182
train-epoch-step: 48-232 -- Loss: 0.18411949276924133
train-epoch-step: 48-233 -- Loss: 0.08127918839454651
train-epoch-step: 48-234 -- Loss: 0.1725127100944519
train-epoch-step: 48-235 -- Loss: 0.14883661270141602
train-epoch-step: 48-236 -- Loss: 0.17848294973373413
train-epoch-step: 48-237 -- Loss: 0.23199890553951263
train-epoch-step: 48-238 -- Loss: 0.15597102046012878
train-epoch-step: 48-239 -- Loss: 0.12593594193458557
train-epoch-step: 48-240 -- Loss: 0.2190542370080948
train-epoch-step: 48-241 -- Loss: 0.15034893155097961
train-epoch-step: 48-242 -- Loss: 0.21546457707881927
train-epoch-step: 48-243 -- Loss: 0.23251022398471832
train-epoch-step: 48-244 -- Loss: 0.20466230809688568
train-epoch-step: 48-245 -- Loss: 0.2024264633655548
train-epoch-step: 48-246 -- Loss: 0.21733340620994568
train-epoch-step: 48-247 -- Loss: 0.20397955179214478
train-epoch-step: 48-248 -- Loss: 0.1782478541135788
train-epoch-step: 48-249 -- Loss: 0.13302555680274963
train-epoch-step: 48-250 -- Loss: 0.19437167048454285
train-epoch-step: 48-251 -- Loss: 0.10563112050294876
train-epoch-step: 48-252 -- Loss: 0.18356585502624512
train-epoch-step: 48-253 -- Loss: 0.13511769473552704
train-epoch-step: 48-254 -- Loss: 0.20663313567638397
train-epoch-step: 48-255 -- Loss: 0.14274659752845764
train-epoch-step: 48-256 -- Loss: 0.14281333982944489
train-epoch-step: 48-257 -- Loss: 0.18835298717021942
train-epoch-step: 48-258 -- Loss: 0.14193099737167358
train-epoch-step: 48-259 -- Loss: 0.1142733246088028
train-epoch-step: 48-260 -- Loss: 0.20096048712730408
train-epoch-step: 48-261 -- Loss: 0.1684742420911789
train-epoch-step: 48-262 -- Loss: 0.2765108346939087
train-epoch-step: 48-263 -- Loss: 0.19165116548538208
train-epoch-step: 48-264 -- Loss: 0.1697247326374054
train-epoch-step: 48-265 -- Loss: 0.10613884776830673
train-epoch-step: 48-266 -- Loss: 0.15273936092853546
train-epoch-step: 48-267 -- Loss: 0.12638820707798004
train-epoch-step: 48-268 -- Loss: 0.11623597145080566
train-epoch-step: 48-269 -- Loss: 0.16679581999778748
train-epoch-step: 48-270 -- Loss: 0.10586916655302048
train-epoch-step: 48-271 -- Loss: 0.14343705773353577
train-epoch-step: 48-272 -- Loss: 0.11043598502874374
train-epoch-step: 48-273 -- Loss: 0.12471850216388702
train-epoch-step: 48-274 -- Loss: 0.17555180191993713
train-epoch-step: 48-275 -- Loss: 0.1935403048992157
train-epoch-step: 48-276 -- Loss: 0.1541798859834671
train-epoch-step: 48-277 -- Loss: 0.1531004160642624
train-epoch-step: 48-278 -- Loss: 0.13377074897289276
train-epoch-step: 48-279 -- Loss: 0.13834701478481293
train-epoch-step: 48-280 -- Loss: 0.21014420688152313
train-epoch-step: 48-281 -- Loss: 0.17659717798233032
train-epoch-step: 48-282 -- Loss: 0.1380288153886795
train-epoch-step: 48-283 -- Loss: 0.1119951382279396
train-epoch-step: 48-284 -- Loss: 0.1343655288219452
train-epoch-step: 48-285 -- Loss: 0.1836654245853424
train-epoch-step: 48-286 -- Loss: 0.14995524287223816
train-epoch-step: 48-287 -- Loss: 0.19814158976078033
train-epoch-step: 48-288 -- Loss: 0.09157047420740128
train-epoch-step: 48-289 -- Loss: 0.12329450249671936
train-epoch-step: 48-290 -- Loss: 0.17400172352790833
train-epoch-step: 48-291 -- Loss: 0.11400853097438812
train-epoch-step: 48-292 -- Loss: 0.15319891273975372
train-epoch-step: 48-293 -- Loss: 0.1348186731338501
train-epoch-step: 48-294 -- Loss: 0.1565023958683014
train-epoch-step: 48-295 -- Loss: 0.25834566354751587
train-epoch-step: 48-296 -- Loss: 0.1591469794511795
train-epoch-step: 48-297 -- Loss: 0.1687469482421875
train-epoch-step: 48-298 -- Loss: 0.22378194332122803
train-epoch-step: 48-299 -- Loss: 0.14163769781589508
train-epoch-step: 48-300 -- Loss: 0.15792064368724823
train-epoch-step: 48-301 -- Loss: 0.1708182692527771
train-epoch-step: 48-302 -- Loss: 0.20975248515605927
train-epoch-step: 48-303 -- Loss: 0.19869953393936157
train-epoch-step: 48-304 -- Loss: 0.12059834599494934
train-epoch-step: 48-305 -- Loss: 0.1408577412366867
train-epoch-step: 48-306 -- Loss: 0.2107340395450592
train-epoch-step: 48-307 -- Loss: 0.16195203363895416
train-epoch-step: 48-308 -- Loss: 0.20799928903579712
train-epoch-step: 48-309 -- Loss: 0.15042832493782043
train-epoch-step: 48-310 -- Loss: 0.16162782907485962
train-epoch-step: 48-311 -- Loss: 0.15219272673130035
train-epoch-step: 48-312 -- Loss: 0.19943895936012268
train-epoch-step: 48-313 -- Loss: 0.09640687704086304
train-epoch-step: 48-314 -- Loss: 0.1894133985042572
train-epoch-step: 48-315 -- Loss: 0.16375280916690826
train-epoch-step: 48-316 -- Loss: 0.15392595529556274
train-epoch-step: 48-317 -- Loss: 0.1339375525712967
train-epoch-step: 48-318 -- Loss: 0.15189658105373383
train-epoch-step: 48-319 -- Loss: 0.15999835729599
train-epoch-step: 48-320 -- Loss: 0.1161201000213623
train-epoch-step: 48-321 -- Loss: 0.12674131989479065
train-epoch-step: 48-322 -- Loss: 0.20513516664505005
train-epoch-step: 48-323 -- Loss: 0.15648163855075836
train-epoch-step: 48-324 -- Loss: 0.25225234031677246
train-epoch-step: 48-325 -- Loss: 0.1475813239812851
train-epoch-step: 48-326 -- Loss: 0.16349001228809357
train-epoch-step: 48-327 -- Loss: 0.2025943547487259
train-epoch-step: 48-328 -- Loss: 0.1894887536764145
train-epoch-step: 48-329 -- Loss: 0.3342585563659668
train-epoch-step: 48-330 -- Loss: 0.3534466326236725
train-epoch-step: 48-331 -- Loss: 0.20417383313179016
train-epoch-step: 48-332 -- Loss: 0.0951378121972084
train-epoch-step: 48-333 -- Loss: 0.17739221453666687
train-epoch-step: 48-334 -- Loss: 0.14898189902305603
train-epoch-step: 48-335 -- Loss: 0.17083662748336792
train-epoch-step: 48-336 -- Loss: 0.14700835943222046
train-epoch-step: 48-337 -- Loss: 0.19849690794944763
train-epoch-step: 48-338 -- Loss: 0.1521383374929428
train-epoch-step: 48-339 -- Loss: 0.14034314453601837
train-epoch-step: 48-340 -- Loss: 0.1956632286310196
train-epoch-step: 48-341 -- Loss: 0.13673749566078186
train-epoch-step: 48-342 -- Loss: 0.15751062333583832
train-epoch-step: 48-343 -- Loss: 0.15173669159412384
train-epoch-step: 48-344 -- Loss: 0.16161344945430756
train-epoch-step: 48-345 -- Loss: 0.13358569145202637
train-epoch-step: 48-346 -- Loss: 0.19544866681098938
train-epoch-step: 48-347 -- Loss: 0.14946779608726501
train-epoch-step: 48-348 -- Loss: 0.2075466811656952
train-epoch-step: 48-349 -- Loss: 0.2031082659959793
train-epoch-step: 48-350 -- Loss: 0.24438485503196716
train-epoch-step: 48-351 -- Loss: 0.1882273256778717
train-epoch-step: 48-352 -- Loss: 0.12122759968042374
train-epoch-step: 48-353 -- Loss: 0.18455290794372559
train-epoch-step: 48-354 -- Loss: 0.2746793329715729
train-epoch-step: 48-355 -- Loss: 0.11632019281387329
train-epoch-step: 48-356 -- Loss: 0.11292935162782669
train-epoch-step: 48-357 -- Loss: 0.18794633448123932
train-epoch-step: 48-358 -- Loss: 0.1803363561630249
train-epoch-step: 48-359 -- Loss: 0.13796736299991608
train-epoch-step: 48-360 -- Loss: 0.12047684192657471
train-epoch-step: 48-361 -- Loss: 0.23727791011333466
train-epoch-step: 48-362 -- Loss: 0.16646158695220947
train-epoch-step: 48-363 -- Loss: 0.10880537331104279
train-epoch-step: 48-364 -- Loss: 0.17603440582752228
train-epoch-step: 48-365 -- Loss: 0.1696677953004837
train-epoch-step: 48-366 -- Loss: 0.20026247203350067
train-epoch-step: 48-367 -- Loss: 0.23211508989334106
train-epoch-step: 48-368 -- Loss: 0.19513152539730072
train-epoch-step: 48-369 -- Loss: 0.28221073746681213
train-epoch-step: 48-370 -- Loss: 0.12315240502357483
train-epoch-step: 48-371 -- Loss: 0.11805076152086258
train-epoch-step: 48-372 -- Loss: 0.14388374984264374
train-epoch-step: 48-373 -- Loss: 0.18441513180732727
train-epoch-step: 48-374 -- Loss: 0.15093523263931274
train-epoch-step: 48-375 -- Loss: 0.26393449306488037
train-epoch-step: 48-376 -- Loss: 0.1602657586336136
train-epoch-step: 48-377 -- Loss: 0.22725892066955566
train-epoch-step: 48-378 -- Loss: 0.19702328741550446
train-epoch-step: 48-379 -- Loss: 0.11552605032920837
train-epoch-step: 48-380 -- Loss: 0.0910683423280716
train-epoch-step: 48-381 -- Loss: 0.2390889823436737
train-epoch-step: 48-382 -- Loss: 0.2282819002866745
train-epoch-step: 48-383 -- Loss: 0.17467422783374786
train-epoch-step: 48-384 -- Loss: 0.21963950991630554
train-epoch-step: 48-385 -- Loss: 0.19291500747203827
train-epoch-step: 48-386 -- Loss: 0.1841454803943634
train-epoch-step: 48-387 -- Loss: 0.19381661713123322
train-epoch-step: 48-388 -- Loss: 0.19001655280590057
train-epoch-step: 48-389 -- Loss: 0.163370281457901
train-epoch-step: 48-390 -- Loss: 0.1429937332868576
train-epoch-step: 48-391 -- Loss: 0.1441018134355545
train-epoch-step: 48-392 -- Loss: 0.18029846251010895
train-epoch-step: 48-393 -- Loss: 0.1572961062192917
train-epoch-step: 48-394 -- Loss: 0.19711022078990936
train-epoch-step: 48-395 -- Loss: 0.1545531451702118
train-epoch-step: 48-396 -- Loss: 0.12381806969642639
train-epoch-step: 48-397 -- Loss: 0.12418120354413986
train-epoch-step: 48-398 -- Loss: 0.1991114318370819
train-epoch-step: 48-399 -- Loss: 0.17431628704071045
train-epoch-step: 48-400 -- Loss: 0.26690933108329773
train-epoch-step: 48-401 -- Loss: 0.12493764609098434
train-epoch-step: 48-402 -- Loss: 0.25170159339904785
train-epoch-step: 48-403 -- Loss: 0.14966514706611633
train-epoch-step: 48-404 -- Loss: 0.13506387174129486
train-epoch-step: 48-405 -- Loss: 0.14040209352970123
train-epoch-step: 48-406 -- Loss: 0.1629471629858017
train-epoch-step: 48-407 -- Loss: 0.11079614609479904
train-epoch-step: 48-408 -- Loss: 0.15759658813476562
train-epoch-step: 48-409 -- Loss: 0.17218634486198425
train-epoch-step: 48-410 -- Loss: 0.16998863220214844
train-epoch-step: 48-411 -- Loss: 0.19718235731124878
train-epoch-step: 48-412 -- Loss: 0.12696565687656403
train-epoch-step: 48-413 -- Loss: 0.1455305516719818
train-epoch-step: 48-414 -- Loss: 0.13149015605449677
train-epoch-step: 48-415 -- Loss: 0.1400892734527588
train-epoch-step: 48-416 -- Loss: 0.2604098320007324
train-epoch-step: 48-417 -- Loss: 0.18855853378772736
train-epoch-step: 48-418 -- Loss: 0.238692045211792
train-epoch-step: 48-419 -- Loss: 0.16522252559661865
train-epoch-step: 48-420 -- Loss: 0.15000741183757782
train-epoch-step: 48-421 -- Loss: 0.17310330271720886
train-epoch-step: 48-422 -- Loss: 0.14594309031963348
train-epoch-step: 48-423 -- Loss: 0.17976543307304382
train-epoch-step: 48-424 -- Loss: 0.13492071628570557
train-epoch-step: 48-425 -- Loss: 0.17837391793727875
train-epoch-step: 48-426 -- Loss: 0.16042396426200867
train-epoch-step: 48-427 -- Loss: 0.1797509342432022
train-epoch-step: 48-428 -- Loss: 0.18751093745231628
train-epoch-step: 48-429 -- Loss: 0.1741679310798645
train-epoch-step: 48-430 -- Loss: 0.14153417944908142
train-epoch-step: 48-431 -- Loss: 0.16030816733837128
train-epoch-step: 48-432 -- Loss: 0.23854036629199982
train-epoch-step: 48-433 -- Loss: 0.14004020392894745
train-epoch-step: 48-434 -- Loss: 0.12952202558517456
train-epoch-step: 48-435 -- Loss: 0.15930689871311188
train-epoch-step: 48-436 -- Loss: 0.1516813337802887
train-epoch-step: 48-437 -- Loss: 0.1453062891960144
train-epoch-step: 48-438 -- Loss: 0.20844760537147522
train-epoch-step: 48-439 -- Loss: 0.27288711071014404
train-epoch-step: 48-440 -- Loss: 0.131344273686409
train-epoch-step: 48-441 -- Loss: 0.212284117937088
train-epoch-step: 48-442 -- Loss: 0.17333298921585083
train-epoch-step: 48-443 -- Loss: 0.15777233242988586
train-epoch-step: 48-444 -- Loss: 0.17657557129859924
train-epoch-step: 48-445 -- Loss: 0.21367760002613068
train-epoch-step: 48-446 -- Loss: 0.17933756113052368
train-epoch-step: 48-447 -- Loss: 0.2028888314962387
train-epoch-step: 48-448 -- Loss: 0.23163479566574097
train-epoch-step: 48-449 -- Loss: 0.1977580487728119
train-epoch-step: 48-450 -- Loss: 0.1840459555387497
train-epoch-step: 48-451 -- Loss: 0.15336225926876068
train-epoch-step: 48-452 -- Loss: 0.132249116897583
train-epoch-step: 48-453 -- Loss: 0.10116191953420639
train-epoch-step: 48-454 -- Loss: 0.23048542439937592
train-epoch-step: 48-455 -- Loss: 0.12096858769655228
train-epoch-step: 48-456 -- Loss: 0.12351994216442108
train-epoch-step: 48-457 -- Loss: 0.22249452769756317
train-epoch-step: 48-458 -- Loss: 0.17171916365623474
train-epoch-step: 48-459 -- Loss: 0.21712687611579895
train-epoch-step: 48-460 -- Loss: 0.12995083630084991
train-epoch-step: 48-461 -- Loss: 0.13529092073440552
train-epoch-step: 48-462 -- Loss: 0.160204216837883
train-epoch-step: 48-463 -- Loss: 0.1355293095111847
train-epoch-step: 48-464 -- Loss: 0.1682252436876297
train-epoch-step: 48-465 -- Loss: 0.24545398354530334
train-epoch-step: 48-466 -- Loss: 0.20220611989498138
train-epoch-step: 48-467 -- Loss: 0.11854208260774612
train-epoch-step: 48-468 -- Loss: 0.16210395097732544
train-epoch-step: 48-469 -- Loss: 0.21234075725078583
train-epoch-step: 48-470 -- Loss: 0.17205043137073517
train-epoch-step: 48-471 -- Loss: 0.15526597201824188
train-epoch-step: 48-472 -- Loss: 0.16077065467834473
train-epoch-step: 48-473 -- Loss: 0.15046261250972748
train-epoch-step: 48-474 -- Loss: 0.11628341674804688
train-epoch-step: 48-475 -- Loss: 0.10969586670398712
train-epoch-step: 48-476 -- Loss: 0.19534872472286224
train-epoch-step: 48-477 -- Loss: 0.20998218655586243
train-epoch-step: 48-478 -- Loss: 0.1896999329328537
train-epoch-step: 48-479 -- Loss: 0.13830937445163727
train-epoch-step: 48-480 -- Loss: 0.19290784001350403
train-epoch-step: 48-481 -- Loss: 0.2786615490913391
train-epoch-step: 48-482 -- Loss: 0.2445710003376007
train-epoch-step: 48-483 -- Loss: 0.17507244646549225
train-epoch-step: 48-484 -- Loss: 0.20723956823349
train-epoch-step: 48-485 -- Loss: 0.12675872445106506
train-epoch-step: 48-486 -- Loss: 0.23766297101974487
train-epoch-step: 48-487 -- Loss: 0.23218506574630737
train-epoch-step: 48-488 -- Loss: 0.19667552411556244
train-epoch-step: 48-489 -- Loss: 0.21962791681289673
train-epoch-step: 48-490 -- Loss: 0.1387988030910492
train-epoch-step: 48-491 -- Loss: 0.13374388217926025
train-epoch-step: 48-492 -- Loss: 0.12478236854076385
train-epoch-step: 48-493 -- Loss: 0.2186512053012848
train-epoch-step: 48-494 -- Loss: 0.2017991840839386
train-epoch-step: 48-495 -- Loss: 0.19831697642803192
train-epoch-step: 48-496 -- Loss: 0.13817939162254333
train-epoch-step: 48-497 -- Loss: 0.18614009022712708
train-epoch-step: 48-498 -- Loss: 0.1465183049440384
train-epoch-step: 48-499 -- Loss: 0.16317099332809448
train-epoch-step: 48-500 -- Loss: 0.15526406466960907
train-epoch-step: 48-501 -- Loss: 0.21039003133773804
train-epoch-step: 48-502 -- Loss: 0.14922179281711578
train-epoch-step: 48-503 -- Loss: 0.23068073391914368
train-epoch-step: 48-504 -- Loss: 0.11908720433712006
train-epoch-step: 48-505 -- Loss: 0.16310778260231018
train-epoch-step: 48-506 -- Loss: 0.11486934125423431
train-epoch-step: 48-507 -- Loss: 0.18274152278900146
train-epoch-step: 48-508 -- Loss: 0.17269395291805267
train-epoch-step: 48-509 -- Loss: 0.16568371653556824
train-epoch-step: 48-510 -- Loss: 0.12412697076797485
train-epoch-step: 48-511 -- Loss: 0.21681086719036102
train-epoch-step: 48-512 -- Loss: 0.17549745738506317
train-epoch-step: 48-513 -- Loss: 0.1831219643354416
train-epoch-step: 48-514 -- Loss: 0.1438772976398468
train-epoch-step: 48-515 -- Loss: 0.15511202812194824
train-epoch-step: 48-516 -- Loss: 0.16630864143371582
train-epoch-step: 48-517 -- Loss: 0.1746216118335724
train-epoch-step: 48-518 -- Loss: 0.13615474104881287
train-epoch-step: 48-519 -- Loss: 0.131505087018013
train-epoch-step: 48-520 -- Loss: 0.1832990050315857
train-epoch-step: 48-521 -- Loss: 0.22149838507175446
train-epoch-step: 48-522 -- Loss: 0.17480309307575226
train-epoch-step: 48-523 -- Loss: 0.15284156799316406
train-epoch-step: 48-524 -- Loss: 0.16520828008651733
train-epoch-step: 48-525 -- Loss: 0.1877627819776535
train-epoch-step: 48-526 -- Loss: 0.12927591800689697
train-epoch-step: 48-527 -- Loss: 0.14863479137420654
train-epoch-step: 48-528 -- Loss: 0.15674109756946564
train-epoch-step: 48-529 -- Loss: 0.15241515636444092
train-epoch-step: 48-530 -- Loss: 0.19476568698883057
train-epoch-step: 48-531 -- Loss: 0.19172321259975433
train-epoch-step: 48-532 -- Loss: 0.16886627674102783
train-epoch-step: 48-533 -- Loss: 0.17419637739658356
train-epoch-step: 48-534 -- Loss: 0.12424053251743317
train-epoch-step: 48-535 -- Loss: 0.2444940209388733
train-epoch-step: 48-536 -- Loss: 0.15175071358680725
train-epoch-step: 48-537 -- Loss: 0.14377455413341522
train-epoch-step: 48-538 -- Loss: 0.1019432321190834
train-epoch-step: 48-539 -- Loss: 0.1791829615831375
train-epoch-step: 48-540 -- Loss: 0.13037343323230743
train-epoch-step: 48-541 -- Loss: 0.20806720852851868
train-epoch-step: 48-542 -- Loss: 0.21738818287849426
train-epoch-step: 48-543 -- Loss: 0.16798070073127747
train-epoch-step: 48-544 -- Loss: 0.2220488339662552
train-epoch-step: 48-545 -- Loss: 0.18697847425937653
train-epoch-step: 48-546 -- Loss: 0.2061821073293686
train-epoch-step: 48-547 -- Loss: 0.17616355419158936
train-epoch-step: 48-548 -- Loss: 0.08824106305837631
train-epoch-step: 48-549 -- Loss: 0.14460375905036926
train-epoch-step: 48-550 -- Loss: 0.1975185126066208
train-epoch-step: 48-551 -- Loss: 0.15491808950901031
train-epoch-step: 48-552 -- Loss: 0.12307003885507584
train-epoch-step: 48-553 -- Loss: 0.18336926400661469
train-epoch-step: 48-554 -- Loss: 0.18430620431900024
train-epoch-step: 48-555 -- Loss: 0.21052433550357819
train-epoch-step: 48-556 -- Loss: 0.14109393954277039
train-epoch-step: 48-557 -- Loss: 0.22779542207717896
train-epoch-step: 48-558 -- Loss: 0.22342735528945923
train-epoch-step: 48-559 -- Loss: 0.13476330041885376
train-epoch-step: 48-560 -- Loss: 0.19832049310207367
train-epoch-step: 48-561 -- Loss: 0.17694061994552612
train-epoch-step: 48-562 -- Loss: 0.15740622580051422
train-epoch-step: 48-563 -- Loss: 0.18107564747333527
train-epoch-step: 48-564 -- Loss: 0.10078790038824081
train-epoch-step: 48-565 -- Loss: 0.17915299534797668
train-epoch-step: 48-566 -- Loss: 0.1461697667837143
train-epoch-step: 48-567 -- Loss: 0.20714493095874786
train-epoch-step: 48-568 -- Loss: 0.15526063740253448
train-epoch-step: 48-569 -- Loss: 0.2374681681394577
train-epoch-step: 48-570 -- Loss: 0.16125375032424927
train-epoch-step: 48-571 -- Loss: 0.20925211906433105
train-epoch-step: 48-572 -- Loss: 0.22796472907066345
train-epoch-step: 48-573 -- Loss: 0.19420108199119568
train-epoch-step: 48-574 -- Loss: 0.24956542253494263
train-epoch-step: 48-575 -- Loss: 0.29072511196136475
train-epoch-step: 48-576 -- Loss: 0.11545948684215546
train-epoch-step: 48-577 -- Loss: 0.16036568582057953
train-epoch-step: 48-578 -- Loss: 0.2216617614030838
train-epoch-step: 48-579 -- Loss: 0.16519726812839508
train-epoch-step: 48-580 -- Loss: 0.16925883293151855
train-epoch-step: 48-581 -- Loss: 0.1361820101737976
train-epoch-step: 48-582 -- Loss: 0.1999378204345703
train-epoch-step: 48-583 -- Loss: 0.2129053771495819
train-epoch-step: 48-584 -- Loss: 0.1594099998474121
train-epoch-step: 48-585 -- Loss: 0.19061832129955292
train-epoch-step: 48-586 -- Loss: 0.25040119886398315
train-epoch-step: 48-587 -- Loss: 0.1561294049024582
train-epoch-step: 48-588 -- Loss: 0.1261359304189682
val-epoch-step: 48-589 -- Loss: 0.19838586449623108
val-epoch-step: 48-590 -- Loss: 0.1506352424621582
val-epoch-step: 48-591 -- Loss: 0.22919262945652008
val-epoch-step: 48-592 -- Loss: 0.1741660237312317
val-epoch-step: 48-593 -- Loss: 0.1959921419620514
val-epoch-step: 48-594 -- Loss: 0.4616391658782959
val-epoch-step: 48-595 -- Loss: 0.17519304156303406
val-epoch-step: 48-596 -- Loss: 0.19817978143692017
val-epoch-step: 48-597 -- Loss: 0.17537821829319
val-epoch-step: 48-598 -- Loss: 0.1651722937822342
val-epoch-step: 48-599 -- Loss: 0.18075765669345856
val-epoch-step: 48-600 -- Loss: 0.1761643886566162
val-epoch-step: 48-601 -- Loss: 0.16185757517814636
val-epoch-step: 48-602 -- Loss: 0.13647577166557312
val-epoch-step: 48-603 -- Loss: 0.19989390671253204
val-epoch-step: 48-604 -- Loss: 0.14858490228652954
val-epoch-step: 48-605 -- Loss: 0.14568689465522766
val-epoch-step: 48-606 -- Loss: 0.2712913751602173
val-epoch-step: 48-607 -- Loss: 0.13342106342315674
val-epoch-step: 48-608 -- Loss: 0.24414972960948944
val-epoch-step: 48-609 -- Loss: 0.15915480256080627
val-epoch-step: 48-610 -- Loss: 0.17546150088310242
val-epoch-step: 48-611 -- Loss: 0.1629396378993988
val-epoch-step: 48-612 -- Loss: 0.47217023372650146
val-epoch-step: 48-613 -- Loss: 0.1749260574579239
val-epoch-step: 48-614 -- Loss: 0.16344377398490906
val-epoch-step: 48-615 -- Loss: 0.17334133386611938
val-epoch-step: 48-616 -- Loss: 0.15635830163955688
val-epoch-step: 48-617 -- Loss: 0.18362508714199066
val-epoch-step: 48-618 -- Loss: 0.18182426691055298
val-epoch-step: 48-619 -- Loss: 0.22358417510986328
val-epoch-step: 48-620 -- Loss: 0.1860906183719635
val-epoch-step: 48-621 -- Loss: 0.12650977075099945
val-epoch-step: 48-622 -- Loss: 0.1447327584028244
val-epoch-step: 48-623 -- Loss: 0.14940603077411652
val-epoch-step: 48-624 -- Loss: 0.14065656065940857
val-epoch-step: 48-625 -- Loss: 0.15258045494556427
val-epoch-step: 48-626 -- Loss: 0.14527982473373413
val-epoch-step: 48-627 -- Loss: 0.18165551126003265
val-epoch-step: 48-628 -- Loss: 0.7806771397590637
val-epoch-step: 48-629 -- Loss: 0.22368483245372772
val-epoch-step: 48-630 -- Loss: 0.3462519645690918
val-epoch-step: 48-631 -- Loss: 0.14576619863510132
val-epoch-step: 48-632 -- Loss: 0.19620980322360992
val-epoch-step: 48-633 -- Loss: 0.1498856395483017
val-epoch-step: 48-634 -- Loss: 0.15889519453048706
val-epoch-step: 48-635 -- Loss: 0.11746597290039062
val-epoch-step: 48-636 -- Loss: 0.17182832956314087
val-epoch-step: 48-637 -- Loss: 0.17735300958156586
val-epoch-step: 48-638 -- Loss: 0.14349845051765442
val-epoch-step: 48-639 -- Loss: 0.26265543699264526
val-epoch-step: 48-640 -- Loss: 0.25423410534858704
val-epoch-step: 48-641 -- Loss: 0.12193119525909424
val-epoch-step: 48-642 -- Loss: 0.20421776175498962
val-epoch-step: 48-643 -- Loss: 0.2158384621143341
val-epoch-step: 48-644 -- Loss: 0.16222183406352997
val-epoch-step: 48-645 -- Loss: 0.21528467535972595
val-epoch-step: 48-646 -- Loss: 0.13098251819610596
val-epoch-step: 48-647 -- Loss: 0.13598622381687164
val-epoch-step: 48-648 -- Loss: 0.15424828231334686
val-epoch-step: 48-649 -- Loss: 0.206539124250412
val-epoch-step: 48-650 -- Loss: 0.25280657410621643
val-epoch-step: 48-651 -- Loss: 0.13967517018318176
val-epoch-step: 48-652 -- Loss: 0.15598691999912262
val-epoch-step: 48-653 -- Loss: 0.19706586003303528
val-epoch-step: 48-654 -- Loss: 0.1086585521697998
Epoch: 48 -- Train Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1432, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 49-0 -- Loss: 0.2204679399728775
train-epoch-step: 49-1 -- Loss: 0.14032752811908722
train-epoch-step: 49-2 -- Loss: 0.19320276379585266
train-epoch-step: 49-3 -- Loss: 0.13697081804275513
train-epoch-step: 49-4 -- Loss: 0.1582985818386078
train-epoch-step: 49-5 -- Loss: 0.17768380045890808
train-epoch-step: 49-6 -- Loss: 0.2106277048587799
train-epoch-step: 49-7 -- Loss: 0.16389702260494232
train-epoch-step: 49-8 -- Loss: 0.17289221286773682
train-epoch-step: 49-9 -- Loss: 0.2230229675769806
train-epoch-step: 49-10 -- Loss: 0.20042285323143005
train-epoch-step: 49-11 -- Loss: 0.17264311015605927
train-epoch-step: 49-12 -- Loss: 0.1473386436700821
train-epoch-step: 49-13 -- Loss: 0.17102286219596863
train-epoch-step: 49-14 -- Loss: 0.158401221036911
train-epoch-step: 49-15 -- Loss: 0.15350210666656494
train-epoch-step: 49-16 -- Loss: 0.15715216100215912
train-epoch-step: 49-17 -- Loss: 0.21326844394207
train-epoch-step: 49-18 -- Loss: 0.19198769330978394
train-epoch-step: 49-19 -- Loss: 0.12559139728546143
train-epoch-step: 49-20 -- Loss: 0.21647971868515015
train-epoch-step: 49-21 -- Loss: 0.24467189610004425
train-epoch-step: 49-22 -- Loss: 0.14176581799983978
train-epoch-step: 49-23 -- Loss: 0.1379479020833969
train-epoch-step: 49-24 -- Loss: 0.12197920680046082
train-epoch-step: 49-25 -- Loss: 0.23053136467933655
train-epoch-step: 49-26 -- Loss: 0.20488059520721436
train-epoch-step: 49-27 -- Loss: 0.22825153172016144
train-epoch-step: 49-28 -- Loss: 0.1256791353225708
train-epoch-step: 49-29 -- Loss: 0.24104180932044983
train-epoch-step: 49-30 -- Loss: 0.10923298448324203
train-epoch-step: 49-31 -- Loss: 0.1315121352672577
train-epoch-step: 49-32 -- Loss: 0.16890555620193481
train-epoch-step: 49-33 -- Loss: 0.27016377449035645
train-epoch-step: 49-34 -- Loss: 0.1669609397649765
train-epoch-step: 49-35 -- Loss: 0.22972071170806885
train-epoch-step: 49-36 -- Loss: 0.14529843628406525
train-epoch-step: 49-37 -- Loss: 0.13458873331546783
train-epoch-step: 49-38 -- Loss: 0.17255756258964539
train-epoch-step: 49-39 -- Loss: 0.21317563951015472
train-epoch-step: 49-40 -- Loss: 0.19067172706127167
train-epoch-step: 49-41 -- Loss: 0.21957018971443176
train-epoch-step: 49-42 -- Loss: 0.14341071248054504
train-epoch-step: 49-43 -- Loss: 0.25673216581344604
train-epoch-step: 49-44 -- Loss: 0.12128052115440369
train-epoch-step: 49-45 -- Loss: 0.11270365864038467
train-epoch-step: 49-46 -- Loss: 0.16259267926216125
train-epoch-step: 49-47 -- Loss: 0.19267627596855164
train-epoch-step: 49-48 -- Loss: 0.15496698021888733
train-epoch-step: 49-49 -- Loss: 0.22406022250652313
train-epoch-step: 49-50 -- Loss: 0.11509734392166138
train-epoch-step: 49-51 -- Loss: 0.1744820922613144
train-epoch-step: 49-52 -- Loss: 0.15376198291778564
train-epoch-step: 49-53 -- Loss: 0.20456337928771973
train-epoch-step: 49-54 -- Loss: 0.28413790464401245
train-epoch-step: 49-55 -- Loss: 0.16402748227119446
train-epoch-step: 49-56 -- Loss: 0.1701449155807495
train-epoch-step: 49-57 -- Loss: 0.22699479758739471
train-epoch-step: 49-58 -- Loss: 0.2774909734725952
train-epoch-step: 49-59 -- Loss: 0.23743097484111786
train-epoch-step: 49-60 -- Loss: 0.13227929174900055
train-epoch-step: 49-61 -- Loss: 0.1967700570821762
train-epoch-step: 49-62 -- Loss: 0.17815431952476501
train-epoch-step: 49-63 -- Loss: 0.1498377025127411
train-epoch-step: 49-64 -- Loss: 0.13991016149520874
train-epoch-step: 49-65 -- Loss: 0.17371638119220734
train-epoch-step: 49-66 -- Loss: 0.10801465809345245
train-epoch-step: 49-67 -- Loss: 0.12071671336889267
train-epoch-step: 49-68 -- Loss: 0.20999808609485626
train-epoch-step: 49-69 -- Loss: 0.11885616928339005
train-epoch-step: 49-70 -- Loss: 0.2150280773639679
train-epoch-step: 49-71 -- Loss: 0.2633814811706543
train-epoch-step: 49-72 -- Loss: 0.17112137377262115
train-epoch-step: 49-73 -- Loss: 0.2029837667942047
train-epoch-step: 49-74 -- Loss: 0.09404299408197403
train-epoch-step: 49-75 -- Loss: 0.1239393800497055
train-epoch-step: 49-76 -- Loss: 0.1460856795310974
train-epoch-step: 49-77 -- Loss: 0.22110626101493835
train-epoch-step: 49-78 -- Loss: 0.24980874359607697
train-epoch-step: 49-79 -- Loss: 0.1898861527442932
train-epoch-step: 49-80 -- Loss: 0.2444288730621338
train-epoch-step: 49-81 -- Loss: 0.12186203896999359
train-epoch-step: 49-82 -- Loss: 0.24715125560760498
train-epoch-step: 49-83 -- Loss: 0.1744479238986969
train-epoch-step: 49-84 -- Loss: 0.1829088032245636
train-epoch-step: 49-85 -- Loss: 0.16577574610710144
train-epoch-step: 49-86 -- Loss: 0.12176304310560226
train-epoch-step: 49-87 -- Loss: 0.21214547753334045
train-epoch-step: 49-88 -- Loss: 0.1457437425851822
train-epoch-step: 49-89 -- Loss: 0.18368765711784363
train-epoch-step: 49-90 -- Loss: 0.187452495098114
train-epoch-step: 49-91 -- Loss: 0.2387821525335312
train-epoch-step: 49-92 -- Loss: 0.15226031839847565
train-epoch-step: 49-93 -- Loss: 0.16916324198246002
train-epoch-step: 49-94 -- Loss: 0.21181483566761017
train-epoch-step: 49-95 -- Loss: 0.18429170548915863
train-epoch-step: 49-96 -- Loss: 0.2056092619895935
train-epoch-step: 49-97 -- Loss: 0.1784408986568451
train-epoch-step: 49-98 -- Loss: 0.15065240859985352
train-epoch-step: 49-99 -- Loss: 0.17784500122070312
train-epoch-step: 49-100 -- Loss: 0.19116605818271637
train-epoch-step: 49-101 -- Loss: 0.2548142671585083
train-epoch-step: 49-102 -- Loss: 0.21400979161262512
train-epoch-step: 49-103 -- Loss: 0.18093551695346832
train-epoch-step: 49-104 -- Loss: 0.14590859413146973
train-epoch-step: 49-105 -- Loss: 0.25857365131378174
train-epoch-step: 49-106 -- Loss: 0.17212256789207458
train-epoch-step: 49-107 -- Loss: 0.18401940166950226
train-epoch-step: 49-108 -- Loss: 0.18793897330760956
train-epoch-step: 49-109 -- Loss: 0.14423835277557373
train-epoch-step: 49-110 -- Loss: 0.17895129323005676
train-epoch-step: 49-111 -- Loss: 0.17559601366519928
train-epoch-step: 49-112 -- Loss: 0.16253159940242767
train-epoch-step: 49-113 -- Loss: 0.15479859709739685
train-epoch-step: 49-114 -- Loss: 0.19107045233249664
train-epoch-step: 49-115 -- Loss: 0.1533590704202652
train-epoch-step: 49-116 -- Loss: 0.13454115390777588
train-epoch-step: 49-117 -- Loss: 0.1274755597114563
train-epoch-step: 49-118 -- Loss: 0.18669340014457703
train-epoch-step: 49-119 -- Loss: 0.14840167760849
train-epoch-step: 49-120 -- Loss: 0.2567104697227478
train-epoch-step: 49-121 -- Loss: 0.22653913497924805
train-epoch-step: 49-122 -- Loss: 0.20749597251415253
train-epoch-step: 49-123 -- Loss: 0.19933851063251495
train-epoch-step: 49-124 -- Loss: 0.12204757332801819
train-epoch-step: 49-125 -- Loss: 0.1489880383014679
train-epoch-step: 49-126 -- Loss: 0.2252921760082245
train-epoch-step: 49-127 -- Loss: 0.16549301147460938
train-epoch-step: 49-128 -- Loss: 0.17001937329769135
train-epoch-step: 49-129 -- Loss: 0.1390102058649063
train-epoch-step: 49-130 -- Loss: 0.1857154667377472
train-epoch-step: 49-131 -- Loss: 0.1311436891555786
train-epoch-step: 49-132 -- Loss: 0.19129905104637146
train-epoch-step: 49-133 -- Loss: 0.1129392683506012
train-epoch-step: 49-134 -- Loss: 0.18822678923606873
train-epoch-step: 49-135 -- Loss: 0.14244385063648224
train-epoch-step: 49-136 -- Loss: 0.12210357934236526
train-epoch-step: 49-137 -- Loss: 0.23805896937847137
train-epoch-step: 49-138 -- Loss: 0.2590041160583496
train-epoch-step: 49-139 -- Loss: 0.12957794964313507
train-epoch-step: 49-140 -- Loss: 0.2041281908750534
train-epoch-step: 49-141 -- Loss: 0.22297358512878418
train-epoch-step: 49-142 -- Loss: 0.1992415189743042
train-epoch-step: 49-143 -- Loss: 0.1734287142753601
train-epoch-step: 49-144 -- Loss: 0.18906477093696594
train-epoch-step: 49-145 -- Loss: 0.1395341008901596
train-epoch-step: 49-146 -- Loss: 0.17262515425682068
train-epoch-step: 49-147 -- Loss: 0.16595102846622467
train-epoch-step: 49-148 -- Loss: 0.15397360920906067
train-epoch-step: 49-149 -- Loss: 0.12187950313091278
train-epoch-step: 49-150 -- Loss: 0.18344470858573914
train-epoch-step: 49-151 -- Loss: 0.18638640642166138
train-epoch-step: 49-152 -- Loss: 0.18473508954048157
train-epoch-step: 49-153 -- Loss: 0.25662288069725037
train-epoch-step: 49-154 -- Loss: 0.1276630014181137
train-epoch-step: 49-155 -- Loss: 0.13338792324066162
train-epoch-step: 49-156 -- Loss: 0.11486135423183441
train-epoch-step: 49-157 -- Loss: 0.1655682921409607
train-epoch-step: 49-158 -- Loss: 0.16305029392242432
train-epoch-step: 49-159 -- Loss: 0.17589955031871796
train-epoch-step: 49-160 -- Loss: 0.21658816933631897
train-epoch-step: 49-161 -- Loss: 0.2005239874124527
train-epoch-step: 49-162 -- Loss: 0.20765501260757446
train-epoch-step: 49-163 -- Loss: 0.18121033906936646
train-epoch-step: 49-164 -- Loss: 0.18930727243423462
train-epoch-step: 49-165 -- Loss: 0.15744957327842712
train-epoch-step: 49-166 -- Loss: 0.11776943504810333
train-epoch-step: 49-167 -- Loss: 0.11738443374633789
train-epoch-step: 49-168 -- Loss: 0.19639652967453003
train-epoch-step: 49-169 -- Loss: 0.13822193443775177
train-epoch-step: 49-170 -- Loss: 0.1962864100933075
train-epoch-step: 49-171 -- Loss: 0.14034350216388702
train-epoch-step: 49-172 -- Loss: 0.25658100843429565
train-epoch-step: 49-173 -- Loss: 0.1310480386018753
train-epoch-step: 49-174 -- Loss: 0.24470147490501404
train-epoch-step: 49-175 -- Loss: 0.18309617042541504
train-epoch-step: 49-176 -- Loss: 0.12840703129768372
train-epoch-step: 49-177 -- Loss: 0.17520177364349365
train-epoch-step: 49-178 -- Loss: 0.1738455891609192
train-epoch-step: 49-179 -- Loss: 0.14217989146709442
train-epoch-step: 49-180 -- Loss: 0.14879460632801056
train-epoch-step: 49-181 -- Loss: 0.16334259510040283
train-epoch-step: 49-182 -- Loss: 0.18617241084575653
train-epoch-step: 49-183 -- Loss: 0.2683204114437103
train-epoch-step: 49-184 -- Loss: 0.1363483965396881
train-epoch-step: 49-185 -- Loss: 0.14154069125652313
train-epoch-step: 49-186 -- Loss: 0.184297576546669
train-epoch-step: 49-187 -- Loss: 0.20485751330852509
train-epoch-step: 49-188 -- Loss: 0.1688758134841919
train-epoch-step: 49-189 -- Loss: 0.10439695417881012
train-epoch-step: 49-190 -- Loss: 0.17881838977336884
train-epoch-step: 49-191 -- Loss: 0.15559658408164978
train-epoch-step: 49-192 -- Loss: 0.2231023907661438
train-epoch-step: 49-193 -- Loss: 0.20329737663269043
train-epoch-step: 49-194 -- Loss: 0.18381547927856445
train-epoch-step: 49-195 -- Loss: 0.16124175488948822
train-epoch-step: 49-196 -- Loss: 0.16287767887115479
train-epoch-step: 49-197 -- Loss: 0.12211837619543076
train-epoch-step: 49-198 -- Loss: 0.12862180173397064
train-epoch-step: 49-199 -- Loss: 0.14576415717601776
train-epoch-step: 49-200 -- Loss: 0.12932565808296204
train-epoch-step: 49-201 -- Loss: 0.1786811798810959
train-epoch-step: 49-202 -- Loss: 0.13655567169189453
train-epoch-step: 49-203 -- Loss: 0.16961662471294403
train-epoch-step: 49-204 -- Loss: 0.13303343951702118
train-epoch-step: 49-205 -- Loss: 0.17855438590049744
train-epoch-step: 49-206 -- Loss: 0.19419099390506744
train-epoch-step: 49-207 -- Loss: 0.13155943155288696
train-epoch-step: 49-208 -- Loss: 0.17415666580200195
train-epoch-step: 49-209 -- Loss: 0.1376393586397171
train-epoch-step: 49-210 -- Loss: 0.13197427988052368
train-epoch-step: 49-211 -- Loss: 0.20078805088996887
train-epoch-step: 49-212 -- Loss: 0.19497819244861603
train-epoch-step: 49-213 -- Loss: 0.12470729649066925
train-epoch-step: 49-214 -- Loss: 0.14483296871185303
train-epoch-step: 49-215 -- Loss: 0.12797880172729492
train-epoch-step: 49-216 -- Loss: 0.2025235891342163
train-epoch-step: 49-217 -- Loss: 0.204669788479805
train-epoch-step: 49-218 -- Loss: 0.14205202460289001
train-epoch-step: 49-219 -- Loss: 0.16500595211982727
train-epoch-step: 49-220 -- Loss: 0.1252523511648178
train-epoch-step: 49-221 -- Loss: 0.20315857231616974
train-epoch-step: 49-222 -- Loss: 0.12275993078947067
train-epoch-step: 49-223 -- Loss: 0.1716749519109726
train-epoch-step: 49-224 -- Loss: 0.1876429319381714
train-epoch-step: 49-225 -- Loss: 0.2621198296546936
train-epoch-step: 49-226 -- Loss: 0.201856330037117
train-epoch-step: 49-227 -- Loss: 0.21474821865558624
train-epoch-step: 49-228 -- Loss: 0.1748819351196289
train-epoch-step: 49-229 -- Loss: 0.17106734216213226
train-epoch-step: 49-230 -- Loss: 0.16018559038639069
train-epoch-step: 49-231 -- Loss: 0.15412531793117523
train-epoch-step: 49-232 -- Loss: 0.18396255373954773
train-epoch-step: 49-233 -- Loss: 0.08390607684850693
train-epoch-step: 49-234 -- Loss: 0.17058180272579193
train-epoch-step: 49-235 -- Loss: 0.15180319547653198
train-epoch-step: 49-236 -- Loss: 0.18871258199214935
train-epoch-step: 49-237 -- Loss: 0.22942771017551422
train-epoch-step: 49-238 -- Loss: 0.15445949137210846
train-epoch-step: 49-239 -- Loss: 0.12477974593639374
train-epoch-step: 49-240 -- Loss: 0.22177325189113617
train-epoch-step: 49-241 -- Loss: 0.14799441397190094
train-epoch-step: 49-242 -- Loss: 0.2150314450263977
train-epoch-step: 49-243 -- Loss: 0.2285575270652771
train-epoch-step: 49-244 -- Loss: 0.20620344579219818
train-epoch-step: 49-245 -- Loss: 0.20319291949272156
train-epoch-step: 49-246 -- Loss: 0.2152591198682785
train-epoch-step: 49-247 -- Loss: 0.20163653790950775
train-epoch-step: 49-248 -- Loss: 0.1803007423877716
train-epoch-step: 49-249 -- Loss: 0.1360430270433426
train-epoch-step: 49-250 -- Loss: 0.19320979714393616
train-epoch-step: 49-251 -- Loss: 0.10632960498332977
train-epoch-step: 49-252 -- Loss: 0.18368679285049438
train-epoch-step: 49-253 -- Loss: 0.13268110156059265
train-epoch-step: 49-254 -- Loss: 0.20756107568740845
train-epoch-step: 49-255 -- Loss: 0.1449679583311081
train-epoch-step: 49-256 -- Loss: 0.14609971642494202
train-epoch-step: 49-257 -- Loss: 0.18564364314079285
train-epoch-step: 49-258 -- Loss: 0.1392340213060379
train-epoch-step: 49-259 -- Loss: 0.10903659462928772
train-epoch-step: 49-260 -- Loss: 0.19671514630317688
train-epoch-step: 49-261 -- Loss: 0.171071857213974
train-epoch-step: 49-262 -- Loss: 0.28023743629455566
train-epoch-step: 49-263 -- Loss: 0.19258025288581848
train-epoch-step: 49-264 -- Loss: 0.17601099610328674
train-epoch-step: 49-265 -- Loss: 0.11084328591823578
train-epoch-step: 49-266 -- Loss: 0.15733803808689117
train-epoch-step: 49-267 -- Loss: 0.12954117357730865
train-epoch-step: 49-268 -- Loss: 0.11596815288066864
train-epoch-step: 49-269 -- Loss: 0.17339615523815155
train-epoch-step: 49-270 -- Loss: 0.1055607944726944
train-epoch-step: 49-271 -- Loss: 0.14391236007213593
train-epoch-step: 49-272 -- Loss: 0.1133527010679245
train-epoch-step: 49-273 -- Loss: 0.1231166198849678
train-epoch-step: 49-274 -- Loss: 0.18533702194690704
train-epoch-step: 49-275 -- Loss: 0.19208253920078278
train-epoch-step: 49-276 -- Loss: 0.1525484025478363
train-epoch-step: 49-277 -- Loss: 0.15267501771450043
train-epoch-step: 49-278 -- Loss: 0.14255520701408386
train-epoch-step: 49-279 -- Loss: 0.13726557791233063
train-epoch-step: 49-280 -- Loss: 0.20826172828674316
train-epoch-step: 49-281 -- Loss: 0.17471471428871155
train-epoch-step: 49-282 -- Loss: 0.14139068126678467
train-epoch-step: 49-283 -- Loss: 0.11123452335596085
train-epoch-step: 49-284 -- Loss: 0.13169778883457184
train-epoch-step: 49-285 -- Loss: 0.1838054656982422
train-epoch-step: 49-286 -- Loss: 0.15315794944763184
train-epoch-step: 49-287 -- Loss: 0.1966487318277359
train-epoch-step: 49-288 -- Loss: 0.09280388057231903
train-epoch-step: 49-289 -- Loss: 0.1201465055346489
train-epoch-step: 49-290 -- Loss: 0.17861945927143097
train-epoch-step: 49-291 -- Loss: 0.1145092323422432
train-epoch-step: 49-292 -- Loss: 0.15377536416053772
train-epoch-step: 49-293 -- Loss: 0.1483508050441742
train-epoch-step: 49-294 -- Loss: 0.1561751514673233
train-epoch-step: 49-295 -- Loss: 0.2608538568019867
train-epoch-step: 49-296 -- Loss: 0.1564990133047104
train-epoch-step: 49-297 -- Loss: 0.172673761844635
train-epoch-step: 49-298 -- Loss: 0.23266445100307465
train-epoch-step: 49-299 -- Loss: 0.14346803724765778
train-epoch-step: 49-300 -- Loss: 0.1546259969472885
train-epoch-step: 49-301 -- Loss: 0.16342343389987946
train-epoch-step: 49-302 -- Loss: 0.21486569941043854
train-epoch-step: 49-303 -- Loss: 0.2031211107969284
train-epoch-step: 49-304 -- Loss: 0.12260476499795914
train-epoch-step: 49-305 -- Loss: 0.14132988452911377
train-epoch-step: 49-306 -- Loss: 0.2114870250225067
train-epoch-step: 49-307 -- Loss: 0.16391056776046753
train-epoch-step: 49-308 -- Loss: 0.2125454545021057
train-epoch-step: 49-309 -- Loss: 0.15123920142650604
train-epoch-step: 49-310 -- Loss: 0.17063897848129272
train-epoch-step: 49-311 -- Loss: 0.15913920104503632
train-epoch-step: 49-312 -- Loss: 0.19810515642166138
train-epoch-step: 49-313 -- Loss: 0.09798115491867065
train-epoch-step: 49-314 -- Loss: 0.18617740273475647
train-epoch-step: 49-315 -- Loss: 0.1627952605485916
train-epoch-step: 49-316 -- Loss: 0.14814069867134094
train-epoch-step: 49-317 -- Loss: 0.13613754510879517
train-epoch-step: 49-318 -- Loss: 0.15742707252502441
train-epoch-step: 49-319 -- Loss: 0.16339115798473358
train-epoch-step: 49-320 -- Loss: 0.11377612501382828
train-epoch-step: 49-321 -- Loss: 0.1268773227930069
train-epoch-step: 49-322 -- Loss: 0.20652396976947784
train-epoch-step: 49-323 -- Loss: 0.15809209644794464
train-epoch-step: 49-324 -- Loss: 0.2524850070476532
train-epoch-step: 49-325 -- Loss: 0.15060463547706604
train-epoch-step: 49-326 -- Loss: 0.1676260530948639
train-epoch-step: 49-327 -- Loss: 0.19577451050281525
train-epoch-step: 49-328 -- Loss: 0.18936321139335632
train-epoch-step: 49-329 -- Loss: 0.3369331657886505
train-epoch-step: 49-330 -- Loss: 0.3574407398700714
train-epoch-step: 49-331 -- Loss: 0.2057652473449707
train-epoch-step: 49-332 -- Loss: 0.09597089141607285
train-epoch-step: 49-333 -- Loss: 0.1780771166086197
train-epoch-step: 49-334 -- Loss: 0.15134640038013458
train-epoch-step: 49-335 -- Loss: 0.16782404482364655
train-epoch-step: 49-336 -- Loss: 0.1443810760974884
train-epoch-step: 49-337 -- Loss: 0.19263127446174622
train-epoch-step: 49-338 -- Loss: 0.15709346532821655
train-epoch-step: 49-339 -- Loss: 0.1361583173274994
train-epoch-step: 49-340 -- Loss: 0.19568799436092377
train-epoch-step: 49-341 -- Loss: 0.14207062125205994
train-epoch-step: 49-342 -- Loss: 0.16071344912052155
train-epoch-step: 49-343 -- Loss: 0.14956414699554443
train-epoch-step: 49-344 -- Loss: 0.16514812409877777
train-epoch-step: 49-345 -- Loss: 0.12299501895904541
train-epoch-step: 49-346 -- Loss: 0.198332741856575
train-epoch-step: 49-347 -- Loss: 0.14888790249824524
train-epoch-step: 49-348 -- Loss: 0.2005940079689026
train-epoch-step: 49-349 -- Loss: 0.20209623873233795
train-epoch-step: 49-350 -- Loss: 0.24733181297779083
train-epoch-step: 49-351 -- Loss: 0.18982082605361938
train-epoch-step: 49-352 -- Loss: 0.12217705696821213
train-epoch-step: 49-353 -- Loss: 0.1865694522857666
train-epoch-step: 49-354 -- Loss: 0.27108725905418396
train-epoch-step: 49-355 -- Loss: 0.11644597351551056
train-epoch-step: 49-356 -- Loss: 0.1149194985628128
train-epoch-step: 49-357 -- Loss: 0.18720471858978271
train-epoch-step: 49-358 -- Loss: 0.1798749566078186
train-epoch-step: 49-359 -- Loss: 0.14127445220947266
train-epoch-step: 49-360 -- Loss: 0.12104170769453049
train-epoch-step: 49-361 -- Loss: 0.22926297783851624
train-epoch-step: 49-362 -- Loss: 0.1663765162229538
train-epoch-step: 49-363 -- Loss: 0.10796716064214706
train-epoch-step: 49-364 -- Loss: 0.17653843760490417
train-epoch-step: 49-365 -- Loss: 0.17149336636066437
train-epoch-step: 49-366 -- Loss: 0.19280485808849335
train-epoch-step: 49-367 -- Loss: 0.22661066055297852
train-epoch-step: 49-368 -- Loss: 0.19194528460502625
train-epoch-step: 49-369 -- Loss: 0.2717481851577759
train-epoch-step: 49-370 -- Loss: 0.11957195401191711
train-epoch-step: 49-371 -- Loss: 0.11831146478652954
train-epoch-step: 49-372 -- Loss: 0.14273421466350555
train-epoch-step: 49-373 -- Loss: 0.18367592990398407
train-epoch-step: 49-374 -- Loss: 0.1515347957611084
train-epoch-step: 49-375 -- Loss: 0.2626133859157562
train-epoch-step: 49-376 -- Loss: 0.1525493562221527
train-epoch-step: 49-377 -- Loss: 0.2288813292980194
train-epoch-step: 49-378 -- Loss: 0.19816775619983673
train-epoch-step: 49-379 -- Loss: 0.11715205758810043
train-epoch-step: 49-380 -- Loss: 0.08966755121946335
train-epoch-step: 49-381 -- Loss: 0.23616141080856323
train-epoch-step: 49-382 -- Loss: 0.2269609272480011
train-epoch-step: 49-383 -- Loss: 0.17286323010921478
train-epoch-step: 49-384 -- Loss: 0.21368375420570374
train-epoch-step: 49-385 -- Loss: 0.1843046247959137
train-epoch-step: 49-386 -- Loss: 0.1800801008939743
train-epoch-step: 49-387 -- Loss: 0.19556201994419098
train-epoch-step: 49-388 -- Loss: 0.19226709008216858
train-epoch-step: 49-389 -- Loss: 0.1664750576019287
train-epoch-step: 49-390 -- Loss: 0.14109177887439728
train-epoch-step: 49-391 -- Loss: 0.14200915396213531
train-epoch-step: 49-392 -- Loss: 0.17890039086341858
train-epoch-step: 49-393 -- Loss: 0.15564972162246704
train-epoch-step: 49-394 -- Loss: 0.19602057337760925
train-epoch-step: 49-395 -- Loss: 0.1531117558479309
train-epoch-step: 49-396 -- Loss: 0.1232970729470253
train-epoch-step: 49-397 -- Loss: 0.12464320659637451
train-epoch-step: 49-398 -- Loss: 0.19232740998268127
train-epoch-step: 49-399 -- Loss: 0.17461071908473969
train-epoch-step: 49-400 -- Loss: 0.26665443181991577
train-epoch-step: 49-401 -- Loss: 0.1174016147851944
train-epoch-step: 49-402 -- Loss: 0.25052735209465027
train-epoch-step: 49-403 -- Loss: 0.15212099254131317
train-epoch-step: 49-404 -- Loss: 0.1350780427455902
train-epoch-step: 49-405 -- Loss: 0.14111222326755524
train-epoch-step: 49-406 -- Loss: 0.16293659806251526
train-epoch-step: 49-407 -- Loss: 0.10887467116117477
train-epoch-step: 49-408 -- Loss: 0.15669625997543335
train-epoch-step: 49-409 -- Loss: 0.1728554368019104
train-epoch-step: 49-410 -- Loss: 0.16705329716205597
train-epoch-step: 49-411 -- Loss: 0.187540203332901
train-epoch-step: 49-412 -- Loss: 0.12719660997390747
train-epoch-step: 49-413 -- Loss: 0.14271517097949982
train-epoch-step: 49-414 -- Loss: 0.13271889090538025
train-epoch-step: 49-415 -- Loss: 0.1304198056459427
train-epoch-step: 49-416 -- Loss: 0.26040443778038025
train-epoch-step: 49-417 -- Loss: 0.18527011573314667
train-epoch-step: 49-418 -- Loss: 0.21419504284858704
train-epoch-step: 49-419 -- Loss: 0.16420961916446686
train-epoch-step: 49-420 -- Loss: 0.15173839032649994
train-epoch-step: 49-421 -- Loss: 0.1724780946969986
train-epoch-step: 49-422 -- Loss: 0.144938662648201
train-epoch-step: 49-423 -- Loss: 0.17087870836257935
train-epoch-step: 49-424 -- Loss: 0.13336777687072754
train-epoch-step: 49-425 -- Loss: 0.17901912331581116
train-epoch-step: 49-426 -- Loss: 0.15937212109565735
train-epoch-step: 49-427 -- Loss: 0.11835771799087524
train-epoch-step: 49-428 -- Loss: 0.18901005387306213
train-epoch-step: 49-429 -- Loss: 0.17656734585762024
train-epoch-step: 49-430 -- Loss: 0.1496855616569519
train-epoch-step: 49-431 -- Loss: 0.1636616438627243
train-epoch-step: 49-432 -- Loss: 0.24021287262439728
train-epoch-step: 49-433 -- Loss: 0.13379105925559998
train-epoch-step: 49-434 -- Loss: 0.12630107998847961
train-epoch-step: 49-435 -- Loss: 0.1499362736940384
train-epoch-step: 49-436 -- Loss: 0.14814706146717072
train-epoch-step: 49-437 -- Loss: 0.13016162812709808
train-epoch-step: 49-438 -- Loss: 0.16093268990516663
train-epoch-step: 49-439 -- Loss: 0.25427958369255066
train-epoch-step: 49-440 -- Loss: 0.12942290306091309
train-epoch-step: 49-441 -- Loss: 0.19728460907936096
train-epoch-step: 49-442 -- Loss: 0.1724153757095337
train-epoch-step: 49-443 -- Loss: 0.14966700971126556
train-epoch-step: 49-444 -- Loss: 0.171805277466774
train-epoch-step: 49-445 -- Loss: 0.17783835530281067
train-epoch-step: 49-446 -- Loss: 0.15086068212985992
train-epoch-step: 49-447 -- Loss: 0.18577361106872559
train-epoch-step: 49-448 -- Loss: 0.2193797528743744
train-epoch-step: 49-449 -- Loss: 0.19057327508926392
train-epoch-step: 49-450 -- Loss: 0.17707368731498718
train-epoch-step: 49-451 -- Loss: 0.13977980613708496
train-epoch-step: 49-452 -- Loss: 0.12891855835914612
train-epoch-step: 49-453 -- Loss: 0.08938891440629959
train-epoch-step: 49-454 -- Loss: 0.2291896641254425
train-epoch-step: 49-455 -- Loss: 0.11899805068969727
train-epoch-step: 49-456 -- Loss: 0.12196197360754013
train-epoch-step: 49-457 -- Loss: 0.20929287374019623
train-epoch-step: 49-458 -- Loss: 0.14079631865024567
train-epoch-step: 49-459 -- Loss: 0.20634391903877258
train-epoch-step: 49-460 -- Loss: 0.1203584223985672
train-epoch-step: 49-461 -- Loss: 0.13168810307979584
train-epoch-step: 49-462 -- Loss: 0.1504594385623932
train-epoch-step: 49-463 -- Loss: 0.13207751512527466
train-epoch-step: 49-464 -- Loss: 0.1627051830291748
train-epoch-step: 49-465 -- Loss: 0.23866719007492065
train-epoch-step: 49-466 -- Loss: 0.19538956880569458
train-epoch-step: 49-467 -- Loss: 0.11276344209909439
train-epoch-step: 49-468 -- Loss: 0.1623857468366623
train-epoch-step: 49-469 -- Loss: 0.21251486241817474
train-epoch-step: 49-470 -- Loss: 0.17784494161605835
train-epoch-step: 49-471 -- Loss: 0.15305905044078827
train-epoch-step: 49-472 -- Loss: 0.15399666130542755
train-epoch-step: 49-473 -- Loss: 0.15059003233909607
train-epoch-step: 49-474 -- Loss: 0.12119263410568237
train-epoch-step: 49-475 -- Loss: 0.10762841999530792
train-epoch-step: 49-476 -- Loss: 0.1986241638660431
train-epoch-step: 49-477 -- Loss: 0.20806357264518738
train-epoch-step: 49-478 -- Loss: 0.19055700302124023
train-epoch-step: 49-479 -- Loss: 0.14146830141544342
train-epoch-step: 49-480 -- Loss: 0.20040401816368103
train-epoch-step: 49-481 -- Loss: 0.285716712474823
train-epoch-step: 49-482 -- Loss: 0.27147990465164185
train-epoch-step: 49-483 -- Loss: 0.17130030691623688
train-epoch-step: 49-484 -- Loss: 0.20762863755226135
train-epoch-step: 49-485 -- Loss: 0.12484247982501984
train-epoch-step: 49-486 -- Loss: 0.23341530561447144
train-epoch-step: 49-487 -- Loss: 0.23741647601127625
train-epoch-step: 49-488 -- Loss: 0.18661071360111237
train-epoch-step: 49-489 -- Loss: 0.21625371277332306
train-epoch-step: 49-490 -- Loss: 0.13808025419712067
train-epoch-step: 49-491 -- Loss: 0.14130863547325134
train-epoch-step: 49-492 -- Loss: 0.12111629545688629
train-epoch-step: 49-493 -- Loss: 0.215403750538826
train-epoch-step: 49-494 -- Loss: 0.23069564998149872
train-epoch-step: 49-495 -- Loss: 0.20154380798339844
train-epoch-step: 49-496 -- Loss: 0.1364748179912567
train-epoch-step: 49-497 -- Loss: 0.1817052811384201
train-epoch-step: 49-498 -- Loss: 0.14692284166812897
train-epoch-step: 49-499 -- Loss: 0.16847756505012512
train-epoch-step: 49-500 -- Loss: 0.1536654382944107
train-epoch-step: 49-501 -- Loss: 0.24378632009029388
train-epoch-step: 49-502 -- Loss: 0.15691901743412018
train-epoch-step: 49-503 -- Loss: 0.23015065491199493
train-epoch-step: 49-504 -- Loss: 0.11833734065294266
train-epoch-step: 49-505 -- Loss: 0.17213031649589539
train-epoch-step: 49-506 -- Loss: 0.11574304103851318
train-epoch-step: 49-507 -- Loss: 0.17742399871349335
train-epoch-step: 49-508 -- Loss: 0.18039114773273468
train-epoch-step: 49-509 -- Loss: 0.1861369013786316
train-epoch-step: 49-510 -- Loss: 0.12732678651809692
train-epoch-step: 49-511 -- Loss: 0.22149822115898132
train-epoch-step: 49-512 -- Loss: 0.17289066314697266
train-epoch-step: 49-513 -- Loss: 0.192457914352417
train-epoch-step: 49-514 -- Loss: 0.14627602696418762
train-epoch-step: 49-515 -- Loss: 0.15406528115272522
train-epoch-step: 49-516 -- Loss: 0.19753962755203247
train-epoch-step: 49-517 -- Loss: 0.18050892651081085
train-epoch-step: 49-518 -- Loss: 0.13851530849933624
train-epoch-step: 49-519 -- Loss: 0.13999822735786438
train-epoch-step: 49-520 -- Loss: 0.18433794379234314
train-epoch-step: 49-521 -- Loss: 0.2243383526802063
train-epoch-step: 49-522 -- Loss: 0.17103011906147003
train-epoch-step: 49-523 -- Loss: 0.1715666949748993
train-epoch-step: 49-524 -- Loss: 0.16327700018882751
train-epoch-step: 49-525 -- Loss: 0.18992900848388672
train-epoch-step: 49-526 -- Loss: 0.12798504531383514
train-epoch-step: 49-527 -- Loss: 0.16069325804710388
train-epoch-step: 49-528 -- Loss: 0.15107207000255585
train-epoch-step: 49-529 -- Loss: 0.16114084422588348
train-epoch-step: 49-530 -- Loss: 0.1644466519355774
train-epoch-step: 49-531 -- Loss: 0.19405679404735565
train-epoch-step: 49-532 -- Loss: 0.1656855195760727
train-epoch-step: 49-533 -- Loss: 0.17078664898872375
train-epoch-step: 49-534 -- Loss: 0.13273873925209045
train-epoch-step: 49-535 -- Loss: 0.2463105320930481
train-epoch-step: 49-536 -- Loss: 0.1592848300933838
train-epoch-step: 49-537 -- Loss: 0.1434064507484436
train-epoch-step: 49-538 -- Loss: 0.10507144778966904
train-epoch-step: 49-539 -- Loss: 0.2026931345462799
train-epoch-step: 49-540 -- Loss: 0.13517804443836212
train-epoch-step: 49-541 -- Loss: 0.20804902911186218
train-epoch-step: 49-542 -- Loss: 0.22409793734550476
train-epoch-step: 49-543 -- Loss: 0.1708202064037323
train-epoch-step: 49-544 -- Loss: 0.22470085322856903
train-epoch-step: 49-545 -- Loss: 0.19091692566871643
train-epoch-step: 49-546 -- Loss: 0.21552732586860657
train-epoch-step: 49-547 -- Loss: 0.17949408292770386
train-epoch-step: 49-548 -- Loss: 0.09414830058813095
train-epoch-step: 49-549 -- Loss: 0.15389934182167053
train-epoch-step: 49-550 -- Loss: 0.19742347300052643
train-epoch-step: 49-551 -- Loss: 0.15384618937969208
train-epoch-step: 49-552 -- Loss: 0.12489528954029083
train-epoch-step: 49-553 -- Loss: 0.18785491585731506
train-epoch-step: 49-554 -- Loss: 0.18458794057369232
train-epoch-step: 49-555 -- Loss: 0.2160097360610962
train-epoch-step: 49-556 -- Loss: 0.14080752432346344
train-epoch-step: 49-557 -- Loss: 0.22660411894321442
train-epoch-step: 49-558 -- Loss: 0.2247992753982544
train-epoch-step: 49-559 -- Loss: 0.1348092257976532
train-epoch-step: 49-560 -- Loss: 0.20042143762111664
train-epoch-step: 49-561 -- Loss: 0.17406761646270752
train-epoch-step: 49-562 -- Loss: 0.15945902466773987
train-epoch-step: 49-563 -- Loss: 0.17844927310943604
train-epoch-step: 49-564 -- Loss: 0.09795915335416794
train-epoch-step: 49-565 -- Loss: 0.18837465345859528
train-epoch-step: 49-566 -- Loss: 0.1523917019367218
train-epoch-step: 49-567 -- Loss: 0.21151089668273926
train-epoch-step: 49-568 -- Loss: 0.15747635066509247
train-epoch-step: 49-569 -- Loss: 0.23655153810977936
train-epoch-step: 49-570 -- Loss: 0.16671068966388702
train-epoch-step: 49-571 -- Loss: 0.21794229745864868
train-epoch-step: 49-572 -- Loss: 0.2606421709060669
train-epoch-step: 49-573 -- Loss: 0.19657334685325623
train-epoch-step: 49-574 -- Loss: 0.2420409917831421
train-epoch-step: 49-575 -- Loss: 0.2986346483230591
train-epoch-step: 49-576 -- Loss: 0.1180344894528389
train-epoch-step: 49-577 -- Loss: 0.16605371236801147
train-epoch-step: 49-578 -- Loss: 0.21344073116779327
train-epoch-step: 49-579 -- Loss: 0.17161710560321808
train-epoch-step: 49-580 -- Loss: 0.16750648617744446
train-epoch-step: 49-581 -- Loss: 0.13938048481941223
train-epoch-step: 49-582 -- Loss: 0.20125029981136322
train-epoch-step: 49-583 -- Loss: 0.20947596430778503
train-epoch-step: 49-584 -- Loss: 0.16327513754367828
train-epoch-step: 49-585 -- Loss: 0.19025452435016632
train-epoch-step: 49-586 -- Loss: 0.2509493827819824
train-epoch-step: 49-587 -- Loss: 0.16005858778953552
train-epoch-step: 49-588 -- Loss: 0.12623584270477295
val-epoch-step: 49-589 -- Loss: 0.1951044797897339
val-epoch-step: 49-590 -- Loss: 0.15213115513324738
val-epoch-step: 49-591 -- Loss: 0.23052555322647095
val-epoch-step: 49-592 -- Loss: 0.1738538146018982
val-epoch-step: 49-593 -- Loss: 0.18717914819717407
val-epoch-step: 49-594 -- Loss: 0.4283941984176636
val-epoch-step: 49-595 -- Loss: 0.18144017457962036
val-epoch-step: 49-596 -- Loss: 0.20435784757137299
val-epoch-step: 49-597 -- Loss: 0.1725519597530365
val-epoch-step: 49-598 -- Loss: 0.15038369596004486
val-epoch-step: 49-599 -- Loss: 0.19350211322307587
val-epoch-step: 49-600 -- Loss: 0.19673380255699158
val-epoch-step: 49-601 -- Loss: 0.171403169631958
val-epoch-step: 49-602 -- Loss: 0.1388864517211914
val-epoch-step: 49-603 -- Loss: 0.19363221526145935
val-epoch-step: 49-604 -- Loss: 0.14538222551345825
val-epoch-step: 49-605 -- Loss: 0.1471378058195114
val-epoch-step: 49-606 -- Loss: 0.261959433555603
val-epoch-step: 49-607 -- Loss: 0.12326785922050476
val-epoch-step: 49-608 -- Loss: 0.24556773900985718
val-epoch-step: 49-609 -- Loss: 0.17128786444664001
val-epoch-step: 49-610 -- Loss: 0.18212729692459106
val-epoch-step: 49-611 -- Loss: 0.15446946024894714
val-epoch-step: 49-612 -- Loss: 0.4005874693393707
val-epoch-step: 49-613 -- Loss: 0.17464740574359894
val-epoch-step: 49-614 -- Loss: 0.16947974264621735
val-epoch-step: 49-615 -- Loss: 0.17309416830539703
val-epoch-step: 49-616 -- Loss: 0.14691640436649323
val-epoch-step: 49-617 -- Loss: 0.1839207112789154
val-epoch-step: 49-618 -- Loss: 0.19257457554340363
val-epoch-step: 49-619 -- Loss: 0.20117655396461487
val-epoch-step: 49-620 -- Loss: 0.13992077112197876
val-epoch-step: 49-621 -- Loss: 0.12494277954101562
val-epoch-step: 49-622 -- Loss: 0.14255143702030182
val-epoch-step: 49-623 -- Loss: 0.14868658781051636
val-epoch-step: 49-624 -- Loss: 0.1415616124868393
val-epoch-step: 49-625 -- Loss: 0.15559394657611847
val-epoch-step: 49-626 -- Loss: 0.1478048413991928
val-epoch-step: 49-627 -- Loss: 0.18364641070365906
val-epoch-step: 49-628 -- Loss: 0.6744654178619385
val-epoch-step: 49-629 -- Loss: 0.2004285752773285
val-epoch-step: 49-630 -- Loss: 0.3424752652645111
val-epoch-step: 49-631 -- Loss: 0.13887326419353485
val-epoch-step: 49-632 -- Loss: 0.20159971714019775
val-epoch-step: 49-633 -- Loss: 0.1456645131111145
val-epoch-step: 49-634 -- Loss: 0.13622210919857025
val-epoch-step: 49-635 -- Loss: 0.11502620577812195
val-epoch-step: 49-636 -- Loss: 0.17377811670303345
val-epoch-step: 49-637 -- Loss: 0.1816069632768631
val-epoch-step: 49-638 -- Loss: 0.14584974944591522
val-epoch-step: 49-639 -- Loss: 0.28103047609329224
val-epoch-step: 49-640 -- Loss: 0.260824054479599
val-epoch-step: 49-641 -- Loss: 0.12195047736167908
val-epoch-step: 49-642 -- Loss: 0.18488037586212158
val-epoch-step: 49-643 -- Loss: 0.21100151538848877
val-epoch-step: 49-644 -- Loss: 0.16357439756393433
val-epoch-step: 49-645 -- Loss: 0.21475283801555634
val-epoch-step: 49-646 -- Loss: 0.13088935613632202
val-epoch-step: 49-647 -- Loss: 0.13281020522117615
val-epoch-step: 49-648 -- Loss: 0.15321531891822815
val-epoch-step: 49-649 -- Loss: 0.20154769718647003
val-epoch-step: 49-650 -- Loss: 0.2476043999195099
val-epoch-step: 49-651 -- Loss: 0.13842210173606873
val-epoch-step: 49-652 -- Loss: 0.15553653240203857
val-epoch-step: 49-653 -- Loss: 0.2527652382850647
val-epoch-step: 49-654 -- Loss: 0.1120133250951767
Epoch: 49 -- Train Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1433, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 50-0 -- Loss: 0.2227693349123001
train-epoch-step: 50-1 -- Loss: 0.14150552451610565
train-epoch-step: 50-2 -- Loss: 0.19580809772014618
train-epoch-step: 50-3 -- Loss: 0.1439296007156372
train-epoch-step: 50-4 -- Loss: 0.1542755365371704
train-epoch-step: 50-5 -- Loss: 0.1846967190504074
train-epoch-step: 50-6 -- Loss: 0.21832862496376038
train-epoch-step: 50-7 -- Loss: 0.16258388757705688
train-epoch-step: 50-8 -- Loss: 0.17685922980308533
train-epoch-step: 50-9 -- Loss: 0.21468505263328552
train-epoch-step: 50-10 -- Loss: 0.1919635683298111
train-epoch-step: 50-11 -- Loss: 0.17421209812164307
train-epoch-step: 50-12 -- Loss: 0.15115955471992493
train-epoch-step: 50-13 -- Loss: 0.17731648683547974
train-epoch-step: 50-14 -- Loss: 0.15930986404418945
train-epoch-step: 50-15 -- Loss: 0.1550527960062027
train-epoch-step: 50-16 -- Loss: 0.1651383340358734
train-epoch-step: 50-17 -- Loss: 0.21294203400611877
train-epoch-step: 50-18 -- Loss: 0.19192056357860565
train-epoch-step: 50-19 -- Loss: 0.12803873419761658
train-epoch-step: 50-20 -- Loss: 0.20908549427986145
train-epoch-step: 50-21 -- Loss: 0.24488261342048645
train-epoch-step: 50-22 -- Loss: 0.1375051736831665
train-epoch-step: 50-23 -- Loss: 0.14229519665241241
train-epoch-step: 50-24 -- Loss: 0.12328813225030899
train-epoch-step: 50-25 -- Loss: 0.2246200442314148
train-epoch-step: 50-26 -- Loss: 0.19251450896263123
train-epoch-step: 50-27 -- Loss: 0.2312338650226593
train-epoch-step: 50-28 -- Loss: 0.12174909561872482
train-epoch-step: 50-29 -- Loss: 0.23625177145004272
train-epoch-step: 50-30 -- Loss: 0.11078908294439316
train-epoch-step: 50-31 -- Loss: 0.13322004675865173
train-epoch-step: 50-32 -- Loss: 0.167134627699852
train-epoch-step: 50-33 -- Loss: 0.26925504207611084
train-epoch-step: 50-34 -- Loss: 0.1665169596672058
train-epoch-step: 50-35 -- Loss: 0.23629318177700043
train-epoch-step: 50-36 -- Loss: 0.1428704410791397
train-epoch-step: 50-37 -- Loss: 0.13621650636196136
train-epoch-step: 50-38 -- Loss: 0.17370449006557465
train-epoch-step: 50-39 -- Loss: 0.22004449367523193
train-epoch-step: 50-40 -- Loss: 0.18870246410369873
train-epoch-step: 50-41 -- Loss: 0.2100825160741806
train-epoch-step: 50-42 -- Loss: 0.1477619856595993
train-epoch-step: 50-43 -- Loss: 0.2613379657268524
train-epoch-step: 50-44 -- Loss: 0.12478405237197876
train-epoch-step: 50-45 -- Loss: 0.11253279447555542
train-epoch-step: 50-46 -- Loss: 0.16749529540538788
train-epoch-step: 50-47 -- Loss: 0.19043892621994019
train-epoch-step: 50-48 -- Loss: 0.1538262665271759
train-epoch-step: 50-49 -- Loss: 0.22262409329414368
train-epoch-step: 50-50 -- Loss: 0.10691212117671967
train-epoch-step: 50-51 -- Loss: 0.19335666298866272
train-epoch-step: 50-52 -- Loss: 0.1606340855360031
train-epoch-step: 50-53 -- Loss: 0.20380640029907227
train-epoch-step: 50-54 -- Loss: 0.27912163734436035
train-epoch-step: 50-55 -- Loss: 0.16269485652446747
train-epoch-step: 50-56 -- Loss: 0.17522351443767548
train-epoch-step: 50-57 -- Loss: 0.22846129536628723
train-epoch-step: 50-58 -- Loss: 0.2791588604450226
train-epoch-step: 50-59 -- Loss: 0.23434364795684814
train-epoch-step: 50-60 -- Loss: 0.12710729241371155
train-epoch-step: 50-61 -- Loss: 0.19326554238796234
train-epoch-step: 50-62 -- Loss: 0.18264339864253998
train-epoch-step: 50-63 -- Loss: 0.1413203775882721
train-epoch-step: 50-64 -- Loss: 0.13838380575180054
train-epoch-step: 50-65 -- Loss: 0.17544302344322205
train-epoch-step: 50-66 -- Loss: 0.10734309256076813
train-epoch-step: 50-67 -- Loss: 0.12217250466346741
train-epoch-step: 50-68 -- Loss: 0.20293667912483215
train-epoch-step: 50-69 -- Loss: 0.11844686418771744
train-epoch-step: 50-70 -- Loss: 0.22266045212745667
train-epoch-step: 50-71 -- Loss: 0.25639963150024414
train-epoch-step: 50-72 -- Loss: 0.1716877818107605
train-epoch-step: 50-73 -- Loss: 0.20260831713676453
train-epoch-step: 50-74 -- Loss: 0.09438715130090714
train-epoch-step: 50-75 -- Loss: 0.12704211473464966
train-epoch-step: 50-76 -- Loss: 0.14993292093276978
train-epoch-step: 50-77 -- Loss: 0.22238412499427795
train-epoch-step: 50-78 -- Loss: 0.25374835729599
train-epoch-step: 50-79 -- Loss: 0.18610766530036926
train-epoch-step: 50-80 -- Loss: 0.24721521139144897
train-epoch-step: 50-81 -- Loss: 0.12261555343866348
train-epoch-step: 50-82 -- Loss: 0.244881734251976
train-epoch-step: 50-83 -- Loss: 0.17198210954666138
train-epoch-step: 50-84 -- Loss: 0.18474407494068146
train-epoch-step: 50-85 -- Loss: 0.17018961906433105
train-epoch-step: 50-86 -- Loss: 0.11603690683841705
train-epoch-step: 50-87 -- Loss: 0.20836901664733887
train-epoch-step: 50-88 -- Loss: 0.13881506025791168
train-epoch-step: 50-89 -- Loss: 0.18094255030155182
train-epoch-step: 50-90 -- Loss: 0.18976259231567383
train-epoch-step: 50-91 -- Loss: 0.23878192901611328
train-epoch-step: 50-92 -- Loss: 0.15217278897762299
train-epoch-step: 50-93 -- Loss: 0.1674840748310089
train-epoch-step: 50-94 -- Loss: 0.21641847491264343
train-epoch-step: 50-95 -- Loss: 0.1866726130247116
train-epoch-step: 50-96 -- Loss: 0.20993764698505402
train-epoch-step: 50-97 -- Loss: 0.17108798027038574
train-epoch-step: 50-98 -- Loss: 0.15188854932785034
train-epoch-step: 50-99 -- Loss: 0.17902661859989166
train-epoch-step: 50-100 -- Loss: 0.19310680031776428
train-epoch-step: 50-101 -- Loss: 0.2814200520515442
train-epoch-step: 50-102 -- Loss: 0.2158687710762024
train-epoch-step: 50-103 -- Loss: 0.17987646162509918
train-epoch-step: 50-104 -- Loss: 0.14513364434242249
train-epoch-step: 50-105 -- Loss: 0.26906126737594604
train-epoch-step: 50-106 -- Loss: 0.17362384498119354
train-epoch-step: 50-107 -- Loss: 0.18839383125305176
train-epoch-step: 50-108 -- Loss: 0.18987435102462769
train-epoch-step: 50-109 -- Loss: 0.14206743240356445
train-epoch-step: 50-110 -- Loss: 0.18328621983528137
train-epoch-step: 50-111 -- Loss: 0.1738986372947693
train-epoch-step: 50-112 -- Loss: 0.1641334444284439
train-epoch-step: 50-113 -- Loss: 0.15823008120059967
train-epoch-step: 50-114 -- Loss: 0.1909516453742981
train-epoch-step: 50-115 -- Loss: 0.16118699312210083
train-epoch-step: 50-116 -- Loss: 0.13553062081336975
train-epoch-step: 50-117 -- Loss: 0.12684841454029083
train-epoch-step: 50-118 -- Loss: 0.19212566316127777
train-epoch-step: 50-119 -- Loss: 0.15130333602428436
train-epoch-step: 50-120 -- Loss: 0.24296273291110992
train-epoch-step: 50-121 -- Loss: 0.2261059284210205
train-epoch-step: 50-122 -- Loss: 0.2157195806503296
train-epoch-step: 50-123 -- Loss: 0.19803369045257568
train-epoch-step: 50-124 -- Loss: 0.11902287602424622
train-epoch-step: 50-125 -- Loss: 0.15213215351104736
train-epoch-step: 50-126 -- Loss: 0.2245071828365326
train-epoch-step: 50-127 -- Loss: 0.18020924925804138
train-epoch-step: 50-128 -- Loss: 0.16559529304504395
train-epoch-step: 50-129 -- Loss: 0.13880270719528198
train-epoch-step: 50-130 -- Loss: 0.19280605018138885
train-epoch-step: 50-131 -- Loss: 0.13210204243659973
train-epoch-step: 50-132 -- Loss: 0.1889544278383255
train-epoch-step: 50-133 -- Loss: 0.11234849691390991
train-epoch-step: 50-134 -- Loss: 0.1884121149778366
train-epoch-step: 50-135 -- Loss: 0.13710573315620422
train-epoch-step: 50-136 -- Loss: 0.12239912152290344
train-epoch-step: 50-137 -- Loss: 0.233344167470932
train-epoch-step: 50-138 -- Loss: 0.25229689478874207
train-epoch-step: 50-139 -- Loss: 0.12633207440376282
train-epoch-step: 50-140 -- Loss: 0.2021487057209015
train-epoch-step: 50-141 -- Loss: 0.2254078984260559
train-epoch-step: 50-142 -- Loss: 0.1957554817199707
train-epoch-step: 50-143 -- Loss: 0.16891855001449585
train-epoch-step: 50-144 -- Loss: 0.1843196451663971
train-epoch-step: 50-145 -- Loss: 0.14019212126731873
train-epoch-step: 50-146 -- Loss: 0.17700381577014923
train-epoch-step: 50-147 -- Loss: 0.16593460738658905
train-epoch-step: 50-148 -- Loss: 0.15546882152557373
train-epoch-step: 50-149 -- Loss: 0.11668184399604797
train-epoch-step: 50-150 -- Loss: 0.180228590965271
train-epoch-step: 50-151 -- Loss: 0.18275809288024902
train-epoch-step: 50-152 -- Loss: 0.19266042113304138
train-epoch-step: 50-153 -- Loss: 0.26391586661338806
train-epoch-step: 50-154 -- Loss: 0.12814942002296448
train-epoch-step: 50-155 -- Loss: 0.13418152928352356
train-epoch-step: 50-156 -- Loss: 0.12072665244340897
train-epoch-step: 50-157 -- Loss: 0.15821556746959686
train-epoch-step: 50-158 -- Loss: 0.1640148162841797
train-epoch-step: 50-159 -- Loss: 0.17600290477275848
train-epoch-step: 50-160 -- Loss: 0.2109561711549759
train-epoch-step: 50-161 -- Loss: 0.2006518542766571
train-epoch-step: 50-162 -- Loss: 0.20869819819927216
train-epoch-step: 50-163 -- Loss: 0.17975394427776337
train-epoch-step: 50-164 -- Loss: 0.19075006246566772
train-epoch-step: 50-165 -- Loss: 0.15979310870170593
train-epoch-step: 50-166 -- Loss: 0.1266763061285019
train-epoch-step: 50-167 -- Loss: 0.1234973594546318
train-epoch-step: 50-168 -- Loss: 0.19916552305221558
train-epoch-step: 50-169 -- Loss: 0.13565920293331146
train-epoch-step: 50-170 -- Loss: 0.19440697133541107
train-epoch-step: 50-171 -- Loss: 0.1446809321641922
train-epoch-step: 50-172 -- Loss: 0.2546817660331726
train-epoch-step: 50-173 -- Loss: 0.12902964651584625
train-epoch-step: 50-174 -- Loss: 0.2371591180562973
train-epoch-step: 50-175 -- Loss: 0.184956356883049
train-epoch-step: 50-176 -- Loss: 0.1314961016178131
train-epoch-step: 50-177 -- Loss: 0.17772944271564484
train-epoch-step: 50-178 -- Loss: 0.1811281144618988
train-epoch-step: 50-179 -- Loss: 0.14629864692687988
train-epoch-step: 50-180 -- Loss: 0.151169091463089
train-epoch-step: 50-181 -- Loss: 0.16717864573001862
train-epoch-step: 50-182 -- Loss: 0.17690342664718628
train-epoch-step: 50-183 -- Loss: 0.2719633877277374
train-epoch-step: 50-184 -- Loss: 0.13439759612083435
train-epoch-step: 50-185 -- Loss: 0.14108975231647491
train-epoch-step: 50-186 -- Loss: 0.18476085364818573
train-epoch-step: 50-187 -- Loss: 0.2105383425951004
train-epoch-step: 50-188 -- Loss: 0.16975627839565277
train-epoch-step: 50-189 -- Loss: 0.10400582104921341
train-epoch-step: 50-190 -- Loss: 0.17446359992027283
train-epoch-step: 50-191 -- Loss: 0.15277624130249023
train-epoch-step: 50-192 -- Loss: 0.22757408022880554
train-epoch-step: 50-193 -- Loss: 0.20571300387382507
train-epoch-step: 50-194 -- Loss: 0.17779263854026794
train-epoch-step: 50-195 -- Loss: 0.15961383283138275
train-epoch-step: 50-196 -- Loss: 0.16661420464515686
train-epoch-step: 50-197 -- Loss: 0.12155865132808685
train-epoch-step: 50-198 -- Loss: 0.12911085784435272
train-epoch-step: 50-199 -- Loss: 0.14450247585773468
train-epoch-step: 50-200 -- Loss: 0.12146279215812683
train-epoch-step: 50-201 -- Loss: 0.19079117476940155
train-epoch-step: 50-202 -- Loss: 0.15857529640197754
train-epoch-step: 50-203 -- Loss: 0.17081870138645172
train-epoch-step: 50-204 -- Loss: 0.1322031021118164
train-epoch-step: 50-205 -- Loss: 0.1836351752281189
train-epoch-step: 50-206 -- Loss: 0.19581669569015503
train-epoch-step: 50-207 -- Loss: 0.1297767162322998
train-epoch-step: 50-208 -- Loss: 0.17540530860424042
train-epoch-step: 50-209 -- Loss: 0.14457449316978455
train-epoch-step: 50-210 -- Loss: 0.1294786036014557
train-epoch-step: 50-211 -- Loss: 0.20470181107521057
train-epoch-step: 50-212 -- Loss: 0.21264776587486267
train-epoch-step: 50-213 -- Loss: 0.12496989220380783
train-epoch-step: 50-214 -- Loss: 0.15102627873420715
train-epoch-step: 50-215 -- Loss: 0.1258448213338852
train-epoch-step: 50-216 -- Loss: 0.19884824752807617
train-epoch-step: 50-217 -- Loss: 0.21513406932353973
train-epoch-step: 50-218 -- Loss: 0.15330997109413147
train-epoch-step: 50-219 -- Loss: 0.18444320559501648
train-epoch-step: 50-220 -- Loss: 0.12788358330726624
train-epoch-step: 50-221 -- Loss: 0.2006816565990448
train-epoch-step: 50-222 -- Loss: 0.11243315786123276
train-epoch-step: 50-223 -- Loss: 0.1727747619152069
train-epoch-step: 50-224 -- Loss: 0.2130090594291687
train-epoch-step: 50-225 -- Loss: 0.26849427819252014
train-epoch-step: 50-226 -- Loss: 0.20229002833366394
train-epoch-step: 50-227 -- Loss: 0.21925418078899384
train-epoch-step: 50-228 -- Loss: 0.17304013669490814
train-epoch-step: 50-229 -- Loss: 0.16510000824928284
train-epoch-step: 50-230 -- Loss: 0.16175225377082825
train-epoch-step: 50-231 -- Loss: 0.1534101963043213
train-epoch-step: 50-232 -- Loss: 0.18275950849056244
train-epoch-step: 50-233 -- Loss: 0.08285050839185715
train-epoch-step: 50-234 -- Loss: 0.177408367395401
train-epoch-step: 50-235 -- Loss: 0.1454310566186905
train-epoch-step: 50-236 -- Loss: 0.17677375674247742
train-epoch-step: 50-237 -- Loss: 0.23301903903484344
train-epoch-step: 50-238 -- Loss: 0.1530626267194748
train-epoch-step: 50-239 -- Loss: 0.12267443537712097
train-epoch-step: 50-240 -- Loss: 0.21872302889823914
train-epoch-step: 50-241 -- Loss: 0.1536187082529068
train-epoch-step: 50-242 -- Loss: 0.22044801712036133
train-epoch-step: 50-243 -- Loss: 0.2330557405948639
train-epoch-step: 50-244 -- Loss: 0.20540408790111542
train-epoch-step: 50-245 -- Loss: 0.20403268933296204
train-epoch-step: 50-246 -- Loss: 0.21561120450496674
train-epoch-step: 50-247 -- Loss: 0.2341194450855255
train-epoch-step: 50-248 -- Loss: 0.18428748846054077
train-epoch-step: 50-249 -- Loss: 0.1356925219297409
train-epoch-step: 50-250 -- Loss: 0.18970081210136414
train-epoch-step: 50-251 -- Loss: 0.10344921797513962
train-epoch-step: 50-252 -- Loss: 0.19416432082653046
train-epoch-step: 50-253 -- Loss: 0.13264590501785278
train-epoch-step: 50-254 -- Loss: 0.20948629081249237
train-epoch-step: 50-255 -- Loss: 0.14433521032333374
train-epoch-step: 50-256 -- Loss: 0.13953104615211487
train-epoch-step: 50-257 -- Loss: 0.18503670394420624
train-epoch-step: 50-258 -- Loss: 0.14696568250656128
train-epoch-step: 50-259 -- Loss: 0.16312123835086823
train-epoch-step: 50-260 -- Loss: 0.1992066353559494
train-epoch-step: 50-261 -- Loss: 0.17206376791000366
train-epoch-step: 50-262 -- Loss: 0.2818177342414856
train-epoch-step: 50-263 -- Loss: 0.21582701802253723
train-epoch-step: 50-264 -- Loss: 0.17580315470695496
train-epoch-step: 50-265 -- Loss: 0.10458285361528397
train-epoch-step: 50-266 -- Loss: 0.1502191424369812
train-epoch-step: 50-267 -- Loss: 0.12605682015419006
train-epoch-step: 50-268 -- Loss: 0.12163414806127548
train-epoch-step: 50-269 -- Loss: 0.1728789210319519
train-epoch-step: 50-270 -- Loss: 0.10809238255023956
train-epoch-step: 50-271 -- Loss: 0.15380266308784485
train-epoch-step: 50-272 -- Loss: 0.11472413688898087
train-epoch-step: 50-273 -- Loss: 0.12443298101425171
train-epoch-step: 50-274 -- Loss: 0.1803319752216339
train-epoch-step: 50-275 -- Loss: 0.18941926956176758
train-epoch-step: 50-276 -- Loss: 0.15745379030704498
train-epoch-step: 50-277 -- Loss: 0.1540369838476181
train-epoch-step: 50-278 -- Loss: 0.14175309240818024
train-epoch-step: 50-279 -- Loss: 0.1403612345457077
train-epoch-step: 50-280 -- Loss: 0.21912996470928192
train-epoch-step: 50-281 -- Loss: 0.1784408688545227
train-epoch-step: 50-282 -- Loss: 0.14089104533195496
train-epoch-step: 50-283 -- Loss: 0.11603671312332153
train-epoch-step: 50-284 -- Loss: 0.1330232173204422
train-epoch-step: 50-285 -- Loss: 0.1880882978439331
train-epoch-step: 50-286 -- Loss: 0.15251368284225464
train-epoch-step: 50-287 -- Loss: 0.19644494354724884
train-epoch-step: 50-288 -- Loss: 0.0946861058473587
train-epoch-step: 50-289 -- Loss: 0.12051976472139359
train-epoch-step: 50-290 -- Loss: 0.17643670737743378
train-epoch-step: 50-291 -- Loss: 0.1166691705584526
train-epoch-step: 50-292 -- Loss: 0.15473714470863342
train-epoch-step: 50-293 -- Loss: 0.1328912079334259
train-epoch-step: 50-294 -- Loss: 0.16215071082115173
train-epoch-step: 50-295 -- Loss: 0.26365169882774353
train-epoch-step: 50-296 -- Loss: 0.16418951749801636
train-epoch-step: 50-297 -- Loss: 0.16937051713466644
train-epoch-step: 50-298 -- Loss: 0.22725079953670502
train-epoch-step: 50-299 -- Loss: 0.14589697122573853
train-epoch-step: 50-300 -- Loss: 0.16347236931324005
train-epoch-step: 50-301 -- Loss: 0.18672694265842438
train-epoch-step: 50-302 -- Loss: 0.2123282104730606
train-epoch-step: 50-303 -- Loss: 0.20268194377422333
train-epoch-step: 50-304 -- Loss: 0.12220093607902527
train-epoch-step: 50-305 -- Loss: 0.1412348747253418
train-epoch-step: 50-306 -- Loss: 0.20779910683631897
train-epoch-step: 50-307 -- Loss: 0.16523237526416779
train-epoch-step: 50-308 -- Loss: 0.2211313396692276
train-epoch-step: 50-309 -- Loss: 0.15393514931201935
train-epoch-step: 50-310 -- Loss: 0.16285789012908936
train-epoch-step: 50-311 -- Loss: 0.15876901149749756
train-epoch-step: 50-312 -- Loss: 0.2030203938484192
train-epoch-step: 50-313 -- Loss: 0.09848786890506744
train-epoch-step: 50-314 -- Loss: 0.19079649448394775
train-epoch-step: 50-315 -- Loss: 0.1675575077533722
train-epoch-step: 50-316 -- Loss: 0.1506502628326416
train-epoch-step: 50-317 -- Loss: 0.1360013335943222
train-epoch-step: 50-318 -- Loss: 0.15474404394626617
train-epoch-step: 50-319 -- Loss: 0.16502021253108978
train-epoch-step: 50-320 -- Loss: 0.11348092555999756
train-epoch-step: 50-321 -- Loss: 0.13025043904781342
train-epoch-step: 50-322 -- Loss: 0.21150974929332733
train-epoch-step: 50-323 -- Loss: 0.15671087801456451
train-epoch-step: 50-324 -- Loss: 0.24976804852485657
train-epoch-step: 50-325 -- Loss: 0.1511155068874359
train-epoch-step: 50-326 -- Loss: 0.1665533185005188
train-epoch-step: 50-327 -- Loss: 0.1968536674976349
train-epoch-step: 50-328 -- Loss: 0.18766342103481293
train-epoch-step: 50-329 -- Loss: 0.33165207505226135
train-epoch-step: 50-330 -- Loss: 0.35468024015426636
train-epoch-step: 50-331 -- Loss: 0.20864351093769073
train-epoch-step: 50-332 -- Loss: 0.09743282943964005
train-epoch-step: 50-333 -- Loss: 0.17717722058296204
train-epoch-step: 50-334 -- Loss: 0.1498810201883316
train-epoch-step: 50-335 -- Loss: 0.16845032572746277
train-epoch-step: 50-336 -- Loss: 0.1456681489944458
train-epoch-step: 50-337 -- Loss: 0.1980459839105606
train-epoch-step: 50-338 -- Loss: 0.15819714963436127
train-epoch-step: 50-339 -- Loss: 0.14080266654491425
train-epoch-step: 50-340 -- Loss: 0.1916152834892273
train-epoch-step: 50-341 -- Loss: 0.13561783730983734
train-epoch-step: 50-342 -- Loss: 0.158853217959404
train-epoch-step: 50-343 -- Loss: 0.14907468855381012
train-epoch-step: 50-344 -- Loss: 0.16938579082489014
train-epoch-step: 50-345 -- Loss: 0.12428106367588043
train-epoch-step: 50-346 -- Loss: 0.1967616081237793
train-epoch-step: 50-347 -- Loss: 0.1495591551065445
train-epoch-step: 50-348 -- Loss: 0.19692598283290863
train-epoch-step: 50-349 -- Loss: 0.19479620456695557
train-epoch-step: 50-350 -- Loss: 0.2471064329147339
train-epoch-step: 50-351 -- Loss: 0.18659350275993347
train-epoch-step: 50-352 -- Loss: 0.11891117691993713
train-epoch-step: 50-353 -- Loss: 0.1906067430973053
train-epoch-step: 50-354 -- Loss: 0.27639567852020264
train-epoch-step: 50-355 -- Loss: 0.11740341037511826
train-epoch-step: 50-356 -- Loss: 0.11373917758464813
train-epoch-step: 50-357 -- Loss: 0.19186833500862122
train-epoch-step: 50-358 -- Loss: 0.18439209461212158
train-epoch-step: 50-359 -- Loss: 0.13362520933151245
train-epoch-step: 50-360 -- Loss: 0.12016859650611877
train-epoch-step: 50-361 -- Loss: 0.2331889569759369
train-epoch-step: 50-362 -- Loss: 0.16441333293914795
train-epoch-step: 50-363 -- Loss: 0.1063835471868515
train-epoch-step: 50-364 -- Loss: 0.17693817615509033
train-epoch-step: 50-365 -- Loss: 0.16746196150779724
train-epoch-step: 50-366 -- Loss: 0.2123958021402359
train-epoch-step: 50-367 -- Loss: 0.22717683017253876
train-epoch-step: 50-368 -- Loss: 0.20346520841121674
train-epoch-step: 50-369 -- Loss: 0.26987749338150024
train-epoch-step: 50-370 -- Loss: 0.12016540765762329
train-epoch-step: 50-371 -- Loss: 0.11869638413190842
train-epoch-step: 50-372 -- Loss: 0.1433616727590561
train-epoch-step: 50-373 -- Loss: 0.19757996499538422
train-epoch-step: 50-374 -- Loss: 0.15029433369636536
train-epoch-step: 50-375 -- Loss: 0.2618473172187805
train-epoch-step: 50-376 -- Loss: 0.1686052531003952
train-epoch-step: 50-377 -- Loss: 0.22706817090511322
train-epoch-step: 50-378 -- Loss: 0.19491370022296906
train-epoch-step: 50-379 -- Loss: 0.11956895887851715
train-epoch-step: 50-380 -- Loss: 0.09280329942703247
train-epoch-step: 50-381 -- Loss: 0.23151403665542603
train-epoch-step: 50-382 -- Loss: 0.22983311116695404
train-epoch-step: 50-383 -- Loss: 0.16900436580181122
train-epoch-step: 50-384 -- Loss: 0.21096400916576385
train-epoch-step: 50-385 -- Loss: 0.24052183330059052
train-epoch-step: 50-386 -- Loss: 0.1831422746181488
train-epoch-step: 50-387 -- Loss: 0.20459873974323273
train-epoch-step: 50-388 -- Loss: 0.182047501206398
train-epoch-step: 50-389 -- Loss: 0.1644590049982071
train-epoch-step: 50-390 -- Loss: 0.14319080114364624
train-epoch-step: 50-391 -- Loss: 0.14207756519317627
train-epoch-step: 50-392 -- Loss: 0.18332640826702118
train-epoch-step: 50-393 -- Loss: 0.15193839371204376
train-epoch-step: 50-394 -- Loss: 0.1956823468208313
train-epoch-step: 50-395 -- Loss: 0.15123744308948517
train-epoch-step: 50-396 -- Loss: 0.12294319272041321
train-epoch-step: 50-397 -- Loss: 0.11950789391994476
train-epoch-step: 50-398 -- Loss: 0.1997411847114563
train-epoch-step: 50-399 -- Loss: 0.17953965067863464
train-epoch-step: 50-400 -- Loss: 0.2688489854335785
train-epoch-step: 50-401 -- Loss: 0.11604620516300201
train-epoch-step: 50-402 -- Loss: 0.25453105568885803
train-epoch-step: 50-403 -- Loss: 0.15281552076339722
train-epoch-step: 50-404 -- Loss: 0.13630685210227966
train-epoch-step: 50-405 -- Loss: 0.13897302746772766
train-epoch-step: 50-406 -- Loss: 0.16721701622009277
train-epoch-step: 50-407 -- Loss: 0.110805943608284
train-epoch-step: 50-408 -- Loss: 0.15983951091766357
train-epoch-step: 50-409 -- Loss: 0.1673762947320938
train-epoch-step: 50-410 -- Loss: 0.17319101095199585
train-epoch-step: 50-411 -- Loss: 0.194912850856781
train-epoch-step: 50-412 -- Loss: 0.13001614809036255
train-epoch-step: 50-413 -- Loss: 0.14358113706111908
train-epoch-step: 50-414 -- Loss: 0.13241639733314514
train-epoch-step: 50-415 -- Loss: 0.1312914490699768
train-epoch-step: 50-416 -- Loss: 0.2654484212398529
train-epoch-step: 50-417 -- Loss: 0.18577882647514343
train-epoch-step: 50-418 -- Loss: 0.22545278072357178
train-epoch-step: 50-419 -- Loss: 0.16059304773807526
train-epoch-step: 50-420 -- Loss: 0.1489383429288864
train-epoch-step: 50-421 -- Loss: 0.1748753786087036
train-epoch-step: 50-422 -- Loss: 0.14492730796337128
train-epoch-step: 50-423 -- Loss: 0.17370973527431488
train-epoch-step: 50-424 -- Loss: 0.1338234692811966
train-epoch-step: 50-425 -- Loss: 0.1779487282037735
train-epoch-step: 50-426 -- Loss: 0.159378781914711
train-epoch-step: 50-427 -- Loss: 0.1174498200416565
train-epoch-step: 50-428 -- Loss: 0.1820707619190216
train-epoch-step: 50-429 -- Loss: 0.17197935283184052
train-epoch-step: 50-430 -- Loss: 0.13525545597076416
train-epoch-step: 50-431 -- Loss: 0.15891645848751068
train-epoch-step: 50-432 -- Loss: 0.23152917623519897
train-epoch-step: 50-433 -- Loss: 0.13334810733795166
train-epoch-step: 50-434 -- Loss: 0.12855875492095947
train-epoch-step: 50-435 -- Loss: 0.15117883682250977
train-epoch-step: 50-436 -- Loss: 0.15297594666481018
train-epoch-step: 50-437 -- Loss: 0.13178732991218567
train-epoch-step: 50-438 -- Loss: 0.16347536444664001
train-epoch-step: 50-439 -- Loss: 0.25592952966690063
train-epoch-step: 50-440 -- Loss: 0.12801924347877502
train-epoch-step: 50-441 -- Loss: 0.1958881914615631
train-epoch-step: 50-442 -- Loss: 0.17446932196617126
train-epoch-step: 50-443 -- Loss: 0.1498100459575653
train-epoch-step: 50-444 -- Loss: 0.1665785014629364
train-epoch-step: 50-445 -- Loss: 0.17581161856651306
train-epoch-step: 50-446 -- Loss: 0.15095818042755127
train-epoch-step: 50-447 -- Loss: 0.19234555959701538
train-epoch-step: 50-448 -- Loss: 0.22433024644851685
train-epoch-step: 50-449 -- Loss: 0.18474410474300385
train-epoch-step: 50-450 -- Loss: 0.18030327558517456
train-epoch-step: 50-451 -- Loss: 0.13812638819217682
train-epoch-step: 50-452 -- Loss: 0.12414524704217911
train-epoch-step: 50-453 -- Loss: 0.08874412626028061
train-epoch-step: 50-454 -- Loss: 0.22607047855854034
train-epoch-step: 50-455 -- Loss: 0.12052552402019501
train-epoch-step: 50-456 -- Loss: 0.11324377357959747
train-epoch-step: 50-457 -- Loss: 0.2077825367450714
train-epoch-step: 50-458 -- Loss: 0.1379108726978302
train-epoch-step: 50-459 -- Loss: 0.2102629840373993
train-epoch-step: 50-460 -- Loss: 0.12316840887069702
train-epoch-step: 50-461 -- Loss: 0.13184840977191925
train-epoch-step: 50-462 -- Loss: 0.14986903965473175
train-epoch-step: 50-463 -- Loss: 0.13287264108657837
train-epoch-step: 50-464 -- Loss: 0.15717166662216187
train-epoch-step: 50-465 -- Loss: 0.238855242729187
train-epoch-step: 50-466 -- Loss: 0.19403071701526642
train-epoch-step: 50-467 -- Loss: 0.10940801352262497
train-epoch-step: 50-468 -- Loss: 0.16156744956970215
train-epoch-step: 50-469 -- Loss: 0.2053060233592987
train-epoch-step: 50-470 -- Loss: 0.16537220776081085
train-epoch-step: 50-471 -- Loss: 0.15280060470104218
train-epoch-step: 50-472 -- Loss: 0.15324722230434418
train-epoch-step: 50-473 -- Loss: 0.15174135565757751
train-epoch-step: 50-474 -- Loss: 0.1124388724565506
train-epoch-step: 50-475 -- Loss: 0.10721062868833542
train-epoch-step: 50-476 -- Loss: 0.1944381594657898
train-epoch-step: 50-477 -- Loss: 0.18942713737487793
train-epoch-step: 50-478 -- Loss: 0.1831679344177246
train-epoch-step: 50-479 -- Loss: 0.14045347273349762
train-epoch-step: 50-480 -- Loss: 0.19282886385917664
train-epoch-step: 50-481 -- Loss: 0.27923768758773804
train-epoch-step: 50-482 -- Loss: 0.24167943000793457
train-epoch-step: 50-483 -- Loss: 0.1768667995929718
train-epoch-step: 50-484 -- Loss: 0.20593242347240448
train-epoch-step: 50-485 -- Loss: 0.12521779537200928
train-epoch-step: 50-486 -- Loss: 0.22515131533145905
train-epoch-step: 50-487 -- Loss: 0.22650612890720367
train-epoch-step: 50-488 -- Loss: 0.18981444835662842
train-epoch-step: 50-489 -- Loss: 0.2491876780986786
train-epoch-step: 50-490 -- Loss: 0.1338973045349121
train-epoch-step: 50-491 -- Loss: 0.13768790662288666
train-epoch-step: 50-492 -- Loss: 0.1332450956106186
train-epoch-step: 50-493 -- Loss: 0.18890398740768433
train-epoch-step: 50-494 -- Loss: 0.1971679925918579
train-epoch-step: 50-495 -- Loss: 0.20669710636138916
train-epoch-step: 50-496 -- Loss: 0.14059309661388397
train-epoch-step: 50-497 -- Loss: 0.18305200338363647
train-epoch-step: 50-498 -- Loss: 0.15677562355995178
train-epoch-step: 50-499 -- Loss: 0.17806370556354523
train-epoch-step: 50-500 -- Loss: 0.15571631491184235
train-epoch-step: 50-501 -- Loss: 0.20520272850990295
train-epoch-step: 50-502 -- Loss: 0.15393956005573273
train-epoch-step: 50-503 -- Loss: 0.20988938212394714
train-epoch-step: 50-504 -- Loss: 0.11916155368089676
train-epoch-step: 50-505 -- Loss: 0.17152471840381622
train-epoch-step: 50-506 -- Loss: 0.11425632238388062
train-epoch-step: 50-507 -- Loss: 0.17450577020645142
train-epoch-step: 50-508 -- Loss: 0.1745820939540863
train-epoch-step: 50-509 -- Loss: 0.16424134373664856
train-epoch-step: 50-510 -- Loss: 0.12320002168416977
train-epoch-step: 50-511 -- Loss: 0.21215815842151642
train-epoch-step: 50-512 -- Loss: 0.17154569923877716
train-epoch-step: 50-513 -- Loss: 0.18011534214019775
train-epoch-step: 50-514 -- Loss: 0.14442600309848785
train-epoch-step: 50-515 -- Loss: 0.1541706919670105
train-epoch-step: 50-516 -- Loss: 0.1680452525615692
train-epoch-step: 50-517 -- Loss: 0.17353135347366333
train-epoch-step: 50-518 -- Loss: 0.13866201043128967
train-epoch-step: 50-519 -- Loss: 0.1309211254119873
train-epoch-step: 50-520 -- Loss: 0.18123048543930054
train-epoch-step: 50-521 -- Loss: 0.22689084708690643
train-epoch-step: 50-522 -- Loss: 0.17418120801448822
train-epoch-step: 50-523 -- Loss: 0.15158788859844208
train-epoch-step: 50-524 -- Loss: 0.17140577733516693
train-epoch-step: 50-525 -- Loss: 0.18949313461780548
train-epoch-step: 50-526 -- Loss: 0.1272154152393341
train-epoch-step: 50-527 -- Loss: 0.14669303596019745
train-epoch-step: 50-528 -- Loss: 0.15923954546451569
train-epoch-step: 50-529 -- Loss: 0.1523573398590088
train-epoch-step: 50-530 -- Loss: 0.16447508335113525
train-epoch-step: 50-531 -- Loss: 0.19151993095874786
train-epoch-step: 50-532 -- Loss: 0.16587141156196594
train-epoch-step: 50-533 -- Loss: 0.17156030237674713
train-epoch-step: 50-534 -- Loss: 0.12608928978443146
train-epoch-step: 50-535 -- Loss: 0.24775953590869904
train-epoch-step: 50-536 -- Loss: 0.15130415558815002
train-epoch-step: 50-537 -- Loss: 0.14055708050727844
train-epoch-step: 50-538 -- Loss: 0.10090868175029755
train-epoch-step: 50-539 -- Loss: 0.1753201186656952
train-epoch-step: 50-540 -- Loss: 0.1368686407804489
train-epoch-step: 50-541 -- Loss: 0.20404481887817383
train-epoch-step: 50-542 -- Loss: 0.22062593698501587
train-epoch-step: 50-543 -- Loss: 0.1654125452041626
train-epoch-step: 50-544 -- Loss: 0.2186887115240097
train-epoch-step: 50-545 -- Loss: 0.18934383988380432
train-epoch-step: 50-546 -- Loss: 0.21110689640045166
train-epoch-step: 50-547 -- Loss: 0.17280125617980957
train-epoch-step: 50-548 -- Loss: 0.0895901545882225
train-epoch-step: 50-549 -- Loss: 0.14727680385112762
train-epoch-step: 50-550 -- Loss: 0.2035016268491745
train-epoch-step: 50-551 -- Loss: 0.14979669451713562
train-epoch-step: 50-552 -- Loss: 0.12654082477092743
train-epoch-step: 50-553 -- Loss: 0.18876715004444122
train-epoch-step: 50-554 -- Loss: 0.1834592968225479
train-epoch-step: 50-555 -- Loss: 0.20927263796329498
train-epoch-step: 50-556 -- Loss: 0.14754807949066162
train-epoch-step: 50-557 -- Loss: 0.22813093662261963
train-epoch-step: 50-558 -- Loss: 0.22110088169574738
train-epoch-step: 50-559 -- Loss: 0.1332799196243286
train-epoch-step: 50-560 -- Loss: 0.20490583777427673
train-epoch-step: 50-561 -- Loss: 0.17153050005435944
train-epoch-step: 50-562 -- Loss: 0.16153380274772644
train-epoch-step: 50-563 -- Loss: 0.18780958652496338
train-epoch-step: 50-564 -- Loss: 0.09694263339042664
train-epoch-step: 50-565 -- Loss: 0.17492763698101044
train-epoch-step: 50-566 -- Loss: 0.1444605439901352
train-epoch-step: 50-567 -- Loss: 0.2099292129278183
train-epoch-step: 50-568 -- Loss: 0.15743638575077057
train-epoch-step: 50-569 -- Loss: 0.2357754111289978
train-epoch-step: 50-570 -- Loss: 0.16554704308509827
train-epoch-step: 50-571 -- Loss: 0.21269086003303528
train-epoch-step: 50-572 -- Loss: 0.2370108962059021
train-epoch-step: 50-573 -- Loss: 0.20113222301006317
train-epoch-step: 50-574 -- Loss: 0.23930391669273376
train-epoch-step: 50-575 -- Loss: 0.2914908230304718
train-epoch-step: 50-576 -- Loss: 0.12111789733171463
train-epoch-step: 50-577 -- Loss: 0.16153347492218018
train-epoch-step: 50-578 -- Loss: 0.20911641418933868
train-epoch-step: 50-579 -- Loss: 0.15857985615730286
train-epoch-step: 50-580 -- Loss: 0.16805854439735413
train-epoch-step: 50-581 -- Loss: 0.13217291235923767
train-epoch-step: 50-582 -- Loss: 0.2028021663427353
train-epoch-step: 50-583 -- Loss: 0.2070857137441635
train-epoch-step: 50-584 -- Loss: 0.1604975312948227
train-epoch-step: 50-585 -- Loss: 0.1935027539730072
train-epoch-step: 50-586 -- Loss: 0.24829787015914917
train-epoch-step: 50-587 -- Loss: 0.1538846492767334
train-epoch-step: 50-588 -- Loss: 0.12319113314151764
val-epoch-step: 50-589 -- Loss: 0.20745432376861572
val-epoch-step: 50-590 -- Loss: 0.15213140845298767
val-epoch-step: 50-591 -- Loss: 0.23412103950977325
val-epoch-step: 50-592 -- Loss: 0.17449648678302765
val-epoch-step: 50-593 -- Loss: 0.15408429503440857
val-epoch-step: 50-594 -- Loss: 0.3582398295402527
val-epoch-step: 50-595 -- Loss: 0.1769169569015503
val-epoch-step: 50-596 -- Loss: 0.18902361392974854
val-epoch-step: 50-597 -- Loss: 0.17020542919635773
val-epoch-step: 50-598 -- Loss: 0.15869146585464478
val-epoch-step: 50-599 -- Loss: 0.18455660343170166
val-epoch-step: 50-600 -- Loss: 0.16372594237327576
val-epoch-step: 50-601 -- Loss: 0.16026046872138977
val-epoch-step: 50-602 -- Loss: 0.13449819386005402
val-epoch-step: 50-603 -- Loss: 0.20459014177322388
val-epoch-step: 50-604 -- Loss: 0.14458197355270386
val-epoch-step: 50-605 -- Loss: 0.14410945773124695
val-epoch-step: 50-606 -- Loss: 0.2670983076095581
val-epoch-step: 50-607 -- Loss: 0.12055198848247528
val-epoch-step: 50-608 -- Loss: 0.2442890852689743
val-epoch-step: 50-609 -- Loss: 0.165961354970932
val-epoch-step: 50-610 -- Loss: 0.17395561933517456
val-epoch-step: 50-611 -- Loss: 0.17553545534610748
val-epoch-step: 50-612 -- Loss: 0.43307483196258545
val-epoch-step: 50-613 -- Loss: 0.1707524210214615
val-epoch-step: 50-614 -- Loss: 0.17761531472206116
val-epoch-step: 50-615 -- Loss: 0.17372988164424896
val-epoch-step: 50-616 -- Loss: 0.14331011474132538
val-epoch-step: 50-617 -- Loss: 0.19049443304538727
val-epoch-step: 50-618 -- Loss: 0.1745854765176773
val-epoch-step: 50-619 -- Loss: 0.2108633816242218
val-epoch-step: 50-620 -- Loss: 0.13793660700321198
val-epoch-step: 50-621 -- Loss: 0.12380064278841019
val-epoch-step: 50-622 -- Loss: 0.14036624133586884
val-epoch-step: 50-623 -- Loss: 0.1519453376531601
val-epoch-step: 50-624 -- Loss: 0.13975311815738678
val-epoch-step: 50-625 -- Loss: 0.16095301508903503
val-epoch-step: 50-626 -- Loss: 0.14795096218585968
val-epoch-step: 50-627 -- Loss: 0.1869899183511734
val-epoch-step: 50-628 -- Loss: 0.6316362023353577
val-epoch-step: 50-629 -- Loss: 0.19677576422691345
val-epoch-step: 50-630 -- Loss: 0.338747501373291
val-epoch-step: 50-631 -- Loss: 0.14223863184452057
val-epoch-step: 50-632 -- Loss: 0.19929242134094238
val-epoch-step: 50-633 -- Loss: 0.147225484251976
val-epoch-step: 50-634 -- Loss: 0.1514190137386322
val-epoch-step: 50-635 -- Loss: 0.11022376269102097
val-epoch-step: 50-636 -- Loss: 0.17099928855895996
val-epoch-step: 50-637 -- Loss: 0.17731308937072754
val-epoch-step: 50-638 -- Loss: 0.14437426626682281
val-epoch-step: 50-639 -- Loss: 0.25886979699134827
val-epoch-step: 50-640 -- Loss: 0.2532842457294464
val-epoch-step: 50-641 -- Loss: 0.12347223609685898
val-epoch-step: 50-642 -- Loss: 0.17122526466846466
val-epoch-step: 50-643 -- Loss: 0.20408403873443604
val-epoch-step: 50-644 -- Loss: 0.1692931205034256
val-epoch-step: 50-645 -- Loss: 0.21586807072162628
val-epoch-step: 50-646 -- Loss: 0.127361461520195
val-epoch-step: 50-647 -- Loss: 0.12660647928714752
val-epoch-step: 50-648 -- Loss: 0.15484829246997833
val-epoch-step: 50-649 -- Loss: 0.20333528518676758
val-epoch-step: 50-650 -- Loss: 0.24752895534038544
val-epoch-step: 50-651 -- Loss: 0.1447136551141739
val-epoch-step: 50-652 -- Loss: 0.1534353792667389
val-epoch-step: 50-653 -- Loss: 0.21515294909477234
val-epoch-step: 50-654 -- Loss: 0.10966964811086655
Epoch: 50 -- Train Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.97 -- Val Loss: tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.97
                         Test Loss: 0.0 -- Test Acc: 71.97
train-epoch-step: 51-0 -- Loss: 0.21921369433403015
train-epoch-step: 51-1 -- Loss: 0.1424335390329361
train-epoch-step: 51-2 -- Loss: 0.19447839260101318
train-epoch-step: 51-3 -- Loss: 0.1381264626979828
train-epoch-step: 51-4 -- Loss: 0.15424844622612
train-epoch-step: 51-5 -- Loss: 0.1742185652256012
train-epoch-step: 51-6 -- Loss: 0.214925616979599
train-epoch-step: 51-7 -- Loss: 0.16077850759029388
train-epoch-step: 51-8 -- Loss: 0.1733674705028534
train-epoch-step: 51-9 -- Loss: 0.21983930468559265
train-epoch-step: 51-10 -- Loss: 0.18783611059188843
train-epoch-step: 51-11 -- Loss: 0.17026370763778687
train-epoch-step: 51-12 -- Loss: 0.14278379082679749
train-epoch-step: 51-13 -- Loss: 0.17721699178218842
train-epoch-step: 51-14 -- Loss: 0.1586819738149643
train-epoch-step: 51-15 -- Loss: 0.16231459379196167
train-epoch-step: 51-16 -- Loss: 0.1690448522567749
train-epoch-step: 51-17 -- Loss: 0.22339987754821777
train-epoch-step: 51-18 -- Loss: 0.18861421942710876
train-epoch-step: 51-19 -- Loss: 0.1299637258052826
train-epoch-step: 51-20 -- Loss: 0.2144254893064499
train-epoch-step: 51-21 -- Loss: 0.23724228143692017
train-epoch-step: 51-22 -- Loss: 0.13920541107654572
train-epoch-step: 51-23 -- Loss: 0.13985101878643036
train-epoch-step: 51-24 -- Loss: 0.12284399569034576
train-epoch-step: 51-25 -- Loss: 0.2179936319589615
train-epoch-step: 51-26 -- Loss: 0.19408324360847473
train-epoch-step: 51-27 -- Loss: 0.22635868191719055
train-epoch-step: 51-28 -- Loss: 0.12074335664510727
train-epoch-step: 51-29 -- Loss: 0.23441766202449799
train-epoch-step: 51-30 -- Loss: 0.10722631216049194
train-epoch-step: 51-31 -- Loss: 0.13393770158290863
train-epoch-step: 51-32 -- Loss: 0.17052385210990906
train-epoch-step: 51-33 -- Loss: 0.2691931426525116
train-epoch-step: 51-34 -- Loss: 0.16829943656921387
train-epoch-step: 51-35 -- Loss: 0.23608219623565674
train-epoch-step: 51-36 -- Loss: 0.13584135472774506
train-epoch-step: 51-37 -- Loss: 0.13865330815315247
train-epoch-step: 51-38 -- Loss: 0.19342052936553955
train-epoch-step: 51-39 -- Loss: 0.21657556295394897
train-epoch-step: 51-40 -- Loss: 0.1867762804031372
train-epoch-step: 51-41 -- Loss: 0.21971195936203003
train-epoch-step: 51-42 -- Loss: 0.1479315161705017
train-epoch-step: 51-43 -- Loss: 0.25807985663414
train-epoch-step: 51-44 -- Loss: 0.13671442866325378
train-epoch-step: 51-45 -- Loss: 0.1265292465686798
train-epoch-step: 51-46 -- Loss: 0.1688178926706314
train-epoch-step: 51-47 -- Loss: 0.20090723037719727
train-epoch-step: 51-48 -- Loss: 0.159564808011055
train-epoch-step: 51-49 -- Loss: 0.22518885135650635
train-epoch-step: 51-50 -- Loss: 0.10890533030033112
train-epoch-step: 51-51 -- Loss: 0.18051713705062866
train-epoch-step: 51-52 -- Loss: 0.16233542561531067
train-epoch-step: 51-53 -- Loss: 0.22016648948192596
train-epoch-step: 51-54 -- Loss: 0.28638994693756104
train-epoch-step: 51-55 -- Loss: 0.16804885864257812
train-epoch-step: 51-56 -- Loss: 0.1846773326396942
train-epoch-step: 51-57 -- Loss: 0.23739024996757507
train-epoch-step: 51-58 -- Loss: 0.27739277482032776
train-epoch-step: 51-59 -- Loss: 0.24349355697631836
train-epoch-step: 51-60 -- Loss: 0.13725870847702026
train-epoch-step: 51-61 -- Loss: 0.20202401280403137
train-epoch-step: 51-62 -- Loss: 0.1921742856502533
train-epoch-step: 51-63 -- Loss: 0.1407926231622696
train-epoch-step: 51-64 -- Loss: 0.14064347743988037
train-epoch-step: 51-65 -- Loss: 0.17619185149669647
train-epoch-step: 51-66 -- Loss: 0.11144402623176575
train-epoch-step: 51-67 -- Loss: 0.12700486183166504
train-epoch-step: 51-68 -- Loss: 0.20680010318756104
train-epoch-step: 51-69 -- Loss: 0.12268132716417313
train-epoch-step: 51-70 -- Loss: 0.2220703363418579
train-epoch-step: 51-71 -- Loss: 0.25315195322036743
train-epoch-step: 51-72 -- Loss: 0.1762298196554184
train-epoch-step: 51-73 -- Loss: 0.22326740622520447
train-epoch-step: 51-74 -- Loss: 0.09506109356880188
train-epoch-step: 51-75 -- Loss: 0.12530802190303802
train-epoch-step: 51-76 -- Loss: 0.14280255138874054
train-epoch-step: 51-77 -- Loss: 0.23092283308506012
train-epoch-step: 51-78 -- Loss: 0.2532649636268616
train-epoch-step: 51-79 -- Loss: 0.18539030849933624
train-epoch-step: 51-80 -- Loss: 0.24507515132427216
train-epoch-step: 51-81 -- Loss: 0.12364575266838074
train-epoch-step: 51-82 -- Loss: 0.24786940217018127
train-epoch-step: 51-83 -- Loss: 0.17528589069843292
train-epoch-step: 51-84 -- Loss: 0.18461379408836365
train-epoch-step: 51-85 -- Loss: 0.1713961660861969
train-epoch-step: 51-86 -- Loss: 0.11575522273778915
train-epoch-step: 51-87 -- Loss: 0.20577573776245117
train-epoch-step: 51-88 -- Loss: 0.1395552009344101
train-epoch-step: 51-89 -- Loss: 0.18096818029880524
train-epoch-step: 51-90 -- Loss: 0.18795889616012573
train-epoch-step: 51-91 -- Loss: 0.23967401683330536
train-epoch-step: 51-92 -- Loss: 0.15301664173603058
train-epoch-step: 51-93 -- Loss: 0.1687428504228592
train-epoch-step: 51-94 -- Loss: 0.22404249012470245
train-epoch-step: 51-95 -- Loss: 0.1844823658466339
train-epoch-step: 51-96 -- Loss: 0.21067646145820618
train-epoch-step: 51-97 -- Loss: 0.17739130556583405
train-epoch-step: 51-98 -- Loss: 0.15301690995693207
train-epoch-step: 51-99 -- Loss: 0.1770249605178833
train-epoch-step: 51-100 -- Loss: 0.19372907280921936
train-epoch-step: 51-101 -- Loss: 0.2784380614757538
train-epoch-step: 51-102 -- Loss: 0.21735498309135437
train-epoch-step: 51-103 -- Loss: 0.178491473197937
train-epoch-step: 51-104 -- Loss: 0.14593544602394104
train-epoch-step: 51-105 -- Loss: 0.2616533637046814
train-epoch-step: 51-106 -- Loss: 0.17188510298728943
train-epoch-step: 51-107 -- Loss: 0.17989295721054077
train-epoch-step: 51-108 -- Loss: 0.1816236674785614
train-epoch-step: 51-109 -- Loss: 0.1492597907781601
train-epoch-step: 51-110 -- Loss: 0.17766542732715607
train-epoch-step: 51-111 -- Loss: 0.17518164217472076
train-epoch-step: 51-112 -- Loss: 0.16059154272079468
train-epoch-step: 51-113 -- Loss: 0.15506620705127716
train-epoch-step: 51-114 -- Loss: 0.18877407908439636
train-epoch-step: 51-115 -- Loss: 0.15775157511234283
train-epoch-step: 51-116 -- Loss: 0.13488034904003143
train-epoch-step: 51-117 -- Loss: 0.1267903596162796
train-epoch-step: 51-118 -- Loss: 0.18346376717090607
train-epoch-step: 51-119 -- Loss: 0.14927050471305847
train-epoch-step: 51-120 -- Loss: 0.2512218952178955
train-epoch-step: 51-121 -- Loss: 0.23009520769119263
train-epoch-step: 51-122 -- Loss: 0.21354837715625763
train-epoch-step: 51-123 -- Loss: 0.19776932895183563
train-epoch-step: 51-124 -- Loss: 0.12180810421705246
train-epoch-step: 51-125 -- Loss: 0.15059132874011993
train-epoch-step: 51-126 -- Loss: 0.22451317310333252
train-epoch-step: 51-127 -- Loss: 0.16833412647247314
train-epoch-step: 51-128 -- Loss: 0.1680460274219513
train-epoch-step: 51-129 -- Loss: 0.1441517174243927
train-epoch-step: 51-130 -- Loss: 0.19261576235294342
train-epoch-step: 51-131 -- Loss: 0.1359492689371109
train-epoch-step: 51-132 -- Loss: 0.18145227432250977
train-epoch-step: 51-133 -- Loss: 0.11529082804918289
train-epoch-step: 51-134 -- Loss: 0.19089995324611664
train-epoch-step: 51-135 -- Loss: 0.1383705884218216
train-epoch-step: 51-136 -- Loss: 0.13079240918159485
train-epoch-step: 51-137 -- Loss: 0.23942744731903076
train-epoch-step: 51-138 -- Loss: 0.26829907298088074
train-epoch-step: 51-139 -- Loss: 0.1374904066324234
train-epoch-step: 51-140 -- Loss: 0.2008783519268036
train-epoch-step: 51-141 -- Loss: 0.22398057579994202
train-epoch-step: 51-142 -- Loss: 0.19709932804107666
train-epoch-step: 51-143 -- Loss: 0.17004476487636566
train-epoch-step: 51-144 -- Loss: 0.18536651134490967
train-epoch-step: 51-145 -- Loss: 0.14173077046871185
train-epoch-step: 51-146 -- Loss: 0.18282535672187805
train-epoch-step: 51-147 -- Loss: 0.16239133477210999
train-epoch-step: 51-148 -- Loss: 0.15835781395435333
train-epoch-step: 51-149 -- Loss: 0.11906909942626953
train-epoch-step: 51-150 -- Loss: 0.18277961015701294
train-epoch-step: 51-151 -- Loss: 0.18229049444198608
train-epoch-step: 51-152 -- Loss: 0.18881644308567047
train-epoch-step: 51-153 -- Loss: 0.2693800926208496
train-epoch-step: 51-154 -- Loss: 0.12879690527915955
train-epoch-step: 51-155 -- Loss: 0.13460594415664673
train-epoch-step: 51-156 -- Loss: 0.11375030875205994
train-epoch-step: 51-157 -- Loss: 0.1639259159564972
train-epoch-step: 51-158 -- Loss: 0.16785943508148193
train-epoch-step: 51-159 -- Loss: 0.17512652277946472
train-epoch-step: 51-160 -- Loss: 0.20738768577575684
train-epoch-step: 51-161 -- Loss: 0.2066953033208847
train-epoch-step: 51-162 -- Loss: 0.21001982688903809
train-epoch-step: 51-163 -- Loss: 0.1818077117204666
train-epoch-step: 51-164 -- Loss: 0.19020578265190125
train-epoch-step: 51-165 -- Loss: 0.15707001090049744
train-epoch-step: 51-166 -- Loss: 0.12321611493825912
train-epoch-step: 51-167 -- Loss: 0.12015050649642944
train-epoch-step: 51-168 -- Loss: 0.19366872310638428
train-epoch-step: 51-169 -- Loss: 0.13793569803237915
train-epoch-step: 51-170 -- Loss: 0.1954510509967804
train-epoch-step: 51-171 -- Loss: 0.13995787501335144
train-epoch-step: 51-172 -- Loss: 0.25529783964157104
train-epoch-step: 51-173 -- Loss: 0.1295396089553833
train-epoch-step: 51-174 -- Loss: 0.23938997089862823
train-epoch-step: 51-175 -- Loss: 0.1827535778284073
train-epoch-step: 51-176 -- Loss: 0.1352594494819641
train-epoch-step: 51-177 -- Loss: 0.18435265123844147
train-epoch-step: 51-178 -- Loss: 0.172750324010849
train-epoch-step: 51-179 -- Loss: 0.1501375138759613
train-epoch-step: 51-180 -- Loss: 0.15010994672775269
train-epoch-step: 51-181 -- Loss: 0.16583293676376343
train-epoch-step: 51-182 -- Loss: 0.18536219000816345
train-epoch-step: 51-183 -- Loss: 0.26683464646339417
train-epoch-step: 51-184 -- Loss: 0.13609319925308228
train-epoch-step: 51-185 -- Loss: 0.13879424333572388
train-epoch-step: 51-186 -- Loss: 0.1820133626461029
train-epoch-step: 51-187 -- Loss: 0.2036571204662323
train-epoch-step: 51-188 -- Loss: 0.17059382796287537
train-epoch-step: 51-189 -- Loss: 0.10242465138435364
train-epoch-step: 51-190 -- Loss: 0.17768467962741852
train-epoch-step: 51-191 -- Loss: 0.17011339962482452
train-epoch-step: 51-192 -- Loss: 0.22772184014320374
train-epoch-step: 51-193 -- Loss: 0.2010250836610794
train-epoch-step: 51-194 -- Loss: 0.18147656321525574
train-epoch-step: 51-195 -- Loss: 0.16360850632190704
train-epoch-step: 51-196 -- Loss: 0.16894403100013733
train-epoch-step: 51-197 -- Loss: 0.12351660430431366
train-epoch-step: 51-198 -- Loss: 0.12422545254230499
train-epoch-step: 51-199 -- Loss: 0.14418743550777435
train-epoch-step: 51-200 -- Loss: 0.12983691692352295
train-epoch-step: 51-201 -- Loss: 0.18886464834213257
train-epoch-step: 51-202 -- Loss: 0.13514284789562225
train-epoch-step: 51-203 -- Loss: 0.17128707468509674
train-epoch-step: 51-204 -- Loss: 0.13208447396755219
train-epoch-step: 51-205 -- Loss: 0.182546466588974
train-epoch-step: 51-206 -- Loss: 0.198495015501976
train-epoch-step: 51-207 -- Loss: 0.13411058485507965
train-epoch-step: 51-208 -- Loss: 0.17254790663719177
train-epoch-step: 51-209 -- Loss: 0.14188802242279053
train-epoch-step: 51-210 -- Loss: 0.13164645433425903
train-epoch-step: 51-211 -- Loss: 0.20594468712806702
train-epoch-step: 51-212 -- Loss: 0.19366465508937836
train-epoch-step: 51-213 -- Loss: 0.12321595102548599
train-epoch-step: 51-214 -- Loss: 0.1455623358488083
train-epoch-step: 51-215 -- Loss: 0.1274285912513733
train-epoch-step: 51-216 -- Loss: 0.1996605396270752
train-epoch-step: 51-217 -- Loss: 0.2077496349811554
train-epoch-step: 51-218 -- Loss: 0.14064686000347137
train-epoch-step: 51-219 -- Loss: 0.16657127439975739
train-epoch-step: 51-220 -- Loss: 0.13523747026920319
train-epoch-step: 51-221 -- Loss: 0.2009044587612152
train-epoch-step: 51-222 -- Loss: 0.11431511491537094
train-epoch-step: 51-223 -- Loss: 0.16807977855205536
train-epoch-step: 51-224 -- Loss: 0.1835596114397049
train-epoch-step: 51-225 -- Loss: 0.2605222165584564
train-epoch-step: 51-226 -- Loss: 0.19863590598106384
train-epoch-step: 51-227 -- Loss: 0.213971346616745
train-epoch-step: 51-228 -- Loss: 0.17542129755020142
train-epoch-step: 51-229 -- Loss: 0.17233893275260925
train-epoch-step: 51-230 -- Loss: 0.16089458763599396
train-epoch-step: 51-231 -- Loss: 0.15873117744922638
train-epoch-step: 51-232 -- Loss: 0.1794521063566208
train-epoch-step: 51-233 -- Loss: 0.08441271632909775
train-epoch-step: 51-234 -- Loss: 0.17120063304901123
train-epoch-step: 51-235 -- Loss: 0.1439281702041626
train-epoch-step: 51-236 -- Loss: 0.17630337178707123
train-epoch-step: 51-237 -- Loss: 0.23026207089424133
train-epoch-step: 51-238 -- Loss: 0.15607941150665283
train-epoch-step: 51-239 -- Loss: 0.1295936405658722
train-epoch-step: 51-240 -- Loss: 0.2159707099199295
train-epoch-step: 51-241 -- Loss: 0.15287232398986816
train-epoch-step: 51-242 -- Loss: 0.21589890122413635
train-epoch-step: 51-243 -- Loss: 0.2293386161327362
train-epoch-step: 51-244 -- Loss: 0.19998444616794586
train-epoch-step: 51-245 -- Loss: 0.2054256796836853
train-epoch-step: 51-246 -- Loss: 0.21058213710784912
train-epoch-step: 51-247 -- Loss: 0.2011706382036209
train-epoch-step: 51-248 -- Loss: 0.1848379671573639
train-epoch-step: 51-249 -- Loss: 0.13613441586494446
train-epoch-step: 51-250 -- Loss: 0.1962156444787979
train-epoch-step: 51-251 -- Loss: 0.10531093180179596
train-epoch-step: 51-252 -- Loss: 0.18810299038887024
train-epoch-step: 51-253 -- Loss: 0.13313062489032745
train-epoch-step: 51-254 -- Loss: 0.2060040831565857
train-epoch-step: 51-255 -- Loss: 0.14119453728199005
train-epoch-step: 51-256 -- Loss: 0.14450323581695557
train-epoch-step: 51-257 -- Loss: 0.18084000051021576
train-epoch-step: 51-258 -- Loss: 0.14068396389484406
train-epoch-step: 51-259 -- Loss: 0.14394141733646393
train-epoch-step: 51-260 -- Loss: 0.19760599732398987
train-epoch-step: 51-261 -- Loss: 0.16669423878192902
train-epoch-step: 51-262 -- Loss: 0.2904164493083954
train-epoch-step: 51-263 -- Loss: 0.19534830749034882
train-epoch-step: 51-264 -- Loss: 0.1715947985649109
train-epoch-step: 51-265 -- Loss: 0.10583740472793579
train-epoch-step: 51-266 -- Loss: 0.15162557363510132
train-epoch-step: 51-267 -- Loss: 0.1264573335647583
train-epoch-step: 51-268 -- Loss: 0.11779393255710602
train-epoch-step: 51-269 -- Loss: 0.16984659433364868
train-epoch-step: 51-270 -- Loss: 0.10534980893135071
train-epoch-step: 51-271 -- Loss: 0.1424979567527771
train-epoch-step: 51-272 -- Loss: 0.11366341263055801
train-epoch-step: 51-273 -- Loss: 0.12324485927820206
train-epoch-step: 51-274 -- Loss: 0.17499634623527527
train-epoch-step: 51-275 -- Loss: 0.1894291639328003
train-epoch-step: 51-276 -- Loss: 0.15242090821266174
train-epoch-step: 51-277 -- Loss: 0.14969153702259064
train-epoch-step: 51-278 -- Loss: 0.1360107958316803
train-epoch-step: 51-279 -- Loss: 0.1344970017671585
train-epoch-step: 51-280 -- Loss: 0.2102663218975067
train-epoch-step: 51-281 -- Loss: 0.1709112972021103
train-epoch-step: 51-282 -- Loss: 0.14070646464824677
train-epoch-step: 51-283 -- Loss: 0.11377744376659393
train-epoch-step: 51-284 -- Loss: 0.13982534408569336
train-epoch-step: 51-285 -- Loss: 0.1821570098400116
train-epoch-step: 51-286 -- Loss: 0.1473066359758377
train-epoch-step: 51-287 -- Loss: 0.20006480813026428
train-epoch-step: 51-288 -- Loss: 0.09056981652975082
train-epoch-step: 51-289 -- Loss: 0.11544189602136612
train-epoch-step: 51-290 -- Loss: 0.17719146609306335
train-epoch-step: 51-291 -- Loss: 0.11370089650154114
train-epoch-step: 51-292 -- Loss: 0.15116912126541138
train-epoch-step: 51-293 -- Loss: 0.13370846211910248
train-epoch-step: 51-294 -- Loss: 0.1994926929473877
train-epoch-step: 51-295 -- Loss: 0.27491745352745056
train-epoch-step: 51-296 -- Loss: 0.21005353331565857
train-epoch-step: 51-297 -- Loss: 0.18225553631782532
train-epoch-step: 51-298 -- Loss: 0.23658564686775208
train-epoch-step: 51-299 -- Loss: 0.172342449426651
train-epoch-step: 51-300 -- Loss: 0.15978851914405823
train-epoch-step: 51-301 -- Loss: 0.16724392771720886
train-epoch-step: 51-302 -- Loss: 0.21729715168476105
train-epoch-step: 51-303 -- Loss: 0.20240922272205353
train-epoch-step: 51-304 -- Loss: 0.13386036455631256
train-epoch-step: 51-305 -- Loss: 0.14392393827438354
train-epoch-step: 51-306 -- Loss: 0.2082323431968689
train-epoch-step: 51-307 -- Loss: 0.1704460084438324
train-epoch-step: 51-308 -- Loss: 0.2243056744337082
train-epoch-step: 51-309 -- Loss: 0.1582542508840561
train-epoch-step: 51-310 -- Loss: 0.1615837812423706
train-epoch-step: 51-311 -- Loss: 0.15885832905769348
train-epoch-step: 51-312 -- Loss: 0.20305289328098297
train-epoch-step: 51-313 -- Loss: 0.10248272120952606
train-epoch-step: 51-314 -- Loss: 0.18542282283306122
train-epoch-step: 51-315 -- Loss: 0.16569040715694427
train-epoch-step: 51-316 -- Loss: 0.15277691185474396
train-epoch-step: 51-317 -- Loss: 0.1478433907032013
train-epoch-step: 51-318 -- Loss: 0.16533873975276947
train-epoch-step: 51-319 -- Loss: 0.17093847692012787
train-epoch-step: 51-320 -- Loss: 0.11524825543165207
train-epoch-step: 51-321 -- Loss: 0.13561725616455078
train-epoch-step: 51-322 -- Loss: 0.21334615349769592
train-epoch-step: 51-323 -- Loss: 0.15602527558803558
train-epoch-step: 51-324 -- Loss: 0.2511708736419678
train-epoch-step: 51-325 -- Loss: 0.15597280859947205
train-epoch-step: 51-326 -- Loss: 0.16851133108139038
train-epoch-step: 51-327 -- Loss: 0.19952479004859924
train-epoch-step: 51-328 -- Loss: 0.1934240460395813
train-epoch-step: 51-329 -- Loss: 0.3367688059806824
train-epoch-step: 51-330 -- Loss: 0.35727083683013916
train-epoch-step: 51-331 -- Loss: 0.200521320104599
train-epoch-step: 51-332 -- Loss: 0.09902343153953552
train-epoch-step: 51-333 -- Loss: 0.1804920881986618
train-epoch-step: 51-334 -- Loss: 0.15127433836460114
train-epoch-step: 51-335 -- Loss: 0.17348691821098328
train-epoch-step: 51-336 -- Loss: 0.14753153920173645
train-epoch-step: 51-337 -- Loss: 0.20522449910640717
train-epoch-step: 51-338 -- Loss: 0.15736715495586395
train-epoch-step: 51-339 -- Loss: 0.13762430846691132
train-epoch-step: 51-340 -- Loss: 0.19384652376174927
train-epoch-step: 51-341 -- Loss: 0.13829892873764038
train-epoch-step: 51-342 -- Loss: 0.16157734394073486
train-epoch-step: 51-343 -- Loss: 0.14771604537963867
train-epoch-step: 51-344 -- Loss: 0.16746866703033447
train-epoch-step: 51-345 -- Loss: 0.12434963881969452
train-epoch-step: 51-346 -- Loss: 0.19828587770462036
train-epoch-step: 51-347 -- Loss: 0.14884284138679504
train-epoch-step: 51-348 -- Loss: 0.196559339761734
train-epoch-step: 51-349 -- Loss: 0.20067055523395538
train-epoch-step: 51-350 -- Loss: 0.24601837992668152
train-epoch-step: 51-351 -- Loss: 0.1891443133354187
train-epoch-step: 51-352 -- Loss: 0.12439804524183273
train-epoch-step: 51-353 -- Loss: 0.1890634000301361
train-epoch-step: 51-354 -- Loss: 0.2698865234851837
train-epoch-step: 51-355 -- Loss: 0.11461794376373291
train-epoch-step: 51-356 -- Loss: 0.11536189913749695
train-epoch-step: 51-357 -- Loss: 0.1916595846414566
train-epoch-step: 51-358 -- Loss: 0.17946696281433105
train-epoch-step: 51-359 -- Loss: 0.1389051228761673
train-epoch-step: 51-360 -- Loss: 0.12318983674049377
train-epoch-step: 51-361 -- Loss: 0.2346646934747696
train-epoch-step: 51-362 -- Loss: 0.16385594010353088
train-epoch-step: 51-363 -- Loss: 0.10794889181852341
train-epoch-step: 51-364 -- Loss: 0.18676716089248657
train-epoch-step: 51-365 -- Loss: 0.18560902774333954
train-epoch-step: 51-366 -- Loss: 0.19864968955516815
train-epoch-step: 51-367 -- Loss: 0.24446499347686768
train-epoch-step: 51-368 -- Loss: 0.1958773136138916
train-epoch-step: 51-369 -- Loss: 0.2734403908252716
train-epoch-step: 51-370 -- Loss: 0.1306491196155548
train-epoch-step: 51-371 -- Loss: 0.1207919716835022
train-epoch-step: 51-372 -- Loss: 0.14442826807498932
train-epoch-step: 51-373 -- Loss: 0.19073386490345
train-epoch-step: 51-374 -- Loss: 0.15000326931476593
train-epoch-step: 51-375 -- Loss: 0.2619384825229645
train-epoch-step: 51-376 -- Loss: 0.15332341194152832
train-epoch-step: 51-377 -- Loss: 0.2222769856452942
train-epoch-step: 51-378 -- Loss: 0.2023794949054718
train-epoch-step: 51-379 -- Loss: 0.12720654904842377
train-epoch-step: 51-380 -- Loss: 0.09141148626804352
train-epoch-step: 51-381 -- Loss: 0.23842252790927887
train-epoch-step: 51-382 -- Loss: 0.23046240210533142
train-epoch-step: 51-383 -- Loss: 0.17147193849086761
train-epoch-step: 51-384 -- Loss: 0.21404306590557098
train-epoch-step: 51-385 -- Loss: 0.18774226307868958
train-epoch-step: 51-386 -- Loss: 0.18056127429008484
train-epoch-step: 51-387 -- Loss: 0.19717398285865784
train-epoch-step: 51-388 -- Loss: 0.18023686110973358
train-epoch-step: 51-389 -- Loss: 0.1628788560628891
train-epoch-step: 51-390 -- Loss: 0.14139123260974884
train-epoch-step: 51-391 -- Loss: 0.14418359100818634
train-epoch-step: 51-392 -- Loss: 0.18014425039291382
train-epoch-step: 51-393 -- Loss: 0.15222175419330597
train-epoch-step: 51-394 -- Loss: 0.1967824399471283
train-epoch-step: 51-395 -- Loss: 0.14990027248859406
train-epoch-step: 51-396 -- Loss: 0.12407606840133667
train-epoch-step: 51-397 -- Loss: 0.12235873937606812
train-epoch-step: 51-398 -- Loss: 0.19394610822200775
train-epoch-step: 51-399 -- Loss: 0.17372269928455353
train-epoch-step: 51-400 -- Loss: 0.27129775285720825
train-epoch-step: 51-401 -- Loss: 0.11661524325609207
train-epoch-step: 51-402 -- Loss: 0.24961557984352112
train-epoch-step: 51-403 -- Loss: 0.1538524478673935
train-epoch-step: 51-404 -- Loss: 0.1350385546684265
train-epoch-step: 51-405 -- Loss: 0.13859061896800995
train-epoch-step: 51-406 -- Loss: 0.16028669476509094
train-epoch-step: 51-407 -- Loss: 0.11260074377059937
train-epoch-step: 51-408 -- Loss: 0.15858764946460724
train-epoch-step: 51-409 -- Loss: 0.16586540639400482
train-epoch-step: 51-410 -- Loss: 0.17145460844039917
train-epoch-step: 51-411 -- Loss: 0.19827091693878174
train-epoch-step: 51-412 -- Loss: 0.12842413783073425
train-epoch-step: 51-413 -- Loss: 0.14383083581924438
train-epoch-step: 51-414 -- Loss: 0.1313898116350174
train-epoch-step: 51-415 -- Loss: 0.13261425495147705
train-epoch-step: 51-416 -- Loss: 0.26390400528907776
train-epoch-step: 51-417 -- Loss: 0.1874028444290161
train-epoch-step: 51-418 -- Loss: 0.22320082783699036
train-epoch-step: 51-419 -- Loss: 0.1698167622089386
train-epoch-step: 51-420 -- Loss: 0.14773839712142944
train-epoch-step: 51-421 -- Loss: 0.17176753282546997
train-epoch-step: 51-422 -- Loss: 0.1431455761194229
train-epoch-step: 51-423 -- Loss: 0.16960486769676208
train-epoch-step: 51-424 -- Loss: 0.13355693221092224
train-epoch-step: 51-425 -- Loss: 0.1805107742547989
train-epoch-step: 51-426 -- Loss: 0.16028167307376862
train-epoch-step: 51-427 -- Loss: 0.11986451596021652
train-epoch-step: 51-428 -- Loss: 0.19439996778964996
train-epoch-step: 51-429 -- Loss: 0.1729549914598465
train-epoch-step: 51-430 -- Loss: 0.1371832937002182
train-epoch-step: 51-431 -- Loss: 0.15859109163284302
train-epoch-step: 51-432 -- Loss: 0.239130899310112
train-epoch-step: 51-433 -- Loss: 0.13109178841114044
train-epoch-step: 51-434 -- Loss: 0.12608231604099274
train-epoch-step: 51-435 -- Loss: 0.15093131363391876
train-epoch-step: 51-436 -- Loss: 0.1477050632238388
train-epoch-step: 51-437 -- Loss: 0.12848439812660217
train-epoch-step: 51-438 -- Loss: 0.16213908791542053
train-epoch-step: 51-439 -- Loss: 0.25624972581863403
train-epoch-step: 51-440 -- Loss: 0.12924012541770935
train-epoch-step: 51-441 -- Loss: 0.1948995590209961
train-epoch-step: 51-442 -- Loss: 0.1732219159603119
train-epoch-step: 51-443 -- Loss: 0.1514427661895752
train-epoch-step: 51-444 -- Loss: 0.1742720752954483
train-epoch-step: 51-445 -- Loss: 0.17915520071983337
train-epoch-step: 51-446 -- Loss: 0.14954164624214172
train-epoch-step: 51-447 -- Loss: 0.1896747499704361
train-epoch-step: 51-448 -- Loss: 0.22333259880542755
train-epoch-step: 51-449 -- Loss: 0.18815365433692932
train-epoch-step: 51-450 -- Loss: 0.17830528318881989
train-epoch-step: 51-451 -- Loss: 0.1372494101524353
train-epoch-step: 51-452 -- Loss: 0.12866516411304474
train-epoch-step: 51-453 -- Loss: 0.09039762616157532
train-epoch-step: 51-454 -- Loss: 0.22573362290859222
train-epoch-step: 51-455 -- Loss: 0.11815032362937927
train-epoch-step: 51-456 -- Loss: 0.11922009289264679
train-epoch-step: 51-457 -- Loss: 0.20850610733032227
train-epoch-step: 51-458 -- Loss: 0.14258752763271332
train-epoch-step: 51-459 -- Loss: 0.2097611278295517
train-epoch-step: 51-460 -- Loss: 0.12190116196870804
train-epoch-step: 51-461 -- Loss: 0.13196629285812378
train-epoch-step: 51-462 -- Loss: 0.15080048143863678
train-epoch-step: 51-463 -- Loss: 0.13736313581466675
train-epoch-step: 51-464 -- Loss: 0.15531794726848602
train-epoch-step: 51-465 -- Loss: 0.23627713322639465
train-epoch-step: 51-466 -- Loss: 0.19521446526050568
train-epoch-step: 51-467 -- Loss: 0.1077546775341034
train-epoch-step: 51-468 -- Loss: 0.16227471828460693
train-epoch-step: 51-469 -- Loss: 0.20142103731632233
train-epoch-step: 51-470 -- Loss: 0.1684359908103943
train-epoch-step: 51-471 -- Loss: 0.15487995743751526
train-epoch-step: 51-472 -- Loss: 0.15783974528312683
train-epoch-step: 51-473 -- Loss: 0.14500941336154938
train-epoch-step: 51-474 -- Loss: 0.112544484436512
train-epoch-step: 51-475 -- Loss: 0.10532176494598389
train-epoch-step: 51-476 -- Loss: 0.19511841237545013
train-epoch-step: 51-477 -- Loss: 0.2024349570274353
train-epoch-step: 51-478 -- Loss: 0.18664975464344025
train-epoch-step: 51-479 -- Loss: 0.1344144493341446
train-epoch-step: 51-480 -- Loss: 0.19259318709373474
train-epoch-step: 51-481 -- Loss: 0.275722861289978
train-epoch-step: 51-482 -- Loss: 0.24387072026729584
train-epoch-step: 51-483 -- Loss: 0.1720772087574005
train-epoch-step: 51-484 -- Loss: 0.20644265413284302
train-epoch-step: 51-485 -- Loss: 0.12506428360939026
train-epoch-step: 51-486 -- Loss: 0.2234974354505539
train-epoch-step: 51-487 -- Loss: 0.22624348104000092
train-epoch-step: 51-488 -- Loss: 0.18857812881469727
train-epoch-step: 51-489 -- Loss: 0.21654221415519714
train-epoch-step: 51-490 -- Loss: 0.13740797340869904
train-epoch-step: 51-491 -- Loss: 0.1326015591621399
train-epoch-step: 51-492 -- Loss: 0.12306445091962814
train-epoch-step: 51-493 -- Loss: 0.19446730613708496
train-epoch-step: 51-494 -- Loss: 0.211001917719841
train-epoch-step: 51-495 -- Loss: 0.19944998621940613
train-epoch-step: 51-496 -- Loss: 0.1372927576303482
train-epoch-step: 51-497 -- Loss: 0.17929455637931824
train-epoch-step: 51-498 -- Loss: 0.1472609043121338
train-epoch-step: 51-499 -- Loss: 0.16221316158771515
train-epoch-step: 51-500 -- Loss: 0.15047726035118103
train-epoch-step: 51-501 -- Loss: 0.2146560102701187
train-epoch-step: 51-502 -- Loss: 0.14847485721111298
train-epoch-step: 51-503 -- Loss: 0.21316517889499664
train-epoch-step: 51-504 -- Loss: 0.11788355559110641
train-epoch-step: 51-505 -- Loss: 0.1695365309715271
train-epoch-step: 51-506 -- Loss: 0.1112888902425766
train-epoch-step: 51-507 -- Loss: 0.17536330223083496
train-epoch-step: 51-508 -- Loss: 0.17158633470535278
train-epoch-step: 51-509 -- Loss: 0.16210831701755524
train-epoch-step: 51-510 -- Loss: 0.12387636303901672
train-epoch-step: 51-511 -- Loss: 0.20912382006645203
train-epoch-step: 51-512 -- Loss: 0.16936470568180084
train-epoch-step: 51-513 -- Loss: 0.17630022764205933
train-epoch-step: 51-514 -- Loss: 0.1437348574399948
train-epoch-step: 51-515 -- Loss: 0.15327271819114685
train-epoch-step: 51-516 -- Loss: 0.16456040740013123
train-epoch-step: 51-517 -- Loss: 0.1704799234867096
train-epoch-step: 51-518 -- Loss: 0.13585135340690613
train-epoch-step: 51-519 -- Loss: 0.13101162016391754
train-epoch-step: 51-520 -- Loss: 0.1787630170583725
train-epoch-step: 51-521 -- Loss: 0.22372180223464966
train-epoch-step: 51-522 -- Loss: 0.1674540489912033
train-epoch-step: 51-523 -- Loss: 0.15397198498249054
train-epoch-step: 51-524 -- Loss: 0.16194286942481995
train-epoch-step: 51-525 -- Loss: 0.18324866890907288
train-epoch-step: 51-526 -- Loss: 0.12568339705467224
train-epoch-step: 51-527 -- Loss: 0.14788345992565155
train-epoch-step: 51-528 -- Loss: 0.1519257128238678
train-epoch-step: 51-529 -- Loss: 0.15387338399887085
train-epoch-step: 51-530 -- Loss: 0.16293972730636597
train-epoch-step: 51-531 -- Loss: 0.19582268595695496
train-epoch-step: 51-532 -- Loss: 0.16578412055969238
train-epoch-step: 51-533 -- Loss: 0.16978007555007935
train-epoch-step: 51-534 -- Loss: 0.12682805955410004
train-epoch-step: 51-535 -- Loss: 0.24575749039649963
train-epoch-step: 51-536 -- Loss: 0.15329395234584808
train-epoch-step: 51-537 -- Loss: 0.14158859848976135
train-epoch-step: 51-538 -- Loss: 0.10971347987651825
train-epoch-step: 51-539 -- Loss: 0.17332537472248077
train-epoch-step: 51-540 -- Loss: 0.13405776023864746
train-epoch-step: 51-541 -- Loss: 0.20131543278694153
train-epoch-step: 51-542 -- Loss: 0.21795296669006348
train-epoch-step: 51-543 -- Loss: 0.16816216707229614
train-epoch-step: 51-544 -- Loss: 0.2231273502111435
train-epoch-step: 51-545 -- Loss: 0.18720170855522156
train-epoch-step: 51-546 -- Loss: 0.19950872659683228
train-epoch-step: 51-547 -- Loss: 0.17786571383476257
train-epoch-step: 51-548 -- Loss: 0.08971056342124939
train-epoch-step: 51-549 -- Loss: 0.14700046181678772
train-epoch-step: 51-550 -- Loss: 0.1960129588842392
train-epoch-step: 51-551 -- Loss: 0.15128536522388458
train-epoch-step: 51-552 -- Loss: 0.12089316546916962
train-epoch-step: 51-553 -- Loss: 0.18439732491970062
train-epoch-step: 51-554 -- Loss: 0.18196627497673035
train-epoch-step: 51-555 -- Loss: 0.2083578258752823
train-epoch-step: 51-556 -- Loss: 0.1437586545944214
train-epoch-step: 51-557 -- Loss: 0.2221039980649948
train-epoch-step: 51-558 -- Loss: 0.2213808000087738
train-epoch-step: 51-559 -- Loss: 0.13280563056468964
train-epoch-step: 51-560 -- Loss: 0.19760310649871826
train-epoch-step: 51-561 -- Loss: 0.17510992288589478
train-epoch-step: 51-562 -- Loss: 0.15841099619865417
train-epoch-step: 51-563 -- Loss: 0.17824237048625946
train-epoch-step: 51-564 -- Loss: 0.09663444012403488
train-epoch-step: 51-565 -- Loss: 0.18162907660007477
train-epoch-step: 51-566 -- Loss: 0.14806891977787018
train-epoch-step: 51-567 -- Loss: 0.2043772041797638
train-epoch-step: 51-568 -- Loss: 0.1548077017068863
train-epoch-step: 51-569 -- Loss: 0.23731453716754913
train-epoch-step: 51-570 -- Loss: 0.16956812143325806
train-epoch-step: 51-571 -- Loss: 0.20493942499160767
train-epoch-step: 51-572 -- Loss: 0.2444646805524826
train-epoch-step: 51-573 -- Loss: 0.19829146564006805
train-epoch-step: 51-574 -- Loss: 0.2365187406539917
train-epoch-step: 51-575 -- Loss: 0.28573909401893616
train-epoch-step: 51-576 -- Loss: 0.11526565253734589
train-epoch-step: 51-577 -- Loss: 0.16499459743499756
train-epoch-step: 51-578 -- Loss: 0.21658986806869507
train-epoch-step: 51-579 -- Loss: 0.16209447383880615
train-epoch-step: 51-580 -- Loss: 0.16855140030384064
train-epoch-step: 51-581 -- Loss: 0.13592946529388428
train-epoch-step: 51-582 -- Loss: 0.19863960146903992
train-epoch-step: 51-583 -- Loss: 0.21167385578155518
train-epoch-step: 51-584 -- Loss: 0.15870429575443268
train-epoch-step: 51-585 -- Loss: 0.189544215798378
train-epoch-step: 51-586 -- Loss: 0.2512342631816864
train-epoch-step: 51-587 -- Loss: 0.15820379555225372
train-epoch-step: 51-588 -- Loss: 0.12394967675209045
val-epoch-step: 51-589 -- Loss: 0.19801244139671326
val-epoch-step: 51-590 -- Loss: 0.15292802453041077
val-epoch-step: 51-591 -- Loss: 0.2337125837802887
val-epoch-step: 51-592 -- Loss: 0.17965230345726013
val-epoch-step: 51-593 -- Loss: 0.14666227996349335
val-epoch-step: 51-594 -- Loss: 0.4094768762588501
val-epoch-step: 51-595 -- Loss: 0.17584960162639618
val-epoch-step: 51-596 -- Loss: 0.18968698382377625
val-epoch-step: 51-597 -- Loss: 0.17175301909446716
val-epoch-step: 51-598 -- Loss: 0.14815394580364227
val-epoch-step: 51-599 -- Loss: 0.18501436710357666
val-epoch-step: 51-600 -- Loss: 0.18229332566261292
val-epoch-step: 51-601 -- Loss: 0.1550344079732895
val-epoch-step: 51-602 -- Loss: 0.13966256380081177
val-epoch-step: 51-603 -- Loss: 0.19538144767284393
val-epoch-step: 51-604 -- Loss: 0.14600184559822083
val-epoch-step: 51-605 -- Loss: 0.14813928306102753
val-epoch-step: 51-606 -- Loss: 0.2595866322517395
val-epoch-step: 51-607 -- Loss: 0.12607775628566742
val-epoch-step: 51-608 -- Loss: 0.2409174144268036
val-epoch-step: 51-609 -- Loss: 0.1778917908668518
val-epoch-step: 51-610 -- Loss: 0.17765621840953827
val-epoch-step: 51-611 -- Loss: 0.16591191291809082
val-epoch-step: 51-612 -- Loss: 0.4313424825668335
val-epoch-step: 51-613 -- Loss: 0.17953705787658691
val-epoch-step: 51-614 -- Loss: 0.17739790678024292
val-epoch-step: 51-615 -- Loss: 0.17624983191490173
val-epoch-step: 51-616 -- Loss: 0.14491301774978638
val-epoch-step: 51-617 -- Loss: 0.1824236810207367
val-epoch-step: 51-618 -- Loss: 0.20484322309494019
val-epoch-step: 51-619 -- Loss: 0.22126330435276031
val-epoch-step: 51-620 -- Loss: 0.13095465302467346
val-epoch-step: 51-621 -- Loss: 0.12429149448871613
val-epoch-step: 51-622 -- Loss: 0.14509502053260803
val-epoch-step: 51-623 -- Loss: 0.14866112172603607
val-epoch-step: 51-624 -- Loss: 0.14521479606628418
val-epoch-step: 51-625 -- Loss: 0.1578558385372162
val-epoch-step: 51-626 -- Loss: 0.14491096138954163
val-epoch-step: 51-627 -- Loss: 0.1789705455303192
val-epoch-step: 51-628 -- Loss: 0.6959656476974487
val-epoch-step: 51-629 -- Loss: 0.21684901416301727
val-epoch-step: 51-630 -- Loss: 0.3433202803134918
val-epoch-step: 51-631 -- Loss: 0.13796235620975494
val-epoch-step: 51-632 -- Loss: 0.20252719521522522
val-epoch-step: 51-633 -- Loss: 0.14856891334056854
val-epoch-step: 51-634 -- Loss: 0.13990220427513123
val-epoch-step: 51-635 -- Loss: 0.11324594914913177
val-epoch-step: 51-636 -- Loss: 0.1590907871723175
val-epoch-step: 51-637 -- Loss: 0.18070316314697266
val-epoch-step: 51-638 -- Loss: 0.14774906635284424
val-epoch-step: 51-639 -- Loss: 0.25069519877433777
val-epoch-step: 51-640 -- Loss: 0.24116432666778564
val-epoch-step: 51-641 -- Loss: 0.13012352585792542
val-epoch-step: 51-642 -- Loss: 0.1945953518152237
val-epoch-step: 51-643 -- Loss: 0.2028343826532364
val-epoch-step: 51-644 -- Loss: 0.16762971878051758
val-epoch-step: 51-645 -- Loss: 0.2201288491487503
val-epoch-step: 51-646 -- Loss: 0.13030025362968445
val-epoch-step: 51-647 -- Loss: 0.12864381074905396
val-epoch-step: 51-648 -- Loss: 0.15286152064800262
val-epoch-step: 51-649 -- Loss: 0.20571233332157135
val-epoch-step: 51-650 -- Loss: 0.24035637080669403
val-epoch-step: 51-651 -- Loss: 0.1464255303144455
val-epoch-step: 51-652 -- Loss: 0.1536678671836853
val-epoch-step: 51-653 -- Loss: 0.19568616151809692
val-epoch-step: 51-654 -- Loss: 0.11390918493270874
Epoch: 51 -- Train Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 52-0 -- Loss: 0.22018647193908691
train-epoch-step: 52-1 -- Loss: 0.14170007407665253
train-epoch-step: 52-2 -- Loss: 0.1943717896938324
train-epoch-step: 52-3 -- Loss: 0.1410708725452423
train-epoch-step: 52-4 -- Loss: 0.1611473262310028
train-epoch-step: 52-5 -- Loss: 0.1776292622089386
train-epoch-step: 52-6 -- Loss: 0.2082076072692871
train-epoch-step: 52-7 -- Loss: 0.16319146752357483
train-epoch-step: 52-8 -- Loss: 0.18747226893901825
train-epoch-step: 52-9 -- Loss: 0.21492934226989746
train-epoch-step: 52-10 -- Loss: 0.1890120655298233
train-epoch-step: 52-11 -- Loss: 0.17232546210289001
train-epoch-step: 52-12 -- Loss: 0.14536935091018677
train-epoch-step: 52-13 -- Loss: 0.17674531042575836
train-epoch-step: 52-14 -- Loss: 0.15955477952957153
train-epoch-step: 52-15 -- Loss: 0.15919630229473114
train-epoch-step: 52-16 -- Loss: 0.16389167308807373
train-epoch-step: 52-17 -- Loss: 0.21790799498558044
train-epoch-step: 52-18 -- Loss: 0.1872587502002716
train-epoch-step: 52-19 -- Loss: 0.1269499957561493
train-epoch-step: 52-20 -- Loss: 0.2074420005083084
train-epoch-step: 52-21 -- Loss: 0.2398647665977478
train-epoch-step: 52-22 -- Loss: 0.13401521742343903
train-epoch-step: 52-23 -- Loss: 0.14401105046272278
train-epoch-step: 52-24 -- Loss: 0.12331493943929672
train-epoch-step: 52-25 -- Loss: 0.22313347458839417
train-epoch-step: 52-26 -- Loss: 0.19377458095550537
train-epoch-step: 52-27 -- Loss: 0.22231246531009674
train-epoch-step: 52-28 -- Loss: 0.12638379633426666
train-epoch-step: 52-29 -- Loss: 0.23883703351020813
train-epoch-step: 52-30 -- Loss: 0.10656126588582993
train-epoch-step: 52-31 -- Loss: 0.13326700031757355
train-epoch-step: 52-32 -- Loss: 0.17098399996757507
train-epoch-step: 52-33 -- Loss: 0.2675352096557617
train-epoch-step: 52-34 -- Loss: 0.1695237159729004
train-epoch-step: 52-35 -- Loss: 0.2410573959350586
train-epoch-step: 52-36 -- Loss: 0.13486148416996002
train-epoch-step: 52-37 -- Loss: 0.13516579568386078
train-epoch-step: 52-38 -- Loss: 0.16994817554950714
train-epoch-step: 52-39 -- Loss: 0.211506649851799
train-epoch-step: 52-40 -- Loss: 0.18795081973075867
train-epoch-step: 52-41 -- Loss: 0.21250204741954803
train-epoch-step: 52-42 -- Loss: 0.14545010030269623
train-epoch-step: 52-43 -- Loss: 0.25116056203842163
train-epoch-step: 52-44 -- Loss: 0.12195314466953278
train-epoch-step: 52-45 -- Loss: 0.11387001723051071
train-epoch-step: 52-46 -- Loss: 0.16147416830062866
train-epoch-step: 52-47 -- Loss: 0.19483932852745056
train-epoch-step: 52-48 -- Loss: 0.14872823655605316
train-epoch-step: 52-49 -- Loss: 0.22565609216690063
train-epoch-step: 52-50 -- Loss: 0.1080145537853241
train-epoch-step: 52-51 -- Loss: 0.17265893518924713
train-epoch-step: 52-52 -- Loss: 0.15645113587379456
train-epoch-step: 52-53 -- Loss: 0.20151108503341675
train-epoch-step: 52-54 -- Loss: 0.27570074796676636
train-epoch-step: 52-55 -- Loss: 0.1622166931629181
train-epoch-step: 52-56 -- Loss: 0.17043738067150116
train-epoch-step: 52-57 -- Loss: 0.23216916620731354
train-epoch-step: 52-58 -- Loss: 0.2826942205429077
train-epoch-step: 52-59 -- Loss: 0.23085720837116241
train-epoch-step: 52-60 -- Loss: 0.12626314163208008
train-epoch-step: 52-61 -- Loss: 0.1959804743528366
train-epoch-step: 52-62 -- Loss: 0.17741037905216217
train-epoch-step: 52-63 -- Loss: 0.13329415023326874
train-epoch-step: 52-64 -- Loss: 0.1448317915201187
train-epoch-step: 52-65 -- Loss: 0.18137791752815247
train-epoch-step: 52-66 -- Loss: 0.10736750066280365
train-epoch-step: 52-67 -- Loss: 0.11980423331260681
train-epoch-step: 52-68 -- Loss: 0.20166894793510437
train-epoch-step: 52-69 -- Loss: 0.11936400830745697
train-epoch-step: 52-70 -- Loss: 0.22239641845226288
train-epoch-step: 52-71 -- Loss: 0.24863629043102264
train-epoch-step: 52-72 -- Loss: 0.16961826384067535
train-epoch-step: 52-73 -- Loss: 0.20266520977020264
train-epoch-step: 52-74 -- Loss: 0.09351516515016556
train-epoch-step: 52-75 -- Loss: 0.12282386422157288
train-epoch-step: 52-76 -- Loss: 0.1428012102842331
train-epoch-step: 52-77 -- Loss: 0.22440095245838165
train-epoch-step: 52-78 -- Loss: 0.24996772408485413
train-epoch-step: 52-79 -- Loss: 0.18689005076885223
train-epoch-step: 52-80 -- Loss: 0.24531546235084534
train-epoch-step: 52-81 -- Loss: 0.12148134410381317
train-epoch-step: 52-82 -- Loss: 0.24773168563842773
train-epoch-step: 52-83 -- Loss: 0.17151544988155365
train-epoch-step: 52-84 -- Loss: 0.1869872659444809
train-epoch-step: 52-85 -- Loss: 0.1683361530303955
train-epoch-step: 52-86 -- Loss: 0.11757545918226242
train-epoch-step: 52-87 -- Loss: 0.20379719138145447
train-epoch-step: 52-88 -- Loss: 0.13541074097156525
train-epoch-step: 52-89 -- Loss: 0.1858924925327301
train-epoch-step: 52-90 -- Loss: 0.18690209090709686
train-epoch-step: 52-91 -- Loss: 0.24426771700382233
train-epoch-step: 52-92 -- Loss: 0.15159350633621216
train-epoch-step: 52-93 -- Loss: 0.16666921973228455
train-epoch-step: 52-94 -- Loss: 0.213250994682312
train-epoch-step: 52-95 -- Loss: 0.18754589557647705
train-epoch-step: 52-96 -- Loss: 0.21012839674949646
train-epoch-step: 52-97 -- Loss: 0.1699521243572235
train-epoch-step: 52-98 -- Loss: 0.15456511080265045
train-epoch-step: 52-99 -- Loss: 0.17927005887031555
train-epoch-step: 52-100 -- Loss: 0.18242624402046204
train-epoch-step: 52-101 -- Loss: 0.25016579031944275
train-epoch-step: 52-102 -- Loss: 0.21118904650211334
train-epoch-step: 52-103 -- Loss: 0.17764313519001007
train-epoch-step: 52-104 -- Loss: 0.14346423745155334
train-epoch-step: 52-105 -- Loss: 0.2598987817764282
train-epoch-step: 52-106 -- Loss: 0.16780875623226166
train-epoch-step: 52-107 -- Loss: 0.18283811211585999
train-epoch-step: 52-108 -- Loss: 0.1823357790708542
train-epoch-step: 52-109 -- Loss: 0.14199450612068176
train-epoch-step: 52-110 -- Loss: 0.1756456047296524
train-epoch-step: 52-111 -- Loss: 0.1738496571779251
train-epoch-step: 52-112 -- Loss: 0.16233038902282715
train-epoch-step: 52-113 -- Loss: 0.15511980652809143
train-epoch-step: 52-114 -- Loss: 0.1891898512840271
train-epoch-step: 52-115 -- Loss: 0.15831144154071808
train-epoch-step: 52-116 -- Loss: 0.13534538447856903
train-epoch-step: 52-117 -- Loss: 0.125131756067276
train-epoch-step: 52-118 -- Loss: 0.18857324123382568
train-epoch-step: 52-119 -- Loss: 0.14514082670211792
train-epoch-step: 52-120 -- Loss: 0.24307237565517426
train-epoch-step: 52-121 -- Loss: 0.22619742155075073
train-epoch-step: 52-122 -- Loss: 0.21714556217193604
train-epoch-step: 52-123 -- Loss: 0.2005847990512848
train-epoch-step: 52-124 -- Loss: 0.11842650920152664
train-epoch-step: 52-125 -- Loss: 0.15020738542079926
train-epoch-step: 52-126 -- Loss: 0.2253432273864746
train-epoch-step: 52-127 -- Loss: 0.16086985170841217
train-epoch-step: 52-128 -- Loss: 0.1655489206314087
train-epoch-step: 52-129 -- Loss: 0.14167577028274536
train-epoch-step: 52-130 -- Loss: 0.1860666275024414
train-epoch-step: 52-131 -- Loss: 0.13169889152050018
train-epoch-step: 52-132 -- Loss: 0.18631519377231598
train-epoch-step: 52-133 -- Loss: 0.11075467616319656
train-epoch-step: 52-134 -- Loss: 0.18351854383945465
train-epoch-step: 52-135 -- Loss: 0.13042056560516357
train-epoch-step: 52-136 -- Loss: 0.12310680747032166
train-epoch-step: 52-137 -- Loss: 0.23497481644153595
train-epoch-step: 52-138 -- Loss: 0.2606293261051178
train-epoch-step: 52-139 -- Loss: 0.1336483657360077
train-epoch-step: 52-140 -- Loss: 0.21155662834644318
train-epoch-step: 52-141 -- Loss: 0.2225106656551361
train-epoch-step: 52-142 -- Loss: 0.20161738991737366
train-epoch-step: 52-143 -- Loss: 0.16804131865501404
train-epoch-step: 52-144 -- Loss: 0.18262404203414917
train-epoch-step: 52-145 -- Loss: 0.13637466728687286
train-epoch-step: 52-146 -- Loss: 0.1750350296497345
train-epoch-step: 52-147 -- Loss: 0.16374002397060394
train-epoch-step: 52-148 -- Loss: 0.15651963651180267
train-epoch-step: 52-149 -- Loss: 0.11805703490972519
train-epoch-step: 52-150 -- Loss: 0.18486499786376953
train-epoch-step: 52-151 -- Loss: 0.18354769051074982
train-epoch-step: 52-152 -- Loss: 0.20105990767478943
train-epoch-step: 52-153 -- Loss: 0.2684546113014221
train-epoch-step: 52-154 -- Loss: 0.12923696637153625
train-epoch-step: 52-155 -- Loss: 0.13586944341659546
train-epoch-step: 52-156 -- Loss: 0.11565710604190826
train-epoch-step: 52-157 -- Loss: 0.15921151638031006
train-epoch-step: 52-158 -- Loss: 0.16224625706672668
train-epoch-step: 52-159 -- Loss: 0.17342635989189148
train-epoch-step: 52-160 -- Loss: 0.20631375908851624
train-epoch-step: 52-161 -- Loss: 0.20028898119926453
train-epoch-step: 52-162 -- Loss: 0.20562586188316345
train-epoch-step: 52-163 -- Loss: 0.18209847807884216
train-epoch-step: 52-164 -- Loss: 0.1892184168100357
train-epoch-step: 52-165 -- Loss: 0.15848203003406525
train-epoch-step: 52-166 -- Loss: 0.12647269666194916
train-epoch-step: 52-167 -- Loss: 0.11889776587486267
train-epoch-step: 52-168 -- Loss: 0.19639486074447632
train-epoch-step: 52-169 -- Loss: 0.13478094339370728
train-epoch-step: 52-170 -- Loss: 0.1940179169178009
train-epoch-step: 52-171 -- Loss: 0.14381656050682068
train-epoch-step: 52-172 -- Loss: 0.2598133087158203
train-epoch-step: 52-173 -- Loss: 0.13055630028247833
train-epoch-step: 52-174 -- Loss: 0.245070219039917
train-epoch-step: 52-175 -- Loss: 0.1842273622751236
train-epoch-step: 52-176 -- Loss: 0.12887635827064514
train-epoch-step: 52-177 -- Loss: 0.17577239871025085
train-epoch-step: 52-178 -- Loss: 0.1828281283378601
train-epoch-step: 52-179 -- Loss: 0.1543470025062561
train-epoch-step: 52-180 -- Loss: 0.14970079064369202
train-epoch-step: 52-181 -- Loss: 0.1665656864643097
train-epoch-step: 52-182 -- Loss: 0.1757279485464096
train-epoch-step: 52-183 -- Loss: 0.26535192131996155
train-epoch-step: 52-184 -- Loss: 0.13704299926757812
train-epoch-step: 52-185 -- Loss: 0.13990546762943268
train-epoch-step: 52-186 -- Loss: 0.20201779901981354
train-epoch-step: 52-187 -- Loss: 0.20867058634757996
train-epoch-step: 52-188 -- Loss: 0.16787683963775635
train-epoch-step: 52-189 -- Loss: 0.10124155133962631
train-epoch-step: 52-190 -- Loss: 0.17634829878807068
train-epoch-step: 52-191 -- Loss: 0.1577104777097702
train-epoch-step: 52-192 -- Loss: 0.22972798347473145
train-epoch-step: 52-193 -- Loss: 0.19799447059631348
train-epoch-step: 52-194 -- Loss: 0.17857366800308228
train-epoch-step: 52-195 -- Loss: 0.16216017305850983
train-epoch-step: 52-196 -- Loss: 0.16912171244621277
train-epoch-step: 52-197 -- Loss: 0.11927920579910278
train-epoch-step: 52-198 -- Loss: 0.1241038590669632
train-epoch-step: 52-199 -- Loss: 0.1446133404970169
train-epoch-step: 52-200 -- Loss: 0.12403208017349243
train-epoch-step: 52-201 -- Loss: 0.18608030676841736
train-epoch-step: 52-202 -- Loss: 0.1336451768875122
train-epoch-step: 52-203 -- Loss: 0.17269007861614227
train-epoch-step: 52-204 -- Loss: 0.1311751753091812
train-epoch-step: 52-205 -- Loss: 0.18030643463134766
train-epoch-step: 52-206 -- Loss: 0.20221154391765594
train-epoch-step: 52-207 -- Loss: 0.12843485176563263
train-epoch-step: 52-208 -- Loss: 0.17289063334465027
train-epoch-step: 52-209 -- Loss: 0.14200299978256226
train-epoch-step: 52-210 -- Loss: 0.13047760725021362
train-epoch-step: 52-211 -- Loss: 0.20436078310012817
train-epoch-step: 52-212 -- Loss: 0.19196933507919312
train-epoch-step: 52-213 -- Loss: 0.12569093704223633
train-epoch-step: 52-214 -- Loss: 0.1465054601430893
train-epoch-step: 52-215 -- Loss: 0.12477242946624756
train-epoch-step: 52-216 -- Loss: 0.2032502442598343
train-epoch-step: 52-217 -- Loss: 0.20889812707901
train-epoch-step: 52-218 -- Loss: 0.14314211905002594
train-epoch-step: 52-219 -- Loss: 0.16474714875221252
train-epoch-step: 52-220 -- Loss: 0.1252981424331665
train-epoch-step: 52-221 -- Loss: 0.19812101125717163
train-epoch-step: 52-222 -- Loss: 0.11446377635002136
train-epoch-step: 52-223 -- Loss: 0.168180450797081
train-epoch-step: 52-224 -- Loss: 0.1834629476070404
train-epoch-step: 52-225 -- Loss: 0.26471108198165894
train-epoch-step: 52-226 -- Loss: 0.20554716885089874
train-epoch-step: 52-227 -- Loss: 0.2126411497592926
train-epoch-step: 52-228 -- Loss: 0.1734856367111206
train-epoch-step: 52-229 -- Loss: 0.17112377285957336
train-epoch-step: 52-230 -- Loss: 0.1595146358013153
train-epoch-step: 52-231 -- Loss: 0.16319526731967926
train-epoch-step: 52-232 -- Loss: 0.18155017495155334
train-epoch-step: 52-233 -- Loss: 0.08106913417577744
train-epoch-step: 52-234 -- Loss: 0.17123843729496002
train-epoch-step: 52-235 -- Loss: 0.14996182918548584
train-epoch-step: 52-236 -- Loss: 0.17738819122314453
train-epoch-step: 52-237 -- Loss: 0.23232507705688477
train-epoch-step: 52-238 -- Loss: 0.15447847545146942
train-epoch-step: 52-239 -- Loss: 0.1323913335800171
train-epoch-step: 52-240 -- Loss: 0.21936899423599243
train-epoch-step: 52-241 -- Loss: 0.20365197956562042
train-epoch-step: 52-242 -- Loss: 0.21897001564502716
train-epoch-step: 52-243 -- Loss: 0.23277245461940765
train-epoch-step: 52-244 -- Loss: 0.20107074081897736
train-epoch-step: 52-245 -- Loss: 0.2067774534225464
train-epoch-step: 52-246 -- Loss: 0.22853006422519684
train-epoch-step: 52-247 -- Loss: 0.20269925892353058
train-epoch-step: 52-248 -- Loss: 0.18489517271518707
train-epoch-step: 52-249 -- Loss: 0.13175295293331146
train-epoch-step: 52-250 -- Loss: 0.19455325603485107
train-epoch-step: 52-251 -- Loss: 0.10521574318408966
train-epoch-step: 52-252 -- Loss: 0.21050631999969482
train-epoch-step: 52-253 -- Loss: 0.13521309196949005
train-epoch-step: 52-254 -- Loss: 0.21098074316978455
train-epoch-step: 52-255 -- Loss: 0.14341336488723755
train-epoch-step: 52-256 -- Loss: 0.14737319946289062
train-epoch-step: 52-257 -- Loss: 0.1910400390625
train-epoch-step: 52-258 -- Loss: 0.14307346940040588
train-epoch-step: 52-259 -- Loss: 0.14651671051979065
train-epoch-step: 52-260 -- Loss: 0.19823643565177917
train-epoch-step: 52-261 -- Loss: 0.1681162714958191
train-epoch-step: 52-262 -- Loss: 0.27881932258605957
train-epoch-step: 52-263 -- Loss: 0.1978015899658203
train-epoch-step: 52-264 -- Loss: 0.17250043153762817
train-epoch-step: 52-265 -- Loss: 0.12105512619018555
train-epoch-step: 52-266 -- Loss: 0.1512790322303772
train-epoch-step: 52-267 -- Loss: 0.12776018679141998
train-epoch-step: 52-268 -- Loss: 0.11774230748414993
train-epoch-step: 52-269 -- Loss: 0.16916093230247498
train-epoch-step: 52-270 -- Loss: 0.10539407283067703
train-epoch-step: 52-271 -- Loss: 0.14754916727542877
train-epoch-step: 52-272 -- Loss: 0.11589519679546356
train-epoch-step: 52-273 -- Loss: 0.12510238587856293
train-epoch-step: 52-274 -- Loss: 0.18660439550876617
train-epoch-step: 52-275 -- Loss: 0.19043280184268951
train-epoch-step: 52-276 -- Loss: 0.15446455776691437
train-epoch-step: 52-277 -- Loss: 0.15215203166007996
train-epoch-step: 52-278 -- Loss: 0.13533760607242584
train-epoch-step: 52-279 -- Loss: 0.140855610370636
train-epoch-step: 52-280 -- Loss: 0.2125418335199356
train-epoch-step: 52-281 -- Loss: 0.17351913452148438
train-epoch-step: 52-282 -- Loss: 0.13796080648899078
train-epoch-step: 52-283 -- Loss: 0.11534041911363602
train-epoch-step: 52-284 -- Loss: 0.12450879067182541
train-epoch-step: 52-285 -- Loss: 0.18693989515304565
train-epoch-step: 52-286 -- Loss: 0.14984339475631714
train-epoch-step: 52-287 -- Loss: 0.19964149594306946
train-epoch-step: 52-288 -- Loss: 0.09298472851514816
train-epoch-step: 52-289 -- Loss: 0.11576501280069351
train-epoch-step: 52-290 -- Loss: 0.17903149127960205
train-epoch-step: 52-291 -- Loss: 0.11385464668273926
train-epoch-step: 52-292 -- Loss: 0.1577170491218567
train-epoch-step: 52-293 -- Loss: 0.13666632771492004
train-epoch-step: 52-294 -- Loss: 0.16356617212295532
train-epoch-step: 52-295 -- Loss: 0.28680866956710815
train-epoch-step: 52-296 -- Loss: 0.15818621218204498
train-epoch-step: 52-297 -- Loss: 0.17124909162521362
train-epoch-step: 52-298 -- Loss: 0.22233867645263672
train-epoch-step: 52-299 -- Loss: 0.1493312418460846
train-epoch-step: 52-300 -- Loss: 0.16173042356967926
train-epoch-step: 52-301 -- Loss: 0.16623573005199432
train-epoch-step: 52-302 -- Loss: 0.2179587483406067
train-epoch-step: 52-303 -- Loss: 0.20357583463191986
train-epoch-step: 52-304 -- Loss: 0.13212841749191284
train-epoch-step: 52-305 -- Loss: 0.1456432342529297
train-epoch-step: 52-306 -- Loss: 0.2137756049633026
train-epoch-step: 52-307 -- Loss: 0.16528332233428955
train-epoch-step: 52-308 -- Loss: 0.21750906109809875
train-epoch-step: 52-309 -- Loss: 0.14874422550201416
train-epoch-step: 52-310 -- Loss: 0.16663183271884918
train-epoch-step: 52-311 -- Loss: 0.1530749350786209
train-epoch-step: 52-312 -- Loss: 0.20705416798591614
train-epoch-step: 52-313 -- Loss: 0.10314753651618958
train-epoch-step: 52-314 -- Loss: 0.1920870840549469
train-epoch-step: 52-315 -- Loss: 0.16477909684181213
train-epoch-step: 52-316 -- Loss: 0.1503075361251831
train-epoch-step: 52-317 -- Loss: 0.13643768429756165
train-epoch-step: 52-318 -- Loss: 0.1578395962715149
train-epoch-step: 52-319 -- Loss: 0.15825529396533966
train-epoch-step: 52-320 -- Loss: 0.11916770040988922
train-epoch-step: 52-321 -- Loss: 0.13066837191581726
train-epoch-step: 52-322 -- Loss: 0.20899641513824463
train-epoch-step: 52-323 -- Loss: 0.1577731966972351
train-epoch-step: 52-324 -- Loss: 0.2522905170917511
train-epoch-step: 52-325 -- Loss: 0.1516037881374359
train-epoch-step: 52-326 -- Loss: 0.16585639119148254
train-epoch-step: 52-327 -- Loss: 0.20139212906360626
train-epoch-step: 52-328 -- Loss: 0.19257616996765137
train-epoch-step: 52-329 -- Loss: 0.34489184617996216
train-epoch-step: 52-330 -- Loss: 0.354092538356781
train-epoch-step: 52-331 -- Loss: 0.20891691744327545
train-epoch-step: 52-332 -- Loss: 0.09795170277357101
train-epoch-step: 52-333 -- Loss: 0.1816268265247345
train-epoch-step: 52-334 -- Loss: 0.15039700269699097
train-epoch-step: 52-335 -- Loss: 0.16773968935012817
train-epoch-step: 52-336 -- Loss: 0.14591684937477112
train-epoch-step: 52-337 -- Loss: 0.194825679063797
train-epoch-step: 52-338 -- Loss: 0.15403515100479126
train-epoch-step: 52-339 -- Loss: 0.14212779700756073
train-epoch-step: 52-340 -- Loss: 0.19529882073402405
train-epoch-step: 52-341 -- Loss: 0.1386103630065918
train-epoch-step: 52-342 -- Loss: 0.16450351476669312
train-epoch-step: 52-343 -- Loss: 0.1497439444065094
train-epoch-step: 52-344 -- Loss: 0.16731196641921997
train-epoch-step: 52-345 -- Loss: 0.12371383607387543
train-epoch-step: 52-346 -- Loss: 0.20809602737426758
train-epoch-step: 52-347 -- Loss: 0.15548159182071686
train-epoch-step: 52-348 -- Loss: 0.19805847108364105
train-epoch-step: 52-349 -- Loss: 0.19809523224830627
train-epoch-step: 52-350 -- Loss: 0.25286775827407837
train-epoch-step: 52-351 -- Loss: 0.19078078866004944
train-epoch-step: 52-352 -- Loss: 0.11921437084674835
train-epoch-step: 52-353 -- Loss: 0.1897350698709488
train-epoch-step: 52-354 -- Loss: 0.27683764696121216
train-epoch-step: 52-355 -- Loss: 0.11566503345966339
train-epoch-step: 52-356 -- Loss: 0.11510194838047028
train-epoch-step: 52-357 -- Loss: 0.1821470558643341
train-epoch-step: 52-358 -- Loss: 0.18178324401378632
train-epoch-step: 52-359 -- Loss: 0.13879410922527313
train-epoch-step: 52-360 -- Loss: 0.11731137335300446
train-epoch-step: 52-361 -- Loss: 0.2317695915699005
train-epoch-step: 52-362 -- Loss: 0.1689046174287796
train-epoch-step: 52-363 -- Loss: 0.10767893493175507
train-epoch-step: 52-364 -- Loss: 0.18017855286598206
train-epoch-step: 52-365 -- Loss: 0.1648533046245575
train-epoch-step: 52-366 -- Loss: 0.19593991339206696
train-epoch-step: 52-367 -- Loss: 0.22529827058315277
train-epoch-step: 52-368 -- Loss: 0.19235862791538239
train-epoch-step: 52-369 -- Loss: 0.2731277346611023
train-epoch-step: 52-370 -- Loss: 0.12090465426445007
train-epoch-step: 52-371 -- Loss: 0.1155037060379982
train-epoch-step: 52-372 -- Loss: 0.14534950256347656
train-epoch-step: 52-373 -- Loss: 0.1783531904220581
train-epoch-step: 52-374 -- Loss: 0.1485852599143982
train-epoch-step: 52-375 -- Loss: 0.26397252082824707
train-epoch-step: 52-376 -- Loss: 0.1523255705833435
train-epoch-step: 52-377 -- Loss: 0.23191766440868378
train-epoch-step: 52-378 -- Loss: 0.20205894112586975
train-epoch-step: 52-379 -- Loss: 0.11473296582698822
train-epoch-step: 52-380 -- Loss: 0.08782032877206802
train-epoch-step: 52-381 -- Loss: 0.23885412514209747
train-epoch-step: 52-382 -- Loss: 0.23203474283218384
train-epoch-step: 52-383 -- Loss: 0.1710461974143982
train-epoch-step: 52-384 -- Loss: 0.21559639275074005
train-epoch-step: 52-385 -- Loss: 0.18576568365097046
train-epoch-step: 52-386 -- Loss: 0.18486058712005615
train-epoch-step: 52-387 -- Loss: 0.2046782672405243
train-epoch-step: 52-388 -- Loss: 0.18118013441562653
train-epoch-step: 52-389 -- Loss: 0.16261453926563263
train-epoch-step: 52-390 -- Loss: 0.14043660461902618
train-epoch-step: 52-391 -- Loss: 0.14258719980716705
train-epoch-step: 52-392 -- Loss: 0.18179136514663696
train-epoch-step: 52-393 -- Loss: 0.15738531947135925
train-epoch-step: 52-394 -- Loss: 0.19627630710601807
train-epoch-step: 52-395 -- Loss: 0.15287797152996063
train-epoch-step: 52-396 -- Loss: 0.12430614978075027
train-epoch-step: 52-397 -- Loss: 0.12440121173858643
train-epoch-step: 52-398 -- Loss: 0.19189460575580597
train-epoch-step: 52-399 -- Loss: 0.1704050600528717
train-epoch-step: 52-400 -- Loss: 0.26906248927116394
train-epoch-step: 52-401 -- Loss: 0.11649728566408157
train-epoch-step: 52-402 -- Loss: 0.25765204429626465
train-epoch-step: 52-403 -- Loss: 0.15388906002044678
train-epoch-step: 52-404 -- Loss: 0.1395021378993988
train-epoch-step: 52-405 -- Loss: 0.1373097002506256
train-epoch-step: 52-406 -- Loss: 0.16204145550727844
train-epoch-step: 52-407 -- Loss: 0.11034587025642395
train-epoch-step: 52-408 -- Loss: 0.15563620626926422
train-epoch-step: 52-409 -- Loss: 0.16330143809318542
train-epoch-step: 52-410 -- Loss: 0.17297765612602234
train-epoch-step: 52-411 -- Loss: 0.19491982460021973
train-epoch-step: 52-412 -- Loss: 0.12975439429283142
train-epoch-step: 52-413 -- Loss: 0.14206035435199738
train-epoch-step: 52-414 -- Loss: 0.12888726592063904
train-epoch-step: 52-415 -- Loss: 0.13046865165233612
train-epoch-step: 52-416 -- Loss: 0.25977495312690735
train-epoch-step: 52-417 -- Loss: 0.1864745020866394
train-epoch-step: 52-418 -- Loss: 0.21867062151432037
train-epoch-step: 52-419 -- Loss: 0.1616101711988449
train-epoch-step: 52-420 -- Loss: 0.14960257709026337
train-epoch-step: 52-421 -- Loss: 0.17441105842590332
train-epoch-step: 52-422 -- Loss: 0.14877891540527344
train-epoch-step: 52-423 -- Loss: 0.16783496737480164
train-epoch-step: 52-424 -- Loss: 0.13939733803272247
train-epoch-step: 52-425 -- Loss: 0.17799650132656097
train-epoch-step: 52-426 -- Loss: 0.1592404842376709
train-epoch-step: 52-427 -- Loss: 0.11927592754364014
train-epoch-step: 52-428 -- Loss: 0.20024676620960236
train-epoch-step: 52-429 -- Loss: 0.17205986380577087
train-epoch-step: 52-430 -- Loss: 0.1351003795862198
train-epoch-step: 52-431 -- Loss: 0.1572420746088028
train-epoch-step: 52-432 -- Loss: 0.2302229106426239
train-epoch-step: 52-433 -- Loss: 0.13162027299404144
train-epoch-step: 52-434 -- Loss: 0.12760157883167267
train-epoch-step: 52-435 -- Loss: 0.15281839668750763
train-epoch-step: 52-436 -- Loss: 0.14941121637821198
train-epoch-step: 52-437 -- Loss: 0.13013675808906555
train-epoch-step: 52-438 -- Loss: 0.16236716508865356
train-epoch-step: 52-439 -- Loss: 0.2639842927455902
train-epoch-step: 52-440 -- Loss: 0.12861940264701843
train-epoch-step: 52-441 -- Loss: 0.1937142163515091
train-epoch-step: 52-442 -- Loss: 0.17293882369995117
train-epoch-step: 52-443 -- Loss: 0.14958375692367554
train-epoch-step: 52-444 -- Loss: 0.17692707479000092
train-epoch-step: 52-445 -- Loss: 0.1745932549238205
train-epoch-step: 52-446 -- Loss: 0.15027743577957153
train-epoch-step: 52-447 -- Loss: 0.18598711490631104
train-epoch-step: 52-448 -- Loss: 0.21670283377170563
train-epoch-step: 52-449 -- Loss: 0.1842551976442337
train-epoch-step: 52-450 -- Loss: 0.17482756078243256
train-epoch-step: 52-451 -- Loss: 0.13817158341407776
train-epoch-step: 52-452 -- Loss: 0.1262587606906891
train-epoch-step: 52-453 -- Loss: 0.09239020943641663
train-epoch-step: 52-454 -- Loss: 0.21911439299583435
train-epoch-step: 52-455 -- Loss: 0.12031891942024231
train-epoch-step: 52-456 -- Loss: 0.11841115355491638
train-epoch-step: 52-457 -- Loss: 0.20926246047019958
train-epoch-step: 52-458 -- Loss: 0.14420264959335327
train-epoch-step: 52-459 -- Loss: 0.2079838514328003
train-epoch-step: 52-460 -- Loss: 0.12330061942338943
train-epoch-step: 52-461 -- Loss: 0.1318792998790741
train-epoch-step: 52-462 -- Loss: 0.15406864881515503
train-epoch-step: 52-463 -- Loss: 0.14082500338554382
train-epoch-step: 52-464 -- Loss: 0.16036346554756165
train-epoch-step: 52-465 -- Loss: 0.23702967166900635
train-epoch-step: 52-466 -- Loss: 0.19260187447071075
train-epoch-step: 52-467 -- Loss: 0.10970433056354523
train-epoch-step: 52-468 -- Loss: 0.16263674199581146
train-epoch-step: 52-469 -- Loss: 0.2092505693435669
train-epoch-step: 52-470 -- Loss: 0.16376206278800964
train-epoch-step: 52-471 -- Loss: 0.15425272285938263
train-epoch-step: 52-472 -- Loss: 0.15720921754837036
train-epoch-step: 52-473 -- Loss: 0.14723704755306244
train-epoch-step: 52-474 -- Loss: 0.11413058638572693
train-epoch-step: 52-475 -- Loss: 0.10885832458734512
train-epoch-step: 52-476 -- Loss: 0.19396473467350006
train-epoch-step: 52-477 -- Loss: 0.1948879063129425
train-epoch-step: 52-478 -- Loss: 0.18438751995563507
train-epoch-step: 52-479 -- Loss: 0.1402355581521988
train-epoch-step: 52-480 -- Loss: 0.1912742704153061
train-epoch-step: 52-481 -- Loss: 0.27651309967041016
train-epoch-step: 52-482 -- Loss: 0.24036887288093567
train-epoch-step: 52-483 -- Loss: 0.1764954924583435
train-epoch-step: 52-484 -- Loss: 0.2107207030057907
train-epoch-step: 52-485 -- Loss: 0.12033872306346893
train-epoch-step: 52-486 -- Loss: 0.2201639711856842
train-epoch-step: 52-487 -- Loss: 0.22480112314224243
train-epoch-step: 52-488 -- Loss: 0.17765012383460999
train-epoch-step: 52-489 -- Loss: 0.21158190071582794
train-epoch-step: 52-490 -- Loss: 0.1377216875553131
train-epoch-step: 52-491 -- Loss: 0.13344267010688782
train-epoch-step: 52-492 -- Loss: 0.11936752498149872
train-epoch-step: 52-493 -- Loss: 0.19317762553691864
train-epoch-step: 52-494 -- Loss: 0.19906263053417206
train-epoch-step: 52-495 -- Loss: 0.19656282663345337
train-epoch-step: 52-496 -- Loss: 0.13843917846679688
train-epoch-step: 52-497 -- Loss: 0.1803416609764099
train-epoch-step: 52-498 -- Loss: 0.14368055760860443
train-epoch-step: 52-499 -- Loss: 0.16356919705867767
train-epoch-step: 52-500 -- Loss: 0.15140724182128906
train-epoch-step: 52-501 -- Loss: 0.2060016244649887
train-epoch-step: 52-502 -- Loss: 0.15669497847557068
train-epoch-step: 52-503 -- Loss: 0.2085728943347931
train-epoch-step: 52-504 -- Loss: 0.11309964954853058
train-epoch-step: 52-505 -- Loss: 0.16489435732364655
train-epoch-step: 52-506 -- Loss: 0.11345891654491425
train-epoch-step: 52-507 -- Loss: 0.17343130707740784
train-epoch-step: 52-508 -- Loss: 0.16657881438732147
train-epoch-step: 52-509 -- Loss: 0.16586032509803772
train-epoch-step: 52-510 -- Loss: 0.12380605190992355
train-epoch-step: 52-511 -- Loss: 0.20539171993732452
train-epoch-step: 52-512 -- Loss: 0.17350947856903076
train-epoch-step: 52-513 -- Loss: 0.18368202447891235
train-epoch-step: 52-514 -- Loss: 0.14198416471481323
train-epoch-step: 52-515 -- Loss: 0.1506601870059967
train-epoch-step: 52-516 -- Loss: 0.16592943668365479
train-epoch-step: 52-517 -- Loss: 0.17179308831691742
train-epoch-step: 52-518 -- Loss: 0.1325322985649109
train-epoch-step: 52-519 -- Loss: 0.1318190097808838
train-epoch-step: 52-520 -- Loss: 0.17883352935314178
train-epoch-step: 52-521 -- Loss: 0.2194627970457077
train-epoch-step: 52-522 -- Loss: 0.16626575589179993
train-epoch-step: 52-523 -- Loss: 0.1563207358121872
train-epoch-step: 52-524 -- Loss: 0.1614125370979309
train-epoch-step: 52-525 -- Loss: 0.19033342599868774
train-epoch-step: 52-526 -- Loss: 0.12486112117767334
train-epoch-step: 52-527 -- Loss: 0.15681718289852142
train-epoch-step: 52-528 -- Loss: 0.15406706929206848
train-epoch-step: 52-529 -- Loss: 0.14936435222625732
train-epoch-step: 52-530 -- Loss: 0.16380611062049866
train-epoch-step: 52-531 -- Loss: 0.18820758163928986
train-epoch-step: 52-532 -- Loss: 0.16652405261993408
train-epoch-step: 52-533 -- Loss: 0.1678965836763382
train-epoch-step: 52-534 -- Loss: 0.12633031606674194
train-epoch-step: 52-535 -- Loss: 0.2453455626964569
train-epoch-step: 52-536 -- Loss: 0.16019974648952484
train-epoch-step: 52-537 -- Loss: 0.14314576983451843
train-epoch-step: 52-538 -- Loss: 0.10082598030567169
train-epoch-step: 52-539 -- Loss: 0.17556408047676086
train-epoch-step: 52-540 -- Loss: 0.129947692155838
train-epoch-step: 52-541 -- Loss: 0.20106831192970276
train-epoch-step: 52-542 -- Loss: 0.21616040170192719
train-epoch-step: 52-543 -- Loss: 0.15887990593910217
train-epoch-step: 52-544 -- Loss: 0.22023214399814606
train-epoch-step: 52-545 -- Loss: 0.18744038045406342
train-epoch-step: 52-546 -- Loss: 0.19947177171707153
train-epoch-step: 52-547 -- Loss: 0.17235565185546875
train-epoch-step: 52-548 -- Loss: 0.09016701579093933
train-epoch-step: 52-549 -- Loss: 0.14550566673278809
train-epoch-step: 52-550 -- Loss: 0.19625860452651978
train-epoch-step: 52-551 -- Loss: 0.14855167269706726
train-epoch-step: 52-552 -- Loss: 0.12442847341299057
train-epoch-step: 52-553 -- Loss: 0.18450391292572021
train-epoch-step: 52-554 -- Loss: 0.18060711026191711
train-epoch-step: 52-555 -- Loss: 0.20731575787067413
train-epoch-step: 52-556 -- Loss: 0.1418229192495346
train-epoch-step: 52-557 -- Loss: 0.22457751631736755
train-epoch-step: 52-558 -- Loss: 0.22437837719917297
train-epoch-step: 52-559 -- Loss: 0.13967972993850708
train-epoch-step: 52-560 -- Loss: 0.1986975222826004
train-epoch-step: 52-561 -- Loss: 0.18100237846374512
train-epoch-step: 52-562 -- Loss: 0.1594996601343155
train-epoch-step: 52-563 -- Loss: 0.18006068468093872
train-epoch-step: 52-564 -- Loss: 0.0984022244811058
train-epoch-step: 52-565 -- Loss: 0.1786518096923828
train-epoch-step: 52-566 -- Loss: 0.15214933454990387
train-epoch-step: 52-567 -- Loss: 0.20772072672843933
train-epoch-step: 52-568 -- Loss: 0.15871508419513702
train-epoch-step: 52-569 -- Loss: 0.23376724123954773
train-epoch-step: 52-570 -- Loss: 0.18324249982833862
train-epoch-step: 52-571 -- Loss: 0.20655441284179688
train-epoch-step: 52-572 -- Loss: 0.22949780523777008
train-epoch-step: 52-573 -- Loss: 0.19628676772117615
train-epoch-step: 52-574 -- Loss: 0.23190514743328094
train-epoch-step: 52-575 -- Loss: 0.2813936471939087
train-epoch-step: 52-576 -- Loss: 0.11798662692308426
train-epoch-step: 52-577 -- Loss: 0.16727064549922943
train-epoch-step: 52-578 -- Loss: 0.20592869818210602
train-epoch-step: 52-579 -- Loss: 0.16399651765823364
train-epoch-step: 52-580 -- Loss: 0.16929751634597778
train-epoch-step: 52-581 -- Loss: 0.1397068202495575
train-epoch-step: 52-582 -- Loss: 0.20039209723472595
train-epoch-step: 52-583 -- Loss: 0.20512518286705017
train-epoch-step: 52-584 -- Loss: 0.1564524620771408
train-epoch-step: 52-585 -- Loss: 0.1884946972131729
train-epoch-step: 52-586 -- Loss: 0.24938303232192993
train-epoch-step: 52-587 -- Loss: 0.15815100073814392
train-epoch-step: 52-588 -- Loss: 0.12800081074237823
val-epoch-step: 52-589 -- Loss: 0.20375970005989075
val-epoch-step: 52-590 -- Loss: 0.14980222284793854
val-epoch-step: 52-591 -- Loss: 0.24496448040008545
val-epoch-step: 52-592 -- Loss: 0.17392456531524658
val-epoch-step: 52-593 -- Loss: 0.16583822667598724
val-epoch-step: 52-594 -- Loss: 0.4122980535030365
val-epoch-step: 52-595 -- Loss: 0.18832777440547943
val-epoch-step: 52-596 -- Loss: 0.18687348067760468
val-epoch-step: 52-597 -- Loss: 0.1758342832326889
val-epoch-step: 52-598 -- Loss: 0.14362883567810059
val-epoch-step: 52-599 -- Loss: 0.18003487586975098
val-epoch-step: 52-600 -- Loss: 0.18003487586975098
val-epoch-step: 52-601 -- Loss: 0.15035489201545715
val-epoch-step: 52-602 -- Loss: 0.13486437499523163
val-epoch-step: 52-603 -- Loss: 0.2107723206281662
val-epoch-step: 52-604 -- Loss: 0.15716716647148132
val-epoch-step: 52-605 -- Loss: 0.14496923983097076
val-epoch-step: 52-606 -- Loss: 0.2513987421989441
val-epoch-step: 52-607 -- Loss: 0.12999731302261353
val-epoch-step: 52-608 -- Loss: 0.2520253658294678
val-epoch-step: 52-609 -- Loss: 0.16667678952217102
val-epoch-step: 52-610 -- Loss: 0.17519491910934448
val-epoch-step: 52-611 -- Loss: 0.15427058935165405
val-epoch-step: 52-612 -- Loss: 0.46036383509635925
val-epoch-step: 52-613 -- Loss: 0.1655254065990448
val-epoch-step: 52-614 -- Loss: 0.1767006516456604
val-epoch-step: 52-615 -- Loss: 0.1688033640384674
val-epoch-step: 52-616 -- Loss: 0.14509250223636627
val-epoch-step: 52-617 -- Loss: 0.18977122008800507
val-epoch-step: 52-618 -- Loss: 0.17827843129634857
val-epoch-step: 52-619 -- Loss: 0.2067425400018692
val-epoch-step: 52-620 -- Loss: 0.14305280148983002
val-epoch-step: 52-621 -- Loss: 0.1253567337989807
val-epoch-step: 52-622 -- Loss: 0.14010843634605408
val-epoch-step: 52-623 -- Loss: 0.1465705931186676
val-epoch-step: 52-624 -- Loss: 0.13711516559123993
val-epoch-step: 52-625 -- Loss: 0.15552815794944763
val-epoch-step: 52-626 -- Loss: 0.14312277734279633
val-epoch-step: 52-627 -- Loss: 0.18643076717853546
val-epoch-step: 52-628 -- Loss: 0.6389709711074829
val-epoch-step: 52-629 -- Loss: 0.20095469057559967
val-epoch-step: 52-630 -- Loss: 0.33607110381126404
val-epoch-step: 52-631 -- Loss: 0.14016439020633698
val-epoch-step: 52-632 -- Loss: 0.19506984949111938
val-epoch-step: 52-633 -- Loss: 0.15798848867416382
val-epoch-step: 52-634 -- Loss: 0.1373969316482544
val-epoch-step: 52-635 -- Loss: 0.11077746748924255
val-epoch-step: 52-636 -- Loss: 0.16624952852725983
val-epoch-step: 52-637 -- Loss: 0.1841646134853363
val-epoch-step: 52-638 -- Loss: 0.14894315600395203
val-epoch-step: 52-639 -- Loss: 0.2505647540092468
val-epoch-step: 52-640 -- Loss: 0.24774664640426636
val-epoch-step: 52-641 -- Loss: 0.12755818665027618
val-epoch-step: 52-642 -- Loss: 0.18748342990875244
val-epoch-step: 52-643 -- Loss: 0.1985458880662918
val-epoch-step: 52-644 -- Loss: 0.16180507838726044
val-epoch-step: 52-645 -- Loss: 0.21043606102466583
val-epoch-step: 52-646 -- Loss: 0.135813370347023
val-epoch-step: 52-647 -- Loss: 0.13089169561862946
val-epoch-step: 52-648 -- Loss: 0.1531335860490799
val-epoch-step: 52-649 -- Loss: 0.20405790209770203
val-epoch-step: 52-650 -- Loss: 0.24533481895923615
val-epoch-step: 52-651 -- Loss: 0.14203043282032013
val-epoch-step: 52-652 -- Loss: 0.15100422501564026
val-epoch-step: 52-653 -- Loss: 0.21211619675159454
val-epoch-step: 52-654 -- Loss: 0.10934635996818542
Epoch: 52 -- Train Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 53-0 -- Loss: 0.21689195930957794
train-epoch-step: 53-1 -- Loss: 0.13956105709075928
train-epoch-step: 53-2 -- Loss: 0.19536644220352173
train-epoch-step: 53-3 -- Loss: 0.14382603764533997
train-epoch-step: 53-4 -- Loss: 0.15563364326953888
train-epoch-step: 53-5 -- Loss: 0.17516788840293884
train-epoch-step: 53-6 -- Loss: 0.21261921525001526
train-epoch-step: 53-7 -- Loss: 0.1664046049118042
train-epoch-step: 53-8 -- Loss: 0.17584288120269775
train-epoch-step: 53-9 -- Loss: 0.22023269534111023
train-epoch-step: 53-10 -- Loss: 0.18951645493507385
train-epoch-step: 53-11 -- Loss: 0.17281915247440338
train-epoch-step: 53-12 -- Loss: 0.14439421892166138
train-epoch-step: 53-13 -- Loss: 0.18427467346191406
train-epoch-step: 53-14 -- Loss: 0.15557198226451874
train-epoch-step: 53-15 -- Loss: 0.15709246695041656
train-epoch-step: 53-16 -- Loss: 0.15611892938613892
train-epoch-step: 53-17 -- Loss: 0.21568243205547333
train-epoch-step: 53-18 -- Loss: 0.18701525032520294
train-epoch-step: 53-19 -- Loss: 0.12836769223213196
train-epoch-step: 53-20 -- Loss: 0.2068922072649002
train-epoch-step: 53-21 -- Loss: 0.24882498383522034
train-epoch-step: 53-22 -- Loss: 0.13496264815330505
train-epoch-step: 53-23 -- Loss: 0.14067208766937256
train-epoch-step: 53-24 -- Loss: 0.11947780102491379
train-epoch-step: 53-25 -- Loss: 0.2195853888988495
train-epoch-step: 53-26 -- Loss: 0.18491946160793304
train-epoch-step: 53-27 -- Loss: 0.22919943928718567
train-epoch-step: 53-28 -- Loss: 0.12319371104240417
train-epoch-step: 53-29 -- Loss: 0.2354128360748291
train-epoch-step: 53-30 -- Loss: 0.10616981983184814
train-epoch-step: 53-31 -- Loss: 0.12916859984397888
train-epoch-step: 53-32 -- Loss: 0.17059136927127838
train-epoch-step: 53-33 -- Loss: 0.2645183801651001
train-epoch-step: 53-34 -- Loss: 0.16217835247516632
train-epoch-step: 53-35 -- Loss: 0.23089802265167236
train-epoch-step: 53-36 -- Loss: 0.13560710847377777
train-epoch-step: 53-37 -- Loss: 0.13224537670612335
train-epoch-step: 53-38 -- Loss: 0.16874827444553375
train-epoch-step: 53-39 -- Loss: 0.21318328380584717
train-epoch-step: 53-40 -- Loss: 0.18707643449306488
train-epoch-step: 53-41 -- Loss: 0.2092054784297943
train-epoch-step: 53-42 -- Loss: 0.1437189131975174
train-epoch-step: 53-43 -- Loss: 0.2526748776435852
train-epoch-step: 53-44 -- Loss: 0.12018910050392151
train-epoch-step: 53-45 -- Loss: 0.10986888408660889
train-epoch-step: 53-46 -- Loss: 0.161409392952919
train-epoch-step: 53-47 -- Loss: 0.194904163479805
train-epoch-step: 53-48 -- Loss: 0.1501850038766861
train-epoch-step: 53-49 -- Loss: 0.21902835369110107
train-epoch-step: 53-50 -- Loss: 0.10836918652057648
train-epoch-step: 53-51 -- Loss: 0.1709534376859665
train-epoch-step: 53-52 -- Loss: 0.15629521012306213
train-epoch-step: 53-53 -- Loss: 0.20254135131835938
train-epoch-step: 53-54 -- Loss: 0.2760077714920044
train-epoch-step: 53-55 -- Loss: 0.16193455457687378
train-epoch-step: 53-56 -- Loss: 0.1721654087305069
train-epoch-step: 53-57 -- Loss: 0.22625195980072021
train-epoch-step: 53-58 -- Loss: 0.27770373225212097
train-epoch-step: 53-59 -- Loss: 0.22424381971359253
train-epoch-step: 53-60 -- Loss: 0.12425298988819122
train-epoch-step: 53-61 -- Loss: 0.19484858214855194
train-epoch-step: 53-62 -- Loss: 0.1798471361398697
train-epoch-step: 53-63 -- Loss: 0.13117705285549164
train-epoch-step: 53-64 -- Loss: 0.14132937788963318
train-epoch-step: 53-65 -- Loss: 0.17218326032161713
train-epoch-step: 53-66 -- Loss: 0.1072576493024826
train-epoch-step: 53-67 -- Loss: 0.12057575583457947
train-epoch-step: 53-68 -- Loss: 0.20325884222984314
train-epoch-step: 53-69 -- Loss: 0.11753683537244797
train-epoch-step: 53-70 -- Loss: 0.21803121268749237
train-epoch-step: 53-71 -- Loss: 0.25469350814819336
train-epoch-step: 53-72 -- Loss: 0.1692034751176834
train-epoch-step: 53-73 -- Loss: 0.20174647867679596
train-epoch-step: 53-74 -- Loss: 0.093809112906456
train-epoch-step: 53-75 -- Loss: 0.1269775927066803
train-epoch-step: 53-76 -- Loss: 0.14152874052524567
train-epoch-step: 53-77 -- Loss: 0.22131256759166718
train-epoch-step: 53-78 -- Loss: 0.2443857043981552
train-epoch-step: 53-79 -- Loss: 0.18676361441612244
train-epoch-step: 53-80 -- Loss: 0.24731770157814026
train-epoch-step: 53-81 -- Loss: 0.12123822420835495
train-epoch-step: 53-82 -- Loss: 0.24789848923683167
train-epoch-step: 53-83 -- Loss: 0.17674364149570465
train-epoch-step: 53-84 -- Loss: 0.18564115464687347
train-epoch-step: 53-85 -- Loss: 0.17164695262908936
train-epoch-step: 53-86 -- Loss: 0.11767485737800598
train-epoch-step: 53-87 -- Loss: 0.20220722258090973
train-epoch-step: 53-88 -- Loss: 0.13308820128440857
train-epoch-step: 53-89 -- Loss: 0.1821708381175995
train-epoch-step: 53-90 -- Loss: 0.18613776564598083
train-epoch-step: 53-91 -- Loss: 0.23665300011634827
train-epoch-step: 53-92 -- Loss: 0.14987888932228088
train-epoch-step: 53-93 -- Loss: 0.17051659524440765
train-epoch-step: 53-94 -- Loss: 0.21145771443843842
train-epoch-step: 53-95 -- Loss: 0.1853923350572586
train-epoch-step: 53-96 -- Loss: 0.20725922286510468
train-epoch-step: 53-97 -- Loss: 0.17290480434894562
train-epoch-step: 53-98 -- Loss: 0.15133130550384521
train-epoch-step: 53-99 -- Loss: 0.175800621509552
train-epoch-step: 53-100 -- Loss: 0.18367017805576324
train-epoch-step: 53-101 -- Loss: 0.2728710174560547
train-epoch-step: 53-102 -- Loss: 0.2087431252002716
train-epoch-step: 53-103 -- Loss: 0.17899321019649506
train-epoch-step: 53-104 -- Loss: 0.14571192860603333
train-epoch-step: 53-105 -- Loss: 0.25316449999809265
train-epoch-step: 53-106 -- Loss: 0.1746605485677719
train-epoch-step: 53-107 -- Loss: 0.19056349992752075
train-epoch-step: 53-108 -- Loss: 0.18477816879749298
train-epoch-step: 53-109 -- Loss: 0.14387573301792145
train-epoch-step: 53-110 -- Loss: 0.17742913961410522
train-epoch-step: 53-111 -- Loss: 0.17000725865364075
train-epoch-step: 53-112 -- Loss: 0.1581519991159439
train-epoch-step: 53-113 -- Loss: 0.16277198493480682
train-epoch-step: 53-114 -- Loss: 0.1932373195886612
train-epoch-step: 53-115 -- Loss: 0.16106849908828735
train-epoch-step: 53-116 -- Loss: 0.13496583700180054
train-epoch-step: 53-117 -- Loss: 0.12384591996669769
train-epoch-step: 53-118 -- Loss: 0.18501417338848114
train-epoch-step: 53-119 -- Loss: 0.14529840648174286
train-epoch-step: 53-120 -- Loss: 0.24118568003177643
train-epoch-step: 53-121 -- Loss: 0.23164048790931702
train-epoch-step: 53-122 -- Loss: 0.20907558500766754
train-epoch-step: 53-123 -- Loss: 0.19917744398117065
train-epoch-step: 53-124 -- Loss: 0.11705510318279266
train-epoch-step: 53-125 -- Loss: 0.15197141468524933
train-epoch-step: 53-126 -- Loss: 0.2271776646375656
train-epoch-step: 53-127 -- Loss: 0.17385199666023254
train-epoch-step: 53-128 -- Loss: 0.17126460373401642
train-epoch-step: 53-129 -- Loss: 0.13654738664627075
train-epoch-step: 53-130 -- Loss: 0.19347025454044342
train-epoch-step: 53-131 -- Loss: 0.131728395819664
train-epoch-step: 53-132 -- Loss: 0.18704968690872192
train-epoch-step: 53-133 -- Loss: 0.11167731136083603
train-epoch-step: 53-134 -- Loss: 0.19082953035831451
train-epoch-step: 53-135 -- Loss: 0.13618701696395874
train-epoch-step: 53-136 -- Loss: 0.12192630767822266
train-epoch-step: 53-137 -- Loss: 0.23427967727184296
train-epoch-step: 53-138 -- Loss: 0.2511533796787262
train-epoch-step: 53-139 -- Loss: 0.12800279259681702
train-epoch-step: 53-140 -- Loss: 0.20100004971027374
train-epoch-step: 53-141 -- Loss: 0.2278437316417694
train-epoch-step: 53-142 -- Loss: 0.19843250513076782
train-epoch-step: 53-143 -- Loss: 0.1655556559562683
train-epoch-step: 53-144 -- Loss: 0.17875100672245026
train-epoch-step: 53-145 -- Loss: 0.13591429591178894
train-epoch-step: 53-146 -- Loss: 0.17362624406814575
train-epoch-step: 53-147 -- Loss: 0.1658533215522766
train-epoch-step: 53-148 -- Loss: 0.1669483184814453
train-epoch-step: 53-149 -- Loss: 0.11995448917150497
train-epoch-step: 53-150 -- Loss: 0.18268579244613647
train-epoch-step: 53-151 -- Loss: 0.1918271780014038
train-epoch-step: 53-152 -- Loss: 0.18723444640636444
train-epoch-step: 53-153 -- Loss: 0.26581087708473206
train-epoch-step: 53-154 -- Loss: 0.12754353880882263
train-epoch-step: 53-155 -- Loss: 0.1305720955133438
train-epoch-step: 53-156 -- Loss: 0.11376745998859406
train-epoch-step: 53-157 -- Loss: 0.17300541698932648
train-epoch-step: 53-158 -- Loss: 0.16387751698493958
train-epoch-step: 53-159 -- Loss: 0.17511820793151855
train-epoch-step: 53-160 -- Loss: 0.21048030257225037
train-epoch-step: 53-161 -- Loss: 0.20054611563682556
train-epoch-step: 53-162 -- Loss: 0.20543794333934784
train-epoch-step: 53-163 -- Loss: 0.18499837815761566
train-epoch-step: 53-164 -- Loss: 0.19234618544578552
train-epoch-step: 53-165 -- Loss: 0.15638379752635956
train-epoch-step: 53-166 -- Loss: 0.12029969692230225
train-epoch-step: 53-167 -- Loss: 0.11954386532306671
train-epoch-step: 53-168 -- Loss: 0.1920246034860611
train-epoch-step: 53-169 -- Loss: 0.1369534283876419
train-epoch-step: 53-170 -- Loss: 0.1939154863357544
train-epoch-step: 53-171 -- Loss: 0.1428452432155609
train-epoch-step: 53-172 -- Loss: 0.2535606622695923
train-epoch-step: 53-173 -- Loss: 0.14235292375087738
train-epoch-step: 53-174 -- Loss: 0.23826250433921814
train-epoch-step: 53-175 -- Loss: 0.18004274368286133
train-epoch-step: 53-176 -- Loss: 0.13225336372852325
train-epoch-step: 53-177 -- Loss: 0.1716768890619278
train-epoch-step: 53-178 -- Loss: 0.17824721336364746
train-epoch-step: 53-179 -- Loss: 0.14906232059001923
train-epoch-step: 53-180 -- Loss: 0.14785222709178925
train-epoch-step: 53-181 -- Loss: 0.16479818522930145
train-epoch-step: 53-182 -- Loss: 0.17691519856452942
train-epoch-step: 53-183 -- Loss: 0.27278822660446167
train-epoch-step: 53-184 -- Loss: 0.13585969805717468
train-epoch-step: 53-185 -- Loss: 0.13788288831710815
train-epoch-step: 53-186 -- Loss: 0.18728476762771606
train-epoch-step: 53-187 -- Loss: 0.20370936393737793
train-epoch-step: 53-188 -- Loss: 0.16965822875499725
train-epoch-step: 53-189 -- Loss: 0.1013028472661972
train-epoch-step: 53-190 -- Loss: 0.17686112225055695
train-epoch-step: 53-191 -- Loss: 0.14984968304634094
train-epoch-step: 53-192 -- Loss: 0.22808344662189484
train-epoch-step: 53-193 -- Loss: 0.19915273785591125
train-epoch-step: 53-194 -- Loss: 0.18021690845489502
train-epoch-step: 53-195 -- Loss: 0.16338078677654266
train-epoch-step: 53-196 -- Loss: 0.1684250831604004
train-epoch-step: 53-197 -- Loss: 0.12622325122356415
train-epoch-step: 53-198 -- Loss: 0.1245352029800415
train-epoch-step: 53-199 -- Loss: 0.1455417275428772
train-epoch-step: 53-200 -- Loss: 0.12395870685577393
train-epoch-step: 53-201 -- Loss: 0.18242400884628296
train-epoch-step: 53-202 -- Loss: 0.13368846476078033
train-epoch-step: 53-203 -- Loss: 0.17219600081443787
train-epoch-step: 53-204 -- Loss: 0.13312189280986786
train-epoch-step: 53-205 -- Loss: 0.177500918507576
train-epoch-step: 53-206 -- Loss: 0.19779610633850098
train-epoch-step: 53-207 -- Loss: 0.13324998319149017
train-epoch-step: 53-208 -- Loss: 0.17524485290050507
train-epoch-step: 53-209 -- Loss: 0.13893409073352814
train-epoch-step: 53-210 -- Loss: 0.1357969492673874
train-epoch-step: 53-211 -- Loss: 0.1977706402540207
train-epoch-step: 53-212 -- Loss: 0.1972082406282425
train-epoch-step: 53-213 -- Loss: 0.13042528927326202
train-epoch-step: 53-214 -- Loss: 0.14337792992591858
train-epoch-step: 53-215 -- Loss: 0.12410559505224228
train-epoch-step: 53-216 -- Loss: 0.19676350057125092
train-epoch-step: 53-217 -- Loss: 0.20629553496837616
train-epoch-step: 53-218 -- Loss: 0.14350877702236176
train-epoch-step: 53-219 -- Loss: 0.16648875176906586
train-epoch-step: 53-220 -- Loss: 0.12565898895263672
train-epoch-step: 53-221 -- Loss: 0.19943220913410187
train-epoch-step: 53-222 -- Loss: 0.11283763498067856
train-epoch-step: 53-223 -- Loss: 0.17380666732788086
train-epoch-step: 53-224 -- Loss: 0.18076887726783752
train-epoch-step: 53-225 -- Loss: 0.2644004821777344
train-epoch-step: 53-226 -- Loss: 0.2014697790145874
train-epoch-step: 53-227 -- Loss: 0.2138085961341858
train-epoch-step: 53-228 -- Loss: 0.1721910536289215
train-epoch-step: 53-229 -- Loss: 0.16975609958171844
train-epoch-step: 53-230 -- Loss: 0.16045519709587097
train-epoch-step: 53-231 -- Loss: 0.1523730307817459
train-epoch-step: 53-232 -- Loss: 0.17888085544109344
train-epoch-step: 53-233 -- Loss: 0.08098214119672775
train-epoch-step: 53-234 -- Loss: 0.17039212584495544
train-epoch-step: 53-235 -- Loss: 0.14555546641349792
train-epoch-step: 53-236 -- Loss: 0.17850211262702942
train-epoch-step: 53-237 -- Loss: 0.22858351469039917
train-epoch-step: 53-238 -- Loss: 0.15875069797039032
train-epoch-step: 53-239 -- Loss: 0.12234735488891602
train-epoch-step: 53-240 -- Loss: 0.2198658287525177
train-epoch-step: 53-241 -- Loss: 0.1518213450908661
train-epoch-step: 53-242 -- Loss: 0.21451154351234436
train-epoch-step: 53-243 -- Loss: 0.226896733045578
train-epoch-step: 53-244 -- Loss: 0.2026088535785675
train-epoch-step: 53-245 -- Loss: 0.20000781118869781
train-epoch-step: 53-246 -- Loss: 0.21190831065177917
train-epoch-step: 53-247 -- Loss: 0.2035893350839615
train-epoch-step: 53-248 -- Loss: 0.1801353394985199
train-epoch-step: 53-249 -- Loss: 0.1367451697587967
train-epoch-step: 53-250 -- Loss: 0.19379206001758575
train-epoch-step: 53-251 -- Loss: 0.10344251245260239
train-epoch-step: 53-252 -- Loss: 0.18738499283790588
train-epoch-step: 53-253 -- Loss: 0.1330670863389969
train-epoch-step: 53-254 -- Loss: 0.20111137628555298
train-epoch-step: 53-255 -- Loss: 0.1403850018978119
train-epoch-step: 53-256 -- Loss: 0.1397823542356491
train-epoch-step: 53-257 -- Loss: 0.1794266700744629
train-epoch-step: 53-258 -- Loss: 0.14182022213935852
train-epoch-step: 53-259 -- Loss: 0.11167252063751221
train-epoch-step: 53-260 -- Loss: 0.19565412402153015
train-epoch-step: 53-261 -- Loss: 0.16874872148036957
train-epoch-step: 53-262 -- Loss: 0.27377164363861084
train-epoch-step: 53-263 -- Loss: 0.19510313868522644
train-epoch-step: 53-264 -- Loss: 0.169683575630188
train-epoch-step: 53-265 -- Loss: 0.11485032737255096
train-epoch-step: 53-266 -- Loss: 0.14992231130599976
train-epoch-step: 53-267 -- Loss: 0.1264491230249405
train-epoch-step: 53-268 -- Loss: 0.11465465277433395
train-epoch-step: 53-269 -- Loss: 0.1676560491323471
train-epoch-step: 53-270 -- Loss: 0.10413028299808502
train-epoch-step: 53-271 -- Loss: 0.144607812166214
train-epoch-step: 53-272 -- Loss: 0.11481045186519623
train-epoch-step: 53-273 -- Loss: 0.1243278756737709
train-epoch-step: 53-274 -- Loss: 0.17954497039318085
train-epoch-step: 53-275 -- Loss: 0.18516741693019867
train-epoch-step: 53-276 -- Loss: 0.15220977365970612
train-epoch-step: 53-277 -- Loss: 0.1547064185142517
train-epoch-step: 53-278 -- Loss: 0.13504214584827423
train-epoch-step: 53-279 -- Loss: 0.13408325612545013
train-epoch-step: 53-280 -- Loss: 0.21193929016590118
train-epoch-step: 53-281 -- Loss: 0.1707746684551239
train-epoch-step: 53-282 -- Loss: 0.14058318734169006
train-epoch-step: 53-283 -- Loss: 0.11280182003974915
train-epoch-step: 53-284 -- Loss: 0.12831586599349976
train-epoch-step: 53-285 -- Loss: 0.18271692097187042
train-epoch-step: 53-286 -- Loss: 0.148641437292099
train-epoch-step: 53-287 -- Loss: 0.19357018172740936
train-epoch-step: 53-288 -- Loss: 0.09091069549322128
train-epoch-step: 53-289 -- Loss: 0.11784379929304123
train-epoch-step: 53-290 -- Loss: 0.17400090396404266
train-epoch-step: 53-291 -- Loss: 0.11318232119083405
train-epoch-step: 53-292 -- Loss: 0.1554083228111267
train-epoch-step: 53-293 -- Loss: 0.1349465698003769
train-epoch-step: 53-294 -- Loss: 0.15152183175086975
train-epoch-step: 53-295 -- Loss: 0.26371073722839355
train-epoch-step: 53-296 -- Loss: 0.15791113674640656
train-epoch-step: 53-297 -- Loss: 0.16663506627082825
train-epoch-step: 53-298 -- Loss: 0.22415998578071594
train-epoch-step: 53-299 -- Loss: 0.13986322283744812
train-epoch-step: 53-300 -- Loss: 0.1571555733680725
train-epoch-step: 53-301 -- Loss: 0.17517611384391785
train-epoch-step: 53-302 -- Loss: 0.20888613164424896
train-epoch-step: 53-303 -- Loss: 0.20093153417110443
train-epoch-step: 53-304 -- Loss: 0.12060911953449249
train-epoch-step: 53-305 -- Loss: 0.14043141901493073
train-epoch-step: 53-306 -- Loss: 0.2065693736076355
train-epoch-step: 53-307 -- Loss: 0.16153867542743683
train-epoch-step: 53-308 -- Loss: 0.21359655261039734
train-epoch-step: 53-309 -- Loss: 0.15302607417106628
train-epoch-step: 53-310 -- Loss: 0.1596766710281372
train-epoch-step: 53-311 -- Loss: 0.15432874858379364
train-epoch-step: 53-312 -- Loss: 0.19636107981204987
train-epoch-step: 53-313 -- Loss: 0.0950150117278099
train-epoch-step: 53-314 -- Loss: 0.19271425902843475
train-epoch-step: 53-315 -- Loss: 0.16056221723556519
train-epoch-step: 53-316 -- Loss: 0.14960822463035583
train-epoch-step: 53-317 -- Loss: 0.13368088006973267
train-epoch-step: 53-318 -- Loss: 0.15349029004573822
train-epoch-step: 53-319 -- Loss: 0.16085004806518555
train-epoch-step: 53-320 -- Loss: 0.11481134593486786
train-epoch-step: 53-321 -- Loss: 0.12673363089561462
train-epoch-step: 53-322 -- Loss: 0.20837897062301636
train-epoch-step: 53-323 -- Loss: 0.158579021692276
train-epoch-step: 53-324 -- Loss: 0.25326624512672424
train-epoch-step: 53-325 -- Loss: 0.15148115158081055
train-epoch-step: 53-326 -- Loss: 0.16859067976474762
train-epoch-step: 53-327 -- Loss: 0.19609542191028595
train-epoch-step: 53-328 -- Loss: 0.19039596617221832
train-epoch-step: 53-329 -- Loss: 0.3370921313762665
train-epoch-step: 53-330 -- Loss: 0.357358455657959
train-epoch-step: 53-331 -- Loss: 0.20676574110984802
train-epoch-step: 53-332 -- Loss: 0.09825637936592102
train-epoch-step: 53-333 -- Loss: 0.17818957567214966
train-epoch-step: 53-334 -- Loss: 0.14966222643852234
train-epoch-step: 53-335 -- Loss: 0.1685437262058258
train-epoch-step: 53-336 -- Loss: 0.1467389017343521
train-epoch-step: 53-337 -- Loss: 0.20030540227890015
train-epoch-step: 53-338 -- Loss: 0.16046728193759918
train-epoch-step: 53-339 -- Loss: 0.13926057517528534
train-epoch-step: 53-340 -- Loss: 0.1890474259853363
train-epoch-step: 53-341 -- Loss: 0.1379716992378235
train-epoch-step: 53-342 -- Loss: 0.1587168425321579
train-epoch-step: 53-343 -- Loss: 0.1508656144142151
train-epoch-step: 53-344 -- Loss: 0.1636602282524109
train-epoch-step: 53-345 -- Loss: 0.12410762906074524
train-epoch-step: 53-346 -- Loss: 0.1974332630634308
train-epoch-step: 53-347 -- Loss: 0.15039825439453125
train-epoch-step: 53-348 -- Loss: 0.19845899939537048
train-epoch-step: 53-349 -- Loss: 0.19651660323143005
train-epoch-step: 53-350 -- Loss: 0.2437501847743988
train-epoch-step: 53-351 -- Loss: 0.18741154670715332
train-epoch-step: 53-352 -- Loss: 0.1236429288983345
train-epoch-step: 53-353 -- Loss: 0.18866974115371704
train-epoch-step: 53-354 -- Loss: 0.272201269865036
train-epoch-step: 53-355 -- Loss: 0.11459392309188843
train-epoch-step: 53-356 -- Loss: 0.1192755475640297
train-epoch-step: 53-357 -- Loss: 0.1862848699092865
train-epoch-step: 53-358 -- Loss: 0.18018381297588348
train-epoch-step: 53-359 -- Loss: 0.13515222072601318
train-epoch-step: 53-360 -- Loss: 0.12217428535223007
train-epoch-step: 53-361 -- Loss: 0.22966277599334717
train-epoch-step: 53-362 -- Loss: 0.16452205181121826
train-epoch-step: 53-363 -- Loss: 0.10454222559928894
train-epoch-step: 53-364 -- Loss: 0.17754365503787994
train-epoch-step: 53-365 -- Loss: 0.16861525177955627
train-epoch-step: 53-366 -- Loss: 0.19264838099479675
train-epoch-step: 53-367 -- Loss: 0.2310466766357422
train-epoch-step: 53-368 -- Loss: 0.19907498359680176
train-epoch-step: 53-369 -- Loss: 0.27767035365104675
train-epoch-step: 53-370 -- Loss: 0.12185166776180267
train-epoch-step: 53-371 -- Loss: 0.11960412561893463
train-epoch-step: 53-372 -- Loss: 0.14252647757530212
train-epoch-step: 53-373 -- Loss: 0.1800033450126648
train-epoch-step: 53-374 -- Loss: 0.1490553319454193
train-epoch-step: 53-375 -- Loss: 0.2620463967323303
train-epoch-step: 53-376 -- Loss: 0.15971526503562927
train-epoch-step: 53-377 -- Loss: 0.22303594648838043
train-epoch-step: 53-378 -- Loss: 0.19320067763328552
train-epoch-step: 53-379 -- Loss: 0.11434371769428253
train-epoch-step: 53-380 -- Loss: 0.09044139832258224
train-epoch-step: 53-381 -- Loss: 0.23642794787883759
train-epoch-step: 53-382 -- Loss: 0.22660133242607117
train-epoch-step: 53-383 -- Loss: 0.1717528998851776
train-epoch-step: 53-384 -- Loss: 0.21366280317306519
train-epoch-step: 53-385 -- Loss: 0.18789495527744293
train-epoch-step: 53-386 -- Loss: 0.18267527222633362
train-epoch-step: 53-387 -- Loss: 0.19210316240787506
train-epoch-step: 53-388 -- Loss: 0.24984291195869446
train-epoch-step: 53-389 -- Loss: 0.16155880689620972
train-epoch-step: 53-390 -- Loss: 0.142350435256958
train-epoch-step: 53-391 -- Loss: 0.14485597610473633
train-epoch-step: 53-392 -- Loss: 0.18305489420890808
train-epoch-step: 53-393 -- Loss: 0.16727176308631897
train-epoch-step: 53-394 -- Loss: 0.20658934116363525
train-epoch-step: 53-395 -- Loss: 0.1738225519657135
train-epoch-step: 53-396 -- Loss: 0.1255389302968979
train-epoch-step: 53-397 -- Loss: 0.1265156865119934
train-epoch-step: 53-398 -- Loss: 0.227757066488266
train-epoch-step: 53-399 -- Loss: 0.2017555981874466
train-epoch-step: 53-400 -- Loss: 0.29651015996932983
train-epoch-step: 53-401 -- Loss: 0.12238075584173203
train-epoch-step: 53-402 -- Loss: 0.25972017645835876
train-epoch-step: 53-403 -- Loss: 0.15955570340156555
train-epoch-step: 53-404 -- Loss: 0.13710668683052063
train-epoch-step: 53-405 -- Loss: 0.14513498544692993
train-epoch-step: 53-406 -- Loss: 0.17212821543216705
train-epoch-step: 53-407 -- Loss: 0.1118149682879448
train-epoch-step: 53-408 -- Loss: 0.16631802916526794
train-epoch-step: 53-409 -- Loss: 0.18047267198562622
train-epoch-step: 53-410 -- Loss: 0.1716354340314865
train-epoch-step: 53-411 -- Loss: 0.2018478810787201
train-epoch-step: 53-412 -- Loss: 0.12764056026935577
train-epoch-step: 53-413 -- Loss: 0.14392641186714172
train-epoch-step: 53-414 -- Loss: 0.1325150430202484
train-epoch-step: 53-415 -- Loss: 0.13508857786655426
train-epoch-step: 53-416 -- Loss: 0.2643292546272278
train-epoch-step: 53-417 -- Loss: 0.1913432478904724
train-epoch-step: 53-418 -- Loss: 0.23011572659015656
train-epoch-step: 53-419 -- Loss: 0.16778722405433655
train-epoch-step: 53-420 -- Loss: 0.15151852369308472
train-epoch-step: 53-421 -- Loss: 0.19717782735824585
train-epoch-step: 53-422 -- Loss: 0.15056151151657104
train-epoch-step: 53-423 -- Loss: 0.17481067776679993
train-epoch-step: 53-424 -- Loss: 0.1345207393169403
train-epoch-step: 53-425 -- Loss: 0.18149042129516602
train-epoch-step: 53-426 -- Loss: 0.1613015979528427
train-epoch-step: 53-427 -- Loss: 0.12103848904371262
train-epoch-step: 53-428 -- Loss: 0.1946207582950592
train-epoch-step: 53-429 -- Loss: 0.174494206905365
train-epoch-step: 53-430 -- Loss: 0.1405748724937439
train-epoch-step: 53-431 -- Loss: 0.16144438087940216
train-epoch-step: 53-432 -- Loss: 0.23206162452697754
train-epoch-step: 53-433 -- Loss: 0.14317980408668518
train-epoch-step: 53-434 -- Loss: 0.1270633339881897
train-epoch-step: 53-435 -- Loss: 0.1591753214597702
train-epoch-step: 53-436 -- Loss: 0.14952315390110016
train-epoch-step: 53-437 -- Loss: 0.1316033899784088
train-epoch-step: 53-438 -- Loss: 0.16912831366062164
train-epoch-step: 53-439 -- Loss: 0.2585432529449463
train-epoch-step: 53-440 -- Loss: 0.1331804096698761
train-epoch-step: 53-441 -- Loss: 0.20433998107910156
train-epoch-step: 53-442 -- Loss: 0.17368337512016296
train-epoch-step: 53-443 -- Loss: 0.15557421743869781
train-epoch-step: 53-444 -- Loss: 0.17029379308223724
train-epoch-step: 53-445 -- Loss: 0.17312538623809814
train-epoch-step: 53-446 -- Loss: 0.1485229730606079
train-epoch-step: 53-447 -- Loss: 0.18353083729743958
train-epoch-step: 53-448 -- Loss: 0.22083167731761932
train-epoch-step: 53-449 -- Loss: 0.20203882455825806
train-epoch-step: 53-450 -- Loss: 0.1782146394252777
train-epoch-step: 53-451 -- Loss: 0.14144712686538696
train-epoch-step: 53-452 -- Loss: 0.1288735270500183
train-epoch-step: 53-453 -- Loss: 0.08835543692111969
train-epoch-step: 53-454 -- Loss: 0.2305012345314026
train-epoch-step: 53-455 -- Loss: 0.12203899025917053
train-epoch-step: 53-456 -- Loss: 0.11710537225008011
train-epoch-step: 53-457 -- Loss: 0.21181924641132355
train-epoch-step: 53-458 -- Loss: 0.14050428569316864
train-epoch-step: 53-459 -- Loss: 0.2075226902961731
train-epoch-step: 53-460 -- Loss: 0.1252918690443039
train-epoch-step: 53-461 -- Loss: 0.1329294592142105
train-epoch-step: 53-462 -- Loss: 0.14812736213207245
train-epoch-step: 53-463 -- Loss: 0.13069090247154236
train-epoch-step: 53-464 -- Loss: 0.15735122561454773
train-epoch-step: 53-465 -- Loss: 0.23009233176708221
train-epoch-step: 53-466 -- Loss: 0.19766174256801605
train-epoch-step: 53-467 -- Loss: 0.11100373417139053
train-epoch-step: 53-468 -- Loss: 0.16651327908039093
train-epoch-step: 53-469 -- Loss: 0.21149875223636627
train-epoch-step: 53-470 -- Loss: 0.16518087685108185
train-epoch-step: 53-471 -- Loss: 0.1545601636171341
train-epoch-step: 53-472 -- Loss: 0.1559697836637497
train-epoch-step: 53-473 -- Loss: 0.14783526957035065
train-epoch-step: 53-474 -- Loss: 0.11386851221323013
train-epoch-step: 53-475 -- Loss: 0.10682898759841919
train-epoch-step: 53-476 -- Loss: 0.1998530477285385
train-epoch-step: 53-477 -- Loss: 0.199776291847229
train-epoch-step: 53-478 -- Loss: 0.18178604543209076
train-epoch-step: 53-479 -- Loss: 0.13792812824249268
train-epoch-step: 53-480 -- Loss: 0.19047671556472778
train-epoch-step: 53-481 -- Loss: 0.27902519702911377
train-epoch-step: 53-482 -- Loss: 0.24066945910453796
train-epoch-step: 53-483 -- Loss: 0.17689315974712372
train-epoch-step: 53-484 -- Loss: 0.20527613162994385
train-epoch-step: 53-485 -- Loss: 0.12387365102767944
train-epoch-step: 53-486 -- Loss: 0.23208773136138916
train-epoch-step: 53-487 -- Loss: 0.22967630624771118
train-epoch-step: 53-488 -- Loss: 0.18127380311489105
train-epoch-step: 53-489 -- Loss: 0.2116333544254303
train-epoch-step: 53-490 -- Loss: 0.13344132900238037
train-epoch-step: 53-491 -- Loss: 0.13548988103866577
train-epoch-step: 53-492 -- Loss: 0.1244434267282486
train-epoch-step: 53-493 -- Loss: 0.19018985331058502
train-epoch-step: 53-494 -- Loss: 0.20101486146450043
train-epoch-step: 53-495 -- Loss: 0.19125010073184967
train-epoch-step: 53-496 -- Loss: 0.13985691964626312
train-epoch-step: 53-497 -- Loss: 0.17365548014640808
train-epoch-step: 53-498 -- Loss: 0.14230161905288696
train-epoch-step: 53-499 -- Loss: 0.1625060737133026
train-epoch-step: 53-500 -- Loss: 0.15107738971710205
train-epoch-step: 53-501 -- Loss: 0.20736467838287354
train-epoch-step: 53-502 -- Loss: 0.147252157330513
train-epoch-step: 53-503 -- Loss: 0.2172222137451172
train-epoch-step: 53-504 -- Loss: 0.11808530241250992
train-epoch-step: 53-505 -- Loss: 0.16851471364498138
train-epoch-step: 53-506 -- Loss: 0.11295896768569946
train-epoch-step: 53-507 -- Loss: 0.17663463950157166
train-epoch-step: 53-508 -- Loss: 0.17514745891094208
train-epoch-step: 53-509 -- Loss: 0.16956061124801636
train-epoch-step: 53-510 -- Loss: 0.12223120033740997
train-epoch-step: 53-511 -- Loss: 0.21167033910751343
train-epoch-step: 53-512 -- Loss: 0.17268475890159607
train-epoch-step: 53-513 -- Loss: 0.17836999893188477
train-epoch-step: 53-514 -- Loss: 0.14378821849822998
train-epoch-step: 53-515 -- Loss: 0.1523796021938324
train-epoch-step: 53-516 -- Loss: 0.16774456202983856
train-epoch-step: 53-517 -- Loss: 0.17094814777374268
train-epoch-step: 53-518 -- Loss: 0.13618487119674683
train-epoch-step: 53-519 -- Loss: 0.1303165704011917
train-epoch-step: 53-520 -- Loss: 0.1813264787197113
train-epoch-step: 53-521 -- Loss: 0.21797484159469604
train-epoch-step: 53-522 -- Loss: 0.17996221780776978
train-epoch-step: 53-523 -- Loss: 0.15143907070159912
train-epoch-step: 53-524 -- Loss: 0.1634141504764557
train-epoch-step: 53-525 -- Loss: 0.18651123344898224
train-epoch-step: 53-526 -- Loss: 0.13881319761276245
train-epoch-step: 53-527 -- Loss: 0.14720891416072845
train-epoch-step: 53-528 -- Loss: 0.15825611352920532
train-epoch-step: 53-529 -- Loss: 0.15305198729038239
train-epoch-step: 53-530 -- Loss: 0.2141437977552414
train-epoch-step: 53-531 -- Loss: 0.19218453764915466
train-epoch-step: 53-532 -- Loss: 0.16604149341583252
train-epoch-step: 53-533 -- Loss: 0.1790613979101181
train-epoch-step: 53-534 -- Loss: 0.1325371414422989
train-epoch-step: 53-535 -- Loss: 0.2656763792037964
train-epoch-step: 53-536 -- Loss: 0.1708417534828186
train-epoch-step: 53-537 -- Loss: 0.1687031090259552
train-epoch-step: 53-538 -- Loss: 0.10200891643762589
train-epoch-step: 53-539 -- Loss: 0.18500813841819763
train-epoch-step: 53-540 -- Loss: 0.1350334882736206
train-epoch-step: 53-541 -- Loss: 0.21274670958518982
train-epoch-step: 53-542 -- Loss: 0.22161659598350525
train-epoch-step: 53-543 -- Loss: 0.1844833791255951
train-epoch-step: 53-544 -- Loss: 0.22720113396644592
train-epoch-step: 53-545 -- Loss: 0.18738916516304016
train-epoch-step: 53-546 -- Loss: 0.20607680082321167
train-epoch-step: 53-547 -- Loss: 0.18353930115699768
train-epoch-step: 53-548 -- Loss: 0.10287533700466156
train-epoch-step: 53-549 -- Loss: 0.1581462323665619
train-epoch-step: 53-550 -- Loss: 0.1994137465953827
train-epoch-step: 53-551 -- Loss: 0.15058548748493195
train-epoch-step: 53-552 -- Loss: 0.12706178426742554
train-epoch-step: 53-553 -- Loss: 0.18525967001914978
train-epoch-step: 53-554 -- Loss: 0.18264621496200562
train-epoch-step: 53-555 -- Loss: 0.22122809290885925
train-epoch-step: 53-556 -- Loss: 0.14066629111766815
train-epoch-step: 53-557 -- Loss: 0.22715160250663757
train-epoch-step: 53-558 -- Loss: 0.21952763199806213
train-epoch-step: 53-559 -- Loss: 0.1454189568758011
train-epoch-step: 53-560 -- Loss: 0.2025545835494995
train-epoch-step: 53-561 -- Loss: 0.17558526992797852
train-epoch-step: 53-562 -- Loss: 0.16045761108398438
train-epoch-step: 53-563 -- Loss: 0.18054558336734772
train-epoch-step: 53-564 -- Loss: 0.10193406045436859
train-epoch-step: 53-565 -- Loss: 0.1809493750333786
train-epoch-step: 53-566 -- Loss: 0.14405658841133118
train-epoch-step: 53-567 -- Loss: 0.20679154992103577
train-epoch-step: 53-568 -- Loss: 0.15494340658187866
train-epoch-step: 53-569 -- Loss: 0.23771536350250244
train-epoch-step: 53-570 -- Loss: 0.1648724526166916
train-epoch-step: 53-571 -- Loss: 0.21228083968162537
train-epoch-step: 53-572 -- Loss: 0.23324377834796906
train-epoch-step: 53-573 -- Loss: 0.2006378471851349
train-epoch-step: 53-574 -- Loss: 0.26023802161216736
train-epoch-step: 53-575 -- Loss: 0.28533196449279785
train-epoch-step: 53-576 -- Loss: 0.11565782874822617
train-epoch-step: 53-577 -- Loss: 0.16805380582809448
train-epoch-step: 53-578 -- Loss: 0.21185046434402466
train-epoch-step: 53-579 -- Loss: 0.16029193997383118
train-epoch-step: 53-580 -- Loss: 0.16692224144935608
train-epoch-step: 53-581 -- Loss: 0.14869952201843262
train-epoch-step: 53-582 -- Loss: 0.19867512583732605
train-epoch-step: 53-583 -- Loss: 0.2699051797389984
train-epoch-step: 53-584 -- Loss: 0.1653716266155243
train-epoch-step: 53-585 -- Loss: 0.18586236238479614
train-epoch-step: 53-586 -- Loss: 0.2536754012107849
train-epoch-step: 53-587 -- Loss: 0.15864713490009308
train-epoch-step: 53-588 -- Loss: 0.12367896735668182
val-epoch-step: 53-589 -- Loss: 0.22018882632255554
val-epoch-step: 53-590 -- Loss: 0.15313099324703217
val-epoch-step: 53-591 -- Loss: 0.23220160603523254
val-epoch-step: 53-592 -- Loss: 0.175032377243042
val-epoch-step: 53-593 -- Loss: 0.14831946790218353
val-epoch-step: 53-594 -- Loss: 0.31078940629959106
val-epoch-step: 53-595 -- Loss: 0.1781550645828247
val-epoch-step: 53-596 -- Loss: 0.1860707849264145
val-epoch-step: 53-597 -- Loss: 0.16998611390590668
val-epoch-step: 53-598 -- Loss: 0.1463164985179901
val-epoch-step: 53-599 -- Loss: 0.18134421110153198
val-epoch-step: 53-600 -- Loss: 0.1682794690132141
val-epoch-step: 53-601 -- Loss: 0.16045306622982025
val-epoch-step: 53-602 -- Loss: 0.13217011094093323
val-epoch-step: 53-603 -- Loss: 0.20609837770462036
val-epoch-step: 53-604 -- Loss: 0.1474064588546753
val-epoch-step: 53-605 -- Loss: 0.14822131395339966
val-epoch-step: 53-606 -- Loss: 0.28226134181022644
val-epoch-step: 53-607 -- Loss: 0.12537729740142822
val-epoch-step: 53-608 -- Loss: 0.25155121088027954
val-epoch-step: 53-609 -- Loss: 0.1693858951330185
val-epoch-step: 53-610 -- Loss: 0.17620374262332916
val-epoch-step: 53-611 -- Loss: 0.15459150075912476
val-epoch-step: 53-612 -- Loss: 0.3886615037918091
val-epoch-step: 53-613 -- Loss: 0.17564818263053894
val-epoch-step: 53-614 -- Loss: 0.16150695085525513
val-epoch-step: 53-615 -- Loss: 0.17279262840747833
val-epoch-step: 53-616 -- Loss: 0.14541153609752655
val-epoch-step: 53-617 -- Loss: 0.19170290231704712
val-epoch-step: 53-618 -- Loss: 0.18535198271274567
val-epoch-step: 53-619 -- Loss: 0.20416085422039032
val-epoch-step: 53-620 -- Loss: 0.134123295545578
val-epoch-step: 53-621 -- Loss: 0.12813213467597961
val-epoch-step: 53-622 -- Loss: 0.1447671353816986
val-epoch-step: 53-623 -- Loss: 0.15207526087760925
val-epoch-step: 53-624 -- Loss: 0.15806801617145538
val-epoch-step: 53-625 -- Loss: 0.15277786552906036
val-epoch-step: 53-626 -- Loss: 0.146053746342659
val-epoch-step: 53-627 -- Loss: 0.18512395024299622
val-epoch-step: 53-628 -- Loss: 0.6267423033714294
val-epoch-step: 53-629 -- Loss: 0.18419241905212402
val-epoch-step: 53-630 -- Loss: 0.34256717562675476
val-epoch-step: 53-631 -- Loss: 0.14082753658294678
val-epoch-step: 53-632 -- Loss: 0.2059711217880249
val-epoch-step: 53-633 -- Loss: 0.1536179780960083
val-epoch-step: 53-634 -- Loss: 0.1443392038345337
val-epoch-step: 53-635 -- Loss: 0.11916471272706985
val-epoch-step: 53-636 -- Loss: 0.16952073574066162
val-epoch-step: 53-637 -- Loss: 0.1840182989835739
val-epoch-step: 53-638 -- Loss: 0.15023723244667053
val-epoch-step: 53-639 -- Loss: 0.2693093419075012
val-epoch-step: 53-640 -- Loss: 0.2506232261657715
val-epoch-step: 53-641 -- Loss: 0.13122238218784332
val-epoch-step: 53-642 -- Loss: 0.1835380345582962
val-epoch-step: 53-643 -- Loss: 0.20294582843780518
val-epoch-step: 53-644 -- Loss: 0.15857157111167908
val-epoch-step: 53-645 -- Loss: 0.21866406500339508
val-epoch-step: 53-646 -- Loss: 0.1969667673110962
val-epoch-step: 53-647 -- Loss: 0.13069243729114532
val-epoch-step: 53-648 -- Loss: 0.15546315908432007
val-epoch-step: 53-649 -- Loss: 0.2077132761478424
val-epoch-step: 53-650 -- Loss: 0.2486146092414856
val-epoch-step: 53-651 -- Loss: 0.14835532009601593
val-epoch-step: 53-652 -- Loss: 0.15680016577243805
val-epoch-step: 53-653 -- Loss: 0.21835285425186157
val-epoch-step: 53-654 -- Loss: 0.10929492861032486
Epoch: 53 -- Train Loss: tensor(0.1399, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 54-0 -- Loss: 0.22517025470733643
train-epoch-step: 54-1 -- Loss: 0.1389608085155487
train-epoch-step: 54-2 -- Loss: 0.21487028896808624
train-epoch-step: 54-3 -- Loss: 0.1386277675628662
train-epoch-step: 54-4 -- Loss: 0.15468363463878632
train-epoch-step: 54-5 -- Loss: 0.17929226160049438
train-epoch-step: 54-6 -- Loss: 0.21718427538871765
train-epoch-step: 54-7 -- Loss: 0.16559761762619019
train-epoch-step: 54-8 -- Loss: 0.17572245001792908
train-epoch-step: 54-9 -- Loss: 0.2202768474817276
train-epoch-step: 54-10 -- Loss: 0.19233913719654083
train-epoch-step: 54-11 -- Loss: 0.17638751864433289
train-epoch-step: 54-12 -- Loss: 0.1478201001882553
train-epoch-step: 54-13 -- Loss: 0.17310664057731628
train-epoch-step: 54-14 -- Loss: 0.16028553247451782
train-epoch-step: 54-15 -- Loss: 0.15542958676815033
train-epoch-step: 54-16 -- Loss: 0.1657697856426239
train-epoch-step: 54-17 -- Loss: 0.21169713139533997
train-epoch-step: 54-18 -- Loss: 0.1931019425392151
train-epoch-step: 54-19 -- Loss: 0.13096831738948822
train-epoch-step: 54-20 -- Loss: 0.2137274295091629
train-epoch-step: 54-21 -- Loss: 0.23993510007858276
train-epoch-step: 54-22 -- Loss: 0.13413354754447937
train-epoch-step: 54-23 -- Loss: 0.13941790163516998
train-epoch-step: 54-24 -- Loss: 0.125698059797287
train-epoch-step: 54-25 -- Loss: 0.22186222672462463
train-epoch-step: 54-26 -- Loss: 0.1869489699602127
train-epoch-step: 54-27 -- Loss: 0.22009041905403137
train-epoch-step: 54-28 -- Loss: 0.12274760007858276
train-epoch-step: 54-29 -- Loss: 0.2323639690876007
train-epoch-step: 54-30 -- Loss: 0.10669209808111191
train-epoch-step: 54-31 -- Loss: 0.13482193648815155
train-epoch-step: 54-32 -- Loss: 0.1677057445049286
train-epoch-step: 54-33 -- Loss: 0.27780604362487793
train-epoch-step: 54-34 -- Loss: 0.16660720109939575
train-epoch-step: 54-35 -- Loss: 0.244046151638031
train-epoch-step: 54-36 -- Loss: 0.135809063911438
train-epoch-step: 54-37 -- Loss: 0.13221806287765503
train-epoch-step: 54-38 -- Loss: 0.17832042276859283
train-epoch-step: 54-39 -- Loss: 0.21424120664596558
train-epoch-step: 54-40 -- Loss: 0.18366709351539612
train-epoch-step: 54-41 -- Loss: 0.20317448675632477
train-epoch-step: 54-42 -- Loss: 0.14661064743995667
train-epoch-step: 54-43 -- Loss: 0.2552868723869324
train-epoch-step: 54-44 -- Loss: 0.12712496519088745
train-epoch-step: 54-45 -- Loss: 0.11551815271377563
train-epoch-step: 54-46 -- Loss: 0.1624375432729721
train-epoch-step: 54-47 -- Loss: 0.19591937959194183
train-epoch-step: 54-48 -- Loss: 0.1488661915063858
train-epoch-step: 54-49 -- Loss: 0.2204265296459198
train-epoch-step: 54-50 -- Loss: 0.10766744613647461
train-epoch-step: 54-51 -- Loss: 0.17002597451210022
train-epoch-step: 54-52 -- Loss: 0.15708474814891815
train-epoch-step: 54-53 -- Loss: 0.19923880696296692
train-epoch-step: 54-54 -- Loss: 0.2778297960758209
train-epoch-step: 54-55 -- Loss: 0.1626967489719391
train-epoch-step: 54-56 -- Loss: 0.17229950428009033
train-epoch-step: 54-57 -- Loss: 0.22596442699432373
train-epoch-step: 54-58 -- Loss: 0.27647873759269714
train-epoch-step: 54-59 -- Loss: 0.22984743118286133
train-epoch-step: 54-60 -- Loss: 0.12442478537559509
train-epoch-step: 54-61 -- Loss: 0.19743579626083374
train-epoch-step: 54-62 -- Loss: 0.1772085428237915
train-epoch-step: 54-63 -- Loss: 0.1359994262456894
train-epoch-step: 54-64 -- Loss: 0.13991138339042664
train-epoch-step: 54-65 -- Loss: 0.17965105175971985
train-epoch-step: 54-66 -- Loss: 0.10477244108915329
train-epoch-step: 54-67 -- Loss: 0.12393601983785629
train-epoch-step: 54-68 -- Loss: 0.20725320279598236
train-epoch-step: 54-69 -- Loss: 0.1186189278960228
train-epoch-step: 54-70 -- Loss: 0.21786007285118103
train-epoch-step: 54-71 -- Loss: 0.2570299804210663
train-epoch-step: 54-72 -- Loss: 0.17155054211616516
train-epoch-step: 54-73 -- Loss: 0.20049966871738434
train-epoch-step: 54-74 -- Loss: 0.0954592227935791
train-epoch-step: 54-75 -- Loss: 0.1298222541809082
train-epoch-step: 54-76 -- Loss: 0.14117196202278137
train-epoch-step: 54-77 -- Loss: 0.22843293845653534
train-epoch-step: 54-78 -- Loss: 0.2690283954143524
train-epoch-step: 54-79 -- Loss: 0.1851855367422104
train-epoch-step: 54-80 -- Loss: 0.2380557656288147
train-epoch-step: 54-81 -- Loss: 0.12408512830734253
train-epoch-step: 54-82 -- Loss: 0.24840128421783447
train-epoch-step: 54-83 -- Loss: 0.1721181869506836
train-epoch-step: 54-84 -- Loss: 0.1836663782596588
train-epoch-step: 54-85 -- Loss: 0.17155608534812927
train-epoch-step: 54-86 -- Loss: 0.11828626692295074
train-epoch-step: 54-87 -- Loss: 0.20164822041988373
train-epoch-step: 54-88 -- Loss: 0.136918306350708
train-epoch-step: 54-89 -- Loss: 0.18384650349617004
train-epoch-step: 54-90 -- Loss: 0.18612951040267944
train-epoch-step: 54-91 -- Loss: 0.23551791906356812
train-epoch-step: 54-92 -- Loss: 0.15082187950611115
train-epoch-step: 54-93 -- Loss: 0.19066795706748962
train-epoch-step: 54-94 -- Loss: 0.21413297951221466
train-epoch-step: 54-95 -- Loss: 0.1838383972644806
train-epoch-step: 54-96 -- Loss: 0.2115871012210846
train-epoch-step: 54-97 -- Loss: 0.17009150981903076
train-epoch-step: 54-98 -- Loss: 0.1552012413740158
train-epoch-step: 54-99 -- Loss: 0.18285852670669556
train-epoch-step: 54-100 -- Loss: 0.18329790234565735
train-epoch-step: 54-101 -- Loss: 0.2618531584739685
train-epoch-step: 54-102 -- Loss: 0.21638521552085876
train-epoch-step: 54-103 -- Loss: 0.18105925619602203
train-epoch-step: 54-104 -- Loss: 0.14469099044799805
train-epoch-step: 54-105 -- Loss: 0.25670766830444336
train-epoch-step: 54-106 -- Loss: 0.17407794296741486
train-epoch-step: 54-107 -- Loss: 0.1871526539325714
train-epoch-step: 54-108 -- Loss: 0.18793830275535583
train-epoch-step: 54-109 -- Loss: 0.1426539570093155
train-epoch-step: 54-110 -- Loss: 0.1796036660671234
train-epoch-step: 54-111 -- Loss: 0.1779928207397461
train-epoch-step: 54-112 -- Loss: 0.1607290804386139
train-epoch-step: 54-113 -- Loss: 0.16117480397224426
train-epoch-step: 54-114 -- Loss: 0.2007380723953247
train-epoch-step: 54-115 -- Loss: 0.15905214846134186
train-epoch-step: 54-116 -- Loss: 0.13758546113967896
train-epoch-step: 54-117 -- Loss: 0.12299870699644089
train-epoch-step: 54-118 -- Loss: 0.19214239716529846
train-epoch-step: 54-119 -- Loss: 0.1471933275461197
train-epoch-step: 54-120 -- Loss: 0.24504703283309937
train-epoch-step: 54-121 -- Loss: 0.23941874504089355
train-epoch-step: 54-122 -- Loss: 0.205256387591362
train-epoch-step: 54-123 -- Loss: 0.19924254715442657
train-epoch-step: 54-124 -- Loss: 0.12004692852497101
train-epoch-step: 54-125 -- Loss: 0.1503075212240219
train-epoch-step: 54-126 -- Loss: 0.2259664535522461
train-epoch-step: 54-127 -- Loss: 0.16936258971691132
train-epoch-step: 54-128 -- Loss: 0.16597159206867218
train-epoch-step: 54-129 -- Loss: 0.1395961344242096
train-epoch-step: 54-130 -- Loss: 0.18873673677444458
train-epoch-step: 54-131 -- Loss: 0.13551285862922668
train-epoch-step: 54-132 -- Loss: 0.18526248633861542
train-epoch-step: 54-133 -- Loss: 0.11781389266252518
train-epoch-step: 54-134 -- Loss: 0.18852129578590393
train-epoch-step: 54-135 -- Loss: 0.13142617046833038
train-epoch-step: 54-136 -- Loss: 0.12561319768428802
train-epoch-step: 54-137 -- Loss: 0.23387283086776733
train-epoch-step: 54-138 -- Loss: 0.24814468622207642
train-epoch-step: 54-139 -- Loss: 0.13203930854797363
train-epoch-step: 54-140 -- Loss: 0.20365813374519348
train-epoch-step: 54-141 -- Loss: 0.2259974330663681
train-epoch-step: 54-142 -- Loss: 0.20316681265830994
train-epoch-step: 54-143 -- Loss: 0.1728365272283554
train-epoch-step: 54-144 -- Loss: 0.17525562644004822
train-epoch-step: 54-145 -- Loss: 0.13922622799873352
train-epoch-step: 54-146 -- Loss: 0.17717143893241882
train-epoch-step: 54-147 -- Loss: 0.16606423258781433
train-epoch-step: 54-148 -- Loss: 0.15397414565086365
train-epoch-step: 54-149 -- Loss: 0.11657070368528366
train-epoch-step: 54-150 -- Loss: 0.18040433526039124
train-epoch-step: 54-151 -- Loss: 0.1896323263645172
train-epoch-step: 54-152 -- Loss: 0.18684633076190948
train-epoch-step: 54-153 -- Loss: 0.2592596411705017
train-epoch-step: 54-154 -- Loss: 0.12540993094444275
train-epoch-step: 54-155 -- Loss: 0.13185103237628937
train-epoch-step: 54-156 -- Loss: 0.11381658911705017
train-epoch-step: 54-157 -- Loss: 0.1624157428741455
train-epoch-step: 54-158 -- Loss: 0.15990176796913147
train-epoch-step: 54-159 -- Loss: 0.17458122968673706
train-epoch-step: 54-160 -- Loss: 0.20412984490394592
train-epoch-step: 54-161 -- Loss: 0.2018153816461563
train-epoch-step: 54-162 -- Loss: 0.20642869174480438
train-epoch-step: 54-163 -- Loss: 0.18051064014434814
train-epoch-step: 54-164 -- Loss: 0.19203874468803406
train-epoch-step: 54-165 -- Loss: 0.15973740816116333
train-epoch-step: 54-166 -- Loss: 0.11711033433675766
train-epoch-step: 54-167 -- Loss: 0.12008549273014069
train-epoch-step: 54-168 -- Loss: 0.19939914345741272
train-epoch-step: 54-169 -- Loss: 0.13336436450481415
train-epoch-step: 54-170 -- Loss: 0.19644081592559814
train-epoch-step: 54-171 -- Loss: 0.14025405049324036
train-epoch-step: 54-172 -- Loss: 0.2563076317310333
train-epoch-step: 54-173 -- Loss: 0.1263110190629959
train-epoch-step: 54-174 -- Loss: 0.24214649200439453
train-epoch-step: 54-175 -- Loss: 0.1845483034849167
train-epoch-step: 54-176 -- Loss: 0.13470499217510223
train-epoch-step: 54-177 -- Loss: 0.1745195984840393
train-epoch-step: 54-178 -- Loss: 0.1754932403564453
train-epoch-step: 54-179 -- Loss: 0.1481279879808426
train-epoch-step: 54-180 -- Loss: 0.1483597755432129
train-epoch-step: 54-181 -- Loss: 0.1623285561800003
train-epoch-step: 54-182 -- Loss: 0.17451448738574982
train-epoch-step: 54-183 -- Loss: 0.26133131980895996
train-epoch-step: 54-184 -- Loss: 0.13492323458194733
train-epoch-step: 54-185 -- Loss: 0.14022141695022583
train-epoch-step: 54-186 -- Loss: 0.18390245735645294
train-epoch-step: 54-187 -- Loss: 0.20968469977378845
train-epoch-step: 54-188 -- Loss: 0.16680404543876648
train-epoch-step: 54-189 -- Loss: 0.10567700117826462
train-epoch-step: 54-190 -- Loss: 0.1790386587381363
train-epoch-step: 54-191 -- Loss: 0.15501907467842102
train-epoch-step: 54-192 -- Loss: 0.2273891121149063
train-epoch-step: 54-193 -- Loss: 0.20177306234836578
train-epoch-step: 54-194 -- Loss: 0.17883169651031494
train-epoch-step: 54-195 -- Loss: 0.16153225302696228
train-epoch-step: 54-196 -- Loss: 0.15988287329673767
train-epoch-step: 54-197 -- Loss: 0.12459028512239456
train-epoch-step: 54-198 -- Loss: 0.1254761815071106
train-epoch-step: 54-199 -- Loss: 0.14470461010932922
train-epoch-step: 54-200 -- Loss: 0.13050927221775055
train-epoch-step: 54-201 -- Loss: 0.1819646805524826
train-epoch-step: 54-202 -- Loss: 0.1356518715620041
train-epoch-step: 54-203 -- Loss: 0.17000500857830048
train-epoch-step: 54-204 -- Loss: 0.13106492161750793
train-epoch-step: 54-205 -- Loss: 0.17949707806110382
train-epoch-step: 54-206 -- Loss: 0.19328396022319794
train-epoch-step: 54-207 -- Loss: 0.13223347067832947
train-epoch-step: 54-208 -- Loss: 0.17180626094341278
train-epoch-step: 54-209 -- Loss: 0.14003823697566986
train-epoch-step: 54-210 -- Loss: 0.1280149519443512
train-epoch-step: 54-211 -- Loss: 0.20010587573051453
train-epoch-step: 54-212 -- Loss: 0.19272515177726746
train-epoch-step: 54-213 -- Loss: 0.12351267039775848
train-epoch-step: 54-214 -- Loss: 0.1423303782939911
train-epoch-step: 54-215 -- Loss: 0.12405470758676529
train-epoch-step: 54-216 -- Loss: 0.20017357170581818
train-epoch-step: 54-217 -- Loss: 0.2048082947731018
train-epoch-step: 54-218 -- Loss: 0.14518657326698303
train-epoch-step: 54-219 -- Loss: 0.15851303935050964
train-epoch-step: 54-220 -- Loss: 0.12420661747455597
train-epoch-step: 54-221 -- Loss: 0.20658144354820251
train-epoch-step: 54-222 -- Loss: 0.11572317034006119
train-epoch-step: 54-223 -- Loss: 0.16798248887062073
train-epoch-step: 54-224 -- Loss: 0.17916300892829895
train-epoch-step: 54-225 -- Loss: 0.26150229573249817
train-epoch-step: 54-226 -- Loss: 0.2035272717475891
train-epoch-step: 54-227 -- Loss: 0.21584631502628326
train-epoch-step: 54-228 -- Loss: 0.17841675877571106
train-epoch-step: 54-229 -- Loss: 0.17436382174491882
train-epoch-step: 54-230 -- Loss: 0.15896263718605042
train-epoch-step: 54-231 -- Loss: 0.15013335645198822
train-epoch-step: 54-232 -- Loss: 0.1808648556470871
train-epoch-step: 54-233 -- Loss: 0.08258461207151413
train-epoch-step: 54-234 -- Loss: 0.1735871136188507
train-epoch-step: 54-235 -- Loss: 0.14512132108211517
train-epoch-step: 54-236 -- Loss: 0.1737128496170044
train-epoch-step: 54-237 -- Loss: 0.23391251266002655
train-epoch-step: 54-238 -- Loss: 0.15046021342277527
train-epoch-step: 54-239 -- Loss: 0.1228918731212616
train-epoch-step: 54-240 -- Loss: 0.21604660153388977
train-epoch-step: 54-241 -- Loss: 0.14909793436527252
train-epoch-step: 54-242 -- Loss: 0.21317219734191895
train-epoch-step: 54-243 -- Loss: 0.2348693460226059
train-epoch-step: 54-244 -- Loss: 0.20132926106452942
train-epoch-step: 54-245 -- Loss: 0.21507561206817627
train-epoch-step: 54-246 -- Loss: 0.21107453107833862
train-epoch-step: 54-247 -- Loss: 0.19913962483406067
train-epoch-step: 54-248 -- Loss: 0.18163876235485077
train-epoch-step: 54-249 -- Loss: 0.1372213512659073
train-epoch-step: 54-250 -- Loss: 0.1945715844631195
train-epoch-step: 54-251 -- Loss: 0.11029097437858582
train-epoch-step: 54-252 -- Loss: 0.18323227763175964
train-epoch-step: 54-253 -- Loss: 0.13493600487709045
train-epoch-step: 54-254 -- Loss: 0.2089843451976776
train-epoch-step: 54-255 -- Loss: 0.14082071185112
train-epoch-step: 54-256 -- Loss: 0.14094750583171844
train-epoch-step: 54-257 -- Loss: 0.1822044551372528
train-epoch-step: 54-258 -- Loss: 0.14248746633529663
train-epoch-step: 54-259 -- Loss: 0.11140523105859756
train-epoch-step: 54-260 -- Loss: 0.2038431167602539
train-epoch-step: 54-261 -- Loss: 0.17012885212898254
train-epoch-step: 54-262 -- Loss: 0.2798076868057251
train-epoch-step: 54-263 -- Loss: 0.19579482078552246
train-epoch-step: 54-264 -- Loss: 0.16854099929332733
train-epoch-step: 54-265 -- Loss: 0.1087644025683403
train-epoch-step: 54-266 -- Loss: 0.1527387946844101
train-epoch-step: 54-267 -- Loss: 0.12668825685977936
train-epoch-step: 54-268 -- Loss: 0.11265359818935394
train-epoch-step: 54-269 -- Loss: 0.16850349307060242
train-epoch-step: 54-270 -- Loss: 0.10475553572177887
train-epoch-step: 54-271 -- Loss: 0.1428786963224411
train-epoch-step: 54-272 -- Loss: 0.1114019900560379
train-epoch-step: 54-273 -- Loss: 0.12267114222049713
train-epoch-step: 54-274 -- Loss: 0.17957766354084015
train-epoch-step: 54-275 -- Loss: 0.19250766932964325
train-epoch-step: 54-276 -- Loss: 0.15678872168064117
train-epoch-step: 54-277 -- Loss: 0.15195149183273315
train-epoch-step: 54-278 -- Loss: 0.13595673441886902
train-epoch-step: 54-279 -- Loss: 0.13703683018684387
train-epoch-step: 54-280 -- Loss: 0.21022404730319977
train-epoch-step: 54-281 -- Loss: 0.17149122059345245
train-epoch-step: 54-282 -- Loss: 0.13704758882522583
train-epoch-step: 54-283 -- Loss: 0.11380921304225922
train-epoch-step: 54-284 -- Loss: 0.1297469437122345
train-epoch-step: 54-285 -- Loss: 0.1828734129667282
train-epoch-step: 54-286 -- Loss: 0.15006525814533234
train-epoch-step: 54-287 -- Loss: 0.19111019372940063
train-epoch-step: 54-288 -- Loss: 0.09213582426309586
train-epoch-step: 54-289 -- Loss: 0.1195969209074974
train-epoch-step: 54-290 -- Loss: 0.17425532639026642
train-epoch-step: 54-291 -- Loss: 0.11480586975812912
train-epoch-step: 54-292 -- Loss: 0.15484005212783813
train-epoch-step: 54-293 -- Loss: 0.1386486440896988
train-epoch-step: 54-294 -- Loss: 0.1602017879486084
train-epoch-step: 54-295 -- Loss: 0.2584439516067505
train-epoch-step: 54-296 -- Loss: 0.15669474005699158
train-epoch-step: 54-297 -- Loss: 0.16598983108997345
train-epoch-step: 54-298 -- Loss: 0.22304096817970276
train-epoch-step: 54-299 -- Loss: 0.14234371483325958
train-epoch-step: 54-300 -- Loss: 0.15824973583221436
train-epoch-step: 54-301 -- Loss: 0.16119027137756348
train-epoch-step: 54-302 -- Loss: 0.2091847062110901
train-epoch-step: 54-303 -- Loss: 0.206376850605011
train-epoch-step: 54-304 -- Loss: 0.12031613290309906
train-epoch-step: 54-305 -- Loss: 0.1432073414325714
train-epoch-step: 54-306 -- Loss: 0.21052314341068268
train-epoch-step: 54-307 -- Loss: 0.15945054590702057
train-epoch-step: 54-308 -- Loss: 0.20644018054008484
train-epoch-step: 54-309 -- Loss: 0.1484667956829071
train-epoch-step: 54-310 -- Loss: 0.16472353041172028
train-epoch-step: 54-311 -- Loss: 0.15637287497520447
train-epoch-step: 54-312 -- Loss: 0.20276081562042236
train-epoch-step: 54-313 -- Loss: 0.09769504517316818
train-epoch-step: 54-314 -- Loss: 0.18978644907474518
train-epoch-step: 54-315 -- Loss: 0.164342999458313
train-epoch-step: 54-316 -- Loss: 0.14847327768802643
train-epoch-step: 54-317 -- Loss: 0.13813939690589905
train-epoch-step: 54-318 -- Loss: 0.15386034548282623
train-epoch-step: 54-319 -- Loss: 0.1579497903585434
train-epoch-step: 54-320 -- Loss: 0.11396534740924835
train-epoch-step: 54-321 -- Loss: 0.12831372022628784
train-epoch-step: 54-322 -- Loss: 0.20562803745269775
train-epoch-step: 54-323 -- Loss: 0.1536475569009781
train-epoch-step: 54-324 -- Loss: 0.24377480149269104
train-epoch-step: 54-325 -- Loss: 0.14894415438175201
train-epoch-step: 54-326 -- Loss: 0.1729981005191803
train-epoch-step: 54-327 -- Loss: 0.20204217731952667
train-epoch-step: 54-328 -- Loss: 0.18559616804122925
train-epoch-step: 54-329 -- Loss: 0.32925736904144287
train-epoch-step: 54-330 -- Loss: 0.35060355067253113
train-epoch-step: 54-331 -- Loss: 0.20392492413520813
train-epoch-step: 54-332 -- Loss: 0.0971960499882698
train-epoch-step: 54-333 -- Loss: 0.17420634627342224
train-epoch-step: 54-334 -- Loss: 0.14941497147083282
train-epoch-step: 54-335 -- Loss: 0.16426847875118256
train-epoch-step: 54-336 -- Loss: 0.14556042850017548
train-epoch-step: 54-337 -- Loss: 0.19893671572208405
train-epoch-step: 54-338 -- Loss: 0.15627822279930115
train-epoch-step: 54-339 -- Loss: 0.13806985318660736
train-epoch-step: 54-340 -- Loss: 0.18952707946300507
train-epoch-step: 54-341 -- Loss: 0.13689091801643372
train-epoch-step: 54-342 -- Loss: 0.1646849811077118
train-epoch-step: 54-343 -- Loss: 0.14816497266292572
train-epoch-step: 54-344 -- Loss: 0.170938640832901
train-epoch-step: 54-345 -- Loss: 0.12482314556837082
train-epoch-step: 54-346 -- Loss: 0.199594646692276
train-epoch-step: 54-347 -- Loss: 0.147650808095932
train-epoch-step: 54-348 -- Loss: 0.1979529857635498
train-epoch-step: 54-349 -- Loss: 0.19949871301651
train-epoch-step: 54-350 -- Loss: 0.24749374389648438
train-epoch-step: 54-351 -- Loss: 0.18552838265895844
train-epoch-step: 54-352 -- Loss: 0.1177811473608017
train-epoch-step: 54-353 -- Loss: 0.18780703842639923
train-epoch-step: 54-354 -- Loss: 0.2844271659851074
train-epoch-step: 54-355 -- Loss: 0.1165035143494606
train-epoch-step: 54-356 -- Loss: 0.11346036940813065
train-epoch-step: 54-357 -- Loss: 0.18259873986244202
train-epoch-step: 54-358 -- Loss: 0.1834903061389923
train-epoch-step: 54-359 -- Loss: 0.13523989915847778
train-epoch-step: 54-360 -- Loss: 0.11667570471763611
train-epoch-step: 54-361 -- Loss: 0.2328065037727356
train-epoch-step: 54-362 -- Loss: 0.1640121191740036
train-epoch-step: 54-363 -- Loss: 0.10424723476171494
train-epoch-step: 54-364 -- Loss: 0.17373591661453247
train-epoch-step: 54-365 -- Loss: 0.16443757712841034
train-epoch-step: 54-366 -- Loss: 0.1952594518661499
train-epoch-step: 54-367 -- Loss: 0.22756735980510712
train-epoch-step: 54-368 -- Loss: 0.19753286242485046
train-epoch-step: 54-369 -- Loss: 0.27260875701904297
train-epoch-step: 54-370 -- Loss: 0.1213265061378479
train-epoch-step: 54-371 -- Loss: 0.11785276234149933
train-epoch-step: 54-372 -- Loss: 0.14398548007011414
train-epoch-step: 54-373 -- Loss: 0.18198730051517487
train-epoch-step: 54-374 -- Loss: 0.14755520224571228
train-epoch-step: 54-375 -- Loss: 0.2603444457054138
train-epoch-step: 54-376 -- Loss: 0.15598665177822113
train-epoch-step: 54-377 -- Loss: 0.22334988415241241
train-epoch-step: 54-378 -- Loss: 0.1971631646156311
train-epoch-step: 54-379 -- Loss: 0.11477826535701752
train-epoch-step: 54-380 -- Loss: 0.09020549058914185
train-epoch-step: 54-381 -- Loss: 0.2359432876110077
train-epoch-step: 54-382 -- Loss: 0.2583226263523102
train-epoch-step: 54-383 -- Loss: 0.17679695785045624
train-epoch-step: 54-384 -- Loss: 0.21233722567558289
train-epoch-step: 54-385 -- Loss: 0.18344470858573914
train-epoch-step: 54-386 -- Loss: 0.1873742789030075
train-epoch-step: 54-387 -- Loss: 0.20273886620998383
train-epoch-step: 54-388 -- Loss: 0.18369249999523163
train-epoch-step: 54-389 -- Loss: 0.16440600156784058
train-epoch-step: 54-390 -- Loss: 0.14026565849781036
train-epoch-step: 54-391 -- Loss: 0.14534711837768555
train-epoch-step: 54-392 -- Loss: 0.1809237003326416
train-epoch-step: 54-393 -- Loss: 0.156105637550354
train-epoch-step: 54-394 -- Loss: 0.18954330682754517
train-epoch-step: 54-395 -- Loss: 0.1666763424873352
train-epoch-step: 54-396 -- Loss: 0.12672047317028046
train-epoch-step: 54-397 -- Loss: 0.12552036345005035
train-epoch-step: 54-398 -- Loss: 0.19814364612102509
train-epoch-step: 54-399 -- Loss: 0.1680382937192917
train-epoch-step: 54-400 -- Loss: 0.28590071201324463
train-epoch-step: 54-401 -- Loss: 0.11570482701063156
train-epoch-step: 54-402 -- Loss: 0.253068745136261
train-epoch-step: 54-403 -- Loss: 0.15456387400627136
train-epoch-step: 54-404 -- Loss: 0.14110343158245087
train-epoch-step: 54-405 -- Loss: 0.1623246818780899
train-epoch-step: 54-406 -- Loss: 0.16198799014091492
train-epoch-step: 54-407 -- Loss: 0.11032141000032425
train-epoch-step: 54-408 -- Loss: 0.16021890938282013
train-epoch-step: 54-409 -- Loss: 0.168853297829628
train-epoch-step: 54-410 -- Loss: 0.17257337272167206
train-epoch-step: 54-411 -- Loss: 0.1972120702266693
train-epoch-step: 54-412 -- Loss: 0.13133402168750763
train-epoch-step: 54-413 -- Loss: 0.14661690592765808
train-epoch-step: 54-414 -- Loss: 0.13514235615730286
train-epoch-step: 54-415 -- Loss: 0.13358359038829803
train-epoch-step: 54-416 -- Loss: 0.2614489793777466
train-epoch-step: 54-417 -- Loss: 0.18645501136779785
train-epoch-step: 54-418 -- Loss: 0.2294398993253708
train-epoch-step: 54-419 -- Loss: 0.1624307781457901
train-epoch-step: 54-420 -- Loss: 0.15150552988052368
train-epoch-step: 54-421 -- Loss: 0.17314521968364716
train-epoch-step: 54-422 -- Loss: 0.14695902168750763
train-epoch-step: 54-423 -- Loss: 0.1733996868133545
train-epoch-step: 54-424 -- Loss: 0.13298359513282776
train-epoch-step: 54-425 -- Loss: 0.1791529804468155
train-epoch-step: 54-426 -- Loss: 0.1605026125907898
train-epoch-step: 54-427 -- Loss: 0.1175970733165741
train-epoch-step: 54-428 -- Loss: 0.19033853709697723
train-epoch-step: 54-429 -- Loss: 0.17536015808582306
train-epoch-step: 54-430 -- Loss: 0.13943706452846527
train-epoch-step: 54-431 -- Loss: 0.162387415766716
train-epoch-step: 54-432 -- Loss: 0.23788635432720184
train-epoch-step: 54-433 -- Loss: 0.13859963417053223
train-epoch-step: 54-434 -- Loss: 0.1273876130580902
train-epoch-step: 54-435 -- Loss: 0.15552721917629242
train-epoch-step: 54-436 -- Loss: 0.15179209411144257
train-epoch-step: 54-437 -- Loss: 0.12907420098781586
train-epoch-step: 54-438 -- Loss: 0.1625705361366272
train-epoch-step: 54-439 -- Loss: 0.2651214599609375
train-epoch-step: 54-440 -- Loss: 0.126521036028862
train-epoch-step: 54-441 -- Loss: 0.1932329386472702
train-epoch-step: 54-442 -- Loss: 0.17666617035865784
train-epoch-step: 54-443 -- Loss: 0.14969214797019958
train-epoch-step: 54-444 -- Loss: 0.2213623821735382
train-epoch-step: 54-445 -- Loss: 0.17593111097812653
train-epoch-step: 54-446 -- Loss: 0.14939425885677338
train-epoch-step: 54-447 -- Loss: 0.18285809457302094
train-epoch-step: 54-448 -- Loss: 0.226335346698761
train-epoch-step: 54-449 -- Loss: 0.19167786836624146
train-epoch-step: 54-450 -- Loss: 0.1825089454650879
train-epoch-step: 54-451 -- Loss: 0.13730600476264954
train-epoch-step: 54-452 -- Loss: 0.12607067823410034
train-epoch-step: 54-453 -- Loss: 0.09187357127666473
train-epoch-step: 54-454 -- Loss: 0.22709861397743225
train-epoch-step: 54-455 -- Loss: 0.1191864088177681
train-epoch-step: 54-456 -- Loss: 0.12144199013710022
train-epoch-step: 54-457 -- Loss: 0.21451808512210846
train-epoch-step: 54-458 -- Loss: 0.1416987031698227
train-epoch-step: 54-459 -- Loss: 0.20589494705200195
train-epoch-step: 54-460 -- Loss: 0.12649142742156982
train-epoch-step: 54-461 -- Loss: 0.13414740562438965
train-epoch-step: 54-462 -- Loss: 0.15035882592201233
train-epoch-step: 54-463 -- Loss: 0.13180118799209595
train-epoch-step: 54-464 -- Loss: 0.15795114636421204
train-epoch-step: 54-465 -- Loss: 0.23026078939437866
train-epoch-step: 54-466 -- Loss: 0.18824036419391632
train-epoch-step: 54-467 -- Loss: 0.10907053202390671
train-epoch-step: 54-468 -- Loss: 0.16793084144592285
train-epoch-step: 54-469 -- Loss: 0.20149445533752441
train-epoch-step: 54-470 -- Loss: 0.16502900421619415
train-epoch-step: 54-471 -- Loss: 0.1579788327217102
train-epoch-step: 54-472 -- Loss: 0.15572287142276764
train-epoch-step: 54-473 -- Loss: 0.1486973911523819
train-epoch-step: 54-474 -- Loss: 0.11780612915754318
train-epoch-step: 54-475 -- Loss: 0.10548548400402069
train-epoch-step: 54-476 -- Loss: 0.19414934515953064
train-epoch-step: 54-477 -- Loss: 0.19099371135234833
train-epoch-step: 54-478 -- Loss: 0.17950908839702606
train-epoch-step: 54-479 -- Loss: 0.13652455806732178
train-epoch-step: 54-480 -- Loss: 0.1905197948217392
train-epoch-step: 54-481 -- Loss: 0.2788238525390625
train-epoch-step: 54-482 -- Loss: 0.244045227766037
train-epoch-step: 54-483 -- Loss: 0.17106448113918304
train-epoch-step: 54-484 -- Loss: 0.2073906511068344
train-epoch-step: 54-485 -- Loss: 0.12321284413337708
train-epoch-step: 54-486 -- Loss: 0.22203198075294495
train-epoch-step: 54-487 -- Loss: 0.22615183889865875
train-epoch-step: 54-488 -- Loss: 0.1839733123779297
train-epoch-step: 54-489 -- Loss: 0.21386763453483582
train-epoch-step: 54-490 -- Loss: 0.14106404781341553
train-epoch-step: 54-491 -- Loss: 0.13398462533950806
train-epoch-step: 54-492 -- Loss: 0.12317073345184326
train-epoch-step: 54-493 -- Loss: 0.19886192679405212
train-epoch-step: 54-494 -- Loss: 0.1952977478504181
train-epoch-step: 54-495 -- Loss: 0.19401636719703674
train-epoch-step: 54-496 -- Loss: 0.14038380980491638
train-epoch-step: 54-497 -- Loss: 0.17848658561706543
train-epoch-step: 54-498 -- Loss: 0.14285987615585327
train-epoch-step: 54-499 -- Loss: 0.161213681101799
train-epoch-step: 54-500 -- Loss: 0.15149907767772675
train-epoch-step: 54-501 -- Loss: 0.20937415957450867
train-epoch-step: 54-502 -- Loss: 0.17180892825126648
train-epoch-step: 54-503 -- Loss: 0.21398669481277466
train-epoch-step: 54-504 -- Loss: 0.11941389739513397
train-epoch-step: 54-505 -- Loss: 0.17109519243240356
train-epoch-step: 54-506 -- Loss: 0.11505438387393951
train-epoch-step: 54-507 -- Loss: 0.18314485251903534
train-epoch-step: 54-508 -- Loss: 0.17509014904499054
train-epoch-step: 54-509 -- Loss: 0.16347041726112366
train-epoch-step: 54-510 -- Loss: 0.12299305945634842
train-epoch-step: 54-511 -- Loss: 0.21032924950122833
train-epoch-step: 54-512 -- Loss: 0.1714087277650833
train-epoch-step: 54-513 -- Loss: 0.18049998581409454
train-epoch-step: 54-514 -- Loss: 0.14407148957252502
train-epoch-step: 54-515 -- Loss: 0.1518535017967224
train-epoch-step: 54-516 -- Loss: 0.16527009010314941
train-epoch-step: 54-517 -- Loss: 0.1715315878391266
train-epoch-step: 54-518 -- Loss: 0.1362028270959854
train-epoch-step: 54-519 -- Loss: 0.13155226409435272
train-epoch-step: 54-520 -- Loss: 0.18084043264389038
train-epoch-step: 54-521 -- Loss: 0.22303473949432373
train-epoch-step: 54-522 -- Loss: 0.16676650941371918
train-epoch-step: 54-523 -- Loss: 0.15253891050815582
train-epoch-step: 54-524 -- Loss: 0.1614859700202942
train-epoch-step: 54-525 -- Loss: 0.18866419792175293
train-epoch-step: 54-526 -- Loss: 0.1275993436574936
train-epoch-step: 54-527 -- Loss: 0.14917758107185364
train-epoch-step: 54-528 -- Loss: 0.15559595823287964
train-epoch-step: 54-529 -- Loss: 0.15200017392635345
train-epoch-step: 54-530 -- Loss: 0.16118857264518738
train-epoch-step: 54-531 -- Loss: 0.18889395892620087
train-epoch-step: 54-532 -- Loss: 0.16216543316841125
train-epoch-step: 54-533 -- Loss: 0.1693621277809143
train-epoch-step: 54-534 -- Loss: 0.12498071789741516
train-epoch-step: 54-535 -- Loss: 0.2441820204257965
train-epoch-step: 54-536 -- Loss: 0.15095938742160797
train-epoch-step: 54-537 -- Loss: 0.14163123071193695
train-epoch-step: 54-538 -- Loss: 0.10001328587532043
train-epoch-step: 54-539 -- Loss: 0.1765545904636383
train-epoch-step: 54-540 -- Loss: 0.1337520182132721
train-epoch-step: 54-541 -- Loss: 0.19928547739982605
train-epoch-step: 54-542 -- Loss: 0.21543753147125244
train-epoch-step: 54-543 -- Loss: 0.17454195022583008
train-epoch-step: 54-544 -- Loss: 0.22144752740859985
train-epoch-step: 54-545 -- Loss: 0.18638800084590912
train-epoch-step: 54-546 -- Loss: 0.21088771522045135
train-epoch-step: 54-547 -- Loss: 0.17722611129283905
train-epoch-step: 54-548 -- Loss: 0.08913399279117584
train-epoch-step: 54-549 -- Loss: 0.1482895463705063
train-epoch-step: 54-550 -- Loss: 0.19544437527656555
train-epoch-step: 54-551 -- Loss: 0.1511179655790329
train-epoch-step: 54-552 -- Loss: 0.12338569760322571
train-epoch-step: 54-553 -- Loss: 0.18013852834701538
train-epoch-step: 54-554 -- Loss: 0.1879800707101822
train-epoch-step: 54-555 -- Loss: 0.20682887732982635
train-epoch-step: 54-556 -- Loss: 0.14206212759017944
train-epoch-step: 54-557 -- Loss: 0.2450515776872635
train-epoch-step: 54-558 -- Loss: 0.22003838419914246
train-epoch-step: 54-559 -- Loss: 0.13188530504703522
train-epoch-step: 54-560 -- Loss: 0.19953876733779907
train-epoch-step: 54-561 -- Loss: 0.17260819673538208
train-epoch-step: 54-562 -- Loss: 0.15860621631145477
train-epoch-step: 54-563 -- Loss: 0.17981907725334167
train-epoch-step: 54-564 -- Loss: 0.0973639041185379
train-epoch-step: 54-565 -- Loss: 0.17559275031089783
train-epoch-step: 54-566 -- Loss: 0.1462017148733139
train-epoch-step: 54-567 -- Loss: 0.20431870222091675
train-epoch-step: 54-568 -- Loss: 0.15369734168052673
train-epoch-step: 54-569 -- Loss: 0.23758834600448608
train-epoch-step: 54-570 -- Loss: 0.15968744456768036
train-epoch-step: 54-571 -- Loss: 0.20860908925533295
train-epoch-step: 54-572 -- Loss: 0.23077259957790375
train-epoch-step: 54-573 -- Loss: 0.19549869000911713
train-epoch-step: 54-574 -- Loss: 0.23554188013076782
train-epoch-step: 54-575 -- Loss: 0.28987425565719604
train-epoch-step: 54-576 -- Loss: 0.11487554013729095
train-epoch-step: 54-577 -- Loss: 0.16108377277851105
train-epoch-step: 54-578 -- Loss: 0.21076111495494843
train-epoch-step: 54-579 -- Loss: 0.1590278595685959
train-epoch-step: 54-580 -- Loss: 0.16914823651313782
train-epoch-step: 54-581 -- Loss: 0.13472267985343933
train-epoch-step: 54-582 -- Loss: 0.20632216334342957
train-epoch-step: 54-583 -- Loss: 0.22379329800605774
train-epoch-step: 54-584 -- Loss: 0.16235674917697906
train-epoch-step: 54-585 -- Loss: 0.19103312492370605
train-epoch-step: 54-586 -- Loss: 0.24921903014183044
train-epoch-step: 54-587 -- Loss: 0.1538107544183731
train-epoch-step: 54-588 -- Loss: 0.13152894377708435
val-epoch-step: 54-589 -- Loss: 0.2165229618549347
val-epoch-step: 54-590 -- Loss: 0.1559678316116333
val-epoch-step: 54-591 -- Loss: 0.23426605761051178
val-epoch-step: 54-592 -- Loss: 0.231336310505867
val-epoch-step: 54-593 -- Loss: 0.1788838654756546
val-epoch-step: 54-594 -- Loss: 0.4873543679714203
val-epoch-step: 54-595 -- Loss: 0.24223662912845612
val-epoch-step: 54-596 -- Loss: 0.2533648908138275
val-epoch-step: 54-597 -- Loss: 0.23435914516448975
val-epoch-step: 54-598 -- Loss: 0.15355733036994934
val-epoch-step: 54-599 -- Loss: 0.1850530505180359
val-epoch-step: 54-600 -- Loss: 0.22344279289245605
val-epoch-step: 54-601 -- Loss: 0.1684902012348175
val-epoch-step: 54-602 -- Loss: 0.1402711272239685
val-epoch-step: 54-603 -- Loss: 0.2213326096534729
val-epoch-step: 54-604 -- Loss: 0.1516450047492981
val-epoch-step: 54-605 -- Loss: 0.1613960862159729
val-epoch-step: 54-606 -- Loss: 0.2599058747291565
val-epoch-step: 54-607 -- Loss: 0.15532037615776062
val-epoch-step: 54-608 -- Loss: 0.28206539154052734
val-epoch-step: 54-609 -- Loss: 0.18031974136829376
val-epoch-step: 54-610 -- Loss: 0.20686139166355133
val-epoch-step: 54-611 -- Loss: 0.18310557305812836
val-epoch-step: 54-612 -- Loss: 0.5745855569839478
val-epoch-step: 54-613 -- Loss: 0.17528438568115234
val-epoch-step: 54-614 -- Loss: 0.1917266547679901
val-epoch-step: 54-615 -- Loss: 0.18330277502536774
val-epoch-step: 54-616 -- Loss: 0.15274466574192047
val-epoch-step: 54-617 -- Loss: 0.20281857252120972
val-epoch-step: 54-618 -- Loss: 0.20155084133148193
val-epoch-step: 54-619 -- Loss: 0.2289438247680664
val-epoch-step: 54-620 -- Loss: 0.14322733879089355
val-epoch-step: 54-621 -- Loss: 0.14487092196941376
val-epoch-step: 54-622 -- Loss: 0.15685585141181946
val-epoch-step: 54-623 -- Loss: 0.15633980929851532
val-epoch-step: 54-624 -- Loss: 0.15100780129432678
val-epoch-step: 54-625 -- Loss: 0.16539454460144043
val-epoch-step: 54-626 -- Loss: 0.14782413840293884
val-epoch-step: 54-627 -- Loss: 0.184381365776062
val-epoch-step: 54-628 -- Loss: 0.7932506203651428
val-epoch-step: 54-629 -- Loss: 0.29239562153816223
val-epoch-step: 54-630 -- Loss: 0.34592488408088684
val-epoch-step: 54-631 -- Loss: 0.14321725070476532
val-epoch-step: 54-632 -- Loss: 0.21055012941360474
val-epoch-step: 54-633 -- Loss: 0.18855948746204376
val-epoch-step: 54-634 -- Loss: 0.14365097880363464
val-epoch-step: 54-635 -- Loss: 0.12327700853347778
val-epoch-step: 54-636 -- Loss: 0.22176384925842285
val-epoch-step: 54-637 -- Loss: 0.2248307466506958
val-epoch-step: 54-638 -- Loss: 0.19761553406715393
val-epoch-step: 54-639 -- Loss: 0.26886793971061707
val-epoch-step: 54-640 -- Loss: 0.28278738260269165
val-epoch-step: 54-641 -- Loss: 0.14404001832008362
val-epoch-step: 54-642 -- Loss: 0.23275718092918396
val-epoch-step: 54-643 -- Loss: 0.22203414142131805
val-epoch-step: 54-644 -- Loss: 0.17060181498527527
val-epoch-step: 54-645 -- Loss: 0.23907345533370972
val-epoch-step: 54-646 -- Loss: 0.14427027106285095
val-epoch-step: 54-647 -- Loss: 0.1331520974636078
val-epoch-step: 54-648 -- Loss: 0.16342759132385254
val-epoch-step: 54-649 -- Loss: 0.20279493927955627
val-epoch-step: 54-650 -- Loss: 0.25564491748809814
val-epoch-step: 54-651 -- Loss: 0.1459387242794037
val-epoch-step: 54-652 -- Loss: 0.17139750719070435
val-epoch-step: 54-653 -- Loss: 0.21527759730815887
val-epoch-step: 54-654 -- Loss: 0.12655022740364075
Epoch: 54 -- Train Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 55-0 -- Loss: 0.22667473554611206
train-epoch-step: 55-1 -- Loss: 0.14904989302158356
train-epoch-step: 55-2 -- Loss: 0.20562034845352173
train-epoch-step: 55-3 -- Loss: 0.1616651713848114
train-epoch-step: 55-4 -- Loss: 0.16693711280822754
train-epoch-step: 55-5 -- Loss: 0.20889581739902496
train-epoch-step: 55-6 -- Loss: 0.2294057011604309
train-epoch-step: 55-7 -- Loss: 0.1591106504201889
train-epoch-step: 55-8 -- Loss: 0.19837050139904022
train-epoch-step: 55-9 -- Loss: 0.22087621688842773
train-epoch-step: 55-10 -- Loss: 0.19840390980243683
train-epoch-step: 55-11 -- Loss: 0.21341204643249512
train-epoch-step: 55-12 -- Loss: 0.1567697376012802
train-epoch-step: 55-13 -- Loss: 0.17613500356674194
train-epoch-step: 55-14 -- Loss: 0.18021835386753082
train-epoch-step: 55-15 -- Loss: 0.15910948812961578
train-epoch-step: 55-16 -- Loss: 0.19852246344089508
train-epoch-step: 55-17 -- Loss: 0.22706013917922974
train-epoch-step: 55-18 -- Loss: 0.1953580230474472
train-epoch-step: 55-19 -- Loss: 0.13281649351119995
train-epoch-step: 55-20 -- Loss: 0.22236208617687225
train-epoch-step: 55-21 -- Loss: 0.2420404553413391
train-epoch-step: 55-22 -- Loss: 0.13672667741775513
train-epoch-step: 55-23 -- Loss: 0.1481853425502777
train-epoch-step: 55-24 -- Loss: 0.12666422128677368
train-epoch-step: 55-25 -- Loss: 0.24392744898796082
train-epoch-step: 55-26 -- Loss: 0.1965661644935608
train-epoch-step: 55-27 -- Loss: 0.2357518970966339
train-epoch-step: 55-28 -- Loss: 0.12720803916454315
train-epoch-step: 55-29 -- Loss: 0.23923707008361816
train-epoch-step: 55-30 -- Loss: 0.11110705137252808
train-epoch-step: 55-31 -- Loss: 0.13506142795085907
train-epoch-step: 55-32 -- Loss: 0.17167499661445618
train-epoch-step: 55-33 -- Loss: 0.2728392779827118
train-epoch-step: 55-34 -- Loss: 0.16570089757442474
train-epoch-step: 55-35 -- Loss: 0.2376231700181961
train-epoch-step: 55-36 -- Loss: 0.13473282754421234
train-epoch-step: 55-37 -- Loss: 0.13417749106884003
train-epoch-step: 55-38 -- Loss: 0.17897121608257294
train-epoch-step: 55-39 -- Loss: 0.23251329362392426
train-epoch-step: 55-40 -- Loss: 0.1929849237203598
train-epoch-step: 55-41 -- Loss: 0.21288111805915833
train-epoch-step: 55-42 -- Loss: 0.14470408856868744
train-epoch-step: 55-43 -- Loss: 0.259647011756897
train-epoch-step: 55-44 -- Loss: 0.13485084474086761
train-epoch-step: 55-45 -- Loss: 0.11132177710533142
train-epoch-step: 55-46 -- Loss: 0.16977283358573914
train-epoch-step: 55-47 -- Loss: 0.20120705664157867
train-epoch-step: 55-48 -- Loss: 0.1527584046125412
train-epoch-step: 55-49 -- Loss: 0.2207382321357727
train-epoch-step: 55-50 -- Loss: 0.10897305607795715
train-epoch-step: 55-51 -- Loss: 0.17796316742897034
train-epoch-step: 55-52 -- Loss: 0.15437699854373932
train-epoch-step: 55-53 -- Loss: 0.2061125934123993
train-epoch-step: 55-54 -- Loss: 0.28203967213630676
train-epoch-step: 55-55 -- Loss: 0.16609910130500793
train-epoch-step: 55-56 -- Loss: 0.1706254482269287
train-epoch-step: 55-57 -- Loss: 0.229146808385849
train-epoch-step: 55-58 -- Loss: 0.2756909728050232
train-epoch-step: 55-59 -- Loss: 0.2323857992887497
train-epoch-step: 55-60 -- Loss: 0.12973037362098694
train-epoch-step: 55-61 -- Loss: 0.19521257281303406
train-epoch-step: 55-62 -- Loss: 0.18135088682174683
train-epoch-step: 55-63 -- Loss: 0.13938835263252258
train-epoch-step: 55-64 -- Loss: 0.14554402232170105
train-epoch-step: 55-65 -- Loss: 0.1726073920726776
train-epoch-step: 55-66 -- Loss: 0.10822001099586487
train-epoch-step: 55-67 -- Loss: 0.1294141262769699
train-epoch-step: 55-68 -- Loss: 0.20413833856582642
train-epoch-step: 55-69 -- Loss: 0.11932094395160675
train-epoch-step: 55-70 -- Loss: 0.21802157163619995
train-epoch-step: 55-71 -- Loss: 0.2515225410461426
train-epoch-step: 55-72 -- Loss: 0.17024371027946472
train-epoch-step: 55-73 -- Loss: 0.2010505199432373
train-epoch-step: 55-74 -- Loss: 0.10213719308376312
train-epoch-step: 55-75 -- Loss: 0.12689942121505737
train-epoch-step: 55-76 -- Loss: 0.15706585347652435
train-epoch-step: 55-77 -- Loss: 0.22807925939559937
train-epoch-step: 55-78 -- Loss: 0.24868077039718628
train-epoch-step: 55-79 -- Loss: 0.18748381733894348
train-epoch-step: 55-80 -- Loss: 0.24219942092895508
train-epoch-step: 55-81 -- Loss: 0.11951287090778351
train-epoch-step: 55-82 -- Loss: 0.2445480227470398
train-epoch-step: 55-83 -- Loss: 0.17424026131629944
train-epoch-step: 55-84 -- Loss: 0.19791677594184875
train-epoch-step: 55-85 -- Loss: 0.17075154185295105
train-epoch-step: 55-86 -- Loss: 0.11609797179698944
train-epoch-step: 55-87 -- Loss: 0.20880252122879028
train-epoch-step: 55-88 -- Loss: 0.1339261531829834
train-epoch-step: 55-89 -- Loss: 0.18264365196228027
train-epoch-step: 55-90 -- Loss: 0.18746499717235565
train-epoch-step: 55-91 -- Loss: 0.26032471656799316
train-epoch-step: 55-92 -- Loss: 0.15019769966602325
train-epoch-step: 55-93 -- Loss: 0.16837692260742188
train-epoch-step: 55-94 -- Loss: 0.22408057749271393
train-epoch-step: 55-95 -- Loss: 0.18362820148468018
train-epoch-step: 55-96 -- Loss: 0.21089065074920654
train-epoch-step: 55-97 -- Loss: 0.17756739258766174
train-epoch-step: 55-98 -- Loss: 0.14990071952342987
train-epoch-step: 55-99 -- Loss: 0.18758216500282288
train-epoch-step: 55-100 -- Loss: 0.18605801463127136
train-epoch-step: 55-101 -- Loss: 0.26466310024261475
train-epoch-step: 55-102 -- Loss: 0.2164270281791687
train-epoch-step: 55-103 -- Loss: 0.181913822889328
train-epoch-step: 55-104 -- Loss: 0.14643734693527222
train-epoch-step: 55-105 -- Loss: 0.2570365369319916
train-epoch-step: 55-106 -- Loss: 0.17697809636592865
train-epoch-step: 55-107 -- Loss: 0.1860985904932022
train-epoch-step: 55-108 -- Loss: 0.18555155396461487
train-epoch-step: 55-109 -- Loss: 0.1447324901819229
train-epoch-step: 55-110 -- Loss: 0.1832200586795807
train-epoch-step: 55-111 -- Loss: 0.17169439792633057
train-epoch-step: 55-112 -- Loss: 0.16372311115264893
train-epoch-step: 55-113 -- Loss: 0.1570543348789215
train-epoch-step: 55-114 -- Loss: 0.19410648941993713
train-epoch-step: 55-115 -- Loss: 0.15810348093509674
train-epoch-step: 55-116 -- Loss: 0.13861848413944244
train-epoch-step: 55-117 -- Loss: 0.12393122166395187
train-epoch-step: 55-118 -- Loss: 0.1907355934381485
train-epoch-step: 55-119 -- Loss: 0.14671356976032257
train-epoch-step: 55-120 -- Loss: 0.24093115329742432
train-epoch-step: 55-121 -- Loss: 0.2325020283460617
train-epoch-step: 55-122 -- Loss: 0.21236470341682434
train-epoch-step: 55-123 -- Loss: 0.19969400763511658
train-epoch-step: 55-124 -- Loss: 0.11850433051586151
train-epoch-step: 55-125 -- Loss: 0.15241241455078125
train-epoch-step: 55-126 -- Loss: 0.21924154460430145
train-epoch-step: 55-127 -- Loss: 0.18773846328258514
train-epoch-step: 55-128 -- Loss: 0.16893434524536133
train-epoch-step: 55-129 -- Loss: 0.14233192801475525
train-epoch-step: 55-130 -- Loss: 0.18495847284793854
train-epoch-step: 55-131 -- Loss: 0.13460347056388855
train-epoch-step: 55-132 -- Loss: 0.1888924390077591
train-epoch-step: 55-133 -- Loss: 0.11996887624263763
train-epoch-step: 55-134 -- Loss: 0.19025066494941711
train-epoch-step: 55-135 -- Loss: 0.13015033304691315
train-epoch-step: 55-136 -- Loss: 0.13948774337768555
train-epoch-step: 55-137 -- Loss: 0.23533375561237335
train-epoch-step: 55-138 -- Loss: 0.25471723079681396
train-epoch-step: 55-139 -- Loss: 0.1273190975189209
train-epoch-step: 55-140 -- Loss: 0.20680812001228333
train-epoch-step: 55-141 -- Loss: 0.2248971313238144
train-epoch-step: 55-142 -- Loss: 0.20090973377227783
train-epoch-step: 55-143 -- Loss: 0.17624041438102722
train-epoch-step: 55-144 -- Loss: 0.18121272325515747
train-epoch-step: 55-145 -- Loss: 0.13491250574588776
train-epoch-step: 55-146 -- Loss: 0.17602528631687164
train-epoch-step: 55-147 -- Loss: 0.16370636224746704
train-epoch-step: 55-148 -- Loss: 0.15333180129528046
train-epoch-step: 55-149 -- Loss: 0.11607490479946136
train-epoch-step: 55-150 -- Loss: 0.1779874861240387
train-epoch-step: 55-151 -- Loss: 0.18561871349811554
train-epoch-step: 55-152 -- Loss: 0.19467735290527344
train-epoch-step: 55-153 -- Loss: 0.2563322186470032
train-epoch-step: 55-154 -- Loss: 0.12539082765579224
train-epoch-step: 55-155 -- Loss: 0.13115930557250977
train-epoch-step: 55-156 -- Loss: 0.11381761729717255
train-epoch-step: 55-157 -- Loss: 0.16611523926258087
train-epoch-step: 55-158 -- Loss: 0.16116690635681152
train-epoch-step: 55-159 -- Loss: 0.17263858020305634
train-epoch-step: 55-160 -- Loss: 0.2076336294412613
train-epoch-step: 55-161 -- Loss: 0.20121720433235168
train-epoch-step: 55-162 -- Loss: 0.20560850203037262
train-epoch-step: 55-163 -- Loss: 0.18370863795280457
train-epoch-step: 55-164 -- Loss: 0.19077202677726746
train-epoch-step: 55-165 -- Loss: 0.16016411781311035
train-epoch-step: 55-166 -- Loss: 0.1163664385676384
train-epoch-step: 55-167 -- Loss: 0.11876695603132248
train-epoch-step: 55-168 -- Loss: 0.19658438861370087
train-epoch-step: 55-169 -- Loss: 0.13376882672309875
train-epoch-step: 55-170 -- Loss: 0.19460678100585938
train-epoch-step: 55-171 -- Loss: 0.14432871341705322
train-epoch-step: 55-172 -- Loss: 0.25897416472435
train-epoch-step: 55-173 -- Loss: 0.13782627880573273
train-epoch-step: 55-174 -- Loss: 0.2428411990404129
train-epoch-step: 55-175 -- Loss: 0.18430611491203308
train-epoch-step: 55-176 -- Loss: 0.12735095620155334
train-epoch-step: 55-177 -- Loss: 0.1763547658920288
train-epoch-step: 55-178 -- Loss: 0.17526620626449585
train-epoch-step: 55-179 -- Loss: 0.14348940551280975
train-epoch-step: 55-180 -- Loss: 0.14617562294006348
train-epoch-step: 55-181 -- Loss: 0.16563789546489716
train-epoch-step: 55-182 -- Loss: 0.18146131932735443
train-epoch-step: 55-183 -- Loss: 0.2642284631729126
train-epoch-step: 55-184 -- Loss: 0.13938605785369873
train-epoch-step: 55-185 -- Loss: 0.13925635814666748
train-epoch-step: 55-186 -- Loss: 0.18090231716632843
train-epoch-step: 55-187 -- Loss: 0.20331799983978271
train-epoch-step: 55-188 -- Loss: 0.17426545917987823
train-epoch-step: 55-189 -- Loss: 0.10134953260421753
train-epoch-step: 55-190 -- Loss: 0.17944782972335815
train-epoch-step: 55-191 -- Loss: 0.15128804743289948
train-epoch-step: 55-192 -- Loss: 0.22942624986171722
train-epoch-step: 55-193 -- Loss: 0.20269878208637238
train-epoch-step: 55-194 -- Loss: 0.17792977392673492
train-epoch-step: 55-195 -- Loss: 0.16276583075523376
train-epoch-step: 55-196 -- Loss: 0.15981857478618622
train-epoch-step: 55-197 -- Loss: 0.12478575855493546
train-epoch-step: 55-198 -- Loss: 0.12306789308786392
train-epoch-step: 55-199 -- Loss: 0.14429964125156403
train-epoch-step: 55-200 -- Loss: 0.12267240881919861
train-epoch-step: 55-201 -- Loss: 0.19206026196479797
train-epoch-step: 55-202 -- Loss: 0.13594207167625427
train-epoch-step: 55-203 -- Loss: 0.16852512955665588
train-epoch-step: 55-204 -- Loss: 0.1345146894454956
train-epoch-step: 55-205 -- Loss: 0.17851564288139343
train-epoch-step: 55-206 -- Loss: 0.19915135204792023
train-epoch-step: 55-207 -- Loss: 0.1302640289068222
train-epoch-step: 55-208 -- Loss: 0.1738390326499939
train-epoch-step: 55-209 -- Loss: 0.13825178146362305
train-epoch-step: 55-210 -- Loss: 0.13389261066913605
train-epoch-step: 55-211 -- Loss: 0.19588050246238708
train-epoch-step: 55-212 -- Loss: 0.19587402045726776
train-epoch-step: 55-213 -- Loss: 0.1258169561624527
train-epoch-step: 55-214 -- Loss: 0.14560212194919586
train-epoch-step: 55-215 -- Loss: 0.12724190950393677
train-epoch-step: 55-216 -- Loss: 0.1981753259897232
train-epoch-step: 55-217 -- Loss: 0.2070639729499817
train-epoch-step: 55-218 -- Loss: 0.14368359744548798
train-epoch-step: 55-219 -- Loss: 0.1697452962398529
train-epoch-step: 55-220 -- Loss: 0.13050295412540436
train-epoch-step: 55-221 -- Loss: 0.19951298832893372
train-epoch-step: 55-222 -- Loss: 0.11364578455686569
train-epoch-step: 55-223 -- Loss: 0.16887468099594116
train-epoch-step: 55-224 -- Loss: 0.1817850023508072
train-epoch-step: 55-225 -- Loss: 0.2564660608768463
train-epoch-step: 55-226 -- Loss: 0.19658787548542023
train-epoch-step: 55-227 -- Loss: 0.21331991255283356
train-epoch-step: 55-228 -- Loss: 0.1734422892332077
train-epoch-step: 55-229 -- Loss: 0.165651336312294
train-epoch-step: 55-230 -- Loss: 0.16202187538146973
train-epoch-step: 55-231 -- Loss: 0.15062259137630463
train-epoch-step: 55-232 -- Loss: 0.18112105131149292
train-epoch-step: 55-233 -- Loss: 0.07940088212490082
train-epoch-step: 55-234 -- Loss: 0.17229638993740082
train-epoch-step: 55-235 -- Loss: 0.14366160333156586
train-epoch-step: 55-236 -- Loss: 0.17992562055587769
train-epoch-step: 55-237 -- Loss: 0.22915491461753845
train-epoch-step: 55-238 -- Loss: 0.1515928953886032
train-epoch-step: 55-239 -- Loss: 0.12138061225414276
train-epoch-step: 55-240 -- Loss: 0.21548157930374146
train-epoch-step: 55-241 -- Loss: 0.15177848935127258
train-epoch-step: 55-242 -- Loss: 0.21394206583499908
train-epoch-step: 55-243 -- Loss: 0.2291877269744873
train-epoch-step: 55-244 -- Loss: 0.2059677541255951
train-epoch-step: 55-245 -- Loss: 0.19872494041919708
train-epoch-step: 55-246 -- Loss: 0.21220412850379944
train-epoch-step: 55-247 -- Loss: 0.20704880356788635
train-epoch-step: 55-248 -- Loss: 0.18095757067203522
train-epoch-step: 55-249 -- Loss: 0.13337287306785583
train-epoch-step: 55-250 -- Loss: 0.19360481202602386
train-epoch-step: 55-251 -- Loss: 0.1045932024717331
train-epoch-step: 55-252 -- Loss: 0.18630358576774597
train-epoch-step: 55-253 -- Loss: 0.1327812373638153
train-epoch-step: 55-254 -- Loss: 0.20730185508728027
train-epoch-step: 55-255 -- Loss: 0.13998329639434814
train-epoch-step: 55-256 -- Loss: 0.1440940648317337
train-epoch-step: 55-257 -- Loss: 0.18548020720481873
train-epoch-step: 55-258 -- Loss: 0.14166417717933655
train-epoch-step: 55-259 -- Loss: 0.11380312591791153
train-epoch-step: 55-260 -- Loss: 0.19476935267448425
train-epoch-step: 55-261 -- Loss: 0.16877181828022003
train-epoch-step: 55-262 -- Loss: 0.28363344073295593
train-epoch-step: 55-263 -- Loss: 0.19782289862632751
train-epoch-step: 55-264 -- Loss: 0.17095838487148285
train-epoch-step: 55-265 -- Loss: 0.1113615334033966
train-epoch-step: 55-266 -- Loss: 0.14860066771507263
train-epoch-step: 55-267 -- Loss: 0.12539012730121613
train-epoch-step: 55-268 -- Loss: 0.1137709692120552
train-epoch-step: 55-269 -- Loss: 0.17237672209739685
train-epoch-step: 55-270 -- Loss: 0.10358411073684692
train-epoch-step: 55-271 -- Loss: 0.1440778523683548
train-epoch-step: 55-272 -- Loss: 0.11178131401538849
train-epoch-step: 55-273 -- Loss: 0.12399086356163025
train-epoch-step: 55-274 -- Loss: 0.1730385571718216
train-epoch-step: 55-275 -- Loss: 0.18517178297042847
train-epoch-step: 55-276 -- Loss: 0.15177962183952332
train-epoch-step: 55-277 -- Loss: 0.15427574515342712
train-epoch-step: 55-278 -- Loss: 0.1348201334476471
train-epoch-step: 55-279 -- Loss: 0.13441823422908783
train-epoch-step: 55-280 -- Loss: 0.2073456048965454
train-epoch-step: 55-281 -- Loss: 0.17048120498657227
train-epoch-step: 55-282 -- Loss: 0.14201684296131134
train-epoch-step: 55-283 -- Loss: 0.11190517991781235
train-epoch-step: 55-284 -- Loss: 0.14640726149082184
train-epoch-step: 55-285 -- Loss: 0.1875794529914856
train-epoch-step: 55-286 -- Loss: 0.1520174741744995
train-epoch-step: 55-287 -- Loss: 0.19320881366729736
train-epoch-step: 55-288 -- Loss: 0.0917314738035202
train-epoch-step: 55-289 -- Loss: 0.12432591617107391
train-epoch-step: 55-290 -- Loss: 0.18229106068611145
train-epoch-step: 55-291 -- Loss: 0.114197738468647
train-epoch-step: 55-292 -- Loss: 0.15357722342014313
train-epoch-step: 55-293 -- Loss: 0.13562026619911194
train-epoch-step: 55-294 -- Loss: 0.15390045940876007
train-epoch-step: 55-295 -- Loss: 0.2559090554714203
train-epoch-step: 55-296 -- Loss: 0.1513349562883377
train-epoch-step: 55-297 -- Loss: 0.16739673912525177
train-epoch-step: 55-298 -- Loss: 0.22518029808998108
train-epoch-step: 55-299 -- Loss: 0.14061981439590454
train-epoch-step: 55-300 -- Loss: 0.16352945566177368
train-epoch-step: 55-301 -- Loss: 0.1708197295665741
train-epoch-step: 55-302 -- Loss: 0.2124214917421341
train-epoch-step: 55-303 -- Loss: 0.20003938674926758
train-epoch-step: 55-304 -- Loss: 0.12221312522888184
train-epoch-step: 55-305 -- Loss: 0.13888780772686005
train-epoch-step: 55-306 -- Loss: 0.20898301899433136
train-epoch-step: 55-307 -- Loss: 0.16624516248703003
train-epoch-step: 55-308 -- Loss: 0.2102471888065338
train-epoch-step: 55-309 -- Loss: 0.15002259612083435
train-epoch-step: 55-310 -- Loss: 0.15738223493099213
train-epoch-step: 55-311 -- Loss: 0.15333804488182068
train-epoch-step: 55-312 -- Loss: 0.2003348469734192
train-epoch-step: 55-313 -- Loss: 0.09321660548448563
train-epoch-step: 55-314 -- Loss: 0.18789063394069672
train-epoch-step: 55-315 -- Loss: 0.16203828155994415
train-epoch-step: 55-316 -- Loss: 0.1480366736650467
train-epoch-step: 55-317 -- Loss: 0.13686972856521606
train-epoch-step: 55-318 -- Loss: 0.1571076214313507
train-epoch-step: 55-319 -- Loss: 0.16677802801132202
train-epoch-step: 55-320 -- Loss: 0.11481380462646484
train-epoch-step: 55-321 -- Loss: 0.13093101978302002
train-epoch-step: 55-322 -- Loss: 0.20579469203948975
train-epoch-step: 55-323 -- Loss: 0.1602293699979782
train-epoch-step: 55-324 -- Loss: 0.24818718433380127
train-epoch-step: 55-325 -- Loss: 0.1514226645231247
train-epoch-step: 55-326 -- Loss: 0.16306567192077637
train-epoch-step: 55-327 -- Loss: 0.19790638983249664
train-epoch-step: 55-328 -- Loss: 0.1881258636713028
train-epoch-step: 55-329 -- Loss: 0.3241605758666992
train-epoch-step: 55-330 -- Loss: 0.35904332995414734
train-epoch-step: 55-331 -- Loss: 0.2033545970916748
train-epoch-step: 55-332 -- Loss: 0.09655299782752991
train-epoch-step: 55-333 -- Loss: 0.17511671781539917
train-epoch-step: 55-334 -- Loss: 0.15036283433437347
train-epoch-step: 55-335 -- Loss: 0.1679466962814331
train-epoch-step: 55-336 -- Loss: 0.14373354613780975
train-epoch-step: 55-337 -- Loss: 0.2087002992630005
train-epoch-step: 55-338 -- Loss: 0.15865492820739746
train-epoch-step: 55-339 -- Loss: 0.14638158679008484
train-epoch-step: 55-340 -- Loss: 0.1919456571340561
train-epoch-step: 55-341 -- Loss: 0.1380138397216797
train-epoch-step: 55-342 -- Loss: 0.16000273823738098
train-epoch-step: 55-343 -- Loss: 0.14950686693191528
train-epoch-step: 55-344 -- Loss: 0.16425439715385437
train-epoch-step: 55-345 -- Loss: 0.12437686324119568
train-epoch-step: 55-346 -- Loss: 0.20289349555969238
train-epoch-step: 55-347 -- Loss: 0.14670313894748688
train-epoch-step: 55-348 -- Loss: 0.1960737705230713
train-epoch-step: 55-349 -- Loss: 0.20056745409965515
train-epoch-step: 55-350 -- Loss: 0.2432079166173935
train-epoch-step: 55-351 -- Loss: 0.18504978716373444
train-epoch-step: 55-352 -- Loss: 0.12067997455596924
train-epoch-step: 55-353 -- Loss: 0.18504898250102997
train-epoch-step: 55-354 -- Loss: 0.2767505645751953
train-epoch-step: 55-355 -- Loss: 0.11706855148077011
train-epoch-step: 55-356 -- Loss: 0.11354237794876099
train-epoch-step: 55-357 -- Loss: 0.18456633388996124
train-epoch-step: 55-358 -- Loss: 0.1833597868680954
train-epoch-step: 55-359 -- Loss: 0.13630637526512146
train-epoch-step: 55-360 -- Loss: 0.120263010263443
train-epoch-step: 55-361 -- Loss: 0.23359709978103638
train-epoch-step: 55-362 -- Loss: 0.16492274403572083
train-epoch-step: 55-363 -- Loss: 0.10892599076032639
train-epoch-step: 55-364 -- Loss: 0.17564764618873596
train-epoch-step: 55-365 -- Loss: 0.168247789144516
train-epoch-step: 55-366 -- Loss: 0.19320550560951233
train-epoch-step: 55-367 -- Loss: 0.2252640277147293
train-epoch-step: 55-368 -- Loss: 0.19216078519821167
train-epoch-step: 55-369 -- Loss: 0.27656280994415283
train-epoch-step: 55-370 -- Loss: 0.12197466939687729
train-epoch-step: 55-371 -- Loss: 0.11858686059713364
train-epoch-step: 55-372 -- Loss: 0.14129270613193512
train-epoch-step: 55-373 -- Loss: 0.18893679976463318
train-epoch-step: 55-374 -- Loss: 0.1504630744457245
train-epoch-step: 55-375 -- Loss: 0.25986871123313904
train-epoch-step: 55-376 -- Loss: 0.16002830862998962
train-epoch-step: 55-377 -- Loss: 0.2266869843006134
train-epoch-step: 55-378 -- Loss: 0.19446873664855957
train-epoch-step: 55-379 -- Loss: 0.11447446048259735
train-epoch-step: 55-380 -- Loss: 0.08873574435710907
train-epoch-step: 55-381 -- Loss: 0.2395222932100296
train-epoch-step: 55-382 -- Loss: 0.2298203706741333
train-epoch-step: 55-383 -- Loss: 0.1680106818675995
train-epoch-step: 55-384 -- Loss: 0.20816048979759216
train-epoch-step: 55-385 -- Loss: 0.18921661376953125
train-epoch-step: 55-386 -- Loss: 0.1831902116537094
train-epoch-step: 55-387 -- Loss: 0.19532573223114014
train-epoch-step: 55-388 -- Loss: 0.1808890849351883
train-epoch-step: 55-389 -- Loss: 0.16388528048992157
train-epoch-step: 55-390 -- Loss: 0.13798588514328003
train-epoch-step: 55-391 -- Loss: 0.1412433236837387
train-epoch-step: 55-392 -- Loss: 0.17845605313777924
train-epoch-step: 55-393 -- Loss: 0.15625940263271332
train-epoch-step: 55-394 -- Loss: 0.19549959897994995
train-epoch-step: 55-395 -- Loss: 0.15450896322727203
train-epoch-step: 55-396 -- Loss: 0.12263141572475433
train-epoch-step: 55-397 -- Loss: 0.12108619511127472
train-epoch-step: 55-398 -- Loss: 0.1919897198677063
train-epoch-step: 55-399 -- Loss: 0.17086686193943024
train-epoch-step: 55-400 -- Loss: 0.26893073320388794
train-epoch-step: 55-401 -- Loss: 0.12087389826774597
train-epoch-step: 55-402 -- Loss: 0.24879689514636993
train-epoch-step: 55-403 -- Loss: 0.15021273493766785
train-epoch-step: 55-404 -- Loss: 0.13588674366474152
train-epoch-step: 55-405 -- Loss: 0.13975727558135986
train-epoch-step: 55-406 -- Loss: 0.16389966011047363
train-epoch-step: 55-407 -- Loss: 0.10937469452619553
train-epoch-step: 55-408 -- Loss: 0.15571117401123047
train-epoch-step: 55-409 -- Loss: 0.16571398079395294
train-epoch-step: 55-410 -- Loss: 0.16936148703098297
train-epoch-step: 55-411 -- Loss: 0.1947529911994934
train-epoch-step: 55-412 -- Loss: 0.12577418982982635
train-epoch-step: 55-413 -- Loss: 0.14217549562454224
train-epoch-step: 55-414 -- Loss: 0.13231992721557617
train-epoch-step: 55-415 -- Loss: 0.13019593060016632
train-epoch-step: 55-416 -- Loss: 0.2589370310306549
train-epoch-step: 55-417 -- Loss: 0.18392378091812134
train-epoch-step: 55-418 -- Loss: 0.2185838222503662
train-epoch-step: 55-419 -- Loss: 0.16035741567611694
train-epoch-step: 55-420 -- Loss: 0.1476573646068573
train-epoch-step: 55-421 -- Loss: 0.17333613336086273
train-epoch-step: 55-422 -- Loss: 0.14792105555534363
train-epoch-step: 55-423 -- Loss: 0.17999568581581116
train-epoch-step: 55-424 -- Loss: 0.13433894515037537
train-epoch-step: 55-425 -- Loss: 0.17877863347530365
train-epoch-step: 55-426 -- Loss: 0.1582818329334259
train-epoch-step: 55-427 -- Loss: 0.11837422847747803
train-epoch-step: 55-428 -- Loss: 0.18331746757030487
train-epoch-step: 55-429 -- Loss: 0.17225411534309387
train-epoch-step: 55-430 -- Loss: 0.13804957270622253
train-epoch-step: 55-431 -- Loss: 0.1621587723493576
train-epoch-step: 55-432 -- Loss: 0.2328895926475525
train-epoch-step: 55-433 -- Loss: 0.13149218261241913
train-epoch-step: 55-434 -- Loss: 0.12404927611351013
train-epoch-step: 55-435 -- Loss: 0.14710059762001038
train-epoch-step: 55-436 -- Loss: 0.14785142242908478
train-epoch-step: 55-437 -- Loss: 0.1275034248828888
train-epoch-step: 55-438 -- Loss: 0.1640099287033081
train-epoch-step: 55-439 -- Loss: 0.25759175419807434
train-epoch-step: 55-440 -- Loss: 0.12949234247207642
train-epoch-step: 55-441 -- Loss: 0.19801051914691925
train-epoch-step: 55-442 -- Loss: 0.17224302887916565
train-epoch-step: 55-443 -- Loss: 0.14863047003746033
train-epoch-step: 55-444 -- Loss: 0.1689775288105011
train-epoch-step: 55-445 -- Loss: 0.1784970909357071
train-epoch-step: 55-446 -- Loss: 0.14768198132514954
train-epoch-step: 55-447 -- Loss: 0.1843910962343216
train-epoch-step: 55-448 -- Loss: 0.2192401885986328
train-epoch-step: 55-449 -- Loss: 0.1877070963382721
train-epoch-step: 55-450 -- Loss: 0.17392069101333618
train-epoch-step: 55-451 -- Loss: 0.13910405337810516
train-epoch-step: 55-452 -- Loss: 0.13066183030605316
train-epoch-step: 55-453 -- Loss: 0.09007777273654938
train-epoch-step: 55-454 -- Loss: 0.22434952855110168
train-epoch-step: 55-455 -- Loss: 0.12436574697494507
train-epoch-step: 55-456 -- Loss: 0.11597990989685059
train-epoch-step: 55-457 -- Loss: 0.21087472140789032
train-epoch-step: 55-458 -- Loss: 0.14550085365772247
train-epoch-step: 55-459 -- Loss: 0.21205034852027893
train-epoch-step: 55-460 -- Loss: 0.1209021806716919
train-epoch-step: 55-461 -- Loss: 0.1301524043083191
train-epoch-step: 55-462 -- Loss: 0.15099476277828217
train-epoch-step: 55-463 -- Loss: 0.13132381439208984
train-epoch-step: 55-464 -- Loss: 0.15643329918384552
train-epoch-step: 55-465 -- Loss: 0.23223556578159332
train-epoch-step: 55-466 -- Loss: 0.19607609510421753
train-epoch-step: 55-467 -- Loss: 0.11086089164018631
train-epoch-step: 55-468 -- Loss: 0.16219553351402283
train-epoch-step: 55-469 -- Loss: 0.19818536937236786
train-epoch-step: 55-470 -- Loss: 0.1629871279001236
train-epoch-step: 55-471 -- Loss: 0.15131881833076477
train-epoch-step: 55-472 -- Loss: 0.1538526713848114
train-epoch-step: 55-473 -- Loss: 0.14742347598075867
train-epoch-step: 55-474 -- Loss: 0.11583114415407181
train-epoch-step: 55-475 -- Loss: 0.11082462966442108
train-epoch-step: 55-476 -- Loss: 0.19004690647125244
train-epoch-step: 55-477 -- Loss: 0.18949757516384125
train-epoch-step: 55-478 -- Loss: 0.19072654843330383
train-epoch-step: 55-479 -- Loss: 0.13613766431808472
train-epoch-step: 55-480 -- Loss: 0.19140714406967163
train-epoch-step: 55-481 -- Loss: 0.277387797832489
train-epoch-step: 55-482 -- Loss: 0.2574135661125183
train-epoch-step: 55-483 -- Loss: 0.1724608838558197
train-epoch-step: 55-484 -- Loss: 0.20874100923538208
train-epoch-step: 55-485 -- Loss: 0.12255275249481201
train-epoch-step: 55-486 -- Loss: 0.22712357342243195
train-epoch-step: 55-487 -- Loss: 0.2657650113105774
train-epoch-step: 55-488 -- Loss: 0.1977463960647583
train-epoch-step: 55-489 -- Loss: 0.2219461053609848
train-epoch-step: 55-490 -- Loss: 0.1340588927268982
train-epoch-step: 55-491 -- Loss: 0.13880249857902527
train-epoch-step: 55-492 -- Loss: 0.12393757700920105
train-epoch-step: 55-493 -- Loss: 0.1898871809244156
train-epoch-step: 55-494 -- Loss: 0.1922021508216858
train-epoch-step: 55-495 -- Loss: 0.1977778673171997
train-epoch-step: 55-496 -- Loss: 0.13806483149528503
train-epoch-step: 55-497 -- Loss: 0.17814642190933228
train-epoch-step: 55-498 -- Loss: 0.14405159652233124
train-epoch-step: 55-499 -- Loss: 0.16629567742347717
train-epoch-step: 55-500 -- Loss: 0.15093325078487396
train-epoch-step: 55-501 -- Loss: 0.20949611067771912
train-epoch-step: 55-502 -- Loss: 0.15278260409832
train-epoch-step: 55-503 -- Loss: 0.22224944829940796
train-epoch-step: 55-504 -- Loss: 0.11810711026191711
train-epoch-step: 55-505 -- Loss: 0.17008404433727264
train-epoch-step: 55-506 -- Loss: 0.11590030044317245
train-epoch-step: 55-507 -- Loss: 0.17543640732765198
train-epoch-step: 55-508 -- Loss: 0.175995871424675
train-epoch-step: 55-509 -- Loss: 0.16302882134914398
train-epoch-step: 55-510 -- Loss: 0.12440432608127594
train-epoch-step: 55-511 -- Loss: 0.214427188038826
train-epoch-step: 55-512 -- Loss: 0.16914726793766022
train-epoch-step: 55-513 -- Loss: 0.18403387069702148
train-epoch-step: 55-514 -- Loss: 0.1444559246301651
train-epoch-step: 55-515 -- Loss: 0.14771592617034912
train-epoch-step: 55-516 -- Loss: 0.16652345657348633
train-epoch-step: 55-517 -- Loss: 0.17021822929382324
train-epoch-step: 55-518 -- Loss: 0.13493070006370544
train-epoch-step: 55-519 -- Loss: 0.1320119947195053
train-epoch-step: 55-520 -- Loss: 0.1796548068523407
train-epoch-step: 55-521 -- Loss: 0.22452694177627563
train-epoch-step: 55-522 -- Loss: 0.16943971812725067
train-epoch-step: 55-523 -- Loss: 0.14946427941322327
train-epoch-step: 55-524 -- Loss: 0.16094516217708588
train-epoch-step: 55-525 -- Loss: 0.18538670241832733
train-epoch-step: 55-526 -- Loss: 0.1274208128452301
train-epoch-step: 55-527 -- Loss: 0.14641204476356506
train-epoch-step: 55-528 -- Loss: 0.15425091981887817
train-epoch-step: 55-529 -- Loss: 0.1567511409521103
train-epoch-step: 55-530 -- Loss: 0.16162608563899994
train-epoch-step: 55-531 -- Loss: 0.1899658739566803
train-epoch-step: 55-532 -- Loss: 0.16761414706707
train-epoch-step: 55-533 -- Loss: 0.16696718335151672
train-epoch-step: 55-534 -- Loss: 0.12660880386829376
train-epoch-step: 55-535 -- Loss: 0.24269483983516693
train-epoch-step: 55-536 -- Loss: 0.1530982255935669
train-epoch-step: 55-537 -- Loss: 0.1526636779308319
train-epoch-step: 55-538 -- Loss: 0.102338507771492
train-epoch-step: 55-539 -- Loss: 0.17604105174541473
train-epoch-step: 55-540 -- Loss: 0.132423534989357
train-epoch-step: 55-541 -- Loss: 0.19958296418190002
train-epoch-step: 55-542 -- Loss: 0.2162940800189972
train-epoch-step: 55-543 -- Loss: 0.16346484422683716
train-epoch-step: 55-544 -- Loss: 0.22208364307880402
train-epoch-step: 55-545 -- Loss: 0.18492715060710907
train-epoch-step: 55-546 -- Loss: 0.20269465446472168
train-epoch-step: 55-547 -- Loss: 0.1742943674325943
train-epoch-step: 55-548 -- Loss: 0.09018125385046005
train-epoch-step: 55-549 -- Loss: 0.14764457941055298
train-epoch-step: 55-550 -- Loss: 0.19859279692173004
train-epoch-step: 55-551 -- Loss: 0.1489473134279251
train-epoch-step: 55-552 -- Loss: 0.12363643944263458
train-epoch-step: 55-553 -- Loss: 0.18321779370307922
train-epoch-step: 55-554 -- Loss: 0.17749567329883575
train-epoch-step: 55-555 -- Loss: 0.20301394164562225
train-epoch-step: 55-556 -- Loss: 0.14002828299999237
train-epoch-step: 55-557 -- Loss: 0.22489112615585327
train-epoch-step: 55-558 -- Loss: 0.21965470910072327
train-epoch-step: 55-559 -- Loss: 0.13607627153396606
train-epoch-step: 55-560 -- Loss: 0.2032199501991272
train-epoch-step: 55-561 -- Loss: 0.17185242474079132
train-epoch-step: 55-562 -- Loss: 0.15731054544448853
train-epoch-step: 55-563 -- Loss: 0.1794104427099228
train-epoch-step: 55-564 -- Loss: 0.09937845170497894
train-epoch-step: 55-565 -- Loss: 0.17800062894821167
train-epoch-step: 55-566 -- Loss: 0.14278052747249603
train-epoch-step: 55-567 -- Loss: 0.20367534458637238
train-epoch-step: 55-568 -- Loss: 0.15197505056858063
train-epoch-step: 55-569 -- Loss: 0.23883578181266785
train-epoch-step: 55-570 -- Loss: 0.16137579083442688
train-epoch-step: 55-571 -- Loss: 0.20562194287776947
train-epoch-step: 55-572 -- Loss: 0.22605228424072266
train-epoch-step: 55-573 -- Loss: 0.19282639026641846
train-epoch-step: 55-574 -- Loss: 0.2334146946668625
train-epoch-step: 55-575 -- Loss: 0.2931874096393585
train-epoch-step: 55-576 -- Loss: 0.11449991911649704
train-epoch-step: 55-577 -- Loss: 0.16060099005699158
train-epoch-step: 55-578 -- Loss: 0.2089344561100006
train-epoch-step: 55-579 -- Loss: 0.15855860710144043
train-epoch-step: 55-580 -- Loss: 0.16846269369125366
train-epoch-step: 55-581 -- Loss: 0.13078872859477997
train-epoch-step: 55-582 -- Loss: 0.20194755494594574
train-epoch-step: 55-583 -- Loss: 0.20566622912883759
train-epoch-step: 55-584 -- Loss: 0.1608695387840271
train-epoch-step: 55-585 -- Loss: 0.18717136979103088
train-epoch-step: 55-586 -- Loss: 0.24770674109458923
train-epoch-step: 55-587 -- Loss: 0.1546151041984558
train-epoch-step: 55-588 -- Loss: 0.1233726292848587
val-epoch-step: 55-589 -- Loss: 0.1914600282907486
val-epoch-step: 55-590 -- Loss: 0.15057824552059174
val-epoch-step: 55-591 -- Loss: 0.24159987270832062
val-epoch-step: 55-592 -- Loss: 0.17284461855888367
val-epoch-step: 55-593 -- Loss: 0.15544143319129944
val-epoch-step: 55-594 -- Loss: 0.340538889169693
val-epoch-step: 55-595 -- Loss: 0.18539030849933624
val-epoch-step: 55-596 -- Loss: 0.1884930282831192
val-epoch-step: 55-597 -- Loss: 0.16320189833641052
val-epoch-step: 55-598 -- Loss: 0.1459134817123413
val-epoch-step: 55-599 -- Loss: 0.17887656390666962
val-epoch-step: 55-600 -- Loss: 0.20872525870800018
val-epoch-step: 55-601 -- Loss: 0.15825089812278748
val-epoch-step: 55-602 -- Loss: 0.1323850005865097
val-epoch-step: 55-603 -- Loss: 0.2102535367012024
val-epoch-step: 55-604 -- Loss: 0.14656266570091248
val-epoch-step: 55-605 -- Loss: 0.142991840839386
val-epoch-step: 55-606 -- Loss: 0.26646724343299866
val-epoch-step: 55-607 -- Loss: 0.12139581143856049
val-epoch-step: 55-608 -- Loss: 0.24609996378421783
val-epoch-step: 55-609 -- Loss: 0.1654113233089447
val-epoch-step: 55-610 -- Loss: 0.17679515480995178
val-epoch-step: 55-611 -- Loss: 0.15425796806812286
val-epoch-step: 55-612 -- Loss: 0.4181646406650543
val-epoch-step: 55-613 -- Loss: 0.17041566967964172
val-epoch-step: 55-614 -- Loss: 0.1745186746120453
val-epoch-step: 55-615 -- Loss: 0.17034363746643066
val-epoch-step: 55-616 -- Loss: 0.14464902877807617
val-epoch-step: 55-617 -- Loss: 0.1802017092704773
val-epoch-step: 55-618 -- Loss: 0.17984236776828766
val-epoch-step: 55-619 -- Loss: 0.2172650396823883
val-epoch-step: 55-620 -- Loss: 0.15527603030204773
val-epoch-step: 55-621 -- Loss: 0.12354554235935211
val-epoch-step: 55-622 -- Loss: 0.1428852677345276
val-epoch-step: 55-623 -- Loss: 0.1479274332523346
val-epoch-step: 55-624 -- Loss: 0.14209842681884766
val-epoch-step: 55-625 -- Loss: 0.15501195192337036
val-epoch-step: 55-626 -- Loss: 0.14298710227012634
val-epoch-step: 55-627 -- Loss: 0.178337961435318
val-epoch-step: 55-628 -- Loss: 0.6493592858314514
val-epoch-step: 55-629 -- Loss: 0.19863179326057434
val-epoch-step: 55-630 -- Loss: 0.3361513018608093
val-epoch-step: 55-631 -- Loss: 0.13685491681098938
val-epoch-step: 55-632 -- Loss: 0.199300155043602
val-epoch-step: 55-633 -- Loss: 0.14389167726039886
val-epoch-step: 55-634 -- Loss: 0.15610525012016296
val-epoch-step: 55-635 -- Loss: 0.11099199205636978
val-epoch-step: 55-636 -- Loss: 0.16039368510246277
val-epoch-step: 55-637 -- Loss: 0.17626060545444489
val-epoch-step: 55-638 -- Loss: 0.14101848006248474
val-epoch-step: 55-639 -- Loss: 0.2494979202747345
val-epoch-step: 55-640 -- Loss: 0.2564176023006439
val-epoch-step: 55-641 -- Loss: 0.131479412317276
val-epoch-step: 55-642 -- Loss: 0.18048298358917236
val-epoch-step: 55-643 -- Loss: 0.20361709594726562
val-epoch-step: 55-644 -- Loss: 0.16131538152694702
val-epoch-step: 55-645 -- Loss: 0.21081675589084625
val-epoch-step: 55-646 -- Loss: 0.12731283903121948
val-epoch-step: 55-647 -- Loss: 0.12572966516017914
val-epoch-step: 55-648 -- Loss: 0.15081270039081573
val-epoch-step: 55-649 -- Loss: 0.20102638006210327
val-epoch-step: 55-650 -- Loss: 0.24367311596870422
val-epoch-step: 55-651 -- Loss: 0.15133541822433472
val-epoch-step: 55-652 -- Loss: 0.1590360552072525
val-epoch-step: 55-653 -- Loss: 0.20699580013751984
val-epoch-step: 55-654 -- Loss: 0.11258053034543991
Epoch: 55 -- Train Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 56-0 -- Loss: 0.2145349681377411
train-epoch-step: 56-1 -- Loss: 0.13844318687915802
train-epoch-step: 56-2 -- Loss: 0.1925487220287323
train-epoch-step: 56-3 -- Loss: 0.13996143639087677
train-epoch-step: 56-4 -- Loss: 0.1526142805814743
train-epoch-step: 56-5 -- Loss: 0.1728246808052063
train-epoch-step: 56-6 -- Loss: 0.20808497071266174
train-epoch-step: 56-7 -- Loss: 0.16012749075889587
train-epoch-step: 56-8 -- Loss: 0.17206135392189026
train-epoch-step: 56-9 -- Loss: 0.22258737683296204
train-epoch-step: 56-10 -- Loss: 0.18610887229442596
train-epoch-step: 56-11 -- Loss: 0.17062728106975555
train-epoch-step: 56-12 -- Loss: 0.14612004160881042
train-epoch-step: 56-13 -- Loss: 0.1719026267528534
train-epoch-step: 56-14 -- Loss: 0.15995900332927704
train-epoch-step: 56-15 -- Loss: 0.15596142411231995
train-epoch-step: 56-16 -- Loss: 0.15862171351909637
train-epoch-step: 56-17 -- Loss: 0.2091887891292572
train-epoch-step: 56-18 -- Loss: 0.18781442940235138
train-epoch-step: 56-19 -- Loss: 0.12741249799728394
train-epoch-step: 56-20 -- Loss: 0.20902496576309204
train-epoch-step: 56-21 -- Loss: 0.25303447246551514
train-epoch-step: 56-22 -- Loss: 0.13442353904247284
train-epoch-step: 56-23 -- Loss: 0.14362889528274536
train-epoch-step: 56-24 -- Loss: 0.12097084522247314
train-epoch-step: 56-25 -- Loss: 0.21816758811473846
train-epoch-step: 56-26 -- Loss: 0.18963855504989624
train-epoch-step: 56-27 -- Loss: 0.25832411646842957
train-epoch-step: 56-28 -- Loss: 0.12023095041513443
train-epoch-step: 56-29 -- Loss: 0.23428630828857422
train-epoch-step: 56-30 -- Loss: 0.10664945095777512
train-epoch-step: 56-31 -- Loss: 0.1340109407901764
train-epoch-step: 56-32 -- Loss: 0.1728658825159073
train-epoch-step: 56-33 -- Loss: 0.27072155475616455
train-epoch-step: 56-34 -- Loss: 0.16997851431369781
train-epoch-step: 56-35 -- Loss: 0.2351633757352829
train-epoch-step: 56-36 -- Loss: 0.13562576472759247
train-epoch-step: 56-37 -- Loss: 0.13358736038208008
train-epoch-step: 56-38 -- Loss: 0.17300117015838623
train-epoch-step: 56-39 -- Loss: 0.21682536602020264
train-epoch-step: 56-40 -- Loss: 0.18858981132507324
train-epoch-step: 56-41 -- Loss: 0.20666459202766418
train-epoch-step: 56-42 -- Loss: 0.14231011271476746
train-epoch-step: 56-43 -- Loss: 0.2679634988307953
train-epoch-step: 56-44 -- Loss: 0.1225387379527092
train-epoch-step: 56-45 -- Loss: 0.11117027699947357
train-epoch-step: 56-46 -- Loss: 0.16270296275615692
train-epoch-step: 56-47 -- Loss: 0.20226708054542542
train-epoch-step: 56-48 -- Loss: 0.14951850473880768
train-epoch-step: 56-49 -- Loss: 0.22822871804237366
train-epoch-step: 56-50 -- Loss: 0.1048821359872818
train-epoch-step: 56-51 -- Loss: 0.17669227719306946
train-epoch-step: 56-52 -- Loss: 0.15672239661216736
train-epoch-step: 56-53 -- Loss: 0.20085246860980988
train-epoch-step: 56-54 -- Loss: 0.2798178791999817
train-epoch-step: 56-55 -- Loss: 0.1625978946685791
train-epoch-step: 56-56 -- Loss: 0.17276862263679504
train-epoch-step: 56-57 -- Loss: 0.22628921270370483
train-epoch-step: 56-58 -- Loss: 0.27634942531585693
train-epoch-step: 56-59 -- Loss: 0.23358787596225739
train-epoch-step: 56-60 -- Loss: 0.13177691400051117
train-epoch-step: 56-61 -- Loss: 0.20226611196994781
train-epoch-step: 56-62 -- Loss: 0.1828405261039734
train-epoch-step: 56-63 -- Loss: 0.12965106964111328
train-epoch-step: 56-64 -- Loss: 0.1433039754629135
train-epoch-step: 56-65 -- Loss: 0.17418870329856873
train-epoch-step: 56-66 -- Loss: 0.10462846606969833
train-epoch-step: 56-67 -- Loss: 0.12044836580753326
train-epoch-step: 56-68 -- Loss: 0.20475375652313232
train-epoch-step: 56-69 -- Loss: 0.11809471994638443
train-epoch-step: 56-70 -- Loss: 0.21751615405082703
train-epoch-step: 56-71 -- Loss: 0.25465843081474304
train-epoch-step: 56-72 -- Loss: 0.178134024143219
train-epoch-step: 56-73 -- Loss: 0.20397543907165527
train-epoch-step: 56-74 -- Loss: 0.09415525197982788
train-epoch-step: 56-75 -- Loss: 0.12308835983276367
train-epoch-step: 56-76 -- Loss: 0.1439094990491867
train-epoch-step: 56-77 -- Loss: 0.22572025656700134
train-epoch-step: 56-78 -- Loss: 0.25137901306152344
train-epoch-step: 56-79 -- Loss: 0.18740831315517426
train-epoch-step: 56-80 -- Loss: 0.24484892189502716
train-epoch-step: 56-81 -- Loss: 0.11949294060468674
train-epoch-step: 56-82 -- Loss: 0.24873052537441254
train-epoch-step: 56-83 -- Loss: 0.177398681640625
train-epoch-step: 56-84 -- Loss: 0.18545781075954437
train-epoch-step: 56-85 -- Loss: 0.16917119920253754
train-epoch-step: 56-86 -- Loss: 0.11565577238798141
train-epoch-step: 56-87 -- Loss: 0.2078191190958023
train-epoch-step: 56-88 -- Loss: 0.13503195345401764
train-epoch-step: 56-89 -- Loss: 0.1820889413356781
train-epoch-step: 56-90 -- Loss: 0.19606317579746246
train-epoch-step: 56-91 -- Loss: 0.23709022998809814
train-epoch-step: 56-92 -- Loss: 0.1506384015083313
train-epoch-step: 56-93 -- Loss: 0.1690060943365097
train-epoch-step: 56-94 -- Loss: 0.2366606444120407
train-epoch-step: 56-95 -- Loss: 0.18269376456737518
train-epoch-step: 56-96 -- Loss: 0.21400101482868195
train-epoch-step: 56-97 -- Loss: 0.16797974705696106
train-epoch-step: 56-98 -- Loss: 0.15002770721912384
train-epoch-step: 56-99 -- Loss: 0.18441641330718994
train-epoch-step: 56-100 -- Loss: 0.18162237107753754
train-epoch-step: 56-101 -- Loss: 0.25064724683761597
train-epoch-step: 56-102 -- Loss: 0.22024033963680267
train-epoch-step: 56-103 -- Loss: 0.18257883191108704
train-epoch-step: 56-104 -- Loss: 0.14538508653640747
train-epoch-step: 56-105 -- Loss: 0.26642173528671265
train-epoch-step: 56-106 -- Loss: 0.17224298417568207
train-epoch-step: 56-107 -- Loss: 0.18537510931491852
train-epoch-step: 56-108 -- Loss: 0.18556678295135498
train-epoch-step: 56-109 -- Loss: 0.1445850282907486
train-epoch-step: 56-110 -- Loss: 0.17643482983112335
train-epoch-step: 56-111 -- Loss: 0.1777030974626541
train-epoch-step: 56-112 -- Loss: 0.15718761086463928
train-epoch-step: 56-113 -- Loss: 0.1601080596446991
train-epoch-step: 56-114 -- Loss: 0.18867109715938568
train-epoch-step: 56-115 -- Loss: 0.16876496374607086
train-epoch-step: 56-116 -- Loss: 0.137409046292305
train-epoch-step: 56-117 -- Loss: 0.1284835785627365
train-epoch-step: 56-118 -- Loss: 0.19112823903560638
train-epoch-step: 56-119 -- Loss: 0.1476224958896637
train-epoch-step: 56-120 -- Loss: 0.24004369974136353
train-epoch-step: 56-121 -- Loss: 0.225908100605011
train-epoch-step: 56-122 -- Loss: 0.22318680584430695
train-epoch-step: 56-123 -- Loss: 0.20091481506824493
train-epoch-step: 56-124 -- Loss: 0.11849990487098694
train-epoch-step: 56-125 -- Loss: 0.1522684395313263
train-epoch-step: 56-126 -- Loss: 0.22366654872894287
train-epoch-step: 56-127 -- Loss: 0.16650739312171936
train-epoch-step: 56-128 -- Loss: 0.16872718930244446
train-epoch-step: 56-129 -- Loss: 0.13754311203956604
train-epoch-step: 56-130 -- Loss: 0.18975605070590973
train-epoch-step: 56-131 -- Loss: 0.13721118867397308
train-epoch-step: 56-132 -- Loss: 0.18107423186302185
train-epoch-step: 56-133 -- Loss: 0.1265045702457428
train-epoch-step: 56-134 -- Loss: 0.18530616164207458
train-epoch-step: 56-135 -- Loss: 0.13123905658721924
train-epoch-step: 56-136 -- Loss: 0.12143061310052872
train-epoch-step: 56-137 -- Loss: 0.2371889054775238
train-epoch-step: 56-138 -- Loss: 0.25881272554397583
train-epoch-step: 56-139 -- Loss: 0.12842097878456116
train-epoch-step: 56-140 -- Loss: 0.20402012765407562
train-epoch-step: 56-141 -- Loss: 0.22309735417366028
train-epoch-step: 56-142 -- Loss: 0.19897843897342682
train-epoch-step: 56-143 -- Loss: 0.16764114797115326
train-epoch-step: 56-144 -- Loss: 0.1763344407081604
train-epoch-step: 56-145 -- Loss: 0.14094647765159607
train-epoch-step: 56-146 -- Loss: 0.1774357110261917
train-epoch-step: 56-147 -- Loss: 0.16518287360668182
train-epoch-step: 56-148 -- Loss: 0.15417060256004333
train-epoch-step: 56-149 -- Loss: 0.11579817533493042
train-epoch-step: 56-150 -- Loss: 0.17749372124671936
train-epoch-step: 56-151 -- Loss: 0.19100329279899597
train-epoch-step: 56-152 -- Loss: 0.18425503373146057
train-epoch-step: 56-153 -- Loss: 0.25913792848587036
train-epoch-step: 56-154 -- Loss: 0.12976284325122833
train-epoch-step: 56-155 -- Loss: 0.13942228257656097
train-epoch-step: 56-156 -- Loss: 0.11620832979679108
train-epoch-step: 56-157 -- Loss: 0.1650727242231369
train-epoch-step: 56-158 -- Loss: 0.16499944031238556
train-epoch-step: 56-159 -- Loss: 0.1750020980834961
train-epoch-step: 56-160 -- Loss: 0.2037755846977234
train-epoch-step: 56-161 -- Loss: 0.20611406862735748
train-epoch-step: 56-162 -- Loss: 0.21487677097320557
train-epoch-step: 56-163 -- Loss: 0.18762169778347015
train-epoch-step: 56-164 -- Loss: 0.18714573979377747
train-epoch-step: 56-165 -- Loss: 0.1616239696741104
train-epoch-step: 56-166 -- Loss: 0.11521270871162415
train-epoch-step: 56-167 -- Loss: 0.12610414624214172
train-epoch-step: 56-168 -- Loss: 0.2022397220134735
train-epoch-step: 56-169 -- Loss: 0.14195775985717773
train-epoch-step: 56-170 -- Loss: 0.19260920584201813
train-epoch-step: 56-171 -- Loss: 0.13860246539115906
train-epoch-step: 56-172 -- Loss: 0.24967309832572937
train-epoch-step: 56-173 -- Loss: 0.1245485246181488
train-epoch-step: 56-174 -- Loss: 0.2445334941148758
train-epoch-step: 56-175 -- Loss: 0.1826101541519165
train-epoch-step: 56-176 -- Loss: 0.1281190663576126
train-epoch-step: 56-177 -- Loss: 0.17424362897872925
train-epoch-step: 56-178 -- Loss: 0.17323140799999237
train-epoch-step: 56-179 -- Loss: 0.15262041985988617
train-epoch-step: 56-180 -- Loss: 0.14563380181789398
train-epoch-step: 56-181 -- Loss: 0.163845032453537
train-epoch-step: 56-182 -- Loss: 0.17487454414367676
train-epoch-step: 56-183 -- Loss: 0.2726108431816101
train-epoch-step: 56-184 -- Loss: 0.13502620160579681
train-epoch-step: 56-185 -- Loss: 0.14051862061023712
train-epoch-step: 56-186 -- Loss: 0.1879298835992813
train-epoch-step: 56-187 -- Loss: 0.2037111073732376
train-epoch-step: 56-188 -- Loss: 0.16815346479415894
train-epoch-step: 56-189 -- Loss: 0.10170162469148636
train-epoch-step: 56-190 -- Loss: 0.18037138879299164
train-epoch-step: 56-191 -- Loss: 0.16812703013420105
train-epoch-step: 56-192 -- Loss: 0.22357454895973206
train-epoch-step: 56-193 -- Loss: 0.19550448656082153
train-epoch-step: 56-194 -- Loss: 0.18255066871643066
train-epoch-step: 56-195 -- Loss: 0.16202035546302795
train-epoch-step: 56-196 -- Loss: 0.16699613630771637
train-epoch-step: 56-197 -- Loss: 0.12393670529127121
train-epoch-step: 56-198 -- Loss: 0.1257680356502533
train-epoch-step: 56-199 -- Loss: 0.1426149606704712
train-epoch-step: 56-200 -- Loss: 0.12155577540397644
train-epoch-step: 56-201 -- Loss: 0.18664905428886414
train-epoch-step: 56-202 -- Loss: 0.1344439834356308
train-epoch-step: 56-203 -- Loss: 0.16749034821987152
train-epoch-step: 56-204 -- Loss: 0.1334950029850006
train-epoch-step: 56-205 -- Loss: 0.17857575416564941
train-epoch-step: 56-206 -- Loss: 0.1979888379573822
train-epoch-step: 56-207 -- Loss: 0.12853923439979553
train-epoch-step: 56-208 -- Loss: 0.1722862869501114
train-epoch-step: 56-209 -- Loss: 0.14108386635780334
train-epoch-step: 56-210 -- Loss: 0.13037435710430145
train-epoch-step: 56-211 -- Loss: 0.20012438297271729
train-epoch-step: 56-212 -- Loss: 0.19133861362934113
train-epoch-step: 56-213 -- Loss: 0.12706485390663147
train-epoch-step: 56-214 -- Loss: 0.14966128766536713
train-epoch-step: 56-215 -- Loss: 0.12582509219646454
train-epoch-step: 56-216 -- Loss: 0.20364004373550415
train-epoch-step: 56-217 -- Loss: 0.20718586444854736
train-epoch-step: 56-218 -- Loss: 0.13717682659626007
train-epoch-step: 56-219 -- Loss: 0.16458971798419952
train-epoch-step: 56-220 -- Loss: 0.12845586240291595
train-epoch-step: 56-221 -- Loss: 0.2015533149242401
train-epoch-step: 56-222 -- Loss: 0.11696845293045044
train-epoch-step: 56-223 -- Loss: 0.1729246824979782
train-epoch-step: 56-224 -- Loss: 0.18796131014823914
train-epoch-step: 56-225 -- Loss: 0.2589297890663147
train-epoch-step: 56-226 -- Loss: 0.20610103011131287
train-epoch-step: 56-227 -- Loss: 0.21282349526882172
train-epoch-step: 56-228 -- Loss: 0.17233708500862122
train-epoch-step: 56-229 -- Loss: 0.1673133820295334
train-epoch-step: 56-230 -- Loss: 0.15974968671798706
train-epoch-step: 56-231 -- Loss: 0.14946293830871582
train-epoch-step: 56-232 -- Loss: 0.17985829710960388
train-epoch-step: 56-233 -- Loss: 0.08253058046102524
train-epoch-step: 56-234 -- Loss: 0.1722114533185959
train-epoch-step: 56-235 -- Loss: 0.14158537983894348
train-epoch-step: 56-236 -- Loss: 0.17714367806911469
train-epoch-step: 56-237 -- Loss: 0.22681103646755219
train-epoch-step: 56-238 -- Loss: 0.15312109887599945
train-epoch-step: 56-239 -- Loss: 0.1253053843975067
train-epoch-step: 56-240 -- Loss: 0.2137739211320877
train-epoch-step: 56-241 -- Loss: 0.1543084681034088
train-epoch-step: 56-242 -- Loss: 0.21337994933128357
train-epoch-step: 56-243 -- Loss: 0.22786560654640198
train-epoch-step: 56-244 -- Loss: 0.20130683481693268
train-epoch-step: 56-245 -- Loss: 0.19877073168754578
train-epoch-step: 56-246 -- Loss: 0.21691547334194183
train-epoch-step: 56-247 -- Loss: 0.19936323165893555
train-epoch-step: 56-248 -- Loss: 0.18470817804336548
train-epoch-step: 56-249 -- Loss: 0.13364309072494507
train-epoch-step: 56-250 -- Loss: 0.19628296792507172
train-epoch-step: 56-251 -- Loss: 0.10456915944814682
train-epoch-step: 56-252 -- Loss: 0.18629589676856995
train-epoch-step: 56-253 -- Loss: 0.13558293879032135
train-epoch-step: 56-254 -- Loss: 0.2084103226661682
train-epoch-step: 56-255 -- Loss: 0.143342986702919
train-epoch-step: 56-256 -- Loss: 0.14366717636585236
train-epoch-step: 56-257 -- Loss: 0.18179821968078613
train-epoch-step: 56-258 -- Loss: 0.14232811331748962
train-epoch-step: 56-259 -- Loss: 0.11002014577388763
train-epoch-step: 56-260 -- Loss: 0.195601686835289
train-epoch-step: 56-261 -- Loss: 0.16795481741428375
train-epoch-step: 56-262 -- Loss: 0.28080785274505615
train-epoch-step: 56-263 -- Loss: 0.1966536045074463
train-epoch-step: 56-264 -- Loss: 0.17237699031829834
train-epoch-step: 56-265 -- Loss: 0.1040974110364914
train-epoch-step: 56-266 -- Loss: 0.15084701776504517
train-epoch-step: 56-267 -- Loss: 0.12458090484142303
train-epoch-step: 56-268 -- Loss: 0.11433692276477814
train-epoch-step: 56-269 -- Loss: 0.1692160964012146
train-epoch-step: 56-270 -- Loss: 0.10402858257293701
train-epoch-step: 56-271 -- Loss: 0.14188013970851898
train-epoch-step: 56-272 -- Loss: 0.11177363991737366
train-epoch-step: 56-273 -- Loss: 0.12447243183851242
train-epoch-step: 56-274 -- Loss: 0.17866718769073486
train-epoch-step: 56-275 -- Loss: 0.19431766867637634
train-epoch-step: 56-276 -- Loss: 0.15093635022640228
train-epoch-step: 56-277 -- Loss: 0.15292149782180786
train-epoch-step: 56-278 -- Loss: 0.13301576673984528
train-epoch-step: 56-279 -- Loss: 0.13696321845054626
train-epoch-step: 56-280 -- Loss: 0.2071365863084793
train-epoch-step: 56-281 -- Loss: 0.1720462441444397
train-epoch-step: 56-282 -- Loss: 0.1417413055896759
train-epoch-step: 56-283 -- Loss: 0.11248187720775604
train-epoch-step: 56-284 -- Loss: 0.1271527260541916
train-epoch-step: 56-285 -- Loss: 0.1831916719675064
train-epoch-step: 56-286 -- Loss: 0.14993253350257874
train-epoch-step: 56-287 -- Loss: 0.19680991768836975
train-epoch-step: 56-288 -- Loss: 0.09260877221822739
train-epoch-step: 56-289 -- Loss: 0.11826780438423157
train-epoch-step: 56-290 -- Loss: 0.17252866923809052
train-epoch-step: 56-291 -- Loss: 0.1137276291847229
train-epoch-step: 56-292 -- Loss: 0.14975818991661072
train-epoch-step: 56-293 -- Loss: 0.13372139632701874
train-epoch-step: 56-294 -- Loss: 0.1585465967655182
train-epoch-step: 56-295 -- Loss: 0.26410287618637085
train-epoch-step: 56-296 -- Loss: 0.15439806878566742
train-epoch-step: 56-297 -- Loss: 0.1683899462223053
train-epoch-step: 56-298 -- Loss: 0.22201597690582275
train-epoch-step: 56-299 -- Loss: 0.14437535405158997
train-epoch-step: 56-300 -- Loss: 0.15934984385967255
train-epoch-step: 56-301 -- Loss: 0.16953209042549133
train-epoch-step: 56-302 -- Loss: 0.21267308294773102
train-epoch-step: 56-303 -- Loss: 0.20054645836353302
train-epoch-step: 56-304 -- Loss: 0.12089169025421143
train-epoch-step: 56-305 -- Loss: 0.13906949758529663
train-epoch-step: 56-306 -- Loss: 0.20335382223129272
train-epoch-step: 56-307 -- Loss: 0.16068784892559052
train-epoch-step: 56-308 -- Loss: 0.20957624912261963
train-epoch-step: 56-309 -- Loss: 0.14988428354263306
train-epoch-step: 56-310 -- Loss: 0.16051197052001953
train-epoch-step: 56-311 -- Loss: 0.15394262969493866
train-epoch-step: 56-312 -- Loss: 0.20185256004333496
train-epoch-step: 56-313 -- Loss: 0.09547532349824905
train-epoch-step: 56-314 -- Loss: 0.1875278204679489
train-epoch-step: 56-315 -- Loss: 0.16605253517627716
train-epoch-step: 56-316 -- Loss: 0.15281511843204498
train-epoch-step: 56-317 -- Loss: 0.1356610655784607
train-epoch-step: 56-318 -- Loss: 0.16305851936340332
train-epoch-step: 56-319 -- Loss: 0.1656547486782074
train-epoch-step: 56-320 -- Loss: 0.11763103306293488
train-epoch-step: 56-321 -- Loss: 0.12924186885356903
train-epoch-step: 56-322 -- Loss: 0.20953968167304993
train-epoch-step: 56-323 -- Loss: 0.1576380431652069
train-epoch-step: 56-324 -- Loss: 0.24944312870502472
train-epoch-step: 56-325 -- Loss: 0.1499759405851364
train-epoch-step: 56-326 -- Loss: 0.16781455278396606
train-epoch-step: 56-327 -- Loss: 0.1945708692073822
train-epoch-step: 56-328 -- Loss: 0.1855415403842926
train-epoch-step: 56-329 -- Loss: 0.3372935652732849
train-epoch-step: 56-330 -- Loss: 0.34860658645629883
train-epoch-step: 56-331 -- Loss: 0.20234562456607819
train-epoch-step: 56-332 -- Loss: 0.09693125635385513
train-epoch-step: 56-333 -- Loss: 0.18098212778568268
train-epoch-step: 56-334 -- Loss: 0.15117858350276947
train-epoch-step: 56-335 -- Loss: 0.16947788000106812
train-epoch-step: 56-336 -- Loss: 0.14331242442131042
train-epoch-step: 56-337 -- Loss: 0.2101384848356247
train-epoch-step: 56-338 -- Loss: 0.15458615124225616
train-epoch-step: 56-339 -- Loss: 0.13801716268062592
train-epoch-step: 56-340 -- Loss: 0.19411109387874603
train-epoch-step: 56-341 -- Loss: 0.13615642488002777
train-epoch-step: 56-342 -- Loss: 0.16229966282844543
train-epoch-step: 56-343 -- Loss: 0.15037274360656738
train-epoch-step: 56-344 -- Loss: 0.16285185515880585
train-epoch-step: 56-345 -- Loss: 0.1393018215894699
train-epoch-step: 56-346 -- Loss: 0.1909283548593521
train-epoch-step: 56-347 -- Loss: 0.14533132314682007
train-epoch-step: 56-348 -- Loss: 0.20149949193000793
train-epoch-step: 56-349 -- Loss: 0.1929323822259903
train-epoch-step: 56-350 -- Loss: 0.24699094891548157
train-epoch-step: 56-351 -- Loss: 0.18786904215812683
train-epoch-step: 56-352 -- Loss: 0.12828300893306732
train-epoch-step: 56-353 -- Loss: 0.18871545791625977
train-epoch-step: 56-354 -- Loss: 0.2766987085342407
train-epoch-step: 56-355 -- Loss: 0.11278426647186279
train-epoch-step: 56-356 -- Loss: 0.11728043109178543
train-epoch-step: 56-357 -- Loss: 0.18254660069942474
train-epoch-step: 56-358 -- Loss: 0.17979063093662262
train-epoch-step: 56-359 -- Loss: 0.13752701878547668
train-epoch-step: 56-360 -- Loss: 0.1220589205622673
train-epoch-step: 56-361 -- Loss: 0.23338934779167175
train-epoch-step: 56-362 -- Loss: 0.16340221464633942
train-epoch-step: 56-363 -- Loss: 0.10618127137422562
train-epoch-step: 56-364 -- Loss: 0.1735243797302246
train-epoch-step: 56-365 -- Loss: 0.168188214302063
train-epoch-step: 56-366 -- Loss: 0.1937469244003296
train-epoch-step: 56-367 -- Loss: 0.22461725771427155
train-epoch-step: 56-368 -- Loss: 0.18907016515731812
train-epoch-step: 56-369 -- Loss: 0.27024662494659424
train-epoch-step: 56-370 -- Loss: 0.12235169857740402
train-epoch-step: 56-371 -- Loss: 0.11951729655265808
train-epoch-step: 56-372 -- Loss: 0.14404870569705963
train-epoch-step: 56-373 -- Loss: 0.18006503582000732
train-epoch-step: 56-374 -- Loss: 0.1501142978668213
train-epoch-step: 56-375 -- Loss: 0.2580946981906891
train-epoch-step: 56-376 -- Loss: 0.15173543989658356
train-epoch-step: 56-377 -- Loss: 0.220302015542984
train-epoch-step: 56-378 -- Loss: 0.192715123295784
train-epoch-step: 56-379 -- Loss: 0.11522224545478821
train-epoch-step: 56-380 -- Loss: 0.0883476734161377
train-epoch-step: 56-381 -- Loss: 0.23544256389141083
train-epoch-step: 56-382 -- Loss: 0.22176481783390045
train-epoch-step: 56-383 -- Loss: 0.17096751928329468
train-epoch-step: 56-384 -- Loss: 0.2182033807039261
train-epoch-step: 56-385 -- Loss: 0.18281053006649017
train-epoch-step: 56-386 -- Loss: 0.18102145195007324
train-epoch-step: 56-387 -- Loss: 0.19850212335586548
train-epoch-step: 56-388 -- Loss: 0.17639893293380737
train-epoch-step: 56-389 -- Loss: 0.16251860558986664
train-epoch-step: 56-390 -- Loss: 0.14595334231853485
train-epoch-step: 56-391 -- Loss: 0.14533564448356628
train-epoch-step: 56-392 -- Loss: 0.18168634176254272
train-epoch-step: 56-393 -- Loss: 0.15011869370937347
train-epoch-step: 56-394 -- Loss: 0.18995782732963562
train-epoch-step: 56-395 -- Loss: 0.15221649408340454
train-epoch-step: 56-396 -- Loss: 0.12109416723251343
train-epoch-step: 56-397 -- Loss: 0.12174470722675323
train-epoch-step: 56-398 -- Loss: 0.19084930419921875
train-epoch-step: 56-399 -- Loss: 0.17432951927185059
train-epoch-step: 56-400 -- Loss: 0.26557689905166626
train-epoch-step: 56-401 -- Loss: 0.1171477884054184
train-epoch-step: 56-402 -- Loss: 0.2464541345834732
train-epoch-step: 56-403 -- Loss: 0.1620735377073288
train-epoch-step: 56-404 -- Loss: 0.1355438530445099
train-epoch-step: 56-405 -- Loss: 0.14326608180999756
train-epoch-step: 56-406 -- Loss: 0.16135618090629578
train-epoch-step: 56-407 -- Loss: 0.1111878976225853
train-epoch-step: 56-408 -- Loss: 0.157579243183136
train-epoch-step: 56-409 -- Loss: 0.16681745648384094
train-epoch-step: 56-410 -- Loss: 0.17568862438201904
train-epoch-step: 56-411 -- Loss: 0.20045796036720276
train-epoch-step: 56-412 -- Loss: 0.1289631426334381
train-epoch-step: 56-413 -- Loss: 0.1452452391386032
train-epoch-step: 56-414 -- Loss: 0.13089019060134888
train-epoch-step: 56-415 -- Loss: 0.12983764708042145
train-epoch-step: 56-416 -- Loss: 0.2558477520942688
train-epoch-step: 56-417 -- Loss: 0.1833343505859375
train-epoch-step: 56-418 -- Loss: 0.2206052541732788
train-epoch-step: 56-419 -- Loss: 0.1641249656677246
train-epoch-step: 56-420 -- Loss: 0.15026505291461945
train-epoch-step: 56-421 -- Loss: 0.17294727265834808
train-epoch-step: 56-422 -- Loss: 0.14767302572727203
train-epoch-step: 56-423 -- Loss: 0.1706574261188507
train-epoch-step: 56-424 -- Loss: 0.13417084515094757
train-epoch-step: 56-425 -- Loss: 0.17734463512897491
train-epoch-step: 56-426 -- Loss: 0.16752871870994568
train-epoch-step: 56-427 -- Loss: 0.11764084547758102
train-epoch-step: 56-428 -- Loss: 0.1896299421787262
train-epoch-step: 56-429 -- Loss: 0.17692184448242188
train-epoch-step: 56-430 -- Loss: 0.1351603865623474
train-epoch-step: 56-431 -- Loss: 0.1563391387462616
train-epoch-step: 56-432 -- Loss: 0.23171810805797577
train-epoch-step: 56-433 -- Loss: 0.13190136849880219
train-epoch-step: 56-434 -- Loss: 0.12903372943401337
train-epoch-step: 56-435 -- Loss: 0.1732693761587143
train-epoch-step: 56-436 -- Loss: 0.14764948189258575
train-epoch-step: 56-437 -- Loss: 0.12967394292354584
train-epoch-step: 56-438 -- Loss: 0.1693502813577652
train-epoch-step: 56-439 -- Loss: 0.26862049102783203
train-epoch-step: 56-440 -- Loss: 0.13051652908325195
train-epoch-step: 56-441 -- Loss: 0.19583357870578766
train-epoch-step: 56-442 -- Loss: 0.17440971732139587
train-epoch-step: 56-443 -- Loss: 0.1452808976173401
train-epoch-step: 56-444 -- Loss: 0.1717074066400528
train-epoch-step: 56-445 -- Loss: 0.17034432291984558
train-epoch-step: 56-446 -- Loss: 0.14923569560050964
train-epoch-step: 56-447 -- Loss: 0.18968890607357025
train-epoch-step: 56-448 -- Loss: 0.21987290680408478
train-epoch-step: 56-449 -- Loss: 0.18466803431510925
train-epoch-step: 56-450 -- Loss: 0.17548099160194397
train-epoch-step: 56-451 -- Loss: 0.13905923068523407
train-epoch-step: 56-452 -- Loss: 0.124742291867733
train-epoch-step: 56-453 -- Loss: 0.08924636244773865
train-epoch-step: 56-454 -- Loss: 0.23357133567333221
train-epoch-step: 56-455 -- Loss: 0.11998049914836884
train-epoch-step: 56-456 -- Loss: 0.11784709990024567
train-epoch-step: 56-457 -- Loss: 0.20810295641422272
train-epoch-step: 56-458 -- Loss: 0.13864213228225708
train-epoch-step: 56-459 -- Loss: 0.21061335504055023
train-epoch-step: 56-460 -- Loss: 0.12827283143997192
train-epoch-step: 56-461 -- Loss: 0.12998679280281067
train-epoch-step: 56-462 -- Loss: 0.15427899360656738
train-epoch-step: 56-463 -- Loss: 0.1333717256784439
train-epoch-step: 56-464 -- Loss: 0.15734891593456268
train-epoch-step: 56-465 -- Loss: 0.23381386697292328
train-epoch-step: 56-466 -- Loss: 0.19850879907608032
train-epoch-step: 56-467 -- Loss: 0.11117518693208694
train-epoch-step: 56-468 -- Loss: 0.16410090029239655
train-epoch-step: 56-469 -- Loss: 0.1991698443889618
train-epoch-step: 56-470 -- Loss: 0.16237932443618774
train-epoch-step: 56-471 -- Loss: 0.15184059739112854
train-epoch-step: 56-472 -- Loss: 0.15437543392181396
train-epoch-step: 56-473 -- Loss: 0.14838597178459167
train-epoch-step: 56-474 -- Loss: 0.11467548459768295
train-epoch-step: 56-475 -- Loss: 0.10386797785758972
train-epoch-step: 56-476 -- Loss: 0.1949220895767212
train-epoch-step: 56-477 -- Loss: 0.19676654040813446
train-epoch-step: 56-478 -- Loss: 0.18200194835662842
train-epoch-step: 56-479 -- Loss: 0.14166662096977234
train-epoch-step: 56-480 -- Loss: 0.18810567259788513
train-epoch-step: 56-481 -- Loss: 0.27970606088638306
train-epoch-step: 56-482 -- Loss: 0.24186596274375916
train-epoch-step: 56-483 -- Loss: 0.1765919327735901
train-epoch-step: 56-484 -- Loss: 0.20154327154159546
train-epoch-step: 56-485 -- Loss: 0.118827223777771
train-epoch-step: 56-486 -- Loss: 0.22646814584732056
train-epoch-step: 56-487 -- Loss: 0.22655868530273438
train-epoch-step: 56-488 -- Loss: 0.17605000734329224
train-epoch-step: 56-489 -- Loss: 0.21548399329185486
train-epoch-step: 56-490 -- Loss: 0.13621222972869873
train-epoch-step: 56-491 -- Loss: 0.13087552785873413
train-epoch-step: 56-492 -- Loss: 0.12433099746704102
train-epoch-step: 56-493 -- Loss: 0.20241233706474304
train-epoch-step: 56-494 -- Loss: 0.19385620951652527
train-epoch-step: 56-495 -- Loss: 0.20071463286876678
train-epoch-step: 56-496 -- Loss: 0.14094536006450653
train-epoch-step: 56-497 -- Loss: 0.17623001337051392
train-epoch-step: 56-498 -- Loss: 0.14079022407531738
train-epoch-step: 56-499 -- Loss: 0.16144345700740814
train-epoch-step: 56-500 -- Loss: 0.15381737053394318
train-epoch-step: 56-501 -- Loss: 0.204454243183136
train-epoch-step: 56-502 -- Loss: 0.15428853034973145
train-epoch-step: 56-503 -- Loss: 0.2104235738515854
train-epoch-step: 56-504 -- Loss: 0.11706867814064026
train-epoch-step: 56-505 -- Loss: 0.16555407643318176
train-epoch-step: 56-506 -- Loss: 0.112205371260643
train-epoch-step: 56-507 -- Loss: 0.17245596647262573
train-epoch-step: 56-508 -- Loss: 0.16685393452644348
train-epoch-step: 56-509 -- Loss: 0.16722840070724487
train-epoch-step: 56-510 -- Loss: 0.12360002845525742
train-epoch-step: 56-511 -- Loss: 0.20878556370735168
train-epoch-step: 56-512 -- Loss: 0.17006181180477142
train-epoch-step: 56-513 -- Loss: 0.18528442084789276
train-epoch-step: 56-514 -- Loss: 0.1401113122701645
train-epoch-step: 56-515 -- Loss: 0.14856642484664917
train-epoch-step: 56-516 -- Loss: 0.1662646234035492
train-epoch-step: 56-517 -- Loss: 0.16831479966640472
train-epoch-step: 56-518 -- Loss: 0.13296040892601013
train-epoch-step: 56-519 -- Loss: 0.13149398565292358
train-epoch-step: 56-520 -- Loss: 0.1812233030796051
train-epoch-step: 56-521 -- Loss: 0.22107669711112976
train-epoch-step: 56-522 -- Loss: 0.17090490460395813
train-epoch-step: 56-523 -- Loss: 0.1551062911748886
train-epoch-step: 56-524 -- Loss: 0.16267366707324982
train-epoch-step: 56-525 -- Loss: 0.1858806610107422
train-epoch-step: 56-526 -- Loss: 0.1268957406282425
train-epoch-step: 56-527 -- Loss: 0.1435030996799469
train-epoch-step: 56-528 -- Loss: 0.15286417305469513
train-epoch-step: 56-529 -- Loss: 0.14911380410194397
train-epoch-step: 56-530 -- Loss: 0.16535641252994537
train-epoch-step: 56-531 -- Loss: 0.1915595531463623
train-epoch-step: 56-532 -- Loss: 0.16251370310783386
train-epoch-step: 56-533 -- Loss: 0.1683785617351532
train-epoch-step: 56-534 -- Loss: 0.12776541709899902
train-epoch-step: 56-535 -- Loss: 0.24081683158874512
train-epoch-step: 56-536 -- Loss: 0.15112346410751343
train-epoch-step: 56-537 -- Loss: 0.1418680101633072
train-epoch-step: 56-538 -- Loss: 0.1036255806684494
train-epoch-step: 56-539 -- Loss: 0.1756649613380432
train-epoch-step: 56-540 -- Loss: 0.13277244567871094
train-epoch-step: 56-541 -- Loss: 0.20007048547267914
train-epoch-step: 56-542 -- Loss: 0.21803346276283264
train-epoch-step: 56-543 -- Loss: 0.17168593406677246
train-epoch-step: 56-544 -- Loss: 0.22590984404087067
train-epoch-step: 56-545 -- Loss: 0.1874440610408783
train-epoch-step: 56-546 -- Loss: 0.20129941403865814
train-epoch-step: 56-547 -- Loss: 0.1746990829706192
train-epoch-step: 56-548 -- Loss: 0.0889490619301796
train-epoch-step: 56-549 -- Loss: 0.14299213886260986
train-epoch-step: 56-550 -- Loss: 0.19918039441108704
train-epoch-step: 56-551 -- Loss: 0.1487828642129898
train-epoch-step: 56-552 -- Loss: 0.1221032589673996
train-epoch-step: 56-553 -- Loss: 0.1830388754606247
train-epoch-step: 56-554 -- Loss: 0.18675291538238525
train-epoch-step: 56-555 -- Loss: 0.21220755577087402
train-epoch-step: 56-556 -- Loss: 0.14162686467170715
train-epoch-step: 56-557 -- Loss: 0.2353869527578354
train-epoch-step: 56-558 -- Loss: 0.22496318817138672
train-epoch-step: 56-559 -- Loss: 0.1318417638540268
train-epoch-step: 56-560 -- Loss: 0.20169112086296082
train-epoch-step: 56-561 -- Loss: 0.1775520145893097
train-epoch-step: 56-562 -- Loss: 0.1558692455291748
train-epoch-step: 56-563 -- Loss: 0.1804122030735016
train-epoch-step: 56-564 -- Loss: 0.09592894464731216
train-epoch-step: 56-565 -- Loss: 0.1806778758764267
train-epoch-step: 56-566 -- Loss: 0.14216500520706177
train-epoch-step: 56-567 -- Loss: 0.20551007986068726
train-epoch-step: 56-568 -- Loss: 0.15177348256111145
train-epoch-step: 56-569 -- Loss: 0.23586788773536682
train-epoch-step: 56-570 -- Loss: 0.1603061556816101
train-epoch-step: 56-571 -- Loss: 0.20438605546951294
train-epoch-step: 56-572 -- Loss: 0.23136577010154724
train-epoch-step: 56-573 -- Loss: 0.19528968632221222
train-epoch-step: 56-574 -- Loss: 0.23484370112419128
train-epoch-step: 56-575 -- Loss: 0.28801125288009644
train-epoch-step: 56-576 -- Loss: 0.11519648134708405
train-epoch-step: 56-577 -- Loss: 0.15873493254184723
train-epoch-step: 56-578 -- Loss: 0.21251264214515686
train-epoch-step: 56-579 -- Loss: 0.17571094632148743
train-epoch-step: 56-580 -- Loss: 0.17054498195648193
train-epoch-step: 56-581 -- Loss: 0.1322127878665924
train-epoch-step: 56-582 -- Loss: 0.1991254985332489
train-epoch-step: 56-583 -- Loss: 0.20497499406337738
train-epoch-step: 56-584 -- Loss: 0.15639516711235046
train-epoch-step: 56-585 -- Loss: 0.19170916080474854
train-epoch-step: 56-586 -- Loss: 0.24693197011947632
train-epoch-step: 56-587 -- Loss: 0.1586364358663559
train-epoch-step: 56-588 -- Loss: 0.12359167635440826
val-epoch-step: 56-589 -- Loss: 0.19417181611061096
val-epoch-step: 56-590 -- Loss: 0.1506800502538681
val-epoch-step: 56-591 -- Loss: 0.21980082988739014
val-epoch-step: 56-592 -- Loss: 0.17058619856834412
val-epoch-step: 56-593 -- Loss: 0.16139313578605652
val-epoch-step: 56-594 -- Loss: 0.4141337275505066
val-epoch-step: 56-595 -- Loss: 0.18654073774814606
val-epoch-step: 56-596 -- Loss: 0.1882036030292511
val-epoch-step: 56-597 -- Loss: 0.17165589332580566
val-epoch-step: 56-598 -- Loss: 0.14575821161270142
val-epoch-step: 56-599 -- Loss: 0.18283231556415558
val-epoch-step: 56-600 -- Loss: 0.2398315668106079
val-epoch-step: 56-601 -- Loss: 0.15361030399799347
val-epoch-step: 56-602 -- Loss: 0.1345445066690445
val-epoch-step: 56-603 -- Loss: 0.19002333283424377
val-epoch-step: 56-604 -- Loss: 0.14347368478775024
val-epoch-step: 56-605 -- Loss: 0.1500726044178009
val-epoch-step: 56-606 -- Loss: 0.287906289100647
val-epoch-step: 56-607 -- Loss: 0.12277159094810486
val-epoch-step: 56-608 -- Loss: 0.24118122458457947
val-epoch-step: 56-609 -- Loss: 0.16130614280700684
val-epoch-step: 56-610 -- Loss: 0.17658200860023499
val-epoch-step: 56-611 -- Loss: 0.1655585616827011
val-epoch-step: 56-612 -- Loss: 0.5108851790428162
val-epoch-step: 56-613 -- Loss: 0.16873252391815186
val-epoch-step: 56-614 -- Loss: 0.1799929440021515
val-epoch-step: 56-615 -- Loss: 0.17285819351673126
val-epoch-step: 56-616 -- Loss: 0.13957859575748444
val-epoch-step: 56-617 -- Loss: 0.18633094429969788
val-epoch-step: 56-618 -- Loss: 0.17857478559017181
val-epoch-step: 56-619 -- Loss: 0.2024870216846466
val-epoch-step: 56-620 -- Loss: 0.1359291672706604
val-epoch-step: 56-621 -- Loss: 0.12526820600032806
val-epoch-step: 56-622 -- Loss: 0.1429569274187088
val-epoch-step: 56-623 -- Loss: 0.14606213569641113
val-epoch-step: 56-624 -- Loss: 0.14048591256141663
val-epoch-step: 56-625 -- Loss: 0.1511119157075882
val-epoch-step: 56-626 -- Loss: 0.14478440582752228
val-epoch-step: 56-627 -- Loss: 0.17723716795444489
val-epoch-step: 56-628 -- Loss: 0.726544976234436
val-epoch-step: 56-629 -- Loss: 0.19749514758586884
val-epoch-step: 56-630 -- Loss: 0.34059566259384155
val-epoch-step: 56-631 -- Loss: 0.1461910605430603
val-epoch-step: 56-632 -- Loss: 0.2109709233045578
val-epoch-step: 56-633 -- Loss: 0.1484324187040329
val-epoch-step: 56-634 -- Loss: 0.15134137868881226
val-epoch-step: 56-635 -- Loss: 0.11224573105573654
val-epoch-step: 56-636 -- Loss: 0.16474011540412903
val-epoch-step: 56-637 -- Loss: 0.17964667081832886
val-epoch-step: 56-638 -- Loss: 0.14650848507881165
val-epoch-step: 56-639 -- Loss: 0.2642006278038025
val-epoch-step: 56-640 -- Loss: 0.24282139539718628
val-epoch-step: 56-641 -- Loss: 0.1349315345287323
val-epoch-step: 56-642 -- Loss: 0.20261156558990479
val-epoch-step: 56-643 -- Loss: 0.20280690491199493
val-epoch-step: 56-644 -- Loss: 0.16778366267681122
val-epoch-step: 56-645 -- Loss: 0.217201828956604
val-epoch-step: 56-646 -- Loss: 0.13992179930210114
val-epoch-step: 56-647 -- Loss: 0.13085997104644775
val-epoch-step: 56-648 -- Loss: 0.15007580816745758
val-epoch-step: 56-649 -- Loss: 0.20686030387878418
val-epoch-step: 56-650 -- Loss: 0.24402910470962524
val-epoch-step: 56-651 -- Loss: 0.14032214879989624
val-epoch-step: 56-652 -- Loss: 0.15164174139499664
val-epoch-step: 56-653 -- Loss: 0.19075892865657806
val-epoch-step: 56-654 -- Loss: 0.12090612202882767
Epoch: 56 -- Train Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 57-0 -- Loss: 0.22363384068012238
train-epoch-step: 57-1 -- Loss: 0.13850010931491852
train-epoch-step: 57-2 -- Loss: 0.19462516903877258
train-epoch-step: 57-3 -- Loss: 0.1467784196138382
train-epoch-step: 57-4 -- Loss: 0.15463100373744965
train-epoch-step: 57-5 -- Loss: 0.17333513498306274
train-epoch-step: 57-6 -- Loss: 0.2119968682527542
train-epoch-step: 57-7 -- Loss: 0.16442905366420746
train-epoch-step: 57-8 -- Loss: 0.17488041520118713
train-epoch-step: 57-9 -- Loss: 0.26639246940612793
train-epoch-step: 57-10 -- Loss: 0.19169315695762634
train-epoch-step: 57-11 -- Loss: 0.16961659491062164
train-epoch-step: 57-12 -- Loss: 0.14419661462306976
train-epoch-step: 57-13 -- Loss: 0.18197694420814514
train-epoch-step: 57-14 -- Loss: 0.16833500564098358
train-epoch-step: 57-15 -- Loss: 0.15662412345409393
train-epoch-step: 57-16 -- Loss: 0.15987634658813477
train-epoch-step: 57-17 -- Loss: 0.20882365107536316
train-epoch-step: 57-18 -- Loss: 0.1913089156150818
train-epoch-step: 57-19 -- Loss: 0.12892331182956696
train-epoch-step: 57-20 -- Loss: 0.20669375360012054
train-epoch-step: 57-21 -- Loss: 0.24439282715320587
train-epoch-step: 57-22 -- Loss: 0.13379868865013123
train-epoch-step: 57-23 -- Loss: 0.1388453245162964
train-epoch-step: 57-24 -- Loss: 0.12396533042192459
train-epoch-step: 57-25 -- Loss: 0.22090135514736176
train-epoch-step: 57-26 -- Loss: 0.18725983798503876
train-epoch-step: 57-27 -- Loss: 0.2222951054573059
train-epoch-step: 57-28 -- Loss: 0.12231171876192093
train-epoch-step: 57-29 -- Loss: 0.2382247895002365
train-epoch-step: 57-30 -- Loss: 0.1050879955291748
train-epoch-step: 57-31 -- Loss: 0.13335634768009186
train-epoch-step: 57-32 -- Loss: 0.17089350521564484
train-epoch-step: 57-33 -- Loss: 0.2644105553627014
train-epoch-step: 57-34 -- Loss: 0.161492720246315
train-epoch-step: 57-35 -- Loss: 0.2331935167312622
train-epoch-step: 57-36 -- Loss: 0.13665905594825745
train-epoch-step: 57-37 -- Loss: 0.13499592244625092
train-epoch-step: 57-38 -- Loss: 0.16927894949913025
train-epoch-step: 57-39 -- Loss: 0.20988453924655914
train-epoch-step: 57-40 -- Loss: 0.18765029311180115
train-epoch-step: 57-41 -- Loss: 0.2070111334323883
train-epoch-step: 57-42 -- Loss: 0.14740337431430817
train-epoch-step: 57-43 -- Loss: 0.2577262222766876
train-epoch-step: 57-44 -- Loss: 0.12220610678195953
train-epoch-step: 57-45 -- Loss: 0.10899597406387329
train-epoch-step: 57-46 -- Loss: 0.15940751135349274
train-epoch-step: 57-47 -- Loss: 0.20892809331417084
train-epoch-step: 57-48 -- Loss: 0.15260431170463562
train-epoch-step: 57-49 -- Loss: 0.22491832077503204
train-epoch-step: 57-50 -- Loss: 0.10837235301733017
train-epoch-step: 57-51 -- Loss: 0.1692138910293579
train-epoch-step: 57-52 -- Loss: 0.15845702588558197
train-epoch-step: 57-53 -- Loss: 0.20117557048797607
train-epoch-step: 57-54 -- Loss: 0.2804800570011139
train-epoch-step: 57-55 -- Loss: 0.16519109904766083
train-epoch-step: 57-56 -- Loss: 0.1744222491979599
train-epoch-step: 57-57 -- Loss: 0.22801131010055542
train-epoch-step: 57-58 -- Loss: 0.27185872197151184
train-epoch-step: 57-59 -- Loss: 0.23085221648216248
train-epoch-step: 57-60 -- Loss: 0.12547147274017334
train-epoch-step: 57-61 -- Loss: 0.1963016390800476
train-epoch-step: 57-62 -- Loss: 0.18039633333683014
train-epoch-step: 57-63 -- Loss: 0.136440247297287
train-epoch-step: 57-64 -- Loss: 0.14073696732521057
train-epoch-step: 57-65 -- Loss: 0.17498944699764252
train-epoch-step: 57-66 -- Loss: 0.10880114883184433
train-epoch-step: 57-67 -- Loss: 0.1233154833316803
train-epoch-step: 57-68 -- Loss: 0.21060720086097717
train-epoch-step: 57-69 -- Loss: 0.11747841536998749
train-epoch-step: 57-70 -- Loss: 0.22282880544662476
train-epoch-step: 57-71 -- Loss: 0.251998633146286
train-epoch-step: 57-72 -- Loss: 0.16685432195663452
train-epoch-step: 57-73 -- Loss: 0.20071789622306824
train-epoch-step: 57-74 -- Loss: 0.09394513070583344
train-epoch-step: 57-75 -- Loss: 0.1260993480682373
train-epoch-step: 57-76 -- Loss: 0.14747996628284454
train-epoch-step: 57-77 -- Loss: 0.22645756602287292
train-epoch-step: 57-78 -- Loss: 0.25526073575019836
train-epoch-step: 57-79 -- Loss: 0.18504869937896729
train-epoch-step: 57-80 -- Loss: 0.2384006530046463
train-epoch-step: 57-81 -- Loss: 0.12327000498771667
train-epoch-step: 57-82 -- Loss: 0.24432119727134705
train-epoch-step: 57-83 -- Loss: 0.17749927937984467
train-epoch-step: 57-84 -- Loss: 0.18255212903022766
train-epoch-step: 57-85 -- Loss: 0.17046411335468292
train-epoch-step: 57-86 -- Loss: 0.11761538684368134
train-epoch-step: 57-87 -- Loss: 0.2008451521396637
train-epoch-step: 57-88 -- Loss: 0.14004257321357727
train-epoch-step: 57-89 -- Loss: 0.18528389930725098
train-epoch-step: 57-90 -- Loss: 0.18722113966941833
train-epoch-step: 57-91 -- Loss: 0.23678530752658844
train-epoch-step: 57-92 -- Loss: 0.15121838450431824
train-epoch-step: 57-93 -- Loss: 0.16765104234218597
train-epoch-step: 57-94 -- Loss: 0.2163877785205841
train-epoch-step: 57-95 -- Loss: 0.18613877892494202
train-epoch-step: 57-96 -- Loss: 0.20870772004127502
train-epoch-step: 57-97 -- Loss: 0.1707957535982132
train-epoch-step: 57-98 -- Loss: 0.1526230275630951
train-epoch-step: 57-99 -- Loss: 0.18179860711097717
train-epoch-step: 57-100 -- Loss: 0.1849672794342041
train-epoch-step: 57-101 -- Loss: 0.25714993476867676
train-epoch-step: 57-102 -- Loss: 0.20977796614170074
train-epoch-step: 57-103 -- Loss: 0.1761540323495865
train-epoch-step: 57-104 -- Loss: 0.14484603703022003
train-epoch-step: 57-105 -- Loss: 0.2630918025970459
train-epoch-step: 57-106 -- Loss: 0.17022472620010376
train-epoch-step: 57-107 -- Loss: 0.18312866985797882
train-epoch-step: 57-108 -- Loss: 0.18086236715316772
train-epoch-step: 57-109 -- Loss: 0.14689278602600098
train-epoch-step: 57-110 -- Loss: 0.17976264655590057
train-epoch-step: 57-111 -- Loss: 0.1749107539653778
train-epoch-step: 57-112 -- Loss: 0.1574711799621582
train-epoch-step: 57-113 -- Loss: 0.15539324283599854
train-epoch-step: 57-114 -- Loss: 0.19583576917648315
train-epoch-step: 57-115 -- Loss: 0.160169318318367
train-epoch-step: 57-116 -- Loss: 0.1329454779624939
train-epoch-step: 57-117 -- Loss: 0.12325280159711838
train-epoch-step: 57-118 -- Loss: 0.1907730996608734
train-epoch-step: 57-119 -- Loss: 0.14681237936019897
train-epoch-step: 57-120 -- Loss: 0.23969833552837372
train-epoch-step: 57-121 -- Loss: 0.22471587359905243
train-epoch-step: 57-122 -- Loss: 0.208118736743927
train-epoch-step: 57-123 -- Loss: 0.199232280254364
train-epoch-step: 57-124 -- Loss: 0.12113623321056366
train-epoch-step: 57-125 -- Loss: 0.14920000731945038
train-epoch-step: 57-126 -- Loss: 0.22966502606868744
train-epoch-step: 57-127 -- Loss: 0.17328542470932007
train-epoch-step: 57-128 -- Loss: 0.16956306993961334
train-epoch-step: 57-129 -- Loss: 0.13801738619804382
train-epoch-step: 57-130 -- Loss: 0.18962597846984863
train-epoch-step: 57-131 -- Loss: 0.13045895099639893
train-epoch-step: 57-132 -- Loss: 0.20474843680858612
train-epoch-step: 57-133 -- Loss: 0.11746099591255188
train-epoch-step: 57-134 -- Loss: 0.19407737255096436
train-epoch-step: 57-135 -- Loss: 0.13127657771110535
train-epoch-step: 57-136 -- Loss: 0.13037998974323273
train-epoch-step: 57-137 -- Loss: 0.23616532981395721
train-epoch-step: 57-138 -- Loss: 0.2529621124267578
train-epoch-step: 57-139 -- Loss: 0.13379889726638794
train-epoch-step: 57-140 -- Loss: 0.20483726263046265
train-epoch-step: 57-141 -- Loss: 0.22136545181274414
train-epoch-step: 57-142 -- Loss: 0.19821670651435852
train-epoch-step: 57-143 -- Loss: 0.16279344260692596
train-epoch-step: 57-144 -- Loss: 0.17892983555793762
train-epoch-step: 57-145 -- Loss: 0.1377730816602707
train-epoch-step: 57-146 -- Loss: 0.1731569766998291
train-epoch-step: 57-147 -- Loss: 0.16577854752540588
train-epoch-step: 57-148 -- Loss: 0.15593495965003967
train-epoch-step: 57-149 -- Loss: 0.11847097426652908
train-epoch-step: 57-150 -- Loss: 0.1802133470773697
train-epoch-step: 57-151 -- Loss: 0.1963176131248474
train-epoch-step: 57-152 -- Loss: 0.18734191358089447
train-epoch-step: 57-153 -- Loss: 0.26852861046791077
train-epoch-step: 57-154 -- Loss: 0.12630748748779297
train-epoch-step: 57-155 -- Loss: 0.13579736649990082
train-epoch-step: 57-156 -- Loss: 0.1161733940243721
train-epoch-step: 57-157 -- Loss: 0.16120897233486176
train-epoch-step: 57-158 -- Loss: 0.1650291383266449
train-epoch-step: 57-159 -- Loss: 0.17463232576847076
train-epoch-step: 57-160 -- Loss: 0.21533505618572235
train-epoch-step: 57-161 -- Loss: 0.20032405853271484
train-epoch-step: 57-162 -- Loss: 0.21144670248031616
train-epoch-step: 57-163 -- Loss: 0.18384912610054016
train-epoch-step: 57-164 -- Loss: 0.18489134311676025
train-epoch-step: 57-165 -- Loss: 0.15798544883728027
train-epoch-step: 57-166 -- Loss: 0.12162738293409348
train-epoch-step: 57-167 -- Loss: 0.12021943926811218
train-epoch-step: 57-168 -- Loss: 0.1978810727596283
train-epoch-step: 57-169 -- Loss: 0.13223905861377716
train-epoch-step: 57-170 -- Loss: 0.194326251745224
train-epoch-step: 57-171 -- Loss: 0.14352716505527496
train-epoch-step: 57-172 -- Loss: 0.2581350803375244
train-epoch-step: 57-173 -- Loss: 0.12447332590818405
train-epoch-step: 57-174 -- Loss: 0.24157947301864624
train-epoch-step: 57-175 -- Loss: 0.1814231276512146
train-epoch-step: 57-176 -- Loss: 0.1309274286031723
train-epoch-step: 57-177 -- Loss: 0.1840832233428955
train-epoch-step: 57-178 -- Loss: 0.1788019984960556
train-epoch-step: 57-179 -- Loss: 0.14274299144744873
train-epoch-step: 57-180 -- Loss: 0.1545208990573883
train-epoch-step: 57-181 -- Loss: 0.16149483621120453
train-epoch-step: 57-182 -- Loss: 0.1810329705476761
train-epoch-step: 57-183 -- Loss: 0.262221097946167
train-epoch-step: 57-184 -- Loss: 0.1360330730676651
train-epoch-step: 57-185 -- Loss: 0.13763926923274994
train-epoch-step: 57-186 -- Loss: 0.18196113407611847
train-epoch-step: 57-187 -- Loss: 0.2080112099647522
train-epoch-step: 57-188 -- Loss: 0.17033834755420685
train-epoch-step: 57-189 -- Loss: 0.10489901900291443
train-epoch-step: 57-190 -- Loss: 0.1740872710943222
train-epoch-step: 57-191 -- Loss: 0.15821605920791626
train-epoch-step: 57-192 -- Loss: 0.2263435572385788
train-epoch-step: 57-193 -- Loss: 0.1982109248638153
train-epoch-step: 57-194 -- Loss: 0.18216858804225922
train-epoch-step: 57-195 -- Loss: 0.16177935898303986
train-epoch-step: 57-196 -- Loss: 0.1629704385995865
train-epoch-step: 57-197 -- Loss: 0.12323752045631409
train-epoch-step: 57-198 -- Loss: 0.12332354485988617
train-epoch-step: 57-199 -- Loss: 0.14050208032131195
train-epoch-step: 57-200 -- Loss: 0.12190327793359756
train-epoch-step: 57-201 -- Loss: 0.20422494411468506
train-epoch-step: 57-202 -- Loss: 0.13506832718849182
train-epoch-step: 57-203 -- Loss: 0.17153653502464294
train-epoch-step: 57-204 -- Loss: 0.13414952158927917
train-epoch-step: 57-205 -- Loss: 0.1788872927427292
train-epoch-step: 57-206 -- Loss: 0.19551648199558258
train-epoch-step: 57-207 -- Loss: 0.12907272577285767
train-epoch-step: 57-208 -- Loss: 0.17745119333267212
train-epoch-step: 57-209 -- Loss: 0.13876038789749146
train-epoch-step: 57-210 -- Loss: 0.13179951906204224
train-epoch-step: 57-211 -- Loss: 0.19992899894714355
train-epoch-step: 57-212 -- Loss: 0.1978617161512375
train-epoch-step: 57-213 -- Loss: 0.12535767257213593
train-epoch-step: 57-214 -- Loss: 0.145830437541008
train-epoch-step: 57-215 -- Loss: 0.12765754759311676
train-epoch-step: 57-216 -- Loss: 0.1995793581008911
train-epoch-step: 57-217 -- Loss: 0.2540684938430786
train-epoch-step: 57-218 -- Loss: 0.1440676897764206
train-epoch-step: 57-219 -- Loss: 0.16355477273464203
train-epoch-step: 57-220 -- Loss: 0.1248854547739029
train-epoch-step: 57-221 -- Loss: 0.1987021267414093
train-epoch-step: 57-222 -- Loss: 0.11248534172773361
train-epoch-step: 57-223 -- Loss: 0.17140065133571625
train-epoch-step: 57-224 -- Loss: 0.1829412281513214
train-epoch-step: 57-225 -- Loss: 0.2609992027282715
train-epoch-step: 57-226 -- Loss: 0.20812349021434784
train-epoch-step: 57-227 -- Loss: 0.22393587231636047
train-epoch-step: 57-228 -- Loss: 0.17228299379348755
train-epoch-step: 57-229 -- Loss: 0.16601333022117615
train-epoch-step: 57-230 -- Loss: 0.1592881828546524
train-epoch-step: 57-231 -- Loss: 0.15351128578186035
train-epoch-step: 57-232 -- Loss: 0.18458743393421173
train-epoch-step: 57-233 -- Loss: 0.08209307491779327
train-epoch-step: 57-234 -- Loss: 0.16893349587917328
train-epoch-step: 57-235 -- Loss: 0.14582620561122894
train-epoch-step: 57-236 -- Loss: 0.1754140853881836
train-epoch-step: 57-237 -- Loss: 0.23341135680675507
train-epoch-step: 57-238 -- Loss: 0.15257477760314941
train-epoch-step: 57-239 -- Loss: 0.12282121181488037
train-epoch-step: 57-240 -- Loss: 0.21629758179187775
train-epoch-step: 57-241 -- Loss: 0.15248094499111176
train-epoch-step: 57-242 -- Loss: 0.21491530537605286
train-epoch-step: 57-243 -- Loss: 0.23003658652305603
train-epoch-step: 57-244 -- Loss: 0.1997319459915161
train-epoch-step: 57-245 -- Loss: 0.2001761943101883
train-epoch-step: 57-246 -- Loss: 0.2269877791404724
train-epoch-step: 57-247 -- Loss: 0.20320148766040802
train-epoch-step: 57-248 -- Loss: 0.18703025579452515
train-epoch-step: 57-249 -- Loss: 0.13681963086128235
train-epoch-step: 57-250 -- Loss: 0.19285373389720917
train-epoch-step: 57-251 -- Loss: 0.1024879664182663
train-epoch-step: 57-252 -- Loss: 0.19686052203178406
train-epoch-step: 57-253 -- Loss: 0.13424521684646606
train-epoch-step: 57-254 -- Loss: 0.20846426486968994
train-epoch-step: 57-255 -- Loss: 0.1437530368566513
train-epoch-step: 57-256 -- Loss: 0.1489020586013794
train-epoch-step: 57-257 -- Loss: 0.1817215383052826
train-epoch-step: 57-258 -- Loss: 0.14145061373710632
train-epoch-step: 57-259 -- Loss: 0.11900758743286133
train-epoch-step: 57-260 -- Loss: 0.1943245828151703
train-epoch-step: 57-261 -- Loss: 0.17553500831127167
train-epoch-step: 57-262 -- Loss: 0.2843340337276459
train-epoch-step: 57-263 -- Loss: 0.19438914954662323
train-epoch-step: 57-264 -- Loss: 0.17080014944076538
train-epoch-step: 57-265 -- Loss: 0.10782280564308167
train-epoch-step: 57-266 -- Loss: 0.1518569141626358
train-epoch-step: 57-267 -- Loss: 0.12535008788108826
train-epoch-step: 57-268 -- Loss: 0.11696335673332214
train-epoch-step: 57-269 -- Loss: 0.16738276183605194
train-epoch-step: 57-270 -- Loss: 0.10417331010103226
train-epoch-step: 57-271 -- Loss: 0.14083440601825714
train-epoch-step: 57-272 -- Loss: 0.1101512610912323
train-epoch-step: 57-273 -- Loss: 0.12166911363601685
train-epoch-step: 57-274 -- Loss: 0.18043994903564453
train-epoch-step: 57-275 -- Loss: 0.2110471874475479
train-epoch-step: 57-276 -- Loss: 0.159318208694458
train-epoch-step: 57-277 -- Loss: 0.15395452082157135
train-epoch-step: 57-278 -- Loss: 0.13430771231651306
train-epoch-step: 57-279 -- Loss: 0.14904476702213287
train-epoch-step: 57-280 -- Loss: 0.21199952065944672
train-epoch-step: 57-281 -- Loss: 0.17229527235031128
train-epoch-step: 57-282 -- Loss: 0.13849365711212158
train-epoch-step: 57-283 -- Loss: 0.11617153882980347
train-epoch-step: 57-284 -- Loss: 0.12996213138103485
train-epoch-step: 57-285 -- Loss: 0.18598799407482147
train-epoch-step: 57-286 -- Loss: 0.14865879714488983
train-epoch-step: 57-287 -- Loss: 0.1991441398859024
train-epoch-step: 57-288 -- Loss: 0.0912061259150505
train-epoch-step: 57-289 -- Loss: 0.11635693162679672
train-epoch-step: 57-290 -- Loss: 0.17788368463516235
train-epoch-step: 57-291 -- Loss: 0.11437734961509705
train-epoch-step: 57-292 -- Loss: 0.15266740322113037
train-epoch-step: 57-293 -- Loss: 0.13407166302204132
train-epoch-step: 57-294 -- Loss: 0.15948395431041718
train-epoch-step: 57-295 -- Loss: 0.26834365725517273
train-epoch-step: 57-296 -- Loss: 0.1568644493818283
train-epoch-step: 57-297 -- Loss: 0.1677825152873993
train-epoch-step: 57-298 -- Loss: 0.22485822439193726
train-epoch-step: 57-299 -- Loss: 0.1408444494009018
train-epoch-step: 57-300 -- Loss: 0.15993234515190125
train-epoch-step: 57-301 -- Loss: 0.17337995767593384
train-epoch-step: 57-302 -- Loss: 0.20750142633914948
train-epoch-step: 57-303 -- Loss: 0.20165309309959412
train-epoch-step: 57-304 -- Loss: 0.1292913407087326
train-epoch-step: 57-305 -- Loss: 0.13933917880058289
train-epoch-step: 57-306 -- Loss: 0.21572621166706085
train-epoch-step: 57-307 -- Loss: 0.16103631258010864
train-epoch-step: 57-308 -- Loss: 0.21397176384925842
train-epoch-step: 57-309 -- Loss: 0.15302500128746033
train-epoch-step: 57-310 -- Loss: 0.15929880738258362
train-epoch-step: 57-311 -- Loss: 0.1533799171447754
train-epoch-step: 57-312 -- Loss: 0.21483950316905975
train-epoch-step: 57-313 -- Loss: 0.09449416399002075
train-epoch-step: 57-314 -- Loss: 0.1858697384595871
train-epoch-step: 57-315 -- Loss: 0.1658654808998108
train-epoch-step: 57-316 -- Loss: 0.1516435444355011
train-epoch-step: 57-317 -- Loss: 0.13516686856746674
train-epoch-step: 57-318 -- Loss: 0.15711230039596558
train-epoch-step: 57-319 -- Loss: 0.1730102300643921
train-epoch-step: 57-320 -- Loss: 0.11620699614286423
train-epoch-step: 57-321 -- Loss: 0.12614034116268158
train-epoch-step: 57-322 -- Loss: 0.2044639140367508
train-epoch-step: 57-323 -- Loss: 0.15941089391708374
train-epoch-step: 57-324 -- Loss: 0.25295761227607727
train-epoch-step: 57-325 -- Loss: 0.15080080926418304
train-epoch-step: 57-326 -- Loss: 0.16791516542434692
train-epoch-step: 57-327 -- Loss: 0.19904397428035736
train-epoch-step: 57-328 -- Loss: 0.18963539600372314
train-epoch-step: 57-329 -- Loss: 0.3334096074104309
train-epoch-step: 57-330 -- Loss: 0.35081639885902405
train-epoch-step: 57-331 -- Loss: 0.20753219723701477
train-epoch-step: 57-332 -- Loss: 0.09812919050455093
train-epoch-step: 57-333 -- Loss: 0.1752214878797531
train-epoch-step: 57-334 -- Loss: 0.15135814249515533
train-epoch-step: 57-335 -- Loss: 0.16780361533164978
train-epoch-step: 57-336 -- Loss: 0.14482836425304413
train-epoch-step: 57-337 -- Loss: 0.1954052895307541
train-epoch-step: 57-338 -- Loss: 0.15650606155395508
train-epoch-step: 57-339 -- Loss: 0.13557730615139008
train-epoch-step: 57-340 -- Loss: 0.19219882786273956
train-epoch-step: 57-341 -- Loss: 0.13827620446681976
train-epoch-step: 57-342 -- Loss: 0.16315212845802307
train-epoch-step: 57-343 -- Loss: 0.14823901653289795
train-epoch-step: 57-344 -- Loss: 0.1596987396478653
train-epoch-step: 57-345 -- Loss: 0.12258708477020264
train-epoch-step: 57-346 -- Loss: 0.19553588330745697
train-epoch-step: 57-347 -- Loss: 0.14676693081855774
train-epoch-step: 57-348 -- Loss: 0.20072227716445923
train-epoch-step: 57-349 -- Loss: 0.1955360770225525
train-epoch-step: 57-350 -- Loss: 0.2464330941438675
train-epoch-step: 57-351 -- Loss: 0.188687264919281
train-epoch-step: 57-352 -- Loss: 0.1167629286646843
train-epoch-step: 57-353 -- Loss: 0.19069580733776093
train-epoch-step: 57-354 -- Loss: 0.2764206528663635
train-epoch-step: 57-355 -- Loss: 0.11425340920686722
train-epoch-step: 57-356 -- Loss: 0.11153779178857803
train-epoch-step: 57-357 -- Loss: 0.18489253520965576
train-epoch-step: 57-358 -- Loss: 0.18309195339679718
train-epoch-step: 57-359 -- Loss: 0.135667085647583
train-epoch-step: 57-360 -- Loss: 0.12150068581104279
train-epoch-step: 57-361 -- Loss: 0.2300470620393753
train-epoch-step: 57-362 -- Loss: 0.16323989629745483
train-epoch-step: 57-363 -- Loss: 0.1083834245800972
train-epoch-step: 57-364 -- Loss: 0.17315346002578735
train-epoch-step: 57-365 -- Loss: 0.16900378465652466
train-epoch-step: 57-366 -- Loss: 0.19364729523658752
train-epoch-step: 57-367 -- Loss: 0.22526304423809052
train-epoch-step: 57-368 -- Loss: 0.19745942950248718
train-epoch-step: 57-369 -- Loss: 0.26737892627716064
train-epoch-step: 57-370 -- Loss: 0.12056393176317215
train-epoch-step: 57-371 -- Loss: 0.11875320971012115
train-epoch-step: 57-372 -- Loss: 0.14460915327072144
train-epoch-step: 57-373 -- Loss: 0.18063968420028687
train-epoch-step: 57-374 -- Loss: 0.14758671820163727
train-epoch-step: 57-375 -- Loss: 0.2647329568862915
train-epoch-step: 57-376 -- Loss: 0.1560972034931183
train-epoch-step: 57-377 -- Loss: 0.21857891976833344
train-epoch-step: 57-378 -- Loss: 0.1918172389268875
train-epoch-step: 57-379 -- Loss: 0.11291765421628952
train-epoch-step: 57-380 -- Loss: 0.08896290510892868
train-epoch-step: 57-381 -- Loss: 0.23826174437999725
train-epoch-step: 57-382 -- Loss: 0.23357081413269043
train-epoch-step: 57-383 -- Loss: 0.16977956891059875
train-epoch-step: 57-384 -- Loss: 0.21725887060165405
train-epoch-step: 57-385 -- Loss: 0.18315574526786804
train-epoch-step: 57-386 -- Loss: 0.18246018886566162
train-epoch-step: 57-387 -- Loss: 0.1912994235754013
train-epoch-step: 57-388 -- Loss: 0.18507656455039978
train-epoch-step: 57-389 -- Loss: 0.16274206340312958
train-epoch-step: 57-390 -- Loss: 0.13958270847797394
train-epoch-step: 57-391 -- Loss: 0.1401440054178238
train-epoch-step: 57-392 -- Loss: 0.18023860454559326
train-epoch-step: 57-393 -- Loss: 0.1514383852481842
train-epoch-step: 57-394 -- Loss: 0.19719785451889038
train-epoch-step: 57-395 -- Loss: 0.15627345442771912
train-epoch-step: 57-396 -- Loss: 0.12513844668865204
train-epoch-step: 57-397 -- Loss: 0.12340809404850006
train-epoch-step: 57-398 -- Loss: 0.19410796463489532
train-epoch-step: 57-399 -- Loss: 0.175479456782341
train-epoch-step: 57-400 -- Loss: 0.27061963081359863
train-epoch-step: 57-401 -- Loss: 0.11473969370126724
train-epoch-step: 57-402 -- Loss: 0.24953114986419678
train-epoch-step: 57-403 -- Loss: 0.15006598830223083
train-epoch-step: 57-404 -- Loss: 0.14175960421562195
train-epoch-step: 57-405 -- Loss: 0.14209382236003876
train-epoch-step: 57-406 -- Loss: 0.16000357270240784
train-epoch-step: 57-407 -- Loss: 0.10913591086864471
train-epoch-step: 57-408 -- Loss: 0.15787562727928162
train-epoch-step: 57-409 -- Loss: 0.16769087314605713
train-epoch-step: 57-410 -- Loss: 0.1678561270236969
train-epoch-step: 57-411 -- Loss: 0.19316518306732178
train-epoch-step: 57-412 -- Loss: 0.12991942465305328
train-epoch-step: 57-413 -- Loss: 0.14426177740097046
train-epoch-step: 57-414 -- Loss: 0.12993650138378143
train-epoch-step: 57-415 -- Loss: 0.13155482709407806
train-epoch-step: 57-416 -- Loss: 0.2548891305923462
train-epoch-step: 57-417 -- Loss: 0.19481945037841797
train-epoch-step: 57-418 -- Loss: 0.22227811813354492
train-epoch-step: 57-419 -- Loss: 0.16350597143173218
train-epoch-step: 57-420 -- Loss: 0.1496724784374237
train-epoch-step: 57-421 -- Loss: 0.17174598574638367
train-epoch-step: 57-422 -- Loss: 0.14532174170017242
train-epoch-step: 57-423 -- Loss: 0.17264993488788605
train-epoch-step: 57-424 -- Loss: 0.13449057936668396
train-epoch-step: 57-425 -- Loss: 0.17676854133605957
train-epoch-step: 57-426 -- Loss: 0.16148076951503754
train-epoch-step: 57-427 -- Loss: 0.11994639039039612
train-epoch-step: 57-428 -- Loss: 0.19091568887233734
train-epoch-step: 57-429 -- Loss: 0.17210018634796143
train-epoch-step: 57-430 -- Loss: 0.13585060834884644
train-epoch-step: 57-431 -- Loss: 0.17622943222522736
train-epoch-step: 57-432 -- Loss: 0.23218579590320587
train-epoch-step: 57-433 -- Loss: 0.13209287822246552
train-epoch-step: 57-434 -- Loss: 0.12652260065078735
train-epoch-step: 57-435 -- Loss: 0.15060274302959442
train-epoch-step: 57-436 -- Loss: 0.14904670417308807
train-epoch-step: 57-437 -- Loss: 0.1299554854631424
train-epoch-step: 57-438 -- Loss: 0.16361910104751587
train-epoch-step: 57-439 -- Loss: 0.25936445593833923
train-epoch-step: 57-440 -- Loss: 0.12970228493213654
train-epoch-step: 57-441 -- Loss: 0.18829718232154846
train-epoch-step: 57-442 -- Loss: 0.17983055114746094
train-epoch-step: 57-443 -- Loss: 0.14624768495559692
train-epoch-step: 57-444 -- Loss: 0.17254167795181274
train-epoch-step: 57-445 -- Loss: 0.17149142920970917
train-epoch-step: 57-446 -- Loss: 0.1493486613035202
train-epoch-step: 57-447 -- Loss: 0.18742328882217407
train-epoch-step: 57-448 -- Loss: 0.21818792819976807
train-epoch-step: 57-449 -- Loss: 0.18462315201759338
train-epoch-step: 57-450 -- Loss: 0.17862513661384583
train-epoch-step: 57-451 -- Loss: 0.1414581537246704
train-epoch-step: 57-452 -- Loss: 0.12279942631721497
train-epoch-step: 57-453 -- Loss: 0.08851603418588638
train-epoch-step: 57-454 -- Loss: 0.229450523853302
train-epoch-step: 57-455 -- Loss: 0.12148158252239227
train-epoch-step: 57-456 -- Loss: 0.11827865988016129
train-epoch-step: 57-457 -- Loss: 0.21140727400779724
train-epoch-step: 57-458 -- Loss: 0.14377281069755554
train-epoch-step: 57-459 -- Loss: 0.21297578513622284
train-epoch-step: 57-460 -- Loss: 0.12185164541006088
train-epoch-step: 57-461 -- Loss: 0.13152256608009338
train-epoch-step: 57-462 -- Loss: 0.14719299972057343
train-epoch-step: 57-463 -- Loss: 0.1318552941083908
train-epoch-step: 57-464 -- Loss: 0.1546633243560791
train-epoch-step: 57-465 -- Loss: 0.232571542263031
train-epoch-step: 57-466 -- Loss: 0.1942484974861145
train-epoch-step: 57-467 -- Loss: 0.11136379092931747
train-epoch-step: 57-468 -- Loss: 0.16069090366363525
train-epoch-step: 57-469 -- Loss: 0.20064371824264526
train-epoch-step: 57-470 -- Loss: 0.16265109181404114
train-epoch-step: 57-471 -- Loss: 0.15071585774421692
train-epoch-step: 57-472 -- Loss: 0.15261802077293396
train-epoch-step: 57-473 -- Loss: 0.14947959780693054
train-epoch-step: 57-474 -- Loss: 0.11345358937978745
train-epoch-step: 57-475 -- Loss: 0.10537934303283691
train-epoch-step: 57-476 -- Loss: 0.19642549753189087
train-epoch-step: 57-477 -- Loss: 0.19925206899642944
train-epoch-step: 57-478 -- Loss: 0.18264950811862946
train-epoch-step: 57-479 -- Loss: 0.13323141634464264
train-epoch-step: 57-480 -- Loss: 0.1856587529182434
train-epoch-step: 57-481 -- Loss: 0.27090901136398315
train-epoch-step: 57-482 -- Loss: 0.24303315579891205
train-epoch-step: 57-483 -- Loss: 0.1717522144317627
train-epoch-step: 57-484 -- Loss: 0.20709756016731262
train-epoch-step: 57-485 -- Loss: 0.12041862308979034
train-epoch-step: 57-486 -- Loss: 0.22466441988945007
train-epoch-step: 57-487 -- Loss: 0.2222336083650589
train-epoch-step: 57-488 -- Loss: 0.18629591166973114
train-epoch-step: 57-489 -- Loss: 0.21262572705745697
train-epoch-step: 57-490 -- Loss: 0.13808315992355347
train-epoch-step: 57-491 -- Loss: 0.13201749324798584
train-epoch-step: 57-492 -- Loss: 0.12412944436073303
train-epoch-step: 57-493 -- Loss: 0.1916266679763794
train-epoch-step: 57-494 -- Loss: 0.19640183448791504
train-epoch-step: 57-495 -- Loss: 0.19468143582344055
train-epoch-step: 57-496 -- Loss: 0.13845092058181763
train-epoch-step: 57-497 -- Loss: 0.17741349339485168
train-epoch-step: 57-498 -- Loss: 0.14644980430603027
train-epoch-step: 57-499 -- Loss: 0.16554534435272217
train-epoch-step: 57-500 -- Loss: 0.15126904845237732
train-epoch-step: 57-501 -- Loss: 0.21282580494880676
train-epoch-step: 57-502 -- Loss: 0.15096677839756012
train-epoch-step: 57-503 -- Loss: 0.21266856789588928
train-epoch-step: 57-504 -- Loss: 0.1133175939321518
train-epoch-step: 57-505 -- Loss: 0.1701754629611969
train-epoch-step: 57-506 -- Loss: 0.11173920333385468
train-epoch-step: 57-507 -- Loss: 0.1737593561410904
train-epoch-step: 57-508 -- Loss: 0.17771224677562714
train-epoch-step: 57-509 -- Loss: 0.16384820640087128
train-epoch-step: 57-510 -- Loss: 0.12323128432035446
train-epoch-step: 57-511 -- Loss: 0.21296505630016327
train-epoch-step: 57-512 -- Loss: 0.17674285173416138
train-epoch-step: 57-513 -- Loss: 0.1820736676454544
train-epoch-step: 57-514 -- Loss: 0.14341191947460175
train-epoch-step: 57-515 -- Loss: 0.1603461056947708
train-epoch-step: 57-516 -- Loss: 0.16795271635055542
train-epoch-step: 57-517 -- Loss: 0.1722668558359146
train-epoch-step: 57-518 -- Loss: 0.13665297627449036
train-epoch-step: 57-519 -- Loss: 0.13249319791793823
train-epoch-step: 57-520 -- Loss: 0.181643545627594
train-epoch-step: 57-521 -- Loss: 0.2149161845445633
train-epoch-step: 57-522 -- Loss: 0.1740330010652542
train-epoch-step: 57-523 -- Loss: 0.1498774290084839
train-epoch-step: 57-524 -- Loss: 0.1608145385980606
train-epoch-step: 57-525 -- Loss: 0.1848357915878296
train-epoch-step: 57-526 -- Loss: 0.1311776340007782
train-epoch-step: 57-527 -- Loss: 0.14575724303722382
train-epoch-step: 57-528 -- Loss: 0.15251681208610535
train-epoch-step: 57-529 -- Loss: 0.15258225798606873
train-epoch-step: 57-530 -- Loss: 0.17009896039962769
train-epoch-step: 57-531 -- Loss: 0.19035540521144867
train-epoch-step: 57-532 -- Loss: 0.17641086876392365
train-epoch-step: 57-533 -- Loss: 0.16628201305866241
train-epoch-step: 57-534 -- Loss: 0.12390883266925812
train-epoch-step: 57-535 -- Loss: 0.2507683038711548
train-epoch-step: 57-536 -- Loss: 0.1536456197500229
train-epoch-step: 57-537 -- Loss: 0.14454512298107147
train-epoch-step: 57-538 -- Loss: 0.10087808966636658
train-epoch-step: 57-539 -- Loss: 0.17694860696792603
train-epoch-step: 57-540 -- Loss: 0.13621723651885986
train-epoch-step: 57-541 -- Loss: 0.20378591120243073
train-epoch-step: 57-542 -- Loss: 0.2259783148765564
train-epoch-step: 57-543 -- Loss: 0.1665322631597519
train-epoch-step: 57-544 -- Loss: 0.2246829867362976
train-epoch-step: 57-545 -- Loss: 0.18921245634555817
train-epoch-step: 57-546 -- Loss: 0.19687265157699585
train-epoch-step: 57-547 -- Loss: 0.17708541452884674
train-epoch-step: 57-548 -- Loss: 0.09007251262664795
train-epoch-step: 57-549 -- Loss: 0.14641226828098297
train-epoch-step: 57-550 -- Loss: 0.1964578628540039
train-epoch-step: 57-551 -- Loss: 0.15376845002174377
train-epoch-step: 57-552 -- Loss: 0.12367863953113556
train-epoch-step: 57-553 -- Loss: 0.18236292898654938
train-epoch-step: 57-554 -- Loss: 0.18605439364910126
train-epoch-step: 57-555 -- Loss: 0.20299385488033295
train-epoch-step: 57-556 -- Loss: 0.1372690051794052
train-epoch-step: 57-557 -- Loss: 0.2279714196920395
train-epoch-step: 57-558 -- Loss: 0.21767082810401917
train-epoch-step: 57-559 -- Loss: 0.1324610561132431
train-epoch-step: 57-560 -- Loss: 0.19556312263011932
train-epoch-step: 57-561 -- Loss: 0.17414267361164093
train-epoch-step: 57-562 -- Loss: 0.15603229403495789
train-epoch-step: 57-563 -- Loss: 0.1824580729007721
train-epoch-step: 57-564 -- Loss: 0.09467937052249908
train-epoch-step: 57-565 -- Loss: 0.18175633251667023
train-epoch-step: 57-566 -- Loss: 0.14238408207893372
train-epoch-step: 57-567 -- Loss: 0.2016616314649582
train-epoch-step: 57-568 -- Loss: 0.15671299397945404
train-epoch-step: 57-569 -- Loss: 0.23690062761306763
train-epoch-step: 57-570 -- Loss: 0.16928040981292725
train-epoch-step: 57-571 -- Loss: 0.21030184626579285
train-epoch-step: 57-572 -- Loss: 0.2600962519645691
train-epoch-step: 57-573 -- Loss: 0.1941450536251068
train-epoch-step: 57-574 -- Loss: 0.2317536324262619
train-epoch-step: 57-575 -- Loss: 0.30149510502815247
train-epoch-step: 57-576 -- Loss: 0.11442993581295013
train-epoch-step: 57-577 -- Loss: 0.1627941131591797
train-epoch-step: 57-578 -- Loss: 0.20755761861801147
train-epoch-step: 57-579 -- Loss: 0.16695822775363922
train-epoch-step: 57-580 -- Loss: 0.16700035333633423
train-epoch-step: 57-581 -- Loss: 0.13486458361148834
train-epoch-step: 57-582 -- Loss: 0.20253895223140717
train-epoch-step: 57-583 -- Loss: 0.2080879658460617
train-epoch-step: 57-584 -- Loss: 0.15910443663597107
train-epoch-step: 57-585 -- Loss: 0.18840743601322174
train-epoch-step: 57-586 -- Loss: 0.25009745359420776
train-epoch-step: 57-587 -- Loss: 0.1563737839460373
train-epoch-step: 57-588 -- Loss: 0.12203387916088104
val-epoch-step: 57-589 -- Loss: 0.20934335887432098
val-epoch-step: 57-590 -- Loss: 0.15147686004638672
val-epoch-step: 57-591 -- Loss: 0.22243201732635498
val-epoch-step: 57-592 -- Loss: 0.1736850142478943
val-epoch-step: 57-593 -- Loss: 0.1599167287349701
val-epoch-step: 57-594 -- Loss: 0.36138916015625
val-epoch-step: 57-595 -- Loss: 0.1751745045185089
val-epoch-step: 57-596 -- Loss: 0.19116343557834625
val-epoch-step: 57-597 -- Loss: 0.16695013642311096
val-epoch-step: 57-598 -- Loss: 0.14547652006149292
val-epoch-step: 57-599 -- Loss: 0.18481580913066864
val-epoch-step: 57-600 -- Loss: 0.16373300552368164
val-epoch-step: 57-601 -- Loss: 0.1520857959985733
val-epoch-step: 57-602 -- Loss: 0.13328346610069275
val-epoch-step: 57-603 -- Loss: 0.2066555917263031
val-epoch-step: 57-604 -- Loss: 0.1431444138288498
val-epoch-step: 57-605 -- Loss: 0.14378181099891663
val-epoch-step: 57-606 -- Loss: 0.24800941348075867
val-epoch-step: 57-607 -- Loss: 0.13849309086799622
val-epoch-step: 57-608 -- Loss: 0.24230006337165833
val-epoch-step: 57-609 -- Loss: 0.17366838455200195
val-epoch-step: 57-610 -- Loss: 0.1758532077074051
val-epoch-step: 57-611 -- Loss: 0.14840863645076752
val-epoch-step: 57-612 -- Loss: 0.32116949558258057
val-epoch-step: 57-613 -- Loss: 0.16646988689899445
val-epoch-step: 57-614 -- Loss: 0.16754364967346191
val-epoch-step: 57-615 -- Loss: 0.17456692457199097
val-epoch-step: 57-616 -- Loss: 0.13930577039718628
val-epoch-step: 57-617 -- Loss: 0.1843532770872116
val-epoch-step: 57-618 -- Loss: 0.1775159388780594
val-epoch-step: 57-619 -- Loss: 0.26637664437294006
val-epoch-step: 57-620 -- Loss: 0.13360995054244995
val-epoch-step: 57-621 -- Loss: 0.12322254478931427
val-epoch-step: 57-622 -- Loss: 0.14453771710395813
val-epoch-step: 57-623 -- Loss: 0.14626632630825043
val-epoch-step: 57-624 -- Loss: 0.13713008165359497
val-epoch-step: 57-625 -- Loss: 0.15869905054569244
val-epoch-step: 57-626 -- Loss: 0.14350926876068115
val-epoch-step: 57-627 -- Loss: 0.18529033660888672
val-epoch-step: 57-628 -- Loss: 0.6180740594863892
val-epoch-step: 57-629 -- Loss: 0.22226987779140472
val-epoch-step: 57-630 -- Loss: 0.3384391665458679
val-epoch-step: 57-631 -- Loss: 0.14083047211170197
val-epoch-step: 57-632 -- Loss: 0.19074638187885284
val-epoch-step: 57-633 -- Loss: 0.14392223954200745
val-epoch-step: 57-634 -- Loss: 0.14241012930870056
val-epoch-step: 57-635 -- Loss: 0.11318989843130112
val-epoch-step: 57-636 -- Loss: 0.16118957102298737
val-epoch-step: 57-637 -- Loss: 0.17556394636631012
val-epoch-step: 57-638 -- Loss: 0.16254062950611115
val-epoch-step: 57-639 -- Loss: 0.2583942413330078
val-epoch-step: 57-640 -- Loss: 0.24601155519485474
val-epoch-step: 57-641 -- Loss: 0.13292083144187927
val-epoch-step: 57-642 -- Loss: 0.17283496260643005
val-epoch-step: 57-643 -- Loss: 0.2042929232120514
val-epoch-step: 57-644 -- Loss: 0.16523294150829315
val-epoch-step: 57-645 -- Loss: 0.21598464250564575
val-epoch-step: 57-646 -- Loss: 0.14080727100372314
val-epoch-step: 57-647 -- Loss: 0.13095295429229736
val-epoch-step: 57-648 -- Loss: 0.15582314133644104
val-epoch-step: 57-649 -- Loss: 0.2067151963710785
val-epoch-step: 57-650 -- Loss: 0.23987480998039246
val-epoch-step: 57-651 -- Loss: 0.14066167175769806
val-epoch-step: 57-652 -- Loss: 0.15189844369888306
val-epoch-step: 57-653 -- Loss: 0.2067852020263672
val-epoch-step: 57-654 -- Loss: 0.10712933540344238
Epoch: 57 -- Train Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 58-0 -- Loss: 0.21624767780303955
train-epoch-step: 58-1 -- Loss: 0.13774627447128296
train-epoch-step: 58-2 -- Loss: 0.1874549835920334
train-epoch-step: 58-3 -- Loss: 0.14112488925457
train-epoch-step: 58-4 -- Loss: 0.15981894731521606
train-epoch-step: 58-5 -- Loss: 0.17319224774837494
train-epoch-step: 58-6 -- Loss: 0.2111128866672516
train-epoch-step: 58-7 -- Loss: 0.1662089228630066
train-epoch-step: 58-8 -- Loss: 0.18656741082668304
train-epoch-step: 58-9 -- Loss: 0.2235131710767746
train-epoch-step: 58-10 -- Loss: 0.1883748173713684
train-epoch-step: 58-11 -- Loss: 0.1843799650669098
train-epoch-step: 58-12 -- Loss: 0.1413280963897705
train-epoch-step: 58-13 -- Loss: 0.17362871766090393
train-epoch-step: 58-14 -- Loss: 0.15909527242183685
train-epoch-step: 58-15 -- Loss: 0.1581479012966156
train-epoch-step: 58-16 -- Loss: 0.17698025703430176
train-epoch-step: 58-17 -- Loss: 0.21084371209144592
train-epoch-step: 58-18 -- Loss: 0.1890764832496643
train-epoch-step: 58-19 -- Loss: 0.1274288445711136
train-epoch-step: 58-20 -- Loss: 0.20740821957588196
train-epoch-step: 58-21 -- Loss: 0.24415946006774902
train-epoch-step: 58-22 -- Loss: 0.14175918698310852
train-epoch-step: 58-23 -- Loss: 0.135959193110466
train-epoch-step: 58-24 -- Loss: 0.12422472983598709
train-epoch-step: 58-25 -- Loss: 0.22383145987987518
train-epoch-step: 58-26 -- Loss: 0.19140441715717316
train-epoch-step: 58-27 -- Loss: 0.21687158942222595
train-epoch-step: 58-28 -- Loss: 0.12201830744743347
train-epoch-step: 58-29 -- Loss: 0.23339848220348358
train-epoch-step: 58-30 -- Loss: 0.10676410794258118
train-epoch-step: 58-31 -- Loss: 0.13281497359275818
train-epoch-step: 58-32 -- Loss: 0.17086300253868103
train-epoch-step: 58-33 -- Loss: 0.2653513550758362
train-epoch-step: 58-34 -- Loss: 0.16450601816177368
train-epoch-step: 58-35 -- Loss: 0.23705396056175232
train-epoch-step: 58-36 -- Loss: 0.13626372814178467
train-epoch-step: 58-37 -- Loss: 0.13126160204410553
train-epoch-step: 58-38 -- Loss: 0.1710270792245865
train-epoch-step: 58-39 -- Loss: 0.2101343274116516
train-epoch-step: 58-40 -- Loss: 0.1840360462665558
train-epoch-step: 58-41 -- Loss: 0.20426088571548462
train-epoch-step: 58-42 -- Loss: 0.14564944803714752
train-epoch-step: 58-43 -- Loss: 0.2517671585083008
train-epoch-step: 58-44 -- Loss: 0.1262006163597107
train-epoch-step: 58-45 -- Loss: 0.11426109075546265
train-epoch-step: 58-46 -- Loss: 0.1646307110786438
train-epoch-step: 58-47 -- Loss: 0.186351478099823
train-epoch-step: 58-48 -- Loss: 0.15115222334861755
train-epoch-step: 58-49 -- Loss: 0.22012796998023987
train-epoch-step: 58-50 -- Loss: 0.10714900493621826
train-epoch-step: 58-51 -- Loss: 0.1697072684764862
train-epoch-step: 58-52 -- Loss: 0.15461990237236023
train-epoch-step: 58-53 -- Loss: 0.20348265767097473
train-epoch-step: 58-54 -- Loss: 0.27783071994781494
train-epoch-step: 58-55 -- Loss: 0.1634884774684906
train-epoch-step: 58-56 -- Loss: 0.17569619417190552
train-epoch-step: 58-57 -- Loss: 0.2290758192539215
train-epoch-step: 58-58 -- Loss: 0.275135338306427
train-epoch-step: 58-59 -- Loss: 0.22496336698532104
train-epoch-step: 58-60 -- Loss: 0.12503471970558167
train-epoch-step: 58-61 -- Loss: 0.21236085891723633
train-epoch-step: 58-62 -- Loss: 0.1797371804714203
train-epoch-step: 58-63 -- Loss: 0.13324633240699768
train-epoch-step: 58-64 -- Loss: 0.13834699988365173
train-epoch-step: 58-65 -- Loss: 0.17554132640361786
train-epoch-step: 58-66 -- Loss: 0.10452239215373993
train-epoch-step: 58-67 -- Loss: 0.12045568227767944
train-epoch-step: 58-68 -- Loss: 0.20345762372016907
train-epoch-step: 58-69 -- Loss: 0.11761440336704254
train-epoch-step: 58-70 -- Loss: 0.220159113407135
train-epoch-step: 58-71 -- Loss: 0.2541615068912506
train-epoch-step: 58-72 -- Loss: 0.1693950742483139
train-epoch-step: 58-73 -- Loss: 0.20141397416591644
train-epoch-step: 58-74 -- Loss: 0.09393559396266937
train-epoch-step: 58-75 -- Loss: 0.12078443914651871
train-epoch-step: 58-76 -- Loss: 0.1411418914794922
train-epoch-step: 58-77 -- Loss: 0.2202184945344925
train-epoch-step: 58-78 -- Loss: 0.24686279892921448
train-epoch-step: 58-79 -- Loss: 0.18346752226352692
train-epoch-step: 58-80 -- Loss: 0.234756201505661
train-epoch-step: 58-81 -- Loss: 0.1173681989312172
train-epoch-step: 58-82 -- Loss: 0.23969200253486633
train-epoch-step: 58-83 -- Loss: 0.17031481862068176
train-epoch-step: 58-84 -- Loss: 0.1823968142271042
train-epoch-step: 58-85 -- Loss: 0.16662442684173584
train-epoch-step: 58-86 -- Loss: 0.11741107702255249
train-epoch-step: 58-87 -- Loss: 0.20234303176403046
train-epoch-step: 58-88 -- Loss: 0.1397625058889389
train-epoch-step: 58-89 -- Loss: 0.1824209988117218
train-epoch-step: 58-90 -- Loss: 0.18428128957748413
train-epoch-step: 58-91 -- Loss: 0.23523709177970886
train-epoch-step: 58-92 -- Loss: 0.15278469026088715
train-epoch-step: 58-93 -- Loss: 0.16324594616889954
train-epoch-step: 58-94 -- Loss: 0.21309970319271088
train-epoch-step: 58-95 -- Loss: 0.18618914484977722
train-epoch-step: 58-96 -- Loss: 0.21007801592350006
train-epoch-step: 58-97 -- Loss: 0.17284473776817322
train-epoch-step: 58-98 -- Loss: 0.15104718506336212
train-epoch-step: 58-99 -- Loss: 0.17684030532836914
train-epoch-step: 58-100 -- Loss: 0.18214936554431915
train-epoch-step: 58-101 -- Loss: 0.2640475630760193
train-epoch-step: 58-102 -- Loss: 0.21237047016620636
train-epoch-step: 58-103 -- Loss: 0.1783878654241562
train-epoch-step: 58-104 -- Loss: 0.14444458484649658
train-epoch-step: 58-105 -- Loss: 0.25721099972724915
train-epoch-step: 58-106 -- Loss: 0.17130467295646667
train-epoch-step: 58-107 -- Loss: 0.18492203950881958
train-epoch-step: 58-108 -- Loss: 0.18599022924900055
train-epoch-step: 58-109 -- Loss: 0.1411697268486023
train-epoch-step: 58-110 -- Loss: 0.17904002964496613
train-epoch-step: 58-111 -- Loss: 0.17524294555187225
train-epoch-step: 58-112 -- Loss: 0.16312849521636963
train-epoch-step: 58-113 -- Loss: 0.15943478047847748
train-epoch-step: 58-114 -- Loss: 0.21393975615501404
train-epoch-step: 58-115 -- Loss: 0.15559644997119904
train-epoch-step: 58-116 -- Loss: 0.1339576095342636
train-epoch-step: 58-117 -- Loss: 0.12684811651706696
train-epoch-step: 58-118 -- Loss: 0.18768811225891113
train-epoch-step: 58-119 -- Loss: 0.1459294557571411
train-epoch-step: 58-120 -- Loss: 0.24112512171268463
train-epoch-step: 58-121 -- Loss: 0.23710231482982635
train-epoch-step: 58-122 -- Loss: 0.21057400107383728
train-epoch-step: 58-123 -- Loss: 0.19697241485118866
train-epoch-step: 58-124 -- Loss: 0.12195026129484177
train-epoch-step: 58-125 -- Loss: 0.1486859917640686
train-epoch-step: 58-126 -- Loss: 0.22648614645004272
train-epoch-step: 58-127 -- Loss: 0.1674087792634964
train-epoch-step: 58-128 -- Loss: 0.16481609642505646
train-epoch-step: 58-129 -- Loss: 0.13679756224155426
train-epoch-step: 58-130 -- Loss: 0.1851186752319336
train-epoch-step: 58-131 -- Loss: 0.13124044239521027
train-epoch-step: 58-132 -- Loss: 0.18530555069446564
train-epoch-step: 58-133 -- Loss: 0.11594117432832718
train-epoch-step: 58-134 -- Loss: 0.194388747215271
train-epoch-step: 58-135 -- Loss: 0.13120833039283752
train-epoch-step: 58-136 -- Loss: 0.12136261910200119
train-epoch-step: 58-137 -- Loss: 0.23548190295696259
train-epoch-step: 58-138 -- Loss: 0.25122976303100586
train-epoch-step: 58-139 -- Loss: 0.12479203939437866
train-epoch-step: 58-140 -- Loss: 0.1999509483575821
train-epoch-step: 58-141 -- Loss: 0.22534415125846863
train-epoch-step: 58-142 -- Loss: 0.1956169605255127
train-epoch-step: 58-143 -- Loss: 0.16491641104221344
train-epoch-step: 58-144 -- Loss: 0.17702820897102356
train-epoch-step: 58-145 -- Loss: 0.13631165027618408
train-epoch-step: 58-146 -- Loss: 0.17456229031085968
train-epoch-step: 58-147 -- Loss: 0.16504736244678497
train-epoch-step: 58-148 -- Loss: 0.16113269329071045
train-epoch-step: 58-149 -- Loss: 0.12206639349460602
train-epoch-step: 58-150 -- Loss: 0.17703992128372192
train-epoch-step: 58-151 -- Loss: 0.18322254717350006
train-epoch-step: 58-152 -- Loss: 0.1834423542022705
train-epoch-step: 58-153 -- Loss: 0.2549508213996887
train-epoch-step: 58-154 -- Loss: 0.12630923092365265
train-epoch-step: 58-155 -- Loss: 0.13032101094722748
train-epoch-step: 58-156 -- Loss: 0.11230593919754028
train-epoch-step: 58-157 -- Loss: 0.16488373279571533
train-epoch-step: 58-158 -- Loss: 0.16346153616905212
train-epoch-step: 58-159 -- Loss: 0.17553792893886566
train-epoch-step: 58-160 -- Loss: 0.20503254234790802
train-epoch-step: 58-161 -- Loss: 0.19513830542564392
train-epoch-step: 58-162 -- Loss: 0.20124489068984985
train-epoch-step: 58-163 -- Loss: 0.18369898200035095
train-epoch-step: 58-164 -- Loss: 0.1902780532836914
train-epoch-step: 58-165 -- Loss: 0.16199851036071777
train-epoch-step: 58-166 -- Loss: 0.11781510710716248
train-epoch-step: 58-167 -- Loss: 0.12755627930164337
train-epoch-step: 58-168 -- Loss: 0.19833624362945557
train-epoch-step: 58-169 -- Loss: 0.13535678386688232
train-epoch-step: 58-170 -- Loss: 0.19492892920970917
train-epoch-step: 58-171 -- Loss: 0.14087359607219696
train-epoch-step: 58-172 -- Loss: 0.2532570958137512
train-epoch-step: 58-173 -- Loss: 0.12702588737010956
train-epoch-step: 58-174 -- Loss: 0.24043673276901245
train-epoch-step: 58-175 -- Loss: 0.18109509348869324
train-epoch-step: 58-176 -- Loss: 0.12796708941459656
train-epoch-step: 58-177 -- Loss: 0.17741328477859497
train-epoch-step: 58-178 -- Loss: 0.17377901077270508
train-epoch-step: 58-179 -- Loss: 0.13773708045482635
train-epoch-step: 58-180 -- Loss: 0.14724914729595184
train-epoch-step: 58-181 -- Loss: 0.1632595658302307
train-epoch-step: 58-182 -- Loss: 0.1824979931116104
train-epoch-step: 58-183 -- Loss: 0.26767978072166443
train-epoch-step: 58-184 -- Loss: 0.13562071323394775
train-epoch-step: 58-185 -- Loss: 0.1386442929506302
train-epoch-step: 58-186 -- Loss: 0.18304044008255005
train-epoch-step: 58-187 -- Loss: 0.20441901683807373
train-epoch-step: 58-188 -- Loss: 0.17021867632865906
train-epoch-step: 58-189 -- Loss: 0.10374349355697632
train-epoch-step: 58-190 -- Loss: 0.17874905467033386
train-epoch-step: 58-191 -- Loss: 0.1539783775806427
train-epoch-step: 58-192 -- Loss: 0.221711203455925
train-epoch-step: 58-193 -- Loss: 0.2011953443288803
train-epoch-step: 58-194 -- Loss: 0.18026067316532135
train-epoch-step: 58-195 -- Loss: 0.16008257865905762
train-epoch-step: 58-196 -- Loss: 0.16196221113204956
train-epoch-step: 58-197 -- Loss: 0.1221986711025238
train-epoch-step: 58-198 -- Loss: 0.124599389731884
train-epoch-step: 58-199 -- Loss: 0.14664770662784576
train-epoch-step: 58-200 -- Loss: 0.12138138711452484
train-epoch-step: 58-201 -- Loss: 0.18527700006961823
train-epoch-step: 58-202 -- Loss: 0.13572052121162415
train-epoch-step: 58-203 -- Loss: 0.16993138194084167
train-epoch-step: 58-204 -- Loss: 0.13400274515151978
train-epoch-step: 58-205 -- Loss: 0.18615594506263733
train-epoch-step: 58-206 -- Loss: 0.19482886791229248
train-epoch-step: 58-207 -- Loss: 0.12993568181991577
train-epoch-step: 58-208 -- Loss: 0.17226654291152954
train-epoch-step: 58-209 -- Loss: 0.13925564289093018
train-epoch-step: 58-210 -- Loss: 0.1394379585981369
train-epoch-step: 58-211 -- Loss: 0.19887539744377136
train-epoch-step: 58-212 -- Loss: 0.1943764090538025
train-epoch-step: 58-213 -- Loss: 0.124152772128582
train-epoch-step: 58-214 -- Loss: 0.14145737886428833
train-epoch-step: 58-215 -- Loss: 0.1264169067144394
train-epoch-step: 58-216 -- Loss: 0.20161345601081848
train-epoch-step: 58-217 -- Loss: 0.20507273077964783
train-epoch-step: 58-218 -- Loss: 0.13863907754421234
train-epoch-step: 58-219 -- Loss: 0.16363686323165894
train-epoch-step: 58-220 -- Loss: 0.12426415085792542
train-epoch-step: 58-221 -- Loss: 0.1972452849149704
train-epoch-step: 58-222 -- Loss: 0.11379406601190567
train-epoch-step: 58-223 -- Loss: 0.17052648961544037
train-epoch-step: 58-224 -- Loss: 0.18151114881038666
train-epoch-step: 58-225 -- Loss: 0.27035295963287354
train-epoch-step: 58-226 -- Loss: 0.19903352856636047
train-epoch-step: 58-227 -- Loss: 0.21656079590320587
train-epoch-step: 58-228 -- Loss: 0.17206163704395294
train-epoch-step: 58-229 -- Loss: 0.16751717031002045
train-epoch-step: 58-230 -- Loss: 0.15954521298408508
train-epoch-step: 58-231 -- Loss: 0.15254917740821838
train-epoch-step: 58-232 -- Loss: 0.19601455330848694
train-epoch-step: 58-233 -- Loss: 0.08299587666988373
train-epoch-step: 58-234 -- Loss: 0.17156383395195007
train-epoch-step: 58-235 -- Loss: 0.15224222838878632
train-epoch-step: 58-236 -- Loss: 0.18050047755241394
train-epoch-step: 58-237 -- Loss: 0.23389413952827454
train-epoch-step: 58-238 -- Loss: 0.15775997936725616
train-epoch-step: 58-239 -- Loss: 0.12312544882297516
train-epoch-step: 58-240 -- Loss: 0.21460145711898804
train-epoch-step: 58-241 -- Loss: 0.14743269979953766
train-epoch-step: 58-242 -- Loss: 0.2155432403087616
train-epoch-step: 58-243 -- Loss: 0.22819998860359192
train-epoch-step: 58-244 -- Loss: 0.20272186398506165
train-epoch-step: 58-245 -- Loss: 0.20439675450325012
train-epoch-step: 58-246 -- Loss: 0.21587663888931274
train-epoch-step: 58-247 -- Loss: 0.21134544909000397
train-epoch-step: 58-248 -- Loss: 0.18204323947429657
train-epoch-step: 58-249 -- Loss: 0.13386207818984985
train-epoch-step: 58-250 -- Loss: 0.19816777110099792
train-epoch-step: 58-251 -- Loss: 0.10294564813375473
train-epoch-step: 58-252 -- Loss: 0.18483135104179382
train-epoch-step: 58-253 -- Loss: 0.13399693369865417
train-epoch-step: 58-254 -- Loss: 0.2090747356414795
train-epoch-step: 58-255 -- Loss: 0.1452263444662094
train-epoch-step: 58-256 -- Loss: 0.15312957763671875
train-epoch-step: 58-257 -- Loss: 0.18386824429035187
train-epoch-step: 58-258 -- Loss: 0.14033065736293793
train-epoch-step: 58-259 -- Loss: 0.1071646586060524
train-epoch-step: 58-260 -- Loss: 0.1939699649810791
train-epoch-step: 58-261 -- Loss: 0.17041416466236115
train-epoch-step: 58-262 -- Loss: 0.27552706003189087
train-epoch-step: 58-263 -- Loss: 0.19649769365787506
train-epoch-step: 58-264 -- Loss: 0.16796311736106873
train-epoch-step: 58-265 -- Loss: 0.10700873285531998
train-epoch-step: 58-266 -- Loss: 0.14994028210639954
train-epoch-step: 58-267 -- Loss: 0.1294143944978714
train-epoch-step: 58-268 -- Loss: 0.11538642644882202
train-epoch-step: 58-269 -- Loss: 0.17174600064754486
train-epoch-step: 58-270 -- Loss: 0.10605189949274063
train-epoch-step: 58-271 -- Loss: 0.1443547159433365
train-epoch-step: 58-272 -- Loss: 0.1122652143239975
train-epoch-step: 58-273 -- Loss: 0.12149287015199661
train-epoch-step: 58-274 -- Loss: 0.17810088396072388
train-epoch-step: 58-275 -- Loss: 0.18744155764579773
train-epoch-step: 58-276 -- Loss: 0.1566692441701889
train-epoch-step: 58-277 -- Loss: 0.15055811405181885
train-epoch-step: 58-278 -- Loss: 0.14097975194454193
train-epoch-step: 58-279 -- Loss: 0.14539042115211487
train-epoch-step: 58-280 -- Loss: 0.21251295506954193
train-epoch-step: 58-281 -- Loss: 0.17143985629081726
train-epoch-step: 58-282 -- Loss: 0.1419364959001541
train-epoch-step: 58-283 -- Loss: 0.1188158243894577
train-epoch-step: 58-284 -- Loss: 0.1307435929775238
train-epoch-step: 58-285 -- Loss: 0.1868293583393097
train-epoch-step: 58-286 -- Loss: 0.1525193750858307
train-epoch-step: 58-287 -- Loss: 0.19175858795642853
train-epoch-step: 58-288 -- Loss: 0.09164409339427948
train-epoch-step: 58-289 -- Loss: 0.11666013300418854
train-epoch-step: 58-290 -- Loss: 0.17895470559597015
train-epoch-step: 58-291 -- Loss: 0.11432008445262909
train-epoch-step: 58-292 -- Loss: 0.15423455834388733
train-epoch-step: 58-293 -- Loss: 0.13406257331371307
train-epoch-step: 58-294 -- Loss: 0.1537323296070099
train-epoch-step: 58-295 -- Loss: 0.27116185426712036
train-epoch-step: 58-296 -- Loss: 0.1549127995967865
train-epoch-step: 58-297 -- Loss: 0.1720522940158844
train-epoch-step: 58-298 -- Loss: 0.23066775500774384
train-epoch-step: 58-299 -- Loss: 0.15763939917087555
train-epoch-step: 58-300 -- Loss: 0.15660052001476288
train-epoch-step: 58-301 -- Loss: 0.18928170204162598
train-epoch-step: 58-302 -- Loss: 0.21425984799861908
train-epoch-step: 58-303 -- Loss: 0.20293965935707092
train-epoch-step: 58-304 -- Loss: 0.12440501153469086
train-epoch-step: 58-305 -- Loss: 0.1404624879360199
train-epoch-step: 58-306 -- Loss: 0.24463911354541779
train-epoch-step: 58-307 -- Loss: 0.1613093614578247
train-epoch-step: 58-308 -- Loss: 0.22308512032032013
train-epoch-step: 58-309 -- Loss: 0.15238255262374878
train-epoch-step: 58-310 -- Loss: 0.16360801458358765
train-epoch-step: 58-311 -- Loss: 0.15661941468715668
train-epoch-step: 58-312 -- Loss: 0.19982823729515076
train-epoch-step: 58-313 -- Loss: 0.0942157432436943
train-epoch-step: 58-314 -- Loss: 0.19627657532691956
train-epoch-step: 58-315 -- Loss: 0.1699201762676239
train-epoch-step: 58-316 -- Loss: 0.14959271252155304
train-epoch-step: 58-317 -- Loss: 0.1373448669910431
train-epoch-step: 58-318 -- Loss: 0.15441593527793884
train-epoch-step: 58-319 -- Loss: 0.16131487488746643
train-epoch-step: 58-320 -- Loss: 0.11714567244052887
train-epoch-step: 58-321 -- Loss: 0.14044074714183807
train-epoch-step: 58-322 -- Loss: 0.20825831592082977
train-epoch-step: 58-323 -- Loss: 0.16393744945526123
train-epoch-step: 58-324 -- Loss: 0.25211429595947266
train-epoch-step: 58-325 -- Loss: 0.15262390673160553
train-epoch-step: 58-326 -- Loss: 0.16754059493541718
train-epoch-step: 58-327 -- Loss: 0.1989366114139557
train-epoch-step: 58-328 -- Loss: 0.19427964091300964
train-epoch-step: 58-329 -- Loss: 0.33050668239593506
train-epoch-step: 58-330 -- Loss: 0.3499348759651184
train-epoch-step: 58-331 -- Loss: 0.2027083933353424
train-epoch-step: 58-332 -- Loss: 0.10080628097057343
train-epoch-step: 58-333 -- Loss: 0.1765180230140686
train-epoch-step: 58-334 -- Loss: 0.15042239427566528
train-epoch-step: 58-335 -- Loss: 0.16960138082504272
train-epoch-step: 58-336 -- Loss: 0.14449526369571686
train-epoch-step: 58-337 -- Loss: 0.19915258884429932
train-epoch-step: 58-338 -- Loss: 0.15526223182678223
train-epoch-step: 58-339 -- Loss: 0.14078065752983093
train-epoch-step: 58-340 -- Loss: 0.19103549420833588
train-epoch-step: 58-341 -- Loss: 0.1352863609790802
train-epoch-step: 58-342 -- Loss: 0.15796954929828644
train-epoch-step: 58-343 -- Loss: 0.14941246807575226
train-epoch-step: 58-344 -- Loss: 0.16693507134914398
train-epoch-step: 58-345 -- Loss: 0.1273331344127655
train-epoch-step: 58-346 -- Loss: 0.19438597559928894
train-epoch-step: 58-347 -- Loss: 0.14720310270786285
train-epoch-step: 58-348 -- Loss: 0.20009782910346985
train-epoch-step: 58-349 -- Loss: 0.19339723885059357
train-epoch-step: 58-350 -- Loss: 0.24379390478134155
train-epoch-step: 58-351 -- Loss: 0.19193853437900543
train-epoch-step: 58-352 -- Loss: 0.12188837677240372
train-epoch-step: 58-353 -- Loss: 0.19103628396987915
train-epoch-step: 58-354 -- Loss: 0.2702837586402893
train-epoch-step: 58-355 -- Loss: 0.1161806732416153
train-epoch-step: 58-356 -- Loss: 0.11794967204332352
train-epoch-step: 58-357 -- Loss: 0.18464165925979614
train-epoch-step: 58-358 -- Loss: 0.18223106861114502
train-epoch-step: 58-359 -- Loss: 0.13279758393764496
train-epoch-step: 58-360 -- Loss: 0.11992574483156204
train-epoch-step: 58-361 -- Loss: 0.23210552334785461
train-epoch-step: 58-362 -- Loss: 0.1653456836938858
train-epoch-step: 58-363 -- Loss: 0.10599052160978317
train-epoch-step: 58-364 -- Loss: 0.17401914298534393
train-epoch-step: 58-365 -- Loss: 0.16293872892856598
train-epoch-step: 58-366 -- Loss: 0.2004648596048355
train-epoch-step: 58-367 -- Loss: 0.2243107259273529
train-epoch-step: 58-368 -- Loss: 0.1930340975522995
train-epoch-step: 58-369 -- Loss: 0.26714539527893066
train-epoch-step: 58-370 -- Loss: 0.12100780010223389
train-epoch-step: 58-371 -- Loss: 0.11768553406000137
train-epoch-step: 58-372 -- Loss: 0.1440000981092453
train-epoch-step: 58-373 -- Loss: 0.1854192316532135
train-epoch-step: 58-374 -- Loss: 0.15018387138843536
train-epoch-step: 58-375 -- Loss: 0.2610517740249634
train-epoch-step: 58-376 -- Loss: 0.1568576842546463
train-epoch-step: 58-377 -- Loss: 0.22310985624790192
train-epoch-step: 58-378 -- Loss: 0.1982356756925583
train-epoch-step: 58-379 -- Loss: 0.11698031425476074
train-epoch-step: 58-380 -- Loss: 0.08982377499341965
train-epoch-step: 58-381 -- Loss: 0.2345794290304184
train-epoch-step: 58-382 -- Loss: 0.22987626492977142
train-epoch-step: 58-383 -- Loss: 0.173149973154068
train-epoch-step: 58-384 -- Loss: 0.21258562803268433
train-epoch-step: 58-385 -- Loss: 0.18338817358016968
train-epoch-step: 58-386 -- Loss: 0.17995117604732513
train-epoch-step: 58-387 -- Loss: 0.19430479407310486
train-epoch-step: 58-388 -- Loss: 0.18051844835281372
train-epoch-step: 58-389 -- Loss: 0.16316957771778107
train-epoch-step: 58-390 -- Loss: 0.13699771463871002
train-epoch-step: 58-391 -- Loss: 0.1405881941318512
train-epoch-step: 58-392 -- Loss: 0.18108926713466644
train-epoch-step: 58-393 -- Loss: 0.15224307775497437
train-epoch-step: 58-394 -- Loss: 0.18798480927944183
train-epoch-step: 58-395 -- Loss: 0.1528291553258896
train-epoch-step: 58-396 -- Loss: 0.12275958061218262
train-epoch-step: 58-397 -- Loss: 0.12117867916822433
train-epoch-step: 58-398 -- Loss: 0.18991632759571075
train-epoch-step: 58-399 -- Loss: 0.1700865626335144
train-epoch-step: 58-400 -- Loss: 0.26871222257614136
train-epoch-step: 58-401 -- Loss: 0.11544253677129745
train-epoch-step: 58-402 -- Loss: 0.2529096007347107
train-epoch-step: 58-403 -- Loss: 0.14977045357227325
train-epoch-step: 58-404 -- Loss: 0.13360543549060822
train-epoch-step: 58-405 -- Loss: 0.1359979212284088
train-epoch-step: 58-406 -- Loss: 0.16268998384475708
train-epoch-step: 58-407 -- Loss: 0.11078502237796783
train-epoch-step: 58-408 -- Loss: 0.16025808453559875
train-epoch-step: 58-409 -- Loss: 0.16651760041713715
train-epoch-step: 58-410 -- Loss: 0.16824708878993988
train-epoch-step: 58-411 -- Loss: 0.19600847363471985
train-epoch-step: 58-412 -- Loss: 0.12575213611125946
train-epoch-step: 58-413 -- Loss: 0.1438009887933731
train-epoch-step: 58-414 -- Loss: 0.12946468591690063
train-epoch-step: 58-415 -- Loss: 0.13192534446716309
train-epoch-step: 58-416 -- Loss: 0.2555963099002838
train-epoch-step: 58-417 -- Loss: 0.18434439599514008
train-epoch-step: 58-418 -- Loss: 0.2182900607585907
train-epoch-step: 58-419 -- Loss: 0.16155962646007538
train-epoch-step: 58-420 -- Loss: 0.14788350462913513
train-epoch-step: 58-421 -- Loss: 0.17328448593616486
train-epoch-step: 58-422 -- Loss: 0.14342407882213593
train-epoch-step: 58-423 -- Loss: 0.16973009705543518
train-epoch-step: 58-424 -- Loss: 0.1313011199235916
train-epoch-step: 58-425 -- Loss: 0.17957402765750885
train-epoch-step: 58-426 -- Loss: 0.16243523359298706
train-epoch-step: 58-427 -- Loss: 0.12096032500267029
train-epoch-step: 58-428 -- Loss: 0.20010294020175934
train-epoch-step: 58-429 -- Loss: 0.17041917145252228
train-epoch-step: 58-430 -- Loss: 0.1368347704410553
train-epoch-step: 58-431 -- Loss: 0.16101790964603424
train-epoch-step: 58-432 -- Loss: 0.23728010058403015
train-epoch-step: 58-433 -- Loss: 0.13408498466014862
train-epoch-step: 58-434 -- Loss: 0.12678298354148865
train-epoch-step: 58-435 -- Loss: 0.1489151269197464
train-epoch-step: 58-436 -- Loss: 0.1492408663034439
train-epoch-step: 58-437 -- Loss: 0.12920933961868286
train-epoch-step: 58-438 -- Loss: 0.1657230705022812
train-epoch-step: 58-439 -- Loss: 0.2598295211791992
train-epoch-step: 58-440 -- Loss: 0.1269902139902115
train-epoch-step: 58-441 -- Loss: 0.20217548310756683
train-epoch-step: 58-442 -- Loss: 0.17010283470153809
train-epoch-step: 58-443 -- Loss: 0.1487501859664917
train-epoch-step: 58-444 -- Loss: 0.1786130964756012
train-epoch-step: 58-445 -- Loss: 0.1709313690662384
train-epoch-step: 58-446 -- Loss: 0.1469849944114685
train-epoch-step: 58-447 -- Loss: 0.1849258989095688
train-epoch-step: 58-448 -- Loss: 0.21926407516002655
train-epoch-step: 58-449 -- Loss: 0.1871485710144043
train-epoch-step: 58-450 -- Loss: 0.17970526218414307
train-epoch-step: 58-451 -- Loss: 0.13826024532318115
train-epoch-step: 58-452 -- Loss: 0.12930557131767273
train-epoch-step: 58-453 -- Loss: 0.08801895380020142
train-epoch-step: 58-454 -- Loss: 0.22750505805015564
train-epoch-step: 58-455 -- Loss: 0.12007606029510498
train-epoch-step: 58-456 -- Loss: 0.11404524743556976
train-epoch-step: 58-457 -- Loss: 0.20834749937057495
train-epoch-step: 58-458 -- Loss: 0.15129271149635315
train-epoch-step: 58-459 -- Loss: 0.20731176435947418
train-epoch-step: 58-460 -- Loss: 0.12387098371982574
train-epoch-step: 58-461 -- Loss: 0.13037386536598206
train-epoch-step: 58-462 -- Loss: 0.14830069243907928
train-epoch-step: 58-463 -- Loss: 0.13220927119255066
train-epoch-step: 58-464 -- Loss: 0.15842166543006897
train-epoch-step: 58-465 -- Loss: 0.23715335130691528
train-epoch-step: 58-466 -- Loss: 0.19787359237670898
train-epoch-step: 58-467 -- Loss: 0.10851110517978668
train-epoch-step: 58-468 -- Loss: 0.16152475774288177
train-epoch-step: 58-469 -- Loss: 0.20403344929218292
train-epoch-step: 58-470 -- Loss: 0.17218010127544403
train-epoch-step: 58-471 -- Loss: 0.15981857478618622
train-epoch-step: 58-472 -- Loss: 0.15602564811706543
train-epoch-step: 58-473 -- Loss: 0.1457507610321045
train-epoch-step: 58-474 -- Loss: 0.11548515409231186
train-epoch-step: 58-475 -- Loss: 0.10559291392564774
train-epoch-step: 58-476 -- Loss: 0.19001668691635132
train-epoch-step: 58-477 -- Loss: 0.20065993070602417
train-epoch-step: 58-478 -- Loss: 0.18771490454673767
train-epoch-step: 58-479 -- Loss: 0.13402090966701508
train-epoch-step: 58-480 -- Loss: 0.18368370831012726
train-epoch-step: 58-481 -- Loss: 0.2753041386604309
train-epoch-step: 58-482 -- Loss: 0.25478339195251465
train-epoch-step: 58-483 -- Loss: 0.1770295798778534
train-epoch-step: 58-484 -- Loss: 0.21428626775741577
train-epoch-step: 58-485 -- Loss: 0.12282463908195496
train-epoch-step: 58-486 -- Loss: 0.22628489136695862
train-epoch-step: 58-487 -- Loss: 0.22593295574188232
train-epoch-step: 58-488 -- Loss: 0.1956239938735962
train-epoch-step: 58-489 -- Loss: 0.21314480900764465
train-epoch-step: 58-490 -- Loss: 0.13461512327194214
train-epoch-step: 58-491 -- Loss: 0.13453024625778198
train-epoch-step: 58-492 -- Loss: 0.1236630529165268
train-epoch-step: 58-493 -- Loss: 0.19161424040794373
train-epoch-step: 58-494 -- Loss: 0.19706088304519653
train-epoch-step: 58-495 -- Loss: 0.19662177562713623
train-epoch-step: 58-496 -- Loss: 0.1360345035791397
train-epoch-step: 58-497 -- Loss: 0.18243715167045593
train-epoch-step: 58-498 -- Loss: 0.1398966759443283
train-epoch-step: 58-499 -- Loss: 0.16598647832870483
train-epoch-step: 58-500 -- Loss: 0.15236787497997284
train-epoch-step: 58-501 -- Loss: 0.20479357242584229
train-epoch-step: 58-502 -- Loss: 0.15795627236366272
train-epoch-step: 58-503 -- Loss: 0.2103717029094696
train-epoch-step: 58-504 -- Loss: 0.11486537754535675
train-epoch-step: 58-505 -- Loss: 0.16254818439483643
train-epoch-step: 58-506 -- Loss: 0.11167826503515244
train-epoch-step: 58-507 -- Loss: 0.17887359857559204
train-epoch-step: 58-508 -- Loss: 0.16839918494224548
train-epoch-step: 58-509 -- Loss: 0.1676853895187378
train-epoch-step: 58-510 -- Loss: 0.12379235774278641
train-epoch-step: 58-511 -- Loss: 0.21241457760334015
train-epoch-step: 58-512 -- Loss: 0.17269998788833618
train-epoch-step: 58-513 -- Loss: 0.19735252857208252
train-epoch-step: 58-514 -- Loss: 0.14598920941352844
train-epoch-step: 58-515 -- Loss: 0.15054994821548462
train-epoch-step: 58-516 -- Loss: 0.1663447618484497
train-epoch-step: 58-517 -- Loss: 0.17155992984771729
train-epoch-step: 58-518 -- Loss: 0.1357162594795227
train-epoch-step: 58-519 -- Loss: 0.1325272023677826
train-epoch-step: 58-520 -- Loss: 0.18152016401290894
train-epoch-step: 58-521 -- Loss: 0.21975167095661163
train-epoch-step: 58-522 -- Loss: 0.1669493168592453
train-epoch-step: 58-523 -- Loss: 0.1544664204120636
train-epoch-step: 58-524 -- Loss: 0.16788583993911743
train-epoch-step: 58-525 -- Loss: 0.18332166969776154
train-epoch-step: 58-526 -- Loss: 0.12459485977888107
train-epoch-step: 58-527 -- Loss: 0.14807452261447906
train-epoch-step: 58-528 -- Loss: 0.15126925706863403
train-epoch-step: 58-529 -- Loss: 0.15874682366847992
train-epoch-step: 58-530 -- Loss: 0.16709066927433014
train-epoch-step: 58-531 -- Loss: 0.19003459811210632
train-epoch-step: 58-532 -- Loss: 0.16138602793216705
train-epoch-step: 58-533 -- Loss: 0.16963285207748413
train-epoch-step: 58-534 -- Loss: 0.1274019032716751
train-epoch-step: 58-535 -- Loss: 0.24468335509300232
train-epoch-step: 58-536 -- Loss: 0.15272970497608185
train-epoch-step: 58-537 -- Loss: 0.14322394132614136
train-epoch-step: 58-538 -- Loss: 0.1004398912191391
train-epoch-step: 58-539 -- Loss: 0.18085479736328125
train-epoch-step: 58-540 -- Loss: 0.13569055497646332
train-epoch-step: 58-541 -- Loss: 0.20089517533779144
train-epoch-step: 58-542 -- Loss: 0.2178824245929718
train-epoch-step: 58-543 -- Loss: 0.1661190688610077
train-epoch-step: 58-544 -- Loss: 0.2192813754081726
train-epoch-step: 58-545 -- Loss: 0.201887845993042
train-epoch-step: 58-546 -- Loss: 0.20001152157783508
train-epoch-step: 58-547 -- Loss: 0.17601093649864197
train-epoch-step: 58-548 -- Loss: 0.08943673223257065
train-epoch-step: 58-549 -- Loss: 0.14603865146636963
train-epoch-step: 58-550 -- Loss: 0.19999508559703827
train-epoch-step: 58-551 -- Loss: 0.15226012468338013
train-epoch-step: 58-552 -- Loss: 0.12056059390306473
train-epoch-step: 58-553 -- Loss: 0.18540267646312714
train-epoch-step: 58-554 -- Loss: 0.1886254847049713
train-epoch-step: 58-555 -- Loss: 0.21843221783638
train-epoch-step: 58-556 -- Loss: 0.1389380246400833
train-epoch-step: 58-557 -- Loss: 0.22292590141296387
train-epoch-step: 58-558 -- Loss: 0.22639387845993042
train-epoch-step: 58-559 -- Loss: 0.13094495236873627
train-epoch-step: 58-560 -- Loss: 0.20036394894123077
train-epoch-step: 58-561 -- Loss: 0.17478841543197632
train-epoch-step: 58-562 -- Loss: 0.1576158106327057
train-epoch-step: 58-563 -- Loss: 0.17859908938407898
train-epoch-step: 58-564 -- Loss: 0.09944528341293335
train-epoch-step: 58-565 -- Loss: 0.18001316487789154
train-epoch-step: 58-566 -- Loss: 0.1446782350540161
train-epoch-step: 58-567 -- Loss: 0.20711396634578705
train-epoch-step: 58-568 -- Loss: 0.15686850249767303
train-epoch-step: 58-569 -- Loss: 0.23448604345321655
train-epoch-step: 58-570 -- Loss: 0.16598239541053772
train-epoch-step: 58-571 -- Loss: 0.20625776052474976
train-epoch-step: 58-572 -- Loss: 0.2330089658498764
train-epoch-step: 58-573 -- Loss: 0.19639867544174194
train-epoch-step: 58-574 -- Loss: 0.23112888634204865
train-epoch-step: 58-575 -- Loss: 0.3046722710132599
train-epoch-step: 58-576 -- Loss: 0.11291611939668655
train-epoch-step: 58-577 -- Loss: 0.16393956542015076
train-epoch-step: 58-578 -- Loss: 0.20950961112976074
train-epoch-step: 58-579 -- Loss: 0.16112017631530762
train-epoch-step: 58-580 -- Loss: 0.16801588237285614
train-epoch-step: 58-581 -- Loss: 0.14205579459667206
train-epoch-step: 58-582 -- Loss: 0.20163197815418243
train-epoch-step: 58-583 -- Loss: 0.2086627185344696
train-epoch-step: 58-584 -- Loss: 0.1612740457057953
train-epoch-step: 58-585 -- Loss: 0.18859489262104034
train-epoch-step: 58-586 -- Loss: 0.24794283509254456
train-epoch-step: 58-587 -- Loss: 0.15558168292045593
train-epoch-step: 58-588 -- Loss: 0.12465202808380127
val-epoch-step: 58-589 -- Loss: 0.22811129689216614
val-epoch-step: 58-590 -- Loss: 0.15374413132667542
val-epoch-step: 58-591 -- Loss: 0.2321474850177765
val-epoch-step: 58-592 -- Loss: 0.1725812703371048
val-epoch-step: 58-593 -- Loss: 0.17751239240169525
val-epoch-step: 58-594 -- Loss: 0.4916984438896179
val-epoch-step: 58-595 -- Loss: 0.1754741072654724
val-epoch-step: 58-596 -- Loss: 0.1969813108444214
val-epoch-step: 58-597 -- Loss: 0.17139366269111633
val-epoch-step: 58-598 -- Loss: 0.14490802586078644
val-epoch-step: 58-599 -- Loss: 0.18564192950725555
val-epoch-step: 58-600 -- Loss: 0.1616923213005066
val-epoch-step: 58-601 -- Loss: 0.16059768199920654
val-epoch-step: 58-602 -- Loss: 0.13433793187141418
val-epoch-step: 58-603 -- Loss: 0.1937284916639328
val-epoch-step: 58-604 -- Loss: 0.14600451290607452
val-epoch-step: 58-605 -- Loss: 0.14638635516166687
val-epoch-step: 58-606 -- Loss: 0.24721205234527588
val-epoch-step: 58-607 -- Loss: 0.12317206710577011
val-epoch-step: 58-608 -- Loss: 0.245182067155838
val-epoch-step: 58-609 -- Loss: 0.16372761130332947
val-epoch-step: 58-610 -- Loss: 0.17658983170986176
val-epoch-step: 58-611 -- Loss: 0.15799540281295776
val-epoch-step: 58-612 -- Loss: 0.5015110969543457
val-epoch-step: 58-613 -- Loss: 0.17370373010635376
val-epoch-step: 58-614 -- Loss: 0.1822848618030548
val-epoch-step: 58-615 -- Loss: 0.17304837703704834
val-epoch-step: 58-616 -- Loss: 0.15218478441238403
val-epoch-step: 58-617 -- Loss: 0.18189379572868347
val-epoch-step: 58-618 -- Loss: 0.17732097208499908
val-epoch-step: 58-619 -- Loss: 0.21173007786273956
val-epoch-step: 58-620 -- Loss: 0.13907690346240997
val-epoch-step: 58-621 -- Loss: 0.12519052624702454
val-epoch-step: 58-622 -- Loss: 0.13875430822372437
val-epoch-step: 58-623 -- Loss: 0.14805202186107635
val-epoch-step: 58-624 -- Loss: 0.14689135551452637
val-epoch-step: 58-625 -- Loss: 0.15553231537342072
val-epoch-step: 58-626 -- Loss: 0.14439059793949127
val-epoch-step: 58-627 -- Loss: 0.1866159737110138
val-epoch-step: 58-628 -- Loss: 0.7956032752990723
val-epoch-step: 58-629 -- Loss: 0.20548254251480103
val-epoch-step: 58-630 -- Loss: 0.34014227986335754
val-epoch-step: 58-631 -- Loss: 0.13865327835083008
val-epoch-step: 58-632 -- Loss: 0.20904001593589783
val-epoch-step: 58-633 -- Loss: 0.14513152837753296
val-epoch-step: 58-634 -- Loss: 0.15408267080783844
val-epoch-step: 58-635 -- Loss: 0.11089455336332321
val-epoch-step: 58-636 -- Loss: 0.15507110953330994
val-epoch-step: 58-637 -- Loss: 0.17944124341011047
val-epoch-step: 58-638 -- Loss: 0.1519952416419983
val-epoch-step: 58-639 -- Loss: 0.2492699921131134
val-epoch-step: 58-640 -- Loss: 0.25667715072631836
val-epoch-step: 58-641 -- Loss: 0.12777894735336304
val-epoch-step: 58-642 -- Loss: 0.19886095821857452
val-epoch-step: 58-643 -- Loss: 0.20625349879264832
val-epoch-step: 58-644 -- Loss: 0.1642431616783142
val-epoch-step: 58-645 -- Loss: 0.21410420536994934
val-epoch-step: 58-646 -- Loss: 0.1298052966594696
val-epoch-step: 58-647 -- Loss: 0.12875470519065857
val-epoch-step: 58-648 -- Loss: 0.15189848840236664
val-epoch-step: 58-649 -- Loss: 0.2048427015542984
val-epoch-step: 58-650 -- Loss: 0.2426297813653946
val-epoch-step: 58-651 -- Loss: 0.14387811720371246
val-epoch-step: 58-652 -- Loss: 0.16166368126869202
val-epoch-step: 58-653 -- Loss: 0.24424201250076294
val-epoch-step: 58-654 -- Loss: 0.13416065275669098
Epoch: 58 -- Train Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 59-0 -- Loss: 0.22019150853157043
train-epoch-step: 59-1 -- Loss: 0.1459326595067978
train-epoch-step: 59-2 -- Loss: 0.19169332087039948
train-epoch-step: 59-3 -- Loss: 0.13768287003040314
train-epoch-step: 59-4 -- Loss: 0.15838560461997986
train-epoch-step: 59-5 -- Loss: 0.17067986726760864
train-epoch-step: 59-6 -- Loss: 0.2104799747467041
train-epoch-step: 59-7 -- Loss: 0.1601552963256836
train-epoch-step: 59-8 -- Loss: 0.17563414573669434
train-epoch-step: 59-9 -- Loss: 0.21861940622329712
train-epoch-step: 59-10 -- Loss: 0.1955043375492096
train-epoch-step: 59-11 -- Loss: 0.17675819993019104
train-epoch-step: 59-12 -- Loss: 0.14535114169120789
train-epoch-step: 59-13 -- Loss: 0.173683300614357
train-epoch-step: 59-14 -- Loss: 0.17403492331504822
train-epoch-step: 59-15 -- Loss: 0.15577684342861176
train-epoch-step: 59-16 -- Loss: 0.1663864105939865
train-epoch-step: 59-17 -- Loss: 0.22307056188583374
train-epoch-step: 59-18 -- Loss: 0.18761283159255981
train-epoch-step: 59-19 -- Loss: 0.13255001604557037
train-epoch-step: 59-20 -- Loss: 0.21746277809143066
train-epoch-step: 59-21 -- Loss: 0.23930436372756958
train-epoch-step: 59-22 -- Loss: 0.13877587020397186
train-epoch-step: 59-23 -- Loss: 0.14201773703098297
train-epoch-step: 59-24 -- Loss: 0.12379962205886841
train-epoch-step: 59-25 -- Loss: 0.21772944927215576
train-epoch-step: 59-26 -- Loss: 0.19412121176719666
train-epoch-step: 59-27 -- Loss: 0.21885184943675995
train-epoch-step: 59-28 -- Loss: 0.12323708087205887
train-epoch-step: 59-29 -- Loss: 0.23698690533638
train-epoch-step: 59-30 -- Loss: 0.10630373656749725
train-epoch-step: 59-31 -- Loss: 0.13591144979000092
train-epoch-step: 59-32 -- Loss: 0.1694181114435196
train-epoch-step: 59-33 -- Loss: 0.2721354365348816
train-epoch-step: 59-34 -- Loss: 0.16907775402069092
train-epoch-step: 59-35 -- Loss: 0.23526373505592346
train-epoch-step: 59-36 -- Loss: 0.1359083503484726
train-epoch-step: 59-37 -- Loss: 0.13786739110946655
train-epoch-step: 59-38 -- Loss: 0.1753750592470169
train-epoch-step: 59-39 -- Loss: 0.21406036615371704
train-epoch-step: 59-40 -- Loss: 0.18988153338432312
train-epoch-step: 59-41 -- Loss: 0.20640717446804047
train-epoch-step: 59-42 -- Loss: 0.14385075867176056
train-epoch-step: 59-43 -- Loss: 0.2572880685329437
train-epoch-step: 59-44 -- Loss: 0.13297663629055023
train-epoch-step: 59-45 -- Loss: 0.11389368772506714
train-epoch-step: 59-46 -- Loss: 0.1634443998336792
train-epoch-step: 59-47 -- Loss: 0.2015073150396347
train-epoch-step: 59-48 -- Loss: 0.15014585852622986
train-epoch-step: 59-49 -- Loss: 0.22068440914154053
train-epoch-step: 59-50 -- Loss: 0.10753000527620316
train-epoch-step: 59-51 -- Loss: 0.17415475845336914
train-epoch-step: 59-52 -- Loss: 0.16104766726493835
train-epoch-step: 59-53 -- Loss: 0.20042452216148376
train-epoch-step: 59-54 -- Loss: 0.27685680985450745
train-epoch-step: 59-55 -- Loss: 0.1732955425977707
train-epoch-step: 59-56 -- Loss: 0.17117616534233093
train-epoch-step: 59-57 -- Loss: 0.2289857119321823
train-epoch-step: 59-58 -- Loss: 0.27214545011520386
train-epoch-step: 59-59 -- Loss: 0.22670269012451172
train-epoch-step: 59-60 -- Loss: 0.130039244890213
train-epoch-step: 59-61 -- Loss: 0.19498968124389648
train-epoch-step: 59-62 -- Loss: 0.1825655996799469
train-epoch-step: 59-63 -- Loss: 0.13165859878063202
train-epoch-step: 59-64 -- Loss: 0.14529024064540863
train-epoch-step: 59-65 -- Loss: 0.18410614132881165
train-epoch-step: 59-66 -- Loss: 0.1057116910815239
train-epoch-step: 59-67 -- Loss: 0.12353101372718811
train-epoch-step: 59-68 -- Loss: 0.20080137252807617
train-epoch-step: 59-69 -- Loss: 0.11690147966146469
train-epoch-step: 59-70 -- Loss: 0.21654599905014038
train-epoch-step: 59-71 -- Loss: 0.24969890713691711
train-epoch-step: 59-72 -- Loss: 0.16882404685020447
train-epoch-step: 59-73 -- Loss: 0.20270586013793945
train-epoch-step: 59-74 -- Loss: 0.09264326840639114
train-epoch-step: 59-75 -- Loss: 0.12314532697200775
train-epoch-step: 59-76 -- Loss: 0.14795389771461487
train-epoch-step: 59-77 -- Loss: 0.22722293436527252
train-epoch-step: 59-78 -- Loss: 0.25000444054603577
train-epoch-step: 59-79 -- Loss: 0.1868458241224289
train-epoch-step: 59-80 -- Loss: 0.24884168803691864
train-epoch-step: 59-81 -- Loss: 0.12133461236953735
train-epoch-step: 59-82 -- Loss: 0.24037565290927887
train-epoch-step: 59-83 -- Loss: 0.17188438773155212
train-epoch-step: 59-84 -- Loss: 0.18115991353988647
train-epoch-step: 59-85 -- Loss: 0.170121967792511
train-epoch-step: 59-86 -- Loss: 0.11992021650075912
train-epoch-step: 59-87 -- Loss: 0.20355439186096191
train-epoch-step: 59-88 -- Loss: 0.13619540631771088
train-epoch-step: 59-89 -- Loss: 0.18412064015865326
train-epoch-step: 59-90 -- Loss: 0.18987447023391724
train-epoch-step: 59-91 -- Loss: 0.23429667949676514
train-epoch-step: 59-92 -- Loss: 0.1512434035539627
train-epoch-step: 59-93 -- Loss: 0.16588492691516876
train-epoch-step: 59-94 -- Loss: 0.21301928162574768
train-epoch-step: 59-95 -- Loss: 0.18454723060131073
train-epoch-step: 59-96 -- Loss: 0.20997212827205658
train-epoch-step: 59-97 -- Loss: 0.16900470852851868
train-epoch-step: 59-98 -- Loss: 0.15104269981384277
train-epoch-step: 59-99 -- Loss: 0.17742693424224854
train-epoch-step: 59-100 -- Loss: 0.1857156753540039
train-epoch-step: 59-101 -- Loss: 0.26104801893234253
train-epoch-step: 59-102 -- Loss: 0.21594786643981934
train-epoch-step: 59-103 -- Loss: 0.178540900349617
train-epoch-step: 59-104 -- Loss: 0.14380362629890442
train-epoch-step: 59-105 -- Loss: 0.25400498509407043
train-epoch-step: 59-106 -- Loss: 0.17066043615341187
train-epoch-step: 59-107 -- Loss: 0.18421928584575653
train-epoch-step: 59-108 -- Loss: 0.18257993459701538
train-epoch-step: 59-109 -- Loss: 0.14530415832996368
train-epoch-step: 59-110 -- Loss: 0.17634913325309753
train-epoch-step: 59-111 -- Loss: 0.17720074951648712
train-epoch-step: 59-112 -- Loss: 0.16391102969646454
train-epoch-step: 59-113 -- Loss: 0.15664954483509064
train-epoch-step: 59-114 -- Loss: 0.18908114731311798
train-epoch-step: 59-115 -- Loss: 0.15536417067050934
train-epoch-step: 59-116 -- Loss: 0.13437120616436005
train-epoch-step: 59-117 -- Loss: 0.12500976026058197
train-epoch-step: 59-118 -- Loss: 0.1896442472934723
train-epoch-step: 59-119 -- Loss: 0.1471169888973236
train-epoch-step: 59-120 -- Loss: 0.24210810661315918
train-epoch-step: 59-121 -- Loss: 0.22599785029888153
train-epoch-step: 59-122 -- Loss: 0.20656073093414307
train-epoch-step: 59-123 -- Loss: 0.1990886628627777
train-epoch-step: 59-124 -- Loss: 0.11650247871875763
train-epoch-step: 59-125 -- Loss: 0.15192237496376038
train-epoch-step: 59-126 -- Loss: 0.22126048803329468
train-epoch-step: 59-127 -- Loss: 0.16300071775913239
train-epoch-step: 59-128 -- Loss: 0.16773466765880585
train-epoch-step: 59-129 -- Loss: 0.13791701197624207
train-epoch-step: 59-130 -- Loss: 0.18883708119392395
train-epoch-step: 59-131 -- Loss: 0.1349589228630066
train-epoch-step: 59-132 -- Loss: 0.18574990332126617
train-epoch-step: 59-133 -- Loss: 0.11750397086143494
train-epoch-step: 59-134 -- Loss: 0.18582309782505035
train-epoch-step: 59-135 -- Loss: 0.13252924382686615
train-epoch-step: 59-136 -- Loss: 0.12074612081050873
train-epoch-step: 59-137 -- Loss: 0.23662766814231873
train-epoch-step: 59-138 -- Loss: 0.25498655438423157
train-epoch-step: 59-139 -- Loss: 0.12606683373451233
train-epoch-step: 59-140 -- Loss: 0.19929984211921692
train-epoch-step: 59-141 -- Loss: 0.2244553565979004
train-epoch-step: 59-142 -- Loss: 0.1974857598543167
train-epoch-step: 59-143 -- Loss: 0.16175194084644318
train-epoch-step: 59-144 -- Loss: 0.17599257826805115
train-epoch-step: 59-145 -- Loss: 0.1387011855840683
train-epoch-step: 59-146 -- Loss: 0.18402546644210815
train-epoch-step: 59-147 -- Loss: 0.16160959005355835
train-epoch-step: 59-148 -- Loss: 0.15448756515979767
train-epoch-step: 59-149 -- Loss: 0.11509436368942261
train-epoch-step: 59-150 -- Loss: 0.18323403596878052
train-epoch-step: 59-151 -- Loss: 0.19308589398860931
train-epoch-step: 59-152 -- Loss: 0.18473786115646362
train-epoch-step: 59-153 -- Loss: 0.2654787003993988
train-epoch-step: 59-154 -- Loss: 0.1238754466176033
train-epoch-step: 59-155 -- Loss: 0.1351078748703003
train-epoch-step: 59-156 -- Loss: 0.11965927481651306
train-epoch-step: 59-157 -- Loss: 0.15610484778881073
train-epoch-step: 59-158 -- Loss: 0.16130781173706055
train-epoch-step: 59-159 -- Loss: 0.17216598987579346
train-epoch-step: 59-160 -- Loss: 0.20668911933898926
train-epoch-step: 59-161 -- Loss: 0.19894683361053467
train-epoch-step: 59-162 -- Loss: 0.20358145236968994
train-epoch-step: 59-163 -- Loss: 0.18430911004543304
train-epoch-step: 59-164 -- Loss: 0.18537946045398712
train-epoch-step: 59-165 -- Loss: 0.15620429813861847
train-epoch-step: 59-166 -- Loss: 0.11941800266504288
train-epoch-step: 59-167 -- Loss: 0.11776535212993622
train-epoch-step: 59-168 -- Loss: 0.19603201746940613
train-epoch-step: 59-169 -- Loss: 0.13514766097068787
train-epoch-step: 59-170 -- Loss: 0.19451279938220978
train-epoch-step: 59-171 -- Loss: 0.14150342345237732
train-epoch-step: 59-172 -- Loss: 0.2560289800167084
train-epoch-step: 59-173 -- Loss: 0.13855013251304626
train-epoch-step: 59-174 -- Loss: 0.24213923513889313
train-epoch-step: 59-175 -- Loss: 0.1849939525127411
train-epoch-step: 59-176 -- Loss: 0.13331584632396698
train-epoch-step: 59-177 -- Loss: 0.1735239177942276
train-epoch-step: 59-178 -- Loss: 0.17323827743530273
train-epoch-step: 59-179 -- Loss: 0.1415945142507553
train-epoch-step: 59-180 -- Loss: 0.14716851711273193
train-epoch-step: 59-181 -- Loss: 0.16431888937950134
train-epoch-step: 59-182 -- Loss: 0.18035544455051422
train-epoch-step: 59-183 -- Loss: 0.2635602355003357
train-epoch-step: 59-184 -- Loss: 0.13411329686641693
train-epoch-step: 59-185 -- Loss: 0.1404401957988739
train-epoch-step: 59-186 -- Loss: 0.18165041506290436
train-epoch-step: 59-187 -- Loss: 0.2037861943244934
train-epoch-step: 59-188 -- Loss: 0.17241939902305603
train-epoch-step: 59-189 -- Loss: 0.10052467882633209
train-epoch-step: 59-190 -- Loss: 0.1848849654197693
train-epoch-step: 59-191 -- Loss: 0.153376966714859
train-epoch-step: 59-192 -- Loss: 0.22545547783374786
train-epoch-step: 59-193 -- Loss: 0.19973817467689514
train-epoch-step: 59-194 -- Loss: 0.17855265736579895
train-epoch-step: 59-195 -- Loss: 0.16173101961612701
train-epoch-step: 59-196 -- Loss: 0.1658889800310135
train-epoch-step: 59-197 -- Loss: 0.11984054744243622
train-epoch-step: 59-198 -- Loss: 0.12354257702827454
train-epoch-step: 59-199 -- Loss: 0.14332178235054016
train-epoch-step: 59-200 -- Loss: 0.12129240483045578
train-epoch-step: 59-201 -- Loss: 0.18142655491828918
train-epoch-step: 59-202 -- Loss: 0.1322363018989563
train-epoch-step: 59-203 -- Loss: 0.1700243502855301
train-epoch-step: 59-204 -- Loss: 0.1295127272605896
train-epoch-step: 59-205 -- Loss: 0.18359938263893127
train-epoch-step: 59-206 -- Loss: 0.19694969058036804
train-epoch-step: 59-207 -- Loss: 0.13018794357776642
train-epoch-step: 59-208 -- Loss: 0.1732068806886673
train-epoch-step: 59-209 -- Loss: 0.14291158318519592
train-epoch-step: 59-210 -- Loss: 0.13616697490215302
train-epoch-step: 59-211 -- Loss: 0.19971805810928345
train-epoch-step: 59-212 -- Loss: 0.18975429236888885
train-epoch-step: 59-213 -- Loss: 0.1243189200758934
train-epoch-step: 59-214 -- Loss: 0.1464037150144577
train-epoch-step: 59-215 -- Loss: 0.12424729764461517
train-epoch-step: 59-216 -- Loss: 0.19220806658267975
train-epoch-step: 59-217 -- Loss: 0.210145965218544
train-epoch-step: 59-218 -- Loss: 0.14404979348182678
train-epoch-step: 59-219 -- Loss: 0.16833186149597168
train-epoch-step: 59-220 -- Loss: 0.12468249350786209
train-epoch-step: 59-221 -- Loss: 0.19911815226078033
train-epoch-step: 59-222 -- Loss: 0.1153121292591095
train-epoch-step: 59-223 -- Loss: 0.16940580308437347
train-epoch-step: 59-224 -- Loss: 0.1793440878391266
train-epoch-step: 59-225 -- Loss: 0.2602559030056
train-epoch-step: 59-226 -- Loss: 0.19993630051612854
train-epoch-step: 59-227 -- Loss: 0.21178829669952393
train-epoch-step: 59-228 -- Loss: 0.172568216919899
train-epoch-step: 59-229 -- Loss: 0.1683291494846344
train-epoch-step: 59-230 -- Loss: 0.16021697223186493
train-epoch-step: 59-231 -- Loss: 0.15568265318870544
train-epoch-step: 59-232 -- Loss: 0.17758247256278992
train-epoch-step: 59-233 -- Loss: 0.0810440257191658
train-epoch-step: 59-234 -- Loss: 0.17704010009765625
train-epoch-step: 59-235 -- Loss: 0.13622820377349854
train-epoch-step: 59-236 -- Loss: 0.17250113189220428
train-epoch-step: 59-237 -- Loss: 0.2314440757036209
train-epoch-step: 59-238 -- Loss: 0.1529475450515747
train-epoch-step: 59-239 -- Loss: 0.12135134637355804
train-epoch-step: 59-240 -- Loss: 0.215768501162529
train-epoch-step: 59-241 -- Loss: 0.15096303820610046
train-epoch-step: 59-242 -- Loss: 0.21310405433177948
train-epoch-step: 59-243 -- Loss: 0.22578221559524536
train-epoch-step: 59-244 -- Loss: 0.20251153409481049
train-epoch-step: 59-245 -- Loss: 0.1992642879486084
train-epoch-step: 59-246 -- Loss: 0.21592365205287933
train-epoch-step: 59-247 -- Loss: 0.20870469510555267
train-epoch-step: 59-248 -- Loss: 0.17996256053447723
train-epoch-step: 59-249 -- Loss: 0.13274742662906647
train-epoch-step: 59-250 -- Loss: 0.19289645552635193
train-epoch-step: 59-251 -- Loss: 0.1028265506029129
train-epoch-step: 59-252 -- Loss: 0.19625982642173767
train-epoch-step: 59-253 -- Loss: 0.13819855451583862
train-epoch-step: 59-254 -- Loss: 0.20430457592010498
train-epoch-step: 59-255 -- Loss: 0.14174312353134155
train-epoch-step: 59-256 -- Loss: 0.14800827205181122
train-epoch-step: 59-257 -- Loss: 0.18410630524158478
train-epoch-step: 59-258 -- Loss: 0.1428307294845581
train-epoch-step: 59-259 -- Loss: 0.11186863481998444
train-epoch-step: 59-260 -- Loss: 0.1964525580406189
train-epoch-step: 59-261 -- Loss: 0.1709042638540268
train-epoch-step: 59-262 -- Loss: 0.27582570910453796
train-epoch-step: 59-263 -- Loss: 0.18970899283885956
train-epoch-step: 59-264 -- Loss: 0.16568756103515625
train-epoch-step: 59-265 -- Loss: 0.10699436068534851
train-epoch-step: 59-266 -- Loss: 0.15079396963119507
train-epoch-step: 59-267 -- Loss: 0.12285148352384567
train-epoch-step: 59-268 -- Loss: 0.1126757487654686
train-epoch-step: 59-269 -- Loss: 0.1704307496547699
train-epoch-step: 59-270 -- Loss: 0.10534023493528366
train-epoch-step: 59-271 -- Loss: 0.14481376111507416
train-epoch-step: 59-272 -- Loss: 0.11376507580280304
train-epoch-step: 59-273 -- Loss: 0.12426652759313583
train-epoch-step: 59-274 -- Loss: 0.17379571497440338
train-epoch-step: 59-275 -- Loss: 0.1857539713382721
train-epoch-step: 59-276 -- Loss: 0.15236066281795502
train-epoch-step: 59-277 -- Loss: 0.14896810054779053
train-epoch-step: 59-278 -- Loss: 0.1314474642276764
train-epoch-step: 59-279 -- Loss: 0.1395321935415268
train-epoch-step: 59-280 -- Loss: 0.2115650624036789
train-epoch-step: 59-281 -- Loss: 0.16835710406303406
train-epoch-step: 59-282 -- Loss: 0.136823832988739
train-epoch-step: 59-283 -- Loss: 0.11275895684957504
train-epoch-step: 59-284 -- Loss: 0.13027235865592957
train-epoch-step: 59-285 -- Loss: 0.19726423919200897
train-epoch-step: 59-286 -- Loss: 0.14786002039909363
train-epoch-step: 59-287 -- Loss: 0.20532891154289246
train-epoch-step: 59-288 -- Loss: 0.09258385002613068
train-epoch-step: 59-289 -- Loss: 0.1338798552751541
train-epoch-step: 59-290 -- Loss: 0.1764308661222458
train-epoch-step: 59-291 -- Loss: 0.11344809830188751
train-epoch-step: 59-292 -- Loss: 0.15473562479019165
train-epoch-step: 59-293 -- Loss: 0.1339670866727829
train-epoch-step: 59-294 -- Loss: 0.1534033715724945
train-epoch-step: 59-295 -- Loss: 0.26056724786758423
train-epoch-step: 59-296 -- Loss: 0.1568307727575302
train-epoch-step: 59-297 -- Loss: 0.1708664447069168
train-epoch-step: 59-298 -- Loss: 0.24562349915504456
train-epoch-step: 59-299 -- Loss: 0.1409762054681778
train-epoch-step: 59-300 -- Loss: 0.17037725448608398
train-epoch-step: 59-301 -- Loss: 0.17692367732524872
train-epoch-step: 59-302 -- Loss: 0.21893224120140076
train-epoch-step: 59-303 -- Loss: 0.19629298150539398
train-epoch-step: 59-304 -- Loss: 0.12094983458518982
train-epoch-step: 59-305 -- Loss: 0.14322808384895325
train-epoch-step: 59-306 -- Loss: 0.2094365358352661
train-epoch-step: 59-307 -- Loss: 0.1641930192708969
train-epoch-step: 59-308 -- Loss: 0.21717911958694458
train-epoch-step: 59-309 -- Loss: 0.15410040318965912
train-epoch-step: 59-310 -- Loss: 0.1648869514465332
train-epoch-step: 59-311 -- Loss: 0.16205793619155884
train-epoch-step: 59-312 -- Loss: 0.20095042884349823
train-epoch-step: 59-313 -- Loss: 0.10036802291870117
train-epoch-step: 59-314 -- Loss: 0.1880648136138916
train-epoch-step: 59-315 -- Loss: 0.16931180655956268
train-epoch-step: 59-316 -- Loss: 0.14706628024578094
train-epoch-step: 59-317 -- Loss: 0.14238327741622925
train-epoch-step: 59-318 -- Loss: 0.1746617555618286
train-epoch-step: 59-319 -- Loss: 0.16475790739059448
train-epoch-step: 59-320 -- Loss: 0.1265457570552826
train-epoch-step: 59-321 -- Loss: 0.131081223487854
train-epoch-step: 59-322 -- Loss: 0.2102508395910263
train-epoch-step: 59-323 -- Loss: 0.15988022089004517
train-epoch-step: 59-324 -- Loss: 0.2532583177089691
train-epoch-step: 59-325 -- Loss: 0.15130886435508728
train-epoch-step: 59-326 -- Loss: 0.1648963987827301
train-epoch-step: 59-327 -- Loss: 0.2033897042274475
train-epoch-step: 59-328 -- Loss: 0.21238811314105988
train-epoch-step: 59-329 -- Loss: 0.3390903174877167
train-epoch-step: 59-330 -- Loss: 0.3503907322883606
train-epoch-step: 59-331 -- Loss: 0.21225212514400482
train-epoch-step: 59-332 -- Loss: 0.09897463023662567
train-epoch-step: 59-333 -- Loss: 0.17573560774326324
train-epoch-step: 59-334 -- Loss: 0.152186319231987
train-epoch-step: 59-335 -- Loss: 0.17124928534030914
train-epoch-step: 59-336 -- Loss: 0.14786487817764282
train-epoch-step: 59-337 -- Loss: 0.19460763037204742
train-epoch-step: 59-338 -- Loss: 0.15778563916683197
train-epoch-step: 59-339 -- Loss: 0.13960739970207214
train-epoch-step: 59-340 -- Loss: 0.1883738487958908
train-epoch-step: 59-341 -- Loss: 0.1381596326828003
train-epoch-step: 59-342 -- Loss: 0.15943090617656708
train-epoch-step: 59-343 -- Loss: 0.15074925124645233
train-epoch-step: 59-344 -- Loss: 0.16404350101947784
train-epoch-step: 59-345 -- Loss: 0.12369129061698914
train-epoch-step: 59-346 -- Loss: 0.2001194953918457
train-epoch-step: 59-347 -- Loss: 0.14772352576255798
train-epoch-step: 59-348 -- Loss: 0.2048645317554474
train-epoch-step: 59-349 -- Loss: 0.21205413341522217
train-epoch-step: 59-350 -- Loss: 0.2480143904685974
train-epoch-step: 59-351 -- Loss: 0.18607601523399353
train-epoch-step: 59-352 -- Loss: 0.12536734342575073
train-epoch-step: 59-353 -- Loss: 0.19263829290866852
train-epoch-step: 59-354 -- Loss: 0.2779557704925537
train-epoch-step: 59-355 -- Loss: 0.1218443512916565
train-epoch-step: 59-356 -- Loss: 0.11301033198833466
train-epoch-step: 59-357 -- Loss: 0.182247132062912
train-epoch-step: 59-358 -- Loss: 0.18397796154022217
train-epoch-step: 59-359 -- Loss: 0.14206261932849884
train-epoch-step: 59-360 -- Loss: 0.1212429627776146
train-epoch-step: 59-361 -- Loss: 0.2300354540348053
train-epoch-step: 59-362 -- Loss: 0.16676154732704163
train-epoch-step: 59-363 -- Loss: 0.10581821948289871
train-epoch-step: 59-364 -- Loss: 0.17545440793037415
train-epoch-step: 59-365 -- Loss: 0.1766486018896103
train-epoch-step: 59-366 -- Loss: 0.1959347128868103
train-epoch-step: 59-367 -- Loss: 0.22607675194740295
train-epoch-step: 59-368 -- Loss: 0.19630880653858185
train-epoch-step: 59-369 -- Loss: 0.2786285877227783
train-epoch-step: 59-370 -- Loss: 0.12218575179576874
train-epoch-step: 59-371 -- Loss: 0.11715813726186752
train-epoch-step: 59-372 -- Loss: 0.1425521820783615
train-epoch-step: 59-373 -- Loss: 0.18542292714118958
train-epoch-step: 59-374 -- Loss: 0.15090437233448029
train-epoch-step: 59-375 -- Loss: 0.2624635696411133
train-epoch-step: 59-376 -- Loss: 0.16041778028011322
train-epoch-step: 59-377 -- Loss: 0.22902199625968933
train-epoch-step: 59-378 -- Loss: 0.19641920924186707
train-epoch-step: 59-379 -- Loss: 0.11765426397323608
train-epoch-step: 59-380 -- Loss: 0.09278582781553268
train-epoch-step: 59-381 -- Loss: 0.23785826563835144
train-epoch-step: 59-382 -- Loss: 0.22697055339813232
train-epoch-step: 59-383 -- Loss: 0.17373445630073547
train-epoch-step: 59-384 -- Loss: 0.21808338165283203
train-epoch-step: 59-385 -- Loss: 0.18671557307243347
train-epoch-step: 59-386 -- Loss: 0.22618521749973297
train-epoch-step: 59-387 -- Loss: 0.19411079585552216
train-epoch-step: 59-388 -- Loss: 0.18434172868728638
train-epoch-step: 59-389 -- Loss: 0.21789881587028503
train-epoch-step: 59-390 -- Loss: 0.1474783718585968
train-epoch-step: 59-391 -- Loss: 0.14823639392852783
train-epoch-step: 59-392 -- Loss: 0.18971410393714905
train-epoch-step: 59-393 -- Loss: 0.15676145255565643
train-epoch-step: 59-394 -- Loss: 0.20558150112628937
train-epoch-step: 59-395 -- Loss: 0.1672145277261734
train-epoch-step: 59-396 -- Loss: 0.1262221336364746
train-epoch-step: 59-397 -- Loss: 0.126845121383667
train-epoch-step: 59-398 -- Loss: 0.19195270538330078
train-epoch-step: 59-399 -- Loss: 0.18163931369781494
train-epoch-step: 59-400 -- Loss: 0.27714067697525024
train-epoch-step: 59-401 -- Loss: 0.1247502788901329
train-epoch-step: 59-402 -- Loss: 0.26941564679145813
train-epoch-step: 59-403 -- Loss: 0.15573953092098236
train-epoch-step: 59-404 -- Loss: 0.141577810049057
train-epoch-step: 59-405 -- Loss: 0.14573007822036743
train-epoch-step: 59-406 -- Loss: 0.17361028492450714
train-epoch-step: 59-407 -- Loss: 0.11271727830171585
train-epoch-step: 59-408 -- Loss: 0.16482995450496674
train-epoch-step: 59-409 -- Loss: 0.16836072504520416
train-epoch-step: 59-410 -- Loss: 0.18222379684448242
train-epoch-step: 59-411 -- Loss: 0.20569941401481628
train-epoch-step: 59-412 -- Loss: 0.13235163688659668
train-epoch-step: 59-413 -- Loss: 0.14516986906528473
train-epoch-step: 59-414 -- Loss: 0.1307947039604187
train-epoch-step: 59-415 -- Loss: 0.13396722078323364
train-epoch-step: 59-416 -- Loss: 0.2635546624660492
train-epoch-step: 59-417 -- Loss: 0.19422337412834167
train-epoch-step: 59-418 -- Loss: 0.225136861205101
train-epoch-step: 59-419 -- Loss: 0.18021999299526215
train-epoch-step: 59-420 -- Loss: 0.1505032330751419
train-epoch-step: 59-421 -- Loss: 0.18323585391044617
train-epoch-step: 59-422 -- Loss: 0.14660003781318665
train-epoch-step: 59-423 -- Loss: 0.1719226986169815
train-epoch-step: 59-424 -- Loss: 0.1362636387348175
train-epoch-step: 59-425 -- Loss: 0.18641921877861023
train-epoch-step: 59-426 -- Loss: 0.1657951921224594
train-epoch-step: 59-427 -- Loss: 0.12400396913290024
train-epoch-step: 59-428 -- Loss: 0.18598395586013794
train-epoch-step: 59-429 -- Loss: 0.1754133254289627
train-epoch-step: 59-430 -- Loss: 0.14136981964111328
train-epoch-step: 59-431 -- Loss: 0.16361959278583527
train-epoch-step: 59-432 -- Loss: 0.23996885120868683
train-epoch-step: 59-433 -- Loss: 0.13473549485206604
train-epoch-step: 59-434 -- Loss: 0.12757495045661926
train-epoch-step: 59-435 -- Loss: 0.15286517143249512
train-epoch-step: 59-436 -- Loss: 0.15165488421916962
train-epoch-step: 59-437 -- Loss: 0.12800726294517517
train-epoch-step: 59-438 -- Loss: 0.16371579468250275
train-epoch-step: 59-439 -- Loss: 0.25629720091819763
train-epoch-step: 59-440 -- Loss: 0.1311997026205063
train-epoch-step: 59-441 -- Loss: 0.19704973697662354
train-epoch-step: 59-442 -- Loss: 0.181919664144516
train-epoch-step: 59-443 -- Loss: 0.1598159223794937
train-epoch-step: 59-444 -- Loss: 0.1748942732810974
train-epoch-step: 59-445 -- Loss: 0.17401434481143951
train-epoch-step: 59-446 -- Loss: 0.16347232460975647
train-epoch-step: 59-447 -- Loss: 0.18532772362232208
train-epoch-step: 59-448 -- Loss: 0.22646154463291168
train-epoch-step: 59-449 -- Loss: 0.1951116919517517
train-epoch-step: 59-450 -- Loss: 0.18149268627166748
train-epoch-step: 59-451 -- Loss: 0.1402687132358551
train-epoch-step: 59-452 -- Loss: 0.12642374634742737
train-epoch-step: 59-453 -- Loss: 0.09201764315366745
train-epoch-step: 59-454 -- Loss: 0.2232881784439087
train-epoch-step: 59-455 -- Loss: 0.11973791569471359
train-epoch-step: 59-456 -- Loss: 0.11887071281671524
train-epoch-step: 59-457 -- Loss: 0.21290187537670135
train-epoch-step: 59-458 -- Loss: 0.14159569144248962
train-epoch-step: 59-459 -- Loss: 0.2072468101978302
train-epoch-step: 59-460 -- Loss: 0.1302354484796524
train-epoch-step: 59-461 -- Loss: 0.13378369808197021
train-epoch-step: 59-462 -- Loss: 0.14950749278068542
train-epoch-step: 59-463 -- Loss: 0.13152354955673218
train-epoch-step: 59-464 -- Loss: 0.1570219248533249
train-epoch-step: 59-465 -- Loss: 0.2375517189502716
train-epoch-step: 59-466 -- Loss: 0.1967885047197342
train-epoch-step: 59-467 -- Loss: 0.11163169145584106
train-epoch-step: 59-468 -- Loss: 0.15992504358291626
train-epoch-step: 59-469 -- Loss: 0.20499423146247864
train-epoch-step: 59-470 -- Loss: 0.16589045524597168
train-epoch-step: 59-471 -- Loss: 0.15587085485458374
train-epoch-step: 59-472 -- Loss: 0.15568888187408447
train-epoch-step: 59-473 -- Loss: 0.14839760959148407
train-epoch-step: 59-474 -- Loss: 0.11558902263641357
train-epoch-step: 59-475 -- Loss: 0.10793502628803253
train-epoch-step: 59-476 -- Loss: 0.19679607450962067
train-epoch-step: 59-477 -- Loss: 0.1998133808374405
train-epoch-step: 59-478 -- Loss: 0.18359825015068054
train-epoch-step: 59-479 -- Loss: 0.13354094326496124
train-epoch-step: 59-480 -- Loss: 0.18295808136463165
train-epoch-step: 59-481 -- Loss: 0.2777771055698395
train-epoch-step: 59-482 -- Loss: 0.2430025041103363
train-epoch-step: 59-483 -- Loss: 0.1740594357252121
train-epoch-step: 59-484 -- Loss: 0.21015509963035583
train-epoch-step: 59-485 -- Loss: 0.12220883369445801
train-epoch-step: 59-486 -- Loss: 0.22253207862377167
train-epoch-step: 59-487 -- Loss: 0.22882318496704102
train-epoch-step: 59-488 -- Loss: 0.18493309617042542
train-epoch-step: 59-489 -- Loss: 0.21476104855537415
train-epoch-step: 59-490 -- Loss: 0.1370421051979065
train-epoch-step: 59-491 -- Loss: 0.13262861967086792
train-epoch-step: 59-492 -- Loss: 0.12294542789459229
train-epoch-step: 59-493 -- Loss: 0.19306515157222748
train-epoch-step: 59-494 -- Loss: 0.19969859719276428
train-epoch-step: 59-495 -- Loss: 0.1945117563009262
train-epoch-step: 59-496 -- Loss: 0.13737830519676208
train-epoch-step: 59-497 -- Loss: 0.17523497343063354
train-epoch-step: 59-498 -- Loss: 0.14161236584186554
train-epoch-step: 59-499 -- Loss: 0.16277939081192017
train-epoch-step: 59-500 -- Loss: 0.14789718389511108
train-epoch-step: 59-501 -- Loss: 0.20802044868469238
train-epoch-step: 59-502 -- Loss: 0.15092027187347412
train-epoch-step: 59-503 -- Loss: 0.21163970232009888
train-epoch-step: 59-504 -- Loss: 0.11530262976884842
train-epoch-step: 59-505 -- Loss: 0.16496998071670532
train-epoch-step: 59-506 -- Loss: 0.11072041839361191
train-epoch-step: 59-507 -- Loss: 0.17524999380111694
train-epoch-step: 59-508 -- Loss: 0.17045368254184723
train-epoch-step: 59-509 -- Loss: 0.1607668399810791
train-epoch-step: 59-510 -- Loss: 0.12313614040613174
train-epoch-step: 59-511 -- Loss: 0.20894025266170502
train-epoch-step: 59-512 -- Loss: 0.17076095938682556
train-epoch-step: 59-513 -- Loss: 0.18262995779514313
train-epoch-step: 59-514 -- Loss: 0.14217622578144073
train-epoch-step: 59-515 -- Loss: 0.14846330881118774
train-epoch-step: 59-516 -- Loss: 0.16662578284740448
train-epoch-step: 59-517 -- Loss: 0.170103520154953
train-epoch-step: 59-518 -- Loss: 0.13605502247810364
train-epoch-step: 59-519 -- Loss: 0.1302960067987442
train-epoch-step: 59-520 -- Loss: 0.1843661665916443
train-epoch-step: 59-521 -- Loss: 0.21878360211849213
train-epoch-step: 59-522 -- Loss: 0.1675766110420227
train-epoch-step: 59-523 -- Loss: 0.15257501602172852
train-epoch-step: 59-524 -- Loss: 0.16359245777130127
train-epoch-step: 59-525 -- Loss: 0.18857920169830322
train-epoch-step: 59-526 -- Loss: 0.12398926913738251
train-epoch-step: 59-527 -- Loss: 0.14458659291267395
train-epoch-step: 59-528 -- Loss: 0.15194937586784363
train-epoch-step: 59-529 -- Loss: 0.15272505581378937
train-epoch-step: 59-530 -- Loss: 0.16181713342666626
train-epoch-step: 59-531 -- Loss: 0.18791568279266357
train-epoch-step: 59-532 -- Loss: 0.1623290479183197
train-epoch-step: 59-533 -- Loss: 0.16824232041835785
train-epoch-step: 59-534 -- Loss: 0.12527669966220856
train-epoch-step: 59-535 -- Loss: 0.2399003803730011
train-epoch-step: 59-536 -- Loss: 0.15195465087890625
train-epoch-step: 59-537 -- Loss: 0.14214329421520233
train-epoch-step: 59-538 -- Loss: 0.09819072484970093
train-epoch-step: 59-539 -- Loss: 0.1784789115190506
train-epoch-step: 59-540 -- Loss: 0.1324596405029297
train-epoch-step: 59-541 -- Loss: 0.20220184326171875
train-epoch-step: 59-542 -- Loss: 0.21347731351852417
train-epoch-step: 59-543 -- Loss: 0.16374586522579193
train-epoch-step: 59-544 -- Loss: 0.22715982794761658
train-epoch-step: 59-545 -- Loss: 0.1852876842021942
train-epoch-step: 59-546 -- Loss: 0.19923165440559387
train-epoch-step: 59-547 -- Loss: 0.172455295920372
train-epoch-step: 59-548 -- Loss: 0.08790989220142365
train-epoch-step: 59-549 -- Loss: 0.1424255520105362
train-epoch-step: 59-550 -- Loss: 0.1964152455329895
train-epoch-step: 59-551 -- Loss: 0.15288735926151276
train-epoch-step: 59-552 -- Loss: 0.12132275104522705
train-epoch-step: 59-553 -- Loss: 0.18311786651611328
train-epoch-step: 59-554 -- Loss: 0.18149670958518982
train-epoch-step: 59-555 -- Loss: 0.20868541300296783
train-epoch-step: 59-556 -- Loss: 0.138107568025589
train-epoch-step: 59-557 -- Loss: 0.22965919971466064
train-epoch-step: 59-558 -- Loss: 0.2169506549835205
train-epoch-step: 59-559 -- Loss: 0.1359255313873291
train-epoch-step: 59-560 -- Loss: 0.1980811357498169
train-epoch-step: 59-561 -- Loss: 0.1731131374835968
train-epoch-step: 59-562 -- Loss: 0.1545514166355133
train-epoch-step: 59-563 -- Loss: 0.17876607179641724
train-epoch-step: 59-564 -- Loss: 0.09670430421829224
train-epoch-step: 59-565 -- Loss: 0.17757776379585266
train-epoch-step: 59-566 -- Loss: 0.1438019573688507
train-epoch-step: 59-567 -- Loss: 0.20674452185630798
train-epoch-step: 59-568 -- Loss: 0.15420128405094147
train-epoch-step: 59-569 -- Loss: 0.23560553789138794
train-epoch-step: 59-570 -- Loss: 0.16153523325920105
train-epoch-step: 59-571 -- Loss: 0.20531029999256134
train-epoch-step: 59-572 -- Loss: 0.22913771867752075
train-epoch-step: 59-573 -- Loss: 0.19816854596138
train-epoch-step: 59-574 -- Loss: 0.23466403782367706
train-epoch-step: 59-575 -- Loss: 0.2952245771884918
train-epoch-step: 59-576 -- Loss: 0.11486645042896271
train-epoch-step: 59-577 -- Loss: 0.16150231659412384
train-epoch-step: 59-578 -- Loss: 0.2093842476606369
train-epoch-step: 59-579 -- Loss: 0.16092613339424133
train-epoch-step: 59-580 -- Loss: 0.1734502911567688
train-epoch-step: 59-581 -- Loss: 0.13260072469711304
train-epoch-step: 59-582 -- Loss: 0.2001565843820572
train-epoch-step: 59-583 -- Loss: 0.2071826159954071
train-epoch-step: 59-584 -- Loss: 0.1590489149093628
train-epoch-step: 59-585 -- Loss: 0.18911491334438324
train-epoch-step: 59-586 -- Loss: 0.2443254590034485
train-epoch-step: 59-587 -- Loss: 0.1550833135843277
train-epoch-step: 59-588 -- Loss: 0.12496993690729141
val-epoch-step: 59-589 -- Loss: 0.20528621971607208
val-epoch-step: 59-590 -- Loss: 0.15177004039287567
val-epoch-step: 59-591 -- Loss: 0.23571570217609406
val-epoch-step: 59-592 -- Loss: 0.17295542359352112
val-epoch-step: 59-593 -- Loss: 0.17380204796791077
val-epoch-step: 59-594 -- Loss: 0.3664472699165344
val-epoch-step: 59-595 -- Loss: 0.17703522741794586
val-epoch-step: 59-596 -- Loss: 0.2030714452266693
val-epoch-step: 59-597 -- Loss: 0.17314296960830688
val-epoch-step: 59-598 -- Loss: 0.1435972899198532
val-epoch-step: 59-599 -- Loss: 0.1790432333946228
val-epoch-step: 59-600 -- Loss: 0.15971213579177856
val-epoch-step: 59-601 -- Loss: 0.1610850691795349
val-epoch-step: 59-602 -- Loss: 0.1364758014678955
val-epoch-step: 59-603 -- Loss: 0.2020200788974762
val-epoch-step: 59-604 -- Loss: 0.14259527623653412
val-epoch-step: 59-605 -- Loss: 0.142317533493042
val-epoch-step: 59-606 -- Loss: 0.24787206947803497
val-epoch-step: 59-607 -- Loss: 0.12225668877363205
val-epoch-step: 59-608 -- Loss: 0.23739482462406158
val-epoch-step: 59-609 -- Loss: 0.16077767312526703
val-epoch-step: 59-610 -- Loss: 0.17324009537696838
val-epoch-step: 59-611 -- Loss: 0.1552136391401291
val-epoch-step: 59-612 -- Loss: 0.40112510323524475
val-epoch-step: 59-613 -- Loss: 0.16671450436115265
val-epoch-step: 59-614 -- Loss: 0.16613304615020752
val-epoch-step: 59-615 -- Loss: 0.17293834686279297
val-epoch-step: 59-616 -- Loss: 0.1451110541820526
val-epoch-step: 59-617 -- Loss: 0.1874307543039322
val-epoch-step: 59-618 -- Loss: 0.17747703194618225
val-epoch-step: 59-619 -- Loss: 0.20210684835910797
val-epoch-step: 59-620 -- Loss: 0.12746866047382355
val-epoch-step: 59-621 -- Loss: 0.12279029190540314
val-epoch-step: 59-622 -- Loss: 0.14000560343265533
val-epoch-step: 59-623 -- Loss: 0.14588427543640137
val-epoch-step: 59-624 -- Loss: 0.13803662359714508
val-epoch-step: 59-625 -- Loss: 0.15352025628089905
val-epoch-step: 59-626 -- Loss: 0.14549773931503296
val-epoch-step: 59-627 -- Loss: 0.1852797567844391
val-epoch-step: 59-628 -- Loss: 0.6732472777366638
val-epoch-step: 59-629 -- Loss: 0.22751416265964508
val-epoch-step: 59-630 -- Loss: 0.3338263928890228
val-epoch-step: 59-631 -- Loss: 0.1408618986606598
val-epoch-step: 59-632 -- Loss: 0.1982199251651764
val-epoch-step: 59-633 -- Loss: 0.14773468673229218
val-epoch-step: 59-634 -- Loss: 0.14969715476036072
val-epoch-step: 59-635 -- Loss: 0.11738408356904984
val-epoch-step: 59-636 -- Loss: 0.17802079021930695
val-epoch-step: 59-637 -- Loss: 0.18323880434036255
val-epoch-step: 59-638 -- Loss: 0.15551838278770447
val-epoch-step: 59-639 -- Loss: 0.24772386252880096
val-epoch-step: 59-640 -- Loss: 0.24590879678726196
val-epoch-step: 59-641 -- Loss: 0.12142392992973328
val-epoch-step: 59-642 -- Loss: 0.1767210066318512
val-epoch-step: 59-643 -- Loss: 0.21545886993408203
val-epoch-step: 59-644 -- Loss: 0.17092826962471008
val-epoch-step: 59-645 -- Loss: 0.21352002024650574
val-epoch-step: 59-646 -- Loss: 0.13810569047927856
val-epoch-step: 59-647 -- Loss: 0.12379945814609528
val-epoch-step: 59-648 -- Loss: 0.154494971036911
val-epoch-step: 59-649 -- Loss: 0.1982860416173935
val-epoch-step: 59-650 -- Loss: 0.24911773204803467
val-epoch-step: 59-651 -- Loss: 0.13858695328235626
val-epoch-step: 59-652 -- Loss: 0.1521780788898468
val-epoch-step: 59-653 -- Loss: 0.2087046504020691
val-epoch-step: 59-654 -- Loss: 0.10904879122972488
Epoch: 59 -- Train Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1416, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 60-0 -- Loss: 0.21608179807662964
train-epoch-step: 60-1 -- Loss: 0.14165714383125305
train-epoch-step: 60-2 -- Loss: 0.1931624859571457
train-epoch-step: 60-3 -- Loss: 0.1390390247106552
train-epoch-step: 60-4 -- Loss: 0.15200687944889069
train-epoch-step: 60-5 -- Loss: 0.17555923759937286
train-epoch-step: 60-6 -- Loss: 0.21143242716789246
train-epoch-step: 60-7 -- Loss: 0.159075528383255
train-epoch-step: 60-8 -- Loss: 0.17343966662883759
train-epoch-step: 60-9 -- Loss: 0.21043269336223602
train-epoch-step: 60-10 -- Loss: 0.19616174697875977
train-epoch-step: 60-11 -- Loss: 0.16898435354232788
train-epoch-step: 60-12 -- Loss: 0.14421238005161285
train-epoch-step: 60-13 -- Loss: 0.1733870506286621
train-epoch-step: 60-14 -- Loss: 0.15683908760547638
train-epoch-step: 60-15 -- Loss: 0.15559078752994537
train-epoch-step: 60-16 -- Loss: 0.16144441068172455
train-epoch-step: 60-17 -- Loss: 0.21346263587474823
train-epoch-step: 60-18 -- Loss: 0.18943114578723907
train-epoch-step: 60-19 -- Loss: 0.12944380939006805
train-epoch-step: 60-20 -- Loss: 0.21124552190303802
train-epoch-step: 60-21 -- Loss: 0.23424452543258667
train-epoch-step: 60-22 -- Loss: 0.13621358573436737
train-epoch-step: 60-23 -- Loss: 0.13735713064670563
train-epoch-step: 60-24 -- Loss: 0.12352269887924194
train-epoch-step: 60-25 -- Loss: 0.21919387578964233
train-epoch-step: 60-26 -- Loss: 0.1931842565536499
train-epoch-step: 60-27 -- Loss: 0.2261294424533844
train-epoch-step: 60-28 -- Loss: 0.1258382648229599
train-epoch-step: 60-29 -- Loss: 0.23505568504333496
train-epoch-step: 60-30 -- Loss: 0.10629929602146149
train-epoch-step: 60-31 -- Loss: 0.12875324487686157
train-epoch-step: 60-32 -- Loss: 0.17005398869514465
train-epoch-step: 60-33 -- Loss: 0.2580345571041107
train-epoch-step: 60-34 -- Loss: 0.16353322565555573
train-epoch-step: 60-35 -- Loss: 0.2340720146894455
train-epoch-step: 60-36 -- Loss: 0.1327499896287918
train-epoch-step: 60-37 -- Loss: 0.1339205801486969
train-epoch-step: 60-38 -- Loss: 0.171543687582016
train-epoch-step: 60-39 -- Loss: 0.21089014410972595
train-epoch-step: 60-40 -- Loss: 0.18527339398860931
train-epoch-step: 60-41 -- Loss: 0.20744748413562775
train-epoch-step: 60-42 -- Loss: 0.14480306208133698
train-epoch-step: 60-43 -- Loss: 0.25500616431236267
train-epoch-step: 60-44 -- Loss: 0.12428820133209229
train-epoch-step: 60-45 -- Loss: 0.10910974442958832
train-epoch-step: 60-46 -- Loss: 0.1671464741230011
train-epoch-step: 60-47 -- Loss: 0.195905402302742
train-epoch-step: 60-48 -- Loss: 0.14946813881397247
train-epoch-step: 60-49 -- Loss: 0.22060267627239227
train-epoch-step: 60-50 -- Loss: 0.10672648251056671
train-epoch-step: 60-51 -- Loss: 0.1753484308719635
train-epoch-step: 60-52 -- Loss: 0.15683124959468842
train-epoch-step: 60-53 -- Loss: 0.2020961195230484
train-epoch-step: 60-54 -- Loss: 0.2762435972690582
train-epoch-step: 60-55 -- Loss: 0.16040222346782684
train-epoch-step: 60-56 -- Loss: 0.17495311796665192
train-epoch-step: 60-57 -- Loss: 0.22965608537197113
train-epoch-step: 60-58 -- Loss: 0.27707281708717346
train-epoch-step: 60-59 -- Loss: 0.23561233282089233
train-epoch-step: 60-60 -- Loss: 0.13116063177585602
train-epoch-step: 60-61 -- Loss: 0.19349083304405212
train-epoch-step: 60-62 -- Loss: 0.18375781178474426
train-epoch-step: 60-63 -- Loss: 0.13277918100357056
train-epoch-step: 60-64 -- Loss: 0.13857297599315643
train-epoch-step: 60-65 -- Loss: 0.1817268282175064
train-epoch-step: 60-66 -- Loss: 0.11134731769561768
train-epoch-step: 60-67 -- Loss: 0.12391512095928192
train-epoch-step: 60-68 -- Loss: 0.20208141207695007
train-epoch-step: 60-69 -- Loss: 0.11575762182474136
train-epoch-step: 60-70 -- Loss: 0.21220427751541138
train-epoch-step: 60-71 -- Loss: 0.25090768933296204
train-epoch-step: 60-72 -- Loss: 0.16808201372623444
train-epoch-step: 60-73 -- Loss: 0.19900177419185638
train-epoch-step: 60-74 -- Loss: 0.0936678797006607
train-epoch-step: 60-75 -- Loss: 0.1256519854068756
train-epoch-step: 60-76 -- Loss: 0.14091821014881134
train-epoch-step: 60-77 -- Loss: 0.22086761891841888
train-epoch-step: 60-78 -- Loss: 0.24664254486560822
train-epoch-step: 60-79 -- Loss: 0.17926466464996338
train-epoch-step: 60-80 -- Loss: 0.25787127017974854
train-epoch-step: 60-81 -- Loss: 0.11853472143411636
train-epoch-step: 60-82 -- Loss: 0.2422841489315033
train-epoch-step: 60-83 -- Loss: 0.1713278591632843
train-epoch-step: 60-84 -- Loss: 0.18267546594142914
train-epoch-step: 60-85 -- Loss: 0.1703224927186966
train-epoch-step: 60-86 -- Loss: 0.11684000492095947
train-epoch-step: 60-87 -- Loss: 0.20326483249664307
train-epoch-step: 60-88 -- Loss: 0.13443368673324585
train-epoch-step: 60-89 -- Loss: 0.17994824051856995
train-epoch-step: 60-90 -- Loss: 0.18421587347984314
train-epoch-step: 60-91 -- Loss: 0.2368614822626114
train-epoch-step: 60-92 -- Loss: 0.15104015171527863
train-epoch-step: 60-93 -- Loss: 0.1677391231060028
train-epoch-step: 60-94 -- Loss: 0.2140972763299942
train-epoch-step: 60-95 -- Loss: 0.1851935237646103
train-epoch-step: 60-96 -- Loss: 0.21028585731983185
train-epoch-step: 60-97 -- Loss: 0.17114686965942383
train-epoch-step: 60-98 -- Loss: 0.1524237096309662
train-epoch-step: 60-99 -- Loss: 0.18882758915424347
train-epoch-step: 60-100 -- Loss: 0.1845080703496933
train-epoch-step: 60-101 -- Loss: 0.24871747195720673
train-epoch-step: 60-102 -- Loss: 0.20780031383037567
train-epoch-step: 60-103 -- Loss: 0.18101081252098083
train-epoch-step: 60-104 -- Loss: 0.14857979118824005
train-epoch-step: 60-105 -- Loss: 0.24987609684467316
train-epoch-step: 60-106 -- Loss: 0.17132893204689026
train-epoch-step: 60-107 -- Loss: 0.18002773821353912
train-epoch-step: 60-108 -- Loss: 0.18543916940689087
train-epoch-step: 60-109 -- Loss: 0.1399514228105545
train-epoch-step: 60-110 -- Loss: 0.17513366043567657
train-epoch-step: 60-111 -- Loss: 0.18061316013336182
train-epoch-step: 60-112 -- Loss: 0.16584983468055725
train-epoch-step: 60-113 -- Loss: 0.15634408593177795
train-epoch-step: 60-114 -- Loss: 0.20290692150592804
train-epoch-step: 60-115 -- Loss: 0.15650823712348938
train-epoch-step: 60-116 -- Loss: 0.13459111750125885
train-epoch-step: 60-117 -- Loss: 0.12342818826436996
train-epoch-step: 60-118 -- Loss: 0.18482306599617004
train-epoch-step: 60-119 -- Loss: 0.14682483673095703
train-epoch-step: 60-120 -- Loss: 0.23983487486839294
train-epoch-step: 60-121 -- Loss: 0.23103155195713043
train-epoch-step: 60-122 -- Loss: 0.20620675384998322
train-epoch-step: 60-123 -- Loss: 0.20102038979530334
train-epoch-step: 60-124 -- Loss: 0.1207379624247551
train-epoch-step: 60-125 -- Loss: 0.1492108702659607
train-epoch-step: 60-126 -- Loss: 0.22563761472702026
train-epoch-step: 60-127 -- Loss: 0.1682588756084442
train-epoch-step: 60-128 -- Loss: 0.16646233201026917
train-epoch-step: 60-129 -- Loss: 0.13962820172309875
train-epoch-step: 60-130 -- Loss: 0.18491104245185852
train-epoch-step: 60-131 -- Loss: 0.13238462805747986
train-epoch-step: 60-132 -- Loss: 0.18365633487701416
train-epoch-step: 60-133 -- Loss: 0.1127169206738472
train-epoch-step: 60-134 -- Loss: 0.1935616433620453
train-epoch-step: 60-135 -- Loss: 0.13125908374786377
train-epoch-step: 60-136 -- Loss: 0.12501662969589233
train-epoch-step: 60-137 -- Loss: 0.23882752656936646
train-epoch-step: 60-138 -- Loss: 0.24817122519016266
train-epoch-step: 60-139 -- Loss: 0.12975457310676575
train-epoch-step: 60-140 -- Loss: 0.19869062304496765
train-epoch-step: 60-141 -- Loss: 0.22663213312625885
train-epoch-step: 60-142 -- Loss: 0.19938883185386658
train-epoch-step: 60-143 -- Loss: 0.16260762512683868
train-epoch-step: 60-144 -- Loss: 0.1788214147090912
train-epoch-step: 60-145 -- Loss: 0.13799801468849182
train-epoch-step: 60-146 -- Loss: 0.18488243222236633
train-epoch-step: 60-147 -- Loss: 0.16633158922195435
train-epoch-step: 60-148 -- Loss: 0.15410923957824707
train-epoch-step: 60-149 -- Loss: 0.11533281207084656
train-epoch-step: 60-150 -- Loss: 0.18066106736660004
train-epoch-step: 60-151 -- Loss: 0.18400803208351135
train-epoch-step: 60-152 -- Loss: 0.18445508182048798
train-epoch-step: 60-153 -- Loss: 0.2607578635215759
train-epoch-step: 60-154 -- Loss: 0.1315259486436844
train-epoch-step: 60-155 -- Loss: 0.12987488508224487
train-epoch-step: 60-156 -- Loss: 0.11394908279180527
train-epoch-step: 60-157 -- Loss: 0.1605059802532196
train-epoch-step: 60-158 -- Loss: 0.1638411581516266
train-epoch-step: 60-159 -- Loss: 0.17698507010936737
train-epoch-step: 60-160 -- Loss: 0.20589101314544678
train-epoch-step: 60-161 -- Loss: 0.19678832590579987
train-epoch-step: 60-162 -- Loss: 0.19895672798156738
train-epoch-step: 60-163 -- Loss: 0.18199753761291504
train-epoch-step: 60-164 -- Loss: 0.1880599707365036
train-epoch-step: 60-165 -- Loss: 0.16684553027153015
train-epoch-step: 60-166 -- Loss: 0.11661826819181442
train-epoch-step: 60-167 -- Loss: 0.1173776313662529
train-epoch-step: 60-168 -- Loss: 0.1944759637117386
train-epoch-step: 60-169 -- Loss: 0.132024884223938
train-epoch-step: 60-170 -- Loss: 0.19377194344997406
train-epoch-step: 60-171 -- Loss: 0.13813845813274384
train-epoch-step: 60-172 -- Loss: 0.2543011009693146
train-epoch-step: 60-173 -- Loss: 0.1270512193441391
train-epoch-step: 60-174 -- Loss: 0.2400279939174652
train-epoch-step: 60-175 -- Loss: 0.17877031862735748
train-epoch-step: 60-176 -- Loss: 0.1267271339893341
train-epoch-step: 60-177 -- Loss: 0.1770380139350891
train-epoch-step: 60-178 -- Loss: 0.17186380922794342
train-epoch-step: 60-179 -- Loss: 0.15144357085227966
train-epoch-step: 60-180 -- Loss: 0.14729194343090057
train-epoch-step: 60-181 -- Loss: 0.16260074079036713
train-epoch-step: 60-182 -- Loss: 0.1785743236541748
train-epoch-step: 60-183 -- Loss: 0.26247385144233704
train-epoch-step: 60-184 -- Loss: 0.13232582807540894
train-epoch-step: 60-185 -- Loss: 0.13750699162483215
train-epoch-step: 60-186 -- Loss: 0.17882469296455383
train-epoch-step: 60-187 -- Loss: 0.20560865104198456
train-epoch-step: 60-188 -- Loss: 0.16601301729679108
train-epoch-step: 60-189 -- Loss: 0.10036516189575195
train-epoch-step: 60-190 -- Loss: 0.17761559784412384
train-epoch-step: 60-191 -- Loss: 0.15420043468475342
train-epoch-step: 60-192 -- Loss: 0.2247873842716217
train-epoch-step: 60-193 -- Loss: 0.19630202651023865
train-epoch-step: 60-194 -- Loss: 0.17890501022338867
train-epoch-step: 60-195 -- Loss: 0.15758495032787323
train-epoch-step: 60-196 -- Loss: 0.1643388569355011
train-epoch-step: 60-197 -- Loss: 0.12014217674732208
train-epoch-step: 60-198 -- Loss: 0.12340767681598663
train-epoch-step: 60-199 -- Loss: 0.1412649005651474
train-epoch-step: 60-200 -- Loss: 0.12505418062210083
train-epoch-step: 60-201 -- Loss: 0.1822366863489151
train-epoch-step: 60-202 -- Loss: 0.13710591197013855
train-epoch-step: 60-203 -- Loss: 0.1709955781698227
train-epoch-step: 60-204 -- Loss: 0.1312243491411209
train-epoch-step: 60-205 -- Loss: 0.1758861541748047
train-epoch-step: 60-206 -- Loss: 0.19748002290725708
train-epoch-step: 60-207 -- Loss: 0.1263020634651184
train-epoch-step: 60-208 -- Loss: 0.17817406356334686
train-epoch-step: 60-209 -- Loss: 0.1376369446516037
train-epoch-step: 60-210 -- Loss: 0.13051924109458923
train-epoch-step: 60-211 -- Loss: 0.19916841387748718
train-epoch-step: 60-212 -- Loss: 0.1941150426864624
train-epoch-step: 60-213 -- Loss: 0.12467113137245178
train-epoch-step: 60-214 -- Loss: 0.14470557868480682
train-epoch-step: 60-215 -- Loss: 0.12361163645982742
train-epoch-step: 60-216 -- Loss: 0.19843178987503052
train-epoch-step: 60-217 -- Loss: 0.21065808832645416
train-epoch-step: 60-218 -- Loss: 0.14177154004573822
train-epoch-step: 60-219 -- Loss: 0.17091915011405945
train-epoch-step: 60-220 -- Loss: 0.13517634570598602
train-epoch-step: 60-221 -- Loss: 0.1982704997062683
train-epoch-step: 60-222 -- Loss: 0.11276303231716156
train-epoch-step: 60-223 -- Loss: 0.1684059351682663
train-epoch-step: 60-224 -- Loss: 0.18094570934772491
train-epoch-step: 60-225 -- Loss: 0.2664863169193268
train-epoch-step: 60-226 -- Loss: 0.20097269117832184
train-epoch-step: 60-227 -- Loss: 0.21529076993465424
train-epoch-step: 60-228 -- Loss: 0.17043690383434296
train-epoch-step: 60-229 -- Loss: 0.16918154060840607
train-epoch-step: 60-230 -- Loss: 0.16439485549926758
train-epoch-step: 60-231 -- Loss: 0.15171758830547333
train-epoch-step: 60-232 -- Loss: 0.17754194140434265
train-epoch-step: 60-233 -- Loss: 0.08145590871572495
train-epoch-step: 60-234 -- Loss: 0.17076511681079865
train-epoch-step: 60-235 -- Loss: 0.14622406661510468
train-epoch-step: 60-236 -- Loss: 0.17844341695308685
train-epoch-step: 60-237 -- Loss: 0.22952604293823242
train-epoch-step: 60-238 -- Loss: 0.15754997730255127
train-epoch-step: 60-239 -- Loss: 0.12150400876998901
train-epoch-step: 60-240 -- Loss: 0.21707239747047424
train-epoch-step: 60-241 -- Loss: 0.14941447973251343
train-epoch-step: 60-242 -- Loss: 0.21028468012809753
train-epoch-step: 60-243 -- Loss: 0.23464113473892212
train-epoch-step: 60-244 -- Loss: 0.20162063837051392
train-epoch-step: 60-245 -- Loss: 0.20586538314819336
train-epoch-step: 60-246 -- Loss: 0.21245801448822021
train-epoch-step: 60-247 -- Loss: 0.20417757332324982
train-epoch-step: 60-248 -- Loss: 0.18014651536941528
train-epoch-step: 60-249 -- Loss: 0.13561104238033295
train-epoch-step: 60-250 -- Loss: 0.19321304559707642
train-epoch-step: 60-251 -- Loss: 0.11089613288640976
train-epoch-step: 60-252 -- Loss: 0.18443933129310608
train-epoch-step: 60-253 -- Loss: 0.1362871527671814
train-epoch-step: 60-254 -- Loss: 0.20772264897823334
train-epoch-step: 60-255 -- Loss: 0.14368416368961334
train-epoch-step: 60-256 -- Loss: 0.1463554948568344
train-epoch-step: 60-257 -- Loss: 0.18221928179264069
train-epoch-step: 60-258 -- Loss: 0.1400935798883438
train-epoch-step: 60-259 -- Loss: 0.1099269762635231
train-epoch-step: 60-260 -- Loss: 0.19789119064807892
train-epoch-step: 60-261 -- Loss: 0.1635800004005432
train-epoch-step: 60-262 -- Loss: 0.2780344486236572
train-epoch-step: 60-263 -- Loss: 0.1954730749130249
train-epoch-step: 60-264 -- Loss: 0.1707301139831543
train-epoch-step: 60-265 -- Loss: 0.1056804209947586
train-epoch-step: 60-266 -- Loss: 0.14734967052936554
train-epoch-step: 60-267 -- Loss: 0.12241177260875702
train-epoch-step: 60-268 -- Loss: 0.1140495240688324
train-epoch-step: 60-269 -- Loss: 0.16502201557159424
train-epoch-step: 60-270 -- Loss: 0.10365840792655945
train-epoch-step: 60-271 -- Loss: 0.1438632309436798
train-epoch-step: 60-272 -- Loss: 0.11178797483444214
train-epoch-step: 60-273 -- Loss: 0.12359293550252914
train-epoch-step: 60-274 -- Loss: 0.17550450563430786
train-epoch-step: 60-275 -- Loss: 0.1862076222896576
train-epoch-step: 60-276 -- Loss: 0.15127640962600708
train-epoch-step: 60-277 -- Loss: 0.15047968924045563
train-epoch-step: 60-278 -- Loss: 0.13350100815296173
train-epoch-step: 60-279 -- Loss: 0.13181602954864502
train-epoch-step: 60-280 -- Loss: 0.2047552615404129
train-epoch-step: 60-281 -- Loss: 0.16691257059574127
train-epoch-step: 60-282 -- Loss: 0.13976939022541046
train-epoch-step: 60-283 -- Loss: 0.10987028479576111
train-epoch-step: 60-284 -- Loss: 0.12510143220424652
train-epoch-step: 60-285 -- Loss: 0.18313167989253998
train-epoch-step: 60-286 -- Loss: 0.15115851163864136
train-epoch-step: 60-287 -- Loss: 0.1959293782711029
train-epoch-step: 60-288 -- Loss: 0.0908295214176178
train-epoch-step: 60-289 -- Loss: 0.11945871263742447
train-epoch-step: 60-290 -- Loss: 0.18547585606575012
train-epoch-step: 60-291 -- Loss: 0.11346355825662613
train-epoch-step: 60-292 -- Loss: 0.15527372062206268
train-epoch-step: 60-293 -- Loss: 0.13370376825332642
train-epoch-step: 60-294 -- Loss: 0.15629896521568298
train-epoch-step: 60-295 -- Loss: 0.2561047673225403
train-epoch-step: 60-296 -- Loss: 0.15487885475158691
train-epoch-step: 60-297 -- Loss: 0.17064979672431946
train-epoch-step: 60-298 -- Loss: 0.2271796613931656
train-epoch-step: 60-299 -- Loss: 0.1395874172449112
train-epoch-step: 60-300 -- Loss: 0.1583666056394577
train-epoch-step: 60-301 -- Loss: 0.16542230546474457
train-epoch-step: 60-302 -- Loss: 0.20719940960407257
train-epoch-step: 60-303 -- Loss: 0.20003734529018402
train-epoch-step: 60-304 -- Loss: 0.12158509343862534
train-epoch-step: 60-305 -- Loss: 0.13892579078674316
train-epoch-step: 60-306 -- Loss: 0.21518997848033905
train-epoch-step: 60-307 -- Loss: 0.16008271276950836
train-epoch-step: 60-308 -- Loss: 0.20686942338943481
train-epoch-step: 60-309 -- Loss: 0.15285974740982056
train-epoch-step: 60-310 -- Loss: 0.16051776707172394
train-epoch-step: 60-311 -- Loss: 0.155914768576622
train-epoch-step: 60-312 -- Loss: 0.1983141005039215
train-epoch-step: 60-313 -- Loss: 0.09753741323947906
train-epoch-step: 60-314 -- Loss: 0.18315064907073975
train-epoch-step: 60-315 -- Loss: 0.16934971511363983
train-epoch-step: 60-316 -- Loss: 0.14892160892486572
train-epoch-step: 60-317 -- Loss: 0.13487781584262848
train-epoch-step: 60-318 -- Loss: 0.1558692306280136
train-epoch-step: 60-319 -- Loss: 0.16378626227378845
train-epoch-step: 60-320 -- Loss: 0.11344759166240692
train-epoch-step: 60-321 -- Loss: 0.12737733125686646
train-epoch-step: 60-322 -- Loss: 0.20246455073356628
train-epoch-step: 60-323 -- Loss: 0.162641704082489
train-epoch-step: 60-324 -- Loss: 0.24814730882644653
train-epoch-step: 60-325 -- Loss: 0.14915040135383606
train-epoch-step: 60-326 -- Loss: 0.1645016372203827
train-epoch-step: 60-327 -- Loss: 0.19746313989162445
train-epoch-step: 60-328 -- Loss: 0.18703648447990417
train-epoch-step: 60-329 -- Loss: 0.32862362265586853
train-epoch-step: 60-330 -- Loss: 0.3520791530609131
train-epoch-step: 60-331 -- Loss: 0.20516863465309143
train-epoch-step: 60-332 -- Loss: 0.09857568889856339
train-epoch-step: 60-333 -- Loss: 0.18044888973236084
train-epoch-step: 60-334 -- Loss: 0.15074597299098969
train-epoch-step: 60-335 -- Loss: 0.16624344885349274
train-epoch-step: 60-336 -- Loss: 0.14428585767745972
train-epoch-step: 60-337 -- Loss: 0.20098325610160828
train-epoch-step: 60-338 -- Loss: 0.15643572807312012
train-epoch-step: 60-339 -- Loss: 0.14257946610450745
train-epoch-step: 60-340 -- Loss: 0.1907426416873932
train-epoch-step: 60-341 -- Loss: 0.1383315771818161
train-epoch-step: 60-342 -- Loss: 0.15994268655776978
train-epoch-step: 60-343 -- Loss: 0.1500290334224701
train-epoch-step: 60-344 -- Loss: 0.1615687608718872
train-epoch-step: 60-345 -- Loss: 0.1225930005311966
train-epoch-step: 60-346 -- Loss: 0.19986090064048767
train-epoch-step: 60-347 -- Loss: 0.14890801906585693
train-epoch-step: 60-348 -- Loss: 0.20113389194011688
train-epoch-step: 60-349 -- Loss: 0.19500797986984253
train-epoch-step: 60-350 -- Loss: 0.24698643386363983
train-epoch-step: 60-351 -- Loss: 0.18918977677822113
train-epoch-step: 60-352 -- Loss: 0.12063388526439667
train-epoch-step: 60-353 -- Loss: 0.19160136580467224
train-epoch-step: 60-354 -- Loss: 0.27521756291389465
train-epoch-step: 60-355 -- Loss: 0.11552070826292038
train-epoch-step: 60-356 -- Loss: 0.11226700246334076
train-epoch-step: 60-357 -- Loss: 0.18435275554656982
train-epoch-step: 60-358 -- Loss: 0.18117046356201172
train-epoch-step: 60-359 -- Loss: 0.13663779199123383
train-epoch-step: 60-360 -- Loss: 0.12032178789377213
train-epoch-step: 60-361 -- Loss: 0.23243550956249237
train-epoch-step: 60-362 -- Loss: 0.1645701825618744
train-epoch-step: 60-363 -- Loss: 0.10493241995573044
train-epoch-step: 60-364 -- Loss: 0.17641106247901917
train-epoch-step: 60-365 -- Loss: 0.16534890234470367
train-epoch-step: 60-366 -- Loss: 0.19650641083717346
train-epoch-step: 60-367 -- Loss: 0.22658923268318176
train-epoch-step: 60-368 -- Loss: 0.2007068395614624
train-epoch-step: 60-369 -- Loss: 0.26909157633781433
train-epoch-step: 60-370 -- Loss: 0.12418973445892334
train-epoch-step: 60-371 -- Loss: 0.1178850308060646
train-epoch-step: 60-372 -- Loss: 0.14163324236869812
train-epoch-step: 60-373 -- Loss: 0.17944294214248657
train-epoch-step: 60-374 -- Loss: 0.15151935815811157
train-epoch-step: 60-375 -- Loss: 0.25976717472076416
train-epoch-step: 60-376 -- Loss: 0.15054890513420105
train-epoch-step: 60-377 -- Loss: 0.22211854159832
train-epoch-step: 60-378 -- Loss: 0.19396144151687622
train-epoch-step: 60-379 -- Loss: 0.11775065213441849
train-epoch-step: 60-380 -- Loss: 0.09034652262926102
train-epoch-step: 60-381 -- Loss: 0.2369985729455948
train-epoch-step: 60-382 -- Loss: 0.220512256026268
train-epoch-step: 60-383 -- Loss: 0.1706172376871109
train-epoch-step: 60-384 -- Loss: 0.20901885628700256
train-epoch-step: 60-385 -- Loss: 0.19164103269577026
train-epoch-step: 60-386 -- Loss: 0.1789894998073578
train-epoch-step: 60-387 -- Loss: 0.19649431109428406
train-epoch-step: 60-388 -- Loss: 0.17236296832561493
train-epoch-step: 60-389 -- Loss: 0.1612139493227005
train-epoch-step: 60-390 -- Loss: 0.1418556123971939
train-epoch-step: 60-391 -- Loss: 0.1409449577331543
train-epoch-step: 60-392 -- Loss: 0.18160362541675568
train-epoch-step: 60-393 -- Loss: 0.14908453822135925
train-epoch-step: 60-394 -- Loss: 0.1908147633075714
train-epoch-step: 60-395 -- Loss: 0.15173770487308502
train-epoch-step: 60-396 -- Loss: 0.12332827597856522
train-epoch-step: 60-397 -- Loss: 0.12416693568229675
train-epoch-step: 60-398 -- Loss: 0.19016727805137634
train-epoch-step: 60-399 -- Loss: 0.17054729163646698
train-epoch-step: 60-400 -- Loss: 0.26705044507980347
train-epoch-step: 60-401 -- Loss: 0.11437959223985672
train-epoch-step: 60-402 -- Loss: 0.2516185939311981
train-epoch-step: 60-403 -- Loss: 0.1469205617904663
train-epoch-step: 60-404 -- Loss: 0.13393738865852356
train-epoch-step: 60-405 -- Loss: 0.13628441095352173
train-epoch-step: 60-406 -- Loss: 0.1609373390674591
train-epoch-step: 60-407 -- Loss: 0.1085340604186058
train-epoch-step: 60-408 -- Loss: 0.15710566937923431
train-epoch-step: 60-409 -- Loss: 0.1648518592119217
train-epoch-step: 60-410 -- Loss: 0.1739811897277832
train-epoch-step: 60-411 -- Loss: 0.19204841554164886
train-epoch-step: 60-412 -- Loss: 0.12430469691753387
train-epoch-step: 60-413 -- Loss: 0.142226904630661
train-epoch-step: 60-414 -- Loss: 0.12921607494354248
train-epoch-step: 60-415 -- Loss: 0.12900440394878387
train-epoch-step: 60-416 -- Loss: 0.2601563632488251
train-epoch-step: 60-417 -- Loss: 0.182382270693779
train-epoch-step: 60-418 -- Loss: 0.2172125279903412
train-epoch-step: 60-419 -- Loss: 0.1629294753074646
train-epoch-step: 60-420 -- Loss: 0.14911925792694092
train-epoch-step: 60-421 -- Loss: 0.17228329181671143
train-epoch-step: 60-422 -- Loss: 0.14431266486644745
train-epoch-step: 60-423 -- Loss: 0.16760267317295074
train-epoch-step: 60-424 -- Loss: 0.1346309930086136
train-epoch-step: 60-425 -- Loss: 0.1785717010498047
train-epoch-step: 60-426 -- Loss: 0.1561518907546997
train-epoch-step: 60-427 -- Loss: 0.11587195843458176
train-epoch-step: 60-428 -- Loss: 0.18288962543010712
train-epoch-step: 60-429 -- Loss: 0.17064426839351654
train-epoch-step: 60-430 -- Loss: 0.13676629960536957
train-epoch-step: 60-431 -- Loss: 0.1567719727754593
train-epoch-step: 60-432 -- Loss: 0.23767529428005219
train-epoch-step: 60-433 -- Loss: 0.1298760175704956
train-epoch-step: 60-434 -- Loss: 0.1219988763332367
train-epoch-step: 60-435 -- Loss: 0.1479092687368393
train-epoch-step: 60-436 -- Loss: 0.14884313941001892
train-epoch-step: 60-437 -- Loss: 0.12857770919799805
train-epoch-step: 60-438 -- Loss: 0.16269823908805847
train-epoch-step: 60-439 -- Loss: 0.252484530210495
train-epoch-step: 60-440 -- Loss: 0.1268317997455597
train-epoch-step: 60-441 -- Loss: 0.19542594254016876
train-epoch-step: 60-442 -- Loss: 0.17312940955162048
train-epoch-step: 60-443 -- Loss: 0.14840160310268402
train-epoch-step: 60-444 -- Loss: 0.16820335388183594
train-epoch-step: 60-445 -- Loss: 0.17405156791210175
train-epoch-step: 60-446 -- Loss: 0.1596803218126297
train-epoch-step: 60-447 -- Loss: 0.1868097335100174
train-epoch-step: 60-448 -- Loss: 0.21603943407535553
train-epoch-step: 60-449 -- Loss: 0.18569785356521606
train-epoch-step: 60-450 -- Loss: 0.17736773192882538
train-epoch-step: 60-451 -- Loss: 0.13655710220336914
train-epoch-step: 60-452 -- Loss: 0.12741751968860626
train-epoch-step: 60-453 -- Loss: 0.0886419266462326
train-epoch-step: 60-454 -- Loss: 0.224853515625
train-epoch-step: 60-455 -- Loss: 0.12225958704948425
train-epoch-step: 60-456 -- Loss: 0.1150122657418251
train-epoch-step: 60-457 -- Loss: 0.21108496189117432
train-epoch-step: 60-458 -- Loss: 0.14709994196891785
train-epoch-step: 60-459 -- Loss: 0.21044450998306274
train-epoch-step: 60-460 -- Loss: 0.1216011643409729
train-epoch-step: 60-461 -- Loss: 0.13287943601608276
train-epoch-step: 60-462 -- Loss: 0.15377379953861237
train-epoch-step: 60-463 -- Loss: 0.13117562234401703
train-epoch-step: 60-464 -- Loss: 0.15507034957408905
train-epoch-step: 60-465 -- Loss: 0.23907428979873657
train-epoch-step: 60-466 -- Loss: 0.2014828324317932
train-epoch-step: 60-467 -- Loss: 0.1080518364906311
train-epoch-step: 60-468 -- Loss: 0.15996047854423523
train-epoch-step: 60-469 -- Loss: 0.20368099212646484
train-epoch-step: 60-470 -- Loss: 0.163490429520607
train-epoch-step: 60-471 -- Loss: 0.1550600528717041
train-epoch-step: 60-472 -- Loss: 0.1554805040359497
train-epoch-step: 60-473 -- Loss: 0.14522482454776764
train-epoch-step: 60-474 -- Loss: 0.11454059183597565
train-epoch-step: 60-475 -- Loss: 0.10612168163061142
train-epoch-step: 60-476 -- Loss: 0.19273006916046143
train-epoch-step: 60-477 -- Loss: 0.20661142468452454
train-epoch-step: 60-478 -- Loss: 0.19121375679969788
train-epoch-step: 60-479 -- Loss: 0.14710959792137146
train-epoch-step: 60-480 -- Loss: 0.19062820076942444
train-epoch-step: 60-481 -- Loss: 0.281221866607666
train-epoch-step: 60-482 -- Loss: 0.24758268892765045
train-epoch-step: 60-483 -- Loss: 0.16877280175685883
train-epoch-step: 60-484 -- Loss: 0.20809495449066162
train-epoch-step: 60-485 -- Loss: 0.12291497737169266
train-epoch-step: 60-486 -- Loss: 0.23082122206687927
train-epoch-step: 60-487 -- Loss: 0.22687849402427673
train-epoch-step: 60-488 -- Loss: 0.18731456995010376
train-epoch-step: 60-489 -- Loss: 0.21716687083244324
train-epoch-step: 60-490 -- Loss: 0.1336580067873001
train-epoch-step: 60-491 -- Loss: 0.13372798264026642
train-epoch-step: 60-492 -- Loss: 0.12307440489530563
train-epoch-step: 60-493 -- Loss: 0.19251398742198944
train-epoch-step: 60-494 -- Loss: 0.19489191472530365
train-epoch-step: 60-495 -- Loss: 0.19283327460289001
train-epoch-step: 60-496 -- Loss: 0.1408388912677765
train-epoch-step: 60-497 -- Loss: 0.178078293800354
train-epoch-step: 60-498 -- Loss: 0.14172405004501343
train-epoch-step: 60-499 -- Loss: 0.16115766763687134
train-epoch-step: 60-500 -- Loss: 0.1527790129184723
train-epoch-step: 60-501 -- Loss: 0.20813722908496857
train-epoch-step: 60-502 -- Loss: 0.15234729647636414
train-epoch-step: 60-503 -- Loss: 0.20992453396320343
train-epoch-step: 60-504 -- Loss: 0.11485503613948822
train-epoch-step: 60-505 -- Loss: 0.16721266508102417
train-epoch-step: 60-506 -- Loss: 0.11103608459234238
train-epoch-step: 60-507 -- Loss: 0.1745261400938034
train-epoch-step: 60-508 -- Loss: 0.16915234923362732
train-epoch-step: 60-509 -- Loss: 0.16623279452323914
train-epoch-step: 60-510 -- Loss: 0.12253189086914062
train-epoch-step: 60-511 -- Loss: 0.21510960161685944
train-epoch-step: 60-512 -- Loss: 0.1698511838912964
train-epoch-step: 60-513 -- Loss: 0.17797468602657318
train-epoch-step: 60-514 -- Loss: 0.14546392858028412
train-epoch-step: 60-515 -- Loss: 0.15270797908306122
train-epoch-step: 60-516 -- Loss: 0.1659059077501297
train-epoch-step: 60-517 -- Loss: 0.17068001627922058
train-epoch-step: 60-518 -- Loss: 0.13064797222614288
train-epoch-step: 60-519 -- Loss: 0.12899191677570343
train-epoch-step: 60-520 -- Loss: 0.1816314309835434
train-epoch-step: 60-521 -- Loss: 0.22009524703025818
train-epoch-step: 60-522 -- Loss: 0.1715698391199112
train-epoch-step: 60-523 -- Loss: 0.15416745841503143
train-epoch-step: 60-524 -- Loss: 0.16397832334041595
train-epoch-step: 60-525 -- Loss: 0.1863296926021576
train-epoch-step: 60-526 -- Loss: 0.12531793117523193
train-epoch-step: 60-527 -- Loss: 0.14470456540584564
train-epoch-step: 60-528 -- Loss: 0.1528150588274002
train-epoch-step: 60-529 -- Loss: 0.14756585657596588
train-epoch-step: 60-530 -- Loss: 0.16415415704250336
train-epoch-step: 60-531 -- Loss: 0.19177284836769104
train-epoch-step: 60-532 -- Loss: 0.16306279599666595
train-epoch-step: 60-533 -- Loss: 0.16660478711128235
train-epoch-step: 60-534 -- Loss: 0.12401428073644638
train-epoch-step: 60-535 -- Loss: 0.24835312366485596
train-epoch-step: 60-536 -- Loss: 0.15138858556747437
train-epoch-step: 60-537 -- Loss: 0.1431311070919037
train-epoch-step: 60-538 -- Loss: 0.09892423450946808
train-epoch-step: 60-539 -- Loss: 0.17892412841320038
train-epoch-step: 60-540 -- Loss: 0.13288652896881104
train-epoch-step: 60-541 -- Loss: 0.20245282351970673
train-epoch-step: 60-542 -- Loss: 0.21687091886997223
train-epoch-step: 60-543 -- Loss: 0.1690119355916977
train-epoch-step: 60-544 -- Loss: 0.22170895338058472
train-epoch-step: 60-545 -- Loss: 0.18493522703647614
train-epoch-step: 60-546 -- Loss: 0.2099570631980896
train-epoch-step: 60-547 -- Loss: 0.17286406457424164
train-epoch-step: 60-548 -- Loss: 0.08770547807216644
train-epoch-step: 60-549 -- Loss: 0.1458721160888672
train-epoch-step: 60-550 -- Loss: 0.19418497383594513
train-epoch-step: 60-551 -- Loss: 0.15224044024944305
train-epoch-step: 60-552 -- Loss: 0.1205570250749588
train-epoch-step: 60-553 -- Loss: 0.18019890785217285
train-epoch-step: 60-554 -- Loss: 0.17979367077350616
train-epoch-step: 60-555 -- Loss: 0.20631423592567444
train-epoch-step: 60-556 -- Loss: 0.14011143147945404
train-epoch-step: 60-557 -- Loss: 0.2242887318134308
train-epoch-step: 60-558 -- Loss: 0.2177284061908722
train-epoch-step: 60-559 -- Loss: 0.13212864100933075
train-epoch-step: 60-560 -- Loss: 0.2010093331336975
train-epoch-step: 60-561 -- Loss: 0.16956983506679535
train-epoch-step: 60-562 -- Loss: 0.16296930611133575
train-epoch-step: 60-563 -- Loss: 0.1834031045436859
train-epoch-step: 60-564 -- Loss: 0.09688960015773773
train-epoch-step: 60-565 -- Loss: 0.17939043045043945
train-epoch-step: 60-566 -- Loss: 0.14132964611053467
train-epoch-step: 60-567 -- Loss: 0.20565344393253326
train-epoch-step: 60-568 -- Loss: 0.15559524297714233
train-epoch-step: 60-569 -- Loss: 0.23705093562602997
train-epoch-step: 60-570 -- Loss: 0.16933715343475342
train-epoch-step: 60-571 -- Loss: 0.20142526924610138
train-epoch-step: 60-572 -- Loss: 0.23629184067249298
train-epoch-step: 60-573 -- Loss: 0.1968880295753479
train-epoch-step: 60-574 -- Loss: 0.23485466837882996
train-epoch-step: 60-575 -- Loss: 0.2850228250026703
train-epoch-step: 60-576 -- Loss: 0.11458491533994675
train-epoch-step: 60-577 -- Loss: 0.16150763630867004
train-epoch-step: 60-578 -- Loss: 0.20918026566505432
train-epoch-step: 60-579 -- Loss: 0.16377447545528412
train-epoch-step: 60-580 -- Loss: 0.16823416948318481
train-epoch-step: 60-581 -- Loss: 0.13677841424942017
train-epoch-step: 60-582 -- Loss: 0.19933581352233887
train-epoch-step: 60-583 -- Loss: 0.21612748503684998
train-epoch-step: 60-584 -- Loss: 0.15954557061195374
train-epoch-step: 60-585 -- Loss: 0.18759465217590332
train-epoch-step: 60-586 -- Loss: 0.24656164646148682
train-epoch-step: 60-587 -- Loss: 0.15405017137527466
train-epoch-step: 60-588 -- Loss: 0.12489122152328491
val-epoch-step: 60-589 -- Loss: 0.23159363865852356
val-epoch-step: 60-590 -- Loss: 0.147527813911438
val-epoch-step: 60-591 -- Loss: 0.22863036394119263
val-epoch-step: 60-592 -- Loss: 0.17619289457798004
val-epoch-step: 60-593 -- Loss: 0.17441168427467346
val-epoch-step: 60-594 -- Loss: 0.382229745388031
val-epoch-step: 60-595 -- Loss: 0.2289545238018036
val-epoch-step: 60-596 -- Loss: 0.2023089975118637
val-epoch-step: 60-597 -- Loss: 0.17466238141059875
val-epoch-step: 60-598 -- Loss: 0.14940573275089264
val-epoch-step: 60-599 -- Loss: 0.18909655511379242
val-epoch-step: 60-600 -- Loss: 0.1739969551563263
val-epoch-step: 60-601 -- Loss: 0.15945839881896973
val-epoch-step: 60-602 -- Loss: 0.13116808235645294
val-epoch-step: 60-603 -- Loss: 0.21939973533153534
val-epoch-step: 60-604 -- Loss: 0.14204970002174377
val-epoch-step: 60-605 -- Loss: 0.1422397941350937
val-epoch-step: 60-606 -- Loss: 0.2758687138557434
val-epoch-step: 60-607 -- Loss: 0.12402179837226868
val-epoch-step: 60-608 -- Loss: 0.2396254688501358
val-epoch-step: 60-609 -- Loss: 0.1566597819328308
val-epoch-step: 60-610 -- Loss: 0.18968161940574646
val-epoch-step: 60-611 -- Loss: 0.17092812061309814
val-epoch-step: 60-612 -- Loss: 0.38399970531463623
val-epoch-step: 60-613 -- Loss: 0.1694549322128296
val-epoch-step: 60-614 -- Loss: 0.16484305262565613
val-epoch-step: 60-615 -- Loss: 0.17707566916942596
val-epoch-step: 60-616 -- Loss: 0.1459149569272995
val-epoch-step: 60-617 -- Loss: 0.20468102395534515
val-epoch-step: 60-618 -- Loss: 0.17632392048835754
val-epoch-step: 60-619 -- Loss: 0.21213042736053467
val-epoch-step: 60-620 -- Loss: 0.1351701319217682
val-epoch-step: 60-621 -- Loss: 0.12298069894313812
val-epoch-step: 60-622 -- Loss: 0.14404642581939697
val-epoch-step: 60-623 -- Loss: 0.14640241861343384
val-epoch-step: 60-624 -- Loss: 0.14706116914749146
val-epoch-step: 60-625 -- Loss: 0.1548701673746109
val-epoch-step: 60-626 -- Loss: 0.15045681595802307
val-epoch-step: 60-627 -- Loss: 0.1763332039117813
val-epoch-step: 60-628 -- Loss: 0.6998955011367798
val-epoch-step: 60-629 -- Loss: 0.20203442871570587
val-epoch-step: 60-630 -- Loss: 0.34000012278556824
val-epoch-step: 60-631 -- Loss: 0.15283942222595215
val-epoch-step: 60-632 -- Loss: 0.19457575678825378
val-epoch-step: 60-633 -- Loss: 0.1499793976545334
val-epoch-step: 60-634 -- Loss: 0.15219342708587646
val-epoch-step: 60-635 -- Loss: 0.1160915195941925
val-epoch-step: 60-636 -- Loss: 0.16093486547470093
val-epoch-step: 60-637 -- Loss: 0.17784957587718964
val-epoch-step: 60-638 -- Loss: 0.1583486646413803
val-epoch-step: 60-639 -- Loss: 0.2508457601070404
val-epoch-step: 60-640 -- Loss: 0.24211159348487854
val-epoch-step: 60-641 -- Loss: 0.1440979242324829
val-epoch-step: 60-642 -- Loss: 0.19747623801231384
val-epoch-step: 60-643 -- Loss: 0.19646339118480682
val-epoch-step: 60-644 -- Loss: 0.17069867253303528
val-epoch-step: 60-645 -- Loss: 0.21788378059864044
val-epoch-step: 60-646 -- Loss: 0.15251463651657104
val-epoch-step: 60-647 -- Loss: 0.1275997906923294
val-epoch-step: 60-648 -- Loss: 0.154804989695549
val-epoch-step: 60-649 -- Loss: 0.20362341403961182
val-epoch-step: 60-650 -- Loss: 0.24980171024799347
val-epoch-step: 60-651 -- Loss: 0.1460254192352295
val-epoch-step: 60-652 -- Loss: 0.14975562691688538
val-epoch-step: 60-653 -- Loss: 0.20307499170303345
val-epoch-step: 60-654 -- Loss: 0.1344684213399887
Epoch: 60 -- Train Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 74.27 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 74.27
                         Test Loss: 0.0 -- Test Acc: 74.27
train-epoch-step: 61-0 -- Loss: 0.21688571572303772
train-epoch-step: 61-1 -- Loss: 0.1449740082025528
train-epoch-step: 61-2 -- Loss: 0.18884509801864624
train-epoch-step: 61-3 -- Loss: 0.14983388781547546
train-epoch-step: 61-4 -- Loss: 0.15130218863487244
train-epoch-step: 61-5 -- Loss: 0.18615983426570892
train-epoch-step: 61-6 -- Loss: 0.22337669134140015
train-epoch-step: 61-7 -- Loss: 0.16215790808200836
train-epoch-step: 61-8 -- Loss: 0.18680830299854279
train-epoch-step: 61-9 -- Loss: 0.21707859635353088
train-epoch-step: 61-10 -- Loss: 0.18792599439620972
train-epoch-step: 61-11 -- Loss: 0.16877664625644684
train-epoch-step: 61-12 -- Loss: 0.14648208022117615
train-epoch-step: 61-13 -- Loss: 0.172589972615242
train-epoch-step: 61-14 -- Loss: 0.16274957358837128
train-epoch-step: 61-15 -- Loss: 0.15791937708854675
train-epoch-step: 61-16 -- Loss: 0.15689131617546082
train-epoch-step: 61-17 -- Loss: 0.20618268847465515
train-epoch-step: 61-18 -- Loss: 0.1878570318222046
train-epoch-step: 61-19 -- Loss: 0.1258610635995865
train-epoch-step: 61-20 -- Loss: 0.20775359869003296
train-epoch-step: 61-21 -- Loss: 0.253703773021698
train-epoch-step: 61-22 -- Loss: 0.13357427716255188
train-epoch-step: 61-23 -- Loss: 0.13886097073554993
train-epoch-step: 61-24 -- Loss: 0.1314416080713272
train-epoch-step: 61-25 -- Loss: 0.22976550459861755
train-epoch-step: 61-26 -- Loss: 0.19368082284927368
train-epoch-step: 61-27 -- Loss: 0.23646265268325806
train-epoch-step: 61-28 -- Loss: 0.146323561668396
train-epoch-step: 61-29 -- Loss: 0.23711152374744415
train-epoch-step: 61-30 -- Loss: 0.10830403864383698
train-epoch-step: 61-31 -- Loss: 0.13376271724700928
train-epoch-step: 61-32 -- Loss: 0.17081253230571747
train-epoch-step: 61-33 -- Loss: 0.2637469172477722
train-epoch-step: 61-34 -- Loss: 0.16373488306999207
train-epoch-step: 61-35 -- Loss: 0.23369435966014862
train-epoch-step: 61-36 -- Loss: 0.13772903382778168
train-epoch-step: 61-37 -- Loss: 0.1353224515914917
train-epoch-step: 61-38 -- Loss: 0.17578166723251343
train-epoch-step: 61-39 -- Loss: 0.2121489942073822
train-epoch-step: 61-40 -- Loss: 0.18742519617080688
train-epoch-step: 61-41 -- Loss: 0.20661593973636627
train-epoch-step: 61-42 -- Loss: 0.14676475524902344
train-epoch-step: 61-43 -- Loss: 0.24990913271903992
train-epoch-step: 61-44 -- Loss: 0.12182756513357162
train-epoch-step: 61-45 -- Loss: 0.11675136536359787
train-epoch-step: 61-46 -- Loss: 0.16466598212718964
train-epoch-step: 61-47 -- Loss: 0.19959375262260437
train-epoch-step: 61-48 -- Loss: 0.15398705005645752
train-epoch-step: 61-49 -- Loss: 0.21866732835769653
train-epoch-step: 61-50 -- Loss: 0.10625508427619934
train-epoch-step: 61-51 -- Loss: 0.16945990920066833
train-epoch-step: 61-52 -- Loss: 0.15289466083049774
train-epoch-step: 61-53 -- Loss: 0.20202258229255676
train-epoch-step: 61-54 -- Loss: 0.2782849967479706
train-epoch-step: 61-55 -- Loss: 0.18440884351730347
train-epoch-step: 61-56 -- Loss: 0.17205512523651123
train-epoch-step: 61-57 -- Loss: 0.22918713092803955
train-epoch-step: 61-58 -- Loss: 0.27451959252357483
train-epoch-step: 61-59 -- Loss: 0.2307494878768921
train-epoch-step: 61-60 -- Loss: 0.12434464693069458
train-epoch-step: 61-61 -- Loss: 0.19927610456943512
train-epoch-step: 61-62 -- Loss: 0.18102578818798065
train-epoch-step: 61-63 -- Loss: 0.14818799495697021
train-epoch-step: 61-64 -- Loss: 0.13799011707305908
train-epoch-step: 61-65 -- Loss: 0.17710958421230316
train-epoch-step: 61-66 -- Loss: 0.11007556319236755
train-epoch-step: 61-67 -- Loss: 0.12078353762626648
train-epoch-step: 61-68 -- Loss: 0.20585113763809204
train-epoch-step: 61-69 -- Loss: 0.11966469138860703
train-epoch-step: 61-70 -- Loss: 0.20954029262065887
train-epoch-step: 61-71 -- Loss: 0.25291872024536133
train-epoch-step: 61-72 -- Loss: 0.17092902958393097
train-epoch-step: 61-73 -- Loss: 0.20443832874298096
train-epoch-step: 61-74 -- Loss: 0.09510955214500427
train-epoch-step: 61-75 -- Loss: 0.12738433480262756
train-epoch-step: 61-76 -- Loss: 0.14165714383125305
train-epoch-step: 61-77 -- Loss: 0.22367656230926514
train-epoch-step: 61-78 -- Loss: 0.24982500076293945
train-epoch-step: 61-79 -- Loss: 0.18966758251190186
train-epoch-step: 61-80 -- Loss: 0.23597221076488495
train-epoch-step: 61-81 -- Loss: 0.12329620867967606
train-epoch-step: 61-82 -- Loss: 0.23774074018001556
train-epoch-step: 61-83 -- Loss: 0.17425237596035004
train-epoch-step: 61-84 -- Loss: 0.18623177707195282
train-epoch-step: 61-85 -- Loss: 0.17001110315322876
train-epoch-step: 61-86 -- Loss: 0.11860053241252899
train-epoch-step: 61-87 -- Loss: 0.19971366226673126
train-epoch-step: 61-88 -- Loss: 0.13554047048091888
train-epoch-step: 61-89 -- Loss: 0.18085968494415283
train-epoch-step: 61-90 -- Loss: 0.1874934434890747
train-epoch-step: 61-91 -- Loss: 0.23871326446533203
train-epoch-step: 61-92 -- Loss: 0.14999903738498688
train-epoch-step: 61-93 -- Loss: 0.17187994718551636
train-epoch-step: 61-94 -- Loss: 0.21501684188842773
train-epoch-step: 61-95 -- Loss: 0.18468859791755676
train-epoch-step: 61-96 -- Loss: 0.2111434042453766
train-epoch-step: 61-97 -- Loss: 0.17893151938915253
train-epoch-step: 61-98 -- Loss: 0.1544940173625946
train-epoch-step: 61-99 -- Loss: 0.17839688062667847
train-epoch-step: 61-100 -- Loss: 0.1838291585445404
train-epoch-step: 61-101 -- Loss: 0.24913594126701355
train-epoch-step: 61-102 -- Loss: 0.2107565701007843
train-epoch-step: 61-103 -- Loss: 0.17826907336711884
train-epoch-step: 61-104 -- Loss: 0.14512109756469727
train-epoch-step: 61-105 -- Loss: 0.27370983362197876
train-epoch-step: 61-106 -- Loss: 0.1757461428642273
train-epoch-step: 61-107 -- Loss: 0.18505758047103882
train-epoch-step: 61-108 -- Loss: 0.18304860591888428
train-epoch-step: 61-109 -- Loss: 0.1510368138551712
train-epoch-step: 61-110 -- Loss: 0.17915242910385132
train-epoch-step: 61-111 -- Loss: 0.18068529665470123
train-epoch-step: 61-112 -- Loss: 0.15935161709785461
train-epoch-step: 61-113 -- Loss: 0.15602782368659973
train-epoch-step: 61-114 -- Loss: 0.18984873592853546
train-epoch-step: 61-115 -- Loss: 0.15357182919979095
train-epoch-step: 61-116 -- Loss: 0.13580700755119324
train-epoch-step: 61-117 -- Loss: 0.12642747163772583
train-epoch-step: 61-118 -- Loss: 0.18800117075443268
train-epoch-step: 61-119 -- Loss: 0.14711536467075348
train-epoch-step: 61-120 -- Loss: 0.24211053550243378
train-epoch-step: 61-121 -- Loss: 0.22405654191970825
train-epoch-step: 61-122 -- Loss: 0.20766523480415344
train-epoch-step: 61-123 -- Loss: 0.1981842964887619
train-epoch-step: 61-124 -- Loss: 0.11720231175422668
train-epoch-step: 61-125 -- Loss: 0.15056702494621277
train-epoch-step: 61-126 -- Loss: 0.22501710057258606
train-epoch-step: 61-127 -- Loss: 0.16042928397655487
train-epoch-step: 61-128 -- Loss: 0.16738349199295044
train-epoch-step: 61-129 -- Loss: 0.139968603849411
train-epoch-step: 61-130 -- Loss: 0.18781757354736328
train-epoch-step: 61-131 -- Loss: 0.13165009021759033
train-epoch-step: 61-132 -- Loss: 0.1850912719964981
train-epoch-step: 61-133 -- Loss: 0.11034718155860901
train-epoch-step: 61-134 -- Loss: 0.1886301338672638
train-epoch-step: 61-135 -- Loss: 0.12817446887493134
train-epoch-step: 61-136 -- Loss: 0.12172339111566544
train-epoch-step: 61-137 -- Loss: 0.23997363448143005
train-epoch-step: 61-138 -- Loss: 0.25389769673347473
train-epoch-step: 61-139 -- Loss: 0.12785637378692627
train-epoch-step: 61-140 -- Loss: 0.20065754652023315
train-epoch-step: 61-141 -- Loss: 0.2275811731815338
train-epoch-step: 61-142 -- Loss: 0.1973538100719452
train-epoch-step: 61-143 -- Loss: 0.16637420654296875
train-epoch-step: 61-144 -- Loss: 0.18129262328147888
train-epoch-step: 61-145 -- Loss: 0.13551202416419983
train-epoch-step: 61-146 -- Loss: 0.1747533679008484
train-epoch-step: 61-147 -- Loss: 0.16104115545749664
train-epoch-step: 61-148 -- Loss: 0.1554999202489853
train-epoch-step: 61-149 -- Loss: 0.11541925370693207
train-epoch-step: 61-150 -- Loss: 0.18470074236392975
train-epoch-step: 61-151 -- Loss: 0.1839134246110916
train-epoch-step: 61-152 -- Loss: 0.19011127948760986
train-epoch-step: 61-153 -- Loss: 0.2548443675041199
train-epoch-step: 61-154 -- Loss: 0.12563800811767578
train-epoch-step: 61-155 -- Loss: 0.13227081298828125
train-epoch-step: 61-156 -- Loss: 0.11413607001304626
train-epoch-step: 61-157 -- Loss: 0.1553245186805725
train-epoch-step: 61-158 -- Loss: 0.16166573762893677
train-epoch-step: 61-159 -- Loss: 0.17581436038017273
train-epoch-step: 61-160 -- Loss: 0.20335470139980316
train-epoch-step: 61-161 -- Loss: 0.19913098216056824
train-epoch-step: 61-162 -- Loss: 0.20339983701705933
train-epoch-step: 61-163 -- Loss: 0.18812403082847595
train-epoch-step: 61-164 -- Loss: 0.18702146410942078
train-epoch-step: 61-165 -- Loss: 0.16032248735427856
train-epoch-step: 61-166 -- Loss: 0.11869253218173981
train-epoch-step: 61-167 -- Loss: 0.11974334716796875
train-epoch-step: 61-168 -- Loss: 0.19481486082077026
train-epoch-step: 61-169 -- Loss: 0.1325722187757492
train-epoch-step: 61-170 -- Loss: 0.19824044406414032
train-epoch-step: 61-171 -- Loss: 0.14386723935604095
train-epoch-step: 61-172 -- Loss: 0.25050824880599976
train-epoch-step: 61-173 -- Loss: 0.12780006229877472
train-epoch-step: 61-174 -- Loss: 0.23823560774326324
train-epoch-step: 61-175 -- Loss: 0.18275105953216553
train-epoch-step: 61-176 -- Loss: 0.12830227613449097
train-epoch-step: 61-177 -- Loss: 0.17372678220272064
train-epoch-step: 61-178 -- Loss: 0.17381851375102997
train-epoch-step: 61-179 -- Loss: 0.1509881466627121
train-epoch-step: 61-180 -- Loss: 0.15077370405197144
train-epoch-step: 61-181 -- Loss: 0.16610266268253326
train-epoch-step: 61-182 -- Loss: 0.17417509853839874
train-epoch-step: 61-183 -- Loss: 0.264066606760025
train-epoch-step: 61-184 -- Loss: 0.1330459713935852
train-epoch-step: 61-185 -- Loss: 0.14090251922607422
train-epoch-step: 61-186 -- Loss: 0.17940622568130493
train-epoch-step: 61-187 -- Loss: 0.20086002349853516
train-epoch-step: 61-188 -- Loss: 0.167012020945549
train-epoch-step: 61-189 -- Loss: 0.10459905862808228
train-epoch-step: 61-190 -- Loss: 0.1774405539035797
train-epoch-step: 61-191 -- Loss: 0.15371254086494446
train-epoch-step: 61-192 -- Loss: 0.21994444727897644
train-epoch-step: 61-193 -- Loss: 0.1972189098596573
train-epoch-step: 61-194 -- Loss: 0.17460080981254578
train-epoch-step: 61-195 -- Loss: 0.16393665969371796
train-epoch-step: 61-196 -- Loss: 0.16188642382621765
train-epoch-step: 61-197 -- Loss: 0.1357661783695221
train-epoch-step: 61-198 -- Loss: 0.12217798829078674
train-epoch-step: 61-199 -- Loss: 0.14023944735527039
train-epoch-step: 61-200 -- Loss: 0.1225745677947998
train-epoch-step: 61-201 -- Loss: 0.1815612018108368
train-epoch-step: 61-202 -- Loss: 0.13283586502075195
train-epoch-step: 61-203 -- Loss: 0.1656213104724884
train-epoch-step: 61-204 -- Loss: 0.1278832107782364
train-epoch-step: 61-205 -- Loss: 0.1788984090089798
train-epoch-step: 61-206 -- Loss: 0.1970335990190506
train-epoch-step: 61-207 -- Loss: 0.12753362953662872
train-epoch-step: 61-208 -- Loss: 0.1754164844751358
train-epoch-step: 61-209 -- Loss: 0.13861456513404846
train-epoch-step: 61-210 -- Loss: 0.12895208597183228
train-epoch-step: 61-211 -- Loss: 0.19451086223125458
train-epoch-step: 61-212 -- Loss: 0.1966310292482376
train-epoch-step: 61-213 -- Loss: 0.12438853085041046
train-epoch-step: 61-214 -- Loss: 0.1458565592765808
train-epoch-step: 61-215 -- Loss: 0.12277253717184067
train-epoch-step: 61-216 -- Loss: 0.19183291494846344
train-epoch-step: 61-217 -- Loss: 0.20101378858089447
train-epoch-step: 61-218 -- Loss: 0.13883963227272034
train-epoch-step: 61-219 -- Loss: 0.16123366355895996
train-epoch-step: 61-220 -- Loss: 0.12581665813922882
train-epoch-step: 61-221 -- Loss: 0.2067858725786209
train-epoch-step: 61-222 -- Loss: 0.11439421027898788
train-epoch-step: 61-223 -- Loss: 0.16922882199287415
train-epoch-step: 61-224 -- Loss: 0.18100886046886444
train-epoch-step: 61-225 -- Loss: 0.26105284690856934
train-epoch-step: 61-226 -- Loss: 0.19981181621551514
train-epoch-step: 61-227 -- Loss: 0.2132391780614853
train-epoch-step: 61-228 -- Loss: 0.1704225391149521
train-epoch-step: 61-229 -- Loss: 0.16834557056427002
train-epoch-step: 61-230 -- Loss: 0.15902191400527954
train-epoch-step: 61-231 -- Loss: 0.15546900033950806
train-epoch-step: 61-232 -- Loss: 0.18013715744018555
train-epoch-step: 61-233 -- Loss: 0.08275127410888672
train-epoch-step: 61-234 -- Loss: 0.17147032916545868
train-epoch-step: 61-235 -- Loss: 0.1394827663898468
train-epoch-step: 61-236 -- Loss: 0.1770428568124771
train-epoch-step: 61-237 -- Loss: 0.2281324565410614
train-epoch-step: 61-238 -- Loss: 0.15044288337230682
train-epoch-step: 61-239 -- Loss: 0.12216787040233612
train-epoch-step: 61-240 -- Loss: 0.2142467349767685
train-epoch-step: 61-241 -- Loss: 0.14992445707321167
train-epoch-step: 61-242 -- Loss: 0.21296417713165283
train-epoch-step: 61-243 -- Loss: 0.22519831359386444
train-epoch-step: 61-244 -- Loss: 0.20288103818893433
train-epoch-step: 61-245 -- Loss: 0.1983359307050705
train-epoch-step: 61-246 -- Loss: 0.21015851199626923
train-epoch-step: 61-247 -- Loss: 0.2026195228099823
train-epoch-step: 61-248 -- Loss: 0.18289372324943542
train-epoch-step: 61-249 -- Loss: 0.135537788271904
train-epoch-step: 61-250 -- Loss: 0.190914586186409
train-epoch-step: 61-251 -- Loss: 0.10578876733779907
train-epoch-step: 61-252 -- Loss: 0.18963854014873505
train-epoch-step: 61-253 -- Loss: 0.13153885304927826
train-epoch-step: 61-254 -- Loss: 0.20658627152442932
train-epoch-step: 61-255 -- Loss: 0.14540348947048187
train-epoch-step: 61-256 -- Loss: 0.1455937623977661
train-epoch-step: 61-257 -- Loss: 0.1821688711643219
train-epoch-step: 61-258 -- Loss: 0.14190560579299927
train-epoch-step: 61-259 -- Loss: 0.11111556738615036
train-epoch-step: 61-260 -- Loss: 0.19341354072093964
train-epoch-step: 61-261 -- Loss: 0.1750432550907135
train-epoch-step: 61-262 -- Loss: 0.2788173258304596
train-epoch-step: 61-263 -- Loss: 0.19490140676498413
train-epoch-step: 61-264 -- Loss: 0.16789136826992035
train-epoch-step: 61-265 -- Loss: 0.10310457646846771
train-epoch-step: 61-266 -- Loss: 0.14890463650226593
train-epoch-step: 61-267 -- Loss: 0.12545567750930786
train-epoch-step: 61-268 -- Loss: 0.11397933959960938
train-epoch-step: 61-269 -- Loss: 0.16900181770324707
train-epoch-step: 61-270 -- Loss: 0.10300908237695694
train-epoch-step: 61-271 -- Loss: 0.14741234481334686
train-epoch-step: 61-272 -- Loss: 0.11267301440238953
train-epoch-step: 61-273 -- Loss: 0.12210586667060852
train-epoch-step: 61-274 -- Loss: 0.1755220890045166
train-epoch-step: 61-275 -- Loss: 0.1797223687171936
train-epoch-step: 61-276 -- Loss: 0.1503068506717682
train-epoch-step: 61-277 -- Loss: 0.15145665407180786
train-epoch-step: 61-278 -- Loss: 0.13374251127243042
train-epoch-step: 61-279 -- Loss: 0.13465088605880737
train-epoch-step: 61-280 -- Loss: 0.2059360295534134
train-epoch-step: 61-281 -- Loss: 0.17024081945419312
train-epoch-step: 61-282 -- Loss: 0.1373966932296753
train-epoch-step: 61-283 -- Loss: 0.11119528114795685
train-epoch-step: 61-284 -- Loss: 0.13218361139297485
train-epoch-step: 61-285 -- Loss: 0.1871601641178131
train-epoch-step: 61-286 -- Loss: 0.15225613117218018
train-epoch-step: 61-287 -- Loss: 0.19230680167675018
train-epoch-step: 61-288 -- Loss: 0.09218601882457733
train-epoch-step: 61-289 -- Loss: 0.11818937212228775
train-epoch-step: 61-290 -- Loss: 0.17364829778671265
train-epoch-step: 61-291 -- Loss: 0.1140744760632515
train-epoch-step: 61-292 -- Loss: 0.15384571254253387
train-epoch-step: 61-293 -- Loss: 0.134322851896286
train-epoch-step: 61-294 -- Loss: 0.15489187836647034
train-epoch-step: 61-295 -- Loss: 0.2516780197620392
train-epoch-step: 61-296 -- Loss: 0.1520889550447464
train-epoch-step: 61-297 -- Loss: 0.17030823230743408
train-epoch-step: 61-298 -- Loss: 0.22345604002475739
train-epoch-step: 61-299 -- Loss: 0.14123313128948212
train-epoch-step: 61-300 -- Loss: 0.15507853031158447
train-epoch-step: 61-301 -- Loss: 0.16386078298091888
train-epoch-step: 61-302 -- Loss: 0.21092739701271057
train-epoch-step: 61-303 -- Loss: 0.19228848814964294
train-epoch-step: 61-304 -- Loss: 0.11910291016101837
train-epoch-step: 61-305 -- Loss: 0.14432558417320251
train-epoch-step: 61-306 -- Loss: 0.21373765170574188
train-epoch-step: 61-307 -- Loss: 0.1602703332901001
train-epoch-step: 61-308 -- Loss: 0.21065163612365723
train-epoch-step: 61-309 -- Loss: 0.1499873399734497
train-epoch-step: 61-310 -- Loss: 0.15954023599624634
train-epoch-step: 61-311 -- Loss: 0.15273885428905487
train-epoch-step: 61-312 -- Loss: 0.19795003533363342
train-epoch-step: 61-313 -- Loss: 0.09571605175733566
train-epoch-step: 61-314 -- Loss: 0.18375323712825775
train-epoch-step: 61-315 -- Loss: 0.1663111001253128
train-epoch-step: 61-316 -- Loss: 0.1458970606327057
train-epoch-step: 61-317 -- Loss: 0.13427133858203888
train-epoch-step: 61-318 -- Loss: 0.15371760725975037
train-epoch-step: 61-319 -- Loss: 0.15907903015613556
train-epoch-step: 61-320 -- Loss: 0.11445820331573486
train-epoch-step: 61-321 -- Loss: 0.12856075167655945
train-epoch-step: 61-322 -- Loss: 0.20393837988376617
train-epoch-step: 61-323 -- Loss: 0.15269118547439575
train-epoch-step: 61-324 -- Loss: 0.24683605134487152
train-epoch-step: 61-325 -- Loss: 0.15017399191856384
train-epoch-step: 61-326 -- Loss: 0.16402024030685425
train-epoch-step: 61-327 -- Loss: 0.21604950726032257
train-epoch-step: 61-328 -- Loss: 0.18859359622001648
train-epoch-step: 61-329 -- Loss: 0.32791683077812195
train-epoch-step: 61-330 -- Loss: 0.35307636857032776
train-epoch-step: 61-331 -- Loss: 0.20119145512580872
train-epoch-step: 61-332 -- Loss: 0.0945868194103241
train-epoch-step: 61-333 -- Loss: 0.17672313749790192
train-epoch-step: 61-334 -- Loss: 0.1485230028629303
train-epoch-step: 61-335 -- Loss: 0.16885195672512054
train-epoch-step: 61-336 -- Loss: 0.14089158177375793
train-epoch-step: 61-337 -- Loss: 0.1959730088710785
train-epoch-step: 61-338 -- Loss: 0.1534847617149353
train-epoch-step: 61-339 -- Loss: 0.1372465342283249
train-epoch-step: 61-340 -- Loss: 0.18648721277713776
train-epoch-step: 61-341 -- Loss: 0.13650135695934296
train-epoch-step: 61-342 -- Loss: 0.16047878563404083
train-epoch-step: 61-343 -- Loss: 0.14903298020362854
train-epoch-step: 61-344 -- Loss: 0.15695124864578247
train-epoch-step: 61-345 -- Loss: 0.1229313537478447
train-epoch-step: 61-346 -- Loss: 0.18860816955566406
train-epoch-step: 61-347 -- Loss: 0.14871671795845032
train-epoch-step: 61-348 -- Loss: 0.19329997897148132
train-epoch-step: 61-349 -- Loss: 0.19599810242652893
train-epoch-step: 61-350 -- Loss: 0.242618128657341
train-epoch-step: 61-351 -- Loss: 0.18781664967536926
train-epoch-step: 61-352 -- Loss: 0.12292658537626266
train-epoch-step: 61-353 -- Loss: 0.1873692125082016
train-epoch-step: 61-354 -- Loss: 0.27166804671287537
train-epoch-step: 61-355 -- Loss: 0.11268562078475952
train-epoch-step: 61-356 -- Loss: 0.11249091476202011
train-epoch-step: 61-357 -- Loss: 0.1838330328464508
train-epoch-step: 61-358 -- Loss: 0.1845576912164688
train-epoch-step: 61-359 -- Loss: 0.1346001923084259
train-epoch-step: 61-360 -- Loss: 0.11892102658748627
train-epoch-step: 61-361 -- Loss: 0.2277757227420807
train-epoch-step: 61-362 -- Loss: 0.16378839313983917
train-epoch-step: 61-363 -- Loss: 0.1043015792965889
train-epoch-step: 61-364 -- Loss: 0.1753452718257904
train-epoch-step: 61-365 -- Loss: 0.16549110412597656
train-epoch-step: 61-366 -- Loss: 0.1965329796075821
train-epoch-step: 61-367 -- Loss: 0.2346438467502594
train-epoch-step: 61-368 -- Loss: 0.1910811811685562
train-epoch-step: 61-369 -- Loss: 0.27307063341140747
train-epoch-step: 61-370 -- Loss: 0.12026285380125046
train-epoch-step: 61-371 -- Loss: 0.11724714189767838
train-epoch-step: 61-372 -- Loss: 0.14047151803970337
train-epoch-step: 61-373 -- Loss: 0.1810120791196823
train-epoch-step: 61-374 -- Loss: 0.1480311006307602
train-epoch-step: 61-375 -- Loss: 0.2567189037799835
train-epoch-step: 61-376 -- Loss: 0.16002057492733002
train-epoch-step: 61-377 -- Loss: 0.21772107481956482
train-epoch-step: 61-378 -- Loss: 0.19513002038002014
train-epoch-step: 61-379 -- Loss: 0.1142248660326004
train-epoch-step: 61-380 -- Loss: 0.0875256359577179
train-epoch-step: 61-381 -- Loss: 0.23385994136333466
train-epoch-step: 61-382 -- Loss: 0.22263260185718536
train-epoch-step: 61-383 -- Loss: 0.1660577952861786
train-epoch-step: 61-384 -- Loss: 0.2083476185798645
train-epoch-step: 61-385 -- Loss: 0.18362286686897278
train-epoch-step: 61-386 -- Loss: 0.17722323536872864
train-epoch-step: 61-387 -- Loss: 0.19149525463581085
train-epoch-step: 61-388 -- Loss: 0.17247846722602844
train-epoch-step: 61-389 -- Loss: 0.16975225508213043
train-epoch-step: 61-390 -- Loss: 0.13824960589408875
train-epoch-step: 61-391 -- Loss: 0.14040113985538483
train-epoch-step: 61-392 -- Loss: 0.18118420243263245
train-epoch-step: 61-393 -- Loss: 0.15106594562530518
train-epoch-step: 61-394 -- Loss: 0.18908216059207916
train-epoch-step: 61-395 -- Loss: 0.15032246708869934
train-epoch-step: 61-396 -- Loss: 0.12387864291667938
train-epoch-step: 61-397 -- Loss: 0.11896537989377975
train-epoch-step: 61-398 -- Loss: 0.19178755581378937
train-epoch-step: 61-399 -- Loss: 0.17124733328819275
train-epoch-step: 61-400 -- Loss: 0.26585710048675537
train-epoch-step: 61-401 -- Loss: 0.11322084069252014
train-epoch-step: 61-402 -- Loss: 0.24751095473766327
train-epoch-step: 61-403 -- Loss: 0.149398535490036
train-epoch-step: 61-404 -- Loss: 0.13347792625427246
train-epoch-step: 61-405 -- Loss: 0.13913194835186005
train-epoch-step: 61-406 -- Loss: 0.1658950299024582
train-epoch-step: 61-407 -- Loss: 0.10950089246034622
train-epoch-step: 61-408 -- Loss: 0.15450692176818848
train-epoch-step: 61-409 -- Loss: 0.17149004340171814
train-epoch-step: 61-410 -- Loss: 0.17100811004638672
train-epoch-step: 61-411 -- Loss: 0.18802304565906525
train-epoch-step: 61-412 -- Loss: 0.12373559921979904
train-epoch-step: 61-413 -- Loss: 0.14325013756752014
train-epoch-step: 61-414 -- Loss: 0.13294853270053864
train-epoch-step: 61-415 -- Loss: 0.13048897683620453
train-epoch-step: 61-416 -- Loss: 0.26096659898757935
train-epoch-step: 61-417 -- Loss: 0.18521913886070251
train-epoch-step: 61-418 -- Loss: 0.2211771458387375
train-epoch-step: 61-419 -- Loss: 0.16101714968681335
train-epoch-step: 61-420 -- Loss: 0.14755283296108246
train-epoch-step: 61-421 -- Loss: 0.17260412871837616
train-epoch-step: 61-422 -- Loss: 0.14869676530361176
train-epoch-step: 61-423 -- Loss: 0.17489773035049438
train-epoch-step: 61-424 -- Loss: 0.13278184831142426
train-epoch-step: 61-425 -- Loss: 0.179946169257164
train-epoch-step: 61-426 -- Loss: 0.17271432280540466
train-epoch-step: 61-427 -- Loss: 0.11888670921325684
train-epoch-step: 61-428 -- Loss: 0.186366006731987
train-epoch-step: 61-429 -- Loss: 0.1826619654893875
train-epoch-step: 61-430 -- Loss: 0.14028005301952362
train-epoch-step: 61-431 -- Loss: 0.15891900658607483
train-epoch-step: 61-432 -- Loss: 0.23580224812030792
train-epoch-step: 61-433 -- Loss: 0.13544119894504547
train-epoch-step: 61-434 -- Loss: 0.1256670355796814
train-epoch-step: 61-435 -- Loss: 0.15644589066505432
train-epoch-step: 61-436 -- Loss: 0.1495763063430786
train-epoch-step: 61-437 -- Loss: 0.1384660005569458
train-epoch-step: 61-438 -- Loss: 0.16046686470508575
train-epoch-step: 61-439 -- Loss: 0.2507472336292267
train-epoch-step: 61-440 -- Loss: 0.1310911327600479
train-epoch-step: 61-441 -- Loss: 0.19300293922424316
train-epoch-step: 61-442 -- Loss: 0.18103379011154175
train-epoch-step: 61-443 -- Loss: 0.15164236724376678
train-epoch-step: 61-444 -- Loss: 0.18223462998867035
train-epoch-step: 61-445 -- Loss: 0.17201972007751465
train-epoch-step: 61-446 -- Loss: 0.15933768451213837
train-epoch-step: 61-447 -- Loss: 0.18505993485450745
train-epoch-step: 61-448 -- Loss: 0.22491973638534546
train-epoch-step: 61-449 -- Loss: 0.1887843906879425
train-epoch-step: 61-450 -- Loss: 0.20303404331207275
train-epoch-step: 61-451 -- Loss: 0.1418476402759552
train-epoch-step: 61-452 -- Loss: 0.12683527171611786
train-epoch-step: 61-453 -- Loss: 0.09074313938617706
train-epoch-step: 61-454 -- Loss: 0.22351878881454468
train-epoch-step: 61-455 -- Loss: 0.11936088651418686
train-epoch-step: 61-456 -- Loss: 0.12105539441108704
train-epoch-step: 61-457 -- Loss: 0.21035213768482208
train-epoch-step: 61-458 -- Loss: 0.1477976143360138
train-epoch-step: 61-459 -- Loss: 0.21205434203147888
train-epoch-step: 61-460 -- Loss: 0.12231318652629852
train-epoch-step: 61-461 -- Loss: 0.13254275918006897
train-epoch-step: 61-462 -- Loss: 0.16099342703819275
train-epoch-step: 61-463 -- Loss: 0.1328941434621811
train-epoch-step: 61-464 -- Loss: 0.1580522358417511
train-epoch-step: 61-465 -- Loss: 0.23766109347343445
train-epoch-step: 61-466 -- Loss: 0.1922721415758133
train-epoch-step: 61-467 -- Loss: 0.11096911132335663
train-epoch-step: 61-468 -- Loss: 0.16855528950691223
train-epoch-step: 61-469 -- Loss: 0.19997355341911316
train-epoch-step: 61-470 -- Loss: 0.16963492333889008
train-epoch-step: 61-471 -- Loss: 0.15339171886444092
train-epoch-step: 61-472 -- Loss: 0.1546759307384491
train-epoch-step: 61-473 -- Loss: 0.15540480613708496
train-epoch-step: 61-474 -- Loss: 0.11762279272079468
train-epoch-step: 61-475 -- Loss: 0.10729438811540604
train-epoch-step: 61-476 -- Loss: 0.19539673626422882
train-epoch-step: 61-477 -- Loss: 0.1931147277355194
train-epoch-step: 61-478 -- Loss: 0.18831601738929749
train-epoch-step: 61-479 -- Loss: 0.13820193707942963
train-epoch-step: 61-480 -- Loss: 0.1856381744146347
train-epoch-step: 61-481 -- Loss: 0.2781955301761627
train-epoch-step: 61-482 -- Loss: 0.24842363595962524
train-epoch-step: 61-483 -- Loss: 0.17574149370193481
train-epoch-step: 61-484 -- Loss: 0.20471063256263733
train-epoch-step: 61-485 -- Loss: 0.12515050172805786
train-epoch-step: 61-486 -- Loss: 0.23146435618400574
train-epoch-step: 61-487 -- Loss: 0.225389301776886
train-epoch-step: 61-488 -- Loss: 0.178688645362854
train-epoch-step: 61-489 -- Loss: 0.21069180965423584
train-epoch-step: 61-490 -- Loss: 0.1365661919116974
train-epoch-step: 61-491 -- Loss: 0.13422194123268127
train-epoch-step: 61-492 -- Loss: 0.12705306708812714
train-epoch-step: 61-493 -- Loss: 0.20345726609230042
train-epoch-step: 61-494 -- Loss: 0.1909508854150772
train-epoch-step: 61-495 -- Loss: 0.18798603117465973
train-epoch-step: 61-496 -- Loss: 0.13819938898086548
train-epoch-step: 61-497 -- Loss: 0.1806243658065796
train-epoch-step: 61-498 -- Loss: 0.14146073162555695
train-epoch-step: 61-499 -- Loss: 0.16511604189872742
train-epoch-step: 61-500 -- Loss: 0.15089337527751923
train-epoch-step: 61-501 -- Loss: 0.21029828488826752
train-epoch-step: 61-502 -- Loss: 0.15253689885139465
train-epoch-step: 61-503 -- Loss: 0.2152196764945984
train-epoch-step: 61-504 -- Loss: 0.12374600768089294
train-epoch-step: 61-505 -- Loss: 0.1693120300769806
train-epoch-step: 61-506 -- Loss: 0.11513126641511917
train-epoch-step: 61-507 -- Loss: 0.1836409866809845
train-epoch-step: 61-508 -- Loss: 0.18060800433158875
train-epoch-step: 61-509 -- Loss: 0.16590909659862518
train-epoch-step: 61-510 -- Loss: 0.12552033364772797
train-epoch-step: 61-511 -- Loss: 0.21718358993530273
train-epoch-step: 61-512 -- Loss: 0.17314547300338745
train-epoch-step: 61-513 -- Loss: 0.19090847671031952
train-epoch-step: 61-514 -- Loss: 0.14342579245567322
train-epoch-step: 61-515 -- Loss: 0.14806871116161346
train-epoch-step: 61-516 -- Loss: 0.16451871395111084
train-epoch-step: 61-517 -- Loss: 0.1706036776304245
train-epoch-step: 61-518 -- Loss: 0.13723337650299072
train-epoch-step: 61-519 -- Loss: 0.12976829707622528
train-epoch-step: 61-520 -- Loss: 0.1815284788608551
train-epoch-step: 61-521 -- Loss: 0.2278345823287964
train-epoch-step: 61-522 -- Loss: 0.17116984724998474
train-epoch-step: 61-523 -- Loss: 0.1569635570049286
train-epoch-step: 61-524 -- Loss: 0.16572996973991394
train-epoch-step: 61-525 -- Loss: 0.1887846291065216
train-epoch-step: 61-526 -- Loss: 0.12780724465847015
train-epoch-step: 61-527 -- Loss: 0.15127477049827576
train-epoch-step: 61-528 -- Loss: 0.153681218624115
train-epoch-step: 61-529 -- Loss: 0.15046535432338715
train-epoch-step: 61-530 -- Loss: 0.16340883076190948
train-epoch-step: 61-531 -- Loss: 0.19215060770511627
train-epoch-step: 61-532 -- Loss: 0.16449639201164246
train-epoch-step: 61-533 -- Loss: 0.1719372570514679
train-epoch-step: 61-534 -- Loss: 0.13072694838047028
train-epoch-step: 61-535 -- Loss: 0.24871419370174408
train-epoch-step: 61-536 -- Loss: 0.1545567810535431
train-epoch-step: 61-537 -- Loss: 0.14287923276424408
train-epoch-step: 61-538 -- Loss: 0.10301250964403152
train-epoch-step: 61-539 -- Loss: 0.17576299607753754
train-epoch-step: 61-540 -- Loss: 0.13332685828208923
train-epoch-step: 61-541 -- Loss: 0.20594316720962524
train-epoch-step: 61-542 -- Loss: 0.2142987847328186
train-epoch-step: 61-543 -- Loss: 0.16492922604084015
train-epoch-step: 61-544 -- Loss: 0.2208303064107895
train-epoch-step: 61-545 -- Loss: 0.18802569806575775
train-epoch-step: 61-546 -- Loss: 0.2109488844871521
train-epoch-step: 61-547 -- Loss: 0.1756206750869751
train-epoch-step: 61-548 -- Loss: 0.08945395052433014
train-epoch-step: 61-549 -- Loss: 0.14809739589691162
train-epoch-step: 61-550 -- Loss: 0.19122180342674255
train-epoch-step: 61-551 -- Loss: 0.15241490304470062
train-epoch-step: 61-552 -- Loss: 0.12184350937604904
train-epoch-step: 61-553 -- Loss: 0.18506285548210144
train-epoch-step: 61-554 -- Loss: 0.18374228477478027
train-epoch-step: 61-555 -- Loss: 0.21707741916179657
train-epoch-step: 61-556 -- Loss: 0.14453540742397308
train-epoch-step: 61-557 -- Loss: 0.22953146696090698
train-epoch-step: 61-558 -- Loss: 0.22332710027694702
train-epoch-step: 61-559 -- Loss: 0.13167428970336914
train-epoch-step: 61-560 -- Loss: 0.1962645798921585
train-epoch-step: 61-561 -- Loss: 0.17960020899772644
train-epoch-step: 61-562 -- Loss: 0.1608332246541977
train-epoch-step: 61-563 -- Loss: 0.17838765680789948
train-epoch-step: 61-564 -- Loss: 0.0956580638885498
train-epoch-step: 61-565 -- Loss: 0.1803867518901825
train-epoch-step: 61-566 -- Loss: 0.1469644159078598
train-epoch-step: 61-567 -- Loss: 0.2069539725780487
train-epoch-step: 61-568 -- Loss: 0.15141357481479645
train-epoch-step: 61-569 -- Loss: 0.23635219037532806
train-epoch-step: 61-570 -- Loss: 0.16465680301189423
train-epoch-step: 61-571 -- Loss: 0.21055035293102264
train-epoch-step: 61-572 -- Loss: 0.22734922170639038
train-epoch-step: 61-573 -- Loss: 0.19287599623203278
train-epoch-step: 61-574 -- Loss: 0.2315789759159088
train-epoch-step: 61-575 -- Loss: 0.2859399616718292
train-epoch-step: 61-576 -- Loss: 0.11669600009918213
train-epoch-step: 61-577 -- Loss: 0.16725388169288635
train-epoch-step: 61-578 -- Loss: 0.20919696986675262
train-epoch-step: 61-579 -- Loss: 0.15980561077594757
train-epoch-step: 61-580 -- Loss: 0.16628116369247437
train-epoch-step: 61-581 -- Loss: 0.13226847350597382
train-epoch-step: 61-582 -- Loss: 0.19879722595214844
train-epoch-step: 61-583 -- Loss: 0.20346352458000183
train-epoch-step: 61-584 -- Loss: 0.15582773089408875
train-epoch-step: 61-585 -- Loss: 0.18681100010871887
train-epoch-step: 61-586 -- Loss: 0.24545949697494507
train-epoch-step: 61-587 -- Loss: 0.15512652695178986
train-epoch-step: 61-588 -- Loss: 0.12301547825336456
val-epoch-step: 61-589 -- Loss: 0.189722940325737
val-epoch-step: 61-590 -- Loss: 0.15093617141246796
val-epoch-step: 61-591 -- Loss: 0.23089732229709625
val-epoch-step: 61-592 -- Loss: 0.17535513639450073
val-epoch-step: 61-593 -- Loss: 0.15190716087818146
val-epoch-step: 61-594 -- Loss: 0.3899135887622833
val-epoch-step: 61-595 -- Loss: 0.1758342981338501
val-epoch-step: 61-596 -- Loss: 0.19007045030593872
val-epoch-step: 61-597 -- Loss: 0.16721729934215546
val-epoch-step: 61-598 -- Loss: 0.1507992148399353
val-epoch-step: 61-599 -- Loss: 0.18151481449604034
val-epoch-step: 61-600 -- Loss: 0.21988445520401
val-epoch-step: 61-601 -- Loss: 0.15865956246852875
val-epoch-step: 61-602 -- Loss: 0.13363568484783173
val-epoch-step: 61-603 -- Loss: 0.23111894726753235
val-epoch-step: 61-604 -- Loss: 0.1460380107164383
val-epoch-step: 61-605 -- Loss: 0.14310462772846222
val-epoch-step: 61-606 -- Loss: 0.29310840368270874
val-epoch-step: 61-607 -- Loss: 0.12091507762670517
val-epoch-step: 61-608 -- Loss: 0.23962409794330597
val-epoch-step: 61-609 -- Loss: 0.1595098078250885
val-epoch-step: 61-610 -- Loss: 0.17061960697174072
val-epoch-step: 61-611 -- Loss: 0.15832847356796265
val-epoch-step: 61-612 -- Loss: 0.43274131417274475
val-epoch-step: 61-613 -- Loss: 0.17089705169200897
val-epoch-step: 61-614 -- Loss: 0.18167442083358765
val-epoch-step: 61-615 -- Loss: 0.17406532168388367
val-epoch-step: 61-616 -- Loss: 0.14073020219802856
val-epoch-step: 61-617 -- Loss: 0.18922336399555206
val-epoch-step: 61-618 -- Loss: 0.18154002726078033
val-epoch-step: 61-619 -- Loss: 0.2068236917257309
val-epoch-step: 61-620 -- Loss: 0.13620157539844513
val-epoch-step: 61-621 -- Loss: 0.1234193965792656
val-epoch-step: 61-622 -- Loss: 0.14023357629776
val-epoch-step: 61-623 -- Loss: 0.15032659471035004
val-epoch-step: 61-624 -- Loss: 0.15346506237983704
val-epoch-step: 61-625 -- Loss: 0.15486066043376923
val-epoch-step: 61-626 -- Loss: 0.14460481703281403
val-epoch-step: 61-627 -- Loss: 0.17820674180984497
val-epoch-step: 61-628 -- Loss: 0.68802809715271
val-epoch-step: 61-629 -- Loss: 0.2034093290567398
val-epoch-step: 61-630 -- Loss: 0.3441997468471527
val-epoch-step: 61-631 -- Loss: 0.1418159157037735
val-epoch-step: 61-632 -- Loss: 0.19712427258491516
val-epoch-step: 61-633 -- Loss: 0.1466047167778015
val-epoch-step: 61-634 -- Loss: 0.15727564692497253
val-epoch-step: 61-635 -- Loss: 0.1110474169254303
val-epoch-step: 61-636 -- Loss: 0.1634521633386612
val-epoch-step: 61-637 -- Loss: 0.17774592339992523
val-epoch-step: 61-638 -- Loss: 0.149227112531662
val-epoch-step: 61-639 -- Loss: 0.2565668225288391
val-epoch-step: 61-640 -- Loss: 0.2512527406215668
val-epoch-step: 61-641 -- Loss: 0.12383371591567993
val-epoch-step: 61-642 -- Loss: 0.17506924271583557
val-epoch-step: 61-643 -- Loss: 0.20215082168579102
val-epoch-step: 61-644 -- Loss: 0.17240431904792786
val-epoch-step: 61-645 -- Loss: 0.21774420142173767
val-epoch-step: 61-646 -- Loss: 0.1481722891330719
val-epoch-step: 61-647 -- Loss: 0.12992511689662933
val-epoch-step: 61-648 -- Loss: 0.15365277230739594
val-epoch-step: 61-649 -- Loss: 0.20415213704109192
val-epoch-step: 61-650 -- Loss: 0.2450534999370575
val-epoch-step: 61-651 -- Loss: 0.14337997138500214
val-epoch-step: 61-652 -- Loss: 0.14989565312862396
val-epoch-step: 61-653 -- Loss: 0.23735612630844116
val-epoch-step: 61-654 -- Loss: 0.11022380739450455
Epoch: 61 -- Train Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 62-0 -- Loss: 0.21681863069534302
train-epoch-step: 62-1 -- Loss: 0.14094822108745575
train-epoch-step: 62-2 -- Loss: 0.1966591626405716
train-epoch-step: 62-3 -- Loss: 0.138254776597023
train-epoch-step: 62-4 -- Loss: 0.15428504347801208
train-epoch-step: 62-5 -- Loss: 0.17224684357643127
train-epoch-step: 62-6 -- Loss: 0.2074674516916275
train-epoch-step: 62-7 -- Loss: 0.16291743516921997
train-epoch-step: 62-8 -- Loss: 0.17527088522911072
train-epoch-step: 62-9 -- Loss: 0.21959063410758972
train-epoch-step: 62-10 -- Loss: 0.18618521094322205
train-epoch-step: 62-11 -- Loss: 0.16924762725830078
train-epoch-step: 62-12 -- Loss: 0.14403116703033447
train-epoch-step: 62-13 -- Loss: 0.17002040147781372
train-epoch-step: 62-14 -- Loss: 0.15665042400360107
train-epoch-step: 62-15 -- Loss: 0.1542157679796219
train-epoch-step: 62-16 -- Loss: 0.15780767798423767
train-epoch-step: 62-17 -- Loss: 0.2095261812210083
train-epoch-step: 62-18 -- Loss: 0.18884117901325226
train-epoch-step: 62-19 -- Loss: 0.1269732266664505
train-epoch-step: 62-20 -- Loss: 0.20317667722702026
train-epoch-step: 62-21 -- Loss: 0.2392258495092392
train-epoch-step: 62-22 -- Loss: 0.13204874098300934
train-epoch-step: 62-23 -- Loss: 0.13895726203918457
train-epoch-step: 62-24 -- Loss: 0.11974363774061203
train-epoch-step: 62-25 -- Loss: 0.2184857726097107
train-epoch-step: 62-26 -- Loss: 0.18610937893390656
train-epoch-step: 62-27 -- Loss: 0.221714049577713
train-epoch-step: 62-28 -- Loss: 0.11966586858034134
train-epoch-step: 62-29 -- Loss: 0.237589031457901
train-epoch-step: 62-30 -- Loss: 0.10739144682884216
train-epoch-step: 62-31 -- Loss: 0.1332860291004181
train-epoch-step: 62-32 -- Loss: 0.16748449206352234
train-epoch-step: 62-33 -- Loss: 0.2676404118537903
train-epoch-step: 62-34 -- Loss: 0.1652221530675888
train-epoch-step: 62-35 -- Loss: 0.23517268896102905
train-epoch-step: 62-36 -- Loss: 0.1338629275560379
train-epoch-step: 62-37 -- Loss: 0.13261015713214874
train-epoch-step: 62-38 -- Loss: 0.16737622022628784
train-epoch-step: 62-39 -- Loss: 0.20660927891731262
train-epoch-step: 62-40 -- Loss: 0.18312449753284454
train-epoch-step: 62-41 -- Loss: 0.19979624450206757
train-epoch-step: 62-42 -- Loss: 0.14280301332473755
train-epoch-step: 62-43 -- Loss: 0.24759581685066223
train-epoch-step: 62-44 -- Loss: 0.12184599786996841
train-epoch-step: 62-45 -- Loss: 0.11129919439554214
train-epoch-step: 62-46 -- Loss: 0.16063803434371948
train-epoch-step: 62-47 -- Loss: 0.1966451108455658
train-epoch-step: 62-48 -- Loss: 0.1510249227285385
train-epoch-step: 62-49 -- Loss: 0.2208983600139618
train-epoch-step: 62-50 -- Loss: 0.10643789172172546
train-epoch-step: 62-51 -- Loss: 0.16436052322387695
train-epoch-step: 62-52 -- Loss: 0.1531817764043808
train-epoch-step: 62-53 -- Loss: 0.20167386531829834
train-epoch-step: 62-54 -- Loss: 0.276978462934494
train-epoch-step: 62-55 -- Loss: 0.16384688019752502
train-epoch-step: 62-56 -- Loss: 0.17147545516490936
train-epoch-step: 62-57 -- Loss: 0.22799648344516754
train-epoch-step: 62-58 -- Loss: 0.2701781392097473
train-epoch-step: 62-59 -- Loss: 0.23603835701942444
train-epoch-step: 62-60 -- Loss: 0.12176236510276794
train-epoch-step: 62-61 -- Loss: 0.20130932331085205
train-epoch-step: 62-62 -- Loss: 0.1789391189813614
train-epoch-step: 62-63 -- Loss: 0.13374055922031403
train-epoch-step: 62-64 -- Loss: 0.14018529653549194
train-epoch-step: 62-65 -- Loss: 0.1712363064289093
train-epoch-step: 62-66 -- Loss: 0.1046636775135994
train-epoch-step: 62-67 -- Loss: 0.12349292635917664
train-epoch-step: 62-68 -- Loss: 0.2017003893852234
train-epoch-step: 62-69 -- Loss: 0.11678936332464218
train-epoch-step: 62-70 -- Loss: 0.21636039018630981
train-epoch-step: 62-71 -- Loss: 0.25168171525001526
train-epoch-step: 62-72 -- Loss: 0.1823486089706421
train-epoch-step: 62-73 -- Loss: 0.20536532998085022
train-epoch-step: 62-74 -- Loss: 0.09264224022626877
train-epoch-step: 62-75 -- Loss: 0.12316280603408813
train-epoch-step: 62-76 -- Loss: 0.14299769699573517
train-epoch-step: 62-77 -- Loss: 0.22016820311546326
train-epoch-step: 62-78 -- Loss: 0.24398590624332428
train-epoch-step: 62-79 -- Loss: 0.18340691924095154
train-epoch-step: 62-80 -- Loss: 0.23633474111557007
train-epoch-step: 62-81 -- Loss: 0.1227952316403389
train-epoch-step: 62-82 -- Loss: 0.2440367490053177
train-epoch-step: 62-83 -- Loss: 0.17323637008666992
train-epoch-step: 62-84 -- Loss: 0.18012642860412598
train-epoch-step: 62-85 -- Loss: 0.17238785326480865
train-epoch-step: 62-86 -- Loss: 0.1168031096458435
train-epoch-step: 62-87 -- Loss: 0.20057161152362823
train-epoch-step: 62-88 -- Loss: 0.14657500386238098
train-epoch-step: 62-89 -- Loss: 0.18245363235473633
train-epoch-step: 62-90 -- Loss: 0.18668854236602783
train-epoch-step: 62-91 -- Loss: 0.2356814295053482
train-epoch-step: 62-92 -- Loss: 0.14931036531925201
train-epoch-step: 62-93 -- Loss: 0.1644897758960724
train-epoch-step: 62-94 -- Loss: 0.20802561938762665
train-epoch-step: 62-95 -- Loss: 0.18390962481498718
train-epoch-step: 62-96 -- Loss: 0.2080300748348236
train-epoch-step: 62-97 -- Loss: 0.16597801446914673
train-epoch-step: 62-98 -- Loss: 0.15018169581890106
train-epoch-step: 62-99 -- Loss: 0.17523309588432312
train-epoch-step: 62-100 -- Loss: 0.18494448065757751
train-epoch-step: 62-101 -- Loss: 0.24885597825050354
train-epoch-step: 62-102 -- Loss: 0.2143004983663559
train-epoch-step: 62-103 -- Loss: 0.17722907662391663
train-epoch-step: 62-104 -- Loss: 0.1452675759792328
train-epoch-step: 62-105 -- Loss: 0.2648899555206299
train-epoch-step: 62-106 -- Loss: 0.16883939504623413
train-epoch-step: 62-107 -- Loss: 0.18671032786369324
train-epoch-step: 62-108 -- Loss: 0.18681825697422028
train-epoch-step: 62-109 -- Loss: 0.1436605006456375
train-epoch-step: 62-110 -- Loss: 0.1751140058040619
train-epoch-step: 62-111 -- Loss: 0.17337298393249512
train-epoch-step: 62-112 -- Loss: 0.1579306572675705
train-epoch-step: 62-113 -- Loss: 0.15665864944458008
train-epoch-step: 62-114 -- Loss: 0.1949869841337204
train-epoch-step: 62-115 -- Loss: 0.15428891777992249
train-epoch-step: 62-116 -- Loss: 0.13254119455814362
train-epoch-step: 62-117 -- Loss: 0.12350544333457947
train-epoch-step: 62-118 -- Loss: 0.18429671227931976
train-epoch-step: 62-119 -- Loss: 0.14924614131450653
train-epoch-step: 62-120 -- Loss: 0.24222944676876068
train-epoch-step: 62-121 -- Loss: 0.2398996651172638
train-epoch-step: 62-122 -- Loss: 0.20990462601184845
train-epoch-step: 62-123 -- Loss: 0.20053593814373016
train-epoch-step: 62-124 -- Loss: 0.12323543429374695
train-epoch-step: 62-125 -- Loss: 0.15267421305179596
train-epoch-step: 62-126 -- Loss: 0.22770974040031433
train-epoch-step: 62-127 -- Loss: 0.15918989479541779
train-epoch-step: 62-128 -- Loss: 0.16667424142360687
train-epoch-step: 62-129 -- Loss: 0.13494271039962769
train-epoch-step: 62-130 -- Loss: 0.2179223895072937
train-epoch-step: 62-131 -- Loss: 0.13077905774116516
train-epoch-step: 62-132 -- Loss: 0.2080918848514557
train-epoch-step: 62-133 -- Loss: 0.10904593020677567
train-epoch-step: 62-134 -- Loss: 0.1903127282857895
train-epoch-step: 62-135 -- Loss: 0.13037702441215515
train-epoch-step: 62-136 -- Loss: 0.12423916161060333
train-epoch-step: 62-137 -- Loss: 0.2397434562444687
train-epoch-step: 62-138 -- Loss: 0.25361835956573486
train-epoch-step: 62-139 -- Loss: 0.13234585523605347
train-epoch-step: 62-140 -- Loss: 0.20278161764144897
train-epoch-step: 62-141 -- Loss: 0.22627636790275574
train-epoch-step: 62-142 -- Loss: 0.21392886340618134
train-epoch-step: 62-143 -- Loss: 0.16500331461429596
train-epoch-step: 62-144 -- Loss: 0.18066690862178802
train-epoch-step: 62-145 -- Loss: 0.1404860019683838
train-epoch-step: 62-146 -- Loss: 0.17527981102466583
train-epoch-step: 62-147 -- Loss: 0.17140543460845947
train-epoch-step: 62-148 -- Loss: 0.15556029975414276
train-epoch-step: 62-149 -- Loss: 0.11482097953557968
train-epoch-step: 62-150 -- Loss: 0.18105697631835938
train-epoch-step: 62-151 -- Loss: 0.1867680549621582
train-epoch-step: 62-152 -- Loss: 0.18858174979686737
train-epoch-step: 62-153 -- Loss: 0.26988905668258667
train-epoch-step: 62-154 -- Loss: 0.12835310399532318
train-epoch-step: 62-155 -- Loss: 0.13141560554504395
train-epoch-step: 62-156 -- Loss: 0.11653855443000793
train-epoch-step: 62-157 -- Loss: 0.16026809811592102
train-epoch-step: 62-158 -- Loss: 0.16158732771873474
train-epoch-step: 62-159 -- Loss: 0.17789965867996216
train-epoch-step: 62-160 -- Loss: 0.20678755640983582
train-epoch-step: 62-161 -- Loss: 0.20162658393383026
train-epoch-step: 62-162 -- Loss: 0.2057734578847885
train-epoch-step: 62-163 -- Loss: 0.18341130018234253
train-epoch-step: 62-164 -- Loss: 0.1884070485830307
train-epoch-step: 62-165 -- Loss: 0.15588626265525818
train-epoch-step: 62-166 -- Loss: 0.11682193726301193
train-epoch-step: 62-167 -- Loss: 0.13173532485961914
train-epoch-step: 62-168 -- Loss: 0.19983920454978943
train-epoch-step: 62-169 -- Loss: 0.13181869685649872
train-epoch-step: 62-170 -- Loss: 0.1953037679195404
train-epoch-step: 62-171 -- Loss: 0.13984562456607819
train-epoch-step: 62-172 -- Loss: 0.2554320693016052
train-epoch-step: 62-173 -- Loss: 0.13324704766273499
train-epoch-step: 62-174 -- Loss: 0.23978844285011292
train-epoch-step: 62-175 -- Loss: 0.18585830926895142
train-epoch-step: 62-176 -- Loss: 0.12761688232421875
train-epoch-step: 62-177 -- Loss: 0.17364069819450378
train-epoch-step: 62-178 -- Loss: 0.17320987582206726
train-epoch-step: 62-179 -- Loss: 0.1456649899482727
train-epoch-step: 62-180 -- Loss: 0.1522410809993744
train-epoch-step: 62-181 -- Loss: 0.16699111461639404
train-epoch-step: 62-182 -- Loss: 0.17874209582805634
train-epoch-step: 62-183 -- Loss: 0.256521999835968
train-epoch-step: 62-184 -- Loss: 0.13311970233917236
train-epoch-step: 62-185 -- Loss: 0.13965845108032227
train-epoch-step: 62-186 -- Loss: 0.18037766218185425
train-epoch-step: 62-187 -- Loss: 0.20157742500305176
train-epoch-step: 62-188 -- Loss: 0.16784808039665222
train-epoch-step: 62-189 -- Loss: 0.10209546983242035
train-epoch-step: 62-190 -- Loss: 0.17673014104366302
train-epoch-step: 62-191 -- Loss: 0.15821236371994019
train-epoch-step: 62-192 -- Loss: 0.22859805822372437
train-epoch-step: 62-193 -- Loss: 0.19761940836906433
train-epoch-step: 62-194 -- Loss: 0.17670537531375885
train-epoch-step: 62-195 -- Loss: 0.1593148112297058
train-epoch-step: 62-196 -- Loss: 0.1635041981935501
train-epoch-step: 62-197 -- Loss: 0.12080233544111252
train-epoch-step: 62-198 -- Loss: 0.12388594448566437
train-epoch-step: 62-199 -- Loss: 0.14182740449905396
train-epoch-step: 62-200 -- Loss: 0.12181335687637329
train-epoch-step: 62-201 -- Loss: 0.1805102676153183
train-epoch-step: 62-202 -- Loss: 0.13332733511924744
train-epoch-step: 62-203 -- Loss: 0.1700970083475113
train-epoch-step: 62-204 -- Loss: 0.1346207857131958
train-epoch-step: 62-205 -- Loss: 0.1800142526626587
train-epoch-step: 62-206 -- Loss: 0.19504883885383606
train-epoch-step: 62-207 -- Loss: 0.13016939163208008
train-epoch-step: 62-208 -- Loss: 0.17120404541492462
train-epoch-step: 62-209 -- Loss: 0.13992062211036682
train-epoch-step: 62-210 -- Loss: 0.12881523370742798
train-epoch-step: 62-211 -- Loss: 0.20154555141925812
train-epoch-step: 62-212 -- Loss: 0.19120848178863525
train-epoch-step: 62-213 -- Loss: 0.12348635494709015
train-epoch-step: 62-214 -- Loss: 0.14214156568050385
train-epoch-step: 62-215 -- Loss: 0.12278203666210175
train-epoch-step: 62-216 -- Loss: 0.19131384789943695
train-epoch-step: 62-217 -- Loss: 0.20446035265922546
train-epoch-step: 62-218 -- Loss: 0.14180691540241241
train-epoch-step: 62-219 -- Loss: 0.1637176126241684
train-epoch-step: 62-220 -- Loss: 0.13156859576702118
train-epoch-step: 62-221 -- Loss: 0.19815093278884888
train-epoch-step: 62-222 -- Loss: 0.11319263279438019
train-epoch-step: 62-223 -- Loss: 0.16621002554893494
train-epoch-step: 62-224 -- Loss: 0.17976650595664978
train-epoch-step: 62-225 -- Loss: 0.3020741939544678
train-epoch-step: 62-226 -- Loss: 0.20049582421779633
train-epoch-step: 62-227 -- Loss: 0.2207445353269577
train-epoch-step: 62-228 -- Loss: 0.17133519053459167
train-epoch-step: 62-229 -- Loss: 0.17589107155799866
train-epoch-step: 62-230 -- Loss: 0.1831272542476654
train-epoch-step: 62-231 -- Loss: 0.1515483260154724
train-epoch-step: 62-232 -- Loss: 0.18564634025096893
train-epoch-step: 62-233 -- Loss: 0.09649810194969177
train-epoch-step: 62-234 -- Loss: 0.17939957976341248
train-epoch-step: 62-235 -- Loss: 0.14296801388263702
train-epoch-step: 62-236 -- Loss: 0.18942615389823914
train-epoch-step: 62-237 -- Loss: 0.24061298370361328
train-epoch-step: 62-238 -- Loss: 0.1536192148923874
train-epoch-step: 62-239 -- Loss: 0.137148916721344
train-epoch-step: 62-240 -- Loss: 0.2183370590209961
train-epoch-step: 62-241 -- Loss: 0.15225715935230255
train-epoch-step: 62-242 -- Loss: 0.21921272575855255
train-epoch-step: 62-243 -- Loss: 0.22974231839179993
train-epoch-step: 62-244 -- Loss: 0.21108432114124298
train-epoch-step: 62-245 -- Loss: 0.20909129083156586
train-epoch-step: 62-246 -- Loss: 0.22838059067726135
train-epoch-step: 62-247 -- Loss: 0.23723095655441284
train-epoch-step: 62-248 -- Loss: 0.18109771609306335
train-epoch-step: 62-249 -- Loss: 0.13901999592781067
train-epoch-step: 62-250 -- Loss: 0.19820088148117065
train-epoch-step: 62-251 -- Loss: 0.1054590567946434
train-epoch-step: 62-252 -- Loss: 0.2079790085554123
train-epoch-step: 62-253 -- Loss: 0.1362539827823639
train-epoch-step: 62-254 -- Loss: 0.20959416031837463
train-epoch-step: 62-255 -- Loss: 0.1419704407453537
train-epoch-step: 62-256 -- Loss: 0.1426040679216385
train-epoch-step: 62-257 -- Loss: 0.18552184104919434
train-epoch-step: 62-258 -- Loss: 0.1415989100933075
train-epoch-step: 62-259 -- Loss: 0.11085426807403564
train-epoch-step: 62-260 -- Loss: 0.19303971529006958
train-epoch-step: 62-261 -- Loss: 0.1690410077571869
train-epoch-step: 62-262 -- Loss: 0.28489986062049866
train-epoch-step: 62-263 -- Loss: 0.197514146566391
train-epoch-step: 62-264 -- Loss: 0.16906169056892395
train-epoch-step: 62-265 -- Loss: 0.11030663549900055
train-epoch-step: 62-266 -- Loss: 0.1533706784248352
train-epoch-step: 62-267 -- Loss: 0.12760880589485168
train-epoch-step: 62-268 -- Loss: 0.11760550737380981
train-epoch-step: 62-269 -- Loss: 0.16918590664863586
train-epoch-step: 62-270 -- Loss: 0.10720694810152054
train-epoch-step: 62-271 -- Loss: 0.1450078785419464
train-epoch-step: 62-272 -- Loss: 0.11177444458007812
train-epoch-step: 62-273 -- Loss: 0.1230880618095398
train-epoch-step: 62-274 -- Loss: 0.1770428866147995
train-epoch-step: 62-275 -- Loss: 0.18997026979923248
train-epoch-step: 62-276 -- Loss: 0.15021593868732452
train-epoch-step: 62-277 -- Loss: 0.154882550239563
train-epoch-step: 62-278 -- Loss: 0.13216467201709747
train-epoch-step: 62-279 -- Loss: 0.1366463452577591
train-epoch-step: 62-280 -- Loss: 0.21274934709072113
train-epoch-step: 62-281 -- Loss: 0.17512255907058716
train-epoch-step: 62-282 -- Loss: 0.1393592357635498
train-epoch-step: 62-283 -- Loss: 0.11036717146635056
train-epoch-step: 62-284 -- Loss: 0.13181045651435852
train-epoch-step: 62-285 -- Loss: 0.18541400134563446
train-epoch-step: 62-286 -- Loss: 0.14677885174751282
train-epoch-step: 62-287 -- Loss: 0.19760408997535706
train-epoch-step: 62-288 -- Loss: 0.09194305539131165
train-epoch-step: 62-289 -- Loss: 0.11728037893772125
train-epoch-step: 62-290 -- Loss: 0.17252376675605774
train-epoch-step: 62-291 -- Loss: 0.11325306445360184
train-epoch-step: 62-292 -- Loss: 0.15111510455608368
train-epoch-step: 62-293 -- Loss: 0.1346569061279297
train-epoch-step: 62-294 -- Loss: 0.18227961659431458
train-epoch-step: 62-295 -- Loss: 0.25726884603500366
train-epoch-step: 62-296 -- Loss: 0.15824924409389496
train-epoch-step: 62-297 -- Loss: 0.16754895448684692
train-epoch-step: 62-298 -- Loss: 0.23088614642620087
train-epoch-step: 62-299 -- Loss: 0.16450929641723633
train-epoch-step: 62-300 -- Loss: 0.16671635210514069
train-epoch-step: 62-301 -- Loss: 0.16413944959640503
train-epoch-step: 62-302 -- Loss: 0.21366140246391296
train-epoch-step: 62-303 -- Loss: 0.20575982332229614
train-epoch-step: 62-304 -- Loss: 0.12106874585151672
train-epoch-step: 62-305 -- Loss: 0.13945306837558746
train-epoch-step: 62-306 -- Loss: 0.20505237579345703
train-epoch-step: 62-307 -- Loss: 0.16008280217647552
train-epoch-step: 62-308 -- Loss: 0.21224883198738098
train-epoch-step: 62-309 -- Loss: 0.15418918430805206
train-epoch-step: 62-310 -- Loss: 0.16172020137310028
train-epoch-step: 62-311 -- Loss: 0.1584196835756302
train-epoch-step: 62-312 -- Loss: 0.20586667954921722
train-epoch-step: 62-313 -- Loss: 0.09877175092697144
train-epoch-step: 62-314 -- Loss: 0.18811377882957458
train-epoch-step: 62-315 -- Loss: 0.16255193948745728
train-epoch-step: 62-316 -- Loss: 0.14954841136932373
train-epoch-step: 62-317 -- Loss: 0.13927264511585236
train-epoch-step: 62-318 -- Loss: 0.16349799931049347
train-epoch-step: 62-319 -- Loss: 0.17707091569900513
train-epoch-step: 62-320 -- Loss: 0.11586090922355652
train-epoch-step: 62-321 -- Loss: 0.13635392487049103
train-epoch-step: 62-322 -- Loss: 0.21369296312332153
train-epoch-step: 62-323 -- Loss: 0.18548360466957092
train-epoch-step: 62-324 -- Loss: 0.25230398774147034
train-epoch-step: 62-325 -- Loss: 0.17996151745319366
train-epoch-step: 62-326 -- Loss: 0.18597501516342163
train-epoch-step: 62-327 -- Loss: 0.2091708779335022
train-epoch-step: 62-328 -- Loss: 0.22636699676513672
train-epoch-step: 62-329 -- Loss: 0.3962005376815796
train-epoch-step: 62-330 -- Loss: 0.36379727721214294
train-epoch-step: 62-331 -- Loss: 0.20324154198169708
train-epoch-step: 62-332 -- Loss: 0.10125631839036942
train-epoch-step: 62-333 -- Loss: 0.179310142993927
train-epoch-step: 62-334 -- Loss: 0.1587575376033783
train-epoch-step: 62-335 -- Loss: 0.17415767908096313
train-epoch-step: 62-336 -- Loss: 0.16668754816055298
train-epoch-step: 62-337 -- Loss: 0.22549943625926971
train-epoch-step: 62-338 -- Loss: 0.15945345163345337
train-epoch-step: 62-339 -- Loss: 0.1668623983860016
train-epoch-step: 62-340 -- Loss: 0.1967383474111557
train-epoch-step: 62-341 -- Loss: 0.13556772470474243
train-epoch-step: 62-342 -- Loss: 0.16406992077827454
train-epoch-step: 62-343 -- Loss: 0.15771456062793732
train-epoch-step: 62-344 -- Loss: 0.16843970119953156
train-epoch-step: 62-345 -- Loss: 0.1356251835823059
train-epoch-step: 62-346 -- Loss: 0.19608423113822937
train-epoch-step: 62-347 -- Loss: 0.1466180980205536
train-epoch-step: 62-348 -- Loss: 0.1978120058774948
train-epoch-step: 62-349 -- Loss: 0.2012014091014862
train-epoch-step: 62-350 -- Loss: 0.2456665337085724
train-epoch-step: 62-351 -- Loss: 0.18820558488368988
train-epoch-step: 62-352 -- Loss: 0.1227555200457573
train-epoch-step: 62-353 -- Loss: 0.1889764368534088
train-epoch-step: 62-354 -- Loss: 0.2767973840236664
train-epoch-step: 62-355 -- Loss: 0.11726483702659607
train-epoch-step: 62-356 -- Loss: 0.11567460000514984
train-epoch-step: 62-357 -- Loss: 0.1839091181755066
train-epoch-step: 62-358 -- Loss: 0.18642249703407288
train-epoch-step: 62-359 -- Loss: 0.1346524953842163
train-epoch-step: 62-360 -- Loss: 0.12122026830911636
train-epoch-step: 62-361 -- Loss: 0.23353804647922516
train-epoch-step: 62-362 -- Loss: 0.16842152178287506
train-epoch-step: 62-363 -- Loss: 0.10931956768035889
train-epoch-step: 62-364 -- Loss: 0.17751362919807434
train-epoch-step: 62-365 -- Loss: 0.17332561314105988
train-epoch-step: 62-366 -- Loss: 0.1973980963230133
train-epoch-step: 62-367 -- Loss: 0.2260359823703766
train-epoch-step: 62-368 -- Loss: 0.19440782070159912
train-epoch-step: 62-369 -- Loss: 0.2709868550300598
train-epoch-step: 62-370 -- Loss: 0.12306401133537292
train-epoch-step: 62-371 -- Loss: 0.118691086769104
train-epoch-step: 62-372 -- Loss: 0.14700357615947723
train-epoch-step: 62-373 -- Loss: 0.1820855587720871
train-epoch-step: 62-374 -- Loss: 0.1486724615097046
train-epoch-step: 62-375 -- Loss: 0.2634071409702301
train-epoch-step: 62-376 -- Loss: 0.16445212066173553
train-epoch-step: 62-377 -- Loss: 0.2269717901945114
train-epoch-step: 62-378 -- Loss: 0.1941104233264923
train-epoch-step: 62-379 -- Loss: 0.11529771983623505
train-epoch-step: 62-380 -- Loss: 0.08946990966796875
train-epoch-step: 62-381 -- Loss: 0.23801536858081818
train-epoch-step: 62-382 -- Loss: 0.2280149906873703
train-epoch-step: 62-383 -- Loss: 0.17223021388053894
train-epoch-step: 62-384 -- Loss: 0.2081252485513687
train-epoch-step: 62-385 -- Loss: 0.18774710595607758
train-epoch-step: 62-386 -- Loss: 0.17894311249256134
train-epoch-step: 62-387 -- Loss: 0.1997639536857605
train-epoch-step: 62-388 -- Loss: 0.18684689700603485
train-epoch-step: 62-389 -- Loss: 0.16585934162139893
train-epoch-step: 62-390 -- Loss: 0.1428866982460022
train-epoch-step: 62-391 -- Loss: 0.14440599083900452
train-epoch-step: 62-392 -- Loss: 0.18200847506523132
train-epoch-step: 62-393 -- Loss: 0.14995190501213074
train-epoch-step: 62-394 -- Loss: 0.193634495139122
train-epoch-step: 62-395 -- Loss: 0.14995260536670685
train-epoch-step: 62-396 -- Loss: 0.12291862070560455
train-epoch-step: 62-397 -- Loss: 0.11994487047195435
train-epoch-step: 62-398 -- Loss: 0.19423812627792358
train-epoch-step: 62-399 -- Loss: 0.17120976746082306
train-epoch-step: 62-400 -- Loss: 0.2686856687068939
train-epoch-step: 62-401 -- Loss: 0.11622238159179688
train-epoch-step: 62-402 -- Loss: 0.24878579378128052
train-epoch-step: 62-403 -- Loss: 0.1516372710466385
train-epoch-step: 62-404 -- Loss: 0.13221332430839539
train-epoch-step: 62-405 -- Loss: 0.1353171169757843
train-epoch-step: 62-406 -- Loss: 0.16663537919521332
train-epoch-step: 62-407 -- Loss: 0.10902376472949982
train-epoch-step: 62-408 -- Loss: 0.16030487418174744
train-epoch-step: 62-409 -- Loss: 0.16499236226081848
train-epoch-step: 62-410 -- Loss: 0.17178186774253845
train-epoch-step: 62-411 -- Loss: 0.20526470243930817
train-epoch-step: 62-412 -- Loss: 0.12469463795423508
train-epoch-step: 62-413 -- Loss: 0.140010267496109
train-epoch-step: 62-414 -- Loss: 0.1287432163953781
train-epoch-step: 62-415 -- Loss: 0.1298130452632904
train-epoch-step: 62-416 -- Loss: 0.25614795088768005
train-epoch-step: 62-417 -- Loss: 0.18271344900131226
train-epoch-step: 62-418 -- Loss: 0.22250217199325562
train-epoch-step: 62-419 -- Loss: 0.16262957453727722
train-epoch-step: 62-420 -- Loss: 0.1451118141412735
train-epoch-step: 62-421 -- Loss: 0.17885559797286987
train-epoch-step: 62-422 -- Loss: 0.14635512232780457
train-epoch-step: 62-423 -- Loss: 0.1678438037633896
train-epoch-step: 62-424 -- Loss: 0.13416153192520142
train-epoch-step: 62-425 -- Loss: 0.1752961128950119
train-epoch-step: 62-426 -- Loss: 0.15990470349788666
train-epoch-step: 62-427 -- Loss: 0.11799609661102295
train-epoch-step: 62-428 -- Loss: 0.1893773227930069
train-epoch-step: 62-429 -- Loss: 0.1706242710351944
train-epoch-step: 62-430 -- Loss: 0.13533824682235718
train-epoch-step: 62-431 -- Loss: 0.1567990630865097
train-epoch-step: 62-432 -- Loss: 0.22776441276073456
train-epoch-step: 62-433 -- Loss: 0.1318470537662506
train-epoch-step: 62-434 -- Loss: 0.12426111102104187
train-epoch-step: 62-435 -- Loss: 0.15065354108810425
train-epoch-step: 62-436 -- Loss: 0.15046365559101105
train-epoch-step: 62-437 -- Loss: 0.12903937697410583
train-epoch-step: 62-438 -- Loss: 0.16212260723114014
train-epoch-step: 62-439 -- Loss: 0.2539355158805847
train-epoch-step: 62-440 -- Loss: 0.12705005705356598
train-epoch-step: 62-441 -- Loss: 0.20078428089618683
train-epoch-step: 62-442 -- Loss: 0.16899879276752472
train-epoch-step: 62-443 -- Loss: 0.14897559583187103
train-epoch-step: 62-444 -- Loss: 0.16893526911735535
train-epoch-step: 62-445 -- Loss: 0.17685270309448242
train-epoch-step: 62-446 -- Loss: 0.14942267537117004
train-epoch-step: 62-447 -- Loss: 0.18514016270637512
train-epoch-step: 62-448 -- Loss: 0.21998831629753113
train-epoch-step: 62-449 -- Loss: 0.19287261366844177
train-epoch-step: 62-450 -- Loss: 0.17826852202415466
train-epoch-step: 62-451 -- Loss: 0.14196470379829407
train-epoch-step: 62-452 -- Loss: 0.12985937297344208
train-epoch-step: 62-453 -- Loss: 0.09078878909349442
train-epoch-step: 62-454 -- Loss: 0.22122767567634583
train-epoch-step: 62-455 -- Loss: 0.11654254794120789
train-epoch-step: 62-456 -- Loss: 0.1167348176240921
train-epoch-step: 62-457 -- Loss: 0.21165388822555542
train-epoch-step: 62-458 -- Loss: 0.14200955629348755
train-epoch-step: 62-459 -- Loss: 0.20820896327495575
train-epoch-step: 62-460 -- Loss: 0.12239548563957214
train-epoch-step: 62-461 -- Loss: 0.13090012967586517
train-epoch-step: 62-462 -- Loss: 0.15079265832901
train-epoch-step: 62-463 -- Loss: 0.12906256318092346
train-epoch-step: 62-464 -- Loss: 0.15805672109127045
train-epoch-step: 62-465 -- Loss: 0.23433351516723633
train-epoch-step: 62-466 -- Loss: 0.19018983840942383
train-epoch-step: 62-467 -- Loss: 0.11009347438812256
train-epoch-step: 62-468 -- Loss: 0.15807098150253296
train-epoch-step: 62-469 -- Loss: 0.2023926079273224
train-epoch-step: 62-470 -- Loss: 0.1949785053730011
train-epoch-step: 62-471 -- Loss: 0.16368336975574493
train-epoch-step: 62-472 -- Loss: 0.15286073088645935
train-epoch-step: 62-473 -- Loss: 0.15187425911426544
train-epoch-step: 62-474 -- Loss: 0.11641997843980789
train-epoch-step: 62-475 -- Loss: 0.10368920117616653
train-epoch-step: 62-476 -- Loss: 0.19317035377025604
train-epoch-step: 62-477 -- Loss: 0.20030897855758667
train-epoch-step: 62-478 -- Loss: 0.19325004518032074
train-epoch-step: 62-479 -- Loss: 0.1371421217918396
train-epoch-step: 62-480 -- Loss: 0.1870708465576172
train-epoch-step: 62-481 -- Loss: 0.2747722566127777
train-epoch-step: 62-482 -- Loss: 0.25763487815856934
train-epoch-step: 62-483 -- Loss: 0.17371350526809692
train-epoch-step: 62-484 -- Loss: 0.2072148621082306
train-epoch-step: 62-485 -- Loss: 0.12582756578922272
train-epoch-step: 62-486 -- Loss: 0.22396674752235413
train-epoch-step: 62-487 -- Loss: 0.22306591272354126
train-epoch-step: 62-488 -- Loss: 0.18715427815914154
train-epoch-step: 62-489 -- Loss: 0.21117664873600006
train-epoch-step: 62-490 -- Loss: 0.13399681448936462
train-epoch-step: 62-491 -- Loss: 0.13255274295806885
train-epoch-step: 62-492 -- Loss: 0.12292059510946274
train-epoch-step: 62-493 -- Loss: 0.18932992219924927
train-epoch-step: 62-494 -- Loss: 0.20041686296463013
train-epoch-step: 62-495 -- Loss: 0.19552113115787506
train-epoch-step: 62-496 -- Loss: 0.13656333088874817
train-epoch-step: 62-497 -- Loss: 0.1803375482559204
train-epoch-step: 62-498 -- Loss: 0.14670909941196442
train-epoch-step: 62-499 -- Loss: 0.16621527075767517
train-epoch-step: 62-500 -- Loss: 0.15076065063476562
train-epoch-step: 62-501 -- Loss: 0.20831668376922607
train-epoch-step: 62-502 -- Loss: 0.15205766260623932
train-epoch-step: 62-503 -- Loss: 0.21203230321407318
train-epoch-step: 62-504 -- Loss: 0.11521144956350327
train-epoch-step: 62-505 -- Loss: 0.1634293794631958
train-epoch-step: 62-506 -- Loss: 0.11246059834957123
train-epoch-step: 62-507 -- Loss: 0.17689669132232666
train-epoch-step: 62-508 -- Loss: 0.16635920107364655
train-epoch-step: 62-509 -- Loss: 0.16498301923274994
train-epoch-step: 62-510 -- Loss: 0.12526091933250427
train-epoch-step: 62-511 -- Loss: 0.20765243470668793
train-epoch-step: 62-512 -- Loss: 0.17144352197647095
train-epoch-step: 62-513 -- Loss: 0.17818312346935272
train-epoch-step: 62-514 -- Loss: 0.1441306322813034
train-epoch-step: 62-515 -- Loss: 0.15186430513858795
train-epoch-step: 62-516 -- Loss: 0.1680155098438263
train-epoch-step: 62-517 -- Loss: 0.17194533348083496
train-epoch-step: 62-518 -- Loss: 0.13350330293178558
train-epoch-step: 62-519 -- Loss: 0.1311863213777542
train-epoch-step: 62-520 -- Loss: 0.1785118281841278
train-epoch-step: 62-521 -- Loss: 0.22495155036449432
train-epoch-step: 62-522 -- Loss: 0.16991464793682098
train-epoch-step: 62-523 -- Loss: 0.15491239726543427
train-epoch-step: 62-524 -- Loss: 0.16921764612197876
train-epoch-step: 62-525 -- Loss: 0.18498487770557404
train-epoch-step: 62-526 -- Loss: 0.1242094337940216
train-epoch-step: 62-527 -- Loss: 0.1426391452550888
train-epoch-step: 62-528 -- Loss: 0.1543036252260208
train-epoch-step: 62-529 -- Loss: 0.1491338610649109
train-epoch-step: 62-530 -- Loss: 0.16367772221565247
train-epoch-step: 62-531 -- Loss: 0.18918733298778534
train-epoch-step: 62-532 -- Loss: 0.1646108329296112
train-epoch-step: 62-533 -- Loss: 0.1706238090991974
train-epoch-step: 62-534 -- Loss: 0.12425896525382996
train-epoch-step: 62-535 -- Loss: 0.24334019422531128
train-epoch-step: 62-536 -- Loss: 0.15455010533332825
train-epoch-step: 62-537 -- Loss: 0.14186233282089233
train-epoch-step: 62-538 -- Loss: 0.09984256327152252
train-epoch-step: 62-539 -- Loss: 0.1845550537109375
train-epoch-step: 62-540 -- Loss: 0.13794812560081482
train-epoch-step: 62-541 -- Loss: 0.19816017150878906
train-epoch-step: 62-542 -- Loss: 0.21579083800315857
train-epoch-step: 62-543 -- Loss: 0.16262070834636688
train-epoch-step: 62-544 -- Loss: 0.23174777626991272
train-epoch-step: 62-545 -- Loss: 0.1873183399438858
train-epoch-step: 62-546 -- Loss: 0.207147479057312
train-epoch-step: 62-547 -- Loss: 0.17995931208133698
train-epoch-step: 62-548 -- Loss: 0.0914488136768341
train-epoch-step: 62-549 -- Loss: 0.15028104186058044
train-epoch-step: 62-550 -- Loss: 0.1964418888092041
train-epoch-step: 62-551 -- Loss: 0.1486523598432541
train-epoch-step: 62-552 -- Loss: 0.12129174172878265
train-epoch-step: 62-553 -- Loss: 0.18246693909168243
train-epoch-step: 62-554 -- Loss: 0.18152183294296265
train-epoch-step: 62-555 -- Loss: 0.20727074146270752
train-epoch-step: 62-556 -- Loss: 0.13834203779697418
train-epoch-step: 62-557 -- Loss: 0.2268163561820984
train-epoch-step: 62-558 -- Loss: 0.22160154581069946
train-epoch-step: 62-559 -- Loss: 0.13570648431777954
train-epoch-step: 62-560 -- Loss: 0.19959242641925812
train-epoch-step: 62-561 -- Loss: 0.17480236291885376
train-epoch-step: 62-562 -- Loss: 0.16120511293411255
train-epoch-step: 62-563 -- Loss: 0.17584796249866486
train-epoch-step: 62-564 -- Loss: 0.09683654457330704
train-epoch-step: 62-565 -- Loss: 0.1807851940393448
train-epoch-step: 62-566 -- Loss: 0.1425824761390686
train-epoch-step: 62-567 -- Loss: 0.20363765954971313
train-epoch-step: 62-568 -- Loss: 0.1565088927745819
train-epoch-step: 62-569 -- Loss: 0.23785865306854248
train-epoch-step: 62-570 -- Loss: 0.15937377512454987
train-epoch-step: 62-571 -- Loss: 0.20470693707466125
train-epoch-step: 62-572 -- Loss: 0.22993630170822144
train-epoch-step: 62-573 -- Loss: 0.1966642439365387
train-epoch-step: 62-574 -- Loss: 0.2385515570640564
train-epoch-step: 62-575 -- Loss: 0.2800670564174652
train-epoch-step: 62-576 -- Loss: 0.11379668116569519
train-epoch-step: 62-577 -- Loss: 0.16455328464508057
train-epoch-step: 62-578 -- Loss: 0.20680351555347443
train-epoch-step: 62-579 -- Loss: 0.1613316535949707
train-epoch-step: 62-580 -- Loss: 0.17038632929325104
train-epoch-step: 62-581 -- Loss: 0.13648822903633118
train-epoch-step: 62-582 -- Loss: 0.20014624297618866
train-epoch-step: 62-583 -- Loss: 0.2055892050266266
train-epoch-step: 62-584 -- Loss: 0.15780101716518402
train-epoch-step: 62-585 -- Loss: 0.18744546175003052
train-epoch-step: 62-586 -- Loss: 0.2447575032711029
train-epoch-step: 62-587 -- Loss: 0.1568172723054886
train-epoch-step: 62-588 -- Loss: 0.1257815957069397
val-epoch-step: 62-589 -- Loss: 0.20747998356819153
val-epoch-step: 62-590 -- Loss: 0.15157297253608704
val-epoch-step: 62-591 -- Loss: 0.22597387433052063
val-epoch-step: 62-592 -- Loss: 0.17267201840877533
val-epoch-step: 62-593 -- Loss: 0.1528986543416977
val-epoch-step: 62-594 -- Loss: 0.4104710519313812
val-epoch-step: 62-595 -- Loss: 0.1708076000213623
val-epoch-step: 62-596 -- Loss: 0.20347514748573303
val-epoch-step: 62-597 -- Loss: 0.16864553093910217
val-epoch-step: 62-598 -- Loss: 0.14408449828624725
val-epoch-step: 62-599 -- Loss: 0.18145310878753662
val-epoch-step: 62-600 -- Loss: 0.1640074998140335
val-epoch-step: 62-601 -- Loss: 0.15947701036930084
val-epoch-step: 62-602 -- Loss: 0.1310104876756668
val-epoch-step: 62-603 -- Loss: 0.2170332819223404
val-epoch-step: 62-604 -- Loss: 0.14150328934192657
val-epoch-step: 62-605 -- Loss: 0.14024706184864044
val-epoch-step: 62-606 -- Loss: 0.2584443688392639
val-epoch-step: 62-607 -- Loss: 0.12362230569124222
val-epoch-step: 62-608 -- Loss: 0.24645912647247314
val-epoch-step: 62-609 -- Loss: 0.1611957848072052
val-epoch-step: 62-610 -- Loss: 0.1754203885793686
val-epoch-step: 62-611 -- Loss: 0.16574516892433167
val-epoch-step: 62-612 -- Loss: 0.4259217381477356
val-epoch-step: 62-613 -- Loss: 0.1666625440120697
val-epoch-step: 62-614 -- Loss: 0.16801951825618744
val-epoch-step: 62-615 -- Loss: 0.17327596247196198
val-epoch-step: 62-616 -- Loss: 0.14101345837116241
val-epoch-step: 62-617 -- Loss: 0.1844412386417389
val-epoch-step: 62-618 -- Loss: 0.17540481686592102
val-epoch-step: 62-619 -- Loss: 0.20425084233283997
val-epoch-step: 62-620 -- Loss: 0.1302344650030136
val-epoch-step: 62-621 -- Loss: 0.12153861671686172
val-epoch-step: 62-622 -- Loss: 0.1398356407880783
val-epoch-step: 62-623 -- Loss: 0.1453676074743271
val-epoch-step: 62-624 -- Loss: 0.14069527387619019
val-epoch-step: 62-625 -- Loss: 0.154150128364563
val-epoch-step: 62-626 -- Loss: 0.14556409418582916
val-epoch-step: 62-627 -- Loss: 0.17669540643692017
val-epoch-step: 62-628 -- Loss: 0.652237057685852
val-epoch-step: 62-629 -- Loss: 0.1895645260810852
val-epoch-step: 62-630 -- Loss: 0.34096431732177734
val-epoch-step: 62-631 -- Loss: 0.13863593339920044
val-epoch-step: 62-632 -- Loss: 0.1961176097393036
val-epoch-step: 62-633 -- Loss: 0.14822721481323242
val-epoch-step: 62-634 -- Loss: 0.15337152779102325
val-epoch-step: 62-635 -- Loss: 0.10976208746433258
val-epoch-step: 62-636 -- Loss: 0.1553114503622055
val-epoch-step: 62-637 -- Loss: 0.17667311429977417
val-epoch-step: 62-638 -- Loss: 0.15010911226272583
val-epoch-step: 62-639 -- Loss: 0.25385230779647827
val-epoch-step: 62-640 -- Loss: 0.2464987188577652
val-epoch-step: 62-641 -- Loss: 0.12040755897760391
val-epoch-step: 62-642 -- Loss: 0.18762722611427307
val-epoch-step: 62-643 -- Loss: 0.19926193356513977
val-epoch-step: 62-644 -- Loss: 0.1596893072128296
val-epoch-step: 62-645 -- Loss: 0.21598143875598907
val-epoch-step: 62-646 -- Loss: 0.1339472532272339
val-epoch-step: 62-647 -- Loss: 0.1290745586156845
val-epoch-step: 62-648 -- Loss: 0.1543211191892624
val-epoch-step: 62-649 -- Loss: 0.2003478705883026
val-epoch-step: 62-650 -- Loss: 0.243545264005661
val-epoch-step: 62-651 -- Loss: 0.14542466402053833
val-epoch-step: 62-652 -- Loss: 0.1544780433177948
val-epoch-step: 62-653 -- Loss: 0.20921573042869568
val-epoch-step: 62-654 -- Loss: 0.10989518463611603
Epoch: 62 -- Train Loss: tensor(0.1395, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 63-0 -- Loss: 0.21639086306095123
train-epoch-step: 63-1 -- Loss: 0.13717854022979736
train-epoch-step: 63-2 -- Loss: 0.18832620978355408
train-epoch-step: 63-3 -- Loss: 0.1379241794347763
train-epoch-step: 63-4 -- Loss: 0.1535380780696869
train-epoch-step: 63-5 -- Loss: 0.1738080382347107
train-epoch-step: 63-6 -- Loss: 0.2110762596130371
train-epoch-step: 63-7 -- Loss: 0.16196022927761078
train-epoch-step: 63-8 -- Loss: 0.17213201522827148
train-epoch-step: 63-9 -- Loss: 0.2384643852710724
train-epoch-step: 63-10 -- Loss: 0.18205493688583374
train-epoch-step: 63-11 -- Loss: 0.1657075434923172
train-epoch-step: 63-12 -- Loss: 0.1463848054409027
train-epoch-step: 63-13 -- Loss: 0.1711621880531311
train-epoch-step: 63-14 -- Loss: 0.1543404757976532
train-epoch-step: 63-15 -- Loss: 0.15194788575172424
train-epoch-step: 63-16 -- Loss: 0.16108721494674683
train-epoch-step: 63-17 -- Loss: 0.20355328917503357
train-epoch-step: 63-18 -- Loss: 0.18625882267951965
train-epoch-step: 63-19 -- Loss: 0.12715525925159454
train-epoch-step: 63-20 -- Loss: 0.20561999082565308
train-epoch-step: 63-21 -- Loss: 0.24253341555595398
train-epoch-step: 63-22 -- Loss: 0.13548094034194946
train-epoch-step: 63-23 -- Loss: 0.13983909785747528
train-epoch-step: 63-24 -- Loss: 0.12344494462013245
train-epoch-step: 63-25 -- Loss: 0.21803949773311615
train-epoch-step: 63-26 -- Loss: 0.18592599034309387
train-epoch-step: 63-27 -- Loss: 0.22546130418777466
train-epoch-step: 63-28 -- Loss: 0.12133519351482391
train-epoch-step: 63-29 -- Loss: 0.2323412150144577
train-epoch-step: 63-30 -- Loss: 0.10562041401863098
train-epoch-step: 63-31 -- Loss: 0.12881483137607574
train-epoch-step: 63-32 -- Loss: 0.16720695793628693
train-epoch-step: 63-33 -- Loss: 0.26542240381240845
train-epoch-step: 63-34 -- Loss: 0.16229167580604553
train-epoch-step: 63-35 -- Loss: 0.23045504093170166
train-epoch-step: 63-36 -- Loss: 0.1326039433479309
train-epoch-step: 63-37 -- Loss: 0.13549454510211945
train-epoch-step: 63-38 -- Loss: 0.1676650196313858
train-epoch-step: 63-39 -- Loss: 0.20705994963645935
train-epoch-step: 63-40 -- Loss: 0.1821906566619873
train-epoch-step: 63-41 -- Loss: 0.21234364807605743
train-epoch-step: 63-42 -- Loss: 0.1441280096769333
train-epoch-step: 63-43 -- Loss: 0.25806862115859985
train-epoch-step: 63-44 -- Loss: 0.12061293423175812
train-epoch-step: 63-45 -- Loss: 0.11540653556585312
train-epoch-step: 63-46 -- Loss: 0.16229049861431122
train-epoch-step: 63-47 -- Loss: 0.19685900211334229
train-epoch-step: 63-48 -- Loss: 0.14920851588249207
train-epoch-step: 63-49 -- Loss: 0.2116370052099228
train-epoch-step: 63-50 -- Loss: 0.10781238973140717
train-epoch-step: 63-51 -- Loss: 0.17005905508995056
train-epoch-step: 63-52 -- Loss: 0.15704695880413055
train-epoch-step: 63-53 -- Loss: 0.19885559380054474
train-epoch-step: 63-54 -- Loss: 0.2777876853942871
train-epoch-step: 63-55 -- Loss: 0.16092178225517273
train-epoch-step: 63-56 -- Loss: 0.17199599742889404
train-epoch-step: 63-57 -- Loss: 0.2243771255016327
train-epoch-step: 63-58 -- Loss: 0.2789907157421112
train-epoch-step: 63-59 -- Loss: 0.23119094967842102
train-epoch-step: 63-60 -- Loss: 0.12647397816181183
train-epoch-step: 63-61 -- Loss: 0.19180536270141602
train-epoch-step: 63-62 -- Loss: 0.178521528840065
train-epoch-step: 63-63 -- Loss: 0.13002149760723114
train-epoch-step: 63-64 -- Loss: 0.1379934400320053
train-epoch-step: 63-65 -- Loss: 0.1725783348083496
train-epoch-step: 63-66 -- Loss: 0.10325319319963455
train-epoch-step: 63-67 -- Loss: 0.13026052713394165
train-epoch-step: 63-68 -- Loss: 0.2035384327173233
train-epoch-step: 63-69 -- Loss: 0.1162865087389946
train-epoch-step: 63-70 -- Loss: 0.2170724868774414
train-epoch-step: 63-71 -- Loss: 0.2529042661190033
train-epoch-step: 63-72 -- Loss: 0.16792500019073486
train-epoch-step: 63-73 -- Loss: 0.20109917223453522
train-epoch-step: 63-74 -- Loss: 0.0925600603222847
train-epoch-step: 63-75 -- Loss: 0.12234631180763245
train-epoch-step: 63-76 -- Loss: 0.14153239130973816
train-epoch-step: 63-77 -- Loss: 0.22182095050811768
train-epoch-step: 63-78 -- Loss: 0.2570609748363495
train-epoch-step: 63-79 -- Loss: 0.1815207302570343
train-epoch-step: 63-80 -- Loss: 0.2493906319141388
train-epoch-step: 63-81 -- Loss: 0.12419325858354568
train-epoch-step: 63-82 -- Loss: 0.24408239126205444
train-epoch-step: 63-83 -- Loss: 0.17197231948375702
train-epoch-step: 63-84 -- Loss: 0.18324564397335052
train-epoch-step: 63-85 -- Loss: 0.16656219959259033
train-epoch-step: 63-86 -- Loss: 0.1177845299243927
train-epoch-step: 63-87 -- Loss: 0.20507201552391052
train-epoch-step: 63-88 -- Loss: 0.13772758841514587
train-epoch-step: 63-89 -- Loss: 0.18075403571128845
train-epoch-step: 63-90 -- Loss: 0.18301668763160706
train-epoch-step: 63-91 -- Loss: 0.23294907808303833
train-epoch-step: 63-92 -- Loss: 0.15226852893829346
train-epoch-step: 63-93 -- Loss: 0.16550922393798828
train-epoch-step: 63-94 -- Loss: 0.2138606309890747
train-epoch-step: 63-95 -- Loss: 0.18338844180107117
train-epoch-step: 63-96 -- Loss: 0.20763108134269714
train-epoch-step: 63-97 -- Loss: 0.16820651292800903
train-epoch-step: 63-98 -- Loss: 0.14856024086475372
train-epoch-step: 63-99 -- Loss: 0.17722362279891968
train-epoch-step: 63-100 -- Loss: 0.18173420429229736
train-epoch-step: 63-101 -- Loss: 0.24881397187709808
train-epoch-step: 63-102 -- Loss: 0.20872342586517334
train-epoch-step: 63-103 -- Loss: 0.17723695933818817
train-epoch-step: 63-104 -- Loss: 0.14360260963439941
train-epoch-step: 63-105 -- Loss: 0.25377601385116577
train-epoch-step: 63-106 -- Loss: 0.1687798798084259
train-epoch-step: 63-107 -- Loss: 0.18314526975154877
train-epoch-step: 63-108 -- Loss: 0.18527299165725708
train-epoch-step: 63-109 -- Loss: 0.14022254943847656
train-epoch-step: 63-110 -- Loss: 0.1754344403743744
train-epoch-step: 63-111 -- Loss: 0.1749802678823471
train-epoch-step: 63-112 -- Loss: 0.15773651003837585
train-epoch-step: 63-113 -- Loss: 0.1549605131149292
train-epoch-step: 63-114 -- Loss: 0.18883639574050903
train-epoch-step: 63-115 -- Loss: 0.15609106421470642
train-epoch-step: 63-116 -- Loss: 0.13430878520011902
train-epoch-step: 63-117 -- Loss: 0.1238304153084755
train-epoch-step: 63-118 -- Loss: 0.1871050000190735
train-epoch-step: 63-119 -- Loss: 0.14679007232189178
train-epoch-step: 63-120 -- Loss: 0.24002394080162048
train-epoch-step: 63-121 -- Loss: 0.22249028086662292
train-epoch-step: 63-122 -- Loss: 0.21065616607666016
train-epoch-step: 63-123 -- Loss: 0.19773966073989868
train-epoch-step: 63-124 -- Loss: 0.11629976332187653
train-epoch-step: 63-125 -- Loss: 0.14828374981880188
train-epoch-step: 63-126 -- Loss: 0.22263771295547485
train-epoch-step: 63-127 -- Loss: 0.1630411148071289
train-epoch-step: 63-128 -- Loss: 0.1649596393108368
train-epoch-step: 63-129 -- Loss: 0.13661201298236847
train-epoch-step: 63-130 -- Loss: 0.18600109219551086
train-epoch-step: 63-131 -- Loss: 0.13130071759223938
train-epoch-step: 63-132 -- Loss: 0.18277490139007568
train-epoch-step: 63-133 -- Loss: 0.11178790777921677
train-epoch-step: 63-134 -- Loss: 0.1879948377609253
train-epoch-step: 63-135 -- Loss: 0.12371969223022461
train-epoch-step: 63-136 -- Loss: 0.12526512145996094
train-epoch-step: 63-137 -- Loss: 0.2363777607679367
train-epoch-step: 63-138 -- Loss: 0.24847692251205444
train-epoch-step: 63-139 -- Loss: 0.13137614727020264
train-epoch-step: 63-140 -- Loss: 0.20388036966323853
train-epoch-step: 63-141 -- Loss: 0.22267451882362366
train-epoch-step: 63-142 -- Loss: 0.19779683649539948
train-epoch-step: 63-143 -- Loss: 0.16777631640434265
train-epoch-step: 63-144 -- Loss: 0.17649582028388977
train-epoch-step: 63-145 -- Loss: 0.13675418496131897
train-epoch-step: 63-146 -- Loss: 0.17219656705856323
train-epoch-step: 63-147 -- Loss: 0.16468767821788788
train-epoch-step: 63-148 -- Loss: 0.159652978181839
train-epoch-step: 63-149 -- Loss: 0.11609966307878494
train-epoch-step: 63-150 -- Loss: 0.1826864331960678
train-epoch-step: 63-151 -- Loss: 0.1946021318435669
train-epoch-step: 63-152 -- Loss: 0.18501068651676178
train-epoch-step: 63-153 -- Loss: 0.26203465461730957
train-epoch-step: 63-154 -- Loss: 0.12677499651908875
train-epoch-step: 63-155 -- Loss: 0.1337415724992752
train-epoch-step: 63-156 -- Loss: 0.11421681195497513
train-epoch-step: 63-157 -- Loss: 0.1562952697277069
train-epoch-step: 63-158 -- Loss: 0.1601482778787613
train-epoch-step: 63-159 -- Loss: 0.1719740927219391
train-epoch-step: 63-160 -- Loss: 0.20867158472537994
train-epoch-step: 63-161 -- Loss: 0.19674527645111084
train-epoch-step: 63-162 -- Loss: 0.21118304133415222
train-epoch-step: 63-163 -- Loss: 0.180457204580307
train-epoch-step: 63-164 -- Loss: 0.18934929370880127
train-epoch-step: 63-165 -- Loss: 0.15737755596637726
train-epoch-step: 63-166 -- Loss: 0.11834516376256943
train-epoch-step: 63-167 -- Loss: 0.121440090239048
train-epoch-step: 63-168 -- Loss: 0.19367627799510956
train-epoch-step: 63-169 -- Loss: 0.1390094757080078
train-epoch-step: 63-170 -- Loss: 0.19523945450782776
train-epoch-step: 63-171 -- Loss: 0.1455293893814087
train-epoch-step: 63-172 -- Loss: 0.25530192255973816
train-epoch-step: 63-173 -- Loss: 0.12880349159240723
train-epoch-step: 63-174 -- Loss: 0.24018552899360657
train-epoch-step: 63-175 -- Loss: 0.19332970678806305
train-epoch-step: 63-176 -- Loss: 0.12875328958034515
train-epoch-step: 63-177 -- Loss: 0.187442347407341
train-epoch-step: 63-178 -- Loss: 0.1768759787082672
train-epoch-step: 63-179 -- Loss: 0.14691495895385742
train-epoch-step: 63-180 -- Loss: 0.1494825780391693
train-epoch-step: 63-181 -- Loss: 0.1662110984325409
train-epoch-step: 63-182 -- Loss: 0.17692068219184875
train-epoch-step: 63-183 -- Loss: 0.2661769390106201
train-epoch-step: 63-184 -- Loss: 0.13364775478839874
train-epoch-step: 63-185 -- Loss: 0.14015433192253113
train-epoch-step: 63-186 -- Loss: 0.18737544119358063
train-epoch-step: 63-187 -- Loss: 0.20373469591140747
train-epoch-step: 63-188 -- Loss: 0.17499205470085144
train-epoch-step: 63-189 -- Loss: 0.09935709089040756
train-epoch-step: 63-190 -- Loss: 0.17676618695259094
train-epoch-step: 63-191 -- Loss: 0.1549254208803177
train-epoch-step: 63-192 -- Loss: 0.22277449071407318
train-epoch-step: 63-193 -- Loss: 0.21245527267456055
train-epoch-step: 63-194 -- Loss: 0.17761431634426117
train-epoch-step: 63-195 -- Loss: 0.16228516399860382
train-epoch-step: 63-196 -- Loss: 0.16219760477542877
train-epoch-step: 63-197 -- Loss: 0.12664282321929932
train-epoch-step: 63-198 -- Loss: 0.12519358098506927
train-epoch-step: 63-199 -- Loss: 0.15259435772895813
train-epoch-step: 63-200 -- Loss: 0.12525655329227448
train-epoch-step: 63-201 -- Loss: 0.18430040776729584
train-epoch-step: 63-202 -- Loss: 0.13331098854541779
train-epoch-step: 63-203 -- Loss: 0.16972774267196655
train-epoch-step: 63-204 -- Loss: 0.13924407958984375
train-epoch-step: 63-205 -- Loss: 0.17874003946781158
train-epoch-step: 63-206 -- Loss: 0.20386698842048645
train-epoch-step: 63-207 -- Loss: 0.129480242729187
train-epoch-step: 63-208 -- Loss: 0.17529499530792236
train-epoch-step: 63-209 -- Loss: 0.14291347563266754
train-epoch-step: 63-210 -- Loss: 0.13177144527435303
train-epoch-step: 63-211 -- Loss: 0.20112916827201843
train-epoch-step: 63-212 -- Loss: 0.196059912443161
train-epoch-step: 63-213 -- Loss: 0.12547467648983002
train-epoch-step: 63-214 -- Loss: 0.14753814041614532
train-epoch-step: 63-215 -- Loss: 0.12857894599437714
train-epoch-step: 63-216 -- Loss: 0.20744475722312927
train-epoch-step: 63-217 -- Loss: 0.2073332667350769
train-epoch-step: 63-218 -- Loss: 0.15291057527065277
train-epoch-step: 63-219 -- Loss: 0.1649789661169052
train-epoch-step: 63-220 -- Loss: 0.12834350764751434
train-epoch-step: 63-221 -- Loss: 0.19482217729091644
train-epoch-step: 63-222 -- Loss: 0.11109499633312225
train-epoch-step: 63-223 -- Loss: 0.16807891428470612
train-epoch-step: 63-224 -- Loss: 0.1905829906463623
train-epoch-step: 63-225 -- Loss: 0.25619304180145264
train-epoch-step: 63-226 -- Loss: 0.20301035046577454
train-epoch-step: 63-227 -- Loss: 0.21723045408725739
train-epoch-step: 63-228 -- Loss: 0.20353472232818604
train-epoch-step: 63-229 -- Loss: 0.1675758957862854
train-epoch-step: 63-230 -- Loss: 0.1643105149269104
train-epoch-step: 63-231 -- Loss: 0.14855346083641052
train-epoch-step: 63-232 -- Loss: 0.1779565066099167
train-epoch-step: 63-233 -- Loss: 0.0822579562664032
train-epoch-step: 63-234 -- Loss: 0.1711406409740448
train-epoch-step: 63-235 -- Loss: 0.14463819563388824
train-epoch-step: 63-236 -- Loss: 0.17983800172805786
train-epoch-step: 63-237 -- Loss: 0.2245684564113617
train-epoch-step: 63-238 -- Loss: 0.14991606771945953
train-epoch-step: 63-239 -- Loss: 0.1329387128353119
train-epoch-step: 63-240 -- Loss: 0.21425439417362213
train-epoch-step: 63-241 -- Loss: 0.14988406002521515
train-epoch-step: 63-242 -- Loss: 0.21154585480690002
train-epoch-step: 63-243 -- Loss: 0.23492170870304108
train-epoch-step: 63-244 -- Loss: 0.19959436357021332
train-epoch-step: 63-245 -- Loss: 0.20758138597011566
train-epoch-step: 63-246 -- Loss: 0.21044902503490448
train-epoch-step: 63-247 -- Loss: 0.2064605951309204
train-epoch-step: 63-248 -- Loss: 0.18233206868171692
train-epoch-step: 63-249 -- Loss: 0.13332000374794006
train-epoch-step: 63-250 -- Loss: 0.19431577622890472
train-epoch-step: 63-251 -- Loss: 0.10608164221048355
train-epoch-step: 63-252 -- Loss: 0.1957332193851471
train-epoch-step: 63-253 -- Loss: 0.13226431608200073
train-epoch-step: 63-254 -- Loss: 0.20764555037021637
train-epoch-step: 63-255 -- Loss: 0.14418764412403107
train-epoch-step: 63-256 -- Loss: 0.15200509130954742
train-epoch-step: 63-257 -- Loss: 0.18179461359977722
train-epoch-step: 63-258 -- Loss: 0.138126939535141
train-epoch-step: 63-259 -- Loss: 0.10947515070438385
train-epoch-step: 63-260 -- Loss: 0.19753338396549225
train-epoch-step: 63-261 -- Loss: 0.17069511115550995
train-epoch-step: 63-262 -- Loss: 0.27750664949417114
train-epoch-step: 63-263 -- Loss: 0.19364723563194275
train-epoch-step: 63-264 -- Loss: 0.16795790195465088
train-epoch-step: 63-265 -- Loss: 0.10433755815029144
train-epoch-step: 63-266 -- Loss: 0.15095949172973633
train-epoch-step: 63-267 -- Loss: 0.1278170645236969
train-epoch-step: 63-268 -- Loss: 0.11671160906553268
train-epoch-step: 63-269 -- Loss: 0.16637320816516876
train-epoch-step: 63-270 -- Loss: 0.1039988100528717
train-epoch-step: 63-271 -- Loss: 0.14583876729011536
train-epoch-step: 63-272 -- Loss: 0.11194617301225662
train-epoch-step: 63-273 -- Loss: 0.12378793954849243
train-epoch-step: 63-274 -- Loss: 0.18302923440933228
train-epoch-step: 63-275 -- Loss: 0.18445134162902832
train-epoch-step: 63-276 -- Loss: 0.15128330886363983
train-epoch-step: 63-277 -- Loss: 0.15386851131916046
train-epoch-step: 63-278 -- Loss: 0.13267409801483154
train-epoch-step: 63-279 -- Loss: 0.13616886734962463
train-epoch-step: 63-280 -- Loss: 0.20821928977966309
train-epoch-step: 63-281 -- Loss: 0.16915029287338257
train-epoch-step: 63-282 -- Loss: 0.14075513184070587
train-epoch-step: 63-283 -- Loss: 0.11249788850545883
train-epoch-step: 63-284 -- Loss: 0.12991580367088318
train-epoch-step: 63-285 -- Loss: 0.18482156097888947
train-epoch-step: 63-286 -- Loss: 0.1513080894947052
train-epoch-step: 63-287 -- Loss: 0.19484257698059082
train-epoch-step: 63-288 -- Loss: 0.08997267484664917
train-epoch-step: 63-289 -- Loss: 0.11856767535209656
train-epoch-step: 63-290 -- Loss: 0.17532438039779663
train-epoch-step: 63-291 -- Loss: 0.11221279203891754
train-epoch-step: 63-292 -- Loss: 0.15061363577842712
train-epoch-step: 63-293 -- Loss: 0.13650870323181152
train-epoch-step: 63-294 -- Loss: 0.15537147223949432
train-epoch-step: 63-295 -- Loss: 0.255354106426239
train-epoch-step: 63-296 -- Loss: 0.15347571671009064
train-epoch-step: 63-297 -- Loss: 0.16992710530757904
train-epoch-step: 63-298 -- Loss: 0.2245539426803589
train-epoch-step: 63-299 -- Loss: 0.14180484414100647
train-epoch-step: 63-300 -- Loss: 0.15833531320095062
train-epoch-step: 63-301 -- Loss: 0.1622609794139862
train-epoch-step: 63-302 -- Loss: 0.21286748349666595
train-epoch-step: 63-303 -- Loss: 0.19581571221351624
train-epoch-step: 63-304 -- Loss: 0.12110371887683868
train-epoch-step: 63-305 -- Loss: 0.14174823462963104
train-epoch-step: 63-306 -- Loss: 0.2117861956357956
train-epoch-step: 63-307 -- Loss: 0.16085895895957947
train-epoch-step: 63-308 -- Loss: 0.20977869629859924
train-epoch-step: 63-309 -- Loss: 0.15075446665287018
train-epoch-step: 63-310 -- Loss: 0.16004207730293274
train-epoch-step: 63-311 -- Loss: 0.1521332710981369
train-epoch-step: 63-312 -- Loss: 0.19435185194015503
train-epoch-step: 63-313 -- Loss: 0.09554903954267502
train-epoch-step: 63-314 -- Loss: 0.1815776526927948
train-epoch-step: 63-315 -- Loss: 0.16603808104991913
train-epoch-step: 63-316 -- Loss: 0.14923308789730072
train-epoch-step: 63-317 -- Loss: 0.13674479722976685
train-epoch-step: 63-318 -- Loss: 0.1606481820344925
train-epoch-step: 63-319 -- Loss: 0.16442307829856873
train-epoch-step: 63-320 -- Loss: 0.11503691971302032
train-epoch-step: 63-321 -- Loss: 0.12632519006729126
train-epoch-step: 63-322 -- Loss: 0.20754197239875793
train-epoch-step: 63-323 -- Loss: 0.15499408543109894
train-epoch-step: 63-324 -- Loss: 0.2507191300392151
train-epoch-step: 63-325 -- Loss: 0.15324747562408447
train-epoch-step: 63-326 -- Loss: 0.1616627275943756
train-epoch-step: 63-327 -- Loss: 0.19564929604530334
train-epoch-step: 63-328 -- Loss: 0.1884051263332367
train-epoch-step: 63-329 -- Loss: 0.33239659667015076
train-epoch-step: 63-330 -- Loss: 0.3451979160308838
train-epoch-step: 63-331 -- Loss: 0.2020154595375061
train-epoch-step: 63-332 -- Loss: 0.09696279466152191
train-epoch-step: 63-333 -- Loss: 0.1793108880519867
train-epoch-step: 63-334 -- Loss: 0.15157343447208405
train-epoch-step: 63-335 -- Loss: 0.16602110862731934
train-epoch-step: 63-336 -- Loss: 0.1470900923013687
train-epoch-step: 63-337 -- Loss: 0.19420719146728516
train-epoch-step: 63-338 -- Loss: 0.15661418437957764
train-epoch-step: 63-339 -- Loss: 0.14138011634349823
train-epoch-step: 63-340 -- Loss: 0.1900058090686798
train-epoch-step: 63-341 -- Loss: 0.15261903405189514
train-epoch-step: 63-342 -- Loss: 0.16049699485301971
train-epoch-step: 63-343 -- Loss: 0.14844077825546265
train-epoch-step: 63-344 -- Loss: 0.15920282900333405
train-epoch-step: 63-345 -- Loss: 0.12171963602304459
train-epoch-step: 63-346 -- Loss: 0.19949039816856384
train-epoch-step: 63-347 -- Loss: 0.14957433938980103
train-epoch-step: 63-348 -- Loss: 0.20140290260314941
train-epoch-step: 63-349 -- Loss: 0.1954728662967682
train-epoch-step: 63-350 -- Loss: 0.2507477402687073
train-epoch-step: 63-351 -- Loss: 0.1861436367034912
train-epoch-step: 63-352 -- Loss: 0.11706846952438354
train-epoch-step: 63-353 -- Loss: 0.18862706422805786
train-epoch-step: 63-354 -- Loss: 0.273905485868454
train-epoch-step: 63-355 -- Loss: 0.11251405626535416
train-epoch-step: 63-356 -- Loss: 0.11306977272033691
train-epoch-step: 63-357 -- Loss: 0.19822832942008972
train-epoch-step: 63-358 -- Loss: 0.18361936509609222
train-epoch-step: 63-359 -- Loss: 0.14130808413028717
train-epoch-step: 63-360 -- Loss: 0.1208278015255928
train-epoch-step: 63-361 -- Loss: 0.22841596603393555
train-epoch-step: 63-362 -- Loss: 0.16595301032066345
train-epoch-step: 63-363 -- Loss: 0.1062084436416626
train-epoch-step: 63-364 -- Loss: 0.17466260492801666
train-epoch-step: 63-365 -- Loss: 0.16358628869056702
train-epoch-step: 63-366 -- Loss: 0.19850216805934906
train-epoch-step: 63-367 -- Loss: 0.21851776540279388
train-epoch-step: 63-368 -- Loss: 0.19450479745864868
train-epoch-step: 63-369 -- Loss: 0.2687206268310547
train-epoch-step: 63-370 -- Loss: 0.12260613590478897
train-epoch-step: 63-371 -- Loss: 0.11854202300310135
train-epoch-step: 63-372 -- Loss: 0.14460325241088867
train-epoch-step: 63-373 -- Loss: 0.1794353574514389
train-epoch-step: 63-374 -- Loss: 0.1492539644241333
train-epoch-step: 63-375 -- Loss: 0.260707825422287
train-epoch-step: 63-376 -- Loss: 0.1542847603559494
train-epoch-step: 63-377 -- Loss: 0.21912498772144318
train-epoch-step: 63-378 -- Loss: 0.19446121156215668
train-epoch-step: 63-379 -- Loss: 0.11540590226650238
train-epoch-step: 63-380 -- Loss: 0.08719344437122345
train-epoch-step: 63-381 -- Loss: 0.2300463318824768
train-epoch-step: 63-382 -- Loss: 0.23779793083667755
train-epoch-step: 63-383 -- Loss: 0.16610155999660492
train-epoch-step: 63-384 -- Loss: 0.21408012509346008
train-epoch-step: 63-385 -- Loss: 0.18904021382331848
train-epoch-step: 63-386 -- Loss: 0.18379515409469604
train-epoch-step: 63-387 -- Loss: 0.1935063898563385
train-epoch-step: 63-388 -- Loss: 0.1778923124074936
train-epoch-step: 63-389 -- Loss: 0.16132855415344238
train-epoch-step: 63-390 -- Loss: 0.14560231566429138
train-epoch-step: 63-391 -- Loss: 0.14085163176059723
train-epoch-step: 63-392 -- Loss: 0.18136462569236755
train-epoch-step: 63-393 -- Loss: 0.14896079897880554
train-epoch-step: 63-394 -- Loss: 0.1974344253540039
train-epoch-step: 63-395 -- Loss: 0.15756569802761078
train-epoch-step: 63-396 -- Loss: 0.12335525453090668
train-epoch-step: 63-397 -- Loss: 0.12347568571567535
train-epoch-step: 63-398 -- Loss: 0.1919703483581543
train-epoch-step: 63-399 -- Loss: 0.17235001921653748
train-epoch-step: 63-400 -- Loss: 0.264222115278244
train-epoch-step: 63-401 -- Loss: 0.11657624691724777
train-epoch-step: 63-402 -- Loss: 0.24853049218654633
train-epoch-step: 63-403 -- Loss: 0.14764854311943054
train-epoch-step: 63-404 -- Loss: 0.13176465034484863
train-epoch-step: 63-405 -- Loss: 0.14072152972221375
train-epoch-step: 63-406 -- Loss: 0.16033005714416504
train-epoch-step: 63-407 -- Loss: 0.10844799131155014
train-epoch-step: 63-408 -- Loss: 0.155796080827713
train-epoch-step: 63-409 -- Loss: 0.16488084197044373
train-epoch-step: 63-410 -- Loss: 0.17235657572746277
train-epoch-step: 63-411 -- Loss: 0.19126665592193604
train-epoch-step: 63-412 -- Loss: 0.12359200417995453
train-epoch-step: 63-413 -- Loss: 0.1422627717256546
train-epoch-step: 63-414 -- Loss: 0.13072630763053894
train-epoch-step: 63-415 -- Loss: 0.13074195384979248
train-epoch-step: 63-416 -- Loss: 0.25934717059135437
train-epoch-step: 63-417 -- Loss: 0.18476539850234985
train-epoch-step: 63-418 -- Loss: 0.2218446582555771
train-epoch-step: 63-419 -- Loss: 0.16458386182785034
train-epoch-step: 63-420 -- Loss: 0.15111622214317322
train-epoch-step: 63-421 -- Loss: 0.17219021916389465
train-epoch-step: 63-422 -- Loss: 0.14330200850963593
train-epoch-step: 63-423 -- Loss: 0.17863346636295319
train-epoch-step: 63-424 -- Loss: 0.13494187593460083
train-epoch-step: 63-425 -- Loss: 0.17902520298957825
train-epoch-step: 63-426 -- Loss: 0.15920257568359375
train-epoch-step: 63-427 -- Loss: 0.11578651517629623
train-epoch-step: 63-428 -- Loss: 0.18279698491096497
train-epoch-step: 63-429 -- Loss: 0.16989782452583313
train-epoch-step: 63-430 -- Loss: 0.1358763575553894
train-epoch-step: 63-431 -- Loss: 0.16317841410636902
train-epoch-step: 63-432 -- Loss: 0.2291973978281021
train-epoch-step: 63-433 -- Loss: 0.13062621653079987
train-epoch-step: 63-434 -- Loss: 0.12436909973621368
train-epoch-step: 63-435 -- Loss: 0.15016652643680573
train-epoch-step: 63-436 -- Loss: 0.15241168439388275
train-epoch-step: 63-437 -- Loss: 0.1277458518743515
train-epoch-step: 63-438 -- Loss: 0.16453173756599426
train-epoch-step: 63-439 -- Loss: 0.251091331243515
train-epoch-step: 63-440 -- Loss: 0.12666389346122742
train-epoch-step: 63-441 -- Loss: 0.19130238890647888
train-epoch-step: 63-442 -- Loss: 0.1697712391614914
train-epoch-step: 63-443 -- Loss: 0.14738616347312927
train-epoch-step: 63-444 -- Loss: 0.169002503156662
train-epoch-step: 63-445 -- Loss: 0.1712414026260376
train-epoch-step: 63-446 -- Loss: 0.14945003390312195
train-epoch-step: 63-447 -- Loss: 0.19393368065357208
train-epoch-step: 63-448 -- Loss: 0.21628916263580322
train-epoch-step: 63-449 -- Loss: 0.18717920780181885
train-epoch-step: 63-450 -- Loss: 0.17669600248336792
train-epoch-step: 63-451 -- Loss: 0.13946795463562012
train-epoch-step: 63-452 -- Loss: 0.12451272457838058
train-epoch-step: 63-453 -- Loss: 0.08844798803329468
train-epoch-step: 63-454 -- Loss: 0.21897044777870178
train-epoch-step: 63-455 -- Loss: 0.11735189706087112
train-epoch-step: 63-456 -- Loss: 0.11691661924123764
train-epoch-step: 63-457 -- Loss: 0.20808950066566467
train-epoch-step: 63-458 -- Loss: 0.13849253952503204
train-epoch-step: 63-459 -- Loss: 0.20330967009067535
train-epoch-step: 63-460 -- Loss: 0.12522093951702118
train-epoch-step: 63-461 -- Loss: 0.12945859134197235
train-epoch-step: 63-462 -- Loss: 0.15051856637001038
train-epoch-step: 63-463 -- Loss: 0.13001419603824615
train-epoch-step: 63-464 -- Loss: 0.15577954053878784
train-epoch-step: 63-465 -- Loss: 0.2332458347082138
train-epoch-step: 63-466 -- Loss: 0.19439323246479034
train-epoch-step: 63-467 -- Loss: 0.10869242250919342
train-epoch-step: 63-468 -- Loss: 0.15863698720932007
train-epoch-step: 63-469 -- Loss: 0.21060244739055634
train-epoch-step: 63-470 -- Loss: 0.16548414528369904
train-epoch-step: 63-471 -- Loss: 0.1487686187028885
train-epoch-step: 63-472 -- Loss: 0.15374505519866943
train-epoch-step: 63-473 -- Loss: 0.1536797285079956
train-epoch-step: 63-474 -- Loss: 0.11413412541151047
train-epoch-step: 63-475 -- Loss: 0.10709390044212341
train-epoch-step: 63-476 -- Loss: 0.1942792385816574
train-epoch-step: 63-477 -- Loss: 0.1907719522714615
train-epoch-step: 63-478 -- Loss: 0.18173152208328247
train-epoch-step: 63-479 -- Loss: 0.14377450942993164
train-epoch-step: 63-480 -- Loss: 0.19017769396305084
train-epoch-step: 63-481 -- Loss: 0.2728005647659302
train-epoch-step: 63-482 -- Loss: 0.24050113558769226
train-epoch-step: 63-483 -- Loss: 0.17190955579280853
train-epoch-step: 63-484 -- Loss: 0.20439203083515167
train-epoch-step: 63-485 -- Loss: 0.12035991996526718
train-epoch-step: 63-486 -- Loss: 0.2247166931629181
train-epoch-step: 63-487 -- Loss: 0.22673462331295013
train-epoch-step: 63-488 -- Loss: 0.17765021324157715
train-epoch-step: 63-489 -- Loss: 0.22214502096176147
train-epoch-step: 63-490 -- Loss: 0.14051775634288788
train-epoch-step: 63-491 -- Loss: 0.14754058420658112
train-epoch-step: 63-492 -- Loss: 0.12019018828868866
train-epoch-step: 63-493 -- Loss: 0.1882583647966385
train-epoch-step: 63-494 -- Loss: 0.19505013525485992
train-epoch-step: 63-495 -- Loss: 0.19803380966186523
train-epoch-step: 63-496 -- Loss: 0.1353684365749359
train-epoch-step: 63-497 -- Loss: 0.18416382372379303
train-epoch-step: 63-498 -- Loss: 0.14475925266742706
train-epoch-step: 63-499 -- Loss: 0.16658484935760498
train-epoch-step: 63-500 -- Loss: 0.15284954011440277
train-epoch-step: 63-501 -- Loss: 0.21080662310123444
train-epoch-step: 63-502 -- Loss: 0.15284371376037598
train-epoch-step: 63-503 -- Loss: 0.20851057767868042
train-epoch-step: 63-504 -- Loss: 0.11470617353916168
train-epoch-step: 63-505 -- Loss: 0.16352467238903046
train-epoch-step: 63-506 -- Loss: 0.11652635782957077
train-epoch-step: 63-507 -- Loss: 0.173435240983963
train-epoch-step: 63-508 -- Loss: 0.1684054434299469
train-epoch-step: 63-509 -- Loss: 0.16491836309432983
train-epoch-step: 63-510 -- Loss: 0.12140534073114395
train-epoch-step: 63-511 -- Loss: 0.20994700491428375
train-epoch-step: 63-512 -- Loss: 0.16928304731845856
train-epoch-step: 63-513 -- Loss: 0.1812177300453186
train-epoch-step: 63-514 -- Loss: 0.15566691756248474
train-epoch-step: 63-515 -- Loss: 0.14794868230819702
train-epoch-step: 63-516 -- Loss: 0.16220417618751526
train-epoch-step: 63-517 -- Loss: 0.1714053750038147
train-epoch-step: 63-518 -- Loss: 0.1327337920665741
train-epoch-step: 63-519 -- Loss: 0.1285201907157898
train-epoch-step: 63-520 -- Loss: 0.1803901642560959
train-epoch-step: 63-521 -- Loss: 0.21642005443572998
train-epoch-step: 63-522 -- Loss: 0.16109856963157654
train-epoch-step: 63-523 -- Loss: 0.14896799623966217
train-epoch-step: 63-524 -- Loss: 0.1617719531059265
train-epoch-step: 63-525 -- Loss: 0.19099724292755127
train-epoch-step: 63-526 -- Loss: 0.1249919906258583
train-epoch-step: 63-527 -- Loss: 0.1450415700674057
train-epoch-step: 63-528 -- Loss: 0.1539880633354187
train-epoch-step: 63-529 -- Loss: 0.15018655359745026
train-epoch-step: 63-530 -- Loss: 0.1660747528076172
train-epoch-step: 63-531 -- Loss: 0.1909799426794052
train-epoch-step: 63-532 -- Loss: 0.16125650703907013
train-epoch-step: 63-533 -- Loss: 0.1778046190738678
train-epoch-step: 63-534 -- Loss: 0.12540140748023987
train-epoch-step: 63-535 -- Loss: 0.2403142750263214
train-epoch-step: 63-536 -- Loss: 0.1526075154542923
train-epoch-step: 63-537 -- Loss: 0.153697207570076
train-epoch-step: 63-538 -- Loss: 0.09871920943260193
train-epoch-step: 63-539 -- Loss: 0.19780805706977844
train-epoch-step: 63-540 -- Loss: 0.1362176090478897
train-epoch-step: 63-541 -- Loss: 0.20364727079868317
train-epoch-step: 63-542 -- Loss: 0.2150670439004898
train-epoch-step: 63-543 -- Loss: 0.16789063811302185
train-epoch-step: 63-544 -- Loss: 0.2294204831123352
train-epoch-step: 63-545 -- Loss: 0.18689553439617157
train-epoch-step: 63-546 -- Loss: 0.20106279850006104
train-epoch-step: 63-547 -- Loss: 0.18240879476070404
train-epoch-step: 63-548 -- Loss: 0.09115245938301086
train-epoch-step: 63-549 -- Loss: 0.14363574981689453
train-epoch-step: 63-550 -- Loss: 0.19766700267791748
train-epoch-step: 63-551 -- Loss: 0.14970241487026215
train-epoch-step: 63-552 -- Loss: 0.13374532759189606
train-epoch-step: 63-553 -- Loss: 0.1882127821445465
train-epoch-step: 63-554 -- Loss: 0.17994774878025055
train-epoch-step: 63-555 -- Loss: 0.21159180998802185
train-epoch-step: 63-556 -- Loss: 0.15837490558624268
train-epoch-step: 63-557 -- Loss: 0.23999479413032532
train-epoch-step: 63-558 -- Loss: 0.22061511874198914
train-epoch-step: 63-559 -- Loss: 0.1370535045862198
train-epoch-step: 63-560 -- Loss: 0.20142099261283875
train-epoch-step: 63-561 -- Loss: 0.1901364028453827
train-epoch-step: 63-562 -- Loss: 0.1761043667793274
train-epoch-step: 63-563 -- Loss: 0.17856338620185852
train-epoch-step: 63-564 -- Loss: 0.09638567268848419
train-epoch-step: 63-565 -- Loss: 0.17644858360290527
train-epoch-step: 63-566 -- Loss: 0.14362899959087372
train-epoch-step: 63-567 -- Loss: 0.20039856433868408
train-epoch-step: 63-568 -- Loss: 0.16647347807884216
train-epoch-step: 63-569 -- Loss: 0.23646104335784912
train-epoch-step: 63-570 -- Loss: 0.1629350185394287
train-epoch-step: 63-571 -- Loss: 0.2089555859565735
train-epoch-step: 63-572 -- Loss: 0.24597248435020447
train-epoch-step: 63-573 -- Loss: 0.2024635672569275
train-epoch-step: 63-574 -- Loss: 0.2501996159553528
train-epoch-step: 63-575 -- Loss: 0.2901592552661896
train-epoch-step: 63-576 -- Loss: 0.11509186029434204
train-epoch-step: 63-577 -- Loss: 0.1573546975851059
train-epoch-step: 63-578 -- Loss: 0.2108648121356964
train-epoch-step: 63-579 -- Loss: 0.16557925939559937
train-epoch-step: 63-580 -- Loss: 0.17348018288612366
train-epoch-step: 63-581 -- Loss: 0.13285419344902039
train-epoch-step: 63-582 -- Loss: 0.19923363626003265
train-epoch-step: 63-583 -- Loss: 0.2198755443096161
train-epoch-step: 63-584 -- Loss: 0.1612655222415924
train-epoch-step: 63-585 -- Loss: 0.1958256959915161
train-epoch-step: 63-586 -- Loss: 0.2545422613620758
train-epoch-step: 63-587 -- Loss: 0.15173640847206116
train-epoch-step: 63-588 -- Loss: 0.1243409737944603
val-epoch-step: 63-589 -- Loss: 0.20323511958122253
val-epoch-step: 63-590 -- Loss: 0.14960920810699463
val-epoch-step: 63-591 -- Loss: 0.22941812872886658
val-epoch-step: 63-592 -- Loss: 0.1722743660211563
val-epoch-step: 63-593 -- Loss: 0.14942921698093414
val-epoch-step: 63-594 -- Loss: 0.37366724014282227
val-epoch-step: 63-595 -- Loss: 0.17484614253044128
val-epoch-step: 63-596 -- Loss: 0.2007344365119934
val-epoch-step: 63-597 -- Loss: 0.1724553257226944
val-epoch-step: 63-598 -- Loss: 0.14645379781723022
val-epoch-step: 63-599 -- Loss: 0.18398556113243103
val-epoch-step: 63-600 -- Loss: 0.22404994070529938
val-epoch-step: 63-601 -- Loss: 0.15476779639720917
val-epoch-step: 63-602 -- Loss: 0.13741788268089294
val-epoch-step: 63-603 -- Loss: 0.21420694887638092
val-epoch-step: 63-604 -- Loss: 0.14185255765914917
val-epoch-step: 63-605 -- Loss: 0.14782953262329102
val-epoch-step: 63-606 -- Loss: 0.25920671224594116
val-epoch-step: 63-607 -- Loss: 0.12704408168792725
val-epoch-step: 63-608 -- Loss: 0.2412591576576233
val-epoch-step: 63-609 -- Loss: 0.16880905628204346
val-epoch-step: 63-610 -- Loss: 0.17941038310527802
val-epoch-step: 63-611 -- Loss: 0.16726572811603546
val-epoch-step: 63-612 -- Loss: 0.37861335277557373
val-epoch-step: 63-613 -- Loss: 0.1678289920091629
val-epoch-step: 63-614 -- Loss: 0.16955657303333282
val-epoch-step: 63-615 -- Loss: 0.17867644131183624
val-epoch-step: 63-616 -- Loss: 0.15024897456169128
val-epoch-step: 63-617 -- Loss: 0.20716357231140137
val-epoch-step: 63-618 -- Loss: 0.17976205050945282
val-epoch-step: 63-619 -- Loss: 0.2053094059228897
val-epoch-step: 63-620 -- Loss: 0.12969405949115753
val-epoch-step: 63-621 -- Loss: 0.12197475880384445
val-epoch-step: 63-622 -- Loss: 0.14103621244430542
val-epoch-step: 63-623 -- Loss: 0.14811402559280396
val-epoch-step: 63-624 -- Loss: 0.14032506942749023
val-epoch-step: 63-625 -- Loss: 0.15463191270828247
val-epoch-step: 63-626 -- Loss: 0.15903468430042267
val-epoch-step: 63-627 -- Loss: 0.1874447762966156
val-epoch-step: 63-628 -- Loss: 0.6982330083847046
val-epoch-step: 63-629 -- Loss: 0.19702859222888947
val-epoch-step: 63-630 -- Loss: 0.3345615267753601
val-epoch-step: 63-631 -- Loss: 0.13928158581256866
val-epoch-step: 63-632 -- Loss: 0.194722518324852
val-epoch-step: 63-633 -- Loss: 0.1492237001657486
val-epoch-step: 63-634 -- Loss: 0.14910665154457092
val-epoch-step: 63-635 -- Loss: 0.11441320180892944
val-epoch-step: 63-636 -- Loss: 0.16395147144794464
val-epoch-step: 63-637 -- Loss: 0.1758526712656021
val-epoch-step: 63-638 -- Loss: 0.14605267345905304
val-epoch-step: 63-639 -- Loss: 0.2514437437057495
val-epoch-step: 63-640 -- Loss: 0.2497793734073639
val-epoch-step: 63-641 -- Loss: 0.13225992023944855
val-epoch-step: 63-642 -- Loss: 0.17510361969470978
val-epoch-step: 63-643 -- Loss: 0.20146490633487701
val-epoch-step: 63-644 -- Loss: 0.164709210395813
val-epoch-step: 63-645 -- Loss: 0.2157067060470581
val-epoch-step: 63-646 -- Loss: 0.13360518217086792
val-epoch-step: 63-647 -- Loss: 0.138467937707901
val-epoch-step: 63-648 -- Loss: 0.15537481009960175
val-epoch-step: 63-649 -- Loss: 0.20354638993740082
val-epoch-step: 63-650 -- Loss: 0.2476472556591034
val-epoch-step: 63-651 -- Loss: 0.1404644250869751
val-epoch-step: 63-652 -- Loss: 0.15191788971424103
val-epoch-step: 63-653 -- Loss: 0.20265404880046844
val-epoch-step: 63-654 -- Loss: 0.12563012540340424
Epoch: 63 -- Train Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1423, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 64-0 -- Loss: 0.21703846752643585
train-epoch-step: 64-1 -- Loss: 0.13882440328598022
train-epoch-step: 64-2 -- Loss: 0.2012408822774887
train-epoch-step: 64-3 -- Loss: 0.14699846506118774
train-epoch-step: 64-4 -- Loss: 0.153474822640419
train-epoch-step: 64-5 -- Loss: 0.1748303472995758
train-epoch-step: 64-6 -- Loss: 0.21573615074157715
train-epoch-step: 64-7 -- Loss: 0.16701877117156982
train-epoch-step: 64-8 -- Loss: 0.17597058415412903
train-epoch-step: 64-9 -- Loss: 0.21851426362991333
train-epoch-step: 64-10 -- Loss: 0.1865471452474594
train-epoch-step: 64-11 -- Loss: 0.17355850338935852
train-epoch-step: 64-12 -- Loss: 0.14641547203063965
train-epoch-step: 64-13 -- Loss: 0.17478764057159424
train-epoch-step: 64-14 -- Loss: 0.16008079051971436
train-epoch-step: 64-15 -- Loss: 0.15775166451931
train-epoch-step: 64-16 -- Loss: 0.1601104885339737
train-epoch-step: 64-17 -- Loss: 0.21720485389232635
train-epoch-step: 64-18 -- Loss: 0.1976044774055481
train-epoch-step: 64-19 -- Loss: 0.13097748160362244
train-epoch-step: 64-20 -- Loss: 0.20713014900684357
train-epoch-step: 64-21 -- Loss: 0.23584741353988647
train-epoch-step: 64-22 -- Loss: 0.13245943188667297
train-epoch-step: 64-23 -- Loss: 0.1409064680337906
train-epoch-step: 64-24 -- Loss: 0.11821036785840988
train-epoch-step: 64-25 -- Loss: 0.2147512435913086
train-epoch-step: 64-26 -- Loss: 0.18691904842853546
train-epoch-step: 64-27 -- Loss: 0.21878637373447418
train-epoch-step: 64-28 -- Loss: 0.12247315049171448
train-epoch-step: 64-29 -- Loss: 0.23365090787410736
train-epoch-step: 64-30 -- Loss: 0.1063743457198143
train-epoch-step: 64-31 -- Loss: 0.1307082176208496
train-epoch-step: 64-32 -- Loss: 0.1710679531097412
train-epoch-step: 64-33 -- Loss: 0.2644219696521759
train-epoch-step: 64-34 -- Loss: 0.16489708423614502
train-epoch-step: 64-35 -- Loss: 0.23349420726299286
train-epoch-step: 64-36 -- Loss: 0.13444308936595917
train-epoch-step: 64-37 -- Loss: 0.141098290681839
train-epoch-step: 64-38 -- Loss: 0.16982468962669373
train-epoch-step: 64-39 -- Loss: 0.2081931084394455
train-epoch-step: 64-40 -- Loss: 0.1886376291513443
train-epoch-step: 64-41 -- Loss: 0.20346267521381378
train-epoch-step: 64-42 -- Loss: 0.14501380920410156
train-epoch-step: 64-43 -- Loss: 0.25237053632736206
train-epoch-step: 64-44 -- Loss: 0.1209195926785469
train-epoch-step: 64-45 -- Loss: 0.11279221624135971
train-epoch-step: 64-46 -- Loss: 0.16188198328018188
train-epoch-step: 64-47 -- Loss: 0.19471454620361328
train-epoch-step: 64-48 -- Loss: 0.1499405801296234
train-epoch-step: 64-49 -- Loss: 0.2151060551404953
train-epoch-step: 64-50 -- Loss: 0.11038908362388611
train-epoch-step: 64-51 -- Loss: 0.17144861817359924
train-epoch-step: 64-52 -- Loss: 0.15280352532863617
train-epoch-step: 64-53 -- Loss: 0.20117029547691345
train-epoch-step: 64-54 -- Loss: 0.2769187390804291
train-epoch-step: 64-55 -- Loss: 0.1705634593963623
train-epoch-step: 64-56 -- Loss: 0.17045141756534576
train-epoch-step: 64-57 -- Loss: 0.22674192488193512
train-epoch-step: 64-58 -- Loss: 0.27830785512924194
train-epoch-step: 64-59 -- Loss: 0.23216575384140015
train-epoch-step: 64-60 -- Loss: 0.12495242059230804
train-epoch-step: 64-61 -- Loss: 0.194420725107193
train-epoch-step: 64-62 -- Loss: 0.18066659569740295
train-epoch-step: 64-63 -- Loss: 0.13114115595817566
train-epoch-step: 64-64 -- Loss: 0.1404595673084259
train-epoch-step: 64-65 -- Loss: 0.1721159815788269
train-epoch-step: 64-66 -- Loss: 0.10654671490192413
train-epoch-step: 64-67 -- Loss: 0.1237066239118576
train-epoch-step: 64-68 -- Loss: 0.20213186740875244
train-epoch-step: 64-69 -- Loss: 0.11910486966371536
train-epoch-step: 64-70 -- Loss: 0.21032731235027313
train-epoch-step: 64-71 -- Loss: 0.2485017031431198
train-epoch-step: 64-72 -- Loss: 0.1667165607213974
train-epoch-step: 64-73 -- Loss: 0.19956067204475403
train-epoch-step: 64-74 -- Loss: 0.09338506311178207
train-epoch-step: 64-75 -- Loss: 0.1262216866016388
train-epoch-step: 64-76 -- Loss: 0.1422281265258789
train-epoch-step: 64-77 -- Loss: 0.22001008689403534
train-epoch-step: 64-78 -- Loss: 0.25322720408439636
train-epoch-step: 64-79 -- Loss: 0.18335148692131042
train-epoch-step: 64-80 -- Loss: 0.2441638708114624
train-epoch-step: 64-81 -- Loss: 0.12017718702554703
train-epoch-step: 64-82 -- Loss: 0.23719482123851776
train-epoch-step: 64-83 -- Loss: 0.1687525361776352
train-epoch-step: 64-84 -- Loss: 0.1804834008216858
train-epoch-step: 64-85 -- Loss: 0.16636426746845245
train-epoch-step: 64-86 -- Loss: 0.11687922477722168
train-epoch-step: 64-87 -- Loss: 0.19795286655426025
train-epoch-step: 64-88 -- Loss: 0.13406197726726532
train-epoch-step: 64-89 -- Loss: 0.21108993887901306
train-epoch-step: 64-90 -- Loss: 0.18386201560497284
train-epoch-step: 64-91 -- Loss: 0.2444857507944107
train-epoch-step: 64-92 -- Loss: 0.15184563398361206
train-epoch-step: 64-93 -- Loss: 0.1686873883008957
train-epoch-step: 64-94 -- Loss: 0.21292084455490112
train-epoch-step: 64-95 -- Loss: 0.1840352714061737
train-epoch-step: 64-96 -- Loss: 0.20961448550224304
train-epoch-step: 64-97 -- Loss: 0.17355605959892273
train-epoch-step: 64-98 -- Loss: 0.15130715072155
train-epoch-step: 64-99 -- Loss: 0.17518948018550873
train-epoch-step: 64-100 -- Loss: 0.1848248839378357
train-epoch-step: 64-101 -- Loss: 0.2541045546531677
train-epoch-step: 64-102 -- Loss: 0.20687490701675415
train-epoch-step: 64-103 -- Loss: 0.17405816912651062
train-epoch-step: 64-104 -- Loss: 0.14605341851711273
train-epoch-step: 64-105 -- Loss: 0.2532443702220917
train-epoch-step: 64-106 -- Loss: 0.1688995212316513
train-epoch-step: 64-107 -- Loss: 0.1808738112449646
train-epoch-step: 64-108 -- Loss: 0.1835242360830307
train-epoch-step: 64-109 -- Loss: 0.14131087064743042
train-epoch-step: 64-110 -- Loss: 0.17848430573940277
train-epoch-step: 64-111 -- Loss: 0.17427599430084229
train-epoch-step: 64-112 -- Loss: 0.16124069690704346
train-epoch-step: 64-113 -- Loss: 0.15646269917488098
train-epoch-step: 64-114 -- Loss: 0.1888422667980194
train-epoch-step: 64-115 -- Loss: 0.15734367072582245
train-epoch-step: 64-116 -- Loss: 0.1307525932788849
train-epoch-step: 64-117 -- Loss: 0.12426947057247162
train-epoch-step: 64-118 -- Loss: 0.18497644364833832
train-epoch-step: 64-119 -- Loss: 0.14520612359046936
train-epoch-step: 64-120 -- Loss: 0.23924298584461212
train-epoch-step: 64-121 -- Loss: 0.22958028316497803
train-epoch-step: 64-122 -- Loss: 0.20838378369808197
train-epoch-step: 64-123 -- Loss: 0.1950332224369049
train-epoch-step: 64-124 -- Loss: 0.1209544688463211
train-epoch-step: 64-125 -- Loss: 0.1486634910106659
train-epoch-step: 64-126 -- Loss: 0.22282379865646362
train-epoch-step: 64-127 -- Loss: 0.1645948886871338
train-epoch-step: 64-128 -- Loss: 0.16725018620491028
train-epoch-step: 64-129 -- Loss: 0.1358271688222885
train-epoch-step: 64-130 -- Loss: 0.1840435117483139
train-epoch-step: 64-131 -- Loss: 0.13283444941043854
train-epoch-step: 64-132 -- Loss: 0.18158769607543945
train-epoch-step: 64-133 -- Loss: 0.1115303486585617
train-epoch-step: 64-134 -- Loss: 0.185040682554245
train-epoch-step: 64-135 -- Loss: 0.12902352213859558
train-epoch-step: 64-136 -- Loss: 0.12256090342998505
train-epoch-step: 64-137 -- Loss: 0.23811927437782288
train-epoch-step: 64-138 -- Loss: 0.24762213230133057
train-epoch-step: 64-139 -- Loss: 0.12547481060028076
train-epoch-step: 64-140 -- Loss: 0.20005834102630615
train-epoch-step: 64-141 -- Loss: 0.22586902976036072
train-epoch-step: 64-142 -- Loss: 0.196363165974617
train-epoch-step: 64-143 -- Loss: 0.16524091362953186
train-epoch-step: 64-144 -- Loss: 0.18251457810401917
train-epoch-step: 64-145 -- Loss: 0.1395304799079895
train-epoch-step: 64-146 -- Loss: 0.1729574203491211
train-epoch-step: 64-147 -- Loss: 0.1617671549320221
train-epoch-step: 64-148 -- Loss: 0.1534772366285324
train-epoch-step: 64-149 -- Loss: 0.11187320947647095
train-epoch-step: 64-150 -- Loss: 0.18194186687469482
train-epoch-step: 64-151 -- Loss: 0.18634803593158722
train-epoch-step: 64-152 -- Loss: 0.1892595738172531
train-epoch-step: 64-153 -- Loss: 0.2645723521709442
train-epoch-step: 64-154 -- Loss: 0.12624436616897583
train-epoch-step: 64-155 -- Loss: 0.13274052739143372
train-epoch-step: 64-156 -- Loss: 0.11246708780527115
train-epoch-step: 64-157 -- Loss: 0.15795409679412842
train-epoch-step: 64-158 -- Loss: 0.1600634753704071
train-epoch-step: 64-159 -- Loss: 0.17465394735336304
train-epoch-step: 64-160 -- Loss: 0.20233038067817688
train-epoch-step: 64-161 -- Loss: 0.19587279856204987
train-epoch-step: 64-162 -- Loss: 0.19925425946712494
train-epoch-step: 64-163 -- Loss: 0.180613711476326
train-epoch-step: 64-164 -- Loss: 0.18510521948337555
train-epoch-step: 64-165 -- Loss: 0.15898089110851288
train-epoch-step: 64-166 -- Loss: 0.11736337840557098
train-epoch-step: 64-167 -- Loss: 0.1188402771949768
train-epoch-step: 64-168 -- Loss: 0.19287210702896118
train-epoch-step: 64-169 -- Loss: 0.13496530055999756
train-epoch-step: 64-170 -- Loss: 0.19239646196365356
train-epoch-step: 64-171 -- Loss: 0.14085763692855835
train-epoch-step: 64-172 -- Loss: 0.24987199902534485
train-epoch-step: 64-173 -- Loss: 0.1306052803993225
train-epoch-step: 64-174 -- Loss: 0.24143128097057343
train-epoch-step: 64-175 -- Loss: 0.17803946137428284
train-epoch-step: 64-176 -- Loss: 0.1279669553041458
train-epoch-step: 64-177 -- Loss: 0.17508667707443237
train-epoch-step: 64-178 -- Loss: 0.17279013991355896
train-epoch-step: 64-179 -- Loss: 0.13917917013168335
train-epoch-step: 64-180 -- Loss: 0.14915131032466888
train-epoch-step: 64-181 -- Loss: 0.16266478598117828
train-epoch-step: 64-182 -- Loss: 0.1761806309223175
train-epoch-step: 64-183 -- Loss: 0.2559441328048706
train-epoch-step: 64-184 -- Loss: 0.1335589438676834
train-epoch-step: 64-185 -- Loss: 0.1336585134267807
train-epoch-step: 64-186 -- Loss: 0.18057744204998016
train-epoch-step: 64-187 -- Loss: 0.20717458426952362
train-epoch-step: 64-188 -- Loss: 0.16473203897476196
train-epoch-step: 64-189 -- Loss: 0.10164692997932434
train-epoch-step: 64-190 -- Loss: 0.17916767299175262
train-epoch-step: 64-191 -- Loss: 0.1554146260023117
train-epoch-step: 64-192 -- Loss: 0.2220487743616104
train-epoch-step: 64-193 -- Loss: 0.19988353550434113
train-epoch-step: 64-194 -- Loss: 0.1752879023551941
train-epoch-step: 64-195 -- Loss: 0.15862441062927246
train-epoch-step: 64-196 -- Loss: 0.1610589325428009
train-epoch-step: 64-197 -- Loss: 0.12866458296775818
train-epoch-step: 64-198 -- Loss: 0.12181514501571655
train-epoch-step: 64-199 -- Loss: 0.13802824914455414
train-epoch-step: 64-200 -- Loss: 0.1220272034406662
train-epoch-step: 64-201 -- Loss: 0.1838766187429428
train-epoch-step: 64-202 -- Loss: 0.13498729467391968
train-epoch-step: 64-203 -- Loss: 0.1681222915649414
train-epoch-step: 64-204 -- Loss: 0.13331878185272217
train-epoch-step: 64-205 -- Loss: 0.17668652534484863
train-epoch-step: 64-206 -- Loss: 0.19187535345554352
train-epoch-step: 64-207 -- Loss: 0.12905025482177734
train-epoch-step: 64-208 -- Loss: 0.17298710346221924
train-epoch-step: 64-209 -- Loss: 0.13703656196594238
train-epoch-step: 64-210 -- Loss: 0.13085907697677612
train-epoch-step: 64-211 -- Loss: 0.1965235024690628
train-epoch-step: 64-212 -- Loss: 0.19198481738567352
train-epoch-step: 64-213 -- Loss: 0.12363720685243607
train-epoch-step: 64-214 -- Loss: 0.14322945475578308
train-epoch-step: 64-215 -- Loss: 0.12585005164146423
train-epoch-step: 64-216 -- Loss: 0.18850618600845337
train-epoch-step: 64-217 -- Loss: 0.20331807434558868
train-epoch-step: 64-218 -- Loss: 0.13926072418689728
train-epoch-step: 64-219 -- Loss: 0.16484108567237854
train-epoch-step: 64-220 -- Loss: 0.12451377511024475
train-epoch-step: 64-221 -- Loss: 0.19825318455696106
train-epoch-step: 64-222 -- Loss: 0.11228523403406143
train-epoch-step: 64-223 -- Loss: 0.16938546299934387
train-epoch-step: 64-224 -- Loss: 0.18651548027992249
train-epoch-step: 64-225 -- Loss: 0.25829511880874634
train-epoch-step: 64-226 -- Loss: 0.20041853189468384
train-epoch-step: 64-227 -- Loss: 0.2145145684480667
train-epoch-step: 64-228 -- Loss: 0.17257185280323029
train-epoch-step: 64-229 -- Loss: 0.16706913709640503
train-epoch-step: 64-230 -- Loss: 0.16051635146141052
train-epoch-step: 64-231 -- Loss: 0.15001724660396576
train-epoch-step: 64-232 -- Loss: 0.17769446969032288
train-epoch-step: 64-233 -- Loss: 0.08068016916513443
train-epoch-step: 64-234 -- Loss: 0.16882595419883728
train-epoch-step: 64-235 -- Loss: 0.13919848203659058
train-epoch-step: 64-236 -- Loss: 0.17170141637325287
train-epoch-step: 64-237 -- Loss: 0.2312348484992981
train-epoch-step: 64-238 -- Loss: 0.15366610884666443
train-epoch-step: 64-239 -- Loss: 0.12345690280199051
train-epoch-step: 64-240 -- Loss: 0.21686790883541107
train-epoch-step: 64-241 -- Loss: 0.1496497392654419
train-epoch-step: 64-242 -- Loss: 0.2114025205373764
train-epoch-step: 64-243 -- Loss: 0.2358211874961853
train-epoch-step: 64-244 -- Loss: 0.19817334413528442
train-epoch-step: 64-245 -- Loss: 0.19718977808952332
train-epoch-step: 64-246 -- Loss: 0.20999711751937866
train-epoch-step: 64-247 -- Loss: 0.19921830296516418
train-epoch-step: 64-248 -- Loss: 0.17862944304943085
train-epoch-step: 64-249 -- Loss: 0.13399535417556763
train-epoch-step: 64-250 -- Loss: 0.19132539629936218
train-epoch-step: 64-251 -- Loss: 0.1021130308508873
train-epoch-step: 64-252 -- Loss: 0.1861715316772461
train-epoch-step: 64-253 -- Loss: 0.1317548155784607
train-epoch-step: 64-254 -- Loss: 0.2108858823776245
train-epoch-step: 64-255 -- Loss: 0.140284925699234
train-epoch-step: 64-256 -- Loss: 0.13797089457511902
train-epoch-step: 64-257 -- Loss: 0.18159568309783936
train-epoch-step: 64-258 -- Loss: 0.1417645663022995
train-epoch-step: 64-259 -- Loss: 0.11108965426683426
train-epoch-step: 64-260 -- Loss: 0.19398380815982819
train-epoch-step: 64-261 -- Loss: 0.16781216859817505
train-epoch-step: 64-262 -- Loss: 0.26917946338653564
train-epoch-step: 64-263 -- Loss: 0.19493940472602844
train-epoch-step: 64-264 -- Loss: 0.17337512969970703
train-epoch-step: 64-265 -- Loss: 0.10503306239843369
train-epoch-step: 64-266 -- Loss: 0.14724507927894592
train-epoch-step: 64-267 -- Loss: 0.12450707703828812
train-epoch-step: 64-268 -- Loss: 0.11408701539039612
train-epoch-step: 64-269 -- Loss: 0.16578878462314606
train-epoch-step: 64-270 -- Loss: 0.10334178060293198
train-epoch-step: 64-271 -- Loss: 0.14066089689731598
train-epoch-step: 64-272 -- Loss: 0.1107543334364891
train-epoch-step: 64-273 -- Loss: 0.12291181087493896
train-epoch-step: 64-274 -- Loss: 0.1748945415019989
train-epoch-step: 64-275 -- Loss: 0.18548178672790527
train-epoch-step: 64-276 -- Loss: 0.14844882488250732
train-epoch-step: 64-277 -- Loss: 0.15475289523601532
train-epoch-step: 64-278 -- Loss: 0.13385508954524994
train-epoch-step: 64-279 -- Loss: 0.13312628865242004
train-epoch-step: 64-280 -- Loss: 0.21666443347930908
train-epoch-step: 64-281 -- Loss: 0.16982458531856537
train-epoch-step: 64-282 -- Loss: 0.1355215162038803
train-epoch-step: 64-283 -- Loss: 0.1137022152543068
train-epoch-step: 64-284 -- Loss: 0.1280723214149475
train-epoch-step: 64-285 -- Loss: 0.18545977771282196
train-epoch-step: 64-286 -- Loss: 0.14805538952350616
train-epoch-step: 64-287 -- Loss: 0.1947786808013916
train-epoch-step: 64-288 -- Loss: 0.09179794788360596
train-epoch-step: 64-289 -- Loss: 0.11960244178771973
train-epoch-step: 64-290 -- Loss: 0.17540906369686127
train-epoch-step: 64-291 -- Loss: 0.11442616581916809
train-epoch-step: 64-292 -- Loss: 0.15067264437675476
train-epoch-step: 64-293 -- Loss: 0.13186019659042358
train-epoch-step: 64-294 -- Loss: 0.1586964726448059
train-epoch-step: 64-295 -- Loss: 0.2532510757446289
train-epoch-step: 64-296 -- Loss: 0.1549910306930542
train-epoch-step: 64-297 -- Loss: 0.16668233275413513
train-epoch-step: 64-298 -- Loss: 0.2224053144454956
train-epoch-step: 64-299 -- Loss: 0.13892017304897308
train-epoch-step: 64-300 -- Loss: 0.16042734682559967
train-epoch-step: 64-301 -- Loss: 0.15982061624526978
train-epoch-step: 64-302 -- Loss: 0.20761582255363464
train-epoch-step: 64-303 -- Loss: 0.19713054597377777
train-epoch-step: 64-304 -- Loss: 0.1213911697268486
train-epoch-step: 64-305 -- Loss: 0.13792473077774048
train-epoch-step: 64-306 -- Loss: 0.2039419561624527
train-epoch-step: 64-307 -- Loss: 0.15888258814811707
train-epoch-step: 64-308 -- Loss: 0.20827710628509521
train-epoch-step: 64-309 -- Loss: 0.14776960015296936
train-epoch-step: 64-310 -- Loss: 0.16582074761390686
train-epoch-step: 64-311 -- Loss: 0.15163911879062653
train-epoch-step: 64-312 -- Loss: 0.19526371359825134
train-epoch-step: 64-313 -- Loss: 0.09479450434446335
train-epoch-step: 64-314 -- Loss: 0.18622428178787231
train-epoch-step: 64-315 -- Loss: 0.16436649858951569
train-epoch-step: 64-316 -- Loss: 0.14543282985687256
train-epoch-step: 64-317 -- Loss: 0.13399101793766022
train-epoch-step: 64-318 -- Loss: 0.1537623256444931
train-epoch-step: 64-319 -- Loss: 0.1583593189716339
train-epoch-step: 64-320 -- Loss: 0.11382877081632614
train-epoch-step: 64-321 -- Loss: 0.12902475893497467
train-epoch-step: 64-322 -- Loss: 0.20673391222953796
train-epoch-step: 64-323 -- Loss: 0.15307258069515228
train-epoch-step: 64-324 -- Loss: 0.24767041206359863
train-epoch-step: 64-325 -- Loss: 0.15151222050189972
train-epoch-step: 64-326 -- Loss: 0.16712063550949097
train-epoch-step: 64-327 -- Loss: 0.20063230395317078
train-epoch-step: 64-328 -- Loss: 0.18948617577552795
train-epoch-step: 64-329 -- Loss: 0.32724496722221375
train-epoch-step: 64-330 -- Loss: 0.3566054701805115
train-epoch-step: 64-331 -- Loss: 0.20472407341003418
train-epoch-step: 64-332 -- Loss: 0.09670182317495346
train-epoch-step: 64-333 -- Loss: 0.17519313097000122
train-epoch-step: 64-334 -- Loss: 0.15188509225845337
train-epoch-step: 64-335 -- Loss: 0.1695217341184616
train-epoch-step: 64-336 -- Loss: 0.14242425560951233
train-epoch-step: 64-337 -- Loss: 0.2001836746931076
train-epoch-step: 64-338 -- Loss: 0.15604469180107117
train-epoch-step: 64-339 -- Loss: 0.13959087431430817
train-epoch-step: 64-340 -- Loss: 0.1928667277097702
train-epoch-step: 64-341 -- Loss: 0.1363339126110077
train-epoch-step: 64-342 -- Loss: 0.15977804362773895
train-epoch-step: 64-343 -- Loss: 0.15151400864124298
train-epoch-step: 64-344 -- Loss: 0.16005578637123108
train-epoch-step: 64-345 -- Loss: 0.12369696795940399
train-epoch-step: 64-346 -- Loss: 0.1996384859085083
train-epoch-step: 64-347 -- Loss: 0.1493300348520279
train-epoch-step: 64-348 -- Loss: 0.19623063504695892
train-epoch-step: 64-349 -- Loss: 0.19791382551193237
train-epoch-step: 64-350 -- Loss: 0.2486497461795807
train-epoch-step: 64-351 -- Loss: 0.18683132529258728
train-epoch-step: 64-352 -- Loss: 0.1164601594209671
train-epoch-step: 64-353 -- Loss: 0.19123154878616333
train-epoch-step: 64-354 -- Loss: 0.2762514650821686
train-epoch-step: 64-355 -- Loss: 0.11412927508354187
train-epoch-step: 64-356 -- Loss: 0.11391812562942505
train-epoch-step: 64-357 -- Loss: 0.1823047697544098
train-epoch-step: 64-358 -- Loss: 0.18091784417629242
train-epoch-step: 64-359 -- Loss: 0.13781926035881042
train-epoch-step: 64-360 -- Loss: 0.12056130915880203
train-epoch-step: 64-361 -- Loss: 0.23278099298477173
train-epoch-step: 64-362 -- Loss: 0.18264922499656677
train-epoch-step: 64-363 -- Loss: 0.10689125955104828
train-epoch-step: 64-364 -- Loss: 0.17772690951824188
train-epoch-step: 64-365 -- Loss: 0.16298861801624298
train-epoch-step: 64-366 -- Loss: 0.19520238041877747
train-epoch-step: 64-367 -- Loss: 0.22651547193527222
train-epoch-step: 64-368 -- Loss: 0.19429731369018555
train-epoch-step: 64-369 -- Loss: 0.2701645791530609
train-epoch-step: 64-370 -- Loss: 0.12727266550064087
train-epoch-step: 64-371 -- Loss: 0.11861757934093475
train-epoch-step: 64-372 -- Loss: 0.14574947953224182
train-epoch-step: 64-373 -- Loss: 0.1885199397802353
train-epoch-step: 64-374 -- Loss: 0.14832840859889984
train-epoch-step: 64-375 -- Loss: 0.26960289478302
train-epoch-step: 64-376 -- Loss: 0.1812056005001068
train-epoch-step: 64-377 -- Loss: 0.21694310009479523
train-epoch-step: 64-378 -- Loss: 0.2000042200088501
train-epoch-step: 64-379 -- Loss: 0.11560520529747009
train-epoch-step: 64-380 -- Loss: 0.09237664192914963
train-epoch-step: 64-381 -- Loss: 0.23284420371055603
train-epoch-step: 64-382 -- Loss: 0.23741169273853302
train-epoch-step: 64-383 -- Loss: 0.17325514554977417
train-epoch-step: 64-384 -- Loss: 0.20894324779510498
train-epoch-step: 64-385 -- Loss: 0.19432535767555237
train-epoch-step: 64-386 -- Loss: 0.17919813096523285
train-epoch-step: 64-387 -- Loss: 0.19219790399074554
train-epoch-step: 64-388 -- Loss: 0.17976722121238708
train-epoch-step: 64-389 -- Loss: 0.17285016179084778
train-epoch-step: 64-390 -- Loss: 0.1407616138458252
train-epoch-step: 64-391 -- Loss: 0.14321771264076233
train-epoch-step: 64-392 -- Loss: 0.1798468679189682
train-epoch-step: 64-393 -- Loss: 0.15512573719024658
train-epoch-step: 64-394 -- Loss: 0.1965586394071579
train-epoch-step: 64-395 -- Loss: 0.15022145211696625
train-epoch-step: 64-396 -- Loss: 0.12415286898612976
train-epoch-step: 64-397 -- Loss: 0.12545108795166016
train-epoch-step: 64-398 -- Loss: 0.1908135861158371
train-epoch-step: 64-399 -- Loss: 0.1721896082162857
train-epoch-step: 64-400 -- Loss: 0.27247318625450134
train-epoch-step: 64-401 -- Loss: 0.12474675476551056
train-epoch-step: 64-402 -- Loss: 0.2528180778026581
train-epoch-step: 64-403 -- Loss: 0.14940382540225983
train-epoch-step: 64-404 -- Loss: 0.13535451889038086
train-epoch-step: 64-405 -- Loss: 0.13972903788089752
train-epoch-step: 64-406 -- Loss: 0.157491534948349
train-epoch-step: 64-407 -- Loss: 0.10926224291324615
train-epoch-step: 64-408 -- Loss: 0.15852466225624084
train-epoch-step: 64-409 -- Loss: 0.16486915946006775
train-epoch-step: 64-410 -- Loss: 0.17123034596443176
train-epoch-step: 64-411 -- Loss: 0.18881294131278992
train-epoch-step: 64-412 -- Loss: 0.13109195232391357
train-epoch-step: 64-413 -- Loss: 0.1431187093257904
train-epoch-step: 64-414 -- Loss: 0.13164502382278442
train-epoch-step: 64-415 -- Loss: 0.13327880203723907
train-epoch-step: 64-416 -- Loss: 0.2556840181350708
train-epoch-step: 64-417 -- Loss: 0.1880921572446823
train-epoch-step: 64-418 -- Loss: 0.21655713021755219
train-epoch-step: 64-419 -- Loss: 0.16401761770248413
train-epoch-step: 64-420 -- Loss: 0.14961735904216766
train-epoch-step: 64-421 -- Loss: 0.1736845076084137
train-epoch-step: 64-422 -- Loss: 0.14496967196464539
train-epoch-step: 64-423 -- Loss: 0.17386606335639954
train-epoch-step: 64-424 -- Loss: 0.13487368822097778
train-epoch-step: 64-425 -- Loss: 0.1772920936346054
train-epoch-step: 64-426 -- Loss: 0.15842533111572266
train-epoch-step: 64-427 -- Loss: 0.11803451180458069
train-epoch-step: 64-428 -- Loss: 0.18430854380130768
train-epoch-step: 64-429 -- Loss: 0.16945326328277588
train-epoch-step: 64-430 -- Loss: 0.1392529457807541
train-epoch-step: 64-431 -- Loss: 0.15835848450660706
train-epoch-step: 64-432 -- Loss: 0.22808106243610382
train-epoch-step: 64-433 -- Loss: 0.13025996088981628
train-epoch-step: 64-434 -- Loss: 0.12315251678228378
train-epoch-step: 64-435 -- Loss: 0.1500052958726883
train-epoch-step: 64-436 -- Loss: 0.14692193269729614
train-epoch-step: 64-437 -- Loss: 0.12833335995674133
train-epoch-step: 64-438 -- Loss: 0.16315071284770966
train-epoch-step: 64-439 -- Loss: 0.250870943069458
train-epoch-step: 64-440 -- Loss: 0.125745952129364
train-epoch-step: 64-441 -- Loss: 0.19400125741958618
train-epoch-step: 64-442 -- Loss: 0.1705721914768219
train-epoch-step: 64-443 -- Loss: 0.1477547138929367
train-epoch-step: 64-444 -- Loss: 0.17366287112236023
train-epoch-step: 64-445 -- Loss: 0.16867932677268982
train-epoch-step: 64-446 -- Loss: 0.14843228459358215
train-epoch-step: 64-447 -- Loss: 0.18565750122070312
train-epoch-step: 64-448 -- Loss: 0.2181413471698761
train-epoch-step: 64-449 -- Loss: 0.19063150882720947
train-epoch-step: 64-450 -- Loss: 0.17962071299552917
train-epoch-step: 64-451 -- Loss: 0.13965848088264465
train-epoch-step: 64-452 -- Loss: 0.12365660816431046
train-epoch-step: 64-453 -- Loss: 0.0876939669251442
train-epoch-step: 64-454 -- Loss: 0.21885180473327637
train-epoch-step: 64-455 -- Loss: 0.11693238466978073
train-epoch-step: 64-456 -- Loss: 0.11555519700050354
train-epoch-step: 64-457 -- Loss: 0.210116907954216
train-epoch-step: 64-458 -- Loss: 0.14049221575260162
train-epoch-step: 64-459 -- Loss: 0.20902840793132782
train-epoch-step: 64-460 -- Loss: 0.11973273009061813
train-epoch-step: 64-461 -- Loss: 0.13090543448925018
train-epoch-step: 64-462 -- Loss: 0.14614605903625488
train-epoch-step: 64-463 -- Loss: 0.13135871291160583
train-epoch-step: 64-464 -- Loss: 0.15457698702812195
train-epoch-step: 64-465 -- Loss: 0.23501338064670563
train-epoch-step: 64-466 -- Loss: 0.18917781114578247
train-epoch-step: 64-467 -- Loss: 0.10828711837530136
train-epoch-step: 64-468 -- Loss: 0.1592235267162323
train-epoch-step: 64-469 -- Loss: 0.20354126393795013
train-epoch-step: 64-470 -- Loss: 0.16474539041519165
train-epoch-step: 64-471 -- Loss: 0.14910371601581573
train-epoch-step: 64-472 -- Loss: 0.15205739438533783
train-epoch-step: 64-473 -- Loss: 0.1611338108778
train-epoch-step: 64-474 -- Loss: 0.1124417707324028
train-epoch-step: 64-475 -- Loss: 0.10624460130929947
train-epoch-step: 64-476 -- Loss: 0.19046704471111298
train-epoch-step: 64-477 -- Loss: 0.19325320422649384
train-epoch-step: 64-478 -- Loss: 0.18807265162467957
train-epoch-step: 64-479 -- Loss: 0.1352473646402359
train-epoch-step: 64-480 -- Loss: 0.18396306037902832
train-epoch-step: 64-481 -- Loss: 0.2704426348209381
train-epoch-step: 64-482 -- Loss: 0.24512463808059692
train-epoch-step: 64-483 -- Loss: 0.17266124486923218
train-epoch-step: 64-484 -- Loss: 0.20552220940589905
train-epoch-step: 64-485 -- Loss: 0.12268340587615967
train-epoch-step: 64-486 -- Loss: 0.23432981967926025
train-epoch-step: 64-487 -- Loss: 0.23736512660980225
train-epoch-step: 64-488 -- Loss: 0.18901503086090088
train-epoch-step: 64-489 -- Loss: 0.21253758668899536
train-epoch-step: 64-490 -- Loss: 0.13894256949424744
train-epoch-step: 64-491 -- Loss: 0.13897716999053955
train-epoch-step: 64-492 -- Loss: 0.12199334800243378
train-epoch-step: 64-493 -- Loss: 0.19379018247127533
train-epoch-step: 64-494 -- Loss: 0.20282357931137085
train-epoch-step: 64-495 -- Loss: 0.19156154990196228
train-epoch-step: 64-496 -- Loss: 0.13592731952667236
train-epoch-step: 64-497 -- Loss: 0.17408709228038788
train-epoch-step: 64-498 -- Loss: 0.14269253611564636
train-epoch-step: 64-499 -- Loss: 0.15743432939052582
train-epoch-step: 64-500 -- Loss: 0.1505303680896759
train-epoch-step: 64-501 -- Loss: 0.2050870954990387
train-epoch-step: 64-502 -- Loss: 0.1490205079317093
train-epoch-step: 64-503 -- Loss: 0.2137870490550995
train-epoch-step: 64-504 -- Loss: 0.11757557839155197
train-epoch-step: 64-505 -- Loss: 0.16718119382858276
train-epoch-step: 64-506 -- Loss: 0.11404295265674591
train-epoch-step: 64-507 -- Loss: 0.17235997319221497
train-epoch-step: 64-508 -- Loss: 0.1752079427242279
train-epoch-step: 64-509 -- Loss: 0.16383495926856995
train-epoch-step: 64-510 -- Loss: 0.1228865385055542
train-epoch-step: 64-511 -- Loss: 0.2084505259990692
train-epoch-step: 64-512 -- Loss: 0.17109905183315277
train-epoch-step: 64-513 -- Loss: 0.17839042842388153
train-epoch-step: 64-514 -- Loss: 0.14273084700107574
train-epoch-step: 64-515 -- Loss: 0.14898523688316345
train-epoch-step: 64-516 -- Loss: 0.16315394639968872
train-epoch-step: 64-517 -- Loss: 0.16924220323562622
train-epoch-step: 64-518 -- Loss: 0.14285123348236084
train-epoch-step: 64-519 -- Loss: 0.13006062805652618
train-epoch-step: 64-520 -- Loss: 0.1823461800813675
train-epoch-step: 64-521 -- Loss: 0.21468423306941986
train-epoch-step: 64-522 -- Loss: 0.16634052991867065
train-epoch-step: 64-523 -- Loss: 0.15500426292419434
train-epoch-step: 64-524 -- Loss: 0.16085591912269592
train-epoch-step: 64-525 -- Loss: 0.1851457804441452
train-epoch-step: 64-526 -- Loss: 0.12819789350032806
train-epoch-step: 64-527 -- Loss: 0.14646467566490173
train-epoch-step: 64-528 -- Loss: 0.14951635897159576
train-epoch-step: 64-529 -- Loss: 0.1499832421541214
train-epoch-step: 64-530 -- Loss: 0.1652161031961441
train-epoch-step: 64-531 -- Loss: 0.18785125017166138
train-epoch-step: 64-532 -- Loss: 0.16333793103694916
train-epoch-step: 64-533 -- Loss: 0.17222146689891815
train-epoch-step: 64-534 -- Loss: 0.13011732697486877
train-epoch-step: 64-535 -- Loss: 0.24417339265346527
train-epoch-step: 64-536 -- Loss: 0.16957241296768188
train-epoch-step: 64-537 -- Loss: 0.139842227101326
train-epoch-step: 64-538 -- Loss: 0.09896308183670044
train-epoch-step: 64-539 -- Loss: 0.17394393682479858
train-epoch-step: 64-540 -- Loss: 0.13035109639167786
train-epoch-step: 64-541 -- Loss: 0.2017679214477539
train-epoch-step: 64-542 -- Loss: 0.2155105024576187
train-epoch-step: 64-543 -- Loss: 0.16813862323760986
train-epoch-step: 64-544 -- Loss: 0.21343287825584412
train-epoch-step: 64-545 -- Loss: 0.18871049582958221
train-epoch-step: 64-546 -- Loss: 0.21150261163711548
train-epoch-step: 64-547 -- Loss: 0.17461445927619934
train-epoch-step: 64-548 -- Loss: 0.08936196565628052
train-epoch-step: 64-549 -- Loss: 0.1450178027153015
train-epoch-step: 64-550 -- Loss: 0.19268576800823212
train-epoch-step: 64-551 -- Loss: 0.15212132036685944
train-epoch-step: 64-552 -- Loss: 0.12297403812408447
train-epoch-step: 64-553 -- Loss: 0.17940296232700348
train-epoch-step: 64-554 -- Loss: 0.18424731492996216
train-epoch-step: 64-555 -- Loss: 0.21563707292079926
train-epoch-step: 64-556 -- Loss: 0.13918671011924744
train-epoch-step: 64-557 -- Loss: 0.22112685441970825
train-epoch-step: 64-558 -- Loss: 0.2197836935520172
train-epoch-step: 64-559 -- Loss: 0.12998104095458984
train-epoch-step: 64-560 -- Loss: 0.2011396735906601
train-epoch-step: 64-561 -- Loss: 0.1723930835723877
train-epoch-step: 64-562 -- Loss: 0.1606869399547577
train-epoch-step: 64-563 -- Loss: 0.1775374710559845
train-epoch-step: 64-564 -- Loss: 0.09517352283000946
train-epoch-step: 64-565 -- Loss: 0.18306082487106323
train-epoch-step: 64-566 -- Loss: 0.1413990557193756
train-epoch-step: 64-567 -- Loss: 0.2074388563632965
train-epoch-step: 64-568 -- Loss: 0.15367917716503143
train-epoch-step: 64-569 -- Loss: 0.23846150934696198
train-epoch-step: 64-570 -- Loss: 0.19181649386882782
train-epoch-step: 64-571 -- Loss: 0.20191189646720886
train-epoch-step: 64-572 -- Loss: 0.23153556883335114
train-epoch-step: 64-573 -- Loss: 0.18863265216350555
train-epoch-step: 64-574 -- Loss: 0.2365133911371231
train-epoch-step: 64-575 -- Loss: 0.30294108390808105
train-epoch-step: 64-576 -- Loss: 0.11714585870504379
train-epoch-step: 64-577 -- Loss: 0.16222968697547913
train-epoch-step: 64-578 -- Loss: 0.22032037377357483
train-epoch-step: 64-579 -- Loss: 0.2366127073764801
train-epoch-step: 64-580 -- Loss: 0.17116984724998474
train-epoch-step: 64-581 -- Loss: 0.1414477378129959
train-epoch-step: 64-582 -- Loss: 0.2063465565443039
train-epoch-step: 64-583 -- Loss: 0.20897790789604187
train-epoch-step: 64-584 -- Loss: 0.15772683918476105
train-epoch-step: 64-585 -- Loss: 0.18758977949619293
train-epoch-step: 64-586 -- Loss: 0.2483484148979187
train-epoch-step: 64-587 -- Loss: 0.1595132201910019
train-epoch-step: 64-588 -- Loss: 0.1261492371559143
val-epoch-step: 64-589 -- Loss: 0.2044782191514969
val-epoch-step: 64-590 -- Loss: 0.15284310281276703
val-epoch-step: 64-591 -- Loss: 0.2403208464384079
val-epoch-step: 64-592 -- Loss: 0.17451417446136475
val-epoch-step: 64-593 -- Loss: 0.1566074639558792
val-epoch-step: 64-594 -- Loss: 0.3346007168292999
val-epoch-step: 64-595 -- Loss: 0.17536424100399017
val-epoch-step: 64-596 -- Loss: 0.19270853698253632
val-epoch-step: 64-597 -- Loss: 0.17544391751289368
val-epoch-step: 64-598 -- Loss: 0.15855929255485535
val-epoch-step: 64-599 -- Loss: 0.17910000681877136
val-epoch-step: 64-600 -- Loss: 0.23676377534866333
val-epoch-step: 64-601 -- Loss: 0.16069233417510986
val-epoch-step: 64-602 -- Loss: 0.13378237187862396
val-epoch-step: 64-603 -- Loss: 0.1859758049249649
val-epoch-step: 64-604 -- Loss: 0.14574548602104187
val-epoch-step: 64-605 -- Loss: 0.14433223009109497
val-epoch-step: 64-606 -- Loss: 0.2699791491031647
val-epoch-step: 64-607 -- Loss: 0.12696561217308044
val-epoch-step: 64-608 -- Loss: 0.24943242967128754
val-epoch-step: 64-609 -- Loss: 0.16709285974502563
val-epoch-step: 64-610 -- Loss: 0.17678618431091309
val-epoch-step: 64-611 -- Loss: 0.15581221878528595
val-epoch-step: 64-612 -- Loss: 0.40041762590408325
val-epoch-step: 64-613 -- Loss: 0.16701340675354004
val-epoch-step: 64-614 -- Loss: 0.19677522778511047
val-epoch-step: 64-615 -- Loss: 0.17777374386787415
val-epoch-step: 64-616 -- Loss: 0.1494712233543396
val-epoch-step: 64-617 -- Loss: 0.1865115761756897
val-epoch-step: 64-618 -- Loss: 0.1923832893371582
val-epoch-step: 64-619 -- Loss: 0.20553706586360931
val-epoch-step: 64-620 -- Loss: 0.15165939927101135
val-epoch-step: 64-621 -- Loss: 0.14473554491996765
val-epoch-step: 64-622 -- Loss: 0.13855521380901337
val-epoch-step: 64-623 -- Loss: 0.14750707149505615
val-epoch-step: 64-624 -- Loss: 0.1406974196434021
val-epoch-step: 64-625 -- Loss: 0.16802743077278137
val-epoch-step: 64-626 -- Loss: 0.1458146572113037
val-epoch-step: 64-627 -- Loss: 0.184522345662117
val-epoch-step: 64-628 -- Loss: 0.7312413454055786
val-epoch-step: 64-629 -- Loss: 0.18983225524425507
val-epoch-step: 64-630 -- Loss: 0.3460073173046112
val-epoch-step: 64-631 -- Loss: 0.15066419541835785
val-epoch-step: 64-632 -- Loss: 0.19078943133354187
val-epoch-step: 64-633 -- Loss: 0.14879685640335083
val-epoch-step: 64-634 -- Loss: 0.13839006423950195
val-epoch-step: 64-635 -- Loss: 0.11460096389055252
val-epoch-step: 64-636 -- Loss: 0.16957785189151764
val-epoch-step: 64-637 -- Loss: 0.18193548917770386
val-epoch-step: 64-638 -- Loss: 0.15828031301498413
val-epoch-step: 64-639 -- Loss: 0.2506405711174011
val-epoch-step: 64-640 -- Loss: 0.2543427050113678
val-epoch-step: 64-641 -- Loss: 0.12336458265781403
val-epoch-step: 64-642 -- Loss: 0.18426461517810822
val-epoch-step: 64-643 -- Loss: 0.20698486268520355
val-epoch-step: 64-644 -- Loss: 0.17160141468048096
val-epoch-step: 64-645 -- Loss: 0.22149959206581116
val-epoch-step: 64-646 -- Loss: 0.14241798222064972
val-epoch-step: 64-647 -- Loss: 0.12948152422904968
val-epoch-step: 64-648 -- Loss: 0.1580304503440857
val-epoch-step: 64-649 -- Loss: 0.2029457837343216
val-epoch-step: 64-650 -- Loss: 0.25918111205101013
val-epoch-step: 64-651 -- Loss: 0.14986538887023926
val-epoch-step: 64-652 -- Loss: 0.15362820029258728
val-epoch-step: 64-653 -- Loss: 0.1936795711517334
val-epoch-step: 64-654 -- Loss: 0.11137400567531586
Epoch: 64 -- Train Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1421, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 65-0 -- Loss: 0.2223237007856369
train-epoch-step: 65-1 -- Loss: 0.1405274122953415
train-epoch-step: 65-2 -- Loss: 0.1977173537015915
train-epoch-step: 65-3 -- Loss: 0.14524370431900024
train-epoch-step: 65-4 -- Loss: 0.15623275935649872
train-epoch-step: 65-5 -- Loss: 0.17370828986167908
train-epoch-step: 65-6 -- Loss: 0.21331286430358887
train-epoch-step: 65-7 -- Loss: 0.16587549448013306
train-epoch-step: 65-8 -- Loss: 0.17448002099990845
train-epoch-step: 65-9 -- Loss: 0.21459564566612244
train-epoch-step: 65-10 -- Loss: 0.19497421383857727
train-epoch-step: 65-11 -- Loss: 0.17085689306259155
train-epoch-step: 65-12 -- Loss: 0.15056873857975006
train-epoch-step: 65-13 -- Loss: 0.1748867630958557
train-epoch-step: 65-14 -- Loss: 0.1606527715921402
train-epoch-step: 65-15 -- Loss: 0.15987518429756165
train-epoch-step: 65-16 -- Loss: 0.16451293230056763
train-epoch-step: 65-17 -- Loss: 0.2114039659500122
train-epoch-step: 65-18 -- Loss: 0.19114090502262115
train-epoch-step: 65-19 -- Loss: 0.12530517578125
train-epoch-step: 65-20 -- Loss: 0.2039128839969635
train-epoch-step: 65-21 -- Loss: 0.2404700219631195
train-epoch-step: 65-22 -- Loss: 0.1341344565153122
train-epoch-step: 65-23 -- Loss: 0.1364072561264038
train-epoch-step: 65-24 -- Loss: 0.12321769446134567
train-epoch-step: 65-25 -- Loss: 0.21916402876377106
train-epoch-step: 65-26 -- Loss: 0.1854826807975769
train-epoch-step: 65-27 -- Loss: 0.224394291639328
train-epoch-step: 65-28 -- Loss: 0.12564873695373535
train-epoch-step: 65-29 -- Loss: 0.23758800327777863
train-epoch-step: 65-30 -- Loss: 0.10661632567644119
train-epoch-step: 65-31 -- Loss: 0.13218781352043152
train-epoch-step: 65-32 -- Loss: 0.17023852467536926
train-epoch-step: 65-33 -- Loss: 0.27127185463905334
train-epoch-step: 65-34 -- Loss: 0.16405998170375824
train-epoch-step: 65-35 -- Loss: 0.2346765249967575
train-epoch-step: 65-36 -- Loss: 0.13133172690868378
train-epoch-step: 65-37 -- Loss: 0.13301239907741547
train-epoch-step: 65-38 -- Loss: 0.1702616959810257
train-epoch-step: 65-39 -- Loss: 0.20688076317310333
train-epoch-step: 65-40 -- Loss: 0.1855940967798233
train-epoch-step: 65-41 -- Loss: 0.20694731175899506
train-epoch-step: 65-42 -- Loss: 0.1442890465259552
train-epoch-step: 65-43 -- Loss: 0.2556646168231964
train-epoch-step: 65-44 -- Loss: 0.12889447808265686
train-epoch-step: 65-45 -- Loss: 0.11044800281524658
train-epoch-step: 65-46 -- Loss: 0.16484853625297546
train-epoch-step: 65-47 -- Loss: 0.1870540976524353
train-epoch-step: 65-48 -- Loss: 0.14997512102127075
train-epoch-step: 65-49 -- Loss: 0.22057059407234192
train-epoch-step: 65-50 -- Loss: 0.10747167468070984
train-epoch-step: 65-51 -- Loss: 0.17143884301185608
train-epoch-step: 65-52 -- Loss: 0.15297207236289978
train-epoch-step: 65-53 -- Loss: 0.20226150751113892
train-epoch-step: 65-54 -- Loss: 0.2788164019584656
train-epoch-step: 65-55 -- Loss: 0.16611026227474213
train-epoch-step: 65-56 -- Loss: 0.17237065732479095
train-epoch-step: 65-57 -- Loss: 0.22845980525016785
train-epoch-step: 65-58 -- Loss: 0.2776476740837097
train-epoch-step: 65-59 -- Loss: 0.23261235654354095
train-epoch-step: 65-60 -- Loss: 0.12447626143693924
train-epoch-step: 65-61 -- Loss: 0.19203412532806396
train-epoch-step: 65-62 -- Loss: 0.17733800411224365
train-epoch-step: 65-63 -- Loss: 0.13086505234241486
train-epoch-step: 65-64 -- Loss: 0.14173267781734467
train-epoch-step: 65-65 -- Loss: 0.17232927680015564
train-epoch-step: 65-66 -- Loss: 0.10460780560970306
train-epoch-step: 65-67 -- Loss: 0.11924168467521667
train-epoch-step: 65-68 -- Loss: 0.2062046229839325
train-epoch-step: 65-69 -- Loss: 0.11890261620283127
train-epoch-step: 65-70 -- Loss: 0.22291740775108337
train-epoch-step: 65-71 -- Loss: 0.24860775470733643
train-epoch-step: 65-72 -- Loss: 0.16554638743400574
train-epoch-step: 65-73 -- Loss: 0.2000742405653
train-epoch-step: 65-74 -- Loss: 0.09261863678693771
train-epoch-step: 65-75 -- Loss: 0.12285448610782623
train-epoch-step: 65-76 -- Loss: 0.14053969085216522
train-epoch-step: 65-77 -- Loss: 0.22069600224494934
train-epoch-step: 65-78 -- Loss: 0.24772322177886963
train-epoch-step: 65-79 -- Loss: 0.18419574201107025
train-epoch-step: 65-80 -- Loss: 0.23110279440879822
train-epoch-step: 65-81 -- Loss: 0.1172892302274704
train-epoch-step: 65-82 -- Loss: 0.23634794354438782
train-epoch-step: 65-83 -- Loss: 0.1680757850408554
train-epoch-step: 65-84 -- Loss: 0.17881976068019867
train-epoch-step: 65-85 -- Loss: 0.16620385646820068
train-epoch-step: 65-86 -- Loss: 0.1161801815032959
train-epoch-step: 65-87 -- Loss: 0.21102148294448853
train-epoch-step: 65-88 -- Loss: 0.13541965186595917
train-epoch-step: 65-89 -- Loss: 0.18137672543525696
train-epoch-step: 65-90 -- Loss: 0.18375617265701294
train-epoch-step: 65-91 -- Loss: 0.23482078313827515
train-epoch-step: 65-92 -- Loss: 0.14953672885894775
train-epoch-step: 65-93 -- Loss: 0.16702160239219666
train-epoch-step: 65-94 -- Loss: 0.2121429592370987
train-epoch-step: 65-95 -- Loss: 0.18468959629535675
train-epoch-step: 65-96 -- Loss: 0.2090800255537033
train-epoch-step: 65-97 -- Loss: 0.17433789372444153
train-epoch-step: 65-98 -- Loss: 0.15093250572681427
train-epoch-step: 65-99 -- Loss: 0.17465153336524963
train-epoch-step: 65-100 -- Loss: 0.18202637135982513
train-epoch-step: 65-101 -- Loss: 0.24819700419902802
train-epoch-step: 65-102 -- Loss: 0.21190422773361206
train-epoch-step: 65-103 -- Loss: 0.18557946383953094
train-epoch-step: 65-104 -- Loss: 0.1463388353586197
train-epoch-step: 65-105 -- Loss: 0.2499883472919464
train-epoch-step: 65-106 -- Loss: 0.1731364130973816
train-epoch-step: 65-107 -- Loss: 0.1877554953098297
train-epoch-step: 65-108 -- Loss: 0.18163445591926575
train-epoch-step: 65-109 -- Loss: 0.14301332831382751
train-epoch-step: 65-110 -- Loss: 0.17574995756149292
train-epoch-step: 65-111 -- Loss: 0.17619627714157104
train-epoch-step: 65-112 -- Loss: 0.1592339128255844
train-epoch-step: 65-113 -- Loss: 0.1548769772052765
train-epoch-step: 65-114 -- Loss: 0.18760131299495697
train-epoch-step: 65-115 -- Loss: 0.1547422856092453
train-epoch-step: 65-116 -- Loss: 0.13412219285964966
train-epoch-step: 65-117 -- Loss: 0.12141657620668411
train-epoch-step: 65-118 -- Loss: 0.1872527301311493
train-epoch-step: 65-119 -- Loss: 0.14467597007751465
train-epoch-step: 65-120 -- Loss: 0.24287070333957672
train-epoch-step: 65-121 -- Loss: 0.22540634870529175
train-epoch-step: 65-122 -- Loss: 0.20593872666358948
train-epoch-step: 65-123 -- Loss: 0.1937417984008789
train-epoch-step: 65-124 -- Loss: 0.11946918070316315
train-epoch-step: 65-125 -- Loss: 0.15117204189300537
train-epoch-step: 65-126 -- Loss: 0.2254074215888977
train-epoch-step: 65-127 -- Loss: 0.176799476146698
train-epoch-step: 65-128 -- Loss: 0.16639241576194763
train-epoch-step: 65-129 -- Loss: 0.13833114504814148
train-epoch-step: 65-130 -- Loss: 0.18638132512569427
train-epoch-step: 65-131 -- Loss: 0.13530950248241425
train-epoch-step: 65-132 -- Loss: 0.1854090392589569
train-epoch-step: 65-133 -- Loss: 0.10989963263273239
train-epoch-step: 65-134 -- Loss: 0.1882423311471939
train-epoch-step: 65-135 -- Loss: 0.13213998079299927
train-epoch-step: 65-136 -- Loss: 0.12135972082614899
train-epoch-step: 65-137 -- Loss: 0.23282882571220398
train-epoch-step: 65-138 -- Loss: 0.26306331157684326
train-epoch-step: 65-139 -- Loss: 0.12902861833572388
train-epoch-step: 65-140 -- Loss: 0.2023020088672638
train-epoch-step: 65-141 -- Loss: 0.22506800293922424
train-epoch-step: 65-142 -- Loss: 0.19500195980072021
train-epoch-step: 65-143 -- Loss: 0.17015255987644196
train-epoch-step: 65-144 -- Loss: 0.17973269522190094
train-epoch-step: 65-145 -- Loss: 0.13838538527488708
train-epoch-step: 65-146 -- Loss: 0.17500808835029602
train-epoch-step: 65-147 -- Loss: 0.16691936552524567
train-epoch-step: 65-148 -- Loss: 0.1507672667503357
train-epoch-step: 65-149 -- Loss: 0.12133575230836868
train-epoch-step: 65-150 -- Loss: 0.1899781972169876
train-epoch-step: 65-151 -- Loss: 0.18421345949172974
train-epoch-step: 65-152 -- Loss: 0.18766765296459198
train-epoch-step: 65-153 -- Loss: 0.2612173855304718
train-epoch-step: 65-154 -- Loss: 0.12478556483983994
train-epoch-step: 65-155 -- Loss: 0.13236400485038757
train-epoch-step: 65-156 -- Loss: 0.11348524689674377
train-epoch-step: 65-157 -- Loss: 0.15355226397514343
train-epoch-step: 65-158 -- Loss: 0.16070036590099335
train-epoch-step: 65-159 -- Loss: 0.177162304520607
train-epoch-step: 65-160 -- Loss: 0.20881932973861694
train-epoch-step: 65-161 -- Loss: 0.19521501660346985
train-epoch-step: 65-162 -- Loss: 0.200944185256958
train-epoch-step: 65-163 -- Loss: 0.18340159952640533
train-epoch-step: 65-164 -- Loss: 0.1877620965242386
train-epoch-step: 65-165 -- Loss: 0.15673184394836426
train-epoch-step: 65-166 -- Loss: 0.11640182882547379
train-epoch-step: 65-167 -- Loss: 0.11749901622533798
train-epoch-step: 65-168 -- Loss: 0.19476141035556793
train-epoch-step: 65-169 -- Loss: 0.1316138058900833
train-epoch-step: 65-170 -- Loss: 0.19314230978488922
train-epoch-step: 65-171 -- Loss: 0.13673552870750427
train-epoch-step: 65-172 -- Loss: 0.2534882426261902
train-epoch-step: 65-173 -- Loss: 0.12590447068214417
train-epoch-step: 65-174 -- Loss: 0.23868899047374725
train-epoch-step: 65-175 -- Loss: 0.17944373190402985
train-epoch-step: 65-176 -- Loss: 0.12609504163265228
train-epoch-step: 65-177 -- Loss: 0.1762358695268631
train-epoch-step: 65-178 -- Loss: 0.17223306000232697
train-epoch-step: 65-179 -- Loss: 0.14985837042331696
train-epoch-step: 65-180 -- Loss: 0.1471235454082489
train-epoch-step: 65-181 -- Loss: 0.1626945585012436
train-epoch-step: 65-182 -- Loss: 0.1727512627840042
train-epoch-step: 65-183 -- Loss: 0.26152801513671875
train-epoch-step: 65-184 -- Loss: 0.13475774228572845
train-epoch-step: 65-185 -- Loss: 0.13808941841125488
train-epoch-step: 65-186 -- Loss: 0.18315260112285614
train-epoch-step: 65-187 -- Loss: 0.20574527978897095
train-epoch-step: 65-188 -- Loss: 0.16709135472774506
train-epoch-step: 65-189 -- Loss: 0.10454726219177246
train-epoch-step: 65-190 -- Loss: 0.17737476527690887
train-epoch-step: 65-191 -- Loss: 0.15467481315135956
train-epoch-step: 65-192 -- Loss: 0.23151364922523499
train-epoch-step: 65-193 -- Loss: 0.1987873613834381
train-epoch-step: 65-194 -- Loss: 0.17623171210289001
train-epoch-step: 65-195 -- Loss: 0.161655992269516
train-epoch-step: 65-196 -- Loss: 0.16565096378326416
train-epoch-step: 65-197 -- Loss: 0.12232787907123566
train-epoch-step: 65-198 -- Loss: 0.1394088715314865
train-epoch-step: 65-199 -- Loss: 0.1544950306415558
train-epoch-step: 65-200 -- Loss: 0.1202271580696106
train-epoch-step: 65-201 -- Loss: 0.18486571311950684
train-epoch-step: 65-202 -- Loss: 0.13320793211460114
train-epoch-step: 65-203 -- Loss: 0.17037144303321838
train-epoch-step: 65-204 -- Loss: 0.12910772860050201
train-epoch-step: 65-205 -- Loss: 0.17931228876113892
train-epoch-step: 65-206 -- Loss: 0.19972500205039978
train-epoch-step: 65-207 -- Loss: 0.13375085592269897
train-epoch-step: 65-208 -- Loss: 0.17320206761360168
train-epoch-step: 65-209 -- Loss: 0.1412706971168518
train-epoch-step: 65-210 -- Loss: 0.12805552780628204
train-epoch-step: 65-211 -- Loss: 0.194125235080719
train-epoch-step: 65-212 -- Loss: 0.19001133739948273
train-epoch-step: 65-213 -- Loss: 0.1301746517419815
train-epoch-step: 65-214 -- Loss: 0.1473880559206009
train-epoch-step: 65-215 -- Loss: 0.12440470606088638
train-epoch-step: 65-216 -- Loss: 0.19505226612091064
train-epoch-step: 65-217 -- Loss: 0.20554199814796448
train-epoch-step: 65-218 -- Loss: 0.14071422815322876
train-epoch-step: 65-219 -- Loss: 0.162996307015419
train-epoch-step: 65-220 -- Loss: 0.12521541118621826
train-epoch-step: 65-221 -- Loss: 0.201291024684906
train-epoch-step: 65-222 -- Loss: 0.11456331610679626
train-epoch-step: 65-223 -- Loss: 0.16730383038520813
train-epoch-step: 65-224 -- Loss: 0.18394507467746735
train-epoch-step: 65-225 -- Loss: 0.2601352334022522
train-epoch-step: 65-226 -- Loss: 0.19937029480934143
train-epoch-step: 65-227 -- Loss: 0.21534958481788635
train-epoch-step: 65-228 -- Loss: 0.17246602475643158
train-epoch-step: 65-229 -- Loss: 0.1635814905166626
train-epoch-step: 65-230 -- Loss: 0.1586143672466278
train-epoch-step: 65-231 -- Loss: 0.1511698216199875
train-epoch-step: 65-232 -- Loss: 0.17472611367702484
train-epoch-step: 65-233 -- Loss: 0.08139044046401978
train-epoch-step: 65-234 -- Loss: 0.17390519380569458
train-epoch-step: 65-235 -- Loss: 0.13971568644046783
train-epoch-step: 65-236 -- Loss: 0.17343321442604065
train-epoch-step: 65-237 -- Loss: 0.22974100708961487
train-epoch-step: 65-238 -- Loss: 0.15371742844581604
train-epoch-step: 65-239 -- Loss: 0.12218660116195679
train-epoch-step: 65-240 -- Loss: 0.2150091528892517
train-epoch-step: 65-241 -- Loss: 0.15155908465385437
train-epoch-step: 65-242 -- Loss: 0.21248337626457214
train-epoch-step: 65-243 -- Loss: 0.22880680859088898
train-epoch-step: 65-244 -- Loss: 0.20109480619430542
train-epoch-step: 65-245 -- Loss: 0.19773702323436737
train-epoch-step: 65-246 -- Loss: 0.21066546440124512
train-epoch-step: 65-247 -- Loss: 0.20467540621757507
train-epoch-step: 65-248 -- Loss: 0.17841196060180664
train-epoch-step: 65-249 -- Loss: 0.13616308569908142
train-epoch-step: 65-250 -- Loss: 0.1891777515411377
train-epoch-step: 65-251 -- Loss: 0.10469591617584229
train-epoch-step: 65-252 -- Loss: 0.18369965255260468
train-epoch-step: 65-253 -- Loss: 0.13556957244873047
train-epoch-step: 65-254 -- Loss: 0.20465964078903198
train-epoch-step: 65-255 -- Loss: 0.14145830273628235
train-epoch-step: 65-256 -- Loss: 0.1413545310497284
train-epoch-step: 65-257 -- Loss: 0.1822809875011444
train-epoch-step: 65-258 -- Loss: 0.14001227915287018
train-epoch-step: 65-259 -- Loss: 0.10933208465576172
train-epoch-step: 65-260 -- Loss: 0.19641916453838348
train-epoch-step: 65-261 -- Loss: 0.16999615728855133
train-epoch-step: 65-262 -- Loss: 0.27709367871284485
train-epoch-step: 65-263 -- Loss: 0.19330552220344543
train-epoch-step: 65-264 -- Loss: 0.16853532195091248
train-epoch-step: 65-265 -- Loss: 0.10044681280851364
train-epoch-step: 65-266 -- Loss: 0.14995142817497253
train-epoch-step: 65-267 -- Loss: 0.12453354895114899
train-epoch-step: 65-268 -- Loss: 0.11285202205181122
train-epoch-step: 65-269 -- Loss: 0.16736741364002228
train-epoch-step: 65-270 -- Loss: 0.10308931767940521
train-epoch-step: 65-271 -- Loss: 0.1449608951807022
train-epoch-step: 65-272 -- Loss: 0.11273670196533203
train-epoch-step: 65-273 -- Loss: 0.12341997772455215
train-epoch-step: 65-274 -- Loss: 0.17725735902786255
train-epoch-step: 65-275 -- Loss: 0.18502238392829895
train-epoch-step: 65-276 -- Loss: 0.1503768116235733
train-epoch-step: 65-277 -- Loss: 0.1487949788570404
train-epoch-step: 65-278 -- Loss: 0.1347658634185791
train-epoch-step: 65-279 -- Loss: 0.13418996334075928
train-epoch-step: 65-280 -- Loss: 0.21000543236732483
train-epoch-step: 65-281 -- Loss: 0.17643532156944275
train-epoch-step: 65-282 -- Loss: 0.13705500960350037
train-epoch-step: 65-283 -- Loss: 0.10943123698234558
train-epoch-step: 65-284 -- Loss: 0.12815286219120026
train-epoch-step: 65-285 -- Loss: 0.18191219866275787
train-epoch-step: 65-286 -- Loss: 0.15003478527069092
train-epoch-step: 65-287 -- Loss: 0.19386985898017883
train-epoch-step: 65-288 -- Loss: 0.08975471556186676
train-epoch-step: 65-289 -- Loss: 0.11508070677518845
train-epoch-step: 65-290 -- Loss: 0.17438356578350067
train-epoch-step: 65-291 -- Loss: 0.11432130634784698
train-epoch-step: 65-292 -- Loss: 0.14996056258678436
train-epoch-step: 65-293 -- Loss: 0.13156460225582123
train-epoch-step: 65-294 -- Loss: 0.15319249033927917
train-epoch-step: 65-295 -- Loss: 0.25341206789016724
train-epoch-step: 65-296 -- Loss: 0.15242059528827667
train-epoch-step: 65-297 -- Loss: 0.16915108263492584
train-epoch-step: 65-298 -- Loss: 0.22381168603897095
train-epoch-step: 65-299 -- Loss: 0.1391221582889557
train-epoch-step: 65-300 -- Loss: 0.15570135414600372
train-epoch-step: 65-301 -- Loss: 0.16562172770500183
train-epoch-step: 65-302 -- Loss: 0.21099835634231567
train-epoch-step: 65-303 -- Loss: 0.1980423629283905
train-epoch-step: 65-304 -- Loss: 0.11896765232086182
train-epoch-step: 65-305 -- Loss: 0.14127209782600403
train-epoch-step: 65-306 -- Loss: 0.22017869353294373
train-epoch-step: 65-307 -- Loss: 0.16322030127048492
train-epoch-step: 65-308 -- Loss: 0.20451340079307556
train-epoch-step: 65-309 -- Loss: 0.15066447854042053
train-epoch-step: 65-310 -- Loss: 0.15322114527225494
train-epoch-step: 65-311 -- Loss: 0.15118536353111267
train-epoch-step: 65-312 -- Loss: 0.19944681227207184
train-epoch-step: 65-313 -- Loss: 0.09544462710618973
train-epoch-step: 65-314 -- Loss: 0.18595989048480988
train-epoch-step: 65-315 -- Loss: 0.16211000084877014
train-epoch-step: 65-316 -- Loss: 0.15070103108882904
train-epoch-step: 65-317 -- Loss: 0.14256133139133453
train-epoch-step: 65-318 -- Loss: 0.15026988089084625
train-epoch-step: 65-319 -- Loss: 0.1707526296377182
train-epoch-step: 65-320 -- Loss: 0.11365381628274918
train-epoch-step: 65-321 -- Loss: 0.12728698551654816
train-epoch-step: 65-322 -- Loss: 0.20439265668392181
train-epoch-step: 65-323 -- Loss: 0.15925657749176025
train-epoch-step: 65-324 -- Loss: 0.24634820222854614
train-epoch-step: 65-325 -- Loss: 0.1515350192785263
train-epoch-step: 65-326 -- Loss: 0.16271209716796875
train-epoch-step: 65-327 -- Loss: 0.19734546542167664
train-epoch-step: 65-328 -- Loss: 0.19254368543624878
train-epoch-step: 65-329 -- Loss: 0.33084264397621155
train-epoch-step: 65-330 -- Loss: 0.35353225469589233
train-epoch-step: 65-331 -- Loss: 0.20267346501350403
train-epoch-step: 65-332 -- Loss: 0.09531524032354355
train-epoch-step: 65-333 -- Loss: 0.17760299146175385
train-epoch-step: 65-334 -- Loss: 0.14988069236278534
train-epoch-step: 65-335 -- Loss: 0.17193368077278137
train-epoch-step: 65-336 -- Loss: 0.14284592866897583
train-epoch-step: 65-337 -- Loss: 0.19832316040992737
train-epoch-step: 65-338 -- Loss: 0.1535460352897644
train-epoch-step: 65-339 -- Loss: 0.1399293690919876
train-epoch-step: 65-340 -- Loss: 0.1916298270225525
train-epoch-step: 65-341 -- Loss: 0.13794533908367157
train-epoch-step: 65-342 -- Loss: 0.15907001495361328
train-epoch-step: 65-343 -- Loss: 0.1488475203514099
train-epoch-step: 65-344 -- Loss: 0.1622946858406067
train-epoch-step: 65-345 -- Loss: 0.12258439511060715
train-epoch-step: 65-346 -- Loss: 0.19016359746456146
train-epoch-step: 65-347 -- Loss: 0.14784212410449982
train-epoch-step: 65-348 -- Loss: 0.1956649124622345
train-epoch-step: 65-349 -- Loss: 0.19422993063926697
train-epoch-step: 65-350 -- Loss: 0.24841797351837158
train-epoch-step: 65-351 -- Loss: 0.1868390589952469
train-epoch-step: 65-352 -- Loss: 0.11673426628112793
train-epoch-step: 65-353 -- Loss: 0.18694739043712616
train-epoch-step: 65-354 -- Loss: 0.27034682035446167
train-epoch-step: 65-355 -- Loss: 0.11524951457977295
train-epoch-step: 65-356 -- Loss: 0.11146827787160873
train-epoch-step: 65-357 -- Loss: 0.18220356106758118
train-epoch-step: 65-358 -- Loss: 0.18038856983184814
train-epoch-step: 65-359 -- Loss: 0.1356147825717926
train-epoch-step: 65-360 -- Loss: 0.11981283873319626
train-epoch-step: 65-361 -- Loss: 0.22982028126716614
train-epoch-step: 65-362 -- Loss: 0.16538429260253906
train-epoch-step: 65-363 -- Loss: 0.10888703912496567
train-epoch-step: 65-364 -- Loss: 0.17220120131969452
train-epoch-step: 65-365 -- Loss: 0.16547328233718872
train-epoch-step: 65-366 -- Loss: 0.1915075182914734
train-epoch-step: 65-367 -- Loss: 0.2200721800327301
train-epoch-step: 65-368 -- Loss: 0.1871224343776703
train-epoch-step: 65-369 -- Loss: 0.26551553606987
train-epoch-step: 65-370 -- Loss: 0.12000833451747894
train-epoch-step: 65-371 -- Loss: 0.11787618696689606
train-epoch-step: 65-372 -- Loss: 0.1431606262922287
train-epoch-step: 65-373 -- Loss: 0.18379449844360352
train-epoch-step: 65-374 -- Loss: 0.1472640186548233
train-epoch-step: 65-375 -- Loss: 0.2609865963459015
train-epoch-step: 65-376 -- Loss: 0.15176698565483093
train-epoch-step: 65-377 -- Loss: 0.21784278750419617
train-epoch-step: 65-378 -- Loss: 0.1930598020553589
train-epoch-step: 65-379 -- Loss: 0.11293313652276993
train-epoch-step: 65-380 -- Loss: 0.08743157982826233
train-epoch-step: 65-381 -- Loss: 0.2320011407136917
train-epoch-step: 65-382 -- Loss: 0.22784526646137238
train-epoch-step: 65-383 -- Loss: 0.17396216094493866
train-epoch-step: 65-384 -- Loss: 0.20670410990715027
train-epoch-step: 65-385 -- Loss: 0.18130849301815033
train-epoch-step: 65-386 -- Loss: 0.18211928009986877
train-epoch-step: 65-387 -- Loss: 0.2048143446445465
train-epoch-step: 65-388 -- Loss: 0.17439603805541992
train-epoch-step: 65-389 -- Loss: 0.16208449006080627
train-epoch-step: 65-390 -- Loss: 0.1393355131149292
train-epoch-step: 65-391 -- Loss: 0.14644378423690796
train-epoch-step: 65-392 -- Loss: 0.17972369492053986
train-epoch-step: 65-393 -- Loss: 0.14735260605812073
train-epoch-step: 65-394 -- Loss: 0.18445897102355957
train-epoch-step: 65-395 -- Loss: 0.15215721726417542
train-epoch-step: 65-396 -- Loss: 0.12123184651136398
train-epoch-step: 65-397 -- Loss: 0.12192530930042267
train-epoch-step: 65-398 -- Loss: 0.18944887816905975
train-epoch-step: 65-399 -- Loss: 0.166817307472229
train-epoch-step: 65-400 -- Loss: 0.2657839357852936
train-epoch-step: 65-401 -- Loss: 0.1198965385556221
train-epoch-step: 65-402 -- Loss: 0.24911782145500183
train-epoch-step: 65-403 -- Loss: 0.15451772511005402
train-epoch-step: 65-404 -- Loss: 0.1336652934551239
train-epoch-step: 65-405 -- Loss: 0.13724622130393982
train-epoch-step: 65-406 -- Loss: 0.16832922399044037
train-epoch-step: 65-407 -- Loss: 0.10921412706375122
train-epoch-step: 65-408 -- Loss: 0.15349552035331726
train-epoch-step: 65-409 -- Loss: 0.16342201828956604
train-epoch-step: 65-410 -- Loss: 0.17136354744434357
train-epoch-step: 65-411 -- Loss: 0.19149425625801086
train-epoch-step: 65-412 -- Loss: 0.1251433938741684
train-epoch-step: 65-413 -- Loss: 0.14415712654590607
train-epoch-step: 65-414 -- Loss: 0.13059812784194946
train-epoch-step: 65-415 -- Loss: 0.13149981200695038
train-epoch-step: 65-416 -- Loss: 0.254806786775589
train-epoch-step: 65-417 -- Loss: 0.187712162733078
train-epoch-step: 65-418 -- Loss: 0.21815437078475952
train-epoch-step: 65-419 -- Loss: 0.16087570786476135
train-epoch-step: 65-420 -- Loss: 0.14557434618473053
train-epoch-step: 65-421 -- Loss: 0.1707756519317627
train-epoch-step: 65-422 -- Loss: 0.1468098759651184
train-epoch-step: 65-423 -- Loss: 0.17203590273857117
train-epoch-step: 65-424 -- Loss: 0.1328963339328766
train-epoch-step: 65-425 -- Loss: 0.18272724747657776
train-epoch-step: 65-426 -- Loss: 0.15844318270683289
train-epoch-step: 65-427 -- Loss: 0.11838209629058838
train-epoch-step: 65-428 -- Loss: 0.18710045516490936
train-epoch-step: 65-429 -- Loss: 0.17003263533115387
train-epoch-step: 65-430 -- Loss: 0.137572780251503
train-epoch-step: 65-431 -- Loss: 0.15650221705436707
train-epoch-step: 65-432 -- Loss: 0.23214632272720337
train-epoch-step: 65-433 -- Loss: 0.13048766553401947
train-epoch-step: 65-434 -- Loss: 0.13014845550060272
train-epoch-step: 65-435 -- Loss: 0.14796088635921478
train-epoch-step: 65-436 -- Loss: 0.1472434103488922
train-epoch-step: 65-437 -- Loss: 0.12726163864135742
train-epoch-step: 65-438 -- Loss: 0.16541293263435364
train-epoch-step: 65-439 -- Loss: 0.2478175312280655
train-epoch-step: 65-440 -- Loss: 0.12730498611927032
train-epoch-step: 65-441 -- Loss: 0.1957002729177475
train-epoch-step: 65-442 -- Loss: 0.16807645559310913
train-epoch-step: 65-443 -- Loss: 0.14915192127227783
train-epoch-step: 65-444 -- Loss: 0.1671658158302307
train-epoch-step: 65-445 -- Loss: 0.17338135838508606
train-epoch-step: 65-446 -- Loss: 0.15646779537200928
train-epoch-step: 65-447 -- Loss: 0.18450213968753815
train-epoch-step: 65-448 -- Loss: 0.21868087351322174
train-epoch-step: 65-449 -- Loss: 0.18224962055683136
train-epoch-step: 65-450 -- Loss: 0.17753277719020844
train-epoch-step: 65-451 -- Loss: 0.14237764477729797
train-epoch-step: 65-452 -- Loss: 0.12334486842155457
train-epoch-step: 65-453 -- Loss: 0.09531635046005249
train-epoch-step: 65-454 -- Loss: 0.22111643850803375
train-epoch-step: 65-455 -- Loss: 0.119351327419281
train-epoch-step: 65-456 -- Loss: 0.11346040666103363
train-epoch-step: 65-457 -- Loss: 0.21134932339191437
train-epoch-step: 65-458 -- Loss: 0.13805921375751495
train-epoch-step: 65-459 -- Loss: 0.20958364009857178
train-epoch-step: 65-460 -- Loss: 0.12320519983768463
train-epoch-step: 65-461 -- Loss: 0.1313064694404602
train-epoch-step: 65-462 -- Loss: 0.15165534615516663
train-epoch-step: 65-463 -- Loss: 0.13086068630218506
train-epoch-step: 65-464 -- Loss: 0.15865708887577057
train-epoch-step: 65-465 -- Loss: 0.23224537074565887
train-epoch-step: 65-466 -- Loss: 0.20621153712272644
train-epoch-step: 65-467 -- Loss: 0.10987967252731323
train-epoch-step: 65-468 -- Loss: 0.1622030884027481
train-epoch-step: 65-469 -- Loss: 0.20397481322288513
train-epoch-step: 65-470 -- Loss: 0.16368445754051208
train-epoch-step: 65-471 -- Loss: 0.1512327343225479
train-epoch-step: 65-472 -- Loss: 0.1558094620704651
train-epoch-step: 65-473 -- Loss: 0.1469305455684662
train-epoch-step: 65-474 -- Loss: 0.11944469064474106
train-epoch-step: 65-475 -- Loss: 0.10420163720846176
train-epoch-step: 65-476 -- Loss: 0.19964951276779175
train-epoch-step: 65-477 -- Loss: 0.1920442432165146
train-epoch-step: 65-478 -- Loss: 0.18392585217952728
train-epoch-step: 65-479 -- Loss: 0.15155255794525146
train-epoch-step: 65-480 -- Loss: 0.19074071943759918
train-epoch-step: 65-481 -- Loss: 0.27564117312431335
train-epoch-step: 65-482 -- Loss: 0.24973717331886292
train-epoch-step: 65-483 -- Loss: 0.17030633985996246
train-epoch-step: 65-484 -- Loss: 0.207109272480011
train-epoch-step: 65-485 -- Loss: 0.1316283494234085
train-epoch-step: 65-486 -- Loss: 0.2243000864982605
train-epoch-step: 65-487 -- Loss: 0.2276783287525177
train-epoch-step: 65-488 -- Loss: 0.18583692610263824
train-epoch-step: 65-489 -- Loss: 0.2101551741361618
train-epoch-step: 65-490 -- Loss: 0.1336282640695572
train-epoch-step: 65-491 -- Loss: 0.13091762363910675
train-epoch-step: 65-492 -- Loss: 0.12251883745193481
train-epoch-step: 65-493 -- Loss: 0.18919777870178223
train-epoch-step: 65-494 -- Loss: 0.19311562180519104
train-epoch-step: 65-495 -- Loss: 0.1999416947364807
train-epoch-step: 65-496 -- Loss: 0.13828212022781372
train-epoch-step: 65-497 -- Loss: 0.17752410471439362
train-epoch-step: 65-498 -- Loss: 0.16105863451957703
train-epoch-step: 65-499 -- Loss: 0.16275644302368164
train-epoch-step: 65-500 -- Loss: 0.15019886195659637
train-epoch-step: 65-501 -- Loss: 0.21146924793720245
train-epoch-step: 65-502 -- Loss: 0.15371504426002502
train-epoch-step: 65-503 -- Loss: 0.20939341187477112
train-epoch-step: 65-504 -- Loss: 0.11556656658649445
train-epoch-step: 65-505 -- Loss: 0.16603167355060577
train-epoch-step: 65-506 -- Loss: 0.11506319046020508
train-epoch-step: 65-507 -- Loss: 0.1728927195072174
train-epoch-step: 65-508 -- Loss: 0.16754506528377533
train-epoch-step: 65-509 -- Loss: 0.1649254411458969
train-epoch-step: 65-510 -- Loss: 0.12695515155792236
train-epoch-step: 65-511 -- Loss: 0.2105252891778946
train-epoch-step: 65-512 -- Loss: 0.17015503346920013
train-epoch-step: 65-513 -- Loss: 0.18187850713729858
train-epoch-step: 65-514 -- Loss: 0.14030875265598297
train-epoch-step: 65-515 -- Loss: 0.1497294306755066
train-epoch-step: 65-516 -- Loss: 0.16853733360767365
train-epoch-step: 65-517 -- Loss: 0.1699100136756897
train-epoch-step: 65-518 -- Loss: 0.13242031633853912
train-epoch-step: 65-519 -- Loss: 0.13004545867443085
train-epoch-step: 65-520 -- Loss: 0.1835986077785492
train-epoch-step: 65-521 -- Loss: 0.22208945453166962
train-epoch-step: 65-522 -- Loss: 0.17942437529563904
train-epoch-step: 65-523 -- Loss: 0.15342798829078674
train-epoch-step: 65-524 -- Loss: 0.16173167526721954
train-epoch-step: 65-525 -- Loss: 0.1823650300502777
train-epoch-step: 65-526 -- Loss: 0.12689632177352905
train-epoch-step: 65-527 -- Loss: 0.14839372038841248
train-epoch-step: 65-528 -- Loss: 0.15313509106636047
train-epoch-step: 65-529 -- Loss: 0.15212289988994598
train-epoch-step: 65-530 -- Loss: 0.16294120252132416
train-epoch-step: 65-531 -- Loss: 0.19059835374355316
train-epoch-step: 65-532 -- Loss: 0.1691276729106903
train-epoch-step: 65-533 -- Loss: 0.17326833307743073
train-epoch-step: 65-534 -- Loss: 0.12496468424797058
train-epoch-step: 65-535 -- Loss: 0.24448227882385254
train-epoch-step: 65-536 -- Loss: 0.15601135790348053
train-epoch-step: 65-537 -- Loss: 0.14234714210033417
train-epoch-step: 65-538 -- Loss: 0.10131751745939255
train-epoch-step: 65-539 -- Loss: 0.17771664261817932
train-epoch-step: 65-540 -- Loss: 0.13619235157966614
train-epoch-step: 65-541 -- Loss: 0.20037047564983368
train-epoch-step: 65-542 -- Loss: 0.2079361081123352
train-epoch-step: 65-543 -- Loss: 0.15919755399227142
train-epoch-step: 65-544 -- Loss: 0.22008293867111206
train-epoch-step: 65-545 -- Loss: 0.1846175491809845
train-epoch-step: 65-546 -- Loss: 0.20367246866226196
train-epoch-step: 65-547 -- Loss: 0.173980250954628
train-epoch-step: 65-548 -- Loss: 0.08842620253562927
train-epoch-step: 65-549 -- Loss: 0.14454717934131622
train-epoch-step: 65-550 -- Loss: 0.19827693700790405
train-epoch-step: 65-551 -- Loss: 0.14913061261177063
train-epoch-step: 65-552 -- Loss: 0.12063568085432053
train-epoch-step: 65-553 -- Loss: 0.18152837455272675
train-epoch-step: 65-554 -- Loss: 0.18244291841983795
train-epoch-step: 65-555 -- Loss: 0.2135292887687683
train-epoch-step: 65-556 -- Loss: 0.13985943794250488
train-epoch-step: 65-557 -- Loss: 0.2455339878797531
train-epoch-step: 65-558 -- Loss: 0.21911297738552094
train-epoch-step: 65-559 -- Loss: 0.1319887787103653
train-epoch-step: 65-560 -- Loss: 0.20126736164093018
train-epoch-step: 65-561 -- Loss: 0.17274482548236847
train-epoch-step: 65-562 -- Loss: 0.15556184947490692
train-epoch-step: 65-563 -- Loss: 0.17964588105678558
train-epoch-step: 65-564 -- Loss: 0.0963655486702919
train-epoch-step: 65-565 -- Loss: 0.1811830997467041
train-epoch-step: 65-566 -- Loss: 0.1419154852628708
train-epoch-step: 65-567 -- Loss: 0.20342300832271576
train-epoch-step: 65-568 -- Loss: 0.1594424843788147
train-epoch-step: 65-569 -- Loss: 0.23423196375370026
train-epoch-step: 65-570 -- Loss: 0.1635427176952362
train-epoch-step: 65-571 -- Loss: 0.204621359705925
train-epoch-step: 65-572 -- Loss: 0.23075193166732788
train-epoch-step: 65-573 -- Loss: 0.18921831250190735
train-epoch-step: 65-574 -- Loss: 0.2338743656873703
train-epoch-step: 65-575 -- Loss: 0.2832341194152832
train-epoch-step: 65-576 -- Loss: 0.11565767973661423
train-epoch-step: 65-577 -- Loss: 0.15756507217884064
train-epoch-step: 65-578 -- Loss: 0.207464799284935
train-epoch-step: 65-579 -- Loss: 0.1640971302986145
train-epoch-step: 65-580 -- Loss: 0.16655799746513367
train-epoch-step: 65-581 -- Loss: 0.12967748939990997
train-epoch-step: 65-582 -- Loss: 0.19788828492164612
train-epoch-step: 65-583 -- Loss: 0.19822891056537628
train-epoch-step: 65-584 -- Loss: 0.15860925614833832
train-epoch-step: 65-585 -- Loss: 0.18295475840568542
train-epoch-step: 65-586 -- Loss: 0.23865415155887604
train-epoch-step: 65-587 -- Loss: 0.1543281078338623
train-epoch-step: 65-588 -- Loss: 0.11995668709278107
val-epoch-step: 65-589 -- Loss: 0.19614551961421967
val-epoch-step: 65-590 -- Loss: 0.15137642621994019
val-epoch-step: 65-591 -- Loss: 0.2341056913137436
val-epoch-step: 65-592 -- Loss: 0.1708308458328247
val-epoch-step: 65-593 -- Loss: 0.15942566096782684
val-epoch-step: 65-594 -- Loss: 0.3574051856994629
val-epoch-step: 65-595 -- Loss: 0.18451721966266632
val-epoch-step: 65-596 -- Loss: 0.20694629848003387
val-epoch-step: 65-597 -- Loss: 0.16573213040828705
val-epoch-step: 65-598 -- Loss: 0.14228270947933197
val-epoch-step: 65-599 -- Loss: 0.17877832055091858
val-epoch-step: 65-600 -- Loss: 0.21136000752449036
val-epoch-step: 65-601 -- Loss: 0.15780183672904968
val-epoch-step: 65-602 -- Loss: 0.13299736380577087
val-epoch-step: 65-603 -- Loss: 0.22327888011932373
val-epoch-step: 65-604 -- Loss: 0.1438400000333786
val-epoch-step: 65-605 -- Loss: 0.14674653112888336
val-epoch-step: 65-606 -- Loss: 0.24946290254592896
val-epoch-step: 65-607 -- Loss: 0.11918147653341293
val-epoch-step: 65-608 -- Loss: 0.24483069777488708
val-epoch-step: 65-609 -- Loss: 0.1696988046169281
val-epoch-step: 65-610 -- Loss: 0.17202085256576538
val-epoch-step: 65-611 -- Loss: 0.14836111664772034
val-epoch-step: 65-612 -- Loss: 0.39735954999923706
val-epoch-step: 65-613 -- Loss: 0.18026110529899597
val-epoch-step: 65-614 -- Loss: 0.17556065320968628
val-epoch-step: 65-615 -- Loss: 0.17258037626743317
val-epoch-step: 65-616 -- Loss: 0.1411476582288742
val-epoch-step: 65-617 -- Loss: 0.18290573358535767
val-epoch-step: 65-618 -- Loss: 0.17235957086086273
val-epoch-step: 65-619 -- Loss: 0.20125004649162292
val-epoch-step: 65-620 -- Loss: 0.12944011390209198
val-epoch-step: 65-621 -- Loss: 0.12205737829208374
val-epoch-step: 65-622 -- Loss: 0.14189249277114868
val-epoch-step: 65-623 -- Loss: 0.1485375016927719
val-epoch-step: 65-624 -- Loss: 0.1362372487783432
val-epoch-step: 65-625 -- Loss: 0.1566249132156372
val-epoch-step: 65-626 -- Loss: 0.14357414841651917
val-epoch-step: 65-627 -- Loss: 0.17512966692447662
val-epoch-step: 65-628 -- Loss: 0.7387733459472656
val-epoch-step: 65-629 -- Loss: 0.2027122676372528
val-epoch-step: 65-630 -- Loss: 0.33203375339508057
val-epoch-step: 65-631 -- Loss: 0.13728119432926178
val-epoch-step: 65-632 -- Loss: 0.1971416175365448
val-epoch-step: 65-633 -- Loss: 0.14941079914569855
val-epoch-step: 65-634 -- Loss: 0.14195391535758972
val-epoch-step: 65-635 -- Loss: 0.11198130249977112
val-epoch-step: 65-636 -- Loss: 0.1599065363407135
val-epoch-step: 65-637 -- Loss: 0.17809107899665833
val-epoch-step: 65-638 -- Loss: 0.15880683064460754
val-epoch-step: 65-639 -- Loss: 0.24487914144992828
val-epoch-step: 65-640 -- Loss: 0.2466856688261032
val-epoch-step: 65-641 -- Loss: 0.12180226296186447
val-epoch-step: 65-642 -- Loss: 0.18433669209480286
val-epoch-step: 65-643 -- Loss: 0.19725021719932556
val-epoch-step: 65-644 -- Loss: 0.16725273430347443
val-epoch-step: 65-645 -- Loss: 0.22288605570793152
val-epoch-step: 65-646 -- Loss: 0.12831249833106995
val-epoch-step: 65-647 -- Loss: 0.13786646723747253
val-epoch-step: 65-648 -- Loss: 0.15330739319324493
val-epoch-step: 65-649 -- Loss: 0.20583617687225342
val-epoch-step: 65-650 -- Loss: 0.24477875232696533
val-epoch-step: 65-651 -- Loss: 0.14531947672367096
val-epoch-step: 65-652 -- Loss: 0.15148083865642548
val-epoch-step: 65-653 -- Loss: 0.2017189860343933
val-epoch-step: 65-654 -- Loss: 0.10904686152935028
Epoch: 65 -- Train Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 66-0 -- Loss: 0.2131340205669403
train-epoch-step: 66-1 -- Loss: 0.1374279260635376
train-epoch-step: 66-2 -- Loss: 0.18765205144882202
train-epoch-step: 66-3 -- Loss: 0.13779370486736298
train-epoch-step: 66-4 -- Loss: 0.1502339392900467
train-epoch-step: 66-5 -- Loss: 0.17104779183864594
train-epoch-step: 66-6 -- Loss: 0.200008362531662
train-epoch-step: 66-7 -- Loss: 0.1627127230167389
train-epoch-step: 66-8 -- Loss: 0.18038783967494965
train-epoch-step: 66-9 -- Loss: 0.22047820687294006
train-epoch-step: 66-10 -- Loss: 0.18538589775562286
train-epoch-step: 66-11 -- Loss: 0.1727617233991623
train-epoch-step: 66-12 -- Loss: 0.14296911656856537
train-epoch-step: 66-13 -- Loss: 0.16840124130249023
train-epoch-step: 66-14 -- Loss: 0.15457458794116974
train-epoch-step: 66-15 -- Loss: 0.15240950882434845
train-epoch-step: 66-16 -- Loss: 0.16667550802230835
train-epoch-step: 66-17 -- Loss: 0.20864994823932648
train-epoch-step: 66-18 -- Loss: 0.18601176142692566
train-epoch-step: 66-19 -- Loss: 0.12997686862945557
train-epoch-step: 66-20 -- Loss: 0.21279436349868774
train-epoch-step: 66-21 -- Loss: 0.24220269918441772
train-epoch-step: 66-22 -- Loss: 0.13382326066493988
train-epoch-step: 66-23 -- Loss: 0.17992568016052246
train-epoch-step: 66-24 -- Loss: 0.12603726983070374
train-epoch-step: 66-25 -- Loss: 0.2189745008945465
train-epoch-step: 66-26 -- Loss: 0.18365728855133057
train-epoch-step: 66-27 -- Loss: 0.21943292021751404
train-epoch-step: 66-28 -- Loss: 0.12039731442928314
train-epoch-step: 66-29 -- Loss: 0.23354139924049377
train-epoch-step: 66-30 -- Loss: 0.1081649512052536
train-epoch-step: 66-31 -- Loss: 0.13422708213329315
train-epoch-step: 66-32 -- Loss: 0.17318136990070343
train-epoch-step: 66-33 -- Loss: 0.3422695994377136
train-epoch-step: 66-34 -- Loss: 0.19838523864746094
train-epoch-step: 66-35 -- Loss: 0.2452937364578247
train-epoch-step: 66-36 -- Loss: 0.13307495415210724
train-epoch-step: 66-37 -- Loss: 0.1342335045337677
train-epoch-step: 66-38 -- Loss: 0.17233769595623016
train-epoch-step: 66-39 -- Loss: 0.2504001259803772
train-epoch-step: 66-40 -- Loss: 0.19364069402217865
train-epoch-step: 66-41 -- Loss: 0.21222765743732452
train-epoch-step: 66-42 -- Loss: 0.15294218063354492
train-epoch-step: 66-43 -- Loss: 0.26177385449409485
train-epoch-step: 66-44 -- Loss: 0.11909741163253784
train-epoch-step: 66-45 -- Loss: 0.13821445405483246
train-epoch-step: 66-46 -- Loss: 0.17233791947364807
train-epoch-step: 66-47 -- Loss: 0.21211686730384827
train-epoch-step: 66-48 -- Loss: 0.1527927666902542
train-epoch-step: 66-49 -- Loss: 0.22729678452014923
train-epoch-step: 66-50 -- Loss: 0.1100441962480545
train-epoch-step: 66-51 -- Loss: 0.17271223664283752
train-epoch-step: 66-52 -- Loss: 0.1520562469959259
train-epoch-step: 66-53 -- Loss: 0.20381945371627808
train-epoch-step: 66-54 -- Loss: 0.291953980922699
train-epoch-step: 66-55 -- Loss: 0.16596771776676178
train-epoch-step: 66-56 -- Loss: 0.17402933537960052
train-epoch-step: 66-57 -- Loss: 0.2305515706539154
train-epoch-step: 66-58 -- Loss: 0.2745288908481598
train-epoch-step: 66-59 -- Loss: 0.23471929132938385
train-epoch-step: 66-60 -- Loss: 0.12703870236873627
train-epoch-step: 66-61 -- Loss: 0.19417056441307068
train-epoch-step: 66-62 -- Loss: 0.1857849508523941
train-epoch-step: 66-63 -- Loss: 0.13651549816131592
train-epoch-step: 66-64 -- Loss: 0.1435108184814453
train-epoch-step: 66-65 -- Loss: 0.17421868443489075
train-epoch-step: 66-66 -- Loss: 0.10452931374311447
train-epoch-step: 66-67 -- Loss: 0.12054460495710373
train-epoch-step: 66-68 -- Loss: 0.2048240453004837
train-epoch-step: 66-69 -- Loss: 0.12020284682512283
train-epoch-step: 66-70 -- Loss: 0.21722722053527832
train-epoch-step: 66-71 -- Loss: 0.24969962239265442
train-epoch-step: 66-72 -- Loss: 0.16935956478118896
train-epoch-step: 66-73 -- Loss: 0.21381868422031403
train-epoch-step: 66-74 -- Loss: 0.09320323169231415
train-epoch-step: 66-75 -- Loss: 0.1249714270234108
train-epoch-step: 66-76 -- Loss: 0.14253464341163635
train-epoch-step: 66-77 -- Loss: 0.22412805259227753
train-epoch-step: 66-78 -- Loss: 0.25439634919166565
train-epoch-step: 66-79 -- Loss: 0.18385332822799683
train-epoch-step: 66-80 -- Loss: 0.26369810104370117
train-epoch-step: 66-81 -- Loss: 0.12036393582820892
train-epoch-step: 66-82 -- Loss: 0.2526002824306488
train-epoch-step: 66-83 -- Loss: 0.1701432466506958
train-epoch-step: 66-84 -- Loss: 0.1848238855600357
train-epoch-step: 66-85 -- Loss: 0.17255949974060059
train-epoch-step: 66-86 -- Loss: 0.11705131083726883
train-epoch-step: 66-87 -- Loss: 0.20041924715042114
train-epoch-step: 66-88 -- Loss: 0.1366032063961029
train-epoch-step: 66-89 -- Loss: 0.1909397393465042
train-epoch-step: 66-90 -- Loss: 0.18838150799274445
train-epoch-step: 66-91 -- Loss: 0.2411574125289917
train-epoch-step: 66-92 -- Loss: 0.15269148349761963
train-epoch-step: 66-93 -- Loss: 0.17087846994400024
train-epoch-step: 66-94 -- Loss: 0.21380068361759186
train-epoch-step: 66-95 -- Loss: 0.1826939880847931
train-epoch-step: 66-96 -- Loss: 0.20788957178592682
train-epoch-step: 66-97 -- Loss: 0.17019149661064148
train-epoch-step: 66-98 -- Loss: 0.15100155770778656
train-epoch-step: 66-99 -- Loss: 0.17564406991004944
train-epoch-step: 66-100 -- Loss: 0.23324334621429443
train-epoch-step: 66-101 -- Loss: 0.25213319063186646
train-epoch-step: 66-102 -- Loss: 0.21522964537143707
train-epoch-step: 66-103 -- Loss: 0.1834956407546997
train-epoch-step: 66-104 -- Loss: 0.14577960968017578
train-epoch-step: 66-105 -- Loss: 0.2553645968437195
train-epoch-step: 66-106 -- Loss: 0.17991065979003906
train-epoch-step: 66-107 -- Loss: 0.18609680235385895
train-epoch-step: 66-108 -- Loss: 0.18667899072170258
train-epoch-step: 66-109 -- Loss: 0.13734257221221924
train-epoch-step: 66-110 -- Loss: 0.1806323081254959
train-epoch-step: 66-111 -- Loss: 0.17382857203483582
train-epoch-step: 66-112 -- Loss: 0.1605978161096573
train-epoch-step: 66-113 -- Loss: 0.15661215782165527
train-epoch-step: 66-114 -- Loss: 0.18880945444107056
train-epoch-step: 66-115 -- Loss: 0.15582410991191864
train-epoch-step: 66-116 -- Loss: 0.13244116306304932
train-epoch-step: 66-117 -- Loss: 0.12622658908367157
train-epoch-step: 66-118 -- Loss: 0.187635600566864
train-epoch-step: 66-119 -- Loss: 0.16511493921279907
train-epoch-step: 66-120 -- Loss: 0.24434027075767517
train-epoch-step: 66-121 -- Loss: 0.2245642989873886
train-epoch-step: 66-122 -- Loss: 0.21108198165893555
train-epoch-step: 66-123 -- Loss: 0.19510844349861145
train-epoch-step: 66-124 -- Loss: 0.12304636836051941
train-epoch-step: 66-125 -- Loss: 0.1524367481470108
train-epoch-step: 66-126 -- Loss: 0.22088247537612915
train-epoch-step: 66-127 -- Loss: 0.1623026430606842
train-epoch-step: 66-128 -- Loss: 0.16774974763393402
train-epoch-step: 66-129 -- Loss: 0.13776342570781708
train-epoch-step: 66-130 -- Loss: 0.1913948953151703
train-epoch-step: 66-131 -- Loss: 0.1321810632944107
train-epoch-step: 66-132 -- Loss: 0.18721088767051697
train-epoch-step: 66-133 -- Loss: 0.11039230227470398
train-epoch-step: 66-134 -- Loss: 0.20402050018310547
train-epoch-step: 66-135 -- Loss: 0.12701281905174255
train-epoch-step: 66-136 -- Loss: 0.12229548394680023
train-epoch-step: 66-137 -- Loss: 0.23398549854755402
train-epoch-step: 66-138 -- Loss: 0.24922266602516174
train-epoch-step: 66-139 -- Loss: 0.12712669372558594
train-epoch-step: 66-140 -- Loss: 0.19928677380084991
train-epoch-step: 66-141 -- Loss: 0.22178131341934204
train-epoch-step: 66-142 -- Loss: 0.19821077585220337
train-epoch-step: 66-143 -- Loss: 0.17083469033241272
train-epoch-step: 66-144 -- Loss: 0.17529885470867157
train-epoch-step: 66-145 -- Loss: 0.13795062899589539
train-epoch-step: 66-146 -- Loss: 0.1722901612520218
train-epoch-step: 66-147 -- Loss: 0.1621544063091278
train-epoch-step: 66-148 -- Loss: 0.15712173283100128
train-epoch-step: 66-149 -- Loss: 0.11344996839761734
train-epoch-step: 66-150 -- Loss: 0.1787509024143219
train-epoch-step: 66-151 -- Loss: 0.18749451637268066
train-epoch-step: 66-152 -- Loss: 0.18632441759109497
train-epoch-step: 66-153 -- Loss: 0.2603474259376526
train-epoch-step: 66-154 -- Loss: 0.12922225892543793
train-epoch-step: 66-155 -- Loss: 0.130515918135643
train-epoch-step: 66-156 -- Loss: 0.11255475878715515
train-epoch-step: 66-157 -- Loss: 0.15335498750209808
train-epoch-step: 66-158 -- Loss: 0.16174516081809998
train-epoch-step: 66-159 -- Loss: 0.17451797425746918
train-epoch-step: 66-160 -- Loss: 0.21929550170898438
train-epoch-step: 66-161 -- Loss: 0.19694948196411133
train-epoch-step: 66-162 -- Loss: 0.20411893725395203
train-epoch-step: 66-163 -- Loss: 0.18184614181518555
train-epoch-step: 66-164 -- Loss: 0.1854192614555359
train-epoch-step: 66-165 -- Loss: 0.15823066234588623
train-epoch-step: 66-166 -- Loss: 0.11677795648574829
train-epoch-step: 66-167 -- Loss: 0.12134856730699539
train-epoch-step: 66-168 -- Loss: 0.19701476395130157
train-epoch-step: 66-169 -- Loss: 0.1402483433485031
train-epoch-step: 66-170 -- Loss: 0.19476686418056488
train-epoch-step: 66-171 -- Loss: 0.13951757550239563
train-epoch-step: 66-172 -- Loss: 0.252590537071228
train-epoch-step: 66-173 -- Loss: 0.1317751258611679
train-epoch-step: 66-174 -- Loss: 0.24212904274463654
train-epoch-step: 66-175 -- Loss: 0.18091164529323578
train-epoch-step: 66-176 -- Loss: 0.13264432549476624
train-epoch-step: 66-177 -- Loss: 0.17386406660079956
train-epoch-step: 66-178 -- Loss: 0.17713883519172668
train-epoch-step: 66-179 -- Loss: 0.1411721110343933
train-epoch-step: 66-180 -- Loss: 0.14761395752429962
train-epoch-step: 66-181 -- Loss: 0.1663784682750702
train-epoch-step: 66-182 -- Loss: 0.17710857093334198
train-epoch-step: 66-183 -- Loss: 0.25917312502861023
train-epoch-step: 66-184 -- Loss: 0.1339351236820221
train-epoch-step: 66-185 -- Loss: 0.13904288411140442
train-epoch-step: 66-186 -- Loss: 0.182002991437912
train-epoch-step: 66-187 -- Loss: 0.20360970497131348
train-epoch-step: 66-188 -- Loss: 0.16888751089572906
train-epoch-step: 66-189 -- Loss: 0.10257916897535324
train-epoch-step: 66-190 -- Loss: 0.17690113186836243
train-epoch-step: 66-191 -- Loss: 0.15162573754787445
train-epoch-step: 66-192 -- Loss: 0.22244024276733398
train-epoch-step: 66-193 -- Loss: 0.19889287650585175
train-epoch-step: 66-194 -- Loss: 0.17814359068870544
train-epoch-step: 66-195 -- Loss: 0.16216808557510376
train-epoch-step: 66-196 -- Loss: 0.16570964455604553
train-epoch-step: 66-197 -- Loss: 0.121102474629879
train-epoch-step: 66-198 -- Loss: 0.12340535968542099
train-epoch-step: 66-199 -- Loss: 0.14133016765117645
train-epoch-step: 66-200 -- Loss: 0.12405156344175339
train-epoch-step: 66-201 -- Loss: 0.18357382714748383
train-epoch-step: 66-202 -- Loss: 0.13134752213954926
train-epoch-step: 66-203 -- Loss: 0.16933289170265198
train-epoch-step: 66-204 -- Loss: 0.12899433076381683
train-epoch-step: 66-205 -- Loss: 0.17636191844940186
train-epoch-step: 66-206 -- Loss: 0.19526366889476776
train-epoch-step: 66-207 -- Loss: 0.12614309787750244
train-epoch-step: 66-208 -- Loss: 0.1758616715669632
train-epoch-step: 66-209 -- Loss: 0.13946618139743805
train-epoch-step: 66-210 -- Loss: 0.1287691444158554
train-epoch-step: 66-211 -- Loss: 0.20103132724761963
train-epoch-step: 66-212 -- Loss: 0.19148123264312744
train-epoch-step: 66-213 -- Loss: 0.12785083055496216
train-epoch-step: 66-214 -- Loss: 0.1443607211112976
train-epoch-step: 66-215 -- Loss: 0.12639184296131134
train-epoch-step: 66-216 -- Loss: 0.19681012630462646
train-epoch-step: 66-217 -- Loss: 0.20678608119487762
train-epoch-step: 66-218 -- Loss: 0.139666348695755
train-epoch-step: 66-219 -- Loss: 0.16500291228294373
train-epoch-step: 66-220 -- Loss: 0.1275835633277893
train-epoch-step: 66-221 -- Loss: 0.20111112296581268
train-epoch-step: 66-222 -- Loss: 0.11304689943790436
train-epoch-step: 66-223 -- Loss: 0.17243100702762604
train-epoch-step: 66-224 -- Loss: 0.18191765248775482
train-epoch-step: 66-225 -- Loss: 0.25922003388404846
train-epoch-step: 66-226 -- Loss: 0.20099414885044098
train-epoch-step: 66-227 -- Loss: 0.21121108531951904
train-epoch-step: 66-228 -- Loss: 0.17126870155334473
train-epoch-step: 66-229 -- Loss: 0.17298391461372375
train-epoch-step: 66-230 -- Loss: 0.17016512155532837
train-epoch-step: 66-231 -- Loss: 0.15447358787059784
train-epoch-step: 66-232 -- Loss: 0.17866525053977966
train-epoch-step: 66-233 -- Loss: 0.08077811449766159
train-epoch-step: 66-234 -- Loss: 0.17131444811820984
train-epoch-step: 66-235 -- Loss: 0.14304524660110474
train-epoch-step: 66-236 -- Loss: 0.17123501002788544
train-epoch-step: 66-237 -- Loss: 0.2236040234565735
train-epoch-step: 66-238 -- Loss: 0.15291087329387665
train-epoch-step: 66-239 -- Loss: 0.12186535447835922
train-epoch-step: 66-240 -- Loss: 0.21984021365642548
train-epoch-step: 66-241 -- Loss: 0.14604659378528595
train-epoch-step: 66-242 -- Loss: 0.21332015097141266
train-epoch-step: 66-243 -- Loss: 0.23397549986839294
train-epoch-step: 66-244 -- Loss: 0.2002929449081421
train-epoch-step: 66-245 -- Loss: 0.20362523198127747
train-epoch-step: 66-246 -- Loss: 0.20672538876533508
train-epoch-step: 66-247 -- Loss: 0.201236754655838
train-epoch-step: 66-248 -- Loss: 0.18593339622020721
train-epoch-step: 66-249 -- Loss: 0.1312624216079712
train-epoch-step: 66-250 -- Loss: 0.19770704209804535
train-epoch-step: 66-251 -- Loss: 0.10873459279537201
train-epoch-step: 66-252 -- Loss: 0.1814935803413391
train-epoch-step: 66-253 -- Loss: 0.1316661387681961
train-epoch-step: 66-254 -- Loss: 0.20513586699962616
train-epoch-step: 66-255 -- Loss: 0.14073437452316284
train-epoch-step: 66-256 -- Loss: 0.1429506093263626
train-epoch-step: 66-257 -- Loss: 0.17819297313690186
train-epoch-step: 66-258 -- Loss: 0.14464806020259857
train-epoch-step: 66-259 -- Loss: 0.10930383205413818
train-epoch-step: 66-260 -- Loss: 0.19484467804431915
train-epoch-step: 66-261 -- Loss: 0.1611766368150711
train-epoch-step: 66-262 -- Loss: 0.28718721866607666
train-epoch-step: 66-263 -- Loss: 0.18816621601581573
train-epoch-step: 66-264 -- Loss: 0.16899928450584412
train-epoch-step: 66-265 -- Loss: 0.10739370435476303
train-epoch-step: 66-266 -- Loss: 0.15710631012916565
train-epoch-step: 66-267 -- Loss: 0.12461274862289429
train-epoch-step: 66-268 -- Loss: 0.11962214857339859
train-epoch-step: 66-269 -- Loss: 0.1664218008518219
train-epoch-step: 66-270 -- Loss: 0.10446202754974365
train-epoch-step: 66-271 -- Loss: 0.14236243069171906
train-epoch-step: 66-272 -- Loss: 0.11221420019865036
train-epoch-step: 66-273 -- Loss: 0.12270306795835495
train-epoch-step: 66-274 -- Loss: 0.18109576404094696
train-epoch-step: 66-275 -- Loss: 0.19106078147888184
train-epoch-step: 66-276 -- Loss: 0.1511254608631134
train-epoch-step: 66-277 -- Loss: 0.1507873237133026
train-epoch-step: 66-278 -- Loss: 0.14397314190864563
train-epoch-step: 66-279 -- Loss: 0.13634832203388214
train-epoch-step: 66-280 -- Loss: 0.20859937369823456
train-epoch-step: 66-281 -- Loss: 0.16904334723949432
train-epoch-step: 66-282 -- Loss: 0.13910196721553802
train-epoch-step: 66-283 -- Loss: 0.11223291605710983
train-epoch-step: 66-284 -- Loss: 0.12798476219177246
train-epoch-step: 66-285 -- Loss: 0.18729162216186523
train-epoch-step: 66-286 -- Loss: 0.14969584345817566
train-epoch-step: 66-287 -- Loss: 0.19334933161735535
train-epoch-step: 66-288 -- Loss: 0.09344523400068283
train-epoch-step: 66-289 -- Loss: 0.12207040190696716
train-epoch-step: 66-290 -- Loss: 0.1750926971435547
train-epoch-step: 66-291 -- Loss: 0.11487957090139389
train-epoch-step: 66-292 -- Loss: 0.15475203096866608
train-epoch-step: 66-293 -- Loss: 0.1327391117811203
train-epoch-step: 66-294 -- Loss: 0.15392626821994781
train-epoch-step: 66-295 -- Loss: 0.2552154064178467
train-epoch-step: 66-296 -- Loss: 0.1569221168756485
train-epoch-step: 66-297 -- Loss: 0.1705501526594162
train-epoch-step: 66-298 -- Loss: 0.2206006944179535
train-epoch-step: 66-299 -- Loss: 0.1414162516593933
train-epoch-step: 66-300 -- Loss: 0.1579464077949524
train-epoch-step: 66-301 -- Loss: 0.16994892060756683
train-epoch-step: 66-302 -- Loss: 0.214548259973526
train-epoch-step: 66-303 -- Loss: 0.20032209157943726
train-epoch-step: 66-304 -- Loss: 0.11997018754482269
train-epoch-step: 66-305 -- Loss: 0.1389446258544922
train-epoch-step: 66-306 -- Loss: 0.20611681044101715
train-epoch-step: 66-307 -- Loss: 0.1642608791589737
train-epoch-step: 66-308 -- Loss: 0.21024245023727417
train-epoch-step: 66-309 -- Loss: 0.14941246807575226
train-epoch-step: 66-310 -- Loss: 0.16073113679885864
train-epoch-step: 66-311 -- Loss: 0.15740792453289032
train-epoch-step: 66-312 -- Loss: 0.19871759414672852
train-epoch-step: 66-313 -- Loss: 0.09450565278530121
train-epoch-step: 66-314 -- Loss: 0.18279369175434113
train-epoch-step: 66-315 -- Loss: 0.16284212470054626
train-epoch-step: 66-316 -- Loss: 0.14489932358264923
train-epoch-step: 66-317 -- Loss: 0.1308443546295166
train-epoch-step: 66-318 -- Loss: 0.16231226921081543
train-epoch-step: 66-319 -- Loss: 0.15762120485305786
train-epoch-step: 66-320 -- Loss: 0.11474609375
train-epoch-step: 66-321 -- Loss: 0.12772220373153687
train-epoch-step: 66-322 -- Loss: 0.20916277170181274
train-epoch-step: 66-323 -- Loss: 0.1552698165178299
train-epoch-step: 66-324 -- Loss: 0.24801912903785706
train-epoch-step: 66-325 -- Loss: 0.14907306432724
train-epoch-step: 66-326 -- Loss: 0.16708438098430634
train-epoch-step: 66-327 -- Loss: 0.2062089443206787
train-epoch-step: 66-328 -- Loss: 0.18682995438575745
train-epoch-step: 66-329 -- Loss: 0.32146090269088745
train-epoch-step: 66-330 -- Loss: 0.34690260887145996
train-epoch-step: 66-331 -- Loss: 0.2060076892375946
train-epoch-step: 66-332 -- Loss: 0.09636091440916061
train-epoch-step: 66-333 -- Loss: 0.17789272964000702
train-epoch-step: 66-334 -- Loss: 0.1511324644088745
train-epoch-step: 66-335 -- Loss: 0.17174947261810303
train-epoch-step: 66-336 -- Loss: 0.1461576372385025
train-epoch-step: 66-337 -- Loss: 0.19651411473751068
train-epoch-step: 66-338 -- Loss: 0.1543186753988266
train-epoch-step: 66-339 -- Loss: 0.13687318563461304
train-epoch-step: 66-340 -- Loss: 0.19417314231395721
train-epoch-step: 66-341 -- Loss: 0.13860677182674408
train-epoch-step: 66-342 -- Loss: 0.15952114760875702
train-epoch-step: 66-343 -- Loss: 0.14605814218521118
train-epoch-step: 66-344 -- Loss: 0.16225849092006683
train-epoch-step: 66-345 -- Loss: 0.1206536591053009
train-epoch-step: 66-346 -- Loss: 0.19507834315299988
train-epoch-step: 66-347 -- Loss: 0.1479026973247528
train-epoch-step: 66-348 -- Loss: 0.19865882396697998
train-epoch-step: 66-349 -- Loss: 0.19123625755310059
train-epoch-step: 66-350 -- Loss: 0.24650225043296814
train-epoch-step: 66-351 -- Loss: 0.18407227098941803
train-epoch-step: 66-352 -- Loss: 0.11790062487125397
train-epoch-step: 66-353 -- Loss: 0.18838059902191162
train-epoch-step: 66-354 -- Loss: 0.27607065439224243
train-epoch-step: 66-355 -- Loss: 0.11395317316055298
train-epoch-step: 66-356 -- Loss: 0.11646388471126556
train-epoch-step: 66-357 -- Loss: 0.18069988489151
train-epoch-step: 66-358 -- Loss: 0.1806153804063797
train-epoch-step: 66-359 -- Loss: 0.1352205127477646
train-epoch-step: 66-360 -- Loss: 0.12031077593564987
train-epoch-step: 66-361 -- Loss: 0.22627268731594086
train-epoch-step: 66-362 -- Loss: 0.16139604151248932
train-epoch-step: 66-363 -- Loss: 0.10584476590156555
train-epoch-step: 66-364 -- Loss: 0.17846404016017914
train-epoch-step: 66-365 -- Loss: 0.16287770867347717
train-epoch-step: 66-366 -- Loss: 0.18949997425079346
train-epoch-step: 66-367 -- Loss: 0.22871729731559753
train-epoch-step: 66-368 -- Loss: 0.19393715262413025
train-epoch-step: 66-369 -- Loss: 0.266831636428833
train-epoch-step: 66-370 -- Loss: 0.1212799996137619
train-epoch-step: 66-371 -- Loss: 0.11734800785779953
train-epoch-step: 66-372 -- Loss: 0.14022648334503174
train-epoch-step: 66-373 -- Loss: 0.17913764715194702
train-epoch-step: 66-374 -- Loss: 0.14839212596416473
train-epoch-step: 66-375 -- Loss: 0.2599577307701111
train-epoch-step: 66-376 -- Loss: 0.15507468581199646
train-epoch-step: 66-377 -- Loss: 0.21972067654132843
train-epoch-step: 66-378 -- Loss: 0.19139204919338226
train-epoch-step: 66-379 -- Loss: 0.11355724185705185
train-epoch-step: 66-380 -- Loss: 0.08758870512247086
train-epoch-step: 66-381 -- Loss: 0.2332235872745514
train-epoch-step: 66-382 -- Loss: 0.22591082751750946
train-epoch-step: 66-383 -- Loss: 0.16829648613929749
train-epoch-step: 66-384 -- Loss: 0.20280815660953522
train-epoch-step: 66-385 -- Loss: 0.18321886658668518
train-epoch-step: 66-386 -- Loss: 0.17511123418807983
train-epoch-step: 66-387 -- Loss: 0.192140132188797
train-epoch-step: 66-388 -- Loss: 0.1838417947292328
train-epoch-step: 66-389 -- Loss: 0.16270330548286438
train-epoch-step: 66-390 -- Loss: 0.13943324983119965
train-epoch-step: 66-391 -- Loss: 0.13827738165855408
train-epoch-step: 66-392 -- Loss: 0.1853371560573578
train-epoch-step: 66-393 -- Loss: 0.14788778126239777
train-epoch-step: 66-394 -- Loss: 0.19261115789413452
train-epoch-step: 66-395 -- Loss: 0.15529872477054596
train-epoch-step: 66-396 -- Loss: 0.12290164828300476
train-epoch-step: 66-397 -- Loss: 0.12390609085559845
train-epoch-step: 66-398 -- Loss: 0.1905350387096405
train-epoch-step: 66-399 -- Loss: 0.1764611005783081
train-epoch-step: 66-400 -- Loss: 0.27299368381500244
train-epoch-step: 66-401 -- Loss: 0.11605995893478394
train-epoch-step: 66-402 -- Loss: 0.24642111361026764
train-epoch-step: 66-403 -- Loss: 0.15967628359794617
train-epoch-step: 66-404 -- Loss: 0.13403832912445068
train-epoch-step: 66-405 -- Loss: 0.1412847340106964
train-epoch-step: 66-406 -- Loss: 0.16276437044143677
train-epoch-step: 66-407 -- Loss: 0.11041078716516495
train-epoch-step: 66-408 -- Loss: 0.1573961228132248
train-epoch-step: 66-409 -- Loss: 0.16654178500175476
train-epoch-step: 66-410 -- Loss: 0.16711898148059845
train-epoch-step: 66-411 -- Loss: 0.18621796369552612
train-epoch-step: 66-412 -- Loss: 0.12486419826745987
train-epoch-step: 66-413 -- Loss: 0.14264096319675446
train-epoch-step: 66-414 -- Loss: 0.12905752658843994
train-epoch-step: 66-415 -- Loss: 0.13178926706314087
train-epoch-step: 66-416 -- Loss: 0.25656813383102417
train-epoch-step: 66-417 -- Loss: 0.18514308333396912
train-epoch-step: 66-418 -- Loss: 0.2157469093799591
train-epoch-step: 66-419 -- Loss: 0.1630142629146576
train-epoch-step: 66-420 -- Loss: 0.14968958497047424
train-epoch-step: 66-421 -- Loss: 0.1715327501296997
train-epoch-step: 66-422 -- Loss: 0.14273890852928162
train-epoch-step: 66-423 -- Loss: 0.16847914457321167
train-epoch-step: 66-424 -- Loss: 0.13441433012485504
train-epoch-step: 66-425 -- Loss: 0.17818820476531982
train-epoch-step: 66-426 -- Loss: 0.15692691504955292
train-epoch-step: 66-427 -- Loss: 0.1169356033205986
train-epoch-step: 66-428 -- Loss: 0.18276852369308472
train-epoch-step: 66-429 -- Loss: 0.1701473593711853
train-epoch-step: 66-430 -- Loss: 0.13553549349308014
train-epoch-step: 66-431 -- Loss: 0.15891900658607483
train-epoch-step: 66-432 -- Loss: 0.23632217943668365
train-epoch-step: 66-433 -- Loss: 0.1313607096672058
train-epoch-step: 66-434 -- Loss: 0.12292159348726273
train-epoch-step: 66-435 -- Loss: 0.14932259917259216
train-epoch-step: 66-436 -- Loss: 0.14910690486431122
train-epoch-step: 66-437 -- Loss: 0.1278613805770874
train-epoch-step: 66-438 -- Loss: 0.16450025141239166
train-epoch-step: 66-439 -- Loss: 0.2598291039466858
train-epoch-step: 66-440 -- Loss: 0.12658467888832092
train-epoch-step: 66-441 -- Loss: 0.19327087700366974
train-epoch-step: 66-442 -- Loss: 0.1719547063112259
train-epoch-step: 66-443 -- Loss: 0.15115639567375183
train-epoch-step: 66-444 -- Loss: 0.1706346571445465
train-epoch-step: 66-445 -- Loss: 0.1742354929447174
train-epoch-step: 66-446 -- Loss: 0.15014345943927765
train-epoch-step: 66-447 -- Loss: 0.18668590486049652
train-epoch-step: 66-448 -- Loss: 0.21696925163269043
train-epoch-step: 66-449 -- Loss: 0.18432080745697021
train-epoch-step: 66-450 -- Loss: 0.17596197128295898
train-epoch-step: 66-451 -- Loss: 0.1442759931087494
train-epoch-step: 66-452 -- Loss: 0.13779641687870026
train-epoch-step: 66-453 -- Loss: 0.08787232637405396
train-epoch-step: 66-454 -- Loss: 0.2243683934211731
train-epoch-step: 66-455 -- Loss: 0.11867136508226395
train-epoch-step: 66-456 -- Loss: 0.1143762469291687
train-epoch-step: 66-457 -- Loss: 0.20821085572242737
train-epoch-step: 66-458 -- Loss: 0.13920511305332184
train-epoch-step: 66-459 -- Loss: 0.20880483090877533
train-epoch-step: 66-460 -- Loss: 0.12168585509061813
train-epoch-step: 66-461 -- Loss: 0.12985894083976746
train-epoch-step: 66-462 -- Loss: 0.1476898044347763
train-epoch-step: 66-463 -- Loss: 0.12989474833011627
train-epoch-step: 66-464 -- Loss: 0.15287236869335175
train-epoch-step: 66-465 -- Loss: 0.232655331492424
train-epoch-step: 66-466 -- Loss: 0.19074442982673645
train-epoch-step: 66-467 -- Loss: 0.11056667566299438
train-epoch-step: 66-468 -- Loss: 0.1575850248336792
train-epoch-step: 66-469 -- Loss: 0.1966170370578766
train-epoch-step: 66-470 -- Loss: 0.16359595954418182
train-epoch-step: 66-471 -- Loss: 0.1491725593805313
train-epoch-step: 66-472 -- Loss: 0.15310807526111603
train-epoch-step: 66-473 -- Loss: 0.146542027592659
train-epoch-step: 66-474 -- Loss: 0.11437144875526428
train-epoch-step: 66-475 -- Loss: 0.10546529293060303
train-epoch-step: 66-476 -- Loss: 0.1929604858160019
train-epoch-step: 66-477 -- Loss: 0.19175951182842255
train-epoch-step: 66-478 -- Loss: 0.1814086139202118
train-epoch-step: 66-479 -- Loss: 0.13342489302158356
train-epoch-step: 66-480 -- Loss: 0.1839675009250641
train-epoch-step: 66-481 -- Loss: 0.2713974118232727
train-epoch-step: 66-482 -- Loss: 0.2417098432779312
train-epoch-step: 66-483 -- Loss: 0.17249950766563416
train-epoch-step: 66-484 -- Loss: 0.19983235001564026
train-epoch-step: 66-485 -- Loss: 0.11994121223688126
train-epoch-step: 66-486 -- Loss: 0.2198323905467987
train-epoch-step: 66-487 -- Loss: 0.2225113958120346
train-epoch-step: 66-488 -- Loss: 0.17851784825325012
train-epoch-step: 66-489 -- Loss: 0.21387027204036713
train-epoch-step: 66-490 -- Loss: 0.13395336270332336
train-epoch-step: 66-491 -- Loss: 0.1307305544614792
train-epoch-step: 66-492 -- Loss: 0.12014011293649673
train-epoch-step: 66-493 -- Loss: 0.18881285190582275
train-epoch-step: 66-494 -- Loss: 0.19364364445209503
train-epoch-step: 66-495 -- Loss: 0.19124262034893036
train-epoch-step: 66-496 -- Loss: 0.1373508870601654
train-epoch-step: 66-497 -- Loss: 0.17702221870422363
train-epoch-step: 66-498 -- Loss: 0.13973172008991241
train-epoch-step: 66-499 -- Loss: 0.16021408140659332
train-epoch-step: 66-500 -- Loss: 0.15128085017204285
train-epoch-step: 66-501 -- Loss: 0.20444265007972717
train-epoch-step: 66-502 -- Loss: 0.15004676580429077
train-epoch-step: 66-503 -- Loss: 0.21092073619365692
train-epoch-step: 66-504 -- Loss: 0.11377345025539398
train-epoch-step: 66-505 -- Loss: 0.16579893231391907
train-epoch-step: 66-506 -- Loss: 0.1114753782749176
train-epoch-step: 66-507 -- Loss: 0.1684921532869339
train-epoch-step: 66-508 -- Loss: 0.164043128490448
train-epoch-step: 66-509 -- Loss: 0.16552507877349854
train-epoch-step: 66-510 -- Loss: 0.12242113053798676
train-epoch-step: 66-511 -- Loss: 0.2108921855688095
train-epoch-step: 66-512 -- Loss: 0.17016176879405975
train-epoch-step: 66-513 -- Loss: 0.17835165560245514
train-epoch-step: 66-514 -- Loss: 0.137925922870636
train-epoch-step: 66-515 -- Loss: 0.1494341790676117
train-epoch-step: 66-516 -- Loss: 0.16446706652641296
train-epoch-step: 66-517 -- Loss: 0.1662970334291458
train-epoch-step: 66-518 -- Loss: 0.13327841460704803
train-epoch-step: 66-519 -- Loss: 0.13034699857234955
train-epoch-step: 66-520 -- Loss: 0.17832864820957184
train-epoch-step: 66-521 -- Loss: 0.2181594967842102
train-epoch-step: 66-522 -- Loss: 0.17327333986759186
train-epoch-step: 66-523 -- Loss: 0.15011118352413177
train-epoch-step: 66-524 -- Loss: 0.16112437844276428
train-epoch-step: 66-525 -- Loss: 0.18051859736442566
train-epoch-step: 66-526 -- Loss: 0.12473095953464508
train-epoch-step: 66-527 -- Loss: 0.14623093605041504
train-epoch-step: 66-528 -- Loss: 0.1484205275774002
train-epoch-step: 66-529 -- Loss: 0.1552768051624298
train-epoch-step: 66-530 -- Loss: 0.16019871830940247
train-epoch-step: 66-531 -- Loss: 0.19089455902576447
train-epoch-step: 66-532 -- Loss: 0.163429856300354
train-epoch-step: 66-533 -- Loss: 0.1701820343732834
train-epoch-step: 66-534 -- Loss: 0.12467091530561447
train-epoch-step: 66-535 -- Loss: 0.24635949730873108
train-epoch-step: 66-536 -- Loss: 0.15103106200695038
train-epoch-step: 66-537 -- Loss: 0.1417337954044342
train-epoch-step: 66-538 -- Loss: 0.09809595346450806
train-epoch-step: 66-539 -- Loss: 0.17347216606140137
train-epoch-step: 66-540 -- Loss: 0.12999550998210907
train-epoch-step: 66-541 -- Loss: 0.19722674787044525
train-epoch-step: 66-542 -- Loss: 0.21490544080734253
train-epoch-step: 66-543 -- Loss: 0.15898171067237854
train-epoch-step: 66-544 -- Loss: 0.21746692061424255
train-epoch-step: 66-545 -- Loss: 0.18363478779792786
train-epoch-step: 66-546 -- Loss: 0.19750253856182098
train-epoch-step: 66-547 -- Loss: 0.17708782851696014
train-epoch-step: 66-548 -- Loss: 0.08858779072761536
train-epoch-step: 66-549 -- Loss: 0.14327818155288696
train-epoch-step: 66-550 -- Loss: 0.1919553130865097
train-epoch-step: 66-551 -- Loss: 0.14595681428909302
train-epoch-step: 66-552 -- Loss: 0.11985332518815994
train-epoch-step: 66-553 -- Loss: 0.1804141104221344
train-epoch-step: 66-554 -- Loss: 0.18476495146751404
train-epoch-step: 66-555 -- Loss: 0.20540674030780792
train-epoch-step: 66-556 -- Loss: 0.14513686299324036
train-epoch-step: 66-557 -- Loss: 0.22911348938941956
train-epoch-step: 66-558 -- Loss: 0.22067347168922424
train-epoch-step: 66-559 -- Loss: 0.1309310793876648
train-epoch-step: 66-560 -- Loss: 0.20255687832832336
train-epoch-step: 66-561 -- Loss: 0.16777528822422028
train-epoch-step: 66-562 -- Loss: 0.15889982879161835
train-epoch-step: 66-563 -- Loss: 0.17685483396053314
train-epoch-step: 66-564 -- Loss: 0.09635680913925171
train-epoch-step: 66-565 -- Loss: 0.17571040987968445
train-epoch-step: 66-566 -- Loss: 0.14258377254009247
train-epoch-step: 66-567 -- Loss: 0.20482362806797028
train-epoch-step: 66-568 -- Loss: 0.15567225217819214
train-epoch-step: 66-569 -- Loss: 0.23017536103725433
train-epoch-step: 66-570 -- Loss: 0.16163499653339386
train-epoch-step: 66-571 -- Loss: 0.20435109734535217
train-epoch-step: 66-572 -- Loss: 0.22450487315654755
train-epoch-step: 66-573 -- Loss: 0.19141867756843567
train-epoch-step: 66-574 -- Loss: 0.2296726256608963
train-epoch-step: 66-575 -- Loss: 0.2824561893939972
train-epoch-step: 66-576 -- Loss: 0.11590082943439484
train-epoch-step: 66-577 -- Loss: 0.15867000818252563
train-epoch-step: 66-578 -- Loss: 0.21131862699985504
train-epoch-step: 66-579 -- Loss: 0.16073279082775116
train-epoch-step: 66-580 -- Loss: 0.1641353964805603
train-epoch-step: 66-581 -- Loss: 0.13252367079257965
train-epoch-step: 66-582 -- Loss: 0.20124424993991852
train-epoch-step: 66-583 -- Loss: 0.2087007761001587
train-epoch-step: 66-584 -- Loss: 0.15558218955993652
train-epoch-step: 66-585 -- Loss: 0.1897488236427307
train-epoch-step: 66-586 -- Loss: 0.2506570816040039
train-epoch-step: 66-587 -- Loss: 0.15459540486335754
train-epoch-step: 66-588 -- Loss: 0.1210319995880127
val-epoch-step: 66-589 -- Loss: 0.18905819952487946
val-epoch-step: 66-590 -- Loss: 0.15047413110733032
val-epoch-step: 66-591 -- Loss: 0.22479715943336487
val-epoch-step: 66-592 -- Loss: 0.17084044218063354
val-epoch-step: 66-593 -- Loss: 0.1616789549589157
val-epoch-step: 66-594 -- Loss: 0.34743666648864746
val-epoch-step: 66-595 -- Loss: 0.17012113332748413
val-epoch-step: 66-596 -- Loss: 0.1865389347076416
val-epoch-step: 66-597 -- Loss: 0.16945388913154602
val-epoch-step: 66-598 -- Loss: 0.14465636014938354
val-epoch-step: 66-599 -- Loss: 0.17608226835727692
val-epoch-step: 66-600 -- Loss: 0.18735072016716003
val-epoch-step: 66-601 -- Loss: 0.15535546839237213
val-epoch-step: 66-602 -- Loss: 0.13135969638824463
val-epoch-step: 66-603 -- Loss: 0.2001175582408905
val-epoch-step: 66-604 -- Loss: 0.1422927975654602
val-epoch-step: 66-605 -- Loss: 0.14253976941108704
val-epoch-step: 66-606 -- Loss: 0.2504694163799286
val-epoch-step: 66-607 -- Loss: 0.11939078569412231
val-epoch-step: 66-608 -- Loss: 0.2525978982448578
val-epoch-step: 66-609 -- Loss: 0.17216503620147705
val-epoch-step: 66-610 -- Loss: 0.17725682258605957
val-epoch-step: 66-611 -- Loss: 0.15176177024841309
val-epoch-step: 66-612 -- Loss: 0.367784321308136
val-epoch-step: 66-613 -- Loss: 0.16897937655448914
val-epoch-step: 66-614 -- Loss: 0.16310091316699982
val-epoch-step: 66-615 -- Loss: 0.1700693517923355
val-epoch-step: 66-616 -- Loss: 0.1525464951992035
val-epoch-step: 66-617 -- Loss: 0.18051426112651825
val-epoch-step: 66-618 -- Loss: 0.17336703836917877
val-epoch-step: 66-619 -- Loss: 0.2589920163154602
val-epoch-step: 66-620 -- Loss: 0.17310985922813416
val-epoch-step: 66-621 -- Loss: 0.12167640775442123
val-epoch-step: 66-622 -- Loss: 0.14335916936397552
val-epoch-step: 66-623 -- Loss: 0.14339767396450043
val-epoch-step: 66-624 -- Loss: 0.13745050132274628
val-epoch-step: 66-625 -- Loss: 0.15216590464115143
val-epoch-step: 66-626 -- Loss: 0.14403514564037323
val-epoch-step: 66-627 -- Loss: 0.17796875536441803
val-epoch-step: 66-628 -- Loss: 0.6819713115692139
val-epoch-step: 66-629 -- Loss: 0.1843433678150177
val-epoch-step: 66-630 -- Loss: 0.3344718813896179
val-epoch-step: 66-631 -- Loss: 0.13952267169952393
val-epoch-step: 66-632 -- Loss: 0.1856815665960312
val-epoch-step: 66-633 -- Loss: 0.1438533067703247
val-epoch-step: 66-634 -- Loss: 0.14355766773223877
val-epoch-step: 66-635 -- Loss: 0.1149861216545105
val-epoch-step: 66-636 -- Loss: 0.16754387319087982
val-epoch-step: 66-637 -- Loss: 0.17365054786205292
val-epoch-step: 66-638 -- Loss: 0.147484689950943
val-epoch-step: 66-639 -- Loss: 0.24982509016990662
val-epoch-step: 66-640 -- Loss: 0.2483595907688141
val-epoch-step: 66-641 -- Loss: 0.12798762321472168
val-epoch-step: 66-642 -- Loss: 0.17054086923599243
val-epoch-step: 66-643 -- Loss: 0.20237895846366882
val-epoch-step: 66-644 -- Loss: 0.15909306704998016
val-epoch-step: 66-645 -- Loss: 0.21616986393928528
val-epoch-step: 66-646 -- Loss: 0.16373592615127563
val-epoch-step: 66-647 -- Loss: 0.1218249648809433
val-epoch-step: 66-648 -- Loss: 0.15245243906974792
val-epoch-step: 66-649 -- Loss: 0.20027600228786469
val-epoch-step: 66-650 -- Loss: 0.2467883825302124
val-epoch-step: 66-651 -- Loss: 0.1413029283285141
val-epoch-step: 66-652 -- Loss: 0.1517479568719864
val-epoch-step: 66-653 -- Loss: 0.2013172060251236
val-epoch-step: 66-654 -- Loss: 0.10634354501962662
Epoch: 66 -- Train Loss: tensor(0.1390, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 67-0 -- Loss: 0.21653123199939728
train-epoch-step: 67-1 -- Loss: 0.13724994659423828
train-epoch-step: 67-2 -- Loss: 0.19087153673171997
train-epoch-step: 67-3 -- Loss: 0.13789010047912598
train-epoch-step: 67-4 -- Loss: 0.1506599485874176
train-epoch-step: 67-5 -- Loss: 0.17363248765468597
train-epoch-step: 67-6 -- Loss: 0.2016982138156891
train-epoch-step: 67-7 -- Loss: 0.16031156480312347
train-epoch-step: 67-8 -- Loss: 0.1713031828403473
train-epoch-step: 67-9 -- Loss: 0.22272424399852753
train-epoch-step: 67-10 -- Loss: 0.18182453513145447
train-epoch-step: 67-11 -- Loss: 0.17030110955238342
train-epoch-step: 67-12 -- Loss: 0.14274555444717407
train-epoch-step: 67-13 -- Loss: 0.169691264629364
train-epoch-step: 67-14 -- Loss: 0.15799427032470703
train-epoch-step: 67-15 -- Loss: 0.15541094541549683
train-epoch-step: 67-16 -- Loss: 0.1572071760892868
train-epoch-step: 67-17 -- Loss: 0.20611217617988586
train-epoch-step: 67-18 -- Loss: 0.1855979859828949
train-epoch-step: 67-19 -- Loss: 0.1298276036977768
train-epoch-step: 67-20 -- Loss: 0.2050330638885498
train-epoch-step: 67-21 -- Loss: 0.24001124501228333
train-epoch-step: 67-22 -- Loss: 0.1307920664548874
train-epoch-step: 67-23 -- Loss: 0.13812223076820374
train-epoch-step: 67-24 -- Loss: 0.12183582782745361
train-epoch-step: 67-25 -- Loss: 0.21292415261268616
train-epoch-step: 67-26 -- Loss: 0.1840551346540451
train-epoch-step: 67-27 -- Loss: 0.21208122372627258
train-epoch-step: 67-28 -- Loss: 0.1200825572013855
train-epoch-step: 67-29 -- Loss: 0.23300345242023468
train-epoch-step: 67-30 -- Loss: 0.10435041785240173
train-epoch-step: 67-31 -- Loss: 0.13064780831336975
train-epoch-step: 67-32 -- Loss: 0.16829071938991547
train-epoch-step: 67-33 -- Loss: 0.26416558027267456
train-epoch-step: 67-34 -- Loss: 0.16086795926094055
train-epoch-step: 67-35 -- Loss: 0.2279747724533081
train-epoch-step: 67-36 -- Loss: 0.1385030597448349
train-epoch-step: 67-37 -- Loss: 0.13358637690544128
train-epoch-step: 67-38 -- Loss: 0.1954059898853302
train-epoch-step: 67-39 -- Loss: 0.20918840169906616
train-epoch-step: 67-40 -- Loss: 0.18760788440704346
train-epoch-step: 67-41 -- Loss: 0.20384185016155243
train-epoch-step: 67-42 -- Loss: 0.14108094573020935
train-epoch-step: 67-43 -- Loss: 0.24930232763290405
train-epoch-step: 67-44 -- Loss: 0.12074675410985947
train-epoch-step: 67-45 -- Loss: 0.10906018316745758
train-epoch-step: 67-46 -- Loss: 0.15957821905612946
train-epoch-step: 67-47 -- Loss: 0.2011280059814453
train-epoch-step: 67-48 -- Loss: 0.14967620372772217
train-epoch-step: 67-49 -- Loss: 0.21976637840270996
train-epoch-step: 67-50 -- Loss: 0.10533224791288376
train-epoch-step: 67-51 -- Loss: 0.18949711322784424
train-epoch-step: 67-52 -- Loss: 0.16232262551784515
train-epoch-step: 67-53 -- Loss: 0.20053842663764954
train-epoch-step: 67-54 -- Loss: 0.2859582304954529
train-epoch-step: 67-55 -- Loss: 0.16766519844532013
train-epoch-step: 67-56 -- Loss: 0.17131061851978302
train-epoch-step: 67-57 -- Loss: 0.23110821843147278
train-epoch-step: 67-58 -- Loss: 0.2913237512111664
train-epoch-step: 67-59 -- Loss: 0.2371649146080017
train-epoch-step: 67-60 -- Loss: 0.13157647848129272
train-epoch-step: 67-61 -- Loss: 0.1957608163356781
train-epoch-step: 67-62 -- Loss: 0.18198734521865845
train-epoch-step: 67-63 -- Loss: 0.14188797771930695
train-epoch-step: 67-64 -- Loss: 0.14129340648651123
train-epoch-step: 67-65 -- Loss: 0.1789262890815735
train-epoch-step: 67-66 -- Loss: 0.10847131162881851
train-epoch-step: 67-67 -- Loss: 0.12097185850143433
train-epoch-step: 67-68 -- Loss: 0.20841209590435028
train-epoch-step: 67-69 -- Loss: 0.11965734511613846
train-epoch-step: 67-70 -- Loss: 0.21422679722309113
train-epoch-step: 67-71 -- Loss: 0.2507011890411377
train-epoch-step: 67-72 -- Loss: 0.16772997379302979
train-epoch-step: 67-73 -- Loss: 0.204327791929245
train-epoch-step: 67-74 -- Loss: 0.09260759502649307
train-epoch-step: 67-75 -- Loss: 0.12285107374191284
train-epoch-step: 67-76 -- Loss: 0.14004534482955933
train-epoch-step: 67-77 -- Loss: 0.22183068096637726
train-epoch-step: 67-78 -- Loss: 0.2514422535896301
train-epoch-step: 67-79 -- Loss: 0.18168717622756958
train-epoch-step: 67-80 -- Loss: 0.24404692649841309
train-epoch-step: 67-81 -- Loss: 0.11875481903553009
train-epoch-step: 67-82 -- Loss: 0.24409808218479156
train-epoch-step: 67-83 -- Loss: 0.17906595766544342
train-epoch-step: 67-84 -- Loss: 0.18437224626541138
train-epoch-step: 67-85 -- Loss: 0.16570265591144562
train-epoch-step: 67-86 -- Loss: 0.12053172290325165
train-epoch-step: 67-87 -- Loss: 0.20573033392429352
train-epoch-step: 67-88 -- Loss: 0.13808423280715942
train-epoch-step: 67-89 -- Loss: 0.18673157691955566
train-epoch-step: 67-90 -- Loss: 0.18656902015209198
train-epoch-step: 67-91 -- Loss: 0.235478013753891
train-epoch-step: 67-92 -- Loss: 0.14877507090568542
train-epoch-step: 67-93 -- Loss: 0.17766126990318298
train-epoch-step: 67-94 -- Loss: 0.21609126031398773
train-epoch-step: 67-95 -- Loss: 0.18333700299263
train-epoch-step: 67-96 -- Loss: 0.2046351283788681
train-epoch-step: 67-97 -- Loss: 0.1706264764070511
train-epoch-step: 67-98 -- Loss: 0.1505817025899887
train-epoch-step: 67-99 -- Loss: 0.17473085224628448
train-epoch-step: 67-100 -- Loss: 0.1835833340883255
train-epoch-step: 67-101 -- Loss: 0.2548198699951172
train-epoch-step: 67-102 -- Loss: 0.20926515758037567
train-epoch-step: 67-103 -- Loss: 0.1786542385816574
train-epoch-step: 67-104 -- Loss: 0.1435295194387436
train-epoch-step: 67-105 -- Loss: 0.2583172619342804
train-epoch-step: 67-106 -- Loss: 0.1721070110797882
train-epoch-step: 67-107 -- Loss: 0.18633678555488586
train-epoch-step: 67-108 -- Loss: 0.1839802861213684
train-epoch-step: 67-109 -- Loss: 0.1402648538351059
train-epoch-step: 67-110 -- Loss: 0.17553888261318207
train-epoch-step: 67-111 -- Loss: 0.1767854392528534
train-epoch-step: 67-112 -- Loss: 0.1588212251663208
train-epoch-step: 67-113 -- Loss: 0.15812472999095917
train-epoch-step: 67-114 -- Loss: 0.1926729679107666
train-epoch-step: 67-115 -- Loss: 0.15784136950969696
train-epoch-step: 67-116 -- Loss: 0.1345796436071396
train-epoch-step: 67-117 -- Loss: 0.12164310365915298
train-epoch-step: 67-118 -- Loss: 0.18466702103614807
train-epoch-step: 67-119 -- Loss: 0.14606007933616638
train-epoch-step: 67-120 -- Loss: 0.24191880226135254
train-epoch-step: 67-121 -- Loss: 0.22135818004608154
train-epoch-step: 67-122 -- Loss: 0.20724369585514069
train-epoch-step: 67-123 -- Loss: 0.19805344939231873
train-epoch-step: 67-124 -- Loss: 0.12275072187185287
train-epoch-step: 67-125 -- Loss: 0.15028038620948792
train-epoch-step: 67-126 -- Loss: 0.2224874198436737
train-epoch-step: 67-127 -- Loss: 0.16071105003356934
train-epoch-step: 67-128 -- Loss: 0.16429412364959717
train-epoch-step: 67-129 -- Loss: 0.1361646205186844
train-epoch-step: 67-130 -- Loss: 0.1832159161567688
train-epoch-step: 67-131 -- Loss: 0.13192841410636902
train-epoch-step: 67-132 -- Loss: 0.18374228477478027
train-epoch-step: 67-133 -- Loss: 0.11722641438245773
train-epoch-step: 67-134 -- Loss: 0.18939177691936493
train-epoch-step: 67-135 -- Loss: 0.12767140567302704
train-epoch-step: 67-136 -- Loss: 0.12127865850925446
train-epoch-step: 67-137 -- Loss: 0.23523418605327606
train-epoch-step: 67-138 -- Loss: 0.24787688255310059
train-epoch-step: 67-139 -- Loss: 0.1260862797498703
train-epoch-step: 67-140 -- Loss: 0.19760340452194214
train-epoch-step: 67-141 -- Loss: 0.2190975397825241
train-epoch-step: 67-142 -- Loss: 0.20650118589401245
train-epoch-step: 67-143 -- Loss: 0.16381797194480896
train-epoch-step: 67-144 -- Loss: 0.17486359179019928
train-epoch-step: 67-145 -- Loss: 0.13804681599140167
train-epoch-step: 67-146 -- Loss: 0.17475686967372894
train-epoch-step: 67-147 -- Loss: 0.16101159155368805
train-epoch-step: 67-148 -- Loss: 0.15532642602920532
train-epoch-step: 67-149 -- Loss: 0.11832693964242935
train-epoch-step: 67-150 -- Loss: 0.18003907799720764
train-epoch-step: 67-151 -- Loss: 0.1894731968641281
train-epoch-step: 67-152 -- Loss: 0.18636441230773926
train-epoch-step: 67-153 -- Loss: 0.2620929479598999
train-epoch-step: 67-154 -- Loss: 0.1278320848941803
train-epoch-step: 67-155 -- Loss: 0.13287284970283508
train-epoch-step: 67-156 -- Loss: 0.11047172546386719
train-epoch-step: 67-157 -- Loss: 0.15736359357833862
train-epoch-step: 67-158 -- Loss: 0.16102313995361328
train-epoch-step: 67-159 -- Loss: 0.17023639380931854
train-epoch-step: 67-160 -- Loss: 0.20317623019218445
train-epoch-step: 67-161 -- Loss: 0.1977095752954483
train-epoch-step: 67-162 -- Loss: 0.20133724808692932
train-epoch-step: 67-163 -- Loss: 0.18304114043712616
train-epoch-step: 67-164 -- Loss: 0.1898907870054245
train-epoch-step: 67-165 -- Loss: 0.1616455465555191
train-epoch-step: 67-166 -- Loss: 0.12287642061710358
train-epoch-step: 67-167 -- Loss: 0.11791107058525085
train-epoch-step: 67-168 -- Loss: 0.19717976450920105
train-epoch-step: 67-169 -- Loss: 0.13037139177322388
train-epoch-step: 67-170 -- Loss: 0.19223448634147644
train-epoch-step: 67-171 -- Loss: 0.14025916159152985
train-epoch-step: 67-172 -- Loss: 0.25598210096359253
train-epoch-step: 67-173 -- Loss: 0.12764234840869904
train-epoch-step: 67-174 -- Loss: 0.23696666955947876
train-epoch-step: 67-175 -- Loss: 0.17985953390598297
train-epoch-step: 67-176 -- Loss: 0.1307651847600937
train-epoch-step: 67-177 -- Loss: 0.1719869077205658
train-epoch-step: 67-178 -- Loss: 0.17374905943870544
train-epoch-step: 67-179 -- Loss: 0.1404586136341095
train-epoch-step: 67-180 -- Loss: 0.15430334210395813
train-epoch-step: 67-181 -- Loss: 0.16350366175174713
train-epoch-step: 67-182 -- Loss: 0.17421409487724304
train-epoch-step: 67-183 -- Loss: 0.26121026277542114
train-epoch-step: 67-184 -- Loss: 0.13389952480793
train-epoch-step: 67-185 -- Loss: 0.14038285613059998
train-epoch-step: 67-186 -- Loss: 0.1853322833776474
train-epoch-step: 67-187 -- Loss: 0.20278827846050262
train-epoch-step: 67-188 -- Loss: 0.16664929687976837
train-epoch-step: 67-189 -- Loss: 0.10285918414592743
train-epoch-step: 67-190 -- Loss: 0.17692232131958008
train-epoch-step: 67-191 -- Loss: 0.15540899336338043
train-epoch-step: 67-192 -- Loss: 0.22131860256195068
train-epoch-step: 67-193 -- Loss: 0.2047930508852005
train-epoch-step: 67-194 -- Loss: 0.17959511280059814
train-epoch-step: 67-195 -- Loss: 0.15732508897781372
train-epoch-step: 67-196 -- Loss: 0.1640775352716446
train-epoch-step: 67-197 -- Loss: 0.12162162363529205
train-epoch-step: 67-198 -- Loss: 0.12269215285778046
train-epoch-step: 67-199 -- Loss: 0.14166268706321716
train-epoch-step: 67-200 -- Loss: 0.1216299906373024
train-epoch-step: 67-201 -- Loss: 0.18604063987731934
train-epoch-step: 67-202 -- Loss: 0.13272400200366974
train-epoch-step: 67-203 -- Loss: 0.1683908998966217
train-epoch-step: 67-204 -- Loss: 0.13280588388442993
train-epoch-step: 67-205 -- Loss: 0.1790258139371872
train-epoch-step: 67-206 -- Loss: 0.1932569295167923
train-epoch-step: 67-207 -- Loss: 0.12769995629787445
train-epoch-step: 67-208 -- Loss: 0.17409440875053406
train-epoch-step: 67-209 -- Loss: 0.13877059519290924
train-epoch-step: 67-210 -- Loss: 0.12758119404315948
train-epoch-step: 67-211 -- Loss: 0.205281063914299
train-epoch-step: 67-212 -- Loss: 0.1936982125043869
train-epoch-step: 67-213 -- Loss: 0.12346842139959335
train-epoch-step: 67-214 -- Loss: 0.14314225316047668
train-epoch-step: 67-215 -- Loss: 0.12417760491371155
train-epoch-step: 67-216 -- Loss: 0.19869907200336456
train-epoch-step: 67-217 -- Loss: 0.20707087218761444
train-epoch-step: 67-218 -- Loss: 0.1451922357082367
train-epoch-step: 67-219 -- Loss: 0.16425961256027222
train-epoch-step: 67-220 -- Loss: 0.12841863930225372
train-epoch-step: 67-221 -- Loss: 0.19798439741134644
train-epoch-step: 67-222 -- Loss: 0.11370633542537689
train-epoch-step: 67-223 -- Loss: 0.16717340052127838
train-epoch-step: 67-224 -- Loss: 0.1889594942331314
train-epoch-step: 67-225 -- Loss: 0.2553090453147888
train-epoch-step: 67-226 -- Loss: 0.1978864073753357
train-epoch-step: 67-227 -- Loss: 0.21225930750370026
train-epoch-step: 67-228 -- Loss: 0.17229005694389343
train-epoch-step: 67-229 -- Loss: 0.1682443618774414
train-epoch-step: 67-230 -- Loss: 0.15765713155269623
train-epoch-step: 67-231 -- Loss: 0.15194085240364075
train-epoch-step: 67-232 -- Loss: 0.17506204545497894
train-epoch-step: 67-233 -- Loss: 0.07937799394130707
train-epoch-step: 67-234 -- Loss: 0.17002660036087036
train-epoch-step: 67-235 -- Loss: 0.13718187808990479
train-epoch-step: 67-236 -- Loss: 0.16887259483337402
train-epoch-step: 67-237 -- Loss: 0.2270386815071106
train-epoch-step: 67-238 -- Loss: 0.14816774427890778
train-epoch-step: 67-239 -- Loss: 0.12363863736391068
train-epoch-step: 67-240 -- Loss: 0.2128378450870514
train-epoch-step: 67-241 -- Loss: 0.14836840331554413
train-epoch-step: 67-242 -- Loss: 0.2133636176586151
train-epoch-step: 67-243 -- Loss: 0.2281707525253296
train-epoch-step: 67-244 -- Loss: 0.1982511281967163
train-epoch-step: 67-245 -- Loss: 0.1995934396982193
train-epoch-step: 67-246 -- Loss: 0.20813174545764923
train-epoch-step: 67-247 -- Loss: 0.1987568438053131
train-epoch-step: 67-248 -- Loss: 0.17695042490959167
train-epoch-step: 67-249 -- Loss: 0.13224604725837708
train-epoch-step: 67-250 -- Loss: 0.19234490394592285
train-epoch-step: 67-251 -- Loss: 0.10266710072755814
train-epoch-step: 67-252 -- Loss: 0.18181130290031433
train-epoch-step: 67-253 -- Loss: 0.13360284268856049
train-epoch-step: 67-254 -- Loss: 0.1999625265598297
train-epoch-step: 67-255 -- Loss: 0.14229942858219147
train-epoch-step: 67-256 -- Loss: 0.14303414523601532
train-epoch-step: 67-257 -- Loss: 0.17574407160282135
train-epoch-step: 67-258 -- Loss: 0.139396071434021
train-epoch-step: 67-259 -- Loss: 0.10782153904438019
train-epoch-step: 67-260 -- Loss: 0.19788247346878052
train-epoch-step: 67-261 -- Loss: 0.16325509548187256
train-epoch-step: 67-262 -- Loss: 0.2956979274749756
train-epoch-step: 67-263 -- Loss: 0.197218120098114
train-epoch-step: 67-264 -- Loss: 0.1701473593711853
train-epoch-step: 67-265 -- Loss: 0.10452687740325928
train-epoch-step: 67-266 -- Loss: 0.15058624744415283
train-epoch-step: 67-267 -- Loss: 0.13198436796665192
train-epoch-step: 67-268 -- Loss: 0.11376035958528519
train-epoch-step: 67-269 -- Loss: 0.17756175994873047
train-epoch-step: 67-270 -- Loss: 0.10328422486782074
train-epoch-step: 67-271 -- Loss: 0.14227187633514404
train-epoch-step: 67-272 -- Loss: 0.1110694408416748
train-epoch-step: 67-273 -- Loss: 0.12411020696163177
train-epoch-step: 67-274 -- Loss: 0.17677123844623566
train-epoch-step: 67-275 -- Loss: 0.2071039378643036
train-epoch-step: 67-276 -- Loss: 0.1488063484430313
train-epoch-step: 67-277 -- Loss: 0.15180064737796783
train-epoch-step: 67-278 -- Loss: 0.14582613110542297
train-epoch-step: 67-279 -- Loss: 0.13417914509773254
train-epoch-step: 67-280 -- Loss: 0.20701870322227478
train-epoch-step: 67-281 -- Loss: 0.17146609723567963
train-epoch-step: 67-282 -- Loss: 0.13966576755046844
train-epoch-step: 67-283 -- Loss: 0.11269862204790115
train-epoch-step: 67-284 -- Loss: 0.14558497071266174
train-epoch-step: 67-285 -- Loss: 0.18199051916599274
train-epoch-step: 67-286 -- Loss: 0.14944419264793396
train-epoch-step: 67-287 -- Loss: 0.19129076600074768
train-epoch-step: 67-288 -- Loss: 0.09120897948741913
train-epoch-step: 67-289 -- Loss: 0.12689495086669922
train-epoch-step: 67-290 -- Loss: 0.18806461989879608
train-epoch-step: 67-291 -- Loss: 0.1133638545870781
train-epoch-step: 67-292 -- Loss: 0.15252535045146942
train-epoch-step: 67-293 -- Loss: 0.13217687606811523
train-epoch-step: 67-294 -- Loss: 0.15871252119541168
train-epoch-step: 67-295 -- Loss: 0.27656203508377075
train-epoch-step: 67-296 -- Loss: 0.15154552459716797
train-epoch-step: 67-297 -- Loss: 0.16480664908885956
train-epoch-step: 67-298 -- Loss: 0.2330177128314972
train-epoch-step: 67-299 -- Loss: 0.14709150791168213
train-epoch-step: 67-300 -- Loss: 0.15930698812007904
train-epoch-step: 67-301 -- Loss: 0.16224205493927002
train-epoch-step: 67-302 -- Loss: 0.221497043967247
train-epoch-step: 67-303 -- Loss: 0.19770987331867218
train-epoch-step: 67-304 -- Loss: 0.12265031039714813
train-epoch-step: 67-305 -- Loss: 0.14012135565280914
train-epoch-step: 67-306 -- Loss: 0.2170417606830597
train-epoch-step: 67-307 -- Loss: 0.16166166961193085
train-epoch-step: 67-308 -- Loss: 0.21199573576450348
train-epoch-step: 67-309 -- Loss: 0.15609779953956604
train-epoch-step: 67-310 -- Loss: 0.15702742338180542
train-epoch-step: 67-311 -- Loss: 0.15361033380031586
train-epoch-step: 67-312 -- Loss: 0.19969531893730164
train-epoch-step: 67-313 -- Loss: 0.0947847068309784
train-epoch-step: 67-314 -- Loss: 0.1866064965724945
train-epoch-step: 67-315 -- Loss: 0.16854968667030334
train-epoch-step: 67-316 -- Loss: 0.16480082273483276
train-epoch-step: 67-317 -- Loss: 0.15003348886966705
train-epoch-step: 67-318 -- Loss: 0.16053466498851776
train-epoch-step: 67-319 -- Loss: 0.15871676802635193
train-epoch-step: 67-320 -- Loss: 0.12186940759420395
train-epoch-step: 67-321 -- Loss: 0.15668654441833496
train-epoch-step: 67-322 -- Loss: 0.20900554955005646
train-epoch-step: 67-323 -- Loss: 0.1538691371679306
train-epoch-step: 67-324 -- Loss: 0.24647410213947296
train-epoch-step: 67-325 -- Loss: 0.15504863858222961
train-epoch-step: 67-326 -- Loss: 0.17418907582759857
train-epoch-step: 67-327 -- Loss: 0.19715848565101624
train-epoch-step: 67-328 -- Loss: 0.18814870715141296
train-epoch-step: 67-329 -- Loss: 0.32941848039627075
train-epoch-step: 67-330 -- Loss: 0.3530609607696533
train-epoch-step: 67-331 -- Loss: 0.2030736804008484
train-epoch-step: 67-332 -- Loss: 0.09866401553153992
train-epoch-step: 67-333 -- Loss: 0.176570326089859
train-epoch-step: 67-334 -- Loss: 0.15156105160713196
train-epoch-step: 67-335 -- Loss: 0.17050883173942566
train-epoch-step: 67-336 -- Loss: 0.14651750028133392
train-epoch-step: 67-337 -- Loss: 0.2036135196685791
train-epoch-step: 67-338 -- Loss: 0.1541026383638382
train-epoch-step: 67-339 -- Loss: 0.13750086724758148
train-epoch-step: 67-340 -- Loss: 0.19138222932815552
train-epoch-step: 67-341 -- Loss: 0.136788472533226
train-epoch-step: 67-342 -- Loss: 0.1600259691476822
train-epoch-step: 67-343 -- Loss: 0.14903584122657776
train-epoch-step: 67-344 -- Loss: 0.16657710075378418
train-epoch-step: 67-345 -- Loss: 0.1291888952255249
train-epoch-step: 67-346 -- Loss: 0.18891505897045135
train-epoch-step: 67-347 -- Loss: 0.14848032593727112
train-epoch-step: 67-348 -- Loss: 0.19959548115730286
train-epoch-step: 67-349 -- Loss: 0.19500042498111725
train-epoch-step: 67-350 -- Loss: 0.24809440970420837
train-epoch-step: 67-351 -- Loss: 0.18913337588310242
train-epoch-step: 67-352 -- Loss: 0.12088920176029205
train-epoch-step: 67-353 -- Loss: 0.18747064471244812
train-epoch-step: 67-354 -- Loss: 0.2749757766723633
train-epoch-step: 67-355 -- Loss: 0.11613858491182327
train-epoch-step: 67-356 -- Loss: 0.11805348098278046
train-epoch-step: 67-357 -- Loss: 0.1858108937740326
train-epoch-step: 67-358 -- Loss: 0.18341811001300812
train-epoch-step: 67-359 -- Loss: 0.13434047996997833
train-epoch-step: 67-360 -- Loss: 0.12243567407131195
train-epoch-step: 67-361 -- Loss: 0.23524630069732666
train-epoch-step: 67-362 -- Loss: 0.1659596711397171
train-epoch-step: 67-363 -- Loss: 0.10508516430854797
train-epoch-step: 67-364 -- Loss: 0.17513209581375122
train-epoch-step: 67-365 -- Loss: 0.16287861764431
train-epoch-step: 67-366 -- Loss: 0.19077208638191223
train-epoch-step: 67-367 -- Loss: 0.2232377827167511
train-epoch-step: 67-368 -- Loss: 0.19310040771961212
train-epoch-step: 67-369 -- Loss: 0.264260470867157
train-epoch-step: 67-370 -- Loss: 0.12080474197864532
train-epoch-step: 67-371 -- Loss: 0.11777236312627792
train-epoch-step: 67-372 -- Loss: 0.14096982777118683
train-epoch-step: 67-373 -- Loss: 0.18114568293094635
train-epoch-step: 67-374 -- Loss: 0.15147608518600464
train-epoch-step: 67-375 -- Loss: 0.2573060691356659
train-epoch-step: 67-376 -- Loss: 0.15355931222438812
train-epoch-step: 67-377 -- Loss: 0.21860764920711517
train-epoch-step: 67-378 -- Loss: 0.19388318061828613
train-epoch-step: 67-379 -- Loss: 0.11563867330551147
train-epoch-step: 67-380 -- Loss: 0.08787026256322861
train-epoch-step: 67-381 -- Loss: 0.23719090223312378
train-epoch-step: 67-382 -- Loss: 0.22243785858154297
train-epoch-step: 67-383 -- Loss: 0.1725458800792694
train-epoch-step: 67-384 -- Loss: 0.20520156621932983
train-epoch-step: 67-385 -- Loss: 0.18198975920677185
train-epoch-step: 67-386 -- Loss: 0.17660515010356903
train-epoch-step: 67-387 -- Loss: 0.19347944855690002
train-epoch-step: 67-388 -- Loss: 0.17528708279132843
train-epoch-step: 67-389 -- Loss: 0.160700261592865
train-epoch-step: 67-390 -- Loss: 0.13849662244319916
train-epoch-step: 67-391 -- Loss: 0.1437072604894638
train-epoch-step: 67-392 -- Loss: 0.1788441389799118
train-epoch-step: 67-393 -- Loss: 0.15230447053909302
train-epoch-step: 67-394 -- Loss: 0.19266141951084137
train-epoch-step: 67-395 -- Loss: 0.15798647701740265
train-epoch-step: 67-396 -- Loss: 0.12257363647222519
train-epoch-step: 67-397 -- Loss: 0.12141859531402588
train-epoch-step: 67-398 -- Loss: 0.19311149418354034
train-epoch-step: 67-399 -- Loss: 0.17124336957931519
train-epoch-step: 67-400 -- Loss: 0.263540655374527
train-epoch-step: 67-401 -- Loss: 0.11308252066373825
train-epoch-step: 67-402 -- Loss: 0.25114309787750244
train-epoch-step: 67-403 -- Loss: 0.15122514963150024
train-epoch-step: 67-404 -- Loss: 0.13455933332443237
train-epoch-step: 67-405 -- Loss: 0.1394723802804947
train-epoch-step: 67-406 -- Loss: 0.15626275539398193
train-epoch-step: 67-407 -- Loss: 0.10896092653274536
train-epoch-step: 67-408 -- Loss: 0.15821413695812225
train-epoch-step: 67-409 -- Loss: 0.16291238367557526
train-epoch-step: 67-410 -- Loss: 0.16806526482105255
train-epoch-step: 67-411 -- Loss: 0.18907839059829712
train-epoch-step: 67-412 -- Loss: 0.1253626048564911
train-epoch-step: 67-413 -- Loss: 0.14254817366600037
train-epoch-step: 67-414 -- Loss: 0.12879815697669983
train-epoch-step: 67-415 -- Loss: 0.13359661400318146
train-epoch-step: 67-416 -- Loss: 0.2634862959384918
train-epoch-step: 67-417 -- Loss: 0.18280640244483948
train-epoch-step: 67-418 -- Loss: 0.2155904620885849
train-epoch-step: 67-419 -- Loss: 0.17601849138736725
train-epoch-step: 67-420 -- Loss: 0.14737772941589355
train-epoch-step: 67-421 -- Loss: 0.1684875339269638
train-epoch-step: 67-422 -- Loss: 0.14385096728801727
train-epoch-step: 67-423 -- Loss: 0.16497653722763062
train-epoch-step: 67-424 -- Loss: 0.13458572328090668
train-epoch-step: 67-425 -- Loss: 0.17682822048664093
train-epoch-step: 67-426 -- Loss: 0.16012969613075256
train-epoch-step: 67-427 -- Loss: 0.12028846889734268
train-epoch-step: 67-428 -- Loss: 0.18902868032455444
train-epoch-step: 67-429 -- Loss: 0.1716374158859253
train-epoch-step: 67-430 -- Loss: 0.14234930276870728
train-epoch-step: 67-431 -- Loss: 0.1632160246372223
train-epoch-step: 67-432 -- Loss: 0.22772885859012604
train-epoch-step: 67-433 -- Loss: 0.13318155705928802
train-epoch-step: 67-434 -- Loss: 0.12279268354177475
train-epoch-step: 67-435 -- Loss: 0.1496492624282837
train-epoch-step: 67-436 -- Loss: 0.14826670289039612
train-epoch-step: 67-437 -- Loss: 0.12681777775287628
train-epoch-step: 67-438 -- Loss: 0.15956124663352966
train-epoch-step: 67-439 -- Loss: 0.2551237642765045
train-epoch-step: 67-440 -- Loss: 0.1295846700668335
train-epoch-step: 67-441 -- Loss: 0.1962430477142334
train-epoch-step: 67-442 -- Loss: 0.1696496158838272
train-epoch-step: 67-443 -- Loss: 0.15038737654685974
train-epoch-step: 67-444 -- Loss: 0.16653738915920258
train-epoch-step: 67-445 -- Loss: 0.1743221879005432
train-epoch-step: 67-446 -- Loss: 0.14664962887763977
train-epoch-step: 67-447 -- Loss: 0.1856554001569748
train-epoch-step: 67-448 -- Loss: 0.2207002341747284
train-epoch-step: 67-449 -- Loss: 0.1842700093984604
train-epoch-step: 67-450 -- Loss: 0.17543667554855347
train-epoch-step: 67-451 -- Loss: 0.13598951697349548
train-epoch-step: 67-452 -- Loss: 0.12881404161453247
train-epoch-step: 67-453 -- Loss: 0.08795644342899323
train-epoch-step: 67-454 -- Loss: 0.2190057635307312
train-epoch-step: 67-455 -- Loss: 0.11723627150058746
train-epoch-step: 67-456 -- Loss: 0.11730534583330154
train-epoch-step: 67-457 -- Loss: 0.20495639741420746
train-epoch-step: 67-458 -- Loss: 0.14037983119487762
train-epoch-step: 67-459 -- Loss: 0.20497363805770874
train-epoch-step: 67-460 -- Loss: 0.1204734519124031
train-epoch-step: 67-461 -- Loss: 0.12885001301765442
train-epoch-step: 67-462 -- Loss: 0.14889270067214966
train-epoch-step: 67-463 -- Loss: 0.1316300332546234
train-epoch-step: 67-464 -- Loss: 0.15076501667499542
train-epoch-step: 67-465 -- Loss: 0.2317899465560913
train-epoch-step: 67-466 -- Loss: 0.19078662991523743
train-epoch-step: 67-467 -- Loss: 0.10965514928102493
train-epoch-step: 67-468 -- Loss: 0.1601095348596573
train-epoch-step: 67-469 -- Loss: 0.1963699907064438
train-epoch-step: 67-470 -- Loss: 0.1689862459897995
train-epoch-step: 67-471 -- Loss: 0.15878592431545258
train-epoch-step: 67-472 -- Loss: 0.15177036821842194
train-epoch-step: 67-473 -- Loss: 0.14873072504997253
train-epoch-step: 67-474 -- Loss: 0.11181848496198654
train-epoch-step: 67-475 -- Loss: 0.10788675397634506
train-epoch-step: 67-476 -- Loss: 0.19219008088111877
train-epoch-step: 67-477 -- Loss: 0.19123394787311554
train-epoch-step: 67-478 -- Loss: 0.18553456664085388
train-epoch-step: 67-479 -- Loss: 0.14764289557933807
train-epoch-step: 67-480 -- Loss: 0.1935783177614212
train-epoch-step: 67-481 -- Loss: 0.27311965823173523
train-epoch-step: 67-482 -- Loss: 0.24780845642089844
train-epoch-step: 67-483 -- Loss: 0.17163830995559692
train-epoch-step: 67-484 -- Loss: 0.2081376612186432
train-epoch-step: 67-485 -- Loss: 0.12122289091348648
train-epoch-step: 67-486 -- Loss: 0.22042779624462128
train-epoch-step: 67-487 -- Loss: 0.22695064544677734
train-epoch-step: 67-488 -- Loss: 0.1750040352344513
train-epoch-step: 67-489 -- Loss: 0.21336902678012848
train-epoch-step: 67-490 -- Loss: 0.1334862858057022
train-epoch-step: 67-491 -- Loss: 0.13356317579746246
train-epoch-step: 67-492 -- Loss: 0.12293680757284164
train-epoch-step: 67-493 -- Loss: 0.18959008157253265
train-epoch-step: 67-494 -- Loss: 0.19160115718841553
train-epoch-step: 67-495 -- Loss: 0.1928669512271881
train-epoch-step: 67-496 -- Loss: 0.1366802603006363
train-epoch-step: 67-497 -- Loss: 0.17926719784736633
train-epoch-step: 67-498 -- Loss: 0.1417756825685501
train-epoch-step: 67-499 -- Loss: 0.16189344227313995
train-epoch-step: 67-500 -- Loss: 0.14992651343345642
train-epoch-step: 67-501 -- Loss: 0.20135743916034698
train-epoch-step: 67-502 -- Loss: 0.15534833073616028
train-epoch-step: 67-503 -- Loss: 0.20648854970932007
train-epoch-step: 67-504 -- Loss: 0.11542637646198273
train-epoch-step: 67-505 -- Loss: 0.16449284553527832
train-epoch-step: 67-506 -- Loss: 0.1127442866563797
train-epoch-step: 67-507 -- Loss: 0.17419861257076263
train-epoch-step: 67-508 -- Loss: 0.17023244500160217
train-epoch-step: 67-509 -- Loss: 0.16280239820480347
train-epoch-step: 67-510 -- Loss: 0.12415305525064468
train-epoch-step: 67-511 -- Loss: 0.20818428695201874
train-epoch-step: 67-512 -- Loss: 0.17019373178482056
train-epoch-step: 67-513 -- Loss: 0.17861878871917725
train-epoch-step: 67-514 -- Loss: 0.13662941753864288
train-epoch-step: 67-515 -- Loss: 0.1485806107521057
train-epoch-step: 67-516 -- Loss: 0.16635726392269135
train-epoch-step: 67-517 -- Loss: 0.1672729104757309
train-epoch-step: 67-518 -- Loss: 0.13284312188625336
train-epoch-step: 67-519 -- Loss: 0.13064874708652496
train-epoch-step: 67-520 -- Loss: 0.1798189878463745
train-epoch-step: 67-521 -- Loss: 0.22506292164325714
train-epoch-step: 67-522 -- Loss: 0.16732822358608246
train-epoch-step: 67-523 -- Loss: 0.14900879561901093
train-epoch-step: 67-524 -- Loss: 0.17275740206241608
train-epoch-step: 67-525 -- Loss: 0.18614445626735687
train-epoch-step: 67-526 -- Loss: 0.12717264890670776
train-epoch-step: 67-527 -- Loss: 0.14477400481700897
train-epoch-step: 67-528 -- Loss: 0.15270768105983734
train-epoch-step: 67-529 -- Loss: 0.1508001983165741
train-epoch-step: 67-530 -- Loss: 0.16316677629947662
train-epoch-step: 67-531 -- Loss: 0.18897336721420288
train-epoch-step: 67-532 -- Loss: 0.16124102473258972
train-epoch-step: 67-533 -- Loss: 0.16626235842704773
train-epoch-step: 67-534 -- Loss: 0.12694597244262695
train-epoch-step: 67-535 -- Loss: 0.2414085865020752
train-epoch-step: 67-536 -- Loss: 0.15063919126987457
train-epoch-step: 67-537 -- Loss: 0.1410519927740097
train-epoch-step: 67-538 -- Loss: 0.10098712146282196
train-epoch-step: 67-539 -- Loss: 0.1800101101398468
train-epoch-step: 67-540 -- Loss: 0.13208280503749847
train-epoch-step: 67-541 -- Loss: 0.20363731682300568
train-epoch-step: 67-542 -- Loss: 0.21422179043293
train-epoch-step: 67-543 -- Loss: 0.16480067372322083
train-epoch-step: 67-544 -- Loss: 0.21884146332740784
train-epoch-step: 67-545 -- Loss: 0.18383736908435822
train-epoch-step: 67-546 -- Loss: 0.1985168606042862
train-epoch-step: 67-547 -- Loss: 0.17357242107391357
train-epoch-step: 67-548 -- Loss: 0.09508354961872101
train-epoch-step: 67-549 -- Loss: 0.145536869764328
train-epoch-step: 67-550 -- Loss: 0.19283872842788696
train-epoch-step: 67-551 -- Loss: 0.14846235513687134
train-epoch-step: 67-552 -- Loss: 0.11910257488489151
train-epoch-step: 67-553 -- Loss: 0.18309958279132843
train-epoch-step: 67-554 -- Loss: 0.17985239624977112
train-epoch-step: 67-555 -- Loss: 0.20573639869689941
train-epoch-step: 67-556 -- Loss: 0.13776694238185883
train-epoch-step: 67-557 -- Loss: 0.21825693547725677
train-epoch-step: 67-558 -- Loss: 0.21927788853645325
train-epoch-step: 67-559 -- Loss: 0.1321088820695877
train-epoch-step: 67-560 -- Loss: 0.19739514589309692
train-epoch-step: 67-561 -- Loss: 0.1692589521408081
train-epoch-step: 67-562 -- Loss: 0.15886902809143066
train-epoch-step: 67-563 -- Loss: 0.1764826476573944
train-epoch-step: 67-564 -- Loss: 0.09597950428724289
train-epoch-step: 67-565 -- Loss: 0.17673692107200623
train-epoch-step: 67-566 -- Loss: 0.14297012984752655
train-epoch-step: 67-567 -- Loss: 0.20587211847305298
train-epoch-step: 67-568 -- Loss: 0.15479514002799988
train-epoch-step: 67-569 -- Loss: 0.23515599966049194
train-epoch-step: 67-570 -- Loss: 0.15827959775924683
train-epoch-step: 67-571 -- Loss: 0.208835169672966
train-epoch-step: 67-572 -- Loss: 0.22271828353405
train-epoch-step: 67-573 -- Loss: 0.19172480702400208
train-epoch-step: 67-574 -- Loss: 0.2360921949148178
train-epoch-step: 67-575 -- Loss: 0.29028865694999695
train-epoch-step: 67-576 -- Loss: 0.1132383719086647
train-epoch-step: 67-577 -- Loss: 0.15828293561935425
train-epoch-step: 67-578 -- Loss: 0.21113479137420654
train-epoch-step: 67-579 -- Loss: 0.1653120219707489
train-epoch-step: 67-580 -- Loss: 0.16468322277069092
train-epoch-step: 67-581 -- Loss: 0.13264837861061096
train-epoch-step: 67-582 -- Loss: 0.1970365345478058
train-epoch-step: 67-583 -- Loss: 0.20129850506782532
train-epoch-step: 67-584 -- Loss: 0.15998654067516327
train-epoch-step: 67-585 -- Loss: 0.18771493434906006
train-epoch-step: 67-586 -- Loss: 0.2437099665403366
train-epoch-step: 67-587 -- Loss: 0.15858039259910583
train-epoch-step: 67-588 -- Loss: 0.12115393579006195
val-epoch-step: 67-589 -- Loss: 0.19832947850227356
val-epoch-step: 67-590 -- Loss: 0.14830122888088226
val-epoch-step: 67-591 -- Loss: 0.23639824986457825
val-epoch-step: 67-592 -- Loss: 0.17095616459846497
val-epoch-step: 67-593 -- Loss: 0.16934582591056824
val-epoch-step: 67-594 -- Loss: 0.4514837861061096
val-epoch-step: 67-595 -- Loss: 0.17940260469913483
val-epoch-step: 67-596 -- Loss: 0.20637601613998413
val-epoch-step: 67-597 -- Loss: 0.1688190996646881
val-epoch-step: 67-598 -- Loss: 0.14622679352760315
val-epoch-step: 67-599 -- Loss: 0.18503862619400024
val-epoch-step: 67-600 -- Loss: 0.17314448952674866
val-epoch-step: 67-601 -- Loss: 0.15195585787296295
val-epoch-step: 67-602 -- Loss: 0.13262681663036346
val-epoch-step: 67-603 -- Loss: 0.2168121337890625
val-epoch-step: 67-604 -- Loss: 0.1419680118560791
val-epoch-step: 67-605 -- Loss: 0.14473238587379456
val-epoch-step: 67-606 -- Loss: 0.24904434382915497
val-epoch-step: 67-607 -- Loss: 0.1263735145330429
val-epoch-step: 67-608 -- Loss: 0.24692758917808533
val-epoch-step: 67-609 -- Loss: 0.16174130141735077
val-epoch-step: 67-610 -- Loss: 0.17817871272563934
val-epoch-step: 67-611 -- Loss: 0.15134355425834656
val-epoch-step: 67-612 -- Loss: 0.4284507632255554
val-epoch-step: 67-613 -- Loss: 0.16876429319381714
val-epoch-step: 67-614 -- Loss: 0.1588834524154663
val-epoch-step: 67-615 -- Loss: 0.16783685982227325
val-epoch-step: 67-616 -- Loss: 0.15426383912563324
val-epoch-step: 67-617 -- Loss: 0.18979987502098083
val-epoch-step: 67-618 -- Loss: 0.18644866347312927
val-epoch-step: 67-619 -- Loss: 0.21206100285053253
val-epoch-step: 67-620 -- Loss: 0.13341540098190308
val-epoch-step: 67-621 -- Loss: 0.12133095413446426
val-epoch-step: 67-622 -- Loss: 0.14502370357513428
val-epoch-step: 67-623 -- Loss: 0.14568988978862762
val-epoch-step: 67-624 -- Loss: 0.1358804702758789
val-epoch-step: 67-625 -- Loss: 0.15092891454696655
val-epoch-step: 67-626 -- Loss: 0.1430034339427948
val-epoch-step: 67-627 -- Loss: 0.17677369713783264
val-epoch-step: 67-628 -- Loss: 0.7408571839332581
val-epoch-step: 67-629 -- Loss: 0.21092844009399414
val-epoch-step: 67-630 -- Loss: 0.3307819962501526
val-epoch-step: 67-631 -- Loss: 0.13611066341400146
val-epoch-step: 67-632 -- Loss: 0.20288652181625366
val-epoch-step: 67-633 -- Loss: 0.1523466557264328
val-epoch-step: 67-634 -- Loss: 0.14410395920276642
val-epoch-step: 67-635 -- Loss: 0.11282134056091309
val-epoch-step: 67-636 -- Loss: 0.18036136031150818
val-epoch-step: 67-637 -- Loss: 0.17634347081184387
val-epoch-step: 67-638 -- Loss: 0.14630205929279327
val-epoch-step: 67-639 -- Loss: 0.24929937720298767
val-epoch-step: 67-640 -- Loss: 0.24489174783229828
val-epoch-step: 67-641 -- Loss: 0.123997263610363
val-epoch-step: 67-642 -- Loss: 0.17274487018585205
val-epoch-step: 67-643 -- Loss: 0.20124273002147675
val-epoch-step: 67-644 -- Loss: 0.16648562252521515
val-epoch-step: 67-645 -- Loss: 0.21046538650989532
val-epoch-step: 67-646 -- Loss: 0.12932513654232025
val-epoch-step: 67-647 -- Loss: 0.12422753870487213
val-epoch-step: 67-648 -- Loss: 0.14974206686019897
val-epoch-step: 67-649 -- Loss: 0.2018527239561081
val-epoch-step: 67-650 -- Loss: 0.2441226840019226
val-epoch-step: 67-651 -- Loss: 0.1414501667022705
val-epoch-step: 67-652 -- Loss: 0.1512807011604309
val-epoch-step: 67-653 -- Loss: 0.20040595531463623
val-epoch-step: 67-654 -- Loss: 0.10803992301225662
Epoch: 67 -- Train Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 68-0 -- Loss: 0.21381813287734985
train-epoch-step: 68-1 -- Loss: 0.14210458099842072
train-epoch-step: 68-2 -- Loss: 0.18896177411079407
train-epoch-step: 68-3 -- Loss: 0.13429227471351624
train-epoch-step: 68-4 -- Loss: 0.15239956974983215
train-epoch-step: 68-5 -- Loss: 0.1696699857711792
train-epoch-step: 68-6 -- Loss: 0.21393007040023804
train-epoch-step: 68-7 -- Loss: 0.16142459213733673
train-epoch-step: 68-8 -- Loss: 0.16747167706489563
train-epoch-step: 68-9 -- Loss: 0.22093981504440308
train-epoch-step: 68-10 -- Loss: 0.1896105706691742
train-epoch-step: 68-11 -- Loss: 0.16961899399757385
train-epoch-step: 68-12 -- Loss: 0.14364881813526154
train-epoch-step: 68-13 -- Loss: 0.17001429200172424
train-epoch-step: 68-14 -- Loss: 0.1540464609861374
train-epoch-step: 68-15 -- Loss: 0.15484224259853363
train-epoch-step: 68-16 -- Loss: 0.1718977689743042
train-epoch-step: 68-17 -- Loss: 0.2126382738351822
train-epoch-step: 68-18 -- Loss: 0.18439346551895142
train-epoch-step: 68-19 -- Loss: 0.12626248598098755
train-epoch-step: 68-20 -- Loss: 0.20884519815444946
train-epoch-step: 68-21 -- Loss: 0.242079958319664
train-epoch-step: 68-22 -- Loss: 0.1394764930009842
train-epoch-step: 68-23 -- Loss: 0.1378399133682251
train-epoch-step: 68-24 -- Loss: 0.12699376046657562
train-epoch-step: 68-25 -- Loss: 0.2391374558210373
train-epoch-step: 68-26 -- Loss: 0.1871444582939148
train-epoch-step: 68-27 -- Loss: 0.21827435493469238
train-epoch-step: 68-28 -- Loss: 0.12055309116840363
train-epoch-step: 68-29 -- Loss: 0.23477189242839813
train-epoch-step: 68-30 -- Loss: 0.10708935558795929
train-epoch-step: 68-31 -- Loss: 0.1284000128507614
train-epoch-step: 68-32 -- Loss: 0.1629514843225479
train-epoch-step: 68-33 -- Loss: 0.2743196487426758
train-epoch-step: 68-34 -- Loss: 0.1617617905139923
train-epoch-step: 68-35 -- Loss: 0.23432029783725739
train-epoch-step: 68-36 -- Loss: 0.13207581639289856
train-epoch-step: 68-37 -- Loss: 0.13208124041557312
train-epoch-step: 68-38 -- Loss: 0.16916632652282715
train-epoch-step: 68-39 -- Loss: 0.20818254351615906
train-epoch-step: 68-40 -- Loss: 0.1853182315826416
train-epoch-step: 68-41 -- Loss: 0.21006400883197784
train-epoch-step: 68-42 -- Loss: 0.14473482966423035
train-epoch-step: 68-43 -- Loss: 0.25339439511299133
train-epoch-step: 68-44 -- Loss: 0.11901852488517761
train-epoch-step: 68-45 -- Loss: 0.10976256430149078
train-epoch-step: 68-46 -- Loss: 0.16146942973136902
train-epoch-step: 68-47 -- Loss: 0.18930812180042267
train-epoch-step: 68-48 -- Loss: 0.15180671215057373
train-epoch-step: 68-49 -- Loss: 0.21797588467597961
train-epoch-step: 68-50 -- Loss: 0.1111748218536377
train-epoch-step: 68-51 -- Loss: 0.16486027836799622
train-epoch-step: 68-52 -- Loss: 0.1543283611536026
train-epoch-step: 68-53 -- Loss: 0.19977118074893951
train-epoch-step: 68-54 -- Loss: 0.27593037486076355
train-epoch-step: 68-55 -- Loss: 0.15696915984153748
train-epoch-step: 68-56 -- Loss: 0.17237302660942078
train-epoch-step: 68-57 -- Loss: 0.2235649824142456
train-epoch-step: 68-58 -- Loss: 0.28054162859916687
train-epoch-step: 68-59 -- Loss: 0.2238835245370865
train-epoch-step: 68-60 -- Loss: 0.12714749574661255
train-epoch-step: 68-61 -- Loss: 0.19104033708572388
train-epoch-step: 68-62 -- Loss: 0.1776999682188034
train-epoch-step: 68-63 -- Loss: 0.12943580746650696
train-epoch-step: 68-64 -- Loss: 0.13688309490680695
train-epoch-step: 68-65 -- Loss: 0.16754472255706787
train-epoch-step: 68-66 -- Loss: 0.10633007436990738
train-epoch-step: 68-67 -- Loss: 0.11732254177331924
train-epoch-step: 68-68 -- Loss: 0.20485523343086243
train-epoch-step: 68-69 -- Loss: 0.11875320971012115
train-epoch-step: 68-70 -- Loss: 0.21272532641887665
train-epoch-step: 68-71 -- Loss: 0.24989375472068787
train-epoch-step: 68-72 -- Loss: 0.16696393489837646
train-epoch-step: 68-73 -- Loss: 0.20295962691307068
train-epoch-step: 68-74 -- Loss: 0.09172701835632324
train-epoch-step: 68-75 -- Loss: 0.1222495287656784
train-epoch-step: 68-76 -- Loss: 0.13949841260910034
train-epoch-step: 68-77 -- Loss: 0.22222670912742615
train-epoch-step: 68-78 -- Loss: 0.2488442063331604
train-epoch-step: 68-79 -- Loss: 0.1822129786014557
train-epoch-step: 68-80 -- Loss: 0.24225328862667084
train-epoch-step: 68-81 -- Loss: 0.1201341524720192
train-epoch-step: 68-82 -- Loss: 0.23908492922782898
train-epoch-step: 68-83 -- Loss: 0.16901662945747375
train-epoch-step: 68-84 -- Loss: 0.1810457706451416
train-epoch-step: 68-85 -- Loss: 0.1691552996635437
train-epoch-step: 68-86 -- Loss: 0.11879947781562805
train-epoch-step: 68-87 -- Loss: 0.19873782992362976
train-epoch-step: 68-88 -- Loss: 0.13327200710773468
train-epoch-step: 68-89 -- Loss: 0.18098384141921997
train-epoch-step: 68-90 -- Loss: 0.1831435114145279
train-epoch-step: 68-91 -- Loss: 0.23876947164535522
train-epoch-step: 68-92 -- Loss: 0.14910341799259186
train-epoch-step: 68-93 -- Loss: 0.1675332486629486
train-epoch-step: 68-94 -- Loss: 0.21116861701011658
train-epoch-step: 68-95 -- Loss: 0.18775077164173126
train-epoch-step: 68-96 -- Loss: 0.2062249779701233
train-epoch-step: 68-97 -- Loss: 0.16708815097808838
train-epoch-step: 68-98 -- Loss: 0.15028133988380432
train-epoch-step: 68-99 -- Loss: 0.1765931397676468
train-epoch-step: 68-100 -- Loss: 0.1816578507423401
train-epoch-step: 68-101 -- Loss: 0.2478581964969635
train-epoch-step: 68-102 -- Loss: 0.2096230685710907
train-epoch-step: 68-103 -- Loss: 0.18098706007003784
train-epoch-step: 68-104 -- Loss: 0.1428566873073578
train-epoch-step: 68-105 -- Loss: 0.25941169261932373
train-epoch-step: 68-106 -- Loss: 0.17075486481189728
train-epoch-step: 68-107 -- Loss: 0.18591167032718658
train-epoch-step: 68-108 -- Loss: 0.1834927499294281
train-epoch-step: 68-109 -- Loss: 0.14324265718460083
train-epoch-step: 68-110 -- Loss: 0.1751084178686142
train-epoch-step: 68-111 -- Loss: 0.17124676704406738
train-epoch-step: 68-112 -- Loss: 0.16389921307563782
train-epoch-step: 68-113 -- Loss: 0.15368251502513885
train-epoch-step: 68-114 -- Loss: 0.1903519332408905
train-epoch-step: 68-115 -- Loss: 0.15628120303153992
train-epoch-step: 68-116 -- Loss: 0.13429385423660278
train-epoch-step: 68-117 -- Loss: 0.12275735288858414
train-epoch-step: 68-118 -- Loss: 0.18469788134098053
train-epoch-step: 68-119 -- Loss: 0.14460334181785583
train-epoch-step: 68-120 -- Loss: 0.2416478395462036
train-epoch-step: 68-121 -- Loss: 0.22611360251903534
train-epoch-step: 68-122 -- Loss: 0.202201709151268
train-epoch-step: 68-123 -- Loss: 0.1967044621706009
train-epoch-step: 68-124 -- Loss: 0.12439949810504913
train-epoch-step: 68-125 -- Loss: 0.14966981112957
train-epoch-step: 68-126 -- Loss: 0.23040646314620972
train-epoch-step: 68-127 -- Loss: 0.16341128945350647
train-epoch-step: 68-128 -- Loss: 0.1660500466823578
train-epoch-step: 68-129 -- Loss: 0.13381561636924744
train-epoch-step: 68-130 -- Loss: 0.188028946518898
train-epoch-step: 68-131 -- Loss: 0.13260972499847412
train-epoch-step: 68-132 -- Loss: 0.18413491547107697
train-epoch-step: 68-133 -- Loss: 0.11330481618642807
train-epoch-step: 68-134 -- Loss: 0.18730750679969788
train-epoch-step: 68-135 -- Loss: 0.12845802307128906
train-epoch-step: 68-136 -- Loss: 0.12360621243715286
train-epoch-step: 68-137 -- Loss: 0.24010221660137177
train-epoch-step: 68-138 -- Loss: 0.25212106108665466
train-epoch-step: 68-139 -- Loss: 0.12865807116031647
train-epoch-step: 68-140 -- Loss: 0.1968657225370407
train-epoch-step: 68-141 -- Loss: 0.2191726118326187
train-epoch-step: 68-142 -- Loss: 0.19518716633319855
train-epoch-step: 68-143 -- Loss: 0.16278301179409027
train-epoch-step: 68-144 -- Loss: 0.17923153936862946
train-epoch-step: 68-145 -- Loss: 0.1434510499238968
train-epoch-step: 68-146 -- Loss: 0.17418664693832397
train-epoch-step: 68-147 -- Loss: 0.15974484384059906
train-epoch-step: 68-148 -- Loss: 0.15998168289661407
train-epoch-step: 68-149 -- Loss: 0.11416633427143097
train-epoch-step: 68-150 -- Loss: 0.17776288092136383
train-epoch-step: 68-151 -- Loss: 0.18283523619174957
train-epoch-step: 68-152 -- Loss: 0.18351183831691742
train-epoch-step: 68-153 -- Loss: 0.252235472202301
train-epoch-step: 68-154 -- Loss: 0.12418525665998459
train-epoch-step: 68-155 -- Loss: 0.13375981152057648
train-epoch-step: 68-156 -- Loss: 0.12818360328674316
train-epoch-step: 68-157 -- Loss: 0.17472852766513824
train-epoch-step: 68-158 -- Loss: 0.159590482711792
train-epoch-step: 68-159 -- Loss: 0.1753522753715515
train-epoch-step: 68-160 -- Loss: 0.20738378167152405
train-epoch-step: 68-161 -- Loss: 0.19519875943660736
train-epoch-step: 68-162 -- Loss: 0.2097814977169037
train-epoch-step: 68-163 -- Loss: 0.18228843808174133
train-epoch-step: 68-164 -- Loss: 0.18698634207248688
train-epoch-step: 68-165 -- Loss: 0.16129803657531738
train-epoch-step: 68-166 -- Loss: 0.11890112608671188
train-epoch-step: 68-167 -- Loss: 0.11822855472564697
train-epoch-step: 68-168 -- Loss: 0.19759297370910645
train-epoch-step: 68-169 -- Loss: 0.13361890614032745
train-epoch-step: 68-170 -- Loss: 0.1939743310213089
train-epoch-step: 68-171 -- Loss: 0.1394929587841034
train-epoch-step: 68-172 -- Loss: 0.2520807981491089
train-epoch-step: 68-173 -- Loss: 0.13466961681842804
train-epoch-step: 68-174 -- Loss: 0.2387446016073227
train-epoch-step: 68-175 -- Loss: 0.176908478140831
train-epoch-step: 68-176 -- Loss: 0.129267618060112
train-epoch-step: 68-177 -- Loss: 0.18005481362342834
train-epoch-step: 68-178 -- Loss: 0.1755484640598297
train-epoch-step: 68-179 -- Loss: 0.14445625245571136
train-epoch-step: 68-180 -- Loss: 0.1476011574268341
train-epoch-step: 68-181 -- Loss: 0.16192685067653656
train-epoch-step: 68-182 -- Loss: 0.17774321138858795
train-epoch-step: 68-183 -- Loss: 0.2662131190299988
train-epoch-step: 68-184 -- Loss: 0.13594144582748413
train-epoch-step: 68-185 -- Loss: 0.13580602407455444
train-epoch-step: 68-186 -- Loss: 0.1837281435728073
train-epoch-step: 68-187 -- Loss: 0.21342453360557556
train-epoch-step: 68-188 -- Loss: 0.16872049868106842
train-epoch-step: 68-189 -- Loss: 0.1061709076166153
train-epoch-step: 68-190 -- Loss: 0.17747080326080322
train-epoch-step: 68-191 -- Loss: 0.15242649614810944
train-epoch-step: 68-192 -- Loss: 0.21925503015518188
train-epoch-step: 68-193 -- Loss: 0.25105714797973633
train-epoch-step: 68-194 -- Loss: 0.1784900724887848
train-epoch-step: 68-195 -- Loss: 0.16352702677249908
train-epoch-step: 68-196 -- Loss: 0.17601285874843597
train-epoch-step: 68-197 -- Loss: 0.12374799698591232
train-epoch-step: 68-198 -- Loss: 0.12265455722808838
train-epoch-step: 68-199 -- Loss: 0.14666976034641266
train-epoch-step: 68-200 -- Loss: 0.1232386976480484
train-epoch-step: 68-201 -- Loss: 0.19487914443016052
train-epoch-step: 68-202 -- Loss: 0.13453873991966248
train-epoch-step: 68-203 -- Loss: 0.17046627402305603
train-epoch-step: 68-204 -- Loss: 0.13892875611782074
train-epoch-step: 68-205 -- Loss: 0.18510650098323822
train-epoch-step: 68-206 -- Loss: 0.19747304916381836
train-epoch-step: 68-207 -- Loss: 0.13253745436668396
train-epoch-step: 68-208 -- Loss: 0.17692208290100098
train-epoch-step: 68-209 -- Loss: 0.1387348771095276
train-epoch-step: 68-210 -- Loss: 0.12711507081985474
train-epoch-step: 68-211 -- Loss: 0.19867904484272003
train-epoch-step: 68-212 -- Loss: 0.1952621340751648
train-epoch-step: 68-213 -- Loss: 0.12352432310581207
train-epoch-step: 68-214 -- Loss: 0.1449645608663559
train-epoch-step: 68-215 -- Loss: 0.12800991535186768
train-epoch-step: 68-216 -- Loss: 0.195247620344162
train-epoch-step: 68-217 -- Loss: 0.20882900059223175
train-epoch-step: 68-218 -- Loss: 0.15332302451133728
train-epoch-step: 68-219 -- Loss: 0.35164326429367065
train-epoch-step: 68-220 -- Loss: 0.12718069553375244
train-epoch-step: 68-221 -- Loss: 0.20466437935829163
train-epoch-step: 68-222 -- Loss: 0.1230117529630661
train-epoch-step: 68-223 -- Loss: 0.18569213151931763
train-epoch-step: 68-224 -- Loss: 0.19384066760540009
train-epoch-step: 68-225 -- Loss: 0.32106977701187134
train-epoch-step: 68-226 -- Loss: 0.19637909531593323
train-epoch-step: 68-227 -- Loss: 0.2200479954481125
train-epoch-step: 68-228 -- Loss: 0.17176716029644012
train-epoch-step: 68-229 -- Loss: 0.1700907200574875
train-epoch-step: 68-230 -- Loss: 0.1627356857061386
train-epoch-step: 68-231 -- Loss: 0.19658002257347107
train-epoch-step: 68-232 -- Loss: 0.20354479551315308
train-epoch-step: 68-233 -- Loss: 0.08320274949073792
train-epoch-step: 68-234 -- Loss: 0.177892804145813
train-epoch-step: 68-235 -- Loss: 0.16022346913814545
train-epoch-step: 68-236 -- Loss: 0.17997384071350098
train-epoch-step: 68-237 -- Loss: 0.24275031685829163
train-epoch-step: 68-238 -- Loss: 0.158502459526062
train-epoch-step: 68-239 -- Loss: 0.1267174929380417
train-epoch-step: 68-240 -- Loss: 0.2664922773838043
train-epoch-step: 68-241 -- Loss: 0.15321438014507294
train-epoch-step: 68-242 -- Loss: 0.22288917005062103
train-epoch-step: 68-243 -- Loss: 0.2636311650276184
train-epoch-step: 68-244 -- Loss: 0.20784081518650055
train-epoch-step: 68-245 -- Loss: 0.20751501619815826
train-epoch-step: 68-246 -- Loss: 0.2225019633769989
train-epoch-step: 68-247 -- Loss: 0.2189558446407318
train-epoch-step: 68-248 -- Loss: 0.18398022651672363
train-epoch-step: 68-249 -- Loss: 0.1396304965019226
train-epoch-step: 68-250 -- Loss: 0.21070221066474915
train-epoch-step: 68-251 -- Loss: 0.11184477806091309
train-epoch-step: 68-252 -- Loss: 0.1939360499382019
train-epoch-step: 68-253 -- Loss: 0.13778793811798096
train-epoch-step: 68-254 -- Loss: 0.21288618445396423
train-epoch-step: 68-255 -- Loss: 0.14692422747612
train-epoch-step: 68-256 -- Loss: 0.14493323862552643
train-epoch-step: 68-257 -- Loss: 0.18696725368499756
train-epoch-step: 68-258 -- Loss: 0.1480986773967743
train-epoch-step: 68-259 -- Loss: 0.10919960588216782
train-epoch-step: 68-260 -- Loss: 0.20211873948574066
train-epoch-step: 68-261 -- Loss: 0.1721826195716858
train-epoch-step: 68-262 -- Loss: 0.29841041564941406
train-epoch-step: 68-263 -- Loss: 0.19588807225227356
train-epoch-step: 68-264 -- Loss: 0.17634612321853638
train-epoch-step: 68-265 -- Loss: 0.12688404321670532
train-epoch-step: 68-266 -- Loss: 0.1524895280599594
train-epoch-step: 68-267 -- Loss: 0.12965701520442963
train-epoch-step: 68-268 -- Loss: 0.11658389121294022
train-epoch-step: 68-269 -- Loss: 0.18915832042694092
train-epoch-step: 68-270 -- Loss: 0.1094207763671875
train-epoch-step: 68-271 -- Loss: 0.1433314085006714
train-epoch-step: 68-272 -- Loss: 0.11423790454864502
train-epoch-step: 68-273 -- Loss: 0.12505745887756348
train-epoch-step: 68-274 -- Loss: 0.20380350947380066
train-epoch-step: 68-275 -- Loss: 0.18765659630298615
train-epoch-step: 68-276 -- Loss: 0.15271461009979248
train-epoch-step: 68-277 -- Loss: 0.15300506353378296
train-epoch-step: 68-278 -- Loss: 0.13488852977752686
train-epoch-step: 68-279 -- Loss: 0.1335233598947525
train-epoch-step: 68-280 -- Loss: 0.21493704617023468
train-epoch-step: 68-281 -- Loss: 0.17095696926116943
train-epoch-step: 68-282 -- Loss: 0.13814343512058258
train-epoch-step: 68-283 -- Loss: 0.11206819117069244
train-epoch-step: 68-284 -- Loss: 0.13007183372974396
train-epoch-step: 68-285 -- Loss: 0.19007940590381622
train-epoch-step: 68-286 -- Loss: 0.15087562799453735
train-epoch-step: 68-287 -- Loss: 0.19830387830734253
train-epoch-step: 68-288 -- Loss: 0.09151361882686615
train-epoch-step: 68-289 -- Loss: 0.11966273188591003
train-epoch-step: 68-290 -- Loss: 0.1784767359495163
train-epoch-step: 68-291 -- Loss: 0.11373892426490784
train-epoch-step: 68-292 -- Loss: 0.1541360318660736
train-epoch-step: 68-293 -- Loss: 0.13663947582244873
train-epoch-step: 68-294 -- Loss: 0.157283216714859
train-epoch-step: 68-295 -- Loss: 0.26925262808799744
train-epoch-step: 68-296 -- Loss: 0.16049593687057495
train-epoch-step: 68-297 -- Loss: 0.1693505048751831
train-epoch-step: 68-298 -- Loss: 0.2322184443473816
train-epoch-step: 68-299 -- Loss: 0.14248307049274445
train-epoch-step: 68-300 -- Loss: 0.15715858340263367
train-epoch-step: 68-301 -- Loss: 0.16977007687091827
train-epoch-step: 68-302 -- Loss: 0.20932695269584656
train-epoch-step: 68-303 -- Loss: 0.19772018492221832
train-epoch-step: 68-304 -- Loss: 0.12593317031860352
train-epoch-step: 68-305 -- Loss: 0.14094044268131256
train-epoch-step: 68-306 -- Loss: 0.2106269896030426
train-epoch-step: 68-307 -- Loss: 0.16297757625579834
train-epoch-step: 68-308 -- Loss: 0.21196189522743225
train-epoch-step: 68-309 -- Loss: 0.15013942122459412
train-epoch-step: 68-310 -- Loss: 0.15767177939414978
train-epoch-step: 68-311 -- Loss: 0.1528758853673935
train-epoch-step: 68-312 -- Loss: 0.20216210186481476
train-epoch-step: 68-313 -- Loss: 0.09750322997570038
train-epoch-step: 68-314 -- Loss: 0.1817176342010498
train-epoch-step: 68-315 -- Loss: 0.166777104139328
train-epoch-step: 68-316 -- Loss: 0.15216925740242004
train-epoch-step: 68-317 -- Loss: 0.1367889940738678
train-epoch-step: 68-318 -- Loss: 0.15397055447101593
train-epoch-step: 68-319 -- Loss: 0.15899595618247986
train-epoch-step: 68-320 -- Loss: 0.11583789438009262
train-epoch-step: 68-321 -- Loss: 0.13075697422027588
train-epoch-step: 68-322 -- Loss: 0.20936298370361328
train-epoch-step: 68-323 -- Loss: 0.15403598546981812
train-epoch-step: 68-324 -- Loss: 0.25324711203575134
train-epoch-step: 68-325 -- Loss: 0.15119977295398712
train-epoch-step: 68-326 -- Loss: 0.16541779041290283
train-epoch-step: 68-327 -- Loss: 0.19753918051719666
train-epoch-step: 68-328 -- Loss: 0.18679289519786835
train-epoch-step: 68-329 -- Loss: 0.33275991678237915
train-epoch-step: 68-330 -- Loss: 0.3522098958492279
train-epoch-step: 68-331 -- Loss: 0.20322003960609436
train-epoch-step: 68-332 -- Loss: 0.09765487164258957
train-epoch-step: 68-333 -- Loss: 0.17663145065307617
train-epoch-step: 68-334 -- Loss: 0.14832134544849396
train-epoch-step: 68-335 -- Loss: 0.17427657544612885
train-epoch-step: 68-336 -- Loss: 0.14296391606330872
train-epoch-step: 68-337 -- Loss: 0.19448599219322205
train-epoch-step: 68-338 -- Loss: 0.15459929406642914
train-epoch-step: 68-339 -- Loss: 0.1388920247554779
train-epoch-step: 68-340 -- Loss: 0.19168436527252197
train-epoch-step: 68-341 -- Loss: 0.1362532526254654
train-epoch-step: 68-342 -- Loss: 0.16089338064193726
train-epoch-step: 68-343 -- Loss: 0.15102994441986084
train-epoch-step: 68-344 -- Loss: 0.16203424334526062
train-epoch-step: 68-345 -- Loss: 0.1248137354850769
train-epoch-step: 68-346 -- Loss: 0.1992035210132599
train-epoch-step: 68-347 -- Loss: 0.1469951719045639
train-epoch-step: 68-348 -- Loss: 0.1987934708595276
train-epoch-step: 68-349 -- Loss: 0.19114810228347778
train-epoch-step: 68-350 -- Loss: 0.24482528865337372
train-epoch-step: 68-351 -- Loss: 0.1887388676404953
train-epoch-step: 68-352 -- Loss: 0.1173381581902504
train-epoch-step: 68-353 -- Loss: 0.1909506916999817
train-epoch-step: 68-354 -- Loss: 0.2731489837169647
train-epoch-step: 68-355 -- Loss: 0.11659259349107742
train-epoch-step: 68-356 -- Loss: 0.11374117434024811
train-epoch-step: 68-357 -- Loss: 0.18182015419006348
train-epoch-step: 68-358 -- Loss: 0.17887452244758606
train-epoch-step: 68-359 -- Loss: 0.13632339239120483
train-epoch-step: 68-360 -- Loss: 0.12436734139919281
train-epoch-step: 68-361 -- Loss: 0.22752103209495544
train-epoch-step: 68-362 -- Loss: 0.1658342182636261
train-epoch-step: 68-363 -- Loss: 0.10632327198982239
train-epoch-step: 68-364 -- Loss: 0.17506742477416992
train-epoch-step: 68-365 -- Loss: 0.17186729609966278
train-epoch-step: 68-366 -- Loss: 0.18905684351921082
train-epoch-step: 68-367 -- Loss: 0.22891826927661896
train-epoch-step: 68-368 -- Loss: 0.19851069152355194
train-epoch-step: 68-369 -- Loss: 0.26979511976242065
train-epoch-step: 68-370 -- Loss: 0.120365671813488
train-epoch-step: 68-371 -- Loss: 0.11911585181951523
train-epoch-step: 68-372 -- Loss: 0.14522916078567505
train-epoch-step: 68-373 -- Loss: 0.19348019361495972
train-epoch-step: 68-374 -- Loss: 0.14796146750450134
train-epoch-step: 68-375 -- Loss: 0.26216429471969604
train-epoch-step: 68-376 -- Loss: 0.14943739771842957
train-epoch-step: 68-377 -- Loss: 0.2244565486907959
train-epoch-step: 68-378 -- Loss: 0.19108325242996216
train-epoch-step: 68-379 -- Loss: 0.11741997301578522
train-epoch-step: 68-380 -- Loss: 0.0891023650765419
train-epoch-step: 68-381 -- Loss: 0.23502090573310852
train-epoch-step: 68-382 -- Loss: 0.22274719178676605
train-epoch-step: 68-383 -- Loss: 0.1697293072938919
train-epoch-step: 68-384 -- Loss: 0.21309101581573486
train-epoch-step: 68-385 -- Loss: 0.18982157111167908
train-epoch-step: 68-386 -- Loss: 0.17814472317695618
train-epoch-step: 68-387 -- Loss: 0.19461403787136078
train-epoch-step: 68-388 -- Loss: 0.17678198218345642
train-epoch-step: 68-389 -- Loss: 0.16131776571273804
train-epoch-step: 68-390 -- Loss: 0.13979902863502502
train-epoch-step: 68-391 -- Loss: 0.14268389344215393
train-epoch-step: 68-392 -- Loss: 0.183273583650589
train-epoch-step: 68-393 -- Loss: 0.14914211630821228
train-epoch-step: 68-394 -- Loss: 0.1918984055519104
train-epoch-step: 68-395 -- Loss: 0.15448790788650513
train-epoch-step: 68-396 -- Loss: 0.12124061584472656
train-epoch-step: 68-397 -- Loss: 0.1235671117901802
train-epoch-step: 68-398 -- Loss: 0.19029322266578674
train-epoch-step: 68-399 -- Loss: 0.1701621413230896
train-epoch-step: 68-400 -- Loss: 0.27179375290870667
train-epoch-step: 68-401 -- Loss: 0.11394977569580078
train-epoch-step: 68-402 -- Loss: 0.24858365952968597
train-epoch-step: 68-403 -- Loss: 0.14904652535915375
train-epoch-step: 68-404 -- Loss: 0.13343723118305206
train-epoch-step: 68-405 -- Loss: 0.13877449929714203
train-epoch-step: 68-406 -- Loss: 0.16067300736904144
train-epoch-step: 68-407 -- Loss: 0.10758845508098602
train-epoch-step: 68-408 -- Loss: 0.15842805802822113
train-epoch-step: 68-409 -- Loss: 0.16239038109779358
train-epoch-step: 68-410 -- Loss: 0.16875094175338745
train-epoch-step: 68-411 -- Loss: 0.19000862538814545
train-epoch-step: 68-412 -- Loss: 0.12804725766181946
train-epoch-step: 68-413 -- Loss: 0.1433764398097992
train-epoch-step: 68-414 -- Loss: 0.12831799685955048
train-epoch-step: 68-415 -- Loss: 0.12872985005378723
train-epoch-step: 68-416 -- Loss: 0.25723594427108765
train-epoch-step: 68-417 -- Loss: 0.18346162140369415
train-epoch-step: 68-418 -- Loss: 0.21821165084838867
train-epoch-step: 68-419 -- Loss: 0.1651439070701599
train-epoch-step: 68-420 -- Loss: 0.1462416648864746
train-epoch-step: 68-421 -- Loss: 0.17286133766174316
train-epoch-step: 68-422 -- Loss: 0.14275392889976501
train-epoch-step: 68-423 -- Loss: 0.17196014523506165
train-epoch-step: 68-424 -- Loss: 0.1321917474269867
train-epoch-step: 68-425 -- Loss: 0.17585012316703796
train-epoch-step: 68-426 -- Loss: 0.15820978581905365
train-epoch-step: 68-427 -- Loss: 0.11557581275701523
train-epoch-step: 68-428 -- Loss: 0.20033565163612366
train-epoch-step: 68-429 -- Loss: 0.1723913699388504
train-epoch-step: 68-430 -- Loss: 0.13459016382694244
train-epoch-step: 68-431 -- Loss: 0.15882273018360138
train-epoch-step: 68-432 -- Loss: 0.2307508885860443
train-epoch-step: 68-433 -- Loss: 0.13156570494174957
train-epoch-step: 68-434 -- Loss: 0.1298300325870514
train-epoch-step: 68-435 -- Loss: 0.15030981600284576
train-epoch-step: 68-436 -- Loss: 0.14690913259983063
train-epoch-step: 68-437 -- Loss: 0.12860654294490814
train-epoch-step: 68-438 -- Loss: 0.1624135822057724
train-epoch-step: 68-439 -- Loss: 0.25044211745262146
train-epoch-step: 68-440 -- Loss: 0.12651289999485016
train-epoch-step: 68-441 -- Loss: 0.19474086165428162
train-epoch-step: 68-442 -- Loss: 0.16822677850723267
train-epoch-step: 68-443 -- Loss: 0.1463192105293274
train-epoch-step: 68-444 -- Loss: 0.16929902136325836
train-epoch-step: 68-445 -- Loss: 0.1733502745628357
train-epoch-step: 68-446 -- Loss: 0.1467970311641693
train-epoch-step: 68-447 -- Loss: 0.18533381819725037
train-epoch-step: 68-448 -- Loss: 0.21512678265571594
train-epoch-step: 68-449 -- Loss: 0.1832270324230194
train-epoch-step: 68-450 -- Loss: 0.17467118799686432
train-epoch-step: 68-451 -- Loss: 0.13695038855075836
train-epoch-step: 68-452 -- Loss: 0.12443044036626816
train-epoch-step: 68-453 -- Loss: 0.08632716536521912
train-epoch-step: 68-454 -- Loss: 0.24570110440254211
train-epoch-step: 68-455 -- Loss: 0.11760297417640686
train-epoch-step: 68-456 -- Loss: 0.1123272180557251
train-epoch-step: 68-457 -- Loss: 0.20936544239521027
train-epoch-step: 68-458 -- Loss: 0.1383352279663086
train-epoch-step: 68-459 -- Loss: 0.20516575872898102
train-epoch-step: 68-460 -- Loss: 0.12046557664871216
train-epoch-step: 68-461 -- Loss: 0.13185031712055206
train-epoch-step: 68-462 -- Loss: 0.14975330233573914
train-epoch-step: 68-463 -- Loss: 0.13191412389278412
train-epoch-step: 68-464 -- Loss: 0.1552274227142334
train-epoch-step: 68-465 -- Loss: 0.2341424822807312
train-epoch-step: 68-466 -- Loss: 0.19894254207611084
train-epoch-step: 68-467 -- Loss: 0.11177816987037659
train-epoch-step: 68-468 -- Loss: 0.16066992282867432
train-epoch-step: 68-469 -- Loss: 0.20215079188346863
train-epoch-step: 68-470 -- Loss: 0.16161035001277924
train-epoch-step: 68-471 -- Loss: 0.15300482511520386
train-epoch-step: 68-472 -- Loss: 0.15463629364967346
train-epoch-step: 68-473 -- Loss: 0.14435376226902008
train-epoch-step: 68-474 -- Loss: 0.11551522463560104
train-epoch-step: 68-475 -- Loss: 0.10747676342725754
train-epoch-step: 68-476 -- Loss: 0.19604234397411346
train-epoch-step: 68-477 -- Loss: 0.19572694599628448
train-epoch-step: 68-478 -- Loss: 0.18191902339458466
train-epoch-step: 68-479 -- Loss: 0.13540035486221313
train-epoch-step: 68-480 -- Loss: 0.18223042786121368
train-epoch-step: 68-481 -- Loss: 0.2732153534889221
train-epoch-step: 68-482 -- Loss: 0.2442135512828827
train-epoch-step: 68-483 -- Loss: 0.17650693655014038
train-epoch-step: 68-484 -- Loss: 0.2033645510673523
train-epoch-step: 68-485 -- Loss: 0.12706869840621948
train-epoch-step: 68-486 -- Loss: 0.22459308803081512
train-epoch-step: 68-487 -- Loss: 0.22409141063690186
train-epoch-step: 68-488 -- Loss: 0.18544599413871765
train-epoch-step: 68-489 -- Loss: 0.21269696950912476
train-epoch-step: 68-490 -- Loss: 0.1337519735097885
train-epoch-step: 68-491 -- Loss: 0.13433948159217834
train-epoch-step: 68-492 -- Loss: 0.12418416142463684
train-epoch-step: 68-493 -- Loss: 0.18681712448596954
train-epoch-step: 68-494 -- Loss: 0.19288256764411926
train-epoch-step: 68-495 -- Loss: 0.19326788187026978
train-epoch-step: 68-496 -- Loss: 0.13929182291030884
train-epoch-step: 68-497 -- Loss: 0.17469292879104614
train-epoch-step: 68-498 -- Loss: 0.14227542281150818
train-epoch-step: 68-499 -- Loss: 0.1630808413028717
train-epoch-step: 68-500 -- Loss: 0.14856912195682526
train-epoch-step: 68-501 -- Loss: 0.20822452008724213
train-epoch-step: 68-502 -- Loss: 0.15320318937301636
train-epoch-step: 68-503 -- Loss: 0.2057790756225586
train-epoch-step: 68-504 -- Loss: 0.11547508835792542
train-epoch-step: 68-505 -- Loss: 0.16734667122364044
train-epoch-step: 68-506 -- Loss: 0.11070739477872849
train-epoch-step: 68-507 -- Loss: 0.17065291106700897
train-epoch-step: 68-508 -- Loss: 0.1663023680448532
train-epoch-step: 68-509 -- Loss: 0.16282919049263
train-epoch-step: 68-510 -- Loss: 0.12089823931455612
train-epoch-step: 68-511 -- Loss: 0.21100158989429474
train-epoch-step: 68-512 -- Loss: 0.17030535638332367
train-epoch-step: 68-513 -- Loss: 0.1752985417842865
train-epoch-step: 68-514 -- Loss: 0.14340625703334808
train-epoch-step: 68-515 -- Loss: 0.1493026316165924
train-epoch-step: 68-516 -- Loss: 0.1676638275384903
train-epoch-step: 68-517 -- Loss: 0.16885000467300415
train-epoch-step: 68-518 -- Loss: 0.133247971534729
train-epoch-step: 68-519 -- Loss: 0.12959957122802734
train-epoch-step: 68-520 -- Loss: 0.17949987947940826
train-epoch-step: 68-521 -- Loss: 0.21971634030342102
train-epoch-step: 68-522 -- Loss: 0.1646818071603775
train-epoch-step: 68-523 -- Loss: 0.14858749508857727
train-epoch-step: 68-524 -- Loss: 0.1595514714717865
train-epoch-step: 68-525 -- Loss: 0.18482914566993713
train-epoch-step: 68-526 -- Loss: 0.12417013198137283
train-epoch-step: 68-527 -- Loss: 0.14716443419456482
train-epoch-step: 68-528 -- Loss: 0.15595875680446625
train-epoch-step: 68-529 -- Loss: 0.14660967886447906
train-epoch-step: 68-530 -- Loss: 0.16373322904109955
train-epoch-step: 68-531 -- Loss: 0.18829241394996643
train-epoch-step: 68-532 -- Loss: 0.16263219714164734
train-epoch-step: 68-533 -- Loss: 0.16608038544654846
train-epoch-step: 68-534 -- Loss: 0.12356400489807129
train-epoch-step: 68-535 -- Loss: 0.23971375823020935
train-epoch-step: 68-536 -- Loss: 0.15055713057518005
train-epoch-step: 68-537 -- Loss: 0.1426335573196411
train-epoch-step: 68-538 -- Loss: 0.09886913746595383
train-epoch-step: 68-539 -- Loss: 0.1751132309436798
train-epoch-step: 68-540 -- Loss: 0.13088276982307434
train-epoch-step: 68-541 -- Loss: 0.19935564696788788
train-epoch-step: 68-542 -- Loss: 0.21038010716438293
train-epoch-step: 68-543 -- Loss: 0.16163033246994019
train-epoch-step: 68-544 -- Loss: 0.21526294946670532
train-epoch-step: 68-545 -- Loss: 0.1841059923171997
train-epoch-step: 68-546 -- Loss: 0.19481261074543
train-epoch-step: 68-547 -- Loss: 0.17798152565956116
train-epoch-step: 68-548 -- Loss: 0.08873239904642105
train-epoch-step: 68-549 -- Loss: 0.14392291009426117
train-epoch-step: 68-550 -- Loss: 0.1917904019355774
train-epoch-step: 68-551 -- Loss: 0.14915831387043
train-epoch-step: 68-552 -- Loss: 0.11968151479959488
train-epoch-step: 68-553 -- Loss: 0.18191349506378174
train-epoch-step: 68-554 -- Loss: 0.18044911324977875
train-epoch-step: 68-555 -- Loss: 0.20331718027591705
train-epoch-step: 68-556 -- Loss: 0.14174899458885193
train-epoch-step: 68-557 -- Loss: 0.2192372977733612
train-epoch-step: 68-558 -- Loss: 0.22231313586235046
train-epoch-step: 68-559 -- Loss: 0.1348545253276825
train-epoch-step: 68-560 -- Loss: 0.2004932463169098
train-epoch-step: 68-561 -- Loss: 0.16983415186405182
train-epoch-step: 68-562 -- Loss: 0.15824683010578156
train-epoch-step: 68-563 -- Loss: 0.1727975308895111
train-epoch-step: 68-564 -- Loss: 0.09764441102743149
train-epoch-step: 68-565 -- Loss: 0.17640618979930878
train-epoch-step: 68-566 -- Loss: 0.14500969648361206
train-epoch-step: 68-567 -- Loss: 0.21145933866500854
train-epoch-step: 68-568 -- Loss: 0.15469786524772644
train-epoch-step: 68-569 -- Loss: 0.23098501563072205
train-epoch-step: 68-570 -- Loss: 0.1654166430234909
train-epoch-step: 68-571 -- Loss: 0.2054140567779541
train-epoch-step: 68-572 -- Loss: 0.2373048961162567
train-epoch-step: 68-573 -- Loss: 0.19098487496376038
train-epoch-step: 68-574 -- Loss: 0.22821994125843048
train-epoch-step: 68-575 -- Loss: 0.27770012617111206
train-epoch-step: 68-576 -- Loss: 0.11404001712799072
train-epoch-step: 68-577 -- Loss: 0.15753568708896637
train-epoch-step: 68-578 -- Loss: 0.20751334726810455
train-epoch-step: 68-579 -- Loss: 0.1566532403230667
train-epoch-step: 68-580 -- Loss: 0.1672545075416565
train-epoch-step: 68-581 -- Loss: 0.1359262317419052
train-epoch-step: 68-582 -- Loss: 0.2037803679704666
train-epoch-step: 68-583 -- Loss: 0.20502114295959473
train-epoch-step: 68-584 -- Loss: 0.15646424889564514
train-epoch-step: 68-585 -- Loss: 0.18622684478759766
train-epoch-step: 68-586 -- Loss: 0.248184472322464
train-epoch-step: 68-587 -- Loss: 0.15393173694610596
train-epoch-step: 68-588 -- Loss: 0.12177003175020218
val-epoch-step: 68-589 -- Loss: 0.22410011291503906
val-epoch-step: 68-590 -- Loss: 0.149588480591774
val-epoch-step: 68-591 -- Loss: 0.2250623106956482
val-epoch-step: 68-592 -- Loss: 0.17167975008487701
val-epoch-step: 68-593 -- Loss: 0.17530958354473114
val-epoch-step: 68-594 -- Loss: 0.3731725215911865
val-epoch-step: 68-595 -- Loss: 0.18669523298740387
val-epoch-step: 68-596 -- Loss: 0.18688371777534485
val-epoch-step: 68-597 -- Loss: 0.16546179354190826
val-epoch-step: 68-598 -- Loss: 0.14394648373126984
val-epoch-step: 68-599 -- Loss: 0.18525366485118866
val-epoch-step: 68-600 -- Loss: 0.16388443112373352
val-epoch-step: 68-601 -- Loss: 0.15519219636917114
val-epoch-step: 68-602 -- Loss: 0.1325705349445343
val-epoch-step: 68-603 -- Loss: 0.21869827806949615
val-epoch-step: 68-604 -- Loss: 0.14099806547164917
val-epoch-step: 68-605 -- Loss: 0.14203940331935883
val-epoch-step: 68-606 -- Loss: 0.24347513914108276
val-epoch-step: 68-607 -- Loss: 0.12042927742004395
val-epoch-step: 68-608 -- Loss: 0.2444864809513092
val-epoch-step: 68-609 -- Loss: 0.1603335291147232
val-epoch-step: 68-610 -- Loss: 0.1746351420879364
val-epoch-step: 68-611 -- Loss: 0.1481378674507141
val-epoch-step: 68-612 -- Loss: 0.4064238667488098
val-epoch-step: 68-613 -- Loss: 0.1669493019580841
val-epoch-step: 68-614 -- Loss: 0.17332670092582703
val-epoch-step: 68-615 -- Loss: 0.16966606676578522
val-epoch-step: 68-616 -- Loss: 0.1432161033153534
val-epoch-step: 68-617 -- Loss: 0.18683083355426788
val-epoch-step: 68-618 -- Loss: 0.16814595460891724
val-epoch-step: 68-619 -- Loss: 0.2087767869234085
val-epoch-step: 68-620 -- Loss: 0.13192011415958405
val-epoch-step: 68-621 -- Loss: 0.12744267284870148
val-epoch-step: 68-622 -- Loss: 0.14290016889572144
val-epoch-step: 68-623 -- Loss: 0.14366447925567627
val-epoch-step: 68-624 -- Loss: 0.13757732510566711
val-epoch-step: 68-625 -- Loss: 0.15519565343856812
val-epoch-step: 68-626 -- Loss: 0.14286500215530396
val-epoch-step: 68-627 -- Loss: 0.17608213424682617
val-epoch-step: 68-628 -- Loss: 0.6097699403762817
val-epoch-step: 68-629 -- Loss: 0.19764107465744019
val-epoch-step: 68-630 -- Loss: 0.3311275243759155
val-epoch-step: 68-631 -- Loss: 0.15062007308006287
val-epoch-step: 68-632 -- Loss: 0.19275252521038055
val-epoch-step: 68-633 -- Loss: 0.1496300846338272
val-epoch-step: 68-634 -- Loss: 0.1480390429496765
val-epoch-step: 68-635 -- Loss: 0.10913362354040146
val-epoch-step: 68-636 -- Loss: 0.15883487462997437
val-epoch-step: 68-637 -- Loss: 0.17836230993270874
val-epoch-step: 68-638 -- Loss: 0.1545412689447403
val-epoch-step: 68-639 -- Loss: 0.2525281608104706
val-epoch-step: 68-640 -- Loss: 0.24011307954788208
val-epoch-step: 68-641 -- Loss: 0.11940508335828781
val-epoch-step: 68-642 -- Loss: 0.17114970088005066
val-epoch-step: 68-643 -- Loss: 0.20699191093444824
val-epoch-step: 68-644 -- Loss: 0.1680828183889389
val-epoch-step: 68-645 -- Loss: 0.21653859317302704
val-epoch-step: 68-646 -- Loss: 0.1384516954421997
val-epoch-step: 68-647 -- Loss: 0.12293438613414764
val-epoch-step: 68-648 -- Loss: 0.1501442790031433
val-epoch-step: 68-649 -- Loss: 0.203048974275589
val-epoch-step: 68-650 -- Loss: 0.24081379175186157
val-epoch-step: 68-651 -- Loss: 0.1439506560564041
val-epoch-step: 68-652 -- Loss: 0.15339741110801697
val-epoch-step: 68-653 -- Loss: 0.19395995140075684
val-epoch-step: 68-654 -- Loss: 0.1149282306432724
Epoch: 68 -- Train Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 69-0 -- Loss: 0.21080833673477173
train-epoch-step: 69-1 -- Loss: 0.1408996433019638
train-epoch-step: 69-2 -- Loss: 0.19423045217990875
train-epoch-step: 69-3 -- Loss: 0.13607677817344666
train-epoch-step: 69-4 -- Loss: 0.15145356953144073
train-epoch-step: 69-5 -- Loss: 0.17366084456443787
train-epoch-step: 69-6 -- Loss: 0.21014077961444855
train-epoch-step: 69-7 -- Loss: 0.1604110449552536
train-epoch-step: 69-8 -- Loss: 0.16886019706726074
train-epoch-step: 69-9 -- Loss: 0.21007861196994781
train-epoch-step: 69-10 -- Loss: 0.18150275945663452
train-epoch-step: 69-11 -- Loss: 0.16828322410583496
train-epoch-step: 69-12 -- Loss: 0.14368949830532074
train-epoch-step: 69-13 -- Loss: 0.16922158002853394
train-epoch-step: 69-14 -- Loss: 0.15755745768547058
train-epoch-step: 69-15 -- Loss: 0.15418878197669983
train-epoch-step: 69-16 -- Loss: 0.1630408763885498
train-epoch-step: 69-17 -- Loss: 0.20487436652183533
train-epoch-step: 69-18 -- Loss: 0.18784087896347046
train-epoch-step: 69-19 -- Loss: 0.1273840367794037
train-epoch-step: 69-20 -- Loss: 0.20486755669116974
train-epoch-step: 69-21 -- Loss: 0.23457197844982147
train-epoch-step: 69-22 -- Loss: 0.13248752057552338
train-epoch-step: 69-23 -- Loss: 0.13862740993499756
train-epoch-step: 69-24 -- Loss: 0.12020113319158554
train-epoch-step: 69-25 -- Loss: 0.21627436578273773
train-epoch-step: 69-26 -- Loss: 0.18572911620140076
train-epoch-step: 69-27 -- Loss: 0.23480695486068726
train-epoch-step: 69-28 -- Loss: 0.11908458173274994
train-epoch-step: 69-29 -- Loss: 0.2280069887638092
train-epoch-step: 69-30 -- Loss: 0.10583818703889847
train-epoch-step: 69-31 -- Loss: 0.13017217814922333
train-epoch-step: 69-32 -- Loss: 0.1672174483537674
train-epoch-step: 69-33 -- Loss: 0.2647273540496826
train-epoch-step: 69-34 -- Loss: 0.1584879755973816
train-epoch-step: 69-35 -- Loss: 0.23194244503974915
train-epoch-step: 69-36 -- Loss: 0.13109350204467773
train-epoch-step: 69-37 -- Loss: 0.13300731778144836
train-epoch-step: 69-38 -- Loss: 0.16603846848011017
train-epoch-step: 69-39 -- Loss: 0.20533031225204468
train-epoch-step: 69-40 -- Loss: 0.18346527218818665
train-epoch-step: 69-41 -- Loss: 0.20626574754714966
train-epoch-step: 69-42 -- Loss: 0.1438361406326294
train-epoch-step: 69-43 -- Loss: 0.24929574131965637
train-epoch-step: 69-44 -- Loss: 0.11958163976669312
train-epoch-step: 69-45 -- Loss: 0.10903385281562805
train-epoch-step: 69-46 -- Loss: 0.1580992341041565
train-epoch-step: 69-47 -- Loss: 0.18859848380088806
train-epoch-step: 69-48 -- Loss: 0.14815649390220642
train-epoch-step: 69-49 -- Loss: 0.2108992040157318
train-epoch-step: 69-50 -- Loss: 0.10539429634809494
train-epoch-step: 69-51 -- Loss: 0.16751593351364136
train-epoch-step: 69-52 -- Loss: 0.1518208235502243
train-epoch-step: 69-53 -- Loss: 0.1983540952205658
train-epoch-step: 69-54 -- Loss: 0.27477169036865234
train-epoch-step: 69-55 -- Loss: 0.15995869040489197
train-epoch-step: 69-56 -- Loss: 0.17081783711910248
train-epoch-step: 69-57 -- Loss: 0.2288026511669159
train-epoch-step: 69-58 -- Loss: 0.27060985565185547
train-epoch-step: 69-59 -- Loss: 0.22623926401138306
train-epoch-step: 69-60 -- Loss: 0.12229488790035248
train-epoch-step: 69-61 -- Loss: 0.19390584528446198
train-epoch-step: 69-62 -- Loss: 0.17980723083019257
train-epoch-step: 69-63 -- Loss: 0.13056093454360962
train-epoch-step: 69-64 -- Loss: 0.1391555517911911
train-epoch-step: 69-65 -- Loss: 0.1747444123029709
train-epoch-step: 69-66 -- Loss: 0.10551697760820389
train-epoch-step: 69-67 -- Loss: 0.12388423085212708
train-epoch-step: 69-68 -- Loss: 0.20022456347942352
train-epoch-step: 69-69 -- Loss: 0.11592426151037216
train-epoch-step: 69-70 -- Loss: 0.21291634440422058
train-epoch-step: 69-71 -- Loss: 0.250181645154953
train-epoch-step: 69-72 -- Loss: 0.165190190076828
train-epoch-step: 69-73 -- Loss: 0.19920605421066284
train-epoch-step: 69-74 -- Loss: 0.09033145010471344
train-epoch-step: 69-75 -- Loss: 0.12060919404029846
train-epoch-step: 69-76 -- Loss: 0.14089950919151306
train-epoch-step: 69-77 -- Loss: 0.21907678246498108
train-epoch-step: 69-78 -- Loss: 0.24802009761333466
train-epoch-step: 69-79 -- Loss: 0.18583454191684723
train-epoch-step: 69-80 -- Loss: 0.22949427366256714
train-epoch-step: 69-81 -- Loss: 0.11867652833461761
train-epoch-step: 69-82 -- Loss: 0.2394046038389206
train-epoch-step: 69-83 -- Loss: 0.17221203446388245
train-epoch-step: 69-84 -- Loss: 0.1813248246908188
train-epoch-step: 69-85 -- Loss: 0.16928821802139282
train-epoch-step: 69-86 -- Loss: 0.11446894705295563
train-epoch-step: 69-87 -- Loss: 0.19878190755844116
train-epoch-step: 69-88 -- Loss: 0.13403314352035522
train-epoch-step: 69-89 -- Loss: 0.18095120787620544
train-epoch-step: 69-90 -- Loss: 0.18399760127067566
train-epoch-step: 69-91 -- Loss: 0.23401053249835968
train-epoch-step: 69-92 -- Loss: 0.1481122076511383
train-epoch-step: 69-93 -- Loss: 0.16295430064201355
train-epoch-step: 69-94 -- Loss: 0.21570102870464325
train-epoch-step: 69-95 -- Loss: 0.18005028367042542
train-epoch-step: 69-96 -- Loss: 0.20398353040218353
train-epoch-step: 69-97 -- Loss: 0.1673738807439804
train-epoch-step: 69-98 -- Loss: 0.14966243505477905
train-epoch-step: 69-99 -- Loss: 0.17191825807094574
train-epoch-step: 69-100 -- Loss: 0.18223196268081665
train-epoch-step: 69-101 -- Loss: 0.24928736686706543
train-epoch-step: 69-102 -- Loss: 0.20860323309898376
train-epoch-step: 69-103 -- Loss: 0.17595435678958893
train-epoch-step: 69-104 -- Loss: 0.14408375322818756
train-epoch-step: 69-105 -- Loss: 0.24876853823661804
train-epoch-step: 69-106 -- Loss: 0.16935889422893524
train-epoch-step: 69-107 -- Loss: 0.18642891943454742
train-epoch-step: 69-108 -- Loss: 0.18196621537208557
train-epoch-step: 69-109 -- Loss: 0.13946010172367096
train-epoch-step: 69-110 -- Loss: 0.17572477459907532
train-epoch-step: 69-111 -- Loss: 0.17234474420547485
train-epoch-step: 69-112 -- Loss: 0.15876340866088867
train-epoch-step: 69-113 -- Loss: 0.15454283356666565
train-epoch-step: 69-114 -- Loss: 0.1889687478542328
train-epoch-step: 69-115 -- Loss: 0.1540909707546234
train-epoch-step: 69-116 -- Loss: 0.13372370600700378
train-epoch-step: 69-117 -- Loss: 0.1242905929684639
train-epoch-step: 69-118 -- Loss: 0.18524110317230225
train-epoch-step: 69-119 -- Loss: 0.14723224937915802
train-epoch-step: 69-120 -- Loss: 0.23802447319030762
train-epoch-step: 69-121 -- Loss: 0.21819324791431427
train-epoch-step: 69-122 -- Loss: 0.2090904414653778
train-epoch-step: 69-123 -- Loss: 0.1967342495918274
train-epoch-step: 69-124 -- Loss: 0.11882340162992477
train-epoch-step: 69-125 -- Loss: 0.1553051918745041
train-epoch-step: 69-126 -- Loss: 0.22702060639858246
train-epoch-step: 69-127 -- Loss: 0.16013124585151672
train-epoch-step: 69-128 -- Loss: 0.1649535447359085
train-epoch-step: 69-129 -- Loss: 0.13982878625392914
train-epoch-step: 69-130 -- Loss: 0.1816612184047699
train-epoch-step: 69-131 -- Loss: 0.1292192041873932
train-epoch-step: 69-132 -- Loss: 0.18731920421123505
train-epoch-step: 69-133 -- Loss: 0.12248006463050842
train-epoch-step: 69-134 -- Loss: 0.1949346512556076
train-epoch-step: 69-135 -- Loss: 0.12879988551139832
train-epoch-step: 69-136 -- Loss: 0.12172726541757584
train-epoch-step: 69-137 -- Loss: 0.23299868404865265
train-epoch-step: 69-138 -- Loss: 0.24819998443126678
train-epoch-step: 69-139 -- Loss: 0.12662997841835022
train-epoch-step: 69-140 -- Loss: 0.19658711552619934
train-epoch-step: 69-141 -- Loss: 0.22085021436214447
train-epoch-step: 69-142 -- Loss: 0.1976177990436554
train-epoch-step: 69-143 -- Loss: 0.16483597457408905
train-epoch-step: 69-144 -- Loss: 0.18300145864486694
train-epoch-step: 69-145 -- Loss: 0.14059758186340332
train-epoch-step: 69-146 -- Loss: 0.17913159728050232
train-epoch-step: 69-147 -- Loss: 0.16316893696784973
train-epoch-step: 69-148 -- Loss: 0.15331432223320007
train-epoch-step: 69-149 -- Loss: 0.1163821890950203
train-epoch-step: 69-150 -- Loss: 0.1766025573015213
train-epoch-step: 69-151 -- Loss: 0.1907949447631836
train-epoch-step: 69-152 -- Loss: 0.18441881239414215
train-epoch-step: 69-153 -- Loss: 0.2561194896697998
train-epoch-step: 69-154 -- Loss: 0.12687070667743683
train-epoch-step: 69-155 -- Loss: 0.13301104307174683
train-epoch-step: 69-156 -- Loss: 0.11711692810058594
train-epoch-step: 69-157 -- Loss: 0.1611156314611435
train-epoch-step: 69-158 -- Loss: 0.16312766075134277
train-epoch-step: 69-159 -- Loss: 0.17173552513122559
train-epoch-step: 69-160 -- Loss: 0.20713408291339874
train-epoch-step: 69-161 -- Loss: 0.19735363125801086
train-epoch-step: 69-162 -- Loss: 0.20916172862052917
train-epoch-step: 69-163 -- Loss: 0.18355876207351685
train-epoch-step: 69-164 -- Loss: 0.18907377123832703
train-epoch-step: 69-165 -- Loss: 0.15581145882606506
train-epoch-step: 69-166 -- Loss: 0.11512981355190277
train-epoch-step: 69-167 -- Loss: 0.12294677644968033
train-epoch-step: 69-168 -- Loss: 0.19302186369895935
train-epoch-step: 69-169 -- Loss: 0.13169802725315094
train-epoch-step: 69-170 -- Loss: 0.1921590119600296
train-epoch-step: 69-171 -- Loss: 0.1380413919687271
train-epoch-step: 69-172 -- Loss: 0.2543271481990814
train-epoch-step: 69-173 -- Loss: 0.1289176642894745
train-epoch-step: 69-174 -- Loss: 0.2357766032218933
train-epoch-step: 69-175 -- Loss: 0.18375928699970245
train-epoch-step: 69-176 -- Loss: 0.12585575878620148
train-epoch-step: 69-177 -- Loss: 0.1733282506465912
train-epoch-step: 69-178 -- Loss: 0.17765924334526062
train-epoch-step: 69-179 -- Loss: 0.13603048026561737
train-epoch-step: 69-180 -- Loss: 0.14732903242111206
train-epoch-step: 69-181 -- Loss: 0.16169480979442596
train-epoch-step: 69-182 -- Loss: 0.17459526658058167
train-epoch-step: 69-183 -- Loss: 0.265940397977829
train-epoch-step: 69-184 -- Loss: 0.13246102631092072
train-epoch-step: 69-185 -- Loss: 0.13337171077728271
train-epoch-step: 69-186 -- Loss: 0.1830216497182846
train-epoch-step: 69-187 -- Loss: 0.2032116800546646
train-epoch-step: 69-188 -- Loss: 0.16656070947647095
train-epoch-step: 69-189 -- Loss: 0.10366922616958618
train-epoch-step: 69-190 -- Loss: 0.17516610026359558
train-epoch-step: 69-191 -- Loss: 0.1501493752002716
train-epoch-step: 69-192 -- Loss: 0.21828696131706238
train-epoch-step: 69-193 -- Loss: 0.19736146926879883
train-epoch-step: 69-194 -- Loss: 0.17994867265224457
train-epoch-step: 69-195 -- Loss: 0.15901391208171844
train-epoch-step: 69-196 -- Loss: 0.16215474903583527
train-epoch-step: 69-197 -- Loss: 0.119733527302742
train-epoch-step: 69-198 -- Loss: 0.12142597883939743
train-epoch-step: 69-199 -- Loss: 0.14366725087165833
train-epoch-step: 69-200 -- Loss: 0.12932556867599487
train-epoch-step: 69-201 -- Loss: 0.1971914917230606
train-epoch-step: 69-202 -- Loss: 0.1318034827709198
train-epoch-step: 69-203 -- Loss: 0.16856487095355988
train-epoch-step: 69-204 -- Loss: 0.12939319014549255
train-epoch-step: 69-205 -- Loss: 0.17605257034301758
train-epoch-step: 69-206 -- Loss: 0.19770285487174988
train-epoch-step: 69-207 -- Loss: 0.13498686254024506
train-epoch-step: 69-208 -- Loss: 0.17371952533721924
train-epoch-step: 69-209 -- Loss: 0.14026367664337158
train-epoch-step: 69-210 -- Loss: 0.12784865498542786
train-epoch-step: 69-211 -- Loss: 0.19576841592788696
train-epoch-step: 69-212 -- Loss: 0.19320964813232422
train-epoch-step: 69-213 -- Loss: 0.12144654989242554
train-epoch-step: 69-214 -- Loss: 0.14498694241046906
train-epoch-step: 69-215 -- Loss: 0.12358897924423218
train-epoch-step: 69-216 -- Loss: 0.1982015073299408
train-epoch-step: 69-217 -- Loss: 0.2049744427204132
train-epoch-step: 69-218 -- Loss: 0.14075055718421936
train-epoch-step: 69-219 -- Loss: 0.16468457877635956
train-epoch-step: 69-220 -- Loss: 0.12534119188785553
train-epoch-step: 69-221 -- Loss: 0.20039215683937073
train-epoch-step: 69-222 -- Loss: 0.1205289363861084
train-epoch-step: 69-223 -- Loss: 0.1663874238729477
train-epoch-step: 69-224 -- Loss: 0.18163838982582092
train-epoch-step: 69-225 -- Loss: 0.2589481472969055
train-epoch-step: 69-226 -- Loss: 0.20095419883728027
train-epoch-step: 69-227 -- Loss: 0.2145346999168396
train-epoch-step: 69-228 -- Loss: 0.17485550045967102
train-epoch-step: 69-229 -- Loss: 0.1719726324081421
train-epoch-step: 69-230 -- Loss: 0.16140317916870117
train-epoch-step: 69-231 -- Loss: 0.15199324488639832
train-epoch-step: 69-232 -- Loss: 0.17786699533462524
train-epoch-step: 69-233 -- Loss: 0.08157084882259369
train-epoch-step: 69-234 -- Loss: 0.1822773516178131
train-epoch-step: 69-235 -- Loss: 0.14936688542366028
train-epoch-step: 69-236 -- Loss: 0.17612402141094208
train-epoch-step: 69-237 -- Loss: 0.22323092818260193
train-epoch-step: 69-238 -- Loss: 0.1536363661289215
train-epoch-step: 69-239 -- Loss: 0.12574945390224457
train-epoch-step: 69-240 -- Loss: 0.21333932876586914
train-epoch-step: 69-241 -- Loss: 0.1490020453929901
train-epoch-step: 69-242 -- Loss: 0.22958245873451233
train-epoch-step: 69-243 -- Loss: 0.23763690888881683
train-epoch-step: 69-244 -- Loss: 0.19746890664100647
train-epoch-step: 69-245 -- Loss: 0.19760015606880188
train-epoch-step: 69-246 -- Loss: 0.20987923443317413
train-epoch-step: 69-247 -- Loss: 0.20915575325489044
train-epoch-step: 69-248 -- Loss: 0.18097375333309174
train-epoch-step: 69-249 -- Loss: 0.1340446174144745
train-epoch-step: 69-250 -- Loss: 0.19213342666625977
train-epoch-step: 69-251 -- Loss: 0.10593143850564957
train-epoch-step: 69-252 -- Loss: 0.18449237942695618
train-epoch-step: 69-253 -- Loss: 0.13300837576389313
train-epoch-step: 69-254 -- Loss: 0.20365235209465027
train-epoch-step: 69-255 -- Loss: 0.14287345111370087
train-epoch-step: 69-256 -- Loss: 0.14915944635868073
train-epoch-step: 69-257 -- Loss: 0.1824425756931305
train-epoch-step: 69-258 -- Loss: 0.14024581015110016
train-epoch-step: 69-259 -- Loss: 0.11017750948667526
train-epoch-step: 69-260 -- Loss: 0.19382701814174652
train-epoch-step: 69-261 -- Loss: 0.16931626200675964
train-epoch-step: 69-262 -- Loss: 0.2770839333534241
train-epoch-step: 69-263 -- Loss: 0.19272969663143158
train-epoch-step: 69-264 -- Loss: 0.16772842407226562
train-epoch-step: 69-265 -- Loss: 0.10335426032543182
train-epoch-step: 69-266 -- Loss: 0.14806479215621948
train-epoch-step: 69-267 -- Loss: 0.1266966462135315
train-epoch-step: 69-268 -- Loss: 0.11610540002584457
train-epoch-step: 69-269 -- Loss: 0.1650232970714569
train-epoch-step: 69-270 -- Loss: 0.10384605079889297
train-epoch-step: 69-271 -- Loss: 0.13834398984909058
train-epoch-step: 69-272 -- Loss: 0.11519039422273636
train-epoch-step: 69-273 -- Loss: 0.12272924184799194
train-epoch-step: 69-274 -- Loss: 0.17916540801525116
train-epoch-step: 69-275 -- Loss: 0.17883843183517456
train-epoch-step: 69-276 -- Loss: 0.15015922486782074
train-epoch-step: 69-277 -- Loss: 0.15009337663650513
train-epoch-step: 69-278 -- Loss: 0.13585303723812103
train-epoch-step: 69-279 -- Loss: 0.1377609372138977
train-epoch-step: 69-280 -- Loss: 0.2158515453338623
train-epoch-step: 69-281 -- Loss: 0.16899529099464417
train-epoch-step: 69-282 -- Loss: 0.13879728317260742
train-epoch-step: 69-283 -- Loss: 0.11207988858222961
train-epoch-step: 69-284 -- Loss: 0.13130436837673187
train-epoch-step: 69-285 -- Loss: 0.18445296585559845
train-epoch-step: 69-286 -- Loss: 0.14793971180915833
train-epoch-step: 69-287 -- Loss: 0.19284656643867493
train-epoch-step: 69-288 -- Loss: 0.09088322520256042
train-epoch-step: 69-289 -- Loss: 0.11436901241540909
train-epoch-step: 69-290 -- Loss: 0.18036635220050812
train-epoch-step: 69-291 -- Loss: 0.11184918135404587
train-epoch-step: 69-292 -- Loss: 0.1490275114774704
train-epoch-step: 69-293 -- Loss: 0.1338699907064438
train-epoch-step: 69-294 -- Loss: 0.15013544261455536
train-epoch-step: 69-295 -- Loss: 0.24806246161460876
train-epoch-step: 69-296 -- Loss: 0.1547764092683792
train-epoch-step: 69-297 -- Loss: 0.1679133176803589
train-epoch-step: 69-298 -- Loss: 0.22241155803203583
train-epoch-step: 69-299 -- Loss: 0.14149025082588196
train-epoch-step: 69-300 -- Loss: 0.15470506250858307
train-epoch-step: 69-301 -- Loss: 0.16250503063201904
train-epoch-step: 69-302 -- Loss: 0.208780899643898
train-epoch-step: 69-303 -- Loss: 0.1978883147239685
train-epoch-step: 69-304 -- Loss: 0.11985589563846588
train-epoch-step: 69-305 -- Loss: 0.1386445313692093
train-epoch-step: 69-306 -- Loss: 0.20750311017036438
train-epoch-step: 69-307 -- Loss: 0.16009840369224548
train-epoch-step: 69-308 -- Loss: 0.2119593322277069
train-epoch-step: 69-309 -- Loss: 0.14797323942184448
train-epoch-step: 69-310 -- Loss: 0.1591385006904602
train-epoch-step: 69-311 -- Loss: 0.151208758354187
train-epoch-step: 69-312 -- Loss: 0.19849854707717896
train-epoch-step: 69-313 -- Loss: 0.0932445153594017
train-epoch-step: 69-314 -- Loss: 0.1819942146539688
train-epoch-step: 69-315 -- Loss: 0.16323231160640717
train-epoch-step: 69-316 -- Loss: 0.14566674828529358
train-epoch-step: 69-317 -- Loss: 0.13191120326519012
train-epoch-step: 69-318 -- Loss: 0.14840075373649597
train-epoch-step: 69-319 -- Loss: 0.15919266641139984
train-epoch-step: 69-320 -- Loss: 0.11422699689865112
train-epoch-step: 69-321 -- Loss: 0.12607859075069427
train-epoch-step: 69-322 -- Loss: 0.20396539568901062
train-epoch-step: 69-323 -- Loss: 0.15631242096424103
train-epoch-step: 69-324 -- Loss: 0.24427901208400726
train-epoch-step: 69-325 -- Loss: 0.14885297417640686
train-epoch-step: 69-326 -- Loss: 0.16282683610916138
train-epoch-step: 69-327 -- Loss: 0.1960560828447342
train-epoch-step: 69-328 -- Loss: 0.18756896257400513
train-epoch-step: 69-329 -- Loss: 0.33169758319854736
train-epoch-step: 69-330 -- Loss: 0.352700799703598
train-epoch-step: 69-331 -- Loss: 0.19999882578849792
train-epoch-step: 69-332 -- Loss: 0.09533172100782394
train-epoch-step: 69-333 -- Loss: 0.17561206221580505
train-epoch-step: 69-334 -- Loss: 0.14896591007709503
train-epoch-step: 69-335 -- Loss: 0.16626179218292236
train-epoch-step: 69-336 -- Loss: 0.14227856695652008
train-epoch-step: 69-337 -- Loss: 0.19680067896842957
train-epoch-step: 69-338 -- Loss: 0.15804043412208557
train-epoch-step: 69-339 -- Loss: 0.13685712218284607
train-epoch-step: 69-340 -- Loss: 0.18977844715118408
train-epoch-step: 69-341 -- Loss: 0.1371661126613617
train-epoch-step: 69-342 -- Loss: 0.158869206905365
train-epoch-step: 69-343 -- Loss: 0.1486070454120636
train-epoch-step: 69-344 -- Loss: 0.16568401455879211
train-epoch-step: 69-345 -- Loss: 0.12206099927425385
train-epoch-step: 69-346 -- Loss: 0.189844012260437
train-epoch-step: 69-347 -- Loss: 0.14954063296318054
train-epoch-step: 69-348 -- Loss: 0.1983758807182312
train-epoch-step: 69-349 -- Loss: 0.19528239965438843
train-epoch-step: 69-350 -- Loss: 0.24104496836662292
train-epoch-step: 69-351 -- Loss: 0.18871377408504486
train-epoch-step: 69-352 -- Loss: 0.1212369054555893
train-epoch-step: 69-353 -- Loss: 0.18832629919052124
train-epoch-step: 69-354 -- Loss: 0.2659214735031128
train-epoch-step: 69-355 -- Loss: 0.11538348346948624
train-epoch-step: 69-356 -- Loss: 0.11155647784471512
train-epoch-step: 69-357 -- Loss: 0.18132475018501282
train-epoch-step: 69-358 -- Loss: 0.18104182183742523
train-epoch-step: 69-359 -- Loss: 0.138831228017807
train-epoch-step: 69-360 -- Loss: 0.11949219554662704
train-epoch-step: 69-361 -- Loss: 0.22762247920036316
train-epoch-step: 69-362 -- Loss: 0.1661047339439392
train-epoch-step: 69-363 -- Loss: 0.11117645353078842
train-epoch-step: 69-364 -- Loss: 0.17447113990783691
train-epoch-step: 69-365 -- Loss: 0.16502712666988373
train-epoch-step: 69-366 -- Loss: 0.19478648900985718
train-epoch-step: 69-367 -- Loss: 0.22019362449645996
train-epoch-step: 69-368 -- Loss: 0.1961696743965149
train-epoch-step: 69-369 -- Loss: 0.26872843503952026
train-epoch-step: 69-370 -- Loss: 0.12000347673892975
train-epoch-step: 69-371 -- Loss: 0.11696015298366547
train-epoch-step: 69-372 -- Loss: 0.14162245392799377
train-epoch-step: 69-373 -- Loss: 0.18209123611450195
train-epoch-step: 69-374 -- Loss: 0.14928418397903442
train-epoch-step: 69-375 -- Loss: 0.25712162256240845
train-epoch-step: 69-376 -- Loss: 0.15409958362579346
train-epoch-step: 69-377 -- Loss: 0.22245147824287415
train-epoch-step: 69-378 -- Loss: 0.1900578737258911
train-epoch-step: 69-379 -- Loss: 0.11705782264471054
train-epoch-step: 69-380 -- Loss: 0.08866018801927567
train-epoch-step: 69-381 -- Loss: 0.2328946441411972
train-epoch-step: 69-382 -- Loss: 0.22369849681854248
train-epoch-step: 69-383 -- Loss: 0.17171598970890045
train-epoch-step: 69-384 -- Loss: 0.21670034527778625
train-epoch-step: 69-385 -- Loss: 0.18153579533100128
train-epoch-step: 69-386 -- Loss: 0.1804536134004593
train-epoch-step: 69-387 -- Loss: 0.20626908540725708
train-epoch-step: 69-388 -- Loss: 0.18366219103336334
train-epoch-step: 69-389 -- Loss: 0.16228404641151428
train-epoch-step: 69-390 -- Loss: 0.1406695693731308
train-epoch-step: 69-391 -- Loss: 0.13782881200313568
train-epoch-step: 69-392 -- Loss: 0.18025773763656616
train-epoch-step: 69-393 -- Loss: 0.15026302635669708
train-epoch-step: 69-394 -- Loss: 0.19143716990947723
train-epoch-step: 69-395 -- Loss: 0.16117890179157257
train-epoch-step: 69-396 -- Loss: 0.12257158756256104
train-epoch-step: 69-397 -- Loss: 0.12552517652511597
train-epoch-step: 69-398 -- Loss: 0.1923295110464096
train-epoch-step: 69-399 -- Loss: 0.1695755273103714
train-epoch-step: 69-400 -- Loss: 0.26638317108154297
train-epoch-step: 69-401 -- Loss: 0.11604255437850952
train-epoch-step: 69-402 -- Loss: 0.24759237468242645
train-epoch-step: 69-403 -- Loss: 0.15097561478614807
train-epoch-step: 69-404 -- Loss: 0.14390672743320465
train-epoch-step: 69-405 -- Loss: 0.14000505208969116
train-epoch-step: 69-406 -- Loss: 0.16715839505195618
train-epoch-step: 69-407 -- Loss: 0.109235480427742
train-epoch-step: 69-408 -- Loss: 0.155739426612854
train-epoch-step: 69-409 -- Loss: 0.1648053377866745
train-epoch-step: 69-410 -- Loss: 0.16792365908622742
train-epoch-step: 69-411 -- Loss: 0.19840148091316223
train-epoch-step: 69-412 -- Loss: 0.12709873914718628
train-epoch-step: 69-413 -- Loss: 0.14261943101882935
train-epoch-step: 69-414 -- Loss: 0.13042108714580536
train-epoch-step: 69-415 -- Loss: 0.13277113437652588
train-epoch-step: 69-416 -- Loss: 0.2604232430458069
train-epoch-step: 69-417 -- Loss: 0.18798744678497314
train-epoch-step: 69-418 -- Loss: 0.22180449962615967
train-epoch-step: 69-419 -- Loss: 0.1621650755405426
train-epoch-step: 69-420 -- Loss: 0.14919063448905945
train-epoch-step: 69-421 -- Loss: 0.16963326930999756
train-epoch-step: 69-422 -- Loss: 0.14202460646629333
train-epoch-step: 69-423 -- Loss: 0.16558462381362915
train-epoch-step: 69-424 -- Loss: 0.1323719024658203
train-epoch-step: 69-425 -- Loss: 0.1756475865840912
train-epoch-step: 69-426 -- Loss: 0.15786375105381012
train-epoch-step: 69-427 -- Loss: 0.1168895810842514
train-epoch-step: 69-428 -- Loss: 0.18145106732845306
train-epoch-step: 69-429 -- Loss: 0.17355620861053467
train-epoch-step: 69-430 -- Loss: 0.13386909663677216
train-epoch-step: 69-431 -- Loss: 0.16001716256141663
train-epoch-step: 69-432 -- Loss: 0.2303752899169922
train-epoch-step: 69-433 -- Loss: 0.13358645141124725
train-epoch-step: 69-434 -- Loss: 0.12328494340181351
train-epoch-step: 69-435 -- Loss: 0.15107277035713196
train-epoch-step: 69-436 -- Loss: 0.14833971858024597
train-epoch-step: 69-437 -- Loss: 0.12914720177650452
train-epoch-step: 69-438 -- Loss: 0.16003380715847015
train-epoch-step: 69-439 -- Loss: 0.25349584221839905
train-epoch-step: 69-440 -- Loss: 0.1284661442041397
train-epoch-step: 69-441 -- Loss: 0.19386377930641174
train-epoch-step: 69-442 -- Loss: 0.16801105439662933
train-epoch-step: 69-443 -- Loss: 0.1488606333732605
train-epoch-step: 69-444 -- Loss: 0.1689244508743286
train-epoch-step: 69-445 -- Loss: 0.1719580590724945
train-epoch-step: 69-446 -- Loss: 0.14727440476417542
train-epoch-step: 69-447 -- Loss: 0.18784253299236298
train-epoch-step: 69-448 -- Loss: 0.2140885889530182
train-epoch-step: 69-449 -- Loss: 0.18674764037132263
train-epoch-step: 69-450 -- Loss: 0.17887873947620392
train-epoch-step: 69-451 -- Loss: 0.1417572945356369
train-epoch-step: 69-452 -- Loss: 0.1227726861834526
train-epoch-step: 69-453 -- Loss: 0.09260860830545425
train-epoch-step: 69-454 -- Loss: 0.2210150808095932
train-epoch-step: 69-455 -- Loss: 0.11818937212228775
train-epoch-step: 69-456 -- Loss: 0.1149921715259552
train-epoch-step: 69-457 -- Loss: 0.20853586494922638
train-epoch-step: 69-458 -- Loss: 0.14024779200553894
train-epoch-step: 69-459 -- Loss: 0.20505854487419128
train-epoch-step: 69-460 -- Loss: 0.11904186010360718
train-epoch-step: 69-461 -- Loss: 0.13053202629089355
train-epoch-step: 69-462 -- Loss: 0.14795047044754028
train-epoch-step: 69-463 -- Loss: 0.12754987180233002
train-epoch-step: 69-464 -- Loss: 0.1560128927230835
train-epoch-step: 69-465 -- Loss: 0.23231521248817444
train-epoch-step: 69-466 -- Loss: 0.20047414302825928
train-epoch-step: 69-467 -- Loss: 0.10715613514184952
train-epoch-step: 69-468 -- Loss: 0.15462064743041992
train-epoch-step: 69-469 -- Loss: 0.211481973528862
train-epoch-step: 69-470 -- Loss: 0.1632142961025238
train-epoch-step: 69-471 -- Loss: 0.15596723556518555
train-epoch-step: 69-472 -- Loss: 0.15309469401836395
train-epoch-step: 69-473 -- Loss: 0.14795416593551636
train-epoch-step: 69-474 -- Loss: 0.11455553025007248
train-epoch-step: 69-475 -- Loss: 0.10659879446029663
train-epoch-step: 69-476 -- Loss: 0.19943127036094666
train-epoch-step: 69-477 -- Loss: 0.20584191381931305
train-epoch-step: 69-478 -- Loss: 0.1852157562971115
train-epoch-step: 69-479 -- Loss: 0.1340668499469757
train-epoch-step: 69-480 -- Loss: 0.18824341893196106
train-epoch-step: 69-481 -- Loss: 0.26623082160949707
train-epoch-step: 69-482 -- Loss: 0.2386779636144638
train-epoch-step: 69-483 -- Loss: 0.17146745324134827
train-epoch-step: 69-484 -- Loss: 0.2070736587047577
train-epoch-step: 69-485 -- Loss: 0.12173300981521606
train-epoch-step: 69-486 -- Loss: 0.2219468653202057
train-epoch-step: 69-487 -- Loss: 0.2255166471004486
train-epoch-step: 69-488 -- Loss: 0.18223440647125244
train-epoch-step: 69-489 -- Loss: 0.21362556517124176
train-epoch-step: 69-490 -- Loss: 0.13710100948810577
train-epoch-step: 69-491 -- Loss: 0.13013955950737
train-epoch-step: 69-492 -- Loss: 0.12095072120428085
train-epoch-step: 69-493 -- Loss: 0.187750443816185
train-epoch-step: 69-494 -- Loss: 0.19903461635112762
train-epoch-step: 69-495 -- Loss: 0.19187678396701813
train-epoch-step: 69-496 -- Loss: 0.13511686027050018
train-epoch-step: 69-497 -- Loss: 0.17626425623893738
train-epoch-step: 69-498 -- Loss: 0.1409488022327423
train-epoch-step: 69-499 -- Loss: 0.16109445691108704
train-epoch-step: 69-500 -- Loss: 0.15068060159683228
train-epoch-step: 69-501 -- Loss: 0.21069687604904175
train-epoch-step: 69-502 -- Loss: 0.15162046253681183
train-epoch-step: 69-503 -- Loss: 0.2087154984474182
train-epoch-step: 69-504 -- Loss: 0.11491481214761734
train-epoch-step: 69-505 -- Loss: 0.16815847158432007
train-epoch-step: 69-506 -- Loss: 0.11209626495838165
train-epoch-step: 69-507 -- Loss: 0.17008869349956512
train-epoch-step: 69-508 -- Loss: 0.1624118983745575
train-epoch-step: 69-509 -- Loss: 0.1640377640724182
train-epoch-step: 69-510 -- Loss: 0.12390059232711792
train-epoch-step: 69-511 -- Loss: 0.20743384957313538
train-epoch-step: 69-512 -- Loss: 0.17137950658798218
train-epoch-step: 69-513 -- Loss: 0.18095317482948303
train-epoch-step: 69-514 -- Loss: 0.13977132737636566
train-epoch-step: 69-515 -- Loss: 0.14815753698349
train-epoch-step: 69-516 -- Loss: 0.1623367816209793
train-epoch-step: 69-517 -- Loss: 0.1689220517873764
train-epoch-step: 69-518 -- Loss: 0.13283617794513702
train-epoch-step: 69-519 -- Loss: 0.12873300909996033
train-epoch-step: 69-520 -- Loss: 0.17988839745521545
train-epoch-step: 69-521 -- Loss: 0.22084397077560425
train-epoch-step: 69-522 -- Loss: 0.17236459255218506
train-epoch-step: 69-523 -- Loss: 0.1531313955783844
train-epoch-step: 69-524 -- Loss: 0.15915295481681824
train-epoch-step: 69-525 -- Loss: 0.1874297857284546
train-epoch-step: 69-526 -- Loss: 0.12768037617206573
train-epoch-step: 69-527 -- Loss: 0.1441933959722519
train-epoch-step: 69-528 -- Loss: 0.1484145075082779
train-epoch-step: 69-529 -- Loss: 0.1500971019268036
train-epoch-step: 69-530 -- Loss: 0.1644403040409088
train-epoch-step: 69-531 -- Loss: 0.18867769837379456
train-epoch-step: 69-532 -- Loss: 0.16313567757606506
train-epoch-step: 69-533 -- Loss: 0.1714141070842743
train-epoch-step: 69-534 -- Loss: 0.12314380705356598
train-epoch-step: 69-535 -- Loss: 0.24266789853572845
train-epoch-step: 69-536 -- Loss: 0.15047313272953033
train-epoch-step: 69-537 -- Loss: 0.14224779605865479
train-epoch-step: 69-538 -- Loss: 0.10061196237802505
train-epoch-step: 69-539 -- Loss: 0.17091219127178192
train-epoch-step: 69-540 -- Loss: 0.13288897275924683
train-epoch-step: 69-541 -- Loss: 0.20295493304729462
train-epoch-step: 69-542 -- Loss: 0.21631792187690735
train-epoch-step: 69-543 -- Loss: 0.16163384914398193
train-epoch-step: 69-544 -- Loss: 0.22019772231578827
train-epoch-step: 69-545 -- Loss: 0.19018174707889557
train-epoch-step: 69-546 -- Loss: 0.204105943441391
train-epoch-step: 69-547 -- Loss: 0.17258106172084808
train-epoch-step: 69-548 -- Loss: 0.08802683651447296
train-epoch-step: 69-549 -- Loss: 0.14620499312877655
train-epoch-step: 69-550 -- Loss: 0.19230248034000397
train-epoch-step: 69-551 -- Loss: 0.1458616703748703
train-epoch-step: 69-552 -- Loss: 0.11905255913734436
train-epoch-step: 69-553 -- Loss: 0.18100228905677795
train-epoch-step: 69-554 -- Loss: 0.17860394716262817
train-epoch-step: 69-555 -- Loss: 0.20016887784004211
train-epoch-step: 69-556 -- Loss: 0.13802103698253632
train-epoch-step: 69-557 -- Loss: 0.22013646364212036
train-epoch-step: 69-558 -- Loss: 0.22145098447799683
train-epoch-step: 69-559 -- Loss: 0.13311772048473358
train-epoch-step: 69-560 -- Loss: 0.20259223878383636
train-epoch-step: 69-561 -- Loss: 0.1637597233057022
train-epoch-step: 69-562 -- Loss: 0.15699805319309235
train-epoch-step: 69-563 -- Loss: 0.18423748016357422
train-epoch-step: 69-564 -- Loss: 0.09664372354745865
train-epoch-step: 69-565 -- Loss: 0.17968447506427765
train-epoch-step: 69-566 -- Loss: 0.14515218138694763
train-epoch-step: 69-567 -- Loss: 0.2012786865234375
train-epoch-step: 69-568 -- Loss: 0.1546039879322052
train-epoch-step: 69-569 -- Loss: 0.23611415922641754
train-epoch-step: 69-570 -- Loss: 0.1635299175977707
train-epoch-step: 69-571 -- Loss: 0.19951552152633667
train-epoch-step: 69-572 -- Loss: 0.22868576645851135
train-epoch-step: 69-573 -- Loss: 0.18781226873397827
train-epoch-step: 69-574 -- Loss: 0.23395755887031555
train-epoch-step: 69-575 -- Loss: 0.28167757391929626
train-epoch-step: 69-576 -- Loss: 0.11347942799329758
train-epoch-step: 69-577 -- Loss: 0.16043585538864136
train-epoch-step: 69-578 -- Loss: 0.20273490250110626
train-epoch-step: 69-579 -- Loss: 0.16059711575508118
train-epoch-step: 69-580 -- Loss: 0.1649141013622284
train-epoch-step: 69-581 -- Loss: 0.13838252425193787
train-epoch-step: 69-582 -- Loss: 0.1990049034357071
train-epoch-step: 69-583 -- Loss: 0.19838698208332062
train-epoch-step: 69-584 -- Loss: 0.15981805324554443
train-epoch-step: 69-585 -- Loss: 0.18584173917770386
train-epoch-step: 69-586 -- Loss: 0.24607279896736145
train-epoch-step: 69-587 -- Loss: 0.1492280811071396
train-epoch-step: 69-588 -- Loss: 0.1228322833776474
val-epoch-step: 69-589 -- Loss: 0.20854656398296356
val-epoch-step: 69-590 -- Loss: 0.1536095291376114
val-epoch-step: 69-591 -- Loss: 0.23403239250183105
val-epoch-step: 69-592 -- Loss: 0.17327864468097687
val-epoch-step: 69-593 -- Loss: 0.155278280377388
val-epoch-step: 69-594 -- Loss: 0.3994963765144348
val-epoch-step: 69-595 -- Loss: 0.17616504430770874
val-epoch-step: 69-596 -- Loss: 0.20350076258182526
val-epoch-step: 69-597 -- Loss: 0.17071188986301422
val-epoch-step: 69-598 -- Loss: 0.16301915049552917
val-epoch-step: 69-599 -- Loss: 0.18445461988449097
val-epoch-step: 69-600 -- Loss: 0.16429822146892548
val-epoch-step: 69-601 -- Loss: 0.1531982123851776
val-epoch-step: 69-602 -- Loss: 0.13371412456035614
val-epoch-step: 69-603 -- Loss: 0.19651272892951965
val-epoch-step: 69-604 -- Loss: 0.15018343925476074
val-epoch-step: 69-605 -- Loss: 0.14165665209293365
val-epoch-step: 69-606 -- Loss: 0.2542526423931122
val-epoch-step: 69-607 -- Loss: 0.12463270127773285
val-epoch-step: 69-608 -- Loss: 0.24681729078292847
val-epoch-step: 69-609 -- Loss: 0.1603088527917862
val-epoch-step: 69-610 -- Loss: 0.1761290729045868
val-epoch-step: 69-611 -- Loss: 0.17186804115772247
val-epoch-step: 69-612 -- Loss: 0.39423468708992004
val-epoch-step: 69-613 -- Loss: 0.17201164364814758
val-epoch-step: 69-614 -- Loss: 0.16392287611961365
val-epoch-step: 69-615 -- Loss: 0.17280074954032898
val-epoch-step: 69-616 -- Loss: 0.1544627547264099
val-epoch-step: 69-617 -- Loss: 0.18908335268497467
val-epoch-step: 69-618 -- Loss: 0.18644404411315918
val-epoch-step: 69-619 -- Loss: 0.20108748972415924
val-epoch-step: 69-620 -- Loss: 0.14048081636428833
val-epoch-step: 69-621 -- Loss: 0.12317796051502228
val-epoch-step: 69-622 -- Loss: 0.13780102133750916
val-epoch-step: 69-623 -- Loss: 0.14668357372283936
val-epoch-step: 69-624 -- Loss: 0.1375458538532257
val-epoch-step: 69-625 -- Loss: 0.16862481832504272
val-epoch-step: 69-626 -- Loss: 0.1455773115158081
val-epoch-step: 69-627 -- Loss: 0.17884451150894165
val-epoch-step: 69-628 -- Loss: 0.7496340274810791
val-epoch-step: 69-629 -- Loss: 0.19505420327186584
val-epoch-step: 69-630 -- Loss: 0.33412015438079834
val-epoch-step: 69-631 -- Loss: 0.13815154135227203
val-epoch-step: 69-632 -- Loss: 0.1915709376335144
val-epoch-step: 69-633 -- Loss: 0.14684706926345825
val-epoch-step: 69-634 -- Loss: 0.15819257497787476
val-epoch-step: 69-635 -- Loss: 0.11201848834753036
val-epoch-step: 69-636 -- Loss: 0.16748493909835815
val-epoch-step: 69-637 -- Loss: 0.17817655205726624
val-epoch-step: 69-638 -- Loss: 0.153408020734787
val-epoch-step: 69-639 -- Loss: 0.255576491355896
val-epoch-step: 69-640 -- Loss: 0.2421998530626297
val-epoch-step: 69-641 -- Loss: 0.13882145285606384
val-epoch-step: 69-642 -- Loss: 0.1921413391828537
val-epoch-step: 69-643 -- Loss: 0.20063510537147522
val-epoch-step: 69-644 -- Loss: 0.16104508936405182
val-epoch-step: 69-645 -- Loss: 0.2238379418849945
val-epoch-step: 69-646 -- Loss: 0.1310199797153473
val-epoch-step: 69-647 -- Loss: 0.12941308319568634
val-epoch-step: 69-648 -- Loss: 0.15172702074050903
val-epoch-step: 69-649 -- Loss: 0.19792598485946655
val-epoch-step: 69-650 -- Loss: 0.25063905119895935
val-epoch-step: 69-651 -- Loss: 0.1441056728363037
val-epoch-step: 69-652 -- Loss: 0.15540875494480133
val-epoch-step: 69-653 -- Loss: 0.2216106504201889
val-epoch-step: 69-654 -- Loss: 0.1115616038441658
Epoch: 69 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 70-0 -- Loss: 0.21787232160568237
train-epoch-step: 70-1 -- Loss: 0.14304709434509277
train-epoch-step: 70-2 -- Loss: 0.1913454234600067
train-epoch-step: 70-3 -- Loss: 0.1379144787788391
train-epoch-step: 70-4 -- Loss: 0.15287654101848602
train-epoch-step: 70-5 -- Loss: 0.16915324330329895
train-epoch-step: 70-6 -- Loss: 0.20993539690971375
train-epoch-step: 70-7 -- Loss: 0.15963608026504517
train-epoch-step: 70-8 -- Loss: 0.18558287620544434
train-epoch-step: 70-9 -- Loss: 0.21629877388477325
train-epoch-step: 70-10 -- Loss: 0.17893445491790771
train-epoch-step: 70-11 -- Loss: 0.16886265575885773
train-epoch-step: 70-12 -- Loss: 0.14292550086975098
train-epoch-step: 70-13 -- Loss: 0.17251703143119812
train-epoch-step: 70-14 -- Loss: 0.16226474940776825
train-epoch-step: 70-15 -- Loss: 0.15739892423152924
train-epoch-step: 70-16 -- Loss: 0.15522728860378265
train-epoch-step: 70-17 -- Loss: 0.20422819256782532
train-epoch-step: 70-18 -- Loss: 0.20324820280075073
train-epoch-step: 70-19 -- Loss: 0.12776672840118408
train-epoch-step: 70-20 -- Loss: 0.20562781393527985
train-epoch-step: 70-21 -- Loss: 0.2367543876171112
train-epoch-step: 70-22 -- Loss: 0.13374686241149902
train-epoch-step: 70-23 -- Loss: 0.13798515498638153
train-epoch-step: 70-24 -- Loss: 0.12235335260629654
train-epoch-step: 70-25 -- Loss: 0.2179366797208786
train-epoch-step: 70-26 -- Loss: 0.18549439311027527
train-epoch-step: 70-27 -- Loss: 0.2179614007472992
train-epoch-step: 70-28 -- Loss: 0.11926884949207306
train-epoch-step: 70-29 -- Loss: 0.23025083541870117
train-epoch-step: 70-30 -- Loss: 0.10525877773761749
train-epoch-step: 70-31 -- Loss: 0.12970054149627686
train-epoch-step: 70-32 -- Loss: 0.17259013652801514
train-epoch-step: 70-33 -- Loss: 0.2629396915435791
train-epoch-step: 70-34 -- Loss: 0.1650719940662384
train-epoch-step: 70-35 -- Loss: 0.23195959627628326
train-epoch-step: 70-36 -- Loss: 0.13052508234977722
train-epoch-step: 70-37 -- Loss: 0.13126766681671143
train-epoch-step: 70-38 -- Loss: 0.1715143471956253
train-epoch-step: 70-39 -- Loss: 0.2053336203098297
train-epoch-step: 70-40 -- Loss: 0.18462151288986206
train-epoch-step: 70-41 -- Loss: 0.21248729526996613
train-epoch-step: 70-42 -- Loss: 0.14341357350349426
train-epoch-step: 70-43 -- Loss: 0.2536400854587555
train-epoch-step: 70-44 -- Loss: 0.12075277417898178
train-epoch-step: 70-45 -- Loss: 0.11061955243349075
train-epoch-step: 70-46 -- Loss: 0.15946176648139954
train-epoch-step: 70-47 -- Loss: 0.18503166735172272
train-epoch-step: 70-48 -- Loss: 0.14774516224861145
train-epoch-step: 70-49 -- Loss: 0.21482494473457336
train-epoch-step: 70-50 -- Loss: 0.11455760896205902
train-epoch-step: 70-51 -- Loss: 0.17076806724071503
train-epoch-step: 70-52 -- Loss: 0.15286444127559662
train-epoch-step: 70-53 -- Loss: 0.20393291115760803
train-epoch-step: 70-54 -- Loss: 0.2771531045436859
train-epoch-step: 70-55 -- Loss: 0.1599341183900833
train-epoch-step: 70-56 -- Loss: 0.17056724429130554
train-epoch-step: 70-57 -- Loss: 0.22544142603874207
train-epoch-step: 70-58 -- Loss: 0.27111688256263733
train-epoch-step: 70-59 -- Loss: 0.22069957852363586
train-epoch-step: 70-60 -- Loss: 0.12408514320850372
train-epoch-step: 70-61 -- Loss: 0.18767647445201874
train-epoch-step: 70-62 -- Loss: 0.17553262412548065
train-epoch-step: 70-63 -- Loss: 0.13052266836166382
train-epoch-step: 70-64 -- Loss: 0.13747338950634003
train-epoch-step: 70-65 -- Loss: 0.17045532166957855
train-epoch-step: 70-66 -- Loss: 0.1030689924955368
train-epoch-step: 70-67 -- Loss: 0.1246131956577301
train-epoch-step: 70-68 -- Loss: 0.2062302976846695
train-epoch-step: 70-69 -- Loss: 0.11654220521450043
train-epoch-step: 70-70 -- Loss: 0.2177232801914215
train-epoch-step: 70-71 -- Loss: 0.2505865693092346
train-epoch-step: 70-72 -- Loss: 0.1688353568315506
train-epoch-step: 70-73 -- Loss: 0.2023003250360489
train-epoch-step: 70-74 -- Loss: 0.09393429011106491
train-epoch-step: 70-75 -- Loss: 0.12334435433149338
train-epoch-step: 70-76 -- Loss: 0.14011138677597046
train-epoch-step: 70-77 -- Loss: 0.215975821018219
train-epoch-step: 70-78 -- Loss: 0.25652748346328735
train-epoch-step: 70-79 -- Loss: 0.1827951967716217
train-epoch-step: 70-80 -- Loss: 0.2566458582878113
train-epoch-step: 70-81 -- Loss: 0.11894387006759644
train-epoch-step: 70-82 -- Loss: 0.24596981704235077
train-epoch-step: 70-83 -- Loss: 0.17671918869018555
train-epoch-step: 70-84 -- Loss: 0.1818702518939972
train-epoch-step: 70-85 -- Loss: 0.16927985846996307
train-epoch-step: 70-86 -- Loss: 0.11519993096590042
train-epoch-step: 70-87 -- Loss: 0.1971747875213623
train-epoch-step: 70-88 -- Loss: 0.13601306080818176
train-epoch-step: 70-89 -- Loss: 0.18371456861495972
train-epoch-step: 70-90 -- Loss: 0.18642710149288177
train-epoch-step: 70-91 -- Loss: 0.23531465232372284
train-epoch-step: 70-92 -- Loss: 0.16355761885643005
train-epoch-step: 70-93 -- Loss: 0.16605761647224426
train-epoch-step: 70-94 -- Loss: 0.21327705681324005
train-epoch-step: 70-95 -- Loss: 0.18204230070114136
train-epoch-step: 70-96 -- Loss: 0.20387539267539978
train-epoch-step: 70-97 -- Loss: 0.1723698228597641
train-epoch-step: 70-98 -- Loss: 0.15128105878829956
train-epoch-step: 70-99 -- Loss: 0.17749306559562683
train-epoch-step: 70-100 -- Loss: 0.18326765298843384
train-epoch-step: 70-101 -- Loss: 0.269387423992157
train-epoch-step: 70-102 -- Loss: 0.20712988078594208
train-epoch-step: 70-103 -- Loss: 0.180214986205101
train-epoch-step: 70-104 -- Loss: 0.14406999945640564
train-epoch-step: 70-105 -- Loss: 0.2496069073677063
train-epoch-step: 70-106 -- Loss: 0.17262791097164154
train-epoch-step: 70-107 -- Loss: 0.18529316782951355
train-epoch-step: 70-108 -- Loss: 0.18101291358470917
train-epoch-step: 70-109 -- Loss: 0.14305399358272552
train-epoch-step: 70-110 -- Loss: 0.1907367706298828
train-epoch-step: 70-111 -- Loss: 0.17361204326152802
train-epoch-step: 70-112 -- Loss: 0.16008803248405457
train-epoch-step: 70-113 -- Loss: 0.15752822160720825
train-epoch-step: 70-114 -- Loss: 0.1915549337863922
train-epoch-step: 70-115 -- Loss: 0.1532960832118988
train-epoch-step: 70-116 -- Loss: 0.13365672528743744
train-epoch-step: 70-117 -- Loss: 0.12146607041358948
train-epoch-step: 70-118 -- Loss: 0.18759024143218994
train-epoch-step: 70-119 -- Loss: 0.14368882775306702
train-epoch-step: 70-120 -- Loss: 0.24407246708869934
train-epoch-step: 70-121 -- Loss: 0.2199510633945465
train-epoch-step: 70-122 -- Loss: 0.21372747421264648
train-epoch-step: 70-123 -- Loss: 0.19564956426620483
train-epoch-step: 70-124 -- Loss: 0.1205674409866333
train-epoch-step: 70-125 -- Loss: 0.14782243967056274
train-epoch-step: 70-126 -- Loss: 0.2195042371749878
train-epoch-step: 70-127 -- Loss: 0.16816456615924835
train-epoch-step: 70-128 -- Loss: 0.16696463525295258
train-epoch-step: 70-129 -- Loss: 0.13608679175376892
train-epoch-step: 70-130 -- Loss: 0.19276125729084015
train-epoch-step: 70-131 -- Loss: 0.13572059571743011
train-epoch-step: 70-132 -- Loss: 0.18272289633750916
train-epoch-step: 70-133 -- Loss: 0.11227621138095856
train-epoch-step: 70-134 -- Loss: 0.18697211146354675
train-epoch-step: 70-135 -- Loss: 0.1330721378326416
train-epoch-step: 70-136 -- Loss: 0.12188621610403061
train-epoch-step: 70-137 -- Loss: 0.23323999345302582
train-epoch-step: 70-138 -- Loss: 0.27354997396469116
train-epoch-step: 70-139 -- Loss: 0.12639643251895905
train-epoch-step: 70-140 -- Loss: 0.19813627004623413
train-epoch-step: 70-141 -- Loss: 0.22037121653556824
train-epoch-step: 70-142 -- Loss: 0.20174017548561096
train-epoch-step: 70-143 -- Loss: 0.1639021635055542
train-epoch-step: 70-144 -- Loss: 0.17465318739414215
train-epoch-step: 70-145 -- Loss: 0.1353590041399002
train-epoch-step: 70-146 -- Loss: 0.17278984189033508
train-epoch-step: 70-147 -- Loss: 0.16120463609695435
train-epoch-step: 70-148 -- Loss: 0.15331867337226868
train-epoch-step: 70-149 -- Loss: 0.11773990839719772
train-epoch-step: 70-150 -- Loss: 0.17585612833499908
train-epoch-step: 70-151 -- Loss: 0.18407271802425385
train-epoch-step: 70-152 -- Loss: 0.184170663356781
train-epoch-step: 70-153 -- Loss: 0.2605292797088623
train-epoch-step: 70-154 -- Loss: 0.1237875372171402
train-epoch-step: 70-155 -- Loss: 0.14454716444015503
train-epoch-step: 70-156 -- Loss: 0.11272457987070084
train-epoch-step: 70-157 -- Loss: 0.15850985050201416
train-epoch-step: 70-158 -- Loss: 0.15797695517539978
train-epoch-step: 70-159 -- Loss: 0.17289796471595764
train-epoch-step: 70-160 -- Loss: 0.20109954476356506
train-epoch-step: 70-161 -- Loss: 0.1972309798002243
train-epoch-step: 70-162 -- Loss: 0.19982320070266724
train-epoch-step: 70-163 -- Loss: 0.1824108511209488
train-epoch-step: 70-164 -- Loss: 0.18568719923496246
train-epoch-step: 70-165 -- Loss: 0.15469279885292053
train-epoch-step: 70-166 -- Loss: 0.11665913462638855
train-epoch-step: 70-167 -- Loss: 0.13072969019412994
train-epoch-step: 70-168 -- Loss: 0.19637414813041687
train-epoch-step: 70-169 -- Loss: 0.1342063546180725
train-epoch-step: 70-170 -- Loss: 0.19171632826328278
train-epoch-step: 70-171 -- Loss: 0.14137020707130432
train-epoch-step: 70-172 -- Loss: 0.2512209117412567
train-epoch-step: 70-173 -- Loss: 0.13027548789978027
train-epoch-step: 70-174 -- Loss: 0.24421623349189758
train-epoch-step: 70-175 -- Loss: 0.1813233643770218
train-epoch-step: 70-176 -- Loss: 0.12472221255302429
train-epoch-step: 70-177 -- Loss: 0.18059967458248138
train-epoch-step: 70-178 -- Loss: 0.17128336429595947
train-epoch-step: 70-179 -- Loss: 0.1406959444284439
train-epoch-step: 70-180 -- Loss: 0.14749212563037872
train-epoch-step: 70-181 -- Loss: 0.16318410634994507
train-epoch-step: 70-182 -- Loss: 0.18099915981292725
train-epoch-step: 70-183 -- Loss: 0.2582074999809265
train-epoch-step: 70-184 -- Loss: 0.13508959114551544
train-epoch-step: 70-185 -- Loss: 0.13976606726646423
train-epoch-step: 70-186 -- Loss: 0.18561206758022308
train-epoch-step: 70-187 -- Loss: 0.2017650306224823
train-epoch-step: 70-188 -- Loss: 0.16746580600738525
train-epoch-step: 70-189 -- Loss: 0.1036863625049591
train-epoch-step: 70-190 -- Loss: 0.17714357376098633
train-epoch-step: 70-191 -- Loss: 0.161371111869812
train-epoch-step: 70-192 -- Loss: 0.22510822117328644
train-epoch-step: 70-193 -- Loss: 0.19873350858688354
train-epoch-step: 70-194 -- Loss: 0.17615127563476562
train-epoch-step: 70-195 -- Loss: 0.15924659371376038
train-epoch-step: 70-196 -- Loss: 0.16387592256069183
train-epoch-step: 70-197 -- Loss: 0.12236693501472473
train-epoch-step: 70-198 -- Loss: 0.12845468521118164
train-epoch-step: 70-199 -- Loss: 0.14067864418029785
train-epoch-step: 70-200 -- Loss: 0.12028305232524872
train-epoch-step: 70-201 -- Loss: 0.1798671931028366
train-epoch-step: 70-202 -- Loss: 0.1360560804605484
train-epoch-step: 70-203 -- Loss: 0.1656654328107834
train-epoch-step: 70-204 -- Loss: 0.12726204097270966
train-epoch-step: 70-205 -- Loss: 0.18000343441963196
train-epoch-step: 70-206 -- Loss: 0.1955878734588623
train-epoch-step: 70-207 -- Loss: 0.1325225979089737
train-epoch-step: 70-208 -- Loss: 0.17163100838661194
train-epoch-step: 70-209 -- Loss: 0.13936811685562134
train-epoch-step: 70-210 -- Loss: 0.13032306730747223
train-epoch-step: 70-211 -- Loss: 0.1990741789340973
train-epoch-step: 70-212 -- Loss: 0.19117824733257294
train-epoch-step: 70-213 -- Loss: 0.12496046721935272
train-epoch-step: 70-214 -- Loss: 0.14201964437961578
train-epoch-step: 70-215 -- Loss: 0.12262891232967377
train-epoch-step: 70-216 -- Loss: 0.19396932423114777
train-epoch-step: 70-217 -- Loss: 0.20460939407348633
train-epoch-step: 70-218 -- Loss: 0.13707861304283142
train-epoch-step: 70-219 -- Loss: 0.16228635609149933
train-epoch-step: 70-220 -- Loss: 0.12433204054832458
train-epoch-step: 70-221 -- Loss: 0.19590085744857788
train-epoch-step: 70-222 -- Loss: 0.11356652528047562
train-epoch-step: 70-223 -- Loss: 0.16481025516986847
train-epoch-step: 70-224 -- Loss: 0.1811622679233551
train-epoch-step: 70-225 -- Loss: 0.2533678114414215
train-epoch-step: 70-226 -- Loss: 0.19982074201107025
train-epoch-step: 70-227 -- Loss: 0.21159423887729645
train-epoch-step: 70-228 -- Loss: 0.17108501493930817
train-epoch-step: 70-229 -- Loss: 0.16484031081199646
train-epoch-step: 70-230 -- Loss: 0.1602640450000763
train-epoch-step: 70-231 -- Loss: 0.14925503730773926
train-epoch-step: 70-232 -- Loss: 0.17669159173965454
train-epoch-step: 70-233 -- Loss: 0.07942796498537064
train-epoch-step: 70-234 -- Loss: 0.17505373060703278
train-epoch-step: 70-235 -- Loss: 0.1396668702363968
train-epoch-step: 70-236 -- Loss: 0.17320948839187622
train-epoch-step: 70-237 -- Loss: 0.22595864534378052
train-epoch-step: 70-238 -- Loss: 0.14971917867660522
train-epoch-step: 70-239 -- Loss: 0.1211695522069931
train-epoch-step: 70-240 -- Loss: 0.21210262179374695
train-epoch-step: 70-241 -- Loss: 0.1532103717327118
train-epoch-step: 70-242 -- Loss: 0.21029621362686157
train-epoch-step: 70-243 -- Loss: 0.23311205208301544
train-epoch-step: 70-244 -- Loss: 0.20084695518016815
train-epoch-step: 70-245 -- Loss: 0.1969739943742752
train-epoch-step: 70-246 -- Loss: 0.20887041091918945
train-epoch-step: 70-247 -- Loss: 0.2057247757911682
train-epoch-step: 70-248 -- Loss: 0.1777413785457611
train-epoch-step: 70-249 -- Loss: 0.13856184482574463
train-epoch-step: 70-250 -- Loss: 0.1879316121339798
train-epoch-step: 70-251 -- Loss: 0.10569946467876434
train-epoch-step: 70-252 -- Loss: 0.1904100775718689
train-epoch-step: 70-253 -- Loss: 0.1348586529493332
train-epoch-step: 70-254 -- Loss: 0.2060684859752655
train-epoch-step: 70-255 -- Loss: 0.13789081573486328
train-epoch-step: 70-256 -- Loss: 0.14681938290596008
train-epoch-step: 70-257 -- Loss: 0.18015843629837036
train-epoch-step: 70-258 -- Loss: 0.14132413268089294
train-epoch-step: 70-259 -- Loss: 0.10762961208820343
train-epoch-step: 70-260 -- Loss: 0.2059553563594818
train-epoch-step: 70-261 -- Loss: 0.17088481783866882
train-epoch-step: 70-262 -- Loss: 0.27795863151550293
train-epoch-step: 70-263 -- Loss: 0.19406305253505707
train-epoch-step: 70-264 -- Loss: 0.17152343690395355
train-epoch-step: 70-265 -- Loss: 0.10600546002388
train-epoch-step: 70-266 -- Loss: 0.15270306169986725
train-epoch-step: 70-267 -- Loss: 0.1250905841588974
train-epoch-step: 70-268 -- Loss: 0.11401093006134033
train-epoch-step: 70-269 -- Loss: 0.16444438695907593
train-epoch-step: 70-270 -- Loss: 0.1038229912519455
train-epoch-step: 70-271 -- Loss: 0.1453302502632141
train-epoch-step: 70-272 -- Loss: 0.11276684701442719
train-epoch-step: 70-273 -- Loss: 0.12587283551692963
train-epoch-step: 70-274 -- Loss: 0.17870497703552246
train-epoch-step: 70-275 -- Loss: 0.18644987046718597
train-epoch-step: 70-276 -- Loss: 0.15026050806045532
train-epoch-step: 70-277 -- Loss: 0.15177428722381592
train-epoch-step: 70-278 -- Loss: 0.13512949645519257
train-epoch-step: 70-279 -- Loss: 0.1354430615901947
train-epoch-step: 70-280 -- Loss: 0.2083711326122284
train-epoch-step: 70-281 -- Loss: 0.17378239333629608
train-epoch-step: 70-282 -- Loss: 0.13866646587848663
train-epoch-step: 70-283 -- Loss: 0.11164907366037369
train-epoch-step: 70-284 -- Loss: 0.13222144544124603
train-epoch-step: 70-285 -- Loss: 0.1814977377653122
train-epoch-step: 70-286 -- Loss: 0.15166576206684113
train-epoch-step: 70-287 -- Loss: 0.19639109075069427
train-epoch-step: 70-288 -- Loss: 0.09158490598201752
train-epoch-step: 70-289 -- Loss: 0.11515245586633682
train-epoch-step: 70-290 -- Loss: 0.174139603972435
train-epoch-step: 70-291 -- Loss: 0.11418093740940094
train-epoch-step: 70-292 -- Loss: 0.152650386095047
train-epoch-step: 70-293 -- Loss: 0.1340492069721222
train-epoch-step: 70-294 -- Loss: 0.16320151090621948
train-epoch-step: 70-295 -- Loss: 0.2516646981239319
train-epoch-step: 70-296 -- Loss: 0.15277251601219177
train-epoch-step: 70-297 -- Loss: 0.16611401736736298
train-epoch-step: 70-298 -- Loss: 0.22897569835186005
train-epoch-step: 70-299 -- Loss: 0.1395256370306015
train-epoch-step: 70-300 -- Loss: 0.1533471792936325
train-epoch-step: 70-301 -- Loss: 0.165681391954422
train-epoch-step: 70-302 -- Loss: 0.20921196043491364
train-epoch-step: 70-303 -- Loss: 0.20576174557209015
train-epoch-step: 70-304 -- Loss: 0.12378332018852234
train-epoch-step: 70-305 -- Loss: 0.13755355775356293
train-epoch-step: 70-306 -- Loss: 0.21681568026542664
train-epoch-step: 70-307 -- Loss: 0.1594657599925995
train-epoch-step: 70-308 -- Loss: 0.20833826065063477
train-epoch-step: 70-309 -- Loss: 0.1511031985282898
train-epoch-step: 70-310 -- Loss: 0.15369507670402527
train-epoch-step: 70-311 -- Loss: 0.15553979575634003
train-epoch-step: 70-312 -- Loss: 0.19679683446884155
train-epoch-step: 70-313 -- Loss: 0.09505102038383484
train-epoch-step: 70-314 -- Loss: 0.18184663355350494
train-epoch-step: 70-315 -- Loss: 0.16343741118907928
train-epoch-step: 70-316 -- Loss: 0.1459638774394989
train-epoch-step: 70-317 -- Loss: 0.13513587415218353
train-epoch-step: 70-318 -- Loss: 0.16222555935382843
train-epoch-step: 70-319 -- Loss: 0.15915828943252563
train-epoch-step: 70-320 -- Loss: 0.11327564716339111
train-epoch-step: 70-321 -- Loss: 0.12493856996297836
train-epoch-step: 70-322 -- Loss: 0.2054729461669922
train-epoch-step: 70-323 -- Loss: 0.15657120943069458
train-epoch-step: 70-324 -- Loss: 0.2586442232131958
train-epoch-step: 70-325 -- Loss: 0.15067674219608307
train-epoch-step: 70-326 -- Loss: 0.16259652376174927
train-epoch-step: 70-327 -- Loss: 0.20215630531311035
train-epoch-step: 70-328 -- Loss: 0.18746648728847504
train-epoch-step: 70-329 -- Loss: 0.33239102363586426
train-epoch-step: 70-330 -- Loss: 0.3509830832481384
train-epoch-step: 70-331 -- Loss: 0.20135095715522766
train-epoch-step: 70-332 -- Loss: 0.0982024222612381
train-epoch-step: 70-333 -- Loss: 0.1759282648563385
train-epoch-step: 70-334 -- Loss: 0.1504821926355362
train-epoch-step: 70-335 -- Loss: 0.16661758720874786
train-epoch-step: 70-336 -- Loss: 0.15179188549518585
train-epoch-step: 70-337 -- Loss: 0.20043392479419708
train-epoch-step: 70-338 -- Loss: 0.1534661054611206
train-epoch-step: 70-339 -- Loss: 0.1384996473789215
train-epoch-step: 70-340 -- Loss: 0.19638654589653015
train-epoch-step: 70-341 -- Loss: 0.13697275519371033
train-epoch-step: 70-342 -- Loss: 0.1575852930545807
train-epoch-step: 70-343 -- Loss: 0.147971972823143
train-epoch-step: 70-344 -- Loss: 0.15894988179206848
train-epoch-step: 70-345 -- Loss: 0.12125105410814285
train-epoch-step: 70-346 -- Loss: 0.20715518295764923
train-epoch-step: 70-347 -- Loss: 0.14779233932495117
train-epoch-step: 70-348 -- Loss: 0.19605815410614014
train-epoch-step: 70-349 -- Loss: 0.19561226665973663
train-epoch-step: 70-350 -- Loss: 0.24239782989025116
train-epoch-step: 70-351 -- Loss: 0.1836562603712082
train-epoch-step: 70-352 -- Loss: 0.11937659978866577
train-epoch-step: 70-353 -- Loss: 0.18969139456748962
train-epoch-step: 70-354 -- Loss: 0.2703753411769867
train-epoch-step: 70-355 -- Loss: 0.11309923231601715
train-epoch-step: 70-356 -- Loss: 0.11222215741872787
train-epoch-step: 70-357 -- Loss: 0.18281924724578857
train-epoch-step: 70-358 -- Loss: 0.18229572474956512
train-epoch-step: 70-359 -- Loss: 0.1385529786348343
train-epoch-step: 70-360 -- Loss: 0.11845796555280685
train-epoch-step: 70-361 -- Loss: 0.23075398802757263
train-epoch-step: 70-362 -- Loss: 0.16550204157829285
train-epoch-step: 70-363 -- Loss: 0.10461054742336273
train-epoch-step: 70-364 -- Loss: 0.17467820644378662
train-epoch-step: 70-365 -- Loss: 0.16217821836471558
train-epoch-step: 70-366 -- Loss: 0.18716630339622498
train-epoch-step: 70-367 -- Loss: 0.22322723269462585
train-epoch-step: 70-368 -- Loss: 0.18809227645397186
train-epoch-step: 70-369 -- Loss: 0.2668227553367615
train-epoch-step: 70-370 -- Loss: 0.12074552476406097
train-epoch-step: 70-371 -- Loss: 0.11765197664499283
train-epoch-step: 70-372 -- Loss: 0.14180132746696472
train-epoch-step: 70-373 -- Loss: 0.18126311898231506
train-epoch-step: 70-374 -- Loss: 0.1479734480381012
train-epoch-step: 70-375 -- Loss: 0.2566109895706177
train-epoch-step: 70-376 -- Loss: 0.1563180387020111
train-epoch-step: 70-377 -- Loss: 0.2143167406320572
train-epoch-step: 70-378 -- Loss: 0.19001485407352448
train-epoch-step: 70-379 -- Loss: 0.11335573345422745
train-epoch-step: 70-380 -- Loss: 0.08735989034175873
train-epoch-step: 70-381 -- Loss: 0.2340724766254425
train-epoch-step: 70-382 -- Loss: 0.2197820544242859
train-epoch-step: 70-383 -- Loss: 0.1685439795255661
train-epoch-step: 70-384 -- Loss: 0.20417001843452454
train-epoch-step: 70-385 -- Loss: 0.1843181848526001
train-epoch-step: 70-386 -- Loss: 0.1773509681224823
train-epoch-step: 70-387 -- Loss: 0.19215232133865356
train-epoch-step: 70-388 -- Loss: 0.17959515750408173
train-epoch-step: 70-389 -- Loss: 0.16163179278373718
train-epoch-step: 70-390 -- Loss: 0.13624049723148346
train-epoch-step: 70-391 -- Loss: 0.13855008780956268
train-epoch-step: 70-392 -- Loss: 0.17699837684631348
train-epoch-step: 70-393 -- Loss: 0.14833468198776245
train-epoch-step: 70-394 -- Loss: 0.19185316562652588
train-epoch-step: 70-395 -- Loss: 0.15281648933887482
train-epoch-step: 70-396 -- Loss: 0.12237628549337387
train-epoch-step: 70-397 -- Loss: 0.12137403339147568
train-epoch-step: 70-398 -- Loss: 0.18868067860603333
train-epoch-step: 70-399 -- Loss: 0.16686975955963135
train-epoch-step: 70-400 -- Loss: 0.2680070996284485
train-epoch-step: 70-401 -- Loss: 0.11411614716053009
train-epoch-step: 70-402 -- Loss: 0.24181360006332397
train-epoch-step: 70-403 -- Loss: 0.14817513525485992
train-epoch-step: 70-404 -- Loss: 0.1366470605134964
train-epoch-step: 70-405 -- Loss: 0.1348591446876526
train-epoch-step: 70-406 -- Loss: 0.1591542810201645
train-epoch-step: 70-407 -- Loss: 0.10939556360244751
train-epoch-step: 70-408 -- Loss: 0.15638110041618347
train-epoch-step: 70-409 -- Loss: 0.1670176088809967
train-epoch-step: 70-410 -- Loss: 0.16823694109916687
train-epoch-step: 70-411 -- Loss: 0.1885376274585724
train-epoch-step: 70-412 -- Loss: 0.12466549873352051
train-epoch-step: 70-413 -- Loss: 0.1409485787153244
train-epoch-step: 70-414 -- Loss: 0.1272946000099182
train-epoch-step: 70-415 -- Loss: 0.13053277134895325
train-epoch-step: 70-416 -- Loss: 0.25611627101898193
train-epoch-step: 70-417 -- Loss: 0.18078118562698364
train-epoch-step: 70-418 -- Loss: 0.2108159363269806
train-epoch-step: 70-419 -- Loss: 0.16243159770965576
train-epoch-step: 70-420 -- Loss: 0.14771348237991333
train-epoch-step: 70-421 -- Loss: 0.1729312241077423
train-epoch-step: 70-422 -- Loss: 0.14081822335720062
train-epoch-step: 70-423 -- Loss: 0.16406354308128357
train-epoch-step: 70-424 -- Loss: 0.13503466546535492
train-epoch-step: 70-425 -- Loss: 0.17700454592704773
train-epoch-step: 70-426 -- Loss: 0.15790219604969025
train-epoch-step: 70-427 -- Loss: 0.11689011007547379
train-epoch-step: 70-428 -- Loss: 0.1870695948600769
train-epoch-step: 70-429 -- Loss: 0.16897940635681152
train-epoch-step: 70-430 -- Loss: 0.13401421904563904
train-epoch-step: 70-431 -- Loss: 0.15731853246688843
train-epoch-step: 70-432 -- Loss: 0.22749194502830505
train-epoch-step: 70-433 -- Loss: 0.13052798807621002
train-epoch-step: 70-434 -- Loss: 0.12646910548210144
train-epoch-step: 70-435 -- Loss: 0.14693604409694672
train-epoch-step: 70-436 -- Loss: 0.14792904257774353
train-epoch-step: 70-437 -- Loss: 0.12760241329669952
train-epoch-step: 70-438 -- Loss: 0.15996193885803223
train-epoch-step: 70-439 -- Loss: 0.24323542416095734
train-epoch-step: 70-440 -- Loss: 0.1254286915063858
train-epoch-step: 70-441 -- Loss: 0.19056154787540436
train-epoch-step: 70-442 -- Loss: 0.17207187414169312
train-epoch-step: 70-443 -- Loss: 0.15821826457977295
train-epoch-step: 70-444 -- Loss: 0.1701848804950714
train-epoch-step: 70-445 -- Loss: 0.1708974838256836
train-epoch-step: 70-446 -- Loss: 0.14771689474582672
train-epoch-step: 70-447 -- Loss: 0.18120642006397247
train-epoch-step: 70-448 -- Loss: 0.21688950061798096
train-epoch-step: 70-449 -- Loss: 0.18594421446323395
train-epoch-step: 70-450 -- Loss: 0.17553511261940002
train-epoch-step: 70-451 -- Loss: 0.13949686288833618
train-epoch-step: 70-452 -- Loss: 0.126185342669487
train-epoch-step: 70-453 -- Loss: 0.08671366423368454
train-epoch-step: 70-454 -- Loss: 0.2196090817451477
train-epoch-step: 70-455 -- Loss: 0.1155184879899025
train-epoch-step: 70-456 -- Loss: 0.11674699932336807
train-epoch-step: 70-457 -- Loss: 0.20448528230190277
train-epoch-step: 70-458 -- Loss: 0.15568062663078308
train-epoch-step: 70-459 -- Loss: 0.2066430300474167
train-epoch-step: 70-460 -- Loss: 0.12090574204921722
train-epoch-step: 70-461 -- Loss: 0.13087695837020874
train-epoch-step: 70-462 -- Loss: 0.14573334157466888
train-epoch-step: 70-463 -- Loss: 0.13578280806541443
train-epoch-step: 70-464 -- Loss: 0.1544181853532791
train-epoch-step: 70-465 -- Loss: 0.22907724976539612
train-epoch-step: 70-466 -- Loss: 0.19022102653980255
train-epoch-step: 70-467 -- Loss: 0.10749173164367676
train-epoch-step: 70-468 -- Loss: 0.1583537608385086
train-epoch-step: 70-469 -- Loss: 0.20265452563762665
train-epoch-step: 70-470 -- Loss: 0.1641581654548645
train-epoch-step: 70-471 -- Loss: 0.15285220742225647
train-epoch-step: 70-472 -- Loss: 0.14976996183395386
train-epoch-step: 70-473 -- Loss: 0.14688928425312042
train-epoch-step: 70-474 -- Loss: 0.11965112388134003
train-epoch-step: 70-475 -- Loss: 0.10519326478242874
train-epoch-step: 70-476 -- Loss: 0.1884341984987259
train-epoch-step: 70-477 -- Loss: 0.1884249597787857
train-epoch-step: 70-478 -- Loss: 0.1781621128320694
train-epoch-step: 70-479 -- Loss: 0.13276134431362152
train-epoch-step: 70-480 -- Loss: 0.17892572283744812
train-epoch-step: 70-481 -- Loss: 0.2689070403575897
train-epoch-step: 70-482 -- Loss: 0.24188312888145447
train-epoch-step: 70-483 -- Loss: 0.1709473580121994
train-epoch-step: 70-484 -- Loss: 0.2093069702386856
train-epoch-step: 70-485 -- Loss: 0.12030086666345596
train-epoch-step: 70-486 -- Loss: 0.2226160168647766
train-epoch-step: 70-487 -- Loss: 0.22129562497138977
train-epoch-step: 70-488 -- Loss: 0.18006795644760132
train-epoch-step: 70-489 -- Loss: 0.21340133249759674
train-epoch-step: 70-490 -- Loss: 0.1348349004983902
train-epoch-step: 70-491 -- Loss: 0.13487228751182556
train-epoch-step: 70-492 -- Loss: 0.12202191352844238
train-epoch-step: 70-493 -- Loss: 0.19489532709121704
train-epoch-step: 70-494 -- Loss: 0.19187964498996735
train-epoch-step: 70-495 -- Loss: 0.19897469878196716
train-epoch-step: 70-496 -- Loss: 0.1350679099559784
train-epoch-step: 70-497 -- Loss: 0.17520447075366974
train-epoch-step: 70-498 -- Loss: 0.14092902839183807
train-epoch-step: 70-499 -- Loss: 0.16487470269203186
train-epoch-step: 70-500 -- Loss: 0.14871461689472198
train-epoch-step: 70-501 -- Loss: 0.20623253285884857
train-epoch-step: 70-502 -- Loss: 0.15340471267700195
train-epoch-step: 70-503 -- Loss: 0.2249726951122284
train-epoch-step: 70-504 -- Loss: 0.11308366060256958
train-epoch-step: 70-505 -- Loss: 0.1683184653520584
train-epoch-step: 70-506 -- Loss: 0.11045606434345245
train-epoch-step: 70-507 -- Loss: 0.17220807075500488
train-epoch-step: 70-508 -- Loss: 0.16626062989234924
train-epoch-step: 70-509 -- Loss: 0.16278918087482452
train-epoch-step: 70-510 -- Loss: 0.12292525917291641
train-epoch-step: 70-511 -- Loss: 0.21028439700603485
train-epoch-step: 70-512 -- Loss: 0.16736118495464325
train-epoch-step: 70-513 -- Loss: 0.17433756589889526
train-epoch-step: 70-514 -- Loss: 0.13671720027923584
train-epoch-step: 70-515 -- Loss: 0.14751970767974854
train-epoch-step: 70-516 -- Loss: 0.16891254484653473
train-epoch-step: 70-517 -- Loss: 0.16599583625793457
train-epoch-step: 70-518 -- Loss: 0.13357311487197876
train-epoch-step: 70-519 -- Loss: 0.13018903136253357
train-epoch-step: 70-520 -- Loss: 0.1790391355752945
train-epoch-step: 70-521 -- Loss: 0.22040313482284546
train-epoch-step: 70-522 -- Loss: 0.16649554669857025
train-epoch-step: 70-523 -- Loss: 0.15295888483524323
train-epoch-step: 70-524 -- Loss: 0.1630302369594574
train-epoch-step: 70-525 -- Loss: 0.1857781708240509
train-epoch-step: 70-526 -- Loss: 0.1260390281677246
train-epoch-step: 70-527 -- Loss: 0.1501169502735138
train-epoch-step: 70-528 -- Loss: 0.1487630009651184
train-epoch-step: 70-529 -- Loss: 0.15032580494880676
train-epoch-step: 70-530 -- Loss: 0.1617441475391388
train-epoch-step: 70-531 -- Loss: 0.19104482233524323
train-epoch-step: 70-532 -- Loss: 0.16191521286964417
train-epoch-step: 70-533 -- Loss: 0.1683647632598877
train-epoch-step: 70-534 -- Loss: 0.12705957889556885
train-epoch-step: 70-535 -- Loss: 0.24473287165164948
train-epoch-step: 70-536 -- Loss: 0.1539108008146286
train-epoch-step: 70-537 -- Loss: 0.14920705556869507
train-epoch-step: 70-538 -- Loss: 0.09770013391971588
train-epoch-step: 70-539 -- Loss: 0.17305345833301544
train-epoch-step: 70-540 -- Loss: 0.1326589584350586
train-epoch-step: 70-541 -- Loss: 0.20221462845802307
train-epoch-step: 70-542 -- Loss: 0.2113947868347168
train-epoch-step: 70-543 -- Loss: 0.16654899716377258
train-epoch-step: 70-544 -- Loss: 0.21864649653434753
train-epoch-step: 70-545 -- Loss: 0.2014329731464386
train-epoch-step: 70-546 -- Loss: 0.20080538094043732
train-epoch-step: 70-547 -- Loss: 0.1786923110485077
train-epoch-step: 70-548 -- Loss: 0.09025686234235764
train-epoch-step: 70-549 -- Loss: 0.14224198460578918
train-epoch-step: 70-550 -- Loss: 0.19213029742240906
train-epoch-step: 70-551 -- Loss: 0.15013645589351654
train-epoch-step: 70-552 -- Loss: 0.12111379206180573
train-epoch-step: 70-553 -- Loss: 0.180568128824234
train-epoch-step: 70-554 -- Loss: 0.19024306535720825
train-epoch-step: 70-555 -- Loss: 0.21249842643737793
train-epoch-step: 70-556 -- Loss: 0.1385369896888733
train-epoch-step: 70-557 -- Loss: 0.22822526097297668
train-epoch-step: 70-558 -- Loss: 0.2124866396188736
train-epoch-step: 70-559 -- Loss: 0.1308731883764267
train-epoch-step: 70-560 -- Loss: 0.19599977135658264
train-epoch-step: 70-561 -- Loss: 0.16469022631645203
train-epoch-step: 70-562 -- Loss: 0.15210045874118805
train-epoch-step: 70-563 -- Loss: 0.17906279861927032
train-epoch-step: 70-564 -- Loss: 0.09720128774642944
train-epoch-step: 70-565 -- Loss: 0.1759708672761917
train-epoch-step: 70-566 -- Loss: 0.1489233672618866
train-epoch-step: 70-567 -- Loss: 0.20462313294410706
train-epoch-step: 70-568 -- Loss: 0.15343955159187317
train-epoch-step: 70-569 -- Loss: 0.23787301778793335
train-epoch-step: 70-570 -- Loss: 0.1556999385356903
train-epoch-step: 70-571 -- Loss: 0.20187436044216156
train-epoch-step: 70-572 -- Loss: 0.2304975390434265
train-epoch-step: 70-573 -- Loss: 0.18926462531089783
train-epoch-step: 70-574 -- Loss: 0.23819182813167572
train-epoch-step: 70-575 -- Loss: 0.28099191188812256
train-epoch-step: 70-576 -- Loss: 0.11215861886739731
train-epoch-step: 70-577 -- Loss: 0.1583077758550644
train-epoch-step: 70-578 -- Loss: 0.21110360324382782
train-epoch-step: 70-579 -- Loss: 0.15956540405750275
train-epoch-step: 70-580 -- Loss: 0.16737741231918335
train-epoch-step: 70-581 -- Loss: 0.1337357610464096
train-epoch-step: 70-582 -- Loss: 0.20262238383293152
train-epoch-step: 70-583 -- Loss: 0.20337709784507751
train-epoch-step: 70-584 -- Loss: 0.15908274054527283
train-epoch-step: 70-585 -- Loss: 0.1928258240222931
train-epoch-step: 70-586 -- Loss: 0.24498572945594788
train-epoch-step: 70-587 -- Loss: 0.15674136579036713
train-epoch-step: 70-588 -- Loss: 0.12340021133422852
val-epoch-step: 70-589 -- Loss: 0.20345401763916016
val-epoch-step: 70-590 -- Loss: 0.15377406775951385
val-epoch-step: 70-591 -- Loss: 0.22471299767494202
val-epoch-step: 70-592 -- Loss: 0.16992732882499695
val-epoch-step: 70-593 -- Loss: 0.16422758996486664
val-epoch-step: 70-594 -- Loss: 0.33718425035476685
val-epoch-step: 70-595 -- Loss: 0.17729859054088593
val-epoch-step: 70-596 -- Loss: 0.1882026642560959
val-epoch-step: 70-597 -- Loss: 0.17052216827869415
val-epoch-step: 70-598 -- Loss: 0.14351794123649597
val-epoch-step: 70-599 -- Loss: 0.17922355234622955
val-epoch-step: 70-600 -- Loss: 0.19812949001789093
val-epoch-step: 70-601 -- Loss: 0.1599772870540619
val-epoch-step: 70-602 -- Loss: 0.1332058608531952
val-epoch-step: 70-603 -- Loss: 0.21719664335250854
val-epoch-step: 70-604 -- Loss: 0.14138048887252808
val-epoch-step: 70-605 -- Loss: 0.14108283817768097
val-epoch-step: 70-606 -- Loss: 0.24037721753120422
val-epoch-step: 70-607 -- Loss: 0.11894309520721436
val-epoch-step: 70-608 -- Loss: 0.23856383562088013
val-epoch-step: 70-609 -- Loss: 0.1612883359193802
val-epoch-step: 70-610 -- Loss: 0.17414407432079315
val-epoch-step: 70-611 -- Loss: 0.15527033805847168
val-epoch-step: 70-612 -- Loss: 0.34946364164352417
val-epoch-step: 70-613 -- Loss: 0.16924616694450378
val-epoch-step: 70-614 -- Loss: 0.1632043868303299
val-epoch-step: 70-615 -- Loss: 0.17440377175807953
val-epoch-step: 70-616 -- Loss: 0.14279109239578247
val-epoch-step: 70-617 -- Loss: 0.1887785941362381
val-epoch-step: 70-618 -- Loss: 0.1671682745218277
val-epoch-step: 70-619 -- Loss: 0.20251771807670593
val-epoch-step: 70-620 -- Loss: 0.14239618182182312
val-epoch-step: 70-621 -- Loss: 0.12019307166337967
val-epoch-step: 70-622 -- Loss: 0.14519500732421875
val-epoch-step: 70-623 -- Loss: 0.14700722694396973
val-epoch-step: 70-624 -- Loss: 0.13771384954452515
val-epoch-step: 70-625 -- Loss: 0.15803074836730957
val-epoch-step: 70-626 -- Loss: 0.14220501482486725
val-epoch-step: 70-627 -- Loss: 0.17805880308151245
val-epoch-step: 70-628 -- Loss: 0.7138416767120361
val-epoch-step: 70-629 -- Loss: 0.17893828451633453
val-epoch-step: 70-630 -- Loss: 0.32758045196533203
val-epoch-step: 70-631 -- Loss: 0.13952000439167023
val-epoch-step: 70-632 -- Loss: 0.19115982949733734
val-epoch-step: 70-633 -- Loss: 0.1529519259929657
val-epoch-step: 70-634 -- Loss: 0.1537339687347412
val-epoch-step: 70-635 -- Loss: 0.11363188922405243
val-epoch-step: 70-636 -- Loss: 0.1591828614473343
val-epoch-step: 70-637 -- Loss: 0.17533913254737854
val-epoch-step: 70-638 -- Loss: 0.14605900645256042
val-epoch-step: 70-639 -- Loss: 0.29120415449142456
val-epoch-step: 70-640 -- Loss: 0.2487754225730896
val-epoch-step: 70-641 -- Loss: 0.12430311739444733
val-epoch-step: 70-642 -- Loss: 0.18084214627742767
val-epoch-step: 70-643 -- Loss: 0.19572219252586365
val-epoch-step: 70-644 -- Loss: 0.17058447003364563
val-epoch-step: 70-645 -- Loss: 0.21837985515594482
val-epoch-step: 70-646 -- Loss: 0.13658931851387024
val-epoch-step: 70-647 -- Loss: 0.12898710370063782
val-epoch-step: 70-648 -- Loss: 0.15110012888908386
val-epoch-step: 70-649 -- Loss: 0.20401492714881897
val-epoch-step: 70-650 -- Loss: 0.2487776279449463
val-epoch-step: 70-651 -- Loss: 0.14500007033348083
val-epoch-step: 70-652 -- Loss: 0.15070241689682007
val-epoch-step: 70-653 -- Loss: 0.19997143745422363
val-epoch-step: 70-654 -- Loss: 0.11197550594806671
Epoch: 70 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.64 -- Val Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.64
                         Test Loss: 0.0 -- Test Acc: 75.64
train-epoch-step: 71-0 -- Loss: 0.2192608267068863
train-epoch-step: 71-1 -- Loss: 0.13893729448318481
train-epoch-step: 71-2 -- Loss: 0.19211062788963318
train-epoch-step: 71-3 -- Loss: 0.1387186348438263
train-epoch-step: 71-4 -- Loss: 0.154378741979599
train-epoch-step: 71-5 -- Loss: 0.17266026139259338
train-epoch-step: 71-6 -- Loss: 0.20433104038238525
train-epoch-step: 71-7 -- Loss: 0.16162754595279694
train-epoch-step: 71-8 -- Loss: 0.17271780967712402
train-epoch-step: 71-9 -- Loss: 0.21660290658473969
train-epoch-step: 71-10 -- Loss: 0.17694324254989624
train-epoch-step: 71-11 -- Loss: 0.16886714100837708
train-epoch-step: 71-12 -- Loss: 0.14579255878925323
train-epoch-step: 71-13 -- Loss: 0.1724744588136673
train-epoch-step: 71-14 -- Loss: 0.15640313923358917
train-epoch-step: 71-15 -- Loss: 0.16027197241783142
train-epoch-step: 71-16 -- Loss: 0.16096004843711853
train-epoch-step: 71-17 -- Loss: 0.20667891204357147
train-epoch-step: 71-18 -- Loss: 0.18979734182357788
train-epoch-step: 71-19 -- Loss: 0.13579444587230682
train-epoch-step: 71-20 -- Loss: 0.2138846069574356
train-epoch-step: 71-21 -- Loss: 0.23906828463077545
train-epoch-step: 71-22 -- Loss: 0.13630253076553345
train-epoch-step: 71-23 -- Loss: 0.13739445805549622
train-epoch-step: 71-24 -- Loss: 0.11968318372964859
train-epoch-step: 71-25 -- Loss: 0.21591591835021973
train-epoch-step: 71-26 -- Loss: 0.18328163027763367
train-epoch-step: 71-27 -- Loss: 0.2179582715034485
train-epoch-step: 71-28 -- Loss: 0.1195225864648819
train-epoch-step: 71-29 -- Loss: 0.22799152135849
train-epoch-step: 71-30 -- Loss: 0.10612019896507263
train-epoch-step: 71-31 -- Loss: 0.1315353810787201
train-epoch-step: 71-32 -- Loss: 0.17676803469657898
train-epoch-step: 71-33 -- Loss: 0.26171138882637024
train-epoch-step: 71-34 -- Loss: 0.16584059596061707
train-epoch-step: 71-35 -- Loss: 0.23560841381549835
train-epoch-step: 71-36 -- Loss: 0.13321706652641296
train-epoch-step: 71-37 -- Loss: 0.12956678867340088
train-epoch-step: 71-38 -- Loss: 0.22087588906288147
train-epoch-step: 71-39 -- Loss: 0.20886553823947906
train-epoch-step: 71-40 -- Loss: 0.19054782390594482
train-epoch-step: 71-41 -- Loss: 0.2161489576101303
train-epoch-step: 71-42 -- Loss: 0.14602839946746826
train-epoch-step: 71-43 -- Loss: 0.25683751702308655
train-epoch-step: 71-44 -- Loss: 0.13135942816734314
train-epoch-step: 71-45 -- Loss: 0.11927181482315063
train-epoch-step: 71-46 -- Loss: 0.2001432478427887
train-epoch-step: 71-47 -- Loss: 0.2028135508298874
train-epoch-step: 71-48 -- Loss: 0.1589333713054657
train-epoch-step: 71-49 -- Loss: 0.24593809247016907
train-epoch-step: 71-50 -- Loss: 0.11310403048992157
train-epoch-step: 71-51 -- Loss: 0.22597211599349976
train-epoch-step: 71-52 -- Loss: 0.15169361233711243
train-epoch-step: 71-53 -- Loss: 0.21177248656749725
train-epoch-step: 71-54 -- Loss: 0.32319480180740356
train-epoch-step: 71-55 -- Loss: 0.16984102129936218
train-epoch-step: 71-56 -- Loss: 0.18454161286354065
train-epoch-step: 71-57 -- Loss: 0.2366192787885666
train-epoch-step: 71-58 -- Loss: 0.2845045030117035
train-epoch-step: 71-59 -- Loss: 0.2999955415725708
train-epoch-step: 71-60 -- Loss: 0.13591445982456207
train-epoch-step: 71-61 -- Loss: 0.21325156092643738
train-epoch-step: 71-62 -- Loss: 0.19821110367774963
train-epoch-step: 71-63 -- Loss: 0.14073780179023743
train-epoch-step: 71-64 -- Loss: 0.1423797756433487
train-epoch-step: 71-65 -- Loss: 0.1758050173521042
train-epoch-step: 71-66 -- Loss: 0.10714839398860931
train-epoch-step: 71-67 -- Loss: 0.13836988806724548
train-epoch-step: 71-68 -- Loss: 0.20704329013824463
train-epoch-step: 71-69 -- Loss: 0.12241922318935394
train-epoch-step: 71-70 -- Loss: 0.2235180139541626
train-epoch-step: 71-71 -- Loss: 0.26351356506347656
train-epoch-step: 71-72 -- Loss: 0.16986672580242157
train-epoch-step: 71-73 -- Loss: 0.23059266805648804
train-epoch-step: 71-74 -- Loss: 0.0960538238286972
train-epoch-step: 71-75 -- Loss: 0.12758415937423706
train-epoch-step: 71-76 -- Loss: 0.14248347282409668
train-epoch-step: 71-77 -- Loss: 0.22107894718647003
train-epoch-step: 71-78 -- Loss: 0.2563893795013428
train-epoch-step: 71-79 -- Loss: 0.18607041239738464
train-epoch-step: 71-80 -- Loss: 0.252032995223999
train-epoch-step: 71-81 -- Loss: 0.11961635947227478
train-epoch-step: 71-82 -- Loss: 0.2476653754711151
train-epoch-step: 71-83 -- Loss: 0.17480376362800598
train-epoch-step: 71-84 -- Loss: 0.18553346395492554
train-epoch-step: 71-85 -- Loss: 0.17395253479480743
train-epoch-step: 71-86 -- Loss: 0.12058530747890472
train-epoch-step: 71-87 -- Loss: 0.20470251142978668
train-epoch-step: 71-88 -- Loss: 0.13561272621154785
train-epoch-step: 71-89 -- Loss: 0.20549927651882172
train-epoch-step: 71-90 -- Loss: 0.18811364471912384
train-epoch-step: 71-91 -- Loss: 0.2376578152179718
train-epoch-step: 71-92 -- Loss: 0.15316003561019897
train-epoch-step: 71-93 -- Loss: 0.17723290622234344
train-epoch-step: 71-94 -- Loss: 0.21312406659126282
train-epoch-step: 71-95 -- Loss: 0.1874496340751648
train-epoch-step: 71-96 -- Loss: 0.21344859898090363
train-epoch-step: 71-97 -- Loss: 0.1801864355802536
train-epoch-step: 71-98 -- Loss: 0.15164139866828918
train-epoch-step: 71-99 -- Loss: 0.18047219514846802
train-epoch-step: 71-100 -- Loss: 0.20720338821411133
train-epoch-step: 71-101 -- Loss: 0.28786152601242065
train-epoch-step: 71-102 -- Loss: 0.21390940248966217
train-epoch-step: 71-103 -- Loss: 0.17902769148349762
train-epoch-step: 71-104 -- Loss: 0.14201131463050842
train-epoch-step: 71-105 -- Loss: 0.26965397596359253
train-epoch-step: 71-106 -- Loss: 0.17336034774780273
train-epoch-step: 71-107 -- Loss: 0.18403229117393494
train-epoch-step: 71-108 -- Loss: 0.18613523244857788
train-epoch-step: 71-109 -- Loss: 0.14225731790065765
train-epoch-step: 71-110 -- Loss: 0.1938720941543579
train-epoch-step: 71-111 -- Loss: 0.17237600684165955
train-epoch-step: 71-112 -- Loss: 0.1627647578716278
train-epoch-step: 71-113 -- Loss: 0.1549222469329834
train-epoch-step: 71-114 -- Loss: 0.1906938999891281
train-epoch-step: 71-115 -- Loss: 0.1570674628019333
train-epoch-step: 71-116 -- Loss: 0.13680234551429749
train-epoch-step: 71-117 -- Loss: 0.12646518647670746
train-epoch-step: 71-118 -- Loss: 0.22297483682632446
train-epoch-step: 71-119 -- Loss: 0.1472683548927307
train-epoch-step: 71-120 -- Loss: 0.24287091195583344
train-epoch-step: 71-121 -- Loss: 0.21646834909915924
train-epoch-step: 71-122 -- Loss: 0.21880459785461426
train-epoch-step: 71-123 -- Loss: 0.19615107774734497
train-epoch-step: 71-124 -- Loss: 0.12258929014205933
train-epoch-step: 71-125 -- Loss: 0.14842016994953156
train-epoch-step: 71-126 -- Loss: 0.22003421187400818
train-epoch-step: 71-127 -- Loss: 0.16141995787620544
train-epoch-step: 71-128 -- Loss: 0.1809062659740448
train-epoch-step: 71-129 -- Loss: 0.14933210611343384
train-epoch-step: 71-130 -- Loss: 0.19226041436195374
train-epoch-step: 71-131 -- Loss: 0.134403258562088
train-epoch-step: 71-132 -- Loss: 0.18654310703277588
train-epoch-step: 71-133 -- Loss: 0.11352677643299103
train-epoch-step: 71-134 -- Loss: 0.18834732472896576
train-epoch-step: 71-135 -- Loss: 0.1297498643398285
train-epoch-step: 71-136 -- Loss: 0.12521299719810486
train-epoch-step: 71-137 -- Loss: 0.23725956678390503
train-epoch-step: 71-138 -- Loss: 0.2581591010093689
train-epoch-step: 71-139 -- Loss: 0.1287265419960022
train-epoch-step: 71-140 -- Loss: 0.20174631476402283
train-epoch-step: 71-141 -- Loss: 0.22288846969604492
train-epoch-step: 71-142 -- Loss: 0.200227752327919
train-epoch-step: 71-143 -- Loss: 0.1689739227294922
train-epoch-step: 71-144 -- Loss: 0.17927493155002594
train-epoch-step: 71-145 -- Loss: 0.13974212110042572
train-epoch-step: 71-146 -- Loss: 0.17598804831504822
train-epoch-step: 71-147 -- Loss: 0.16101497411727905
train-epoch-step: 71-148 -- Loss: 0.15966737270355225
train-epoch-step: 71-149 -- Loss: 0.12007860094308853
train-epoch-step: 71-150 -- Loss: 0.18121741712093353
train-epoch-step: 71-151 -- Loss: 0.18666067719459534
train-epoch-step: 71-152 -- Loss: 0.18414096534252167
train-epoch-step: 71-153 -- Loss: 0.25859352946281433
train-epoch-step: 71-154 -- Loss: 0.12819062173366547
train-epoch-step: 71-155 -- Loss: 0.1356995850801468
train-epoch-step: 71-156 -- Loss: 0.11744332313537598
train-epoch-step: 71-157 -- Loss: 0.15521389245986938
train-epoch-step: 71-158 -- Loss: 0.16864658892154694
train-epoch-step: 71-159 -- Loss: 0.17499740421772003
train-epoch-step: 71-160 -- Loss: 0.20653864741325378
train-epoch-step: 71-161 -- Loss: 0.1937246471643448
train-epoch-step: 71-162 -- Loss: 0.19856226444244385
train-epoch-step: 71-163 -- Loss: 0.18344426155090332
train-epoch-step: 71-164 -- Loss: 0.18629102408885956
train-epoch-step: 71-165 -- Loss: 0.1586921513080597
train-epoch-step: 71-166 -- Loss: 0.11379233002662659
train-epoch-step: 71-167 -- Loss: 0.11830682307481766
train-epoch-step: 71-168 -- Loss: 0.19448024034500122
train-epoch-step: 71-169 -- Loss: 0.1344362497329712
train-epoch-step: 71-170 -- Loss: 0.1971433013677597
train-epoch-step: 71-171 -- Loss: 0.1409078985452652
train-epoch-step: 71-172 -- Loss: 0.25190815329551697
train-epoch-step: 71-173 -- Loss: 0.12364277243614197
train-epoch-step: 71-174 -- Loss: 0.2421931028366089
train-epoch-step: 71-175 -- Loss: 0.17988330125808716
train-epoch-step: 71-176 -- Loss: 0.1298740655183792
train-epoch-step: 71-177 -- Loss: 0.17465724050998688
train-epoch-step: 71-178 -- Loss: 0.17724646627902985
train-epoch-step: 71-179 -- Loss: 0.1375899463891983
train-epoch-step: 71-180 -- Loss: 0.1497528851032257
train-epoch-step: 71-181 -- Loss: 0.16306084394454956
train-epoch-step: 71-182 -- Loss: 0.1762520670890808
train-epoch-step: 71-183 -- Loss: 0.25822561979293823
train-epoch-step: 71-184 -- Loss: 0.13526661694049835
train-epoch-step: 71-185 -- Loss: 0.13552866876125336
train-epoch-step: 71-186 -- Loss: 0.18350927531719208
train-epoch-step: 71-187 -- Loss: 0.20138965547084808
train-epoch-step: 71-188 -- Loss: 0.16546465456485748
train-epoch-step: 71-189 -- Loss: 0.10219419747591019
train-epoch-step: 71-190 -- Loss: 0.1776033639907837
train-epoch-step: 71-191 -- Loss: 0.1546543836593628
train-epoch-step: 71-192 -- Loss: 0.2227838784456253
train-epoch-step: 71-193 -- Loss: 0.19549399614334106
train-epoch-step: 71-194 -- Loss: 0.17891378700733185
train-epoch-step: 71-195 -- Loss: 0.1652151644229889
train-epoch-step: 71-196 -- Loss: 0.1622791290283203
train-epoch-step: 71-197 -- Loss: 0.1223316565155983
train-epoch-step: 71-198 -- Loss: 0.1283131241798401
train-epoch-step: 71-199 -- Loss: 0.1454741656780243
train-epoch-step: 71-200 -- Loss: 0.12142963707447052
train-epoch-step: 71-201 -- Loss: 0.18868042528629303
train-epoch-step: 71-202 -- Loss: 0.13197395205497742
train-epoch-step: 71-203 -- Loss: 0.16593292355537415
train-epoch-step: 71-204 -- Loss: 0.1323794424533844
train-epoch-step: 71-205 -- Loss: 0.17859633266925812
train-epoch-step: 71-206 -- Loss: 0.19457513093948364
train-epoch-step: 71-207 -- Loss: 0.13382363319396973
train-epoch-step: 71-208 -- Loss: 0.1742175817489624
train-epoch-step: 71-209 -- Loss: 0.13955073058605194
train-epoch-step: 71-210 -- Loss: 0.129139706492424
train-epoch-step: 71-211 -- Loss: 0.2056998908519745
train-epoch-step: 71-212 -- Loss: 0.19372214376926422
train-epoch-step: 71-213 -- Loss: 0.12432564049959183
train-epoch-step: 71-214 -- Loss: 0.1444547325372696
train-epoch-step: 71-215 -- Loss: 0.12313994765281677
train-epoch-step: 71-216 -- Loss: 0.1961997151374817
train-epoch-step: 71-217 -- Loss: 0.2086285948753357
train-epoch-step: 71-218 -- Loss: 0.139211505651474
train-epoch-step: 71-219 -- Loss: 0.16475969552993774
train-epoch-step: 71-220 -- Loss: 0.12738218903541565
train-epoch-step: 71-221 -- Loss: 0.20011372864246368
train-epoch-step: 71-222 -- Loss: 0.11577512323856354
train-epoch-step: 71-223 -- Loss: 0.17012138664722443
train-epoch-step: 71-224 -- Loss: 0.18288561701774597
train-epoch-step: 71-225 -- Loss: 0.2584196925163269
train-epoch-step: 71-226 -- Loss: 0.1988382339477539
train-epoch-step: 71-227 -- Loss: 0.21547837555408478
train-epoch-step: 71-228 -- Loss: 0.17264464497566223
train-epoch-step: 71-229 -- Loss: 0.17378047108650208
train-epoch-step: 71-230 -- Loss: 0.1622025966644287
train-epoch-step: 71-231 -- Loss: 0.14887626469135284
train-epoch-step: 71-232 -- Loss: 0.17781823873519897
train-epoch-step: 71-233 -- Loss: 0.07976683229207993
train-epoch-step: 71-234 -- Loss: 0.16792380809783936
train-epoch-step: 71-235 -- Loss: 0.13746874034404755
train-epoch-step: 71-236 -- Loss: 0.1720917820930481
train-epoch-step: 71-237 -- Loss: 0.22889210283756256
train-epoch-step: 71-238 -- Loss: 0.1527695506811142
train-epoch-step: 71-239 -- Loss: 0.1243036687374115
train-epoch-step: 71-240 -- Loss: 0.21683965623378754
train-epoch-step: 71-241 -- Loss: 0.14744673669338226
train-epoch-step: 71-242 -- Loss: 0.21482686698436737
train-epoch-step: 71-243 -- Loss: 0.2266448438167572
train-epoch-step: 71-244 -- Loss: 0.19849793612957
train-epoch-step: 71-245 -- Loss: 0.2003595232963562
train-epoch-step: 71-246 -- Loss: 0.21828246116638184
train-epoch-step: 71-247 -- Loss: 0.19865843653678894
train-epoch-step: 71-248 -- Loss: 0.18078792095184326
train-epoch-step: 71-249 -- Loss: 0.13352878391742706
train-epoch-step: 71-250 -- Loss: 0.18805086612701416
train-epoch-step: 71-251 -- Loss: 0.10428465157747269
train-epoch-step: 71-252 -- Loss: 0.18065018951892853
train-epoch-step: 71-253 -- Loss: 0.12946276366710663
train-epoch-step: 71-254 -- Loss: 0.20428995788097382
train-epoch-step: 71-255 -- Loss: 0.14105015993118286
train-epoch-step: 71-256 -- Loss: 0.14184409379959106
train-epoch-step: 71-257 -- Loss: 0.1789986938238144
train-epoch-step: 71-258 -- Loss: 0.1406092494726181
train-epoch-step: 71-259 -- Loss: 0.11388079822063446
train-epoch-step: 71-260 -- Loss: 0.19124284386634827
train-epoch-step: 71-261 -- Loss: 0.16345098614692688
train-epoch-step: 71-262 -- Loss: 0.2735421657562256
train-epoch-step: 71-263 -- Loss: 0.18778328597545624
train-epoch-step: 71-264 -- Loss: 0.16730785369873047
train-epoch-step: 71-265 -- Loss: 0.10299990326166153
train-epoch-step: 71-266 -- Loss: 0.1505792886018753
train-epoch-step: 71-267 -- Loss: 0.12405146658420563
train-epoch-step: 71-268 -- Loss: 0.11136768758296967
train-epoch-step: 71-269 -- Loss: 0.17155496776103973
train-epoch-step: 71-270 -- Loss: 0.1057804673910141
train-epoch-step: 71-271 -- Loss: 0.1421111822128296
train-epoch-step: 71-272 -- Loss: 0.11282441020011902
train-epoch-step: 71-273 -- Loss: 0.12157678604125977
train-epoch-step: 71-274 -- Loss: 0.17617757618427277
train-epoch-step: 71-275 -- Loss: 0.18123576045036316
train-epoch-step: 71-276 -- Loss: 0.15467298030853271
train-epoch-step: 71-277 -- Loss: 0.1484733521938324
train-epoch-step: 71-278 -- Loss: 0.13342641294002533
train-epoch-step: 71-279 -- Loss: 0.12891478836536407
train-epoch-step: 71-280 -- Loss: 0.20206262171268463
train-epoch-step: 71-281 -- Loss: 0.1694897711277008
train-epoch-step: 71-282 -- Loss: 0.13565635681152344
train-epoch-step: 71-283 -- Loss: 0.11171825230121613
train-epoch-step: 71-284 -- Loss: 0.1308973878622055
train-epoch-step: 71-285 -- Loss: 0.18523935973644257
train-epoch-step: 71-286 -- Loss: 0.14812132716178894
train-epoch-step: 71-287 -- Loss: 0.191080704331398
train-epoch-step: 71-288 -- Loss: 0.09026171267032623
train-epoch-step: 71-289 -- Loss: 0.1167069599032402
train-epoch-step: 71-290 -- Loss: 0.17359668016433716
train-epoch-step: 71-291 -- Loss: 0.11198467016220093
train-epoch-step: 71-292 -- Loss: 0.15030041337013245
train-epoch-step: 71-293 -- Loss: 0.1325450837612152
train-epoch-step: 71-294 -- Loss: 0.15584608912467957
train-epoch-step: 71-295 -- Loss: 0.2531590163707733
train-epoch-step: 71-296 -- Loss: 0.15196439623832703
train-epoch-step: 71-297 -- Loss: 0.1651735007762909
train-epoch-step: 71-298 -- Loss: 0.22074946761131287
train-epoch-step: 71-299 -- Loss: 0.14045347273349762
train-epoch-step: 71-300 -- Loss: 0.1569151133298874
train-epoch-step: 71-301 -- Loss: 0.16335000097751617
train-epoch-step: 71-302 -- Loss: 0.20184919238090515
train-epoch-step: 71-303 -- Loss: 0.195794478058815
train-epoch-step: 71-304 -- Loss: 0.11549663543701172
train-epoch-step: 71-305 -- Loss: 0.13724103569984436
train-epoch-step: 71-306 -- Loss: 0.20454274117946625
train-epoch-step: 71-307 -- Loss: 0.15848737955093384
train-epoch-step: 71-308 -- Loss: 0.20665514469146729
train-epoch-step: 71-309 -- Loss: 0.14970184862613678
train-epoch-step: 71-310 -- Loss: 0.15166348218917847
train-epoch-step: 71-311 -- Loss: 0.15002921223640442
train-epoch-step: 71-312 -- Loss: 0.1964610069990158
train-epoch-step: 71-313 -- Loss: 0.09446544945240021
train-epoch-step: 71-314 -- Loss: 0.18810492753982544
train-epoch-step: 71-315 -- Loss: 0.16116727888584137
train-epoch-step: 71-316 -- Loss: 0.15007555484771729
train-epoch-step: 71-317 -- Loss: 0.13242298364639282
train-epoch-step: 71-318 -- Loss: 0.1514376401901245
train-epoch-step: 71-319 -- Loss: 0.15930919349193573
train-epoch-step: 71-320 -- Loss: 0.11174647510051727
train-epoch-step: 71-321 -- Loss: 0.12525103986263275
train-epoch-step: 71-322 -- Loss: 0.21114906668663025
train-epoch-step: 71-323 -- Loss: 0.15310747921466827
train-epoch-step: 71-324 -- Loss: 0.251570463180542
train-epoch-step: 71-325 -- Loss: 0.15238729119300842
train-epoch-step: 71-326 -- Loss: 0.1656358242034912
train-epoch-step: 71-327 -- Loss: 0.19955123960971832
train-epoch-step: 71-328 -- Loss: 0.19017654657363892
train-epoch-step: 71-329 -- Loss: 0.3289538323879242
train-epoch-step: 71-330 -- Loss: 0.35153529047966003
train-epoch-step: 71-331 -- Loss: 0.19923166930675507
train-epoch-step: 71-332 -- Loss: 0.09503161907196045
train-epoch-step: 71-333 -- Loss: 0.17504513263702393
train-epoch-step: 71-334 -- Loss: 0.14718325436115265
train-epoch-step: 71-335 -- Loss: 0.17093177139759064
train-epoch-step: 71-336 -- Loss: 0.1408783495426178
train-epoch-step: 71-337 -- Loss: 0.19244825839996338
train-epoch-step: 71-338 -- Loss: 0.1542324274778366
train-epoch-step: 71-339 -- Loss: 0.13630424439907074
train-epoch-step: 71-340 -- Loss: 0.19249996542930603
train-epoch-step: 71-341 -- Loss: 0.13622242212295532
train-epoch-step: 71-342 -- Loss: 0.15676212310791016
train-epoch-step: 71-343 -- Loss: 0.14929480850696564
train-epoch-step: 71-344 -- Loss: 0.16045349836349487
train-epoch-step: 71-345 -- Loss: 0.12513898313045502
train-epoch-step: 71-346 -- Loss: 0.1969124972820282
train-epoch-step: 71-347 -- Loss: 0.14706677198410034
train-epoch-step: 71-348 -- Loss: 0.19277724623680115
train-epoch-step: 71-349 -- Loss: 0.19442462921142578
train-epoch-step: 71-350 -- Loss: 0.2392171323299408
train-epoch-step: 71-351 -- Loss: 0.18803264200687408
train-epoch-step: 71-352 -- Loss: 0.11762487143278122
train-epoch-step: 71-353 -- Loss: 0.19126051664352417
train-epoch-step: 71-354 -- Loss: 0.27272745966911316
train-epoch-step: 71-355 -- Loss: 0.1131197139620781
train-epoch-step: 71-356 -- Loss: 0.11323361098766327
train-epoch-step: 71-357 -- Loss: 0.1868857741355896
train-epoch-step: 71-358 -- Loss: 0.18002928793430328
train-epoch-step: 71-359 -- Loss: 0.1351451873779297
train-epoch-step: 71-360 -- Loss: 0.11860381066799164
train-epoch-step: 71-361 -- Loss: 0.23166540265083313
train-epoch-step: 71-362 -- Loss: 0.16510464251041412
train-epoch-step: 71-363 -- Loss: 0.10424606502056122
train-epoch-step: 71-364 -- Loss: 0.17442287504673004
train-epoch-step: 71-365 -- Loss: 0.16247251629829407
train-epoch-step: 71-366 -- Loss: 0.2320529967546463
train-epoch-step: 71-367 -- Loss: 0.22282618284225464
train-epoch-step: 71-368 -- Loss: 0.18916617333889008
train-epoch-step: 71-369 -- Loss: 0.27231478691101074
train-epoch-step: 71-370 -- Loss: 0.12135158479213715
train-epoch-step: 71-371 -- Loss: 0.12012384086847305
train-epoch-step: 71-372 -- Loss: 0.15064798295497894
train-epoch-step: 71-373 -- Loss: 0.19241806864738464
train-epoch-step: 71-374 -- Loss: 0.1501123309135437
train-epoch-step: 71-375 -- Loss: 0.2649478316307068
train-epoch-step: 71-376 -- Loss: 0.16310721635818481
train-epoch-step: 71-377 -- Loss: 0.23181365430355072
train-epoch-step: 71-378 -- Loss: 0.19699443876743317
train-epoch-step: 71-379 -- Loss: 0.11365380883216858
train-epoch-step: 71-380 -- Loss: 0.08632860332727432
train-epoch-step: 71-381 -- Loss: 0.23733434081077576
train-epoch-step: 71-382 -- Loss: 0.2275339514017105
train-epoch-step: 71-383 -- Loss: 0.17004245519638062
train-epoch-step: 71-384 -- Loss: 0.2158903032541275
train-epoch-step: 71-385 -- Loss: 0.18214204907417297
train-epoch-step: 71-386 -- Loss: 0.1816466748714447
train-epoch-step: 71-387 -- Loss: 0.19793355464935303
train-epoch-step: 71-388 -- Loss: 0.17266809940338135
train-epoch-step: 71-389 -- Loss: 0.16074499487876892
train-epoch-step: 71-390 -- Loss: 0.14052647352218628
train-epoch-step: 71-391 -- Loss: 0.1401006132364273
train-epoch-step: 71-392 -- Loss: 0.18296867609024048
train-epoch-step: 71-393 -- Loss: 0.15038543939590454
train-epoch-step: 71-394 -- Loss: 0.20088645815849304
train-epoch-step: 71-395 -- Loss: 0.15068292617797852
train-epoch-step: 71-396 -- Loss: 0.12574750185012817
train-epoch-step: 71-397 -- Loss: 0.12264027446508408
train-epoch-step: 71-398 -- Loss: 0.1915963739156723
train-epoch-step: 71-399 -- Loss: 0.1699616014957428
train-epoch-step: 71-400 -- Loss: 0.26722055673599243
train-epoch-step: 71-401 -- Loss: 0.1149231344461441
train-epoch-step: 71-402 -- Loss: 0.2500396966934204
train-epoch-step: 71-403 -- Loss: 0.15932098031044006
train-epoch-step: 71-404 -- Loss: 0.13501131534576416
train-epoch-step: 71-405 -- Loss: 0.13845251500606537
train-epoch-step: 71-406 -- Loss: 0.15886081755161285
train-epoch-step: 71-407 -- Loss: 0.1095944195985794
train-epoch-step: 71-408 -- Loss: 0.15559488534927368
train-epoch-step: 71-409 -- Loss: 0.16407443583011627
train-epoch-step: 71-410 -- Loss: 0.18998363614082336
train-epoch-step: 71-411 -- Loss: 0.18790507316589355
train-epoch-step: 71-412 -- Loss: 0.12897637486457825
train-epoch-step: 71-413 -- Loss: 0.1404917985200882
train-epoch-step: 71-414 -- Loss: 0.13130101561546326
train-epoch-step: 71-415 -- Loss: 0.12981827557086945
train-epoch-step: 71-416 -- Loss: 0.26105642318725586
train-epoch-step: 71-417 -- Loss: 0.18599200248718262
train-epoch-step: 71-418 -- Loss: 0.21886791288852692
train-epoch-step: 71-419 -- Loss: 0.1680702269077301
train-epoch-step: 71-420 -- Loss: 0.1468934565782547
train-epoch-step: 71-421 -- Loss: 0.16963891685009003
train-epoch-step: 71-422 -- Loss: 0.14474335312843323
train-epoch-step: 71-423 -- Loss: 0.16711048781871796
train-epoch-step: 71-424 -- Loss: 0.13387419283390045
train-epoch-step: 71-425 -- Loss: 0.176931232213974
train-epoch-step: 71-426 -- Loss: 0.157181054353714
train-epoch-step: 71-427 -- Loss: 0.1162872463464737
train-epoch-step: 71-428 -- Loss: 0.1818607747554779
train-epoch-step: 71-429 -- Loss: 0.17232796549797058
train-epoch-step: 71-430 -- Loss: 0.13702774047851562
train-epoch-step: 71-431 -- Loss: 0.15951311588287354
train-epoch-step: 71-432 -- Loss: 0.23085087537765503
train-epoch-step: 71-433 -- Loss: 0.13070638477802277
train-epoch-step: 71-434 -- Loss: 0.12323792278766632
train-epoch-step: 71-435 -- Loss: 0.14801904559135437
train-epoch-step: 71-436 -- Loss: 0.14590609073638916
train-epoch-step: 71-437 -- Loss: 0.1264769434928894
train-epoch-step: 71-438 -- Loss: 0.1648462563753128
train-epoch-step: 71-439 -- Loss: 0.2504611015319824
train-epoch-step: 71-440 -- Loss: 0.12813103199005127
train-epoch-step: 71-441 -- Loss: 0.19374726712703705
train-epoch-step: 71-442 -- Loss: 0.17266075313091278
train-epoch-step: 71-443 -- Loss: 0.14825361967086792
train-epoch-step: 71-444 -- Loss: 0.16843074560165405
train-epoch-step: 71-445 -- Loss: 0.17727749049663544
train-epoch-step: 71-446 -- Loss: 0.1540772169828415
train-epoch-step: 71-447 -- Loss: 0.18364393711090088
train-epoch-step: 71-448 -- Loss: 0.22002387046813965
train-epoch-step: 71-449 -- Loss: 0.1883663684129715
train-epoch-step: 71-450 -- Loss: 0.19416049122810364
train-epoch-step: 71-451 -- Loss: 0.14188888669013977
train-epoch-step: 71-452 -- Loss: 0.12253516912460327
train-epoch-step: 71-453 -- Loss: 0.08894110471010208
train-epoch-step: 71-454 -- Loss: 0.21843555569648743
train-epoch-step: 71-455 -- Loss: 0.12056566029787064
train-epoch-step: 71-456 -- Loss: 0.11521872878074646
train-epoch-step: 71-457 -- Loss: 0.2079334408044815
train-epoch-step: 71-458 -- Loss: 0.1418188512325287
train-epoch-step: 71-459 -- Loss: 0.20466655492782593
train-epoch-step: 71-460 -- Loss: 0.12260331213474274
train-epoch-step: 71-461 -- Loss: 0.12967230379581451
train-epoch-step: 71-462 -- Loss: 0.15234337747097015
train-epoch-step: 71-463 -- Loss: 0.1314927637577057
train-epoch-step: 71-464 -- Loss: 0.1583440601825714
train-epoch-step: 71-465 -- Loss: 0.2305462807416916
train-epoch-step: 71-466 -- Loss: 0.19258973002433777
train-epoch-step: 71-467 -- Loss: 0.10645826160907745
train-epoch-step: 71-468 -- Loss: 0.1613210290670395
train-epoch-step: 71-469 -- Loss: 0.2050323486328125
train-epoch-step: 71-470 -- Loss: 0.16522744297981262
train-epoch-step: 71-471 -- Loss: 0.15473446249961853
train-epoch-step: 71-472 -- Loss: 0.1526796966791153
train-epoch-step: 71-473 -- Loss: 0.1457207202911377
train-epoch-step: 71-474 -- Loss: 0.11936552822589874
train-epoch-step: 71-475 -- Loss: 0.10546872764825821
train-epoch-step: 71-476 -- Loss: 0.19139364361763
train-epoch-step: 71-477 -- Loss: 0.1920468509197235
train-epoch-step: 71-478 -- Loss: 0.18935777246952057
train-epoch-step: 71-479 -- Loss: 0.1396099030971527
train-epoch-step: 71-480 -- Loss: 0.182387113571167
train-epoch-step: 71-481 -- Loss: 0.26654481887817383
train-epoch-step: 71-482 -- Loss: 0.23879343271255493
train-epoch-step: 71-483 -- Loss: 0.16991698741912842
train-epoch-step: 71-484 -- Loss: 0.20910042524337769
train-epoch-step: 71-485 -- Loss: 0.12160082161426544
train-epoch-step: 71-486 -- Loss: 0.2306135594844818
train-epoch-step: 71-487 -- Loss: 0.2263655662536621
train-epoch-step: 71-488 -- Loss: 0.1804443746805191
train-epoch-step: 71-489 -- Loss: 0.21770916879177094
train-epoch-step: 71-490 -- Loss: 0.1305517852306366
train-epoch-step: 71-491 -- Loss: 0.1331585943698883
train-epoch-step: 71-492 -- Loss: 0.12125872075557709
train-epoch-step: 71-493 -- Loss: 0.19000285863876343
train-epoch-step: 71-494 -- Loss: 0.19094377756118774
train-epoch-step: 71-495 -- Loss: 0.1912694275379181
train-epoch-step: 71-496 -- Loss: 0.1358177661895752
train-epoch-step: 71-497 -- Loss: 0.17451736330986023
train-epoch-step: 71-498 -- Loss: 0.1396208107471466
train-epoch-step: 71-499 -- Loss: 0.15950757265090942
train-epoch-step: 71-500 -- Loss: 0.14815253019332886
train-epoch-step: 71-501 -- Loss: 0.20561149716377258
train-epoch-step: 71-502 -- Loss: 0.14802458882331848
train-epoch-step: 71-503 -- Loss: 0.20771542191505432
train-epoch-step: 71-504 -- Loss: 0.1160506084561348
train-epoch-step: 71-505 -- Loss: 0.16510722041130066
train-epoch-step: 71-506 -- Loss: 0.11129331588745117
train-epoch-step: 71-507 -- Loss: 0.17611061036586761
train-epoch-step: 71-508 -- Loss: 0.16701483726501465
train-epoch-step: 71-509 -- Loss: 0.16029509902000427
train-epoch-step: 71-510 -- Loss: 0.12165398895740509
train-epoch-step: 71-511 -- Loss: 0.2056846171617508
train-epoch-step: 71-512 -- Loss: 0.1710071861743927
train-epoch-step: 71-513 -- Loss: 0.18090645968914032
train-epoch-step: 71-514 -- Loss: 0.13999292254447937
train-epoch-step: 71-515 -- Loss: 0.15229326486587524
train-epoch-step: 71-516 -- Loss: 0.1701817512512207
train-epoch-step: 71-517 -- Loss: 0.1708759367465973
train-epoch-step: 71-518 -- Loss: 0.13427679240703583
train-epoch-step: 71-519 -- Loss: 0.12997043132781982
train-epoch-step: 71-520 -- Loss: 0.1805115044116974
train-epoch-step: 71-521 -- Loss: 0.2220386117696762
train-epoch-step: 71-522 -- Loss: 0.16857290267944336
train-epoch-step: 71-523 -- Loss: 0.1513761430978775
train-epoch-step: 71-524 -- Loss: 0.16166070103645325
train-epoch-step: 71-525 -- Loss: 0.18445931375026703
train-epoch-step: 71-526 -- Loss: 0.1239895448088646
train-epoch-step: 71-527 -- Loss: 0.1485847681760788
train-epoch-step: 71-528 -- Loss: 0.15078896284103394
train-epoch-step: 71-529 -- Loss: 0.14868448674678802
train-epoch-step: 71-530 -- Loss: 0.1616700291633606
train-epoch-step: 71-531 -- Loss: 0.18767447769641876
train-epoch-step: 71-532 -- Loss: 0.16154365241527557
train-epoch-step: 71-533 -- Loss: 0.17081117630004883
train-epoch-step: 71-534 -- Loss: 0.12476073950529099
train-epoch-step: 71-535 -- Loss: 0.2579214572906494
train-epoch-step: 71-536 -- Loss: 0.1544952392578125
train-epoch-step: 71-537 -- Loss: 0.1427450329065323
train-epoch-step: 71-538 -- Loss: 0.09882532805204391
train-epoch-step: 71-539 -- Loss: 0.17494697868824005
train-epoch-step: 71-540 -- Loss: 0.12961499392986298
train-epoch-step: 71-541 -- Loss: 0.2027321606874466
train-epoch-step: 71-542 -- Loss: 0.20918230712413788
train-epoch-step: 71-543 -- Loss: 0.16117973625659943
train-epoch-step: 71-544 -- Loss: 0.22078527510166168
train-epoch-step: 71-545 -- Loss: 0.18814456462860107
train-epoch-step: 71-546 -- Loss: 0.20094551146030426
train-epoch-step: 71-547 -- Loss: 0.17705033719539642
train-epoch-step: 71-548 -- Loss: 0.08839309215545654
train-epoch-step: 71-549 -- Loss: 0.14322054386138916
train-epoch-step: 71-550 -- Loss: 0.1925574392080307
train-epoch-step: 71-551 -- Loss: 0.14977604150772095
train-epoch-step: 71-552 -- Loss: 0.12627167999744415
train-epoch-step: 71-553 -- Loss: 0.1807427704334259
train-epoch-step: 71-554 -- Loss: 0.18168020248413086
train-epoch-step: 71-555 -- Loss: 0.20109714567661285
train-epoch-step: 71-556 -- Loss: 0.139581099152565
train-epoch-step: 71-557 -- Loss: 0.21859589219093323
train-epoch-step: 71-558 -- Loss: 0.21775823831558228
train-epoch-step: 71-559 -- Loss: 0.12977610528469086
train-epoch-step: 71-560 -- Loss: 0.20188774168491364
train-epoch-step: 71-561 -- Loss: 0.17581257224082947
train-epoch-step: 71-562 -- Loss: 0.16227054595947266
train-epoch-step: 71-563 -- Loss: 0.18018391728401184
train-epoch-step: 71-564 -- Loss: 0.09543213993310928
train-epoch-step: 71-565 -- Loss: 0.17784230411052704
train-epoch-step: 71-566 -- Loss: 0.14102482795715332
train-epoch-step: 71-567 -- Loss: 0.2069697231054306
train-epoch-step: 71-568 -- Loss: 0.15336120128631592
train-epoch-step: 71-569 -- Loss: 0.23905456066131592
train-epoch-step: 71-570 -- Loss: 0.16264848411083221
train-epoch-step: 71-571 -- Loss: 0.2055012434720993
train-epoch-step: 71-572 -- Loss: 0.22989419102668762
train-epoch-step: 71-573 -- Loss: 0.192001074552536
train-epoch-step: 71-574 -- Loss: 0.23795121908187866
train-epoch-step: 71-575 -- Loss: 0.28243184089660645
train-epoch-step: 71-576 -- Loss: 0.11446724086999893
train-epoch-step: 71-577 -- Loss: 0.1614566445350647
train-epoch-step: 71-578 -- Loss: 0.2101689875125885
train-epoch-step: 71-579 -- Loss: 0.15869513154029846
train-epoch-step: 71-580 -- Loss: 0.1686791181564331
train-epoch-step: 71-581 -- Loss: 0.13249275088310242
train-epoch-step: 71-582 -- Loss: 0.20265528559684753
train-epoch-step: 71-583 -- Loss: 0.20927175879478455
train-epoch-step: 71-584 -- Loss: 0.15190207958221436
train-epoch-step: 71-585 -- Loss: 0.1863313466310501
train-epoch-step: 71-586 -- Loss: 0.23919180035591125
train-epoch-step: 71-587 -- Loss: 0.1522572636604309
train-epoch-step: 71-588 -- Loss: 0.12220992147922516
val-epoch-step: 71-589 -- Loss: 0.19398385286331177
val-epoch-step: 71-590 -- Loss: 0.15442700684070587
val-epoch-step: 71-591 -- Loss: 0.23693372309207916
val-epoch-step: 71-592 -- Loss: 0.16967453062534332
val-epoch-step: 71-593 -- Loss: 0.1584722399711609
val-epoch-step: 71-594 -- Loss: 0.3603631854057312
val-epoch-step: 71-595 -- Loss: 0.18647493422031403
val-epoch-step: 71-596 -- Loss: 0.19467201828956604
val-epoch-step: 71-597 -- Loss: 0.17132416367530823
val-epoch-step: 71-598 -- Loss: 0.1496533900499344
val-epoch-step: 71-599 -- Loss: 0.17844688892364502
val-epoch-step: 71-600 -- Loss: 0.17400074005126953
val-epoch-step: 71-601 -- Loss: 0.163191020488739
val-epoch-step: 71-602 -- Loss: 0.13408537209033966
val-epoch-step: 71-603 -- Loss: 0.21450380980968475
val-epoch-step: 71-604 -- Loss: 0.1401205062866211
val-epoch-step: 71-605 -- Loss: 0.14152155816555023
val-epoch-step: 71-606 -- Loss: 0.24080535769462585
val-epoch-step: 71-607 -- Loss: 0.11985734850168228
val-epoch-step: 71-608 -- Loss: 0.2411935031414032
val-epoch-step: 71-609 -- Loss: 0.1744309365749359
val-epoch-step: 71-610 -- Loss: 0.17409130930900574
val-epoch-step: 71-611 -- Loss: 0.16009129583835602
val-epoch-step: 71-612 -- Loss: 0.39783844351768494
val-epoch-step: 71-613 -- Loss: 0.16631804406642914
val-epoch-step: 71-614 -- Loss: 0.14901092648506165
val-epoch-step: 71-615 -- Loss: 0.17536266148090363
val-epoch-step: 71-616 -- Loss: 0.15796911716461182
val-epoch-step: 71-617 -- Loss: 0.1876600980758667
val-epoch-step: 71-618 -- Loss: 0.17572224140167236
val-epoch-step: 71-619 -- Loss: 0.1976855993270874
val-epoch-step: 71-620 -- Loss: 0.15194444358348846
val-epoch-step: 71-621 -- Loss: 0.11968578398227692
val-epoch-step: 71-622 -- Loss: 0.13919153809547424
val-epoch-step: 71-623 -- Loss: 0.14585991203784943
val-epoch-step: 71-624 -- Loss: 0.1366317868232727
val-epoch-step: 71-625 -- Loss: 0.15087160468101501
val-epoch-step: 71-626 -- Loss: 0.1439751386642456
val-epoch-step: 71-627 -- Loss: 0.17437760531902313
val-epoch-step: 71-628 -- Loss: 0.6387476921081543
val-epoch-step: 71-629 -- Loss: 0.19472908973693848
val-epoch-step: 71-630 -- Loss: 0.34076008200645447
val-epoch-step: 71-631 -- Loss: 0.15313684940338135
val-epoch-step: 71-632 -- Loss: 0.18798169493675232
val-epoch-step: 71-633 -- Loss: 0.14595851302146912
val-epoch-step: 71-634 -- Loss: 0.14064784348011017
val-epoch-step: 71-635 -- Loss: 0.11632495373487473
val-epoch-step: 71-636 -- Loss: 0.17004036903381348
val-epoch-step: 71-637 -- Loss: 0.17393435537815094
val-epoch-step: 71-638 -- Loss: 0.155726820230484
val-epoch-step: 71-639 -- Loss: 0.25225767493247986
val-epoch-step: 71-640 -- Loss: 0.24550648033618927
val-epoch-step: 71-641 -- Loss: 0.12352235615253448
val-epoch-step: 71-642 -- Loss: 0.18017467856407166
val-epoch-step: 71-643 -- Loss: 0.20039623975753784
val-epoch-step: 71-644 -- Loss: 0.15588568150997162
val-epoch-step: 71-645 -- Loss: 0.21797943115234375
val-epoch-step: 71-646 -- Loss: 0.13137103617191315
val-epoch-step: 71-647 -- Loss: 0.12487499415874481
val-epoch-step: 71-648 -- Loss: 0.1530846208333969
val-epoch-step: 71-649 -- Loss: 0.20087216794490814
val-epoch-step: 71-650 -- Loss: 0.24288511276245117
val-epoch-step: 71-651 -- Loss: 0.14627066254615784
val-epoch-step: 71-652 -- Loss: 0.15150928497314453
val-epoch-step: 71-653 -- Loss: 0.19019979238510132
val-epoch-step: 71-654 -- Loss: 0.1076081171631813
Epoch: 71 -- Train Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 72-0 -- Loss: 0.21388159692287445
train-epoch-step: 72-1 -- Loss: 0.13897812366485596
train-epoch-step: 72-2 -- Loss: 0.19038546085357666
train-epoch-step: 72-3 -- Loss: 0.1384042352437973
train-epoch-step: 72-4 -- Loss: 0.1520097851753235
train-epoch-step: 72-5 -- Loss: 0.16905494034290314
train-epoch-step: 72-6 -- Loss: 0.20425862073898315
train-epoch-step: 72-7 -- Loss: 0.1600770205259323
train-epoch-step: 72-8 -- Loss: 0.16927778720855713
train-epoch-step: 72-9 -- Loss: 0.21147681772708893
train-epoch-step: 72-10 -- Loss: 0.18172867596149445
train-epoch-step: 72-11 -- Loss: 0.16832968592643738
train-epoch-step: 72-12 -- Loss: 0.14412862062454224
train-epoch-step: 72-13 -- Loss: 0.16719983518123627
train-epoch-step: 72-14 -- Loss: 0.15768270194530487
train-epoch-step: 72-15 -- Loss: 0.15284918248653412
train-epoch-step: 72-16 -- Loss: 0.15948687493801117
train-epoch-step: 72-17 -- Loss: 0.20463331043720245
train-epoch-step: 72-18 -- Loss: 0.18408527970314026
train-epoch-step: 72-19 -- Loss: 0.1261271834373474
train-epoch-step: 72-20 -- Loss: 0.20888444781303406
train-epoch-step: 72-21 -- Loss: 0.24730774760246277
train-epoch-step: 72-22 -- Loss: 0.1308961808681488
train-epoch-step: 72-23 -- Loss: 0.13763080537319183
train-epoch-step: 72-24 -- Loss: 0.12223825603723526
train-epoch-step: 72-25 -- Loss: 0.21283771097660065
train-epoch-step: 72-26 -- Loss: 0.18443915247917175
train-epoch-step: 72-27 -- Loss: 0.22700130939483643
train-epoch-step: 72-28 -- Loss: 0.12674480676651
train-epoch-step: 72-29 -- Loss: 0.2369147092103958
train-epoch-step: 72-30 -- Loss: 0.10583502054214478
train-epoch-step: 72-31 -- Loss: 0.1293635070323944
train-epoch-step: 72-32 -- Loss: 0.171061173081398
train-epoch-step: 72-33 -- Loss: 0.2657376825809479
train-epoch-step: 72-34 -- Loss: 0.17134113609790802
train-epoch-step: 72-35 -- Loss: 0.23913367092609406
train-epoch-step: 72-36 -- Loss: 0.1321723461151123
train-epoch-step: 72-37 -- Loss: 0.12896321713924408
train-epoch-step: 72-38 -- Loss: 0.1681842803955078
train-epoch-step: 72-39 -- Loss: 0.21233883500099182
train-epoch-step: 72-40 -- Loss: 0.21608591079711914
train-epoch-step: 72-41 -- Loss: 0.21729105710983276
train-epoch-step: 72-42 -- Loss: 0.14818815886974335
train-epoch-step: 72-43 -- Loss: 0.2495272010564804
train-epoch-step: 72-44 -- Loss: 0.12104904651641846
train-epoch-step: 72-45 -- Loss: 0.12090720236301422
train-epoch-step: 72-46 -- Loss: 0.1643684059381485
train-epoch-step: 72-47 -- Loss: 0.20574656128883362
train-epoch-step: 72-48 -- Loss: 0.1496247947216034
train-epoch-step: 72-49 -- Loss: 0.2108742892742157
train-epoch-step: 72-50 -- Loss: 0.10453935712575912
train-epoch-step: 72-51 -- Loss: 0.1781364381313324
train-epoch-step: 72-52 -- Loss: 0.15782032907009125
train-epoch-step: 72-53 -- Loss: 0.2035946100950241
train-epoch-step: 72-54 -- Loss: 0.2784237265586853
train-epoch-step: 72-55 -- Loss: 0.16204921901226044
train-epoch-step: 72-56 -- Loss: 0.1708815097808838
train-epoch-step: 72-57 -- Loss: 0.23479461669921875
train-epoch-step: 72-58 -- Loss: 0.2762254774570465
train-epoch-step: 72-59 -- Loss: 0.2287244349718094
train-epoch-step: 72-60 -- Loss: 0.12399905174970627
train-epoch-step: 72-61 -- Loss: 0.20009201765060425
train-epoch-step: 72-62 -- Loss: 0.18305537104606628
train-epoch-step: 72-63 -- Loss: 0.13877935707569122
train-epoch-step: 72-64 -- Loss: 0.13755229115486145
train-epoch-step: 72-65 -- Loss: 0.17710910737514496
train-epoch-step: 72-66 -- Loss: 0.10438106209039688
train-epoch-step: 72-67 -- Loss: 0.1295509934425354
train-epoch-step: 72-68 -- Loss: 0.208272784948349
train-epoch-step: 72-69 -- Loss: 0.12007740139961243
train-epoch-step: 72-70 -- Loss: 0.21982720494270325
train-epoch-step: 72-71 -- Loss: 0.2606417238712311
train-epoch-step: 72-72 -- Loss: 0.16403251886367798
train-epoch-step: 72-73 -- Loss: 0.2026894986629486
train-epoch-step: 72-74 -- Loss: 0.09164687991142273
train-epoch-step: 72-75 -- Loss: 0.12440485507249832
train-epoch-step: 72-76 -- Loss: 0.14212405681610107
train-epoch-step: 72-77 -- Loss: 0.22280080616474152
train-epoch-step: 72-78 -- Loss: 0.254783570766449
train-epoch-step: 72-79 -- Loss: 0.1879429817199707
train-epoch-step: 72-80 -- Loss: 0.25630152225494385
train-epoch-step: 72-81 -- Loss: 0.12673860788345337
train-epoch-step: 72-82 -- Loss: 0.2419165074825287
train-epoch-step: 72-83 -- Loss: 0.1708773970603943
train-epoch-step: 72-84 -- Loss: 0.18326438963413239
train-epoch-step: 72-85 -- Loss: 0.16975200176239014
train-epoch-step: 72-86 -- Loss: 0.12116704881191254
train-epoch-step: 72-87 -- Loss: 0.20776578783988953
train-epoch-step: 72-88 -- Loss: 0.13336868584156036
train-epoch-step: 72-89 -- Loss: 0.18248172104358673
train-epoch-step: 72-90 -- Loss: 0.18746218085289001
train-epoch-step: 72-91 -- Loss: 0.24299834668636322
train-epoch-step: 72-92 -- Loss: 0.15145552158355713
train-epoch-step: 72-93 -- Loss: 0.16953828930854797
train-epoch-step: 72-94 -- Loss: 0.21740497648715973
train-epoch-step: 72-95 -- Loss: 0.18549364805221558
train-epoch-step: 72-96 -- Loss: 0.2079990804195404
train-epoch-step: 72-97 -- Loss: 0.17210708558559418
train-epoch-step: 72-98 -- Loss: 0.15140745043754578
train-epoch-step: 72-99 -- Loss: 0.17594033479690552
train-epoch-step: 72-100 -- Loss: 0.18206626176834106
train-epoch-step: 72-101 -- Loss: 0.24803663790225983
train-epoch-step: 72-102 -- Loss: 0.2083853781223297
train-epoch-step: 72-103 -- Loss: 0.18724752962589264
train-epoch-step: 72-104 -- Loss: 0.14509731531143188
train-epoch-step: 72-105 -- Loss: 0.2525331676006317
train-epoch-step: 72-106 -- Loss: 0.16705355048179626
train-epoch-step: 72-107 -- Loss: 0.1846693903207779
train-epoch-step: 72-108 -- Loss: 0.18050767481327057
train-epoch-step: 72-109 -- Loss: 0.1401320993900299
train-epoch-step: 72-110 -- Loss: 0.17571288347244263
train-epoch-step: 72-111 -- Loss: 0.17298148572444916
train-epoch-step: 72-112 -- Loss: 0.16018196940422058
train-epoch-step: 72-113 -- Loss: 0.1546037346124649
train-epoch-step: 72-114 -- Loss: 0.18856021761894226
train-epoch-step: 72-115 -- Loss: 0.1550697386264801
train-epoch-step: 72-116 -- Loss: 0.13301461935043335
train-epoch-step: 72-117 -- Loss: 0.1231214851140976
train-epoch-step: 72-118 -- Loss: 0.18455930054187775
train-epoch-step: 72-119 -- Loss: 0.14468657970428467
train-epoch-step: 72-120 -- Loss: 0.23723964393138885
train-epoch-step: 72-121 -- Loss: 0.23193255066871643
train-epoch-step: 72-122 -- Loss: 0.20694507658481598
train-epoch-step: 72-123 -- Loss: 0.19568809866905212
train-epoch-step: 72-124 -- Loss: 0.11831431090831757
train-epoch-step: 72-125 -- Loss: 0.15264655649662018
train-epoch-step: 72-126 -- Loss: 0.22346249222755432
train-epoch-step: 72-127 -- Loss: 0.16018496453762054
train-epoch-step: 72-128 -- Loss: 0.16737112402915955
train-epoch-step: 72-129 -- Loss: 0.14315824210643768
train-epoch-step: 72-130 -- Loss: 0.18651294708251953
train-epoch-step: 72-131 -- Loss: 0.1308957189321518
train-epoch-step: 72-132 -- Loss: 0.18293264508247375
train-epoch-step: 72-133 -- Loss: 0.11277393251657486
train-epoch-step: 72-134 -- Loss: 0.1847965121269226
train-epoch-step: 72-135 -- Loss: 0.12695714831352234
train-epoch-step: 72-136 -- Loss: 0.12067297846078873
train-epoch-step: 72-137 -- Loss: 0.23086676001548767
train-epoch-step: 72-138 -- Loss: 0.25463250279426575
train-epoch-step: 72-139 -- Loss: 0.12570692598819733
train-epoch-step: 72-140 -- Loss: 0.20265020430088043
train-epoch-step: 72-141 -- Loss: 0.22654545307159424
train-epoch-step: 72-142 -- Loss: 0.19528061151504517
train-epoch-step: 72-143 -- Loss: 0.16370311379432678
train-epoch-step: 72-144 -- Loss: 0.17490093410015106
train-epoch-step: 72-145 -- Loss: 0.14020897448062897
train-epoch-step: 72-146 -- Loss: 0.1720736026763916
train-epoch-step: 72-147 -- Loss: 0.16115015745162964
train-epoch-step: 72-148 -- Loss: 0.15098746120929718
train-epoch-step: 72-149 -- Loss: 0.11285246908664703
train-epoch-step: 72-150 -- Loss: 0.1758572906255722
train-epoch-step: 72-151 -- Loss: 0.18340040743350983
train-epoch-step: 72-152 -- Loss: 0.18553489446640015
train-epoch-step: 72-153 -- Loss: 0.2637858986854553
train-epoch-step: 72-154 -- Loss: 0.12464446574449539
train-epoch-step: 72-155 -- Loss: 0.12783944606781006
train-epoch-step: 72-156 -- Loss: 0.11298850923776627
train-epoch-step: 72-157 -- Loss: 0.15661989152431488
train-epoch-step: 72-158 -- Loss: 0.1639382243156433
train-epoch-step: 72-159 -- Loss: 0.1762678027153015
train-epoch-step: 72-160 -- Loss: 0.20297038555145264
train-epoch-step: 72-161 -- Loss: 0.2015819400548935
train-epoch-step: 72-162 -- Loss: 0.20316925644874573
train-epoch-step: 72-163 -- Loss: 0.18357975780963898
train-epoch-step: 72-164 -- Loss: 0.18827742338180542
train-epoch-step: 72-165 -- Loss: 0.15622305870056152
train-epoch-step: 72-166 -- Loss: 0.11591190844774246
train-epoch-step: 72-167 -- Loss: 0.11564573645591736
train-epoch-step: 72-168 -- Loss: 0.19310781359672546
train-epoch-step: 72-169 -- Loss: 0.13548752665519714
train-epoch-step: 72-170 -- Loss: 0.19423988461494446
train-epoch-step: 72-171 -- Loss: 0.13864324986934662
train-epoch-step: 72-172 -- Loss: 0.24980050325393677
train-epoch-step: 72-173 -- Loss: 0.12875674664974213
train-epoch-step: 72-174 -- Loss: 0.23886467516422272
train-epoch-step: 72-175 -- Loss: 0.180179625749588
train-epoch-step: 72-176 -- Loss: 0.1264384388923645
train-epoch-step: 72-177 -- Loss: 0.1799793541431427
train-epoch-step: 72-178 -- Loss: 0.17615294456481934
train-epoch-step: 72-179 -- Loss: 0.13882724940776825
train-epoch-step: 72-180 -- Loss: 0.1523602306842804
train-epoch-step: 72-181 -- Loss: 0.16218900680541992
train-epoch-step: 72-182 -- Loss: 0.17481952905654907
train-epoch-step: 72-183 -- Loss: 0.2625477612018585
train-epoch-step: 72-184 -- Loss: 0.13337653875350952
train-epoch-step: 72-185 -- Loss: 0.13523076474666595
train-epoch-step: 72-186 -- Loss: 0.17839977145195007
train-epoch-step: 72-187 -- Loss: 0.2046731561422348
train-epoch-step: 72-188 -- Loss: 0.16712221503257751
train-epoch-step: 72-189 -- Loss: 0.10443039983510971
train-epoch-step: 72-190 -- Loss: 0.17739459872245789
train-epoch-step: 72-191 -- Loss: 0.1541476845741272
train-epoch-step: 72-192 -- Loss: 0.2262316346168518
train-epoch-step: 72-193 -- Loss: 0.19370201230049133
train-epoch-step: 72-194 -- Loss: 0.17720046639442444
train-epoch-step: 72-195 -- Loss: 0.15867945551872253
train-epoch-step: 72-196 -- Loss: 0.1590442657470703
train-epoch-step: 72-197 -- Loss: 0.12123903632164001
train-epoch-step: 72-198 -- Loss: 0.12293607741594315
train-epoch-step: 72-199 -- Loss: 0.13955554366111755
train-epoch-step: 72-200 -- Loss: 0.11837007105350494
train-epoch-step: 72-201 -- Loss: 0.1804850846529007
train-epoch-step: 72-202 -- Loss: 0.1329844892024994
train-epoch-step: 72-203 -- Loss: 0.17674098908901215
train-epoch-step: 72-204 -- Loss: 0.13368865847587585
train-epoch-step: 72-205 -- Loss: 0.17604973912239075
train-epoch-step: 72-206 -- Loss: 0.1962251216173172
train-epoch-step: 72-207 -- Loss: 0.130233496427536
train-epoch-step: 72-208 -- Loss: 0.17052870988845825
train-epoch-step: 72-209 -- Loss: 0.13976117968559265
train-epoch-step: 72-210 -- Loss: 0.1269914209842682
train-epoch-step: 72-211 -- Loss: 0.20079094171524048
train-epoch-step: 72-212 -- Loss: 0.19508050382137299
train-epoch-step: 72-213 -- Loss: 0.12333095073699951
train-epoch-step: 72-214 -- Loss: 0.14408272504806519
train-epoch-step: 72-215 -- Loss: 0.12495695799589157
train-epoch-step: 72-216 -- Loss: 0.19852128624916077
train-epoch-step: 72-217 -- Loss: 0.20280712842941284
train-epoch-step: 72-218 -- Loss: 0.14146314561367035
train-epoch-step: 72-219 -- Loss: 0.16428819298744202
train-epoch-step: 72-220 -- Loss: 0.12533824145793915
train-epoch-step: 72-221 -- Loss: 0.20145806670188904
train-epoch-step: 72-222 -- Loss: 0.11532065272331238
train-epoch-step: 72-223 -- Loss: 0.1701565533876419
train-epoch-step: 72-224 -- Loss: 0.18156203627586365
train-epoch-step: 72-225 -- Loss: 0.25180932879447937
train-epoch-step: 72-226 -- Loss: 0.2023967057466507
train-epoch-step: 72-227 -- Loss: 0.21285411715507507
train-epoch-step: 72-228 -- Loss: 0.17163176834583282
train-epoch-step: 72-229 -- Loss: 0.1664174497127533
train-epoch-step: 72-230 -- Loss: 0.16130982339382172
train-epoch-step: 72-231 -- Loss: 0.1516304761171341
train-epoch-step: 72-232 -- Loss: 0.17804229259490967
train-epoch-step: 72-233 -- Loss: 0.08005397021770477
train-epoch-step: 72-234 -- Loss: 0.1707678586244583
train-epoch-step: 72-235 -- Loss: 0.1429556906223297
train-epoch-step: 72-236 -- Loss: 0.17238304018974304
train-epoch-step: 72-237 -- Loss: 0.2229955941438675
train-epoch-step: 72-238 -- Loss: 0.14964978396892548
train-epoch-step: 72-239 -- Loss: 0.12273553013801575
train-epoch-step: 72-240 -- Loss: 0.20970802009105682
train-epoch-step: 72-241 -- Loss: 0.1455049216747284
train-epoch-step: 72-242 -- Loss: 0.21478602290153503
train-epoch-step: 72-243 -- Loss: 0.22714918851852417
train-epoch-step: 72-244 -- Loss: 0.19446270167827606
train-epoch-step: 72-245 -- Loss: 0.20200686156749725
train-epoch-step: 72-246 -- Loss: 0.21112607419490814
train-epoch-step: 72-247 -- Loss: 0.2002536654472351
train-epoch-step: 72-248 -- Loss: 0.1817401498556137
train-epoch-step: 72-249 -- Loss: 0.13185225427150726
train-epoch-step: 72-250 -- Loss: 0.19729948043823242
train-epoch-step: 72-251 -- Loss: 0.10285394638776779
train-epoch-step: 72-252 -- Loss: 0.19693104922771454
train-epoch-step: 72-253 -- Loss: 0.12886208295822144
train-epoch-step: 72-254 -- Loss: 0.20322535932064056
train-epoch-step: 72-255 -- Loss: 0.14080986380577087
train-epoch-step: 72-256 -- Loss: 0.1440027505159378
train-epoch-step: 72-257 -- Loss: 0.1805087774991989
train-epoch-step: 72-258 -- Loss: 0.13825272023677826
train-epoch-step: 72-259 -- Loss: 0.1251213401556015
train-epoch-step: 72-260 -- Loss: 0.19839371740818024
train-epoch-step: 72-261 -- Loss: 0.16201287508010864
train-epoch-step: 72-262 -- Loss: 0.2819092273712158
train-epoch-step: 72-263 -- Loss: 0.19443048536777496
train-epoch-step: 72-264 -- Loss: 0.1676599681377411
train-epoch-step: 72-265 -- Loss: 0.11722219735383987
train-epoch-step: 72-266 -- Loss: 0.1523762196302414
train-epoch-step: 72-267 -- Loss: 0.123324453830719
train-epoch-step: 72-268 -- Loss: 0.11546570807695389
train-epoch-step: 72-269 -- Loss: 0.16517800092697144
train-epoch-step: 72-270 -- Loss: 0.1040743738412857
train-epoch-step: 72-271 -- Loss: 0.14901916682720184
train-epoch-step: 72-272 -- Loss: 0.11169739067554474
train-epoch-step: 72-273 -- Loss: 0.12171527743339539
train-epoch-step: 72-274 -- Loss: 0.17712391912937164
train-epoch-step: 72-275 -- Loss: 0.1844211369752884
train-epoch-step: 72-276 -- Loss: 0.14911223948001862
train-epoch-step: 72-277 -- Loss: 0.1521623432636261
train-epoch-step: 72-278 -- Loss: 0.13338002562522888
train-epoch-step: 72-279 -- Loss: 0.13508126139640808
train-epoch-step: 72-280 -- Loss: 0.20967429876327515
train-epoch-step: 72-281 -- Loss: 0.17296110093593597
train-epoch-step: 72-282 -- Loss: 0.1380065381526947
train-epoch-step: 72-283 -- Loss: 0.10999128967523575
train-epoch-step: 72-284 -- Loss: 0.13567304611206055
train-epoch-step: 72-285 -- Loss: 0.18310081958770752
train-epoch-step: 72-286 -- Loss: 0.14952196180820465
train-epoch-step: 72-287 -- Loss: 0.18867141008377075
train-epoch-step: 72-288 -- Loss: 0.09071034938097
train-epoch-step: 72-289 -- Loss: 0.11438548564910889
train-epoch-step: 72-290 -- Loss: 0.1742941439151764
train-epoch-step: 72-291 -- Loss: 0.11241563409566879
train-epoch-step: 72-292 -- Loss: 0.15133918821811676
train-epoch-step: 72-293 -- Loss: 0.13430267572402954
train-epoch-step: 72-294 -- Loss: 0.1511160284280777
train-epoch-step: 72-295 -- Loss: 0.2472429871559143
train-epoch-step: 72-296 -- Loss: 0.1554802805185318
train-epoch-step: 72-297 -- Loss: 0.17041093111038208
train-epoch-step: 72-298 -- Loss: 0.22542020678520203
train-epoch-step: 72-299 -- Loss: 0.13890992105007172
train-epoch-step: 72-300 -- Loss: 0.1590898633003235
train-epoch-step: 72-301 -- Loss: 0.1639716476202011
train-epoch-step: 72-302 -- Loss: 0.2086816132068634
train-epoch-step: 72-303 -- Loss: 0.19803544878959656
train-epoch-step: 72-304 -- Loss: 0.11819875985383987
train-epoch-step: 72-305 -- Loss: 0.1405259370803833
train-epoch-step: 72-306 -- Loss: 0.2082686722278595
train-epoch-step: 72-307 -- Loss: 0.16025391221046448
train-epoch-step: 72-308 -- Loss: 0.21195530891418457
train-epoch-step: 72-309 -- Loss: 0.14931762218475342
train-epoch-step: 72-310 -- Loss: 0.154657781124115
train-epoch-step: 72-311 -- Loss: 0.15459872782230377
train-epoch-step: 72-312 -- Loss: 0.19410593807697296
train-epoch-step: 72-313 -- Loss: 0.09551621228456497
train-epoch-step: 72-314 -- Loss: 0.17907990515232086
train-epoch-step: 72-315 -- Loss: 0.16501055657863617
train-epoch-step: 72-316 -- Loss: 0.1453082114458084
train-epoch-step: 72-317 -- Loss: 0.13342048227787018
train-epoch-step: 72-318 -- Loss: 0.1527794897556305
train-epoch-step: 72-319 -- Loss: 0.16234883666038513
train-epoch-step: 72-320 -- Loss: 0.11466652899980545
train-epoch-step: 72-321 -- Loss: 0.12529781460762024
train-epoch-step: 72-322 -- Loss: 0.20534031093120575
train-epoch-step: 72-323 -- Loss: 0.1523411124944687
train-epoch-step: 72-324 -- Loss: 0.24624301493167877
train-epoch-step: 72-325 -- Loss: 0.14905937016010284
train-epoch-step: 72-326 -- Loss: 0.16351714730262756
train-epoch-step: 72-327 -- Loss: 0.1954987496137619
train-epoch-step: 72-328 -- Loss: 0.18469032645225525
train-epoch-step: 72-329 -- Loss: 0.3260156512260437
train-epoch-step: 72-330 -- Loss: 0.352729856967926
train-epoch-step: 72-331 -- Loss: 0.19901981949806213
train-epoch-step: 72-332 -- Loss: 0.09645247459411621
train-epoch-step: 72-333 -- Loss: 0.17611178755760193
train-epoch-step: 72-334 -- Loss: 0.15027108788490295
train-epoch-step: 72-335 -- Loss: 0.167800173163414
train-epoch-step: 72-336 -- Loss: 0.14320459961891174
train-epoch-step: 72-337 -- Loss: 0.1943657100200653
train-epoch-step: 72-338 -- Loss: 0.1519280970096588
train-epoch-step: 72-339 -- Loss: 0.13812655210494995
train-epoch-step: 72-340 -- Loss: 0.18710123002529144
train-epoch-step: 72-341 -- Loss: 0.14148420095443726
train-epoch-step: 72-342 -- Loss: 0.15731969475746155
train-epoch-step: 72-343 -- Loss: 0.14741623401641846
train-epoch-step: 72-344 -- Loss: 0.16185882687568665
train-epoch-step: 72-345 -- Loss: 0.12112157046794891
train-epoch-step: 72-346 -- Loss: 0.192356675863266
train-epoch-step: 72-347 -- Loss: 0.14970740675926208
train-epoch-step: 72-348 -- Loss: 0.1960650235414505
train-epoch-step: 72-349 -- Loss: 0.19378110766410828
train-epoch-step: 72-350 -- Loss: 0.24189510941505432
train-epoch-step: 72-351 -- Loss: 0.18408402800559998
train-epoch-step: 72-352 -- Loss: 0.11718615144491196
train-epoch-step: 72-353 -- Loss: 0.18870028853416443
train-epoch-step: 72-354 -- Loss: 0.2737724483013153
train-epoch-step: 72-355 -- Loss: 0.11316192895174026
train-epoch-step: 72-356 -- Loss: 0.11276320368051529
train-epoch-step: 72-357 -- Loss: 0.18228057026863098
train-epoch-step: 72-358 -- Loss: 0.18081077933311462
train-epoch-step: 72-359 -- Loss: 0.13497090339660645
train-epoch-step: 72-360 -- Loss: 0.12206926941871643
train-epoch-step: 72-361 -- Loss: 0.22660914063453674
train-epoch-step: 72-362 -- Loss: 0.16373981535434723
train-epoch-step: 72-363 -- Loss: 0.10419414937496185
train-epoch-step: 72-364 -- Loss: 0.17365410923957825
train-epoch-step: 72-365 -- Loss: 0.15995804965496063
train-epoch-step: 72-366 -- Loss: 0.19164890050888062
train-epoch-step: 72-367 -- Loss: 0.2207006812095642
train-epoch-step: 72-368 -- Loss: 0.18752849102020264
train-epoch-step: 72-369 -- Loss: 0.2688104510307312
train-epoch-step: 72-370 -- Loss: 0.11991521716117859
train-epoch-step: 72-371 -- Loss: 0.11742554605007172
train-epoch-step: 72-372 -- Loss: 0.1415080428123474
train-epoch-step: 72-373 -- Loss: 0.17976725101470947
train-epoch-step: 72-374 -- Loss: 0.14728926122188568
train-epoch-step: 72-375 -- Loss: 0.25932684540748596
train-epoch-step: 72-376 -- Loss: 0.15736716985702515
train-epoch-step: 72-377 -- Loss: 0.21864356100559235
train-epoch-step: 72-378 -- Loss: 0.19031758606433868
train-epoch-step: 72-379 -- Loss: 0.1154305636882782
train-epoch-step: 72-380 -- Loss: 0.08680646866559982
train-epoch-step: 72-381 -- Loss: 0.23542959988117218
train-epoch-step: 72-382 -- Loss: 0.22180774807929993
train-epoch-step: 72-383 -- Loss: 0.16667576134204865
train-epoch-step: 72-384 -- Loss: 0.20627453923225403
train-epoch-step: 72-385 -- Loss: 0.18045376241207123
train-epoch-step: 72-386 -- Loss: 0.17555800080299377
train-epoch-step: 72-387 -- Loss: 0.19305665791034698
train-epoch-step: 72-388 -- Loss: 0.1809016913175583
train-epoch-step: 72-389 -- Loss: 0.15887899696826935
train-epoch-step: 72-390 -- Loss: 0.14207860827445984
train-epoch-step: 72-391 -- Loss: 0.13851940631866455
train-epoch-step: 72-392 -- Loss: 0.1804245114326477
train-epoch-step: 72-393 -- Loss: 0.14869581162929535
train-epoch-step: 72-394 -- Loss: 0.18545643985271454
train-epoch-step: 72-395 -- Loss: 0.14968076348304749
train-epoch-step: 72-396 -- Loss: 0.12212665379047394
train-epoch-step: 72-397 -- Loss: 0.12322630733251572
train-epoch-step: 72-398 -- Loss: 0.18939226865768433
train-epoch-step: 72-399 -- Loss: 0.17077822983264923
train-epoch-step: 72-400 -- Loss: 0.2679699659347534
train-epoch-step: 72-401 -- Loss: 0.11446303874254227
train-epoch-step: 72-402 -- Loss: 0.25105810165405273
train-epoch-step: 72-403 -- Loss: 0.145612895488739
train-epoch-step: 72-404 -- Loss: 0.13414911925792694
train-epoch-step: 72-405 -- Loss: 0.14419107139110565
train-epoch-step: 72-406 -- Loss: 0.16242431104183197
train-epoch-step: 72-407 -- Loss: 0.11014991998672485
train-epoch-step: 72-408 -- Loss: 0.16145795583724976
train-epoch-step: 72-409 -- Loss: 0.16366057097911835
train-epoch-step: 72-410 -- Loss: 0.16677042841911316
train-epoch-step: 72-411 -- Loss: 0.19376429915428162
train-epoch-step: 72-412 -- Loss: 0.1234612986445427
train-epoch-step: 72-413 -- Loss: 0.14112773537635803
train-epoch-step: 72-414 -- Loss: 0.12924076616764069
train-epoch-step: 72-415 -- Loss: 0.1288491189479828
train-epoch-step: 72-416 -- Loss: 0.25849124789237976
train-epoch-step: 72-417 -- Loss: 0.18349598348140717
train-epoch-step: 72-418 -- Loss: 0.21892571449279785
train-epoch-step: 72-419 -- Loss: 0.16019044816493988
train-epoch-step: 72-420 -- Loss: 0.14844869077205658
train-epoch-step: 72-421 -- Loss: 0.1722935140132904
train-epoch-step: 72-422 -- Loss: 0.14445172250270844
train-epoch-step: 72-423 -- Loss: 0.17225156724452972
train-epoch-step: 72-424 -- Loss: 0.13147024810314178
train-epoch-step: 72-425 -- Loss: 0.176672101020813
train-epoch-step: 72-426 -- Loss: 0.15733477473258972
train-epoch-step: 72-427 -- Loss: 0.11817210912704468
train-epoch-step: 72-428 -- Loss: 0.18028491735458374
train-epoch-step: 72-429 -- Loss: 0.16864913702011108
train-epoch-step: 72-430 -- Loss: 0.136822909116745
train-epoch-step: 72-431 -- Loss: 0.15847516059875488
train-epoch-step: 72-432 -- Loss: 0.2316148430109024
train-epoch-step: 72-433 -- Loss: 0.13091786205768585
train-epoch-step: 72-434 -- Loss: 0.12745901942253113
train-epoch-step: 72-435 -- Loss: 0.15130482614040375
train-epoch-step: 72-436 -- Loss: 0.1485152393579483
train-epoch-step: 72-437 -- Loss: 0.12694045901298523
train-epoch-step: 72-438 -- Loss: 0.16353660821914673
train-epoch-step: 72-439 -- Loss: 0.25217828154563904
train-epoch-step: 72-440 -- Loss: 0.12681162357330322
train-epoch-step: 72-441 -- Loss: 0.19192630052566528
train-epoch-step: 72-442 -- Loss: 0.16820979118347168
train-epoch-step: 72-443 -- Loss: 0.14616933465003967
train-epoch-step: 72-444 -- Loss: 0.18471449613571167
train-epoch-step: 72-445 -- Loss: 0.17136496305465698
train-epoch-step: 72-446 -- Loss: 0.14504742622375488
train-epoch-step: 72-447 -- Loss: 0.18484348058700562
train-epoch-step: 72-448 -- Loss: 0.21364077925682068
train-epoch-step: 72-449 -- Loss: 0.18698668479919434
train-epoch-step: 72-450 -- Loss: 0.17234621942043304
train-epoch-step: 72-451 -- Loss: 0.14110438525676727
train-epoch-step: 72-452 -- Loss: 0.12314022332429886
train-epoch-step: 72-453 -- Loss: 0.08701357245445251
train-epoch-step: 72-454 -- Loss: 0.23001228272914886
train-epoch-step: 72-455 -- Loss: 0.11855599284172058
train-epoch-step: 72-456 -- Loss: 0.11573156714439392
train-epoch-step: 72-457 -- Loss: 0.2064339816570282
train-epoch-step: 72-458 -- Loss: 0.1461963653564453
train-epoch-step: 72-459 -- Loss: 0.2166690230369568
train-epoch-step: 72-460 -- Loss: 0.13617902994155884
train-epoch-step: 72-461 -- Loss: 0.13134460151195526
train-epoch-step: 72-462 -- Loss: 0.145671546459198
train-epoch-step: 72-463 -- Loss: 0.13143068552017212
train-epoch-step: 72-464 -- Loss: 0.15555863082408905
train-epoch-step: 72-465 -- Loss: 0.23067785799503326
train-epoch-step: 72-466 -- Loss: 0.19703158736228943
train-epoch-step: 72-467 -- Loss: 0.10643008351325989
train-epoch-step: 72-468 -- Loss: 0.16051073372364044
train-epoch-step: 72-469 -- Loss: 0.20508530735969543
train-epoch-step: 72-470 -- Loss: 0.16631004214286804
train-epoch-step: 72-471 -- Loss: 0.15122871100902557
train-epoch-step: 72-472 -- Loss: 0.15252123773097992
train-epoch-step: 72-473 -- Loss: 0.16676543653011322
train-epoch-step: 72-474 -- Loss: 0.11917124688625336
train-epoch-step: 72-475 -- Loss: 0.1047448143362999
train-epoch-step: 72-476 -- Loss: 0.1963556706905365
train-epoch-step: 72-477 -- Loss: 0.18803970515727997
train-epoch-step: 72-478 -- Loss: 0.1817820966243744
train-epoch-step: 72-479 -- Loss: 0.13288678228855133
train-epoch-step: 72-480 -- Loss: 0.1799701750278473
train-epoch-step: 72-481 -- Loss: 0.2714591920375824
train-epoch-step: 72-482 -- Loss: 0.24763721227645874
train-epoch-step: 72-483 -- Loss: 0.1683821976184845
train-epoch-step: 72-484 -- Loss: 0.2053045779466629
train-epoch-step: 72-485 -- Loss: 0.12290475517511368
train-epoch-step: 72-486 -- Loss: 0.2207445204257965
train-epoch-step: 72-487 -- Loss: 0.2250615954399109
train-epoch-step: 72-488 -- Loss: 0.17534136772155762
train-epoch-step: 72-489 -- Loss: 0.21542032063007355
train-epoch-step: 72-490 -- Loss: 0.1347576528787613
train-epoch-step: 72-491 -- Loss: 0.13454264402389526
train-epoch-step: 72-492 -- Loss: 0.11964177340269089
train-epoch-step: 72-493 -- Loss: 0.18672674894332886
train-epoch-step: 72-494 -- Loss: 0.19504408538341522
train-epoch-step: 72-495 -- Loss: 0.19420680403709412
train-epoch-step: 72-496 -- Loss: 0.13606497645378113
train-epoch-step: 72-497 -- Loss: 0.1798870712518692
train-epoch-step: 72-498 -- Loss: 0.14149877429008484
train-epoch-step: 72-499 -- Loss: 0.16296839714050293
train-epoch-step: 72-500 -- Loss: 0.14897172152996063
train-epoch-step: 72-501 -- Loss: 0.2021450251340866
train-epoch-step: 72-502 -- Loss: 0.15180398523807526
train-epoch-step: 72-503 -- Loss: 0.20634855329990387
train-epoch-step: 72-504 -- Loss: 0.11491604149341583
train-epoch-step: 72-505 -- Loss: 0.16388832032680511
train-epoch-step: 72-506 -- Loss: 0.11333754658699036
train-epoch-step: 72-507 -- Loss: 0.17641623318195343
train-epoch-step: 72-508 -- Loss: 0.16667845845222473
train-epoch-step: 72-509 -- Loss: 0.1674325317144394
train-epoch-step: 72-510 -- Loss: 0.12280096858739853
train-epoch-step: 72-511 -- Loss: 0.20331667363643646
train-epoch-step: 72-512 -- Loss: 0.17106002569198608
train-epoch-step: 72-513 -- Loss: 0.17969605326652527
train-epoch-step: 72-514 -- Loss: 0.13828763365745544
train-epoch-step: 72-515 -- Loss: 0.14814551174640656
train-epoch-step: 72-516 -- Loss: 0.16777795553207397
train-epoch-step: 72-517 -- Loss: 0.16988125443458557
train-epoch-step: 72-518 -- Loss: 0.13325639069080353
train-epoch-step: 72-519 -- Loss: 0.1285327970981598
train-epoch-step: 72-520 -- Loss: 0.1781124472618103
train-epoch-step: 72-521 -- Loss: 0.21836866438388824
train-epoch-step: 72-522 -- Loss: 0.16577424108982086
train-epoch-step: 72-523 -- Loss: 0.15151666104793549
train-epoch-step: 72-524 -- Loss: 0.15899252891540527
train-epoch-step: 72-525 -- Loss: 0.1851474642753601
train-epoch-step: 72-526 -- Loss: 0.1261405497789383
train-epoch-step: 72-527 -- Loss: 0.14543335139751434
train-epoch-step: 72-528 -- Loss: 0.147416889667511
train-epoch-step: 72-529 -- Loss: 0.149067685008049
train-epoch-step: 72-530 -- Loss: 0.16233506798744202
train-epoch-step: 72-531 -- Loss: 0.18534322082996368
train-epoch-step: 72-532 -- Loss: 0.16174012422561646
train-epoch-step: 72-533 -- Loss: 0.16525927186012268
train-epoch-step: 72-534 -- Loss: 0.1262650191783905
train-epoch-step: 72-535 -- Loss: 0.24233011901378632
train-epoch-step: 72-536 -- Loss: 0.15152892470359802
train-epoch-step: 72-537 -- Loss: 0.14396357536315918
train-epoch-step: 72-538 -- Loss: 0.1007162481546402
train-epoch-step: 72-539 -- Loss: 0.1756695657968521
train-epoch-step: 72-540 -- Loss: 0.1284717321395874
train-epoch-step: 72-541 -- Loss: 0.20147329568862915
train-epoch-step: 72-542 -- Loss: 0.21033060550689697
train-epoch-step: 72-543 -- Loss: 0.1660948246717453
train-epoch-step: 72-544 -- Loss: 0.21866440773010254
train-epoch-step: 72-545 -- Loss: 0.1846231073141098
train-epoch-step: 72-546 -- Loss: 0.19910775125026703
train-epoch-step: 72-547 -- Loss: 0.17323577404022217
train-epoch-step: 72-548 -- Loss: 0.08850974589586258
train-epoch-step: 72-549 -- Loss: 0.14854256808757782
train-epoch-step: 72-550 -- Loss: 0.1961331069469452
train-epoch-step: 72-551 -- Loss: 0.1463528871536255
train-epoch-step: 72-552 -- Loss: 0.1210484430193901
train-epoch-step: 72-553 -- Loss: 0.17950496077537537
train-epoch-step: 72-554 -- Loss: 0.1789034754037857
train-epoch-step: 72-555 -- Loss: 0.198831245303154
train-epoch-step: 72-556 -- Loss: 0.14036841690540314
train-epoch-step: 72-557 -- Loss: 0.22846779227256775
train-epoch-step: 72-558 -- Loss: 0.21507537364959717
train-epoch-step: 72-559 -- Loss: 0.14068223536014557
train-epoch-step: 72-560 -- Loss: 0.19490408897399902
train-epoch-step: 72-561 -- Loss: 0.17736077308654785
train-epoch-step: 72-562 -- Loss: 0.1694510132074356
train-epoch-step: 72-563 -- Loss: 0.17874199151992798
train-epoch-step: 72-564 -- Loss: 0.09596617519855499
train-epoch-step: 72-565 -- Loss: 0.17399148643016815
train-epoch-step: 72-566 -- Loss: 0.14099092781543732
train-epoch-step: 72-567 -- Loss: 0.21015749871730804
train-epoch-step: 72-568 -- Loss: 0.15150605142116547
train-epoch-step: 72-569 -- Loss: 0.23664310574531555
train-epoch-step: 72-570 -- Loss: 0.1565101593732834
train-epoch-step: 72-571 -- Loss: 0.20407067239284515
train-epoch-step: 72-572 -- Loss: 0.2265879213809967
train-epoch-step: 72-573 -- Loss: 0.19172053039073944
train-epoch-step: 72-574 -- Loss: 0.2345779836177826
train-epoch-step: 72-575 -- Loss: 0.2853897213935852
train-epoch-step: 72-576 -- Loss: 0.1136685386300087
train-epoch-step: 72-577 -- Loss: 0.16087335348129272
train-epoch-step: 72-578 -- Loss: 0.20957282185554504
train-epoch-step: 72-579 -- Loss: 0.15848404169082642
train-epoch-step: 72-580 -- Loss: 0.16385972499847412
train-epoch-step: 72-581 -- Loss: 0.13208787143230438
train-epoch-step: 72-582 -- Loss: 0.19653108716011047
train-epoch-step: 72-583 -- Loss: 0.2018924504518509
train-epoch-step: 72-584 -- Loss: 0.15336944162845612
train-epoch-step: 72-585 -- Loss: 0.1861565262079239
train-epoch-step: 72-586 -- Loss: 0.24993205070495605
train-epoch-step: 72-587 -- Loss: 0.1538262516260147
train-epoch-step: 72-588 -- Loss: 0.12475180625915527
val-epoch-step: 72-589 -- Loss: 0.191278338432312
val-epoch-step: 72-590 -- Loss: 0.1493660807609558
val-epoch-step: 72-591 -- Loss: 0.23976312577724457
val-epoch-step: 72-592 -- Loss: 0.16813525557518005
val-epoch-step: 72-593 -- Loss: 0.15227895975112915
val-epoch-step: 72-594 -- Loss: 0.32298505306243896
val-epoch-step: 72-595 -- Loss: 0.17618784308433533
val-epoch-step: 72-596 -- Loss: 0.19101613759994507
val-epoch-step: 72-597 -- Loss: 0.16472096741199493
val-epoch-step: 72-598 -- Loss: 0.14717675745487213
val-epoch-step: 72-599 -- Loss: 0.17807221412658691
val-epoch-step: 72-600 -- Loss: 0.19183212518692017
val-epoch-step: 72-601 -- Loss: 0.15328411757946014
val-epoch-step: 72-602 -- Loss: 0.13270601630210876
val-epoch-step: 72-603 -- Loss: 0.21486449241638184
val-epoch-step: 72-604 -- Loss: 0.14326728880405426
val-epoch-step: 72-605 -- Loss: 0.14407029747962952
val-epoch-step: 72-606 -- Loss: 0.2603793740272522
val-epoch-step: 72-607 -- Loss: 0.1273905336856842
val-epoch-step: 72-608 -- Loss: 0.24249573051929474
val-epoch-step: 72-609 -- Loss: 0.16148759424686432
val-epoch-step: 72-610 -- Loss: 0.17106443643569946
val-epoch-step: 72-611 -- Loss: 0.1753607541322708
val-epoch-step: 72-612 -- Loss: 0.4050859212875366
val-epoch-step: 72-613 -- Loss: 0.16653776168823242
val-epoch-step: 72-614 -- Loss: 0.1626715064048767
val-epoch-step: 72-615 -- Loss: 0.1723189800977707
val-epoch-step: 72-616 -- Loss: 0.15202786028385162
val-epoch-step: 72-617 -- Loss: 0.19366911053657532
val-epoch-step: 72-618 -- Loss: 0.17452499270439148
val-epoch-step: 72-619 -- Loss: 0.199201762676239
val-epoch-step: 72-620 -- Loss: 0.14344334602355957
val-epoch-step: 72-621 -- Loss: 0.1213328167796135
val-epoch-step: 72-622 -- Loss: 0.14314213395118713
val-epoch-step: 72-623 -- Loss: 0.1454010158777237
val-epoch-step: 72-624 -- Loss: 0.14350968599319458
val-epoch-step: 72-625 -- Loss: 0.16249382495880127
val-epoch-step: 72-626 -- Loss: 0.14429593086242676
val-epoch-step: 72-627 -- Loss: 0.18182814121246338
val-epoch-step: 72-628 -- Loss: 0.6230418682098389
val-epoch-step: 72-629 -- Loss: 0.18945620954036713
val-epoch-step: 72-630 -- Loss: 0.3351285457611084
val-epoch-step: 72-631 -- Loss: 0.14885489642620087
val-epoch-step: 72-632 -- Loss: 0.1933617740869522
val-epoch-step: 72-633 -- Loss: 0.14621886610984802
val-epoch-step: 72-634 -- Loss: 0.15180185437202454
val-epoch-step: 72-635 -- Loss: 0.10982318222522736
val-epoch-step: 72-636 -- Loss: 0.16051635146141052
val-epoch-step: 72-637 -- Loss: 0.1787162721157074
val-epoch-step: 72-638 -- Loss: 0.16019782423973083
val-epoch-step: 72-639 -- Loss: 0.2488267421722412
val-epoch-step: 72-640 -- Loss: 0.24622094631195068
val-epoch-step: 72-641 -- Loss: 0.12313146144151688
val-epoch-step: 72-642 -- Loss: 0.17412225902080536
val-epoch-step: 72-643 -- Loss: 0.19759687781333923
val-epoch-step: 72-644 -- Loss: 0.15903574228286743
val-epoch-step: 72-645 -- Loss: 0.21569806337356567
val-epoch-step: 72-646 -- Loss: 0.17173168063163757
val-epoch-step: 72-647 -- Loss: 0.12319204956293106
val-epoch-step: 72-648 -- Loss: 0.14915135502815247
val-epoch-step: 72-649 -- Loss: 0.19785219430923462
val-epoch-step: 72-650 -- Loss: 0.24145285785198212
val-epoch-step: 72-651 -- Loss: 0.15150369703769684
val-epoch-step: 72-652 -- Loss: 0.153710275888443
val-epoch-step: 72-653 -- Loss: 0.2071404904127121
val-epoch-step: 72-654 -- Loss: 0.11002559959888458
Epoch: 72 -- Train Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 73-0 -- Loss: 0.21499869227409363
train-epoch-step: 73-1 -- Loss: 0.13868506252765656
train-epoch-step: 73-2 -- Loss: 0.18845568597316742
train-epoch-step: 73-3 -- Loss: 0.14638926088809967
train-epoch-step: 73-4 -- Loss: 0.15069900453090668
train-epoch-step: 73-5 -- Loss: 0.1731073260307312
train-epoch-step: 73-6 -- Loss: 0.2063245326280594
train-epoch-step: 73-7 -- Loss: 0.1596144139766693
train-epoch-step: 73-8 -- Loss: 0.17168991267681122
train-epoch-step: 73-9 -- Loss: 0.2257232964038849
train-epoch-step: 73-10 -- Loss: 0.18293213844299316
train-epoch-step: 73-11 -- Loss: 0.17502588033676147
train-epoch-step: 73-12 -- Loss: 0.14347437024116516
train-epoch-step: 73-13 -- Loss: 0.16816265881061554
train-epoch-step: 73-14 -- Loss: 0.1557929962873459
train-epoch-step: 73-15 -- Loss: 0.1595282107591629
train-epoch-step: 73-16 -- Loss: 0.1616530418395996
train-epoch-step: 73-17 -- Loss: 0.20848870277404785
train-epoch-step: 73-18 -- Loss: 0.18259017169475555
train-epoch-step: 73-19 -- Loss: 0.1264960914850235
train-epoch-step: 73-20 -- Loss: 0.20908254384994507
train-epoch-step: 73-21 -- Loss: 0.2441776841878891
train-epoch-step: 73-22 -- Loss: 0.13239693641662598
train-epoch-step: 73-23 -- Loss: 0.13628412783145905
train-epoch-step: 73-24 -- Loss: 0.12072831392288208
train-epoch-step: 73-25 -- Loss: 0.21359211206436157
train-epoch-step: 73-26 -- Loss: 0.1835774928331375
train-epoch-step: 73-27 -- Loss: 0.223495215177536
train-epoch-step: 73-28 -- Loss: 0.12008553743362427
train-epoch-step: 73-29 -- Loss: 0.23642843961715698
train-epoch-step: 73-30 -- Loss: 0.10367398709058762
train-epoch-step: 73-31 -- Loss: 0.1306581348180771
train-epoch-step: 73-32 -- Loss: 0.1654561460018158
train-epoch-step: 73-33 -- Loss: 0.25943949818611145
train-epoch-step: 73-34 -- Loss: 0.16302372515201569
train-epoch-step: 73-35 -- Loss: 0.23773953318595886
train-epoch-step: 73-36 -- Loss: 0.1336558610200882
train-epoch-step: 73-37 -- Loss: 0.1324678361415863
train-epoch-step: 73-38 -- Loss: 0.16464939713478088
train-epoch-step: 73-39 -- Loss: 0.20649966597557068
train-epoch-step: 73-40 -- Loss: 0.18688127398490906
train-epoch-step: 73-41 -- Loss: 0.20020687580108643
train-epoch-step: 73-42 -- Loss: 0.14529253542423248
train-epoch-step: 73-43 -- Loss: 0.25783467292785645
train-epoch-step: 73-44 -- Loss: 0.12057061493396759
train-epoch-step: 73-45 -- Loss: 0.1099853664636612
train-epoch-step: 73-46 -- Loss: 0.16332998871803284
train-epoch-step: 73-47 -- Loss: 0.1887470781803131
train-epoch-step: 73-48 -- Loss: 0.14710475504398346
train-epoch-step: 73-49 -- Loss: 0.21538937091827393
train-epoch-step: 73-50 -- Loss: 0.10785068571567535
train-epoch-step: 73-51 -- Loss: 0.16977766156196594
train-epoch-step: 73-52 -- Loss: 0.15438711643218994
train-epoch-step: 73-53 -- Loss: 0.20144417881965637
train-epoch-step: 73-54 -- Loss: 0.2738175690174103
train-epoch-step: 73-55 -- Loss: 0.1618575155735016
train-epoch-step: 73-56 -- Loss: 0.1695641428232193
train-epoch-step: 73-57 -- Loss: 0.22770290076732635
train-epoch-step: 73-58 -- Loss: 0.2716582417488098
train-epoch-step: 73-59 -- Loss: 0.22854258120059967
train-epoch-step: 73-60 -- Loss: 0.12527146935462952
train-epoch-step: 73-61 -- Loss: 0.203181654214859
train-epoch-step: 73-62 -- Loss: 0.17556904256343842
train-epoch-step: 73-63 -- Loss: 0.13229404389858246
train-epoch-step: 73-64 -- Loss: 0.13996826112270355
train-epoch-step: 73-65 -- Loss: 0.18483799695968628
train-epoch-step: 73-66 -- Loss: 0.10855565220117569
train-epoch-step: 73-67 -- Loss: 0.12229479849338531
train-epoch-step: 73-68 -- Loss: 0.1981917768716812
train-epoch-step: 73-69 -- Loss: 0.11628440767526627
train-epoch-step: 73-70 -- Loss: 0.2184213399887085
train-epoch-step: 73-71 -- Loss: 0.2506265640258789
train-epoch-step: 73-72 -- Loss: 0.16697686910629272
train-epoch-step: 73-73 -- Loss: 0.198673814535141
train-epoch-step: 73-74 -- Loss: 0.09310055524110794
train-epoch-step: 73-75 -- Loss: 0.12584416568279266
train-epoch-step: 73-76 -- Loss: 0.14338570833206177
train-epoch-step: 73-77 -- Loss: 0.21538373827934265
train-epoch-step: 73-78 -- Loss: 0.242710679769516
train-epoch-step: 73-79 -- Loss: 0.1817723959684372
train-epoch-step: 73-80 -- Loss: 0.2298959642648697
train-epoch-step: 73-81 -- Loss: 0.1183270663022995
train-epoch-step: 73-82 -- Loss: 0.2424059957265854
train-epoch-step: 73-83 -- Loss: 0.1705053299665451
train-epoch-step: 73-84 -- Loss: 0.18222907185554504
train-epoch-step: 73-85 -- Loss: 0.16804711520671844
train-epoch-step: 73-86 -- Loss: 0.11636503040790558
train-epoch-step: 73-87 -- Loss: 0.20269176363945007
train-epoch-step: 73-88 -- Loss: 0.1336086243391037
train-epoch-step: 73-89 -- Loss: 0.18049487471580505
train-epoch-step: 73-90 -- Loss: 0.1794256865978241
train-epoch-step: 73-91 -- Loss: 0.23373591899871826
train-epoch-step: 73-92 -- Loss: 0.15014153718948364
train-epoch-step: 73-93 -- Loss: 0.16534271836280823
train-epoch-step: 73-94 -- Loss: 0.2100793719291687
train-epoch-step: 73-95 -- Loss: 0.1801730841398239
train-epoch-step: 73-96 -- Loss: 0.20290087163448334
train-epoch-step: 73-97 -- Loss: 0.1651628315448761
train-epoch-step: 73-98 -- Loss: 0.14852374792099
train-epoch-step: 73-99 -- Loss: 0.1780025064945221
train-epoch-step: 73-100 -- Loss: 0.1825619488954544
train-epoch-step: 73-101 -- Loss: 0.24534358084201813
train-epoch-step: 73-102 -- Loss: 0.20289723575115204
train-epoch-step: 73-103 -- Loss: 0.18065884709358215
train-epoch-step: 73-104 -- Loss: 0.1439119279384613
train-epoch-step: 73-105 -- Loss: 0.2587181031703949
train-epoch-step: 73-106 -- Loss: 0.16879162192344666
train-epoch-step: 73-107 -- Loss: 0.18274109065532684
train-epoch-step: 73-108 -- Loss: 0.18415971100330353
train-epoch-step: 73-109 -- Loss: 0.1374339759349823
train-epoch-step: 73-110 -- Loss: 0.17623737454414368
train-epoch-step: 73-111 -- Loss: 0.16999712586402893
train-epoch-step: 73-112 -- Loss: 0.1712384819984436
train-epoch-step: 73-113 -- Loss: 0.1527210921049118
train-epoch-step: 73-114 -- Loss: 0.18978920578956604
train-epoch-step: 73-115 -- Loss: 0.15724867582321167
train-epoch-step: 73-116 -- Loss: 0.13064566254615784
train-epoch-step: 73-117 -- Loss: 0.12402436137199402
train-epoch-step: 73-118 -- Loss: 0.18399518728256226
train-epoch-step: 73-119 -- Loss: 0.14561274647712708
train-epoch-step: 73-120 -- Loss: 0.2417888045310974
train-epoch-step: 73-121 -- Loss: 0.2175889015197754
train-epoch-step: 73-122 -- Loss: 0.20853964984416962
train-epoch-step: 73-123 -- Loss: 0.19377195835113525
train-epoch-step: 73-124 -- Loss: 0.12247689068317413
train-epoch-step: 73-125 -- Loss: 0.15206986665725708
train-epoch-step: 73-126 -- Loss: 0.22095900774002075
train-epoch-step: 73-127 -- Loss: 0.15842215716838837
train-epoch-step: 73-128 -- Loss: 0.16615387797355652
train-epoch-step: 73-129 -- Loss: 0.13147979974746704
train-epoch-step: 73-130 -- Loss: 0.18972551822662354
train-epoch-step: 73-131 -- Loss: 0.13011428713798523
train-epoch-step: 73-132 -- Loss: 0.18103376030921936
train-epoch-step: 73-133 -- Loss: 0.11164598166942596
train-epoch-step: 73-134 -- Loss: 0.187181293964386
train-epoch-step: 73-135 -- Loss: 0.1278679519891739
train-epoch-step: 73-136 -- Loss: 0.12028810381889343
train-epoch-step: 73-137 -- Loss: 0.23592978715896606
train-epoch-step: 73-138 -- Loss: 0.24854840338230133
train-epoch-step: 73-139 -- Loss: 0.12550899386405945
train-epoch-step: 73-140 -- Loss: 0.2024155855178833
train-epoch-step: 73-141 -- Loss: 0.22339752316474915
train-epoch-step: 73-142 -- Loss: 0.1928367018699646
train-epoch-step: 73-143 -- Loss: 0.16179518401622772
train-epoch-step: 73-144 -- Loss: 0.1737118512392044
train-epoch-step: 73-145 -- Loss: 0.13576237857341766
train-epoch-step: 73-146 -- Loss: 0.17104384303092957
train-epoch-step: 73-147 -- Loss: 0.16230107843875885
train-epoch-step: 73-148 -- Loss: 0.15652921795845032
train-epoch-step: 73-149 -- Loss: 0.1162017360329628
train-epoch-step: 73-150 -- Loss: 0.17792367935180664
train-epoch-step: 73-151 -- Loss: 0.180229052901268
train-epoch-step: 73-152 -- Loss: 0.18285663425922394
train-epoch-step: 73-153 -- Loss: 0.2564312815666199
train-epoch-step: 73-154 -- Loss: 0.12694182991981506
train-epoch-step: 73-155 -- Loss: 0.128793865442276
train-epoch-step: 73-156 -- Loss: 0.11270438134670258
train-epoch-step: 73-157 -- Loss: 0.15501798689365387
train-epoch-step: 73-158 -- Loss: 0.1612432450056076
train-epoch-step: 73-159 -- Loss: 0.1706721931695938
train-epoch-step: 73-160 -- Loss: 0.21815575659275055
train-epoch-step: 73-161 -- Loss: 0.19773033261299133
train-epoch-step: 73-162 -- Loss: 0.19792243838310242
train-epoch-step: 73-163 -- Loss: 0.1837366223335266
train-epoch-step: 73-164 -- Loss: 0.18581217527389526
train-epoch-step: 73-165 -- Loss: 0.15476557612419128
train-epoch-step: 73-166 -- Loss: 0.1159713938832283
train-epoch-step: 73-167 -- Loss: 0.1217949166893959
train-epoch-step: 73-168 -- Loss: 0.19248314201831818
train-epoch-step: 73-169 -- Loss: 0.13550426065921783
train-epoch-step: 73-170 -- Loss: 0.18861933052539825
train-epoch-step: 73-171 -- Loss: 0.13956007361412048
train-epoch-step: 73-172 -- Loss: 0.25865188241004944
train-epoch-step: 73-173 -- Loss: 0.1275997757911682
train-epoch-step: 73-174 -- Loss: 0.2392401248216629
train-epoch-step: 73-175 -- Loss: 0.17981861531734467
train-epoch-step: 73-176 -- Loss: 0.1247045248746872
train-epoch-step: 73-177 -- Loss: 0.17495955526828766
train-epoch-step: 73-178 -- Loss: 0.17640800774097443
train-epoch-step: 73-179 -- Loss: 0.14283618330955505
train-epoch-step: 73-180 -- Loss: 0.14538471400737762
train-epoch-step: 73-181 -- Loss: 0.16630934178829193
train-epoch-step: 73-182 -- Loss: 0.1737230122089386
train-epoch-step: 73-183 -- Loss: 0.2551906406879425
train-epoch-step: 73-184 -- Loss: 0.1342737227678299
train-epoch-step: 73-185 -- Loss: 0.13756181299686432
train-epoch-step: 73-186 -- Loss: 0.18870386481285095
train-epoch-step: 73-187 -- Loss: 0.20321960747241974
train-epoch-step: 73-188 -- Loss: 0.16830207407474518
train-epoch-step: 73-189 -- Loss: 0.10137850046157837
train-epoch-step: 73-190 -- Loss: 0.175253763794899
train-epoch-step: 73-191 -- Loss: 0.15070582926273346
train-epoch-step: 73-192 -- Loss: 0.2308625876903534
train-epoch-step: 73-193 -- Loss: 0.20043370127677917
train-epoch-step: 73-194 -- Loss: 0.176027312874794
train-epoch-step: 73-195 -- Loss: 0.15945620834827423
train-epoch-step: 73-196 -- Loss: 0.15944546461105347
train-epoch-step: 73-197 -- Loss: 0.12149406969547272
train-epoch-step: 73-198 -- Loss: 0.1249198466539383
train-epoch-step: 73-199 -- Loss: 0.14955469965934753
train-epoch-step: 73-200 -- Loss: 0.12086062878370285
train-epoch-step: 73-201 -- Loss: 0.18453148007392883
train-epoch-step: 73-202 -- Loss: 0.1335216760635376
train-epoch-step: 73-203 -- Loss: 0.16807791590690613
train-epoch-step: 73-204 -- Loss: 0.13097542524337769
train-epoch-step: 73-205 -- Loss: 0.17882700264453888
train-epoch-step: 73-206 -- Loss: 0.19441518187522888
train-epoch-step: 73-207 -- Loss: 0.12838497757911682
train-epoch-step: 73-208 -- Loss: 0.17291800677776337
train-epoch-step: 73-209 -- Loss: 0.1419592946767807
train-epoch-step: 73-210 -- Loss: 0.1367177665233612
train-epoch-step: 73-211 -- Loss: 0.1983359456062317
train-epoch-step: 73-212 -- Loss: 0.19252178072929382
train-epoch-step: 73-213 -- Loss: 0.12368673086166382
train-epoch-step: 73-214 -- Loss: 0.1420331448316574
train-epoch-step: 73-215 -- Loss: 0.123774453997612
train-epoch-step: 73-216 -- Loss: 0.193043053150177
train-epoch-step: 73-217 -- Loss: 0.20382224023342133
train-epoch-step: 73-218 -- Loss: 0.13957437872886658
train-epoch-step: 73-219 -- Loss: 0.16009320318698883
train-epoch-step: 73-220 -- Loss: 0.12516768276691437
train-epoch-step: 73-221 -- Loss: 0.19712570309638977
train-epoch-step: 73-222 -- Loss: 0.11171858757734299
train-epoch-step: 73-223 -- Loss: 0.16888819634914398
train-epoch-step: 73-224 -- Loss: 0.180591881275177
train-epoch-step: 73-225 -- Loss: 0.2561678886413574
train-epoch-step: 73-226 -- Loss: 0.19985723495483398
train-epoch-step: 73-227 -- Loss: 0.21320673823356628
train-epoch-step: 73-228 -- Loss: 0.17152859270572662
train-epoch-step: 73-229 -- Loss: 0.16549062728881836
train-epoch-step: 73-230 -- Loss: 0.16121503710746765
train-epoch-step: 73-231 -- Loss: 0.15100114047527313
train-epoch-step: 73-232 -- Loss: 0.1784321367740631
train-epoch-step: 73-233 -- Loss: 0.07956015318632126
train-epoch-step: 73-234 -- Loss: 0.16745112836360931
train-epoch-step: 73-235 -- Loss: 0.14350879192352295
train-epoch-step: 73-236 -- Loss: 0.17060263454914093
train-epoch-step: 73-237 -- Loss: 0.22284115850925446
train-epoch-step: 73-238 -- Loss: 0.1496952772140503
train-epoch-step: 73-239 -- Loss: 0.12059327960014343
train-epoch-step: 73-240 -- Loss: 0.21503016352653503
train-epoch-step: 73-241 -- Loss: 0.1481926143169403
train-epoch-step: 73-242 -- Loss: 0.2095581591129303
train-epoch-step: 73-243 -- Loss: 0.23055364191532135
train-epoch-step: 73-244 -- Loss: 0.19955477118492126
train-epoch-step: 73-245 -- Loss: 0.19789516925811768
train-epoch-step: 73-246 -- Loss: 0.2058454006910324
train-epoch-step: 73-247 -- Loss: 0.2050929069519043
train-epoch-step: 73-248 -- Loss: 0.1762923002243042
train-epoch-step: 73-249 -- Loss: 0.13453343510627747
train-epoch-step: 73-250 -- Loss: 0.19331994652748108
train-epoch-step: 73-251 -- Loss: 0.10294225066900253
train-epoch-step: 73-252 -- Loss: 0.18817470967769623
train-epoch-step: 73-253 -- Loss: 0.13397161662578583
train-epoch-step: 73-254 -- Loss: 0.20385576784610748
train-epoch-step: 73-255 -- Loss: 0.13847129046916962
train-epoch-step: 73-256 -- Loss: 0.1383490264415741
train-epoch-step: 73-257 -- Loss: 0.17673887312412262
train-epoch-step: 73-258 -- Loss: 0.1504514515399933
train-epoch-step: 73-259 -- Loss: 0.11099163442850113
train-epoch-step: 73-260 -- Loss: 0.19227465987205505
train-epoch-step: 73-261 -- Loss: 0.16640426218509674
train-epoch-step: 73-262 -- Loss: 0.3058755099773407
train-epoch-step: 73-263 -- Loss: 0.19742335379123688
train-epoch-step: 73-264 -- Loss: 0.16598643362522125
train-epoch-step: 73-265 -- Loss: 0.10210078954696655
train-epoch-step: 73-266 -- Loss: 0.14977647364139557
train-epoch-step: 73-267 -- Loss: 0.1301465630531311
train-epoch-step: 73-268 -- Loss: 0.1163373738527298
train-epoch-step: 73-269 -- Loss: 0.1748901605606079
train-epoch-step: 73-270 -- Loss: 0.1052638366818428
train-epoch-step: 73-271 -- Loss: 0.14326344430446625
train-epoch-step: 73-272 -- Loss: 0.11169081926345825
train-epoch-step: 73-273 -- Loss: 0.12365463376045227
train-epoch-step: 73-274 -- Loss: 0.17466194927692413
train-epoch-step: 73-275 -- Loss: 0.18485897779464722
train-epoch-step: 73-276 -- Loss: 0.1487272083759308
train-epoch-step: 73-277 -- Loss: 0.14916923642158508
train-epoch-step: 73-278 -- Loss: 0.131600022315979
train-epoch-step: 73-279 -- Loss: 0.13182324171066284
train-epoch-step: 73-280 -- Loss: 0.21731093525886536
train-epoch-step: 73-281 -- Loss: 0.16977089643478394
train-epoch-step: 73-282 -- Loss: 0.13740599155426025
train-epoch-step: 73-283 -- Loss: 0.11144976317882538
train-epoch-step: 73-284 -- Loss: 0.21718940138816833
train-epoch-step: 73-285 -- Loss: 0.18476727604866028
train-epoch-step: 73-286 -- Loss: 0.14847099781036377
train-epoch-step: 73-287 -- Loss: 0.2088490128517151
train-epoch-step: 73-288 -- Loss: 0.09246038645505905
train-epoch-step: 73-289 -- Loss: 0.11888705939054489
train-epoch-step: 73-290 -- Loss: 0.1880488395690918
train-epoch-step: 73-291 -- Loss: 0.12166376411914825
train-epoch-step: 73-292 -- Loss: 0.1908283829689026
train-epoch-step: 73-293 -- Loss: 0.1437644213438034
train-epoch-step: 73-294 -- Loss: 0.19753816723823547
train-epoch-step: 73-295 -- Loss: 0.5187581181526184
train-epoch-step: 73-296 -- Loss: 0.32370710372924805
train-epoch-step: 73-297 -- Loss: 0.23882435262203217
train-epoch-step: 73-298 -- Loss: 0.23792923986911774
train-epoch-step: 73-299 -- Loss: 0.16450726985931396
train-epoch-step: 73-300 -- Loss: 0.17025648057460785
train-epoch-step: 73-301 -- Loss: 0.18736541271209717
train-epoch-step: 73-302 -- Loss: 0.2353767454624176
train-epoch-step: 73-303 -- Loss: 0.2235846221446991
train-epoch-step: 73-304 -- Loss: 0.14234989881515503
train-epoch-step: 73-305 -- Loss: 0.15154288709163666
train-epoch-step: 73-306 -- Loss: 0.27302086353302
train-epoch-step: 73-307 -- Loss: 0.18094885349273682
train-epoch-step: 73-308 -- Loss: 0.2411516159772873
train-epoch-step: 73-309 -- Loss: 0.16718947887420654
train-epoch-step: 73-310 -- Loss: 0.17216789722442627
train-epoch-step: 73-311 -- Loss: 0.17034758627414703
train-epoch-step: 73-312 -- Loss: 0.23867225646972656
train-epoch-step: 73-313 -- Loss: 0.11720380187034607
train-epoch-step: 73-314 -- Loss: 0.19785237312316895
train-epoch-step: 73-315 -- Loss: 0.17320793867111206
train-epoch-step: 73-316 -- Loss: 0.15613552927970886
train-epoch-step: 73-317 -- Loss: 0.15411359071731567
train-epoch-step: 73-318 -- Loss: 0.16837766766548157
train-epoch-step: 73-319 -- Loss: 0.19077160954475403
train-epoch-step: 73-320 -- Loss: 0.12511567771434784
train-epoch-step: 73-321 -- Loss: 0.16845133900642395
train-epoch-step: 73-322 -- Loss: 0.22969646751880646
train-epoch-step: 73-323 -- Loss: 0.1593414843082428
train-epoch-step: 73-324 -- Loss: 0.2545303702354431
train-epoch-step: 73-325 -- Loss: 0.16351418197155
train-epoch-step: 73-326 -- Loss: 0.1720348298549652
train-epoch-step: 73-327 -- Loss: 0.21630671620368958
train-epoch-step: 73-328 -- Loss: 0.1982765793800354
train-epoch-step: 73-329 -- Loss: 0.34449857473373413
train-epoch-step: 73-330 -- Loss: 0.3582979142665863
train-epoch-step: 73-331 -- Loss: 0.21293827891349792
train-epoch-step: 73-332 -- Loss: 0.10090360045433044
train-epoch-step: 73-333 -- Loss: 0.18952684104442596
train-epoch-step: 73-334 -- Loss: 0.16090065240859985
train-epoch-step: 73-335 -- Loss: 0.17136186361312866
train-epoch-step: 73-336 -- Loss: 0.1609322428703308
train-epoch-step: 73-337 -- Loss: 0.20316852629184723
train-epoch-step: 73-338 -- Loss: 0.1656462699174881
train-epoch-step: 73-339 -- Loss: 0.14242489635944366
train-epoch-step: 73-340 -- Loss: 0.19456303119659424
train-epoch-step: 73-341 -- Loss: 0.1388639360666275
train-epoch-step: 73-342 -- Loss: 0.16065454483032227
train-epoch-step: 73-343 -- Loss: 0.15537802875041962
train-epoch-step: 73-344 -- Loss: 0.16951803863048553
train-epoch-step: 73-345 -- Loss: 0.1322472095489502
train-epoch-step: 73-346 -- Loss: 0.208429753780365
train-epoch-step: 73-347 -- Loss: 0.15129096806049347
train-epoch-step: 73-348 -- Loss: 0.20730826258659363
train-epoch-step: 73-349 -- Loss: 0.20319393277168274
train-epoch-step: 73-350 -- Loss: 0.28544867038726807
train-epoch-step: 73-351 -- Loss: 0.1914001703262329
train-epoch-step: 73-352 -- Loss: 0.12680301070213318
train-epoch-step: 73-353 -- Loss: 0.19748449325561523
train-epoch-step: 73-354 -- Loss: 0.2852534055709839
train-epoch-step: 73-355 -- Loss: 0.1210193932056427
train-epoch-step: 73-356 -- Loss: 0.11788703501224518
train-epoch-step: 73-357 -- Loss: 0.19489315152168274
train-epoch-step: 73-358 -- Loss: 0.18872228264808655
train-epoch-step: 73-359 -- Loss: 0.13579969108104706
train-epoch-step: 73-360 -- Loss: 0.12067949026823044
train-epoch-step: 73-361 -- Loss: 0.2451125979423523
train-epoch-step: 73-362 -- Loss: 0.16772398352622986
train-epoch-step: 73-363 -- Loss: 0.10880103707313538
train-epoch-step: 73-364 -- Loss: 0.17956098914146423
train-epoch-step: 73-365 -- Loss: 0.16600725054740906
train-epoch-step: 73-366 -- Loss: 0.19644232094287872
train-epoch-step: 73-367 -- Loss: 0.2648564279079437
train-epoch-step: 73-368 -- Loss: 0.20749911665916443
train-epoch-step: 73-369 -- Loss: 0.271960586309433
train-epoch-step: 73-370 -- Loss: 0.12093429267406464
train-epoch-step: 73-371 -- Loss: 0.11871984601020813
train-epoch-step: 73-372 -- Loss: 0.1443839967250824
train-epoch-step: 73-373 -- Loss: 0.19511890411376953
train-epoch-step: 73-374 -- Loss: 0.15340548753738403
train-epoch-step: 73-375 -- Loss: 0.2635706067085266
train-epoch-step: 73-376 -- Loss: 0.17647312581539154
train-epoch-step: 73-377 -- Loss: 0.23470447957515717
train-epoch-step: 73-378 -- Loss: 0.19331470131874084
train-epoch-step: 73-379 -- Loss: 0.11513716727495193
train-epoch-step: 73-380 -- Loss: 0.0916738361120224
train-epoch-step: 73-381 -- Loss: 0.24540098011493683
train-epoch-step: 73-382 -- Loss: 0.24653232097625732
train-epoch-step: 73-383 -- Loss: 0.2111782729625702
train-epoch-step: 73-384 -- Loss: 0.2113378942012787
train-epoch-step: 73-385 -- Loss: 0.18898889422416687
train-epoch-step: 73-386 -- Loss: 0.24321022629737854
train-epoch-step: 73-387 -- Loss: 0.1976427137851715
train-epoch-step: 73-388 -- Loss: 0.19564791023731232
train-epoch-step: 73-389 -- Loss: 0.16720116138458252
train-epoch-step: 73-390 -- Loss: 0.13848142325878143
train-epoch-step: 73-391 -- Loss: 0.1469515562057495
train-epoch-step: 73-392 -- Loss: 0.18212133646011353
train-epoch-step: 73-393 -- Loss: 0.1551005244255066
train-epoch-step: 73-394 -- Loss: 0.19764520227909088
train-epoch-step: 73-395 -- Loss: 0.15818101167678833
train-epoch-step: 73-396 -- Loss: 0.13003632426261902
train-epoch-step: 73-397 -- Loss: 0.1208091527223587
train-epoch-step: 73-398 -- Loss: 0.19561362266540527
train-epoch-step: 73-399 -- Loss: 0.1789618283510208
train-epoch-step: 73-400 -- Loss: 0.26926225423812866
train-epoch-step: 73-401 -- Loss: 0.1190691590309143
train-epoch-step: 73-402 -- Loss: 0.26139330863952637
train-epoch-step: 73-403 -- Loss: 0.16063237190246582
train-epoch-step: 73-404 -- Loss: 0.135664701461792
train-epoch-step: 73-405 -- Loss: 0.1492091715335846
train-epoch-step: 73-406 -- Loss: 0.17191356420516968
train-epoch-step: 73-407 -- Loss: 0.11078239232301712
train-epoch-step: 73-408 -- Loss: 0.15749813616275787
train-epoch-step: 73-409 -- Loss: 0.17038404941558838
train-epoch-step: 73-410 -- Loss: 0.17497456073760986
train-epoch-step: 73-411 -- Loss: 0.19837689399719238
train-epoch-step: 73-412 -- Loss: 0.1275217980146408
train-epoch-step: 73-413 -- Loss: 0.14420157670974731
train-epoch-step: 73-414 -- Loss: 0.13065049052238464
train-epoch-step: 73-415 -- Loss: 0.1394631415605545
train-epoch-step: 73-416 -- Loss: 0.2788981795310974
train-epoch-step: 73-417 -- Loss: 0.18790853023529053
train-epoch-step: 73-418 -- Loss: 0.22918099164962769
train-epoch-step: 73-419 -- Loss: 0.16453103721141815
train-epoch-step: 73-420 -- Loss: 0.15010155737400055
train-epoch-step: 73-421 -- Loss: 0.17338217794895172
train-epoch-step: 73-422 -- Loss: 0.1476563811302185
train-epoch-step: 73-423 -- Loss: 0.17209479212760925
train-epoch-step: 73-424 -- Loss: 0.13771368563175201
train-epoch-step: 73-425 -- Loss: 0.18341566622257233
train-epoch-step: 73-426 -- Loss: 0.16594092547893524
train-epoch-step: 73-427 -- Loss: 0.11802853643894196
train-epoch-step: 73-428 -- Loss: 0.18875786662101746
train-epoch-step: 73-429 -- Loss: 0.17158277332782745
train-epoch-step: 73-430 -- Loss: 0.1437673717737198
train-epoch-step: 73-431 -- Loss: 0.15621116757392883
train-epoch-step: 73-432 -- Loss: 0.2359059900045395
train-epoch-step: 73-433 -- Loss: 0.13374096155166626
train-epoch-step: 73-434 -- Loss: 0.12901058793067932
train-epoch-step: 73-435 -- Loss: 0.14877060055732727
train-epoch-step: 73-436 -- Loss: 0.1526181995868683
train-epoch-step: 73-437 -- Loss: 0.13025400042533875
train-epoch-step: 73-438 -- Loss: 0.1636664718389511
train-epoch-step: 73-439 -- Loss: 0.2748345732688904
train-epoch-step: 73-440 -- Loss: 0.13218502700328827
train-epoch-step: 73-441 -- Loss: 0.19867241382598877
train-epoch-step: 73-442 -- Loss: 0.1732027530670166
train-epoch-step: 73-443 -- Loss: 0.15799038112163544
train-epoch-step: 73-444 -- Loss: 0.17266884446144104
train-epoch-step: 73-445 -- Loss: 0.17437399923801422
train-epoch-step: 73-446 -- Loss: 0.14603035151958466
train-epoch-step: 73-447 -- Loss: 0.18685771524906158
train-epoch-step: 73-448 -- Loss: 0.2218410074710846
train-epoch-step: 73-449 -- Loss: 0.19526763260364532
train-epoch-step: 73-450 -- Loss: 0.1765483319759369
train-epoch-step: 73-451 -- Loss: 0.14119911193847656
train-epoch-step: 73-452 -- Loss: 0.1291024386882782
train-epoch-step: 73-453 -- Loss: 0.08924353867769241
train-epoch-step: 73-454 -- Loss: 0.22503028810024261
train-epoch-step: 73-455 -- Loss: 0.1360732614994049
train-epoch-step: 73-456 -- Loss: 0.12113456428050995
train-epoch-step: 73-457 -- Loss: 0.21029740571975708
train-epoch-step: 73-458 -- Loss: 0.147409588098526
train-epoch-step: 73-459 -- Loss: 0.20813408493995667
train-epoch-step: 73-460 -- Loss: 0.12459193170070648
train-epoch-step: 73-461 -- Loss: 0.1289234161376953
train-epoch-step: 73-462 -- Loss: 0.15858720242977142
train-epoch-step: 73-463 -- Loss: 0.12897074222564697
train-epoch-step: 73-464 -- Loss: 0.15730448067188263
train-epoch-step: 73-465 -- Loss: 0.23648974299430847
train-epoch-step: 73-466 -- Loss: 0.1966451108455658
train-epoch-step: 73-467 -- Loss: 0.10878171771764755
train-epoch-step: 73-468 -- Loss: 0.15933886170387268
train-epoch-step: 73-469 -- Loss: 0.2014906406402588
train-epoch-step: 73-470 -- Loss: 0.1697980761528015
train-epoch-step: 73-471 -- Loss: 0.15777042508125305
train-epoch-step: 73-472 -- Loss: 0.15550680458545685
train-epoch-step: 73-473 -- Loss: 0.14853310585021973
train-epoch-step: 73-474 -- Loss: 0.1166849434375763
train-epoch-step: 73-475 -- Loss: 0.10594695061445236
train-epoch-step: 73-476 -- Loss: 0.2036246657371521
train-epoch-step: 73-477 -- Loss: 0.19401928782463074
train-epoch-step: 73-478 -- Loss: 0.19223518669605255
train-epoch-step: 73-479 -- Loss: 0.13813133537769318
train-epoch-step: 73-480 -- Loss: 0.19457796216011047
train-epoch-step: 73-481 -- Loss: 0.2769569754600525
train-epoch-step: 73-482 -- Loss: 0.24543558061122894
train-epoch-step: 73-483 -- Loss: 0.17152489721775055
train-epoch-step: 73-484 -- Loss: 0.20559179782867432
train-epoch-step: 73-485 -- Loss: 0.12309686839580536
train-epoch-step: 73-486 -- Loss: 0.2361440658569336
train-epoch-step: 73-487 -- Loss: 0.2258085012435913
train-epoch-step: 73-488 -- Loss: 0.18451984226703644
train-epoch-step: 73-489 -- Loss: 0.21772268414497375
train-epoch-step: 73-490 -- Loss: 0.13182352483272552
train-epoch-step: 73-491 -- Loss: 0.13973502814769745
train-epoch-step: 73-492 -- Loss: 0.131964772939682
train-epoch-step: 73-493 -- Loss: 0.19106389582157135
train-epoch-step: 73-494 -- Loss: 0.19367828965187073
train-epoch-step: 73-495 -- Loss: 0.20421327650547028
train-epoch-step: 73-496 -- Loss: 0.13614585995674133
train-epoch-step: 73-497 -- Loss: 0.1799965798854828
train-epoch-step: 73-498 -- Loss: 0.14400289952754974
train-epoch-step: 73-499 -- Loss: 0.16361838579177856
train-epoch-step: 73-500 -- Loss: 0.151657834649086
train-epoch-step: 73-501 -- Loss: 0.20447459816932678
train-epoch-step: 73-502 -- Loss: 0.16721412539482117
train-epoch-step: 73-503 -- Loss: 0.21184423565864563
train-epoch-step: 73-504 -- Loss: 0.12290975451469421
train-epoch-step: 73-505 -- Loss: 0.16977687180042267
train-epoch-step: 73-506 -- Loss: 0.11442627012729645
train-epoch-step: 73-507 -- Loss: 0.18252219259738922
train-epoch-step: 73-508 -- Loss: 0.1738903671503067
train-epoch-step: 73-509 -- Loss: 0.1669912040233612
train-epoch-step: 73-510 -- Loss: 0.1256403774023056
train-epoch-step: 73-511 -- Loss: 0.20867812633514404
train-epoch-step: 73-512 -- Loss: 0.17235764861106873
train-epoch-step: 73-513 -- Loss: 0.18212583661079407
train-epoch-step: 73-514 -- Loss: 0.14212067425251007
train-epoch-step: 73-515 -- Loss: 0.15112408995628357
train-epoch-step: 73-516 -- Loss: 0.16928349435329437
train-epoch-step: 73-517 -- Loss: 0.1691330522298813
train-epoch-step: 73-518 -- Loss: 0.13406996428966522
train-epoch-step: 73-519 -- Loss: 0.13305915892124176
train-epoch-step: 73-520 -- Loss: 0.18102608621120453
train-epoch-step: 73-521 -- Loss: 0.2238411009311676
train-epoch-step: 73-522 -- Loss: 0.17147396504878998
train-epoch-step: 73-523 -- Loss: 0.1542709469795227
train-epoch-step: 73-524 -- Loss: 0.16448789834976196
train-epoch-step: 73-525 -- Loss: 0.1917346864938736
train-epoch-step: 73-526 -- Loss: 0.12519221007823944
train-epoch-step: 73-527 -- Loss: 0.146653950214386
train-epoch-step: 73-528 -- Loss: 0.15204553306102753
train-epoch-step: 73-529 -- Loss: 0.14875805377960205
train-epoch-step: 73-530 -- Loss: 0.16884559392929077
train-epoch-step: 73-531 -- Loss: 0.18793033063411713
train-epoch-step: 73-532 -- Loss: 0.16347727179527283
train-epoch-step: 73-533 -- Loss: 0.16703039407730103
train-epoch-step: 73-534 -- Loss: 0.12610669434070587
train-epoch-step: 73-535 -- Loss: 0.24271202087402344
train-epoch-step: 73-536 -- Loss: 0.151727095246315
train-epoch-step: 73-537 -- Loss: 0.1487845480442047
train-epoch-step: 73-538 -- Loss: 0.09833485633134842
train-epoch-step: 73-539 -- Loss: 0.17492707073688507
train-epoch-step: 73-540 -- Loss: 0.1347619891166687
train-epoch-step: 73-541 -- Loss: 0.20228025317192078
train-epoch-step: 73-542 -- Loss: 0.23670026659965515
train-epoch-step: 73-543 -- Loss: 0.1652241349220276
train-epoch-step: 73-544 -- Loss: 0.2180595099925995
train-epoch-step: 73-545 -- Loss: 0.18529804050922394
train-epoch-step: 73-546 -- Loss: 0.19760571420192719
train-epoch-step: 73-547 -- Loss: 0.17670659720897675
train-epoch-step: 73-548 -- Loss: 0.09062027186155319
train-epoch-step: 73-549 -- Loss: 0.14240197837352753
train-epoch-step: 73-550 -- Loss: 0.1970304250717163
train-epoch-step: 73-551 -- Loss: 0.15387535095214844
train-epoch-step: 73-552 -- Loss: 0.12278638780117035
train-epoch-step: 73-553 -- Loss: 0.18328215181827545
train-epoch-step: 73-554 -- Loss: 0.18137921392917633
train-epoch-step: 73-555 -- Loss: 0.20914869010448456
train-epoch-step: 73-556 -- Loss: 0.1421511173248291
train-epoch-step: 73-557 -- Loss: 0.23668405413627625
train-epoch-step: 73-558 -- Loss: 0.2247314304113388
train-epoch-step: 73-559 -- Loss: 0.1317499577999115
train-epoch-step: 73-560 -- Loss: 0.19608542323112488
train-epoch-step: 73-561 -- Loss: 0.1756855696439743
train-epoch-step: 73-562 -- Loss: 0.1621355563402176
train-epoch-step: 73-563 -- Loss: 0.18256135284900665
train-epoch-step: 73-564 -- Loss: 0.09866264462471008
train-epoch-step: 73-565 -- Loss: 0.18114563822746277
train-epoch-step: 73-566 -- Loss: 0.14370869100093842
train-epoch-step: 73-567 -- Loss: 0.20395004749298096
train-epoch-step: 73-568 -- Loss: 0.15637370944023132
train-epoch-step: 73-569 -- Loss: 0.23947285115718842
train-epoch-step: 73-570 -- Loss: 0.1570693850517273
train-epoch-step: 73-571 -- Loss: 0.2019614279270172
train-epoch-step: 73-572 -- Loss: 0.22882521152496338
train-epoch-step: 73-573 -- Loss: 0.19454708695411682
train-epoch-step: 73-574 -- Loss: 0.2407730519771576
train-epoch-step: 73-575 -- Loss: 0.2908112108707428
train-epoch-step: 73-576 -- Loss: 0.11337700486183167
train-epoch-step: 73-577 -- Loss: 0.15987874567508698
train-epoch-step: 73-578 -- Loss: 0.20701134204864502
train-epoch-step: 73-579 -- Loss: 0.1627066731452942
train-epoch-step: 73-580 -- Loss: 0.16965162754058838
train-epoch-step: 73-581 -- Loss: 0.13693955540657043
train-epoch-step: 73-582 -- Loss: 0.2020481526851654
train-epoch-step: 73-583 -- Loss: 0.20679500699043274
train-epoch-step: 73-584 -- Loss: 0.15850883722305298
train-epoch-step: 73-585 -- Loss: 0.193803071975708
train-epoch-step: 73-586 -- Loss: 0.25227439403533936
train-epoch-step: 73-587 -- Loss: 0.15467528998851776
train-epoch-step: 73-588 -- Loss: 0.12474329024553299
val-epoch-step: 73-589 -- Loss: 0.19622494280338287
val-epoch-step: 73-590 -- Loss: 0.1583017110824585
val-epoch-step: 73-591 -- Loss: 0.2368822693824768
val-epoch-step: 73-592 -- Loss: 0.17235790193080902
val-epoch-step: 73-593 -- Loss: 0.19635891914367676
val-epoch-step: 73-594 -- Loss: 0.43109744787216187
val-epoch-step: 73-595 -- Loss: 0.18108244240283966
val-epoch-step: 73-596 -- Loss: 0.19960127770900726
val-epoch-step: 73-597 -- Loss: 0.17436973750591278
val-epoch-step: 73-598 -- Loss: 0.14768491685390472
val-epoch-step: 73-599 -- Loss: 0.18216422200202942
val-epoch-step: 73-600 -- Loss: 0.1673104614019394
val-epoch-step: 73-601 -- Loss: 0.1576671600341797
val-epoch-step: 73-602 -- Loss: 0.1324911266565323
val-epoch-step: 73-603 -- Loss: 0.2179761826992035
val-epoch-step: 73-604 -- Loss: 0.14223261177539825
val-epoch-step: 73-605 -- Loss: 0.14321720600128174
val-epoch-step: 73-606 -- Loss: 0.24096368253231049
val-epoch-step: 73-607 -- Loss: 0.12275076657533646
val-epoch-step: 73-608 -- Loss: 0.2409394532442093
val-epoch-step: 73-609 -- Loss: 0.17274914681911469
val-epoch-step: 73-610 -- Loss: 0.17669612169265747
val-epoch-step: 73-611 -- Loss: 0.15767738223075867
val-epoch-step: 73-612 -- Loss: 0.42143726348876953
val-epoch-step: 73-613 -- Loss: 0.1707509309053421
val-epoch-step: 73-614 -- Loss: 0.17058515548706055
val-epoch-step: 73-615 -- Loss: 0.17321546375751495
val-epoch-step: 73-616 -- Loss: 0.14322197437286377
val-epoch-step: 73-617 -- Loss: 0.18733125925064087
val-epoch-step: 73-618 -- Loss: 0.20114055275917053
val-epoch-step: 73-619 -- Loss: 0.2060626745223999
val-epoch-step: 73-620 -- Loss: 0.13655143976211548
val-epoch-step: 73-621 -- Loss: 0.12342637777328491
val-epoch-step: 73-622 -- Loss: 0.13985155522823334
val-epoch-step: 73-623 -- Loss: 0.15119771659374237
val-epoch-step: 73-624 -- Loss: 0.13907663524150848
val-epoch-step: 73-625 -- Loss: 0.15021230280399323
val-epoch-step: 73-626 -- Loss: 0.14511506259441376
val-epoch-step: 73-627 -- Loss: 0.17612971365451813
val-epoch-step: 73-628 -- Loss: 0.6564610600471497
val-epoch-step: 73-629 -- Loss: 0.21121454238891602
val-epoch-step: 73-630 -- Loss: 0.34517067670822144
val-epoch-step: 73-631 -- Loss: 0.13584595918655396
val-epoch-step: 73-632 -- Loss: 0.21266667544841766
val-epoch-step: 73-633 -- Loss: 0.14557965099811554
val-epoch-step: 73-634 -- Loss: 0.14625035226345062
val-epoch-step: 73-635 -- Loss: 0.11594339460134506
val-epoch-step: 73-636 -- Loss: 0.15841396152973175
val-epoch-step: 73-637 -- Loss: 0.18212974071502686
val-epoch-step: 73-638 -- Loss: 0.1439702808856964
val-epoch-step: 73-639 -- Loss: 0.24880041182041168
val-epoch-step: 73-640 -- Loss: 0.2533620595932007
val-epoch-step: 73-641 -- Loss: 0.12912985682487488
val-epoch-step: 73-642 -- Loss: 0.1787215769290924
val-epoch-step: 73-643 -- Loss: 0.19949257373809814
val-epoch-step: 73-644 -- Loss: 0.1618715226650238
val-epoch-step: 73-645 -- Loss: 0.21861271560192108
val-epoch-step: 73-646 -- Loss: 0.15528731048107147
val-epoch-step: 73-647 -- Loss: 0.12478003650903702
val-epoch-step: 73-648 -- Loss: 0.1500595510005951
val-epoch-step: 73-649 -- Loss: 0.2073696106672287
val-epoch-step: 73-650 -- Loss: 0.2469489872455597
val-epoch-step: 73-651 -- Loss: 0.14607518911361694
val-epoch-step: 73-652 -- Loss: 0.15283909440040588
val-epoch-step: 73-653 -- Loss: 0.1883576214313507
val-epoch-step: 73-654 -- Loss: 0.10833989083766937
Epoch: 73 -- Train Loss: tensor(0.1396, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 74-0 -- Loss: 0.21956774592399597
train-epoch-step: 74-1 -- Loss: 0.1395055502653122
train-epoch-step: 74-2 -- Loss: 0.19148586690425873
train-epoch-step: 74-3 -- Loss: 0.1418343186378479
train-epoch-step: 74-4 -- Loss: 0.15453065931797028
train-epoch-step: 74-5 -- Loss: 0.16894561052322388
train-epoch-step: 74-6 -- Loss: 0.21499940752983093
train-epoch-step: 74-7 -- Loss: 0.16334140300750732
train-epoch-step: 74-8 -- Loss: 0.1741648018360138
train-epoch-step: 74-9 -- Loss: 0.2143416851758957
train-epoch-step: 74-10 -- Loss: 0.1938299834728241
train-epoch-step: 74-11 -- Loss: 0.16845202445983887
train-epoch-step: 74-12 -- Loss: 0.14545050263404846
train-epoch-step: 74-13 -- Loss: 0.17859962582588196
train-epoch-step: 74-14 -- Loss: 0.15757520496845245
train-epoch-step: 74-15 -- Loss: 0.15828512609004974
train-epoch-step: 74-16 -- Loss: 0.15986426174640656
train-epoch-step: 74-17 -- Loss: 0.2125944346189499
train-epoch-step: 74-18 -- Loss: 0.18814623355865479
train-epoch-step: 74-19 -- Loss: 0.12679001688957214
train-epoch-step: 74-20 -- Loss: 0.2065104991197586
train-epoch-step: 74-21 -- Loss: 0.26915234327316284
train-epoch-step: 74-22 -- Loss: 0.1367688626050949
train-epoch-step: 74-23 -- Loss: 0.1360236555337906
train-epoch-step: 74-24 -- Loss: 0.12170359492301941
train-epoch-step: 74-25 -- Loss: 0.23104050755500793
train-epoch-step: 74-26 -- Loss: 0.18374961614608765
train-epoch-step: 74-27 -- Loss: 0.22979916632175446
train-epoch-step: 74-28 -- Loss: 0.11970223486423492
train-epoch-step: 74-29 -- Loss: 0.23831039667129517
train-epoch-step: 74-30 -- Loss: 0.1095220148563385
train-epoch-step: 74-31 -- Loss: 0.12856878340244293
train-epoch-step: 74-32 -- Loss: 0.17024487257003784
train-epoch-step: 74-33 -- Loss: 0.26401200890541077
train-epoch-step: 74-34 -- Loss: 0.16496816277503967
train-epoch-step: 74-35 -- Loss: 0.22694939374923706
train-epoch-step: 74-36 -- Loss: 0.13530570268630981
train-epoch-step: 74-37 -- Loss: 0.1381419450044632
train-epoch-step: 74-38 -- Loss: 0.17449596524238586
train-epoch-step: 74-39 -- Loss: 0.20805791020393372
train-epoch-step: 74-40 -- Loss: 0.18583077192306519
train-epoch-step: 74-41 -- Loss: 0.22428981959819794
train-epoch-step: 74-42 -- Loss: 0.14676617085933685
train-epoch-step: 74-43 -- Loss: 0.2547817826271057
train-epoch-step: 74-44 -- Loss: 0.1213434562087059
train-epoch-step: 74-45 -- Loss: 0.11215659230947495
train-epoch-step: 74-46 -- Loss: 0.1597665548324585
train-epoch-step: 74-47 -- Loss: 0.19260737299919128
train-epoch-step: 74-48 -- Loss: 0.15108619630336761
train-epoch-step: 74-49 -- Loss: 0.2173115462064743
train-epoch-step: 74-50 -- Loss: 0.10989202558994293
train-epoch-step: 74-51 -- Loss: 0.1716161072254181
train-epoch-step: 74-52 -- Loss: 0.1591520756483078
train-epoch-step: 74-53 -- Loss: 0.20184259116649628
train-epoch-step: 74-54 -- Loss: 0.2746396064758301
train-epoch-step: 74-55 -- Loss: 0.15942618250846863
train-epoch-step: 74-56 -- Loss: 0.17010538280010223
train-epoch-step: 74-57 -- Loss: 0.23296186327934265
train-epoch-step: 74-58 -- Loss: 0.2762186527252197
train-epoch-step: 74-59 -- Loss: 0.22674819827079773
train-epoch-step: 74-60 -- Loss: 0.12600409984588623
train-epoch-step: 74-61 -- Loss: 0.1958935707807541
train-epoch-step: 74-62 -- Loss: 0.17686688899993896
train-epoch-step: 74-63 -- Loss: 0.13001056015491486
train-epoch-step: 74-64 -- Loss: 0.13747994601726532
train-epoch-step: 74-65 -- Loss: 0.1768278330564499
train-epoch-step: 74-66 -- Loss: 0.10579932481050491
train-epoch-step: 74-67 -- Loss: 0.12190936505794525
train-epoch-step: 74-68 -- Loss: 0.20121347904205322
train-epoch-step: 74-69 -- Loss: 0.1198909729719162
train-epoch-step: 74-70 -- Loss: 0.2135930061340332
train-epoch-step: 74-71 -- Loss: 0.25091278553009033
train-epoch-step: 74-72 -- Loss: 0.1649474948644638
train-epoch-step: 74-73 -- Loss: 0.20016074180603027
train-epoch-step: 74-74 -- Loss: 0.09184696525335312
train-epoch-step: 74-75 -- Loss: 0.12455005198717117
train-epoch-step: 74-76 -- Loss: 0.14243312180042267
train-epoch-step: 74-77 -- Loss: 0.22178000211715698
train-epoch-step: 74-78 -- Loss: 0.24748817086219788
train-epoch-step: 74-79 -- Loss: 0.19250448048114777
train-epoch-step: 74-80 -- Loss: 0.2393137514591217
train-epoch-step: 74-81 -- Loss: 0.11740559339523315
train-epoch-step: 74-82 -- Loss: 0.23721528053283691
train-epoch-step: 74-83 -- Loss: 0.17074090242385864
train-epoch-step: 74-84 -- Loss: 0.18639050424098969
train-epoch-step: 74-85 -- Loss: 0.16897699236869812
train-epoch-step: 74-86 -- Loss: 0.11631017178297043
train-epoch-step: 74-87 -- Loss: 0.19827190041542053
train-epoch-step: 74-88 -- Loss: 0.13846729695796967
train-epoch-step: 74-89 -- Loss: 0.1808415949344635
train-epoch-step: 74-90 -- Loss: 0.1852719485759735
train-epoch-step: 74-91 -- Loss: 0.2459157407283783
train-epoch-step: 74-92 -- Loss: 0.15099555253982544
train-epoch-step: 74-93 -- Loss: 0.16198264062404633
train-epoch-step: 74-94 -- Loss: 0.20872965455055237
train-epoch-step: 74-95 -- Loss: 0.18230599164962769
train-epoch-step: 74-96 -- Loss: 0.2063300907611847
train-epoch-step: 74-97 -- Loss: 0.16767944395542145
train-epoch-step: 74-98 -- Loss: 0.15125620365142822
train-epoch-step: 74-99 -- Loss: 0.17546015977859497
train-epoch-step: 74-100 -- Loss: 0.18081118166446686
train-epoch-step: 74-101 -- Loss: 0.25396308302879333
train-epoch-step: 74-102 -- Loss: 0.20846286416053772
train-epoch-step: 74-103 -- Loss: 0.18221519887447357
train-epoch-step: 74-104 -- Loss: 0.14423750340938568
train-epoch-step: 74-105 -- Loss: 0.262753427028656
train-epoch-step: 74-106 -- Loss: 0.16963553428649902
train-epoch-step: 74-107 -- Loss: 0.18094004690647125
train-epoch-step: 74-108 -- Loss: 0.18299318850040436
train-epoch-step: 74-109 -- Loss: 0.14787845313549042
train-epoch-step: 74-110 -- Loss: 0.17650941014289856
train-epoch-step: 74-111 -- Loss: 0.17902550101280212
train-epoch-step: 74-112 -- Loss: 0.1647866815328598
train-epoch-step: 74-113 -- Loss: 0.15470945835113525
train-epoch-step: 74-114 -- Loss: 0.18890118598937988
train-epoch-step: 74-115 -- Loss: 0.15619468688964844
train-epoch-step: 74-116 -- Loss: 0.13441944122314453
train-epoch-step: 74-117 -- Loss: 0.1264619529247284
train-epoch-step: 74-118 -- Loss: 0.18817268311977386
train-epoch-step: 74-119 -- Loss: 0.15818354487419128
train-epoch-step: 74-120 -- Loss: 0.24599245190620422
train-epoch-step: 74-121 -- Loss: 0.23903653025627136
train-epoch-step: 74-122 -- Loss: 0.20584549009799957
train-epoch-step: 74-123 -- Loss: 0.19569119811058044
train-epoch-step: 74-124 -- Loss: 0.12018771469593048
train-epoch-step: 74-125 -- Loss: 0.15004177391529083
train-epoch-step: 74-126 -- Loss: 0.22432667016983032
train-epoch-step: 74-127 -- Loss: 0.1582946479320526
train-epoch-step: 74-128 -- Loss: 0.1701226830482483
train-epoch-step: 74-129 -- Loss: 0.13139024376869202
train-epoch-step: 74-130 -- Loss: 0.18074455857276917
train-epoch-step: 74-131 -- Loss: 0.1340354084968567
train-epoch-step: 74-132 -- Loss: 0.19367830455303192
train-epoch-step: 74-133 -- Loss: 0.1171906515955925
train-epoch-step: 74-134 -- Loss: 0.1934618353843689
train-epoch-step: 74-135 -- Loss: 0.13731810450553894
train-epoch-step: 74-136 -- Loss: 0.12326866388320923
train-epoch-step: 74-137 -- Loss: 0.23542840778827667
train-epoch-step: 74-138 -- Loss: 0.24941815435886383
train-epoch-step: 74-139 -- Loss: 0.12960097193717957
train-epoch-step: 74-140 -- Loss: 0.20168811082839966
train-epoch-step: 74-141 -- Loss: 0.22998479008674622
train-epoch-step: 74-142 -- Loss: 0.19884341955184937
train-epoch-step: 74-143 -- Loss: 0.16733518242835999
train-epoch-step: 74-144 -- Loss: 0.1824432760477066
train-epoch-step: 74-145 -- Loss: 0.1366075724363327
train-epoch-step: 74-146 -- Loss: 0.18221551179885864
train-epoch-step: 74-147 -- Loss: 0.16488924622535706
train-epoch-step: 74-148 -- Loss: 0.15426504611968994
train-epoch-step: 74-149 -- Loss: 0.11643365770578384
train-epoch-step: 74-150 -- Loss: 0.1829432249069214
train-epoch-step: 74-151 -- Loss: 0.18336068093776703
train-epoch-step: 74-152 -- Loss: 0.1857602298259735
train-epoch-step: 74-153 -- Loss: 0.2566649913787842
train-epoch-step: 74-154 -- Loss: 0.12954773008823395
train-epoch-step: 74-155 -- Loss: 0.13438300788402557
train-epoch-step: 74-156 -- Loss: 0.11498542129993439
train-epoch-step: 74-157 -- Loss: 0.16084423661231995
train-epoch-step: 74-158 -- Loss: 0.16081860661506653
train-epoch-step: 74-159 -- Loss: 0.17076879739761353
train-epoch-step: 74-160 -- Loss: 0.20626461505889893
train-epoch-step: 74-161 -- Loss: 0.2021932601928711
train-epoch-step: 74-162 -- Loss: 0.20505616068840027
train-epoch-step: 74-163 -- Loss: 0.1853492558002472
train-epoch-step: 74-164 -- Loss: 0.18663987517356873
train-epoch-step: 74-165 -- Loss: 0.15680019557476044
train-epoch-step: 74-166 -- Loss: 0.11633430421352386
train-epoch-step: 74-167 -- Loss: 0.11571437120437622
train-epoch-step: 74-168 -- Loss: 0.19314667582511902
train-epoch-step: 74-169 -- Loss: 0.13485758006572723
train-epoch-step: 74-170 -- Loss: 0.1940668821334839
train-epoch-step: 74-171 -- Loss: 0.14081944525241852
train-epoch-step: 74-172 -- Loss: 0.25183427333831787
train-epoch-step: 74-173 -- Loss: 0.129677414894104
train-epoch-step: 74-174 -- Loss: 0.23956647515296936
train-epoch-step: 74-175 -- Loss: 0.18077436089515686
train-epoch-step: 74-176 -- Loss: 0.12555569410324097
train-epoch-step: 74-177 -- Loss: 0.17559877038002014
train-epoch-step: 74-178 -- Loss: 0.17698338627815247
train-epoch-step: 74-179 -- Loss: 0.1414298415184021
train-epoch-step: 74-180 -- Loss: 0.1481384038925171
train-epoch-step: 74-181 -- Loss: 0.1632082760334015
train-epoch-step: 74-182 -- Loss: 0.17877018451690674
train-epoch-step: 74-183 -- Loss: 0.2601339817047119
train-epoch-step: 74-184 -- Loss: 0.1322159618139267
train-epoch-step: 74-185 -- Loss: 0.13601729273796082
train-epoch-step: 74-186 -- Loss: 0.18000273406505585
train-epoch-step: 74-187 -- Loss: 0.2058926373720169
train-epoch-step: 74-188 -- Loss: 0.16618753969669342
train-epoch-step: 74-189 -- Loss: 0.10403205454349518
train-epoch-step: 74-190 -- Loss: 0.17436583340168
train-epoch-step: 74-191 -- Loss: 0.15333127975463867
train-epoch-step: 74-192 -- Loss: 0.21899765729904175
train-epoch-step: 74-193 -- Loss: 0.19764134287834167
train-epoch-step: 74-194 -- Loss: 0.1778409779071808
train-epoch-step: 74-195 -- Loss: 0.15772397816181183
train-epoch-step: 74-196 -- Loss: 0.1629791259765625
train-epoch-step: 74-197 -- Loss: 0.11937295645475388
train-epoch-step: 74-198 -- Loss: 0.12855055928230286
train-epoch-step: 74-199 -- Loss: 0.1409561187028885
train-epoch-step: 74-200 -- Loss: 0.11912033706903458
train-epoch-step: 74-201 -- Loss: 0.1843753308057785
train-epoch-step: 74-202 -- Loss: 0.1361076831817627
train-epoch-step: 74-203 -- Loss: 0.16640010476112366
train-epoch-step: 74-204 -- Loss: 0.13211236894130707
train-epoch-step: 74-205 -- Loss: 0.18013569712638855
train-epoch-step: 74-206 -- Loss: 0.192951500415802
train-epoch-step: 74-207 -- Loss: 0.15298467874526978
train-epoch-step: 74-208 -- Loss: 0.17321649193763733
train-epoch-step: 74-209 -- Loss: 0.14001038670539856
train-epoch-step: 74-210 -- Loss: 0.1283530294895172
train-epoch-step: 74-211 -- Loss: 0.19568082690238953
train-epoch-step: 74-212 -- Loss: 0.19438989460468292
train-epoch-step: 74-213 -- Loss: 0.12743379175662994
train-epoch-step: 74-214 -- Loss: 0.14484286308288574
train-epoch-step: 74-215 -- Loss: 0.12486841529607773
train-epoch-step: 74-216 -- Loss: 0.19408825039863586
train-epoch-step: 74-217 -- Loss: 0.2040153443813324
train-epoch-step: 74-218 -- Loss: 0.13985036313533783
train-epoch-step: 74-219 -- Loss: 0.1645750254392624
train-epoch-step: 74-220 -- Loss: 0.12709131836891174
train-epoch-step: 74-221 -- Loss: 0.19828680157661438
train-epoch-step: 74-222 -- Loss: 0.11307920515537262
train-epoch-step: 74-223 -- Loss: 0.17328618466854095
train-epoch-step: 74-224 -- Loss: 0.18122097849845886
train-epoch-step: 74-225 -- Loss: 0.2575232684612274
train-epoch-step: 74-226 -- Loss: 0.19898344576358795
train-epoch-step: 74-227 -- Loss: 0.2163594365119934
train-epoch-step: 74-228 -- Loss: 0.19501392543315887
train-epoch-step: 74-229 -- Loss: 0.16589154303073883
train-epoch-step: 74-230 -- Loss: 0.15972205996513367
train-epoch-step: 74-231 -- Loss: 0.14913281798362732
train-epoch-step: 74-232 -- Loss: 0.17378051578998566
train-epoch-step: 74-233 -- Loss: 0.08246654272079468
train-epoch-step: 74-234 -- Loss: 0.17160409688949585
train-epoch-step: 74-235 -- Loss: 0.1444610357284546
train-epoch-step: 74-236 -- Loss: 0.17248325049877167
train-epoch-step: 74-237 -- Loss: 0.23624756932258606
train-epoch-step: 74-238 -- Loss: 0.150656059384346
train-epoch-step: 74-239 -- Loss: 0.12168864905834198
train-epoch-step: 74-240 -- Loss: 0.21728754043579102
train-epoch-step: 74-241 -- Loss: 0.14697706699371338
train-epoch-step: 74-242 -- Loss: 0.21134819090366364
train-epoch-step: 74-243 -- Loss: 0.22736512124538422
train-epoch-step: 74-244 -- Loss: 0.19599038362503052
train-epoch-step: 74-245 -- Loss: 0.20337915420532227
train-epoch-step: 74-246 -- Loss: 0.21368606388568878
train-epoch-step: 74-247 -- Loss: 0.20571808516979218
train-epoch-step: 74-248 -- Loss: 0.17833511531352997
train-epoch-step: 74-249 -- Loss: 0.13236533105373383
train-epoch-step: 74-250 -- Loss: 0.19149334728717804
train-epoch-step: 74-251 -- Loss: 0.10366825759410858
train-epoch-step: 74-252 -- Loss: 0.19316211342811584
train-epoch-step: 74-253 -- Loss: 0.13046011328697205
train-epoch-step: 74-254 -- Loss: 0.20395199954509735
train-epoch-step: 74-255 -- Loss: 0.14049237966537476
train-epoch-step: 74-256 -- Loss: 0.14141112565994263
train-epoch-step: 74-257 -- Loss: 0.17929589748382568
train-epoch-step: 74-258 -- Loss: 0.1386510133743286
train-epoch-step: 74-259 -- Loss: 0.10835318267345428
train-epoch-step: 74-260 -- Loss: 0.1932418942451477
train-epoch-step: 74-261 -- Loss: 0.16393142938613892
train-epoch-step: 74-262 -- Loss: 0.27637720108032227
train-epoch-step: 74-263 -- Loss: 0.1936148703098297
train-epoch-step: 74-264 -- Loss: 0.16743022203445435
train-epoch-step: 74-265 -- Loss: 0.1068689152598381
train-epoch-step: 74-266 -- Loss: 0.14564594626426697
train-epoch-step: 74-267 -- Loss: 0.13024404644966125
train-epoch-step: 74-268 -- Loss: 0.11167838424444199
train-epoch-step: 74-269 -- Loss: 0.1633680909872055
train-epoch-step: 74-270 -- Loss: 0.10394322872161865
train-epoch-step: 74-271 -- Loss: 0.14100153744220734
train-epoch-step: 74-272 -- Loss: 0.11204013228416443
train-epoch-step: 74-273 -- Loss: 0.12341935187578201
train-epoch-step: 74-274 -- Loss: 0.1838359832763672
train-epoch-step: 74-275 -- Loss: 0.18317250907421112
train-epoch-step: 74-276 -- Loss: 0.14901059865951538
train-epoch-step: 74-277 -- Loss: 0.14759477972984314
train-epoch-step: 74-278 -- Loss: 0.13178297877311707
train-epoch-step: 74-279 -- Loss: 0.13400214910507202
train-epoch-step: 74-280 -- Loss: 0.2059323489665985
train-epoch-step: 74-281 -- Loss: 0.168512761592865
train-epoch-step: 74-282 -- Loss: 0.13990020751953125
train-epoch-step: 74-283 -- Loss: 0.10858967900276184
train-epoch-step: 74-284 -- Loss: 0.12550123035907745
train-epoch-step: 74-285 -- Loss: 0.18433989584445953
train-epoch-step: 74-286 -- Loss: 0.14758871495723724
train-epoch-step: 74-287 -- Loss: 0.198507621884346
train-epoch-step: 74-288 -- Loss: 0.09006556868553162
train-epoch-step: 74-289 -- Loss: 0.11531498283147812
train-epoch-step: 74-290 -- Loss: 0.19368715584278107
train-epoch-step: 74-291 -- Loss: 0.11400023847818375
train-epoch-step: 74-292 -- Loss: 0.1504119634628296
train-epoch-step: 74-293 -- Loss: 0.1318734586238861
train-epoch-step: 74-294 -- Loss: 0.15188434720039368
train-epoch-step: 74-295 -- Loss: 0.25915399193763733
train-epoch-step: 74-296 -- Loss: 0.1507909744977951
train-epoch-step: 74-297 -- Loss: 0.16672611236572266
train-epoch-step: 74-298 -- Loss: 0.2226102203130722
train-epoch-step: 74-299 -- Loss: 0.13959282636642456
train-epoch-step: 74-300 -- Loss: 0.15356555581092834
train-epoch-step: 74-301 -- Loss: 0.16515876352787018
train-epoch-step: 74-302 -- Loss: 0.2120034545660019
train-epoch-step: 74-303 -- Loss: 0.19702139496803284
train-epoch-step: 74-304 -- Loss: 0.11929331719875336
train-epoch-step: 74-305 -- Loss: 0.13779424130916595
train-epoch-step: 74-306 -- Loss: 0.20092985033988953
train-epoch-step: 74-307 -- Loss: 0.1573728322982788
train-epoch-step: 74-308 -- Loss: 0.21571335196495056
train-epoch-step: 74-309 -- Loss: 0.15331695973873138
train-epoch-step: 74-310 -- Loss: 0.15581941604614258
train-epoch-step: 74-311 -- Loss: 0.15118759870529175
train-epoch-step: 74-312 -- Loss: 0.20984293520450592
train-epoch-step: 74-313 -- Loss: 0.0930962786078453
train-epoch-step: 74-314 -- Loss: 0.18399205803871155
train-epoch-step: 74-315 -- Loss: 0.16694435477256775
train-epoch-step: 74-316 -- Loss: 0.1472911387681961
train-epoch-step: 74-317 -- Loss: 0.13160811364650726
train-epoch-step: 74-318 -- Loss: 0.1496136337518692
train-epoch-step: 74-319 -- Loss: 0.15762639045715332
train-epoch-step: 74-320 -- Loss: 0.11252720654010773
train-epoch-step: 74-321 -- Loss: 0.12879791855812073
train-epoch-step: 74-322 -- Loss: 0.20621022582054138
train-epoch-step: 74-323 -- Loss: 0.1542471945285797
train-epoch-step: 74-324 -- Loss: 0.24881382286548615
train-epoch-step: 74-325 -- Loss: 0.15080539882183075
train-epoch-step: 74-326 -- Loss: 0.15932407975196838
train-epoch-step: 74-327 -- Loss: 0.19591376185417175
train-epoch-step: 74-328 -- Loss: 0.18806222081184387
train-epoch-step: 74-329 -- Loss: 0.32663071155548096
train-epoch-step: 74-330 -- Loss: 0.349822461605072
train-epoch-step: 74-331 -- Loss: 0.20493897795677185
train-epoch-step: 74-332 -- Loss: 0.09535623341798782
train-epoch-step: 74-333 -- Loss: 0.178646519780159
train-epoch-step: 74-334 -- Loss: 0.1496889442205429
train-epoch-step: 74-335 -- Loss: 0.1666693091392517
train-epoch-step: 74-336 -- Loss: 0.14089864492416382
train-epoch-step: 74-337 -- Loss: 0.1992381513118744
train-epoch-step: 74-338 -- Loss: 0.15613654255867004
train-epoch-step: 74-339 -- Loss: 0.1376436948776245
train-epoch-step: 74-340 -- Loss: 0.18807612359523773
train-epoch-step: 74-341 -- Loss: 0.13522282242774963
train-epoch-step: 74-342 -- Loss: 0.1555616706609726
train-epoch-step: 74-343 -- Loss: 0.14818669855594635
train-epoch-step: 74-344 -- Loss: 0.16119417548179626
train-epoch-step: 74-345 -- Loss: 0.12473611533641815
train-epoch-step: 74-346 -- Loss: 0.19441895186901093
train-epoch-step: 74-347 -- Loss: 0.14786869287490845
train-epoch-step: 74-348 -- Loss: 0.1933189332485199
train-epoch-step: 74-349 -- Loss: 0.19224229454994202
train-epoch-step: 74-350 -- Loss: 0.24373753368854523
train-epoch-step: 74-351 -- Loss: 0.1885150671005249
train-epoch-step: 74-352 -- Loss: 0.1159951314330101
train-epoch-step: 74-353 -- Loss: 0.19241437315940857
train-epoch-step: 74-354 -- Loss: 0.2715919017791748
train-epoch-step: 74-355 -- Loss: 0.1166931614279747
train-epoch-step: 74-356 -- Loss: 0.1128910481929779
train-epoch-step: 74-357 -- Loss: 0.181791290640831
train-epoch-step: 74-358 -- Loss: 0.1779407411813736
train-epoch-step: 74-359 -- Loss: 0.1361602544784546
train-epoch-step: 74-360 -- Loss: 0.12016656994819641
train-epoch-step: 74-361 -- Loss: 0.2242291420698166
train-epoch-step: 74-362 -- Loss: 0.16460604965686798
train-epoch-step: 74-363 -- Loss: 0.10879343748092651
train-epoch-step: 74-364 -- Loss: 0.17635668814182281
train-epoch-step: 74-365 -- Loss: 0.1625981330871582
train-epoch-step: 74-366 -- Loss: 0.19209986925125122
train-epoch-step: 74-367 -- Loss: 0.22199678421020508
train-epoch-step: 74-368 -- Loss: 0.18783067166805267
train-epoch-step: 74-369 -- Loss: 0.2656365931034088
train-epoch-step: 74-370 -- Loss: 0.11970667541027069
train-epoch-step: 74-371 -- Loss: 0.11734232306480408
train-epoch-step: 74-372 -- Loss: 0.14084239304065704
train-epoch-step: 74-373 -- Loss: 0.17749899625778198
train-epoch-step: 74-374 -- Loss: 0.14830894768238068
train-epoch-step: 74-375 -- Loss: 0.25673046708106995
train-epoch-step: 74-376 -- Loss: 0.16653016209602356
train-epoch-step: 74-377 -- Loss: 0.21917538344860077
train-epoch-step: 74-378 -- Loss: 0.1901986002922058
train-epoch-step: 74-379 -- Loss: 0.11502814292907715
train-epoch-step: 74-380 -- Loss: 0.08812549710273743
train-epoch-step: 74-381 -- Loss: 0.23133520781993866
train-epoch-step: 74-382 -- Loss: 0.22298623621463776
train-epoch-step: 74-383 -- Loss: 0.17110219597816467
train-epoch-step: 74-384 -- Loss: 0.20786578953266144
train-epoch-step: 74-385 -- Loss: 0.18132615089416504
train-epoch-step: 74-386 -- Loss: 0.17925582826137543
train-epoch-step: 74-387 -- Loss: 0.19298072159290314
train-epoch-step: 74-388 -- Loss: 0.1696811020374298
train-epoch-step: 74-389 -- Loss: 0.16305412352085114
train-epoch-step: 74-390 -- Loss: 0.14165130257606506
train-epoch-step: 74-391 -- Loss: 0.1412392556667328
train-epoch-step: 74-392 -- Loss: 0.17753474414348602
train-epoch-step: 74-393 -- Loss: 0.15018980205059052
train-epoch-step: 74-394 -- Loss: 0.18983913958072662
train-epoch-step: 74-395 -- Loss: 0.15023407340049744
train-epoch-step: 74-396 -- Loss: 0.12296994030475616
train-epoch-step: 74-397 -- Loss: 0.12079213559627533
train-epoch-step: 74-398 -- Loss: 0.1930936872959137
train-epoch-step: 74-399 -- Loss: 0.17072580754756927
train-epoch-step: 74-400 -- Loss: 0.2666173577308655
train-epoch-step: 74-401 -- Loss: 0.11402106285095215
train-epoch-step: 74-402 -- Loss: 0.24844913184642792
train-epoch-step: 74-403 -- Loss: 0.1483953893184662
train-epoch-step: 74-404 -- Loss: 0.13148564100265503
train-epoch-step: 74-405 -- Loss: 0.14188767969608307
train-epoch-step: 74-406 -- Loss: 0.15850524604320526
train-epoch-step: 74-407 -- Loss: 0.10982000082731247
train-epoch-step: 74-408 -- Loss: 0.15643508732318878
train-epoch-step: 74-409 -- Loss: 0.16328948736190796
train-epoch-step: 74-410 -- Loss: 0.1685570776462555
train-epoch-step: 74-411 -- Loss: 0.18599659204483032
train-epoch-step: 74-412 -- Loss: 0.12400959432125092
train-epoch-step: 74-413 -- Loss: 0.14030790328979492
train-epoch-step: 74-414 -- Loss: 0.12736384570598602
train-epoch-step: 74-415 -- Loss: 0.12983383238315582
train-epoch-step: 74-416 -- Loss: 0.2526347041130066
train-epoch-step: 74-417 -- Loss: 0.18453693389892578
train-epoch-step: 74-418 -- Loss: 0.2182719111442566
train-epoch-step: 74-419 -- Loss: 0.15968184173107147
train-epoch-step: 74-420 -- Loss: 0.14633142948150635
train-epoch-step: 74-421 -- Loss: 0.1728268712759018
train-epoch-step: 74-422 -- Loss: 0.1417543590068817
train-epoch-step: 74-423 -- Loss: 0.16403760015964508
train-epoch-step: 74-424 -- Loss: 0.14146004617214203
train-epoch-step: 74-425 -- Loss: 0.17705115675926208
train-epoch-step: 74-426 -- Loss: 0.1580529808998108
train-epoch-step: 74-427 -- Loss: 0.11726579070091248
train-epoch-step: 74-428 -- Loss: 0.1847352385520935
train-epoch-step: 74-429 -- Loss: 0.1685216724872589
train-epoch-step: 74-430 -- Loss: 0.1336188018321991
train-epoch-step: 74-431 -- Loss: 0.15624335408210754
train-epoch-step: 74-432 -- Loss: 0.2324923425912857
train-epoch-step: 74-433 -- Loss: 0.132130429148674
train-epoch-step: 74-434 -- Loss: 0.12341704964637756
train-epoch-step: 74-435 -- Loss: 0.1499527394771576
train-epoch-step: 74-436 -- Loss: 0.14995047450065613
train-epoch-step: 74-437 -- Loss: 0.12761060893535614
train-epoch-step: 74-438 -- Loss: 0.16078592836856842
train-epoch-step: 74-439 -- Loss: 0.25422054529190063
train-epoch-step: 74-440 -- Loss: 0.12508130073547363
train-epoch-step: 74-441 -- Loss: 0.19008679687976837
train-epoch-step: 74-442 -- Loss: 0.17092463374137878
train-epoch-step: 74-443 -- Loss: 0.14982929825782776
train-epoch-step: 74-444 -- Loss: 0.16803240776062012
train-epoch-step: 74-445 -- Loss: 0.1711876094341278
train-epoch-step: 74-446 -- Loss: 0.14734938740730286
train-epoch-step: 74-447 -- Loss: 0.18525582551956177
train-epoch-step: 74-448 -- Loss: 0.2190084159374237
train-epoch-step: 74-449 -- Loss: 0.18532784283161163
train-epoch-step: 74-450 -- Loss: 0.1732875555753708
train-epoch-step: 74-451 -- Loss: 0.13609150052070618
train-epoch-step: 74-452 -- Loss: 0.12257464230060577
train-epoch-step: 74-453 -- Loss: 0.08832095563411713
train-epoch-step: 74-454 -- Loss: 0.21940144896507263
train-epoch-step: 74-455 -- Loss: 0.11808497458696365
train-epoch-step: 74-456 -- Loss: 0.11368419229984283
train-epoch-step: 74-457 -- Loss: 0.24637244641780853
train-epoch-step: 74-458 -- Loss: 0.153218075633049
train-epoch-step: 74-459 -- Loss: 0.21848784387111664
train-epoch-step: 74-460 -- Loss: 0.1218770295381546
train-epoch-step: 74-461 -- Loss: 0.13236764073371887
train-epoch-step: 74-462 -- Loss: 0.15657123923301697
train-epoch-step: 74-463 -- Loss: 0.13212734460830688
train-epoch-step: 74-464 -- Loss: 0.15442399680614471
train-epoch-step: 74-465 -- Loss: 0.22801876068115234
train-epoch-step: 74-466 -- Loss: 0.1934039443731308
train-epoch-step: 74-467 -- Loss: 0.11490147560834885
train-epoch-step: 74-468 -- Loss: 0.1713777631521225
train-epoch-step: 74-469 -- Loss: 0.2013629972934723
train-epoch-step: 74-470 -- Loss: 0.1685996800661087
train-epoch-step: 74-471 -- Loss: 0.16790810227394104
train-epoch-step: 74-472 -- Loss: 0.16066034138202667
train-epoch-step: 74-473 -- Loss: 0.14835728704929352
train-epoch-step: 74-474 -- Loss: 0.11738582700490952
train-epoch-step: 74-475 -- Loss: 0.11571311205625534
train-epoch-step: 74-476 -- Loss: 0.1948552131652832
train-epoch-step: 74-477 -- Loss: 0.19836893677711487
train-epoch-step: 74-478 -- Loss: 0.1786239743232727
train-epoch-step: 74-479 -- Loss: 0.13733266294002533
train-epoch-step: 74-480 -- Loss: 0.17880335450172424
train-epoch-step: 74-481 -- Loss: 0.2680198550224304
train-epoch-step: 74-482 -- Loss: 0.24718478322029114
train-epoch-step: 74-483 -- Loss: 0.1737275868654251
train-epoch-step: 74-484 -- Loss: 0.20087413489818573
train-epoch-step: 74-485 -- Loss: 0.13164670765399933
train-epoch-step: 74-486 -- Loss: 0.2244752049446106
train-epoch-step: 74-487 -- Loss: 0.22344812750816345
train-epoch-step: 74-488 -- Loss: 0.1734623908996582
train-epoch-step: 74-489 -- Loss: 0.21600669622421265
train-epoch-step: 74-490 -- Loss: 0.13917283713817596
train-epoch-step: 74-491 -- Loss: 0.13445261120796204
train-epoch-step: 74-492 -- Loss: 0.12210896611213684
train-epoch-step: 74-493 -- Loss: 0.18577782809734344
train-epoch-step: 74-494 -- Loss: 0.19463735818862915
train-epoch-step: 74-495 -- Loss: 0.19576743245124817
train-epoch-step: 74-496 -- Loss: 0.1347496509552002
train-epoch-step: 74-497 -- Loss: 0.17977625131607056
train-epoch-step: 74-498 -- Loss: 0.14149221777915955
train-epoch-step: 74-499 -- Loss: 0.16272543370723724
train-epoch-step: 74-500 -- Loss: 0.1503043919801712
train-epoch-step: 74-501 -- Loss: 0.20829221606254578
train-epoch-step: 74-502 -- Loss: 0.15333294868469238
train-epoch-step: 74-503 -- Loss: 0.20791217684745789
train-epoch-step: 74-504 -- Loss: 0.11752864718437195
train-epoch-step: 74-505 -- Loss: 0.16368305683135986
train-epoch-step: 74-506 -- Loss: 0.11077400296926498
train-epoch-step: 74-507 -- Loss: 0.16786715388298035
train-epoch-step: 74-508 -- Loss: 0.1677316576242447
train-epoch-step: 74-509 -- Loss: 0.16059622168540955
train-epoch-step: 74-510 -- Loss: 0.12394773960113525
train-epoch-step: 74-511 -- Loss: 0.21015603840351105
train-epoch-step: 74-512 -- Loss: 0.17397814989089966
train-epoch-step: 74-513 -- Loss: 0.17660869657993317
train-epoch-step: 74-514 -- Loss: 0.13979245722293854
train-epoch-step: 74-515 -- Loss: 0.14960522949695587
train-epoch-step: 74-516 -- Loss: 0.1622450053691864
train-epoch-step: 74-517 -- Loss: 0.16937139630317688
train-epoch-step: 74-518 -- Loss: 0.13176549971103668
train-epoch-step: 74-519 -- Loss: 0.13095557689666748
train-epoch-step: 74-520 -- Loss: 0.17783409357070923
train-epoch-step: 74-521 -- Loss: 0.21789848804473877
train-epoch-step: 74-522 -- Loss: 0.1602945327758789
train-epoch-step: 74-523 -- Loss: 0.15794891119003296
train-epoch-step: 74-524 -- Loss: 0.16601958870887756
train-epoch-step: 74-525 -- Loss: 0.18256357312202454
train-epoch-step: 74-526 -- Loss: 0.13368767499923706
train-epoch-step: 74-527 -- Loss: 0.14316540956497192
train-epoch-step: 74-528 -- Loss: 0.14961527287960052
train-epoch-step: 74-529 -- Loss: 0.15746110677719116
train-epoch-step: 74-530 -- Loss: 0.16695475578308105
train-epoch-step: 74-531 -- Loss: 0.19677379727363586
train-epoch-step: 74-532 -- Loss: 0.16112567484378815
train-epoch-step: 74-533 -- Loss: 0.17008830606937408
train-epoch-step: 74-534 -- Loss: 0.12390147149562836
train-epoch-step: 74-535 -- Loss: 0.2456238567829132
train-epoch-step: 74-536 -- Loss: 0.1504223346710205
train-epoch-step: 74-537 -- Loss: 0.1425611525774002
train-epoch-step: 74-538 -- Loss: 0.09878301620483398
train-epoch-step: 74-539 -- Loss: 0.17866909503936768
train-epoch-step: 74-540 -- Loss: 0.1304710954427719
train-epoch-step: 74-541 -- Loss: 0.19882707297801971
train-epoch-step: 74-542 -- Loss: 0.22131362557411194
train-epoch-step: 74-543 -- Loss: 0.16655008494853973
train-epoch-step: 74-544 -- Loss: 0.215409055352211
train-epoch-step: 74-545 -- Loss: 0.18802765011787415
train-epoch-step: 74-546 -- Loss: 0.20883388817310333
train-epoch-step: 74-547 -- Loss: 0.17364339530467987
train-epoch-step: 74-548 -- Loss: 0.08819100260734558
train-epoch-step: 74-549 -- Loss: 0.14596687257289886
train-epoch-step: 74-550 -- Loss: 0.1911989152431488
train-epoch-step: 74-551 -- Loss: 0.14596781134605408
train-epoch-step: 74-552 -- Loss: 0.12001605331897736
train-epoch-step: 74-553 -- Loss: 0.18126271665096283
train-epoch-step: 74-554 -- Loss: 0.1814700812101364
train-epoch-step: 74-555 -- Loss: 0.2066897600889206
train-epoch-step: 74-556 -- Loss: 0.13847708702087402
train-epoch-step: 74-557 -- Loss: 0.22500628232955933
train-epoch-step: 74-558 -- Loss: 0.21610474586486816
train-epoch-step: 74-559 -- Loss: 0.13296368718147278
train-epoch-step: 74-560 -- Loss: 0.20173993706703186
train-epoch-step: 74-561 -- Loss: 0.17575466632843018
train-epoch-step: 74-562 -- Loss: 0.1596004068851471
train-epoch-step: 74-563 -- Loss: 0.17883005738258362
train-epoch-step: 74-564 -- Loss: 0.09912031888961792
train-epoch-step: 74-565 -- Loss: 0.17631173133850098
train-epoch-step: 74-566 -- Loss: 0.14252041280269623
train-epoch-step: 74-567 -- Loss: 0.20317292213439941
train-epoch-step: 74-568 -- Loss: 0.15647396445274353
train-epoch-step: 74-569 -- Loss: 0.2315972000360489
train-epoch-step: 74-570 -- Loss: 0.16117984056472778
train-epoch-step: 74-571 -- Loss: 0.20509225130081177
train-epoch-step: 74-572 -- Loss: 0.22788764536380768
train-epoch-step: 74-573 -- Loss: 0.1947263479232788
train-epoch-step: 74-574 -- Loss: 0.23119398951530457
train-epoch-step: 74-575 -- Loss: 0.29340308904647827
train-epoch-step: 74-576 -- Loss: 0.1135457381606102
train-epoch-step: 74-577 -- Loss: 0.15824362635612488
train-epoch-step: 74-578 -- Loss: 0.20966917276382446
train-epoch-step: 74-579 -- Loss: 0.15607847273349762
train-epoch-step: 74-580 -- Loss: 0.1700390726327896
train-epoch-step: 74-581 -- Loss: 0.13167330622673035
train-epoch-step: 74-582 -- Loss: 0.1940411925315857
train-epoch-step: 74-583 -- Loss: 0.19873088598251343
train-epoch-step: 74-584 -- Loss: 0.15483950078487396
train-epoch-step: 74-585 -- Loss: 0.1864391565322876
train-epoch-step: 74-586 -- Loss: 0.24640628695487976
train-epoch-step: 74-587 -- Loss: 0.15437641739845276
train-epoch-step: 74-588 -- Loss: 0.12114877253770828
val-epoch-step: 74-589 -- Loss: 0.1980341374874115
val-epoch-step: 74-590 -- Loss: 0.15547555685043335
val-epoch-step: 74-591 -- Loss: 0.22756029665470123
val-epoch-step: 74-592 -- Loss: 0.17495059967041016
val-epoch-step: 74-593 -- Loss: 0.19193406403064728
val-epoch-step: 74-594 -- Loss: 0.3575443923473358
val-epoch-step: 74-595 -- Loss: 0.16264669597148895
val-epoch-step: 74-596 -- Loss: 0.19079849123954773
val-epoch-step: 74-597 -- Loss: 0.17032156884670258
val-epoch-step: 74-598 -- Loss: 0.14224323630332947
val-epoch-step: 74-599 -- Loss: 0.17856407165527344
val-epoch-step: 74-600 -- Loss: 0.16161489486694336
val-epoch-step: 74-601 -- Loss: 0.16096538305282593
val-epoch-step: 74-602 -- Loss: 0.13380764424800873
val-epoch-step: 74-603 -- Loss: 0.20802411437034607
val-epoch-step: 74-604 -- Loss: 0.1465594619512558
val-epoch-step: 74-605 -- Loss: 0.14213864505290985
val-epoch-step: 74-606 -- Loss: 0.25149285793304443
val-epoch-step: 74-607 -- Loss: 0.1230798065662384
val-epoch-step: 74-608 -- Loss: 0.24539673328399658
val-epoch-step: 74-609 -- Loss: 0.16452835500240326
val-epoch-step: 74-610 -- Loss: 0.17175590991973877
val-epoch-step: 74-611 -- Loss: 0.1537718027830124
val-epoch-step: 74-612 -- Loss: 0.35793083906173706
val-epoch-step: 74-613 -- Loss: 0.16701310873031616
val-epoch-step: 74-614 -- Loss: 0.16017967462539673
val-epoch-step: 74-615 -- Loss: 0.17272037267684937
val-epoch-step: 74-616 -- Loss: 0.15582044422626495
val-epoch-step: 74-617 -- Loss: 0.18822461366653442
val-epoch-step: 74-618 -- Loss: 0.1796947419643402
val-epoch-step: 74-619 -- Loss: 0.2061455398797989
val-epoch-step: 74-620 -- Loss: 0.1364426165819168
val-epoch-step: 74-621 -- Loss: 0.1226382702589035
val-epoch-step: 74-622 -- Loss: 0.13999265432357788
val-epoch-step: 74-623 -- Loss: 0.15000925958156586
val-epoch-step: 74-624 -- Loss: 0.1397658884525299
val-epoch-step: 74-625 -- Loss: 0.15422095358371735
val-epoch-step: 74-626 -- Loss: 0.1441638022661209
val-epoch-step: 74-627 -- Loss: 0.18987783789634705
val-epoch-step: 74-628 -- Loss: 0.6259485483169556
val-epoch-step: 74-629 -- Loss: 0.20597758889198303
val-epoch-step: 74-630 -- Loss: 0.3387235105037689
val-epoch-step: 74-631 -- Loss: 0.14086748659610748
val-epoch-step: 74-632 -- Loss: 0.18875697255134583
val-epoch-step: 74-633 -- Loss: 0.14797303080558777
val-epoch-step: 74-634 -- Loss: 0.14392715692520142
val-epoch-step: 74-635 -- Loss: 0.11567220091819763
val-epoch-step: 74-636 -- Loss: 0.1620752364397049
val-epoch-step: 74-637 -- Loss: 0.17365017533302307
val-epoch-step: 74-638 -- Loss: 0.14244455099105835
val-epoch-step: 74-639 -- Loss: 0.2540239691734314
val-epoch-step: 74-640 -- Loss: 0.24831578135490417
val-epoch-step: 74-641 -- Loss: 0.12845264375209808
val-epoch-step: 74-642 -- Loss: 0.17471539974212646
val-epoch-step: 74-643 -- Loss: 0.2052868902683258
val-epoch-step: 74-644 -- Loss: 0.16410154104232788
val-epoch-step: 74-645 -- Loss: 0.21978306770324707
val-epoch-step: 74-646 -- Loss: 0.13185778260231018
val-epoch-step: 74-647 -- Loss: 0.12431249022483826
val-epoch-step: 74-648 -- Loss: 0.15173467993736267
val-epoch-step: 74-649 -- Loss: 0.19970034062862396
val-epoch-step: 74-650 -- Loss: 0.24914216995239258
val-epoch-step: 74-651 -- Loss: 0.15931348502635956
val-epoch-step: 74-652 -- Loss: 0.1512404978275299
val-epoch-step: 74-653 -- Loss: 0.19728988409042358
val-epoch-step: 74-654 -- Loss: 0.10601846873760223
Epoch: 74 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 75-0 -- Loss: 0.21088773012161255
train-epoch-step: 75-1 -- Loss: 0.7989187240600586
train-epoch-step: 75-2 -- Loss: 0.3706817328929901
train-epoch-step: 75-3 -- Loss: 0.34239813685417175
train-epoch-step: 75-4 -- Loss: 0.5286926031112671
train-epoch-step: 75-5 -- Loss: 0.45365920662879944
train-epoch-step: 75-6 -- Loss: 0.6602400541305542
train-epoch-step: 75-7 -- Loss: 0.4235665202140808
train-epoch-step: 75-8 -- Loss: 0.4439350366592407
train-epoch-step: 75-9 -- Loss: 0.497402161359787
train-epoch-step: 75-10 -- Loss: 0.4542538523674011
train-epoch-step: 75-11 -- Loss: 0.38437801599502563
train-epoch-step: 75-12 -- Loss: 0.36474019289016724
train-epoch-step: 75-13 -- Loss: 0.3873708248138428
train-epoch-step: 75-14 -- Loss: 0.30878809094429016
train-epoch-step: 75-15 -- Loss: 0.2897999882698059
train-epoch-step: 75-16 -- Loss: 0.3039587140083313
train-epoch-step: 75-17 -- Loss: 0.3825472593307495
train-epoch-step: 75-18 -- Loss: 0.2858370244503021
train-epoch-step: 75-19 -- Loss: 0.25444796681404114
train-epoch-step: 75-20 -- Loss: 0.3333515226840973
train-epoch-step: 75-21 -- Loss: 0.3978569805622101
train-epoch-step: 75-22 -- Loss: 0.19592832028865814
train-epoch-step: 75-23 -- Loss: 0.20628182590007782
train-epoch-step: 75-24 -- Loss: 0.18741565942764282
train-epoch-step: 75-25 -- Loss: 0.2959454357624054
train-epoch-step: 75-26 -- Loss: 0.2856571078300476
train-epoch-step: 75-27 -- Loss: 0.5474942922592163
train-epoch-step: 75-28 -- Loss: 0.17029210925102234
train-epoch-step: 75-29 -- Loss: 0.30565327405929565
train-epoch-step: 75-30 -- Loss: 0.14228247106075287
train-epoch-step: 75-31 -- Loss: 0.1909782886505127
train-epoch-step: 75-32 -- Loss: 0.24924448132514954
train-epoch-step: 75-33 -- Loss: 0.4330378472805023
train-epoch-step: 75-34 -- Loss: 0.25218793749809265
train-epoch-step: 75-35 -- Loss: 0.3766658902168274
train-epoch-step: 75-36 -- Loss: 0.19440975785255432
train-epoch-step: 75-37 -- Loss: 0.17734883725643158
train-epoch-step: 75-38 -- Loss: 0.2580966353416443
train-epoch-step: 75-39 -- Loss: 0.3529086709022522
train-epoch-step: 75-40 -- Loss: 0.248374342918396
train-epoch-step: 75-41 -- Loss: 0.27101096510887146
train-epoch-step: 75-42 -- Loss: 0.2170940339565277
train-epoch-step: 75-43 -- Loss: 0.42774754762649536
train-epoch-step: 75-44 -- Loss: 0.2020699679851532
train-epoch-step: 75-45 -- Loss: 0.2063208669424057
train-epoch-step: 75-46 -- Loss: 0.2190552055835724
train-epoch-step: 75-47 -- Loss: 0.24818594753742218
train-epoch-step: 75-48 -- Loss: 0.20582017302513123
train-epoch-step: 75-49 -- Loss: 0.27997642755508423
train-epoch-step: 75-50 -- Loss: 0.14739184081554413
train-epoch-step: 75-51 -- Loss: 0.2573668956756592
train-epoch-step: 75-52 -- Loss: 0.2091394066810608
train-epoch-step: 75-53 -- Loss: 0.3327197730541229
train-epoch-step: 75-54 -- Loss: 0.3684142827987671
train-epoch-step: 75-55 -- Loss: 0.2425483763217926
train-epoch-step: 75-56 -- Loss: 0.2590852379798889
train-epoch-step: 75-57 -- Loss: 0.2982451617717743
train-epoch-step: 75-58 -- Loss: 0.3188398778438568
train-epoch-step: 75-59 -- Loss: 0.2977893352508545
train-epoch-step: 75-60 -- Loss: 0.16937807202339172
train-epoch-step: 75-61 -- Loss: 0.28501981496810913
train-epoch-step: 75-62 -- Loss: 0.22939959168434143
train-epoch-step: 75-63 -- Loss: 0.15892542898654938
train-epoch-step: 75-64 -- Loss: 0.17464250326156616
train-epoch-step: 75-65 -- Loss: 0.2273314893245697
train-epoch-step: 75-66 -- Loss: 0.13057060539722443
train-epoch-step: 75-67 -- Loss: 0.16226346790790558
train-epoch-step: 75-68 -- Loss: 0.25299662351608276
train-epoch-step: 75-69 -- Loss: 0.1453569531440735
train-epoch-step: 75-70 -- Loss: 0.29889509081840515
train-epoch-step: 75-71 -- Loss: 0.3140435814857483
train-epoch-step: 75-72 -- Loss: 0.2083437293767929
train-epoch-step: 75-73 -- Loss: 0.24113517999649048
train-epoch-step: 75-74 -- Loss: 0.11747771501541138
train-epoch-step: 75-75 -- Loss: 0.1448972225189209
train-epoch-step: 75-76 -- Loss: 0.17491236329078674
train-epoch-step: 75-77 -- Loss: 0.24292808771133423
train-epoch-step: 75-78 -- Loss: 0.3704444169998169
train-epoch-step: 75-79 -- Loss: 0.22294560074806213
train-epoch-step: 75-80 -- Loss: 0.3094896078109741
train-epoch-step: 75-81 -- Loss: 0.15606321394443512
train-epoch-step: 75-82 -- Loss: 0.30872416496276855
train-epoch-step: 75-83 -- Loss: 0.21745726466178894
train-epoch-step: 75-84 -- Loss: 0.22503027319908142
train-epoch-step: 75-85 -- Loss: 0.1945590078830719
train-epoch-step: 75-86 -- Loss: 0.13636870682239532
train-epoch-step: 75-87 -- Loss: 0.2577134370803833
train-epoch-step: 75-88 -- Loss: 0.1653563678264618
train-epoch-step: 75-89 -- Loss: 0.2257547229528427
train-epoch-step: 75-90 -- Loss: 0.21288654208183289
train-epoch-step: 75-91 -- Loss: 0.2702590823173523
train-epoch-step: 75-92 -- Loss: 0.1783277690410614
train-epoch-step: 75-93 -- Loss: 0.21398627758026123
train-epoch-step: 75-94 -- Loss: 0.26465368270874023
train-epoch-step: 75-95 -- Loss: 0.20658764243125916
train-epoch-step: 75-96 -- Loss: 0.2305067926645279
train-epoch-step: 75-97 -- Loss: 0.20922324061393738
train-epoch-step: 75-98 -- Loss: 0.22476160526275635
train-epoch-step: 75-99 -- Loss: 0.21379390358924866
train-epoch-step: 75-100 -- Loss: 0.2010745257139206
train-epoch-step: 75-101 -- Loss: 0.3210752606391907
train-epoch-step: 75-102 -- Loss: 0.2994250953197479
train-epoch-step: 75-103 -- Loss: 0.20539307594299316
train-epoch-step: 75-104 -- Loss: 0.17177748680114746
train-epoch-step: 75-105 -- Loss: 0.30525100231170654
train-epoch-step: 75-106 -- Loss: 0.18546921014785767
train-epoch-step: 75-107 -- Loss: 0.20862439274787903
train-epoch-step: 75-108 -- Loss: 0.20336756110191345
train-epoch-step: 75-109 -- Loss: 0.16057032346725464
train-epoch-step: 75-110 -- Loss: 0.21856732666492462
train-epoch-step: 75-111 -- Loss: 0.1914060115814209
train-epoch-step: 75-112 -- Loss: 0.207321435213089
train-epoch-step: 75-113 -- Loss: 0.19342687726020813
train-epoch-step: 75-114 -- Loss: 0.2188602089881897
train-epoch-step: 75-115 -- Loss: 0.19166883826255798
train-epoch-step: 75-116 -- Loss: 0.16046704351902008
train-epoch-step: 75-117 -- Loss: 0.14307382702827454
train-epoch-step: 75-118 -- Loss: 0.22868528962135315
train-epoch-step: 75-119 -- Loss: 0.1684342473745346
train-epoch-step: 75-120 -- Loss: 0.2580017149448395
train-epoch-step: 75-121 -- Loss: 0.26924824714660645
train-epoch-step: 75-122 -- Loss: 0.23265193402767181
train-epoch-step: 75-123 -- Loss: 0.21958833932876587
train-epoch-step: 75-124 -- Loss: 0.13638707995414734
train-epoch-step: 75-125 -- Loss: 0.16204360127449036
train-epoch-step: 75-126 -- Loss: 0.26739197969436646
train-epoch-step: 75-127 -- Loss: 0.19980621337890625
train-epoch-step: 75-128 -- Loss: 0.19468723237514496
train-epoch-step: 75-129 -- Loss: 0.16278916597366333
train-epoch-step: 75-130 -- Loss: 0.2159729301929474
train-epoch-step: 75-131 -- Loss: 0.14531955122947693
train-epoch-step: 75-132 -- Loss: 0.20485800504684448
train-epoch-step: 75-133 -- Loss: 0.1324911266565323
train-epoch-step: 75-134 -- Loss: 0.22249826788902283
train-epoch-step: 75-135 -- Loss: 0.1462567299604416
train-epoch-step: 75-136 -- Loss: 0.13567472994327545
train-epoch-step: 75-137 -- Loss: 0.2747119963169098
train-epoch-step: 75-138 -- Loss: 0.2788195013999939
train-epoch-step: 75-139 -- Loss: 0.14268550276756287
train-epoch-step: 75-140 -- Loss: 0.22863617539405823
train-epoch-step: 75-141 -- Loss: 0.2455417364835739
train-epoch-step: 75-142 -- Loss: 0.21551652252674103
train-epoch-step: 75-143 -- Loss: 0.20028644800186157
train-epoch-step: 75-144 -- Loss: 0.2329758107662201
train-epoch-step: 75-145 -- Loss: 0.16922470927238464
train-epoch-step: 75-146 -- Loss: 0.2094646394252777
train-epoch-step: 75-147 -- Loss: 0.19062890112400055
train-epoch-step: 75-148 -- Loss: 0.19092786312103271
train-epoch-step: 75-149 -- Loss: 0.13137446343898773
train-epoch-step: 75-150 -- Loss: 0.1952953040599823
train-epoch-step: 75-151 -- Loss: 0.19580017030239105
train-epoch-step: 75-152 -- Loss: 0.2111361026763916
train-epoch-step: 75-153 -- Loss: 0.27526354789733887
train-epoch-step: 75-154 -- Loss: 0.14778220653533936
train-epoch-step: 75-155 -- Loss: 0.17674614489078522
train-epoch-step: 75-156 -- Loss: 0.13558286428451538
train-epoch-step: 75-157 -- Loss: 0.18072883784770966
train-epoch-step: 75-158 -- Loss: 0.19711729884147644
train-epoch-step: 75-159 -- Loss: 0.18889090418815613
train-epoch-step: 75-160 -- Loss: 0.26167142391204834
train-epoch-step: 75-161 -- Loss: 0.23264338076114655
train-epoch-step: 75-162 -- Loss: 0.2338038980960846
train-epoch-step: 75-163 -- Loss: 0.20113693177700043
train-epoch-step: 75-164 -- Loss: 0.20131205022335052
train-epoch-step: 75-165 -- Loss: 0.183308407664299
train-epoch-step: 75-166 -- Loss: 0.12399855256080627
train-epoch-step: 75-167 -- Loss: 0.130891352891922
train-epoch-step: 75-168 -- Loss: 0.21019013226032257
train-epoch-step: 75-169 -- Loss: 0.155764639377594
train-epoch-step: 75-170 -- Loss: 0.2140311598777771
train-epoch-step: 75-171 -- Loss: 0.1535266935825348
train-epoch-step: 75-172 -- Loss: 0.268248051404953
train-epoch-step: 75-173 -- Loss: 0.14277681708335876
train-epoch-step: 75-174 -- Loss: 0.2580556273460388
train-epoch-step: 75-175 -- Loss: 0.19449785351753235
train-epoch-step: 75-176 -- Loss: 0.13908492028713226
train-epoch-step: 75-177 -- Loss: 0.18691208958625793
train-epoch-step: 75-178 -- Loss: 0.19940991699695587
train-epoch-step: 75-179 -- Loss: 0.16101674735546112
train-epoch-step: 75-180 -- Loss: 0.16263799369335175
train-epoch-step: 75-181 -- Loss: 0.1840503215789795
train-epoch-step: 75-182 -- Loss: 0.20154744386672974
train-epoch-step: 75-183 -- Loss: 0.30271661281585693
train-epoch-step: 75-184 -- Loss: 0.1514969766139984
train-epoch-step: 75-185 -- Loss: 0.1482987105846405
train-epoch-step: 75-186 -- Loss: 0.207461416721344
train-epoch-step: 75-187 -- Loss: 0.23119936883449554
train-epoch-step: 75-188 -- Loss: 0.18611380457878113
train-epoch-step: 75-189 -- Loss: 0.11336737871170044
train-epoch-step: 75-190 -- Loss: 0.19213315844535828
train-epoch-step: 75-191 -- Loss: 0.1692880243062973
train-epoch-step: 75-192 -- Loss: 0.23689037561416626
train-epoch-step: 75-193 -- Loss: 0.2348996102809906
train-epoch-step: 75-194 -- Loss: 0.19091102480888367
train-epoch-step: 75-195 -- Loss: 0.18008103966712952
train-epoch-step: 75-196 -- Loss: 0.1841019093990326
train-epoch-step: 75-197 -- Loss: 0.13826210796833038
train-epoch-step: 75-198 -- Loss: 0.13951916992664337
train-epoch-step: 75-199 -- Loss: 0.1622105985879898
train-epoch-step: 75-200 -- Loss: 0.12877632677555084
train-epoch-step: 75-201 -- Loss: 0.2020619809627533
train-epoch-step: 75-202 -- Loss: 0.13735373318195343
train-epoch-step: 75-203 -- Loss: 0.20197153091430664
train-epoch-step: 75-204 -- Loss: 0.147392138838768
train-epoch-step: 75-205 -- Loss: 0.18691690266132355
train-epoch-step: 75-206 -- Loss: 0.23526911437511444
train-epoch-step: 75-207 -- Loss: 0.1459469348192215
train-epoch-step: 75-208 -- Loss: 0.1820010244846344
train-epoch-step: 75-209 -- Loss: 0.14914101362228394
train-epoch-step: 75-210 -- Loss: 0.14478516578674316
train-epoch-step: 75-211 -- Loss: 0.22416642308235168
train-epoch-step: 75-212 -- Loss: 0.20847569406032562
train-epoch-step: 75-213 -- Loss: 0.13279017806053162
train-epoch-step: 75-214 -- Loss: 0.15198227763175964
train-epoch-step: 75-215 -- Loss: 0.13108842074871063
train-epoch-step: 75-216 -- Loss: 0.20886899530887604
train-epoch-step: 75-217 -- Loss: 0.22705604135990143
train-epoch-step: 75-218 -- Loss: 0.15605036914348602
train-epoch-step: 75-219 -- Loss: 0.1812288463115692
train-epoch-step: 75-220 -- Loss: 0.1428026705980301
train-epoch-step: 75-221 -- Loss: 0.2077443152666092
train-epoch-step: 75-222 -- Loss: 0.12605075538158417
train-epoch-step: 75-223 -- Loss: 0.17632728815078735
train-epoch-step: 75-224 -- Loss: 0.20876561105251312
train-epoch-step: 75-225 -- Loss: 0.28289228677749634
train-epoch-step: 75-226 -- Loss: 0.21276123821735382
train-epoch-step: 75-227 -- Loss: 0.22882452607154846
train-epoch-step: 75-228 -- Loss: 0.18462973833084106
train-epoch-step: 75-229 -- Loss: 0.1811351776123047
train-epoch-step: 75-230 -- Loss: 0.16400904953479767
train-epoch-step: 75-231 -- Loss: 0.1611688882112503
train-epoch-step: 75-232 -- Loss: 0.20062938332557678
train-epoch-step: 75-233 -- Loss: 0.09046711027622223
train-epoch-step: 75-234 -- Loss: 0.18587210774421692
train-epoch-step: 75-235 -- Loss: 0.14820906519889832
train-epoch-step: 75-236 -- Loss: 0.23098024725914001
train-epoch-step: 75-237 -- Loss: 0.24300992488861084
train-epoch-step: 75-238 -- Loss: 0.15944507718086243
train-epoch-step: 75-239 -- Loss: 0.12973587214946747
train-epoch-step: 75-240 -- Loss: 0.2351023405790329
train-epoch-step: 75-241 -- Loss: 0.1637660562992096
train-epoch-step: 75-242 -- Loss: 0.22894328832626343
train-epoch-step: 75-243 -- Loss: 0.24143461883068085
train-epoch-step: 75-244 -- Loss: 0.2240389883518219
train-epoch-step: 75-245 -- Loss: 0.21868598461151123
train-epoch-step: 75-246 -- Loss: 0.23125329613685608
train-epoch-step: 75-247 -- Loss: 0.22505129873752594
train-epoch-step: 75-248 -- Loss: 0.1846424639225006
train-epoch-step: 75-249 -- Loss: 0.1441618949174881
train-epoch-step: 75-250 -- Loss: 0.20858873426914215
train-epoch-step: 75-251 -- Loss: 0.11170113831758499
train-epoch-step: 75-252 -- Loss: 0.21565720438957214
train-epoch-step: 75-253 -- Loss: 0.16195335984230042
train-epoch-step: 75-254 -- Loss: 0.22018727660179138
train-epoch-step: 75-255 -- Loss: 0.14676092565059662
train-epoch-step: 75-256 -- Loss: 0.164461150765419
train-epoch-step: 75-257 -- Loss: 0.2106805145740509
train-epoch-step: 75-258 -- Loss: 0.1435207724571228
train-epoch-step: 75-259 -- Loss: 0.11741648614406586
train-epoch-step: 75-260 -- Loss: 0.20774801075458527
train-epoch-step: 75-261 -- Loss: 0.18208186328411102
train-epoch-step: 75-262 -- Loss: 0.29981088638305664
train-epoch-step: 75-263 -- Loss: 0.24819697439670563
train-epoch-step: 75-264 -- Loss: 0.29826611280441284
train-epoch-step: 75-265 -- Loss: 0.13606858253479004
train-epoch-step: 75-266 -- Loss: 0.1701069474220276
train-epoch-step: 75-267 -- Loss: 0.18426531553268433
train-epoch-step: 75-268 -- Loss: 0.1617392897605896
train-epoch-step: 75-269 -- Loss: 0.20486262440681458
train-epoch-step: 75-270 -- Loss: 0.14742931723594666
train-epoch-step: 75-271 -- Loss: 0.23989823460578918
train-epoch-step: 75-272 -- Loss: 0.1404268741607666
train-epoch-step: 75-273 -- Loss: 0.1741805523633957
train-epoch-step: 75-274 -- Loss: 0.32206058502197266
train-epoch-step: 75-275 -- Loss: 0.2885614037513733
train-epoch-step: 75-276 -- Loss: 0.16880208253860474
train-epoch-step: 75-277 -- Loss: 0.18982861936092377
train-epoch-step: 75-278 -- Loss: 0.19980458915233612
train-epoch-step: 75-279 -- Loss: 0.1727420538663864
train-epoch-step: 75-280 -- Loss: 0.26857060194015503
train-epoch-step: 75-281 -- Loss: 0.20875702798366547
train-epoch-step: 75-282 -- Loss: 0.1732388138771057
train-epoch-step: 75-283 -- Loss: 0.12806783616542816
train-epoch-step: 75-284 -- Loss: 0.2017579823732376
train-epoch-step: 75-285 -- Loss: 0.23912504315376282
train-epoch-step: 75-286 -- Loss: 0.17841926217079163
train-epoch-step: 75-287 -- Loss: 0.2548205554485321
train-epoch-step: 75-288 -- Loss: 0.13423027098178864
train-epoch-step: 75-289 -- Loss: 0.16784292459487915
train-epoch-step: 75-290 -- Loss: 0.21740639209747314
train-epoch-step: 75-291 -- Loss: 0.14751797914505005
train-epoch-step: 75-292 -- Loss: 0.1895868480205536
train-epoch-step: 75-293 -- Loss: 0.16020920872688293
train-epoch-step: 75-294 -- Loss: 0.1865115612745285
train-epoch-step: 75-295 -- Loss: 0.41475555300712585
train-epoch-step: 75-296 -- Loss: 0.20194946229457855
train-epoch-step: 75-297 -- Loss: 0.1989649534225464
train-epoch-step: 75-298 -- Loss: 0.2558790445327759
train-epoch-step: 75-299 -- Loss: 0.19094513356685638
train-epoch-step: 75-300 -- Loss: 0.195278137922287
train-epoch-step: 75-301 -- Loss: 0.18519674241542816
train-epoch-step: 75-302 -- Loss: 0.25606104731559753
train-epoch-step: 75-303 -- Loss: 0.24243420362472534
train-epoch-step: 75-304 -- Loss: 0.16165678203105927
train-epoch-step: 75-305 -- Loss: 0.16572225093841553
train-epoch-step: 75-306 -- Loss: 0.29823100566864014
train-epoch-step: 75-307 -- Loss: 0.1956007033586502
train-epoch-step: 75-308 -- Loss: 0.26882851123809814
train-epoch-step: 75-309 -- Loss: 0.19870419800281525
train-epoch-step: 75-310 -- Loss: 0.18625299632549286
train-epoch-step: 75-311 -- Loss: 0.19227001070976257
train-epoch-step: 75-312 -- Loss: 0.23003412783145905
train-epoch-step: 75-313 -- Loss: 0.15882372856140137
train-epoch-step: 75-314 -- Loss: 0.21512159705162048
train-epoch-step: 75-315 -- Loss: 0.19771462678909302
train-epoch-step: 75-316 -- Loss: 0.17131216824054718
train-epoch-step: 75-317 -- Loss: 0.15039853751659393
train-epoch-step: 75-318 -- Loss: 0.19900378584861755
train-epoch-step: 75-319 -- Loss: 0.1776021420955658
train-epoch-step: 75-320 -- Loss: 0.12972033023834229
train-epoch-step: 75-321 -- Loss: 0.15288710594177246
train-epoch-step: 75-322 -- Loss: 0.23588712513446808
train-epoch-step: 75-323 -- Loss: 0.17299818992614746
train-epoch-step: 75-324 -- Loss: 0.3048194944858551
train-epoch-step: 75-325 -- Loss: 0.20117846131324768
train-epoch-step: 75-326 -- Loss: 0.21542790532112122
train-epoch-step: 75-327 -- Loss: 0.22318556904792786
train-epoch-step: 75-328 -- Loss: 0.22704783082008362
train-epoch-step: 75-329 -- Loss: 0.3754911720752716
train-epoch-step: 75-330 -- Loss: 0.42944490909576416
train-epoch-step: 75-331 -- Loss: 0.2531082034111023
train-epoch-step: 75-332 -- Loss: 0.11032409965991974
train-epoch-step: 75-333 -- Loss: 0.2242235392332077
train-epoch-step: 75-334 -- Loss: 0.16697584092617035
train-epoch-step: 75-335 -- Loss: 0.21006986498832703
train-epoch-step: 75-336 -- Loss: 0.20403771102428436
train-epoch-step: 75-337 -- Loss: 0.26908746361732483
train-epoch-step: 75-338 -- Loss: 0.1947842389345169
train-epoch-step: 75-339 -- Loss: 0.16355861723423004
train-epoch-step: 75-340 -- Loss: 0.22817528247833252
train-epoch-step: 75-341 -- Loss: 0.1656879186630249
train-epoch-step: 75-342 -- Loss: 0.18724839389324188
train-epoch-step: 75-343 -- Loss: 0.18707576394081116
train-epoch-step: 75-344 -- Loss: 0.20959241688251495
train-epoch-step: 75-345 -- Loss: 0.1688879430294037
train-epoch-step: 75-346 -- Loss: 0.22573569416999817
train-epoch-step: 75-347 -- Loss: 0.1917029768228531
train-epoch-step: 75-348 -- Loss: 0.23765040934085846
train-epoch-step: 75-349 -- Loss: 0.23969070613384247
train-epoch-step: 75-350 -- Loss: 0.32094088196754456
train-epoch-step: 75-351 -- Loss: 0.23441314697265625
train-epoch-step: 75-352 -- Loss: 0.14295385777950287
train-epoch-step: 75-353 -- Loss: 0.2210777848958969
train-epoch-step: 75-354 -- Loss: 0.3171430826187134
train-epoch-step: 75-355 -- Loss: 0.12570925056934357
train-epoch-step: 75-356 -- Loss: 0.1389388144016266
train-epoch-step: 75-357 -- Loss: 0.2102038860321045
train-epoch-step: 75-358 -- Loss: 0.22037670016288757
train-epoch-step: 75-359 -- Loss: 0.16356608271598816
train-epoch-step: 75-360 -- Loss: 0.1494244635105133
train-epoch-step: 75-361 -- Loss: 0.2884286344051361
train-epoch-step: 75-362 -- Loss: 0.17578250169754028
train-epoch-step: 75-363 -- Loss: 0.15394386649131775
train-epoch-step: 75-364 -- Loss: 0.20060458779335022
train-epoch-step: 75-365 -- Loss: 0.2050977349281311
train-epoch-step: 75-366 -- Loss: 0.22635479271411896
train-epoch-step: 75-367 -- Loss: 0.24510951340198517
train-epoch-step: 75-368 -- Loss: 0.22506064176559448
train-epoch-step: 75-369 -- Loss: 0.3247053027153015
train-epoch-step: 75-370 -- Loss: 0.14452038705348969
train-epoch-step: 75-371 -- Loss: 0.13360002636909485
train-epoch-step: 75-372 -- Loss: 0.15866856276988983
train-epoch-step: 75-373 -- Loss: 0.218048557639122
train-epoch-step: 75-374 -- Loss: 0.17095164954662323
train-epoch-step: 75-375 -- Loss: 0.278046190738678
train-epoch-step: 75-376 -- Loss: 0.17862974107265472
train-epoch-step: 75-377 -- Loss: 0.25307008624076843
train-epoch-step: 75-378 -- Loss: 0.2065722495317459
train-epoch-step: 75-379 -- Loss: 0.13225887715816498
train-epoch-step: 75-380 -- Loss: 0.10117729008197784
train-epoch-step: 75-381 -- Loss: 0.2724247872829437
train-epoch-step: 75-382 -- Loss: 0.2779425382614136
train-epoch-step: 75-383 -- Loss: 0.2532418668270111
train-epoch-step: 75-384 -- Loss: 0.24380405247211456
train-epoch-step: 75-385 -- Loss: 0.20691241323947906
train-epoch-step: 75-386 -- Loss: 0.23543807864189148
train-epoch-step: 75-387 -- Loss: 0.2221025824546814
train-epoch-step: 75-388 -- Loss: 0.29207414388656616
train-epoch-step: 75-389 -- Loss: 0.1995200365781784
train-epoch-step: 75-390 -- Loss: 0.15822234749794006
train-epoch-step: 75-391 -- Loss: 0.16072559356689453
train-epoch-step: 75-392 -- Loss: 0.19613441824913025
train-epoch-step: 75-393 -- Loss: 0.17131838202476501
train-epoch-step: 75-394 -- Loss: 0.2193707823753357
train-epoch-step: 75-395 -- Loss: 0.19495408236980438
train-epoch-step: 75-396 -- Loss: 0.13971538841724396
train-epoch-step: 75-397 -- Loss: 0.13546863198280334
train-epoch-step: 75-398 -- Loss: 0.23699423670768738
train-epoch-step: 75-399 -- Loss: 0.21720197796821594
train-epoch-step: 75-400 -- Loss: 0.3242337107658386
train-epoch-step: 75-401 -- Loss: 0.13683421909809113
train-epoch-step: 75-402 -- Loss: 0.2979891300201416
train-epoch-step: 75-403 -- Loss: 0.1864532232284546
train-epoch-step: 75-404 -- Loss: 0.1650712490081787
train-epoch-step: 75-405 -- Loss: 0.16098180413246155
train-epoch-step: 75-406 -- Loss: 0.22404159605503082
train-epoch-step: 75-407 -- Loss: 0.13019144535064697
train-epoch-step: 75-408 -- Loss: 0.18119069933891296
train-epoch-step: 75-409 -- Loss: 0.17988881468772888
train-epoch-step: 75-410 -- Loss: 0.20650511980056763
train-epoch-step: 75-411 -- Loss: 0.22650408744812012
train-epoch-step: 75-412 -- Loss: 0.1455937922000885
train-epoch-step: 75-413 -- Loss: 0.16509631276130676
train-epoch-step: 75-414 -- Loss: 0.15039734542369843
train-epoch-step: 75-415 -- Loss: 0.1421915888786316
train-epoch-step: 75-416 -- Loss: 0.2998110353946686
train-epoch-step: 75-417 -- Loss: 0.23885418474674225
train-epoch-step: 75-418 -- Loss: 0.2974734604358673
train-epoch-step: 75-419 -- Loss: 0.18222300708293915
train-epoch-step: 75-420 -- Loss: 0.17500241100788116
train-epoch-step: 75-421 -- Loss: 0.19191467761993408
train-epoch-step: 75-422 -- Loss: 0.1563473492860794
train-epoch-step: 75-423 -- Loss: 0.1913163661956787
train-epoch-step: 75-424 -- Loss: 0.14752131700515747
train-epoch-step: 75-425 -- Loss: 0.20041429996490479
train-epoch-step: 75-426 -- Loss: 0.20299646258354187
train-epoch-step: 75-427 -- Loss: 0.14114101231098175
train-epoch-step: 75-428 -- Loss: 0.20576389133930206
train-epoch-step: 75-429 -- Loss: 0.20382435619831085
train-epoch-step: 75-430 -- Loss: 0.16934308409690857
train-epoch-step: 75-431 -- Loss: 0.18465237319469452
train-epoch-step: 75-432 -- Loss: 0.3209154009819031
train-epoch-step: 75-433 -- Loss: 0.1477973312139511
train-epoch-step: 75-434 -- Loss: 0.14024604856967926
train-epoch-step: 75-435 -- Loss: 0.17774786055088043
train-epoch-step: 75-436 -- Loss: 0.16872289776802063
train-epoch-step: 75-437 -- Loss: 0.14588387310504913
train-epoch-step: 75-438 -- Loss: 0.21831640601158142
train-epoch-step: 75-439 -- Loss: 0.3263852596282959
train-epoch-step: 75-440 -- Loss: 0.1485164761543274
train-epoch-step: 75-441 -- Loss: 0.20770908892154694
train-epoch-step: 75-442 -- Loss: 0.22655101120471954
train-epoch-step: 75-443 -- Loss: 0.1873985230922699
train-epoch-step: 75-444 -- Loss: 0.20037010312080383
train-epoch-step: 75-445 -- Loss: 0.1925123929977417
train-epoch-step: 75-446 -- Loss: 0.159013569355011
train-epoch-step: 75-447 -- Loss: 0.2133922278881073
train-epoch-step: 75-448 -- Loss: 0.24072101712226868
train-epoch-step: 75-449 -- Loss: 0.20469971001148224
train-epoch-step: 75-450 -- Loss: 0.19119660556316376
train-epoch-step: 75-451 -- Loss: 0.15881796181201935
train-epoch-step: 75-452 -- Loss: 0.1427489072084427
train-epoch-step: 75-453 -- Loss: 0.09701515734195709
train-epoch-step: 75-454 -- Loss: 0.24725687503814697
train-epoch-step: 75-455 -- Loss: 0.13608047366142273
train-epoch-step: 75-456 -- Loss: 0.13276059925556183
train-epoch-step: 75-457 -- Loss: 0.2389528602361679
train-epoch-step: 75-458 -- Loss: 0.24751801788806915
train-epoch-step: 75-459 -- Loss: 0.23797515034675598
train-epoch-step: 75-460 -- Loss: 0.13691431283950806
train-epoch-step: 75-461 -- Loss: 0.15305307507514954
train-epoch-step: 75-462 -- Loss: 0.1639319211244583
train-epoch-step: 75-463 -- Loss: 0.15138739347457886
train-epoch-step: 75-464 -- Loss: 0.1779194474220276
train-epoch-step: 75-465 -- Loss: 0.4121139347553253
train-epoch-step: 75-466 -- Loss: 0.23053044080734253
train-epoch-step: 75-467 -- Loss: 0.12017577141523361
train-epoch-step: 75-468 -- Loss: 0.19208259880542755
train-epoch-step: 75-469 -- Loss: 0.22514797747135162
train-epoch-step: 75-470 -- Loss: 0.21300742030143738
train-epoch-step: 75-471 -- Loss: 0.16763436794281006
train-epoch-step: 75-472 -- Loss: 0.16650450229644775
train-epoch-step: 75-473 -- Loss: 0.17632529139518738
train-epoch-step: 75-474 -- Loss: 0.1318659782409668
train-epoch-step: 75-475 -- Loss: 0.12565234303474426
train-epoch-step: 75-476 -- Loss: 0.2068174183368683
train-epoch-step: 75-477 -- Loss: 0.21749478578567505
train-epoch-step: 75-478 -- Loss: 0.2015659511089325
train-epoch-step: 75-479 -- Loss: 0.14615190029144287
train-epoch-step: 75-480 -- Loss: 0.21188095211982727
train-epoch-step: 75-481 -- Loss: 0.30963385105133057
train-epoch-step: 75-482 -- Loss: 0.2728165090084076
train-epoch-step: 75-483 -- Loss: 0.19045574963092804
train-epoch-step: 75-484 -- Loss: 0.2237832248210907
train-epoch-step: 75-485 -- Loss: 0.1513201743364334
train-epoch-step: 75-486 -- Loss: 0.24323338270187378
train-epoch-step: 75-487 -- Loss: 0.24581649899482727
train-epoch-step: 75-488 -- Loss: 0.21041348576545715
train-epoch-step: 75-489 -- Loss: 0.22397181391716003
train-epoch-step: 75-490 -- Loss: 0.14416548609733582
train-epoch-step: 75-491 -- Loss: 0.1481814980506897
train-epoch-step: 75-492 -- Loss: 0.13160258531570435
train-epoch-step: 75-493 -- Loss: 0.22392073273658752
train-epoch-step: 75-494 -- Loss: 0.22572657465934753
train-epoch-step: 75-495 -- Loss: 0.21568486094474792
train-epoch-step: 75-496 -- Loss: 0.14346978068351746
train-epoch-step: 75-497 -- Loss: 0.24704086780548096
train-epoch-step: 75-498 -- Loss: 0.15204840898513794
train-epoch-step: 75-499 -- Loss: 0.18495365977287292
train-epoch-step: 75-500 -- Loss: 0.1623075306415558
train-epoch-step: 75-501 -- Loss: 0.2437216192483902
train-epoch-step: 75-502 -- Loss: 0.21846333146095276
train-epoch-step: 75-503 -- Loss: 0.23676641285419464
train-epoch-step: 75-504 -- Loss: 0.14308416843414307
train-epoch-step: 75-505 -- Loss: 0.18251584470272064
train-epoch-step: 75-506 -- Loss: 0.12162461131811142
train-epoch-step: 75-507 -- Loss: 0.1994169056415558
train-epoch-step: 75-508 -- Loss: 0.21618951857089996
train-epoch-step: 75-509 -- Loss: 0.17946293950080872
train-epoch-step: 75-510 -- Loss: 0.1471741497516632
train-epoch-step: 75-511 -- Loss: 0.23613768815994263
train-epoch-step: 75-512 -- Loss: 0.20276561379432678
train-epoch-step: 75-513 -- Loss: 0.21255239844322205
train-epoch-step: 75-514 -- Loss: 0.16265010833740234
train-epoch-step: 75-515 -- Loss: 0.17133231461048126
train-epoch-step: 75-516 -- Loss: 0.18072614073753357
train-epoch-step: 75-517 -- Loss: 0.17754578590393066
train-epoch-step: 75-518 -- Loss: 0.14731022715568542
train-epoch-step: 75-519 -- Loss: 0.13978803157806396
train-epoch-step: 75-520 -- Loss: 0.1902856081724167
train-epoch-step: 75-521 -- Loss: 0.25085121393203735
train-epoch-step: 75-522 -- Loss: 0.20731276273727417
train-epoch-step: 75-523 -- Loss: 0.16118155419826508
train-epoch-step: 75-524 -- Loss: 0.1736396998167038
train-epoch-step: 75-525 -- Loss: 0.20182478427886963
train-epoch-step: 75-526 -- Loss: 0.14418964087963104
train-epoch-step: 75-527 -- Loss: 0.1590459942817688
train-epoch-step: 75-528 -- Loss: 0.15636734664440155
train-epoch-step: 75-529 -- Loss: 0.1694743037223816
train-epoch-step: 75-530 -- Loss: 0.17750883102416992
train-epoch-step: 75-531 -- Loss: 0.2203247845172882
train-epoch-step: 75-532 -- Loss: 0.17866353690624237
train-epoch-step: 75-533 -- Loss: 0.1776171773672104
train-epoch-step: 75-534 -- Loss: 0.14074307680130005
train-epoch-step: 75-535 -- Loss: 0.27877551317214966
train-epoch-step: 75-536 -- Loss: 0.16809961199760437
train-epoch-step: 75-537 -- Loss: 0.15007275342941284
train-epoch-step: 75-538 -- Loss: 0.103940449655056
train-epoch-step: 75-539 -- Loss: 0.19612373411655426
train-epoch-step: 75-540 -- Loss: 0.14155574142932892
train-epoch-step: 75-541 -- Loss: 0.22277355194091797
train-epoch-step: 75-542 -- Loss: 0.2350321114063263
train-epoch-step: 75-543 -- Loss: 0.17464423179626465
train-epoch-step: 75-544 -- Loss: 0.23122964799404144
train-epoch-step: 75-545 -- Loss: 0.21551555395126343
train-epoch-step: 75-546 -- Loss: 0.23857170343399048
train-epoch-step: 75-547 -- Loss: 0.19552935659885406
train-epoch-step: 75-548 -- Loss: 0.0947229415178299
train-epoch-step: 75-549 -- Loss: 0.15873761475086212
train-epoch-step: 75-550 -- Loss: 0.20969036221504211
train-epoch-step: 75-551 -- Loss: 0.1636849045753479
train-epoch-step: 75-552 -- Loss: 0.12843790650367737
train-epoch-step: 75-553 -- Loss: 0.195391446352005
train-epoch-step: 75-554 -- Loss: 0.19611889123916626
train-epoch-step: 75-555 -- Loss: 0.3135671615600586
train-epoch-step: 75-556 -- Loss: 0.17744387686252594
train-epoch-step: 75-557 -- Loss: 0.2662675678730011
train-epoch-step: 75-558 -- Loss: 0.27264267206192017
train-epoch-step: 75-559 -- Loss: 0.15554076433181763
train-epoch-step: 75-560 -- Loss: 0.21393054723739624
train-epoch-step: 75-561 -- Loss: 0.20042110979557037
train-epoch-step: 75-562 -- Loss: 0.1737067699432373
train-epoch-step: 75-563 -- Loss: 0.19171032309532166
train-epoch-step: 75-564 -- Loss: 0.10419250279664993
train-epoch-step: 75-565 -- Loss: 0.19084885716438293
train-epoch-step: 75-566 -- Loss: 0.1581982970237732
train-epoch-step: 75-567 -- Loss: 0.21675482392311096
train-epoch-step: 75-568 -- Loss: 0.17500296235084534
train-epoch-step: 75-569 -- Loss: 0.28278279304504395
train-epoch-step: 75-570 -- Loss: 0.18599584698677063
train-epoch-step: 75-571 -- Loss: 0.22819513082504272
train-epoch-step: 75-572 -- Loss: 0.2622348666191101
train-epoch-step: 75-573 -- Loss: 0.22227510809898376
train-epoch-step: 75-574 -- Loss: 0.2776244878768921
train-epoch-step: 75-575 -- Loss: 0.30595579743385315
train-epoch-step: 75-576 -- Loss: 0.15174898505210876
train-epoch-step: 75-577 -- Loss: 0.17574988305568695
train-epoch-step: 75-578 -- Loss: 0.22671407461166382
train-epoch-step: 75-579 -- Loss: 0.1749928742647171
train-epoch-step: 75-580 -- Loss: 0.18826910853385925
train-epoch-step: 75-581 -- Loss: 0.14563117921352386
train-epoch-step: 75-582 -- Loss: 0.22319170832633972
train-epoch-step: 75-583 -- Loss: 0.2523314356803894
train-epoch-step: 75-584 -- Loss: 0.17460225522518158
train-epoch-step: 75-585 -- Loss: 0.1967712938785553
train-epoch-step: 75-586 -- Loss: 0.27577072381973267
train-epoch-step: 75-587 -- Loss: 0.1633487194776535
train-epoch-step: 75-588 -- Loss: 0.1330203115940094
val-epoch-step: 75-589 -- Loss: 0.26171135902404785
val-epoch-step: 75-590 -- Loss: 0.1578196883201599
val-epoch-step: 75-591 -- Loss: 0.25253528356552124
val-epoch-step: 75-592 -- Loss: 0.1858242154121399
val-epoch-step: 75-593 -- Loss: 0.16808518767356873
val-epoch-step: 75-594 -- Loss: 0.4346921443939209
val-epoch-step: 75-595 -- Loss: 0.186137855052948
val-epoch-step: 75-596 -- Loss: 0.19496986269950867
val-epoch-step: 75-597 -- Loss: 0.1781875491142273
val-epoch-step: 75-598 -- Loss: 0.16451126337051392
val-epoch-step: 75-599 -- Loss: 0.19405414164066315
val-epoch-step: 75-600 -- Loss: 0.205412358045578
val-epoch-step: 75-601 -- Loss: 0.16867370903491974
val-epoch-step: 75-602 -- Loss: 0.13892468810081482
val-epoch-step: 75-603 -- Loss: 0.21938300132751465
val-epoch-step: 75-604 -- Loss: 0.16434462368488312
val-epoch-step: 75-605 -- Loss: 0.15153157711029053
val-epoch-step: 75-606 -- Loss: 0.27552127838134766
val-epoch-step: 75-607 -- Loss: 0.14384441077709198
val-epoch-step: 75-608 -- Loss: 0.25565624237060547
val-epoch-step: 75-609 -- Loss: 0.18169346451759338
val-epoch-step: 75-610 -- Loss: 0.18466591835021973
val-epoch-step: 75-611 -- Loss: 0.16041934490203857
val-epoch-step: 75-612 -- Loss: 0.3894385099411011
val-epoch-step: 75-613 -- Loss: 0.1804613173007965
val-epoch-step: 75-614 -- Loss: 0.18971200287342072
val-epoch-step: 75-615 -- Loss: 0.1896122843027115
val-epoch-step: 75-616 -- Loss: 0.17602956295013428
val-epoch-step: 75-617 -- Loss: 0.20092250406742096
val-epoch-step: 75-618 -- Loss: 0.23645201325416565
val-epoch-step: 75-619 -- Loss: 0.2190779149532318
val-epoch-step: 75-620 -- Loss: 0.1654871255159378
val-epoch-step: 75-621 -- Loss: 0.13446760177612305
val-epoch-step: 75-622 -- Loss: 0.1472465991973877
val-epoch-step: 75-623 -- Loss: 0.1547262966632843
val-epoch-step: 75-624 -- Loss: 0.1461605727672577
val-epoch-step: 75-625 -- Loss: 0.16679136455059052
val-epoch-step: 75-626 -- Loss: 0.15589271485805511
val-epoch-step: 75-627 -- Loss: 0.20273081958293915
val-epoch-step: 75-628 -- Loss: 0.45248347520828247
val-epoch-step: 75-629 -- Loss: 0.23163390159606934
val-epoch-step: 75-630 -- Loss: 0.3611835241317749
val-epoch-step: 75-631 -- Loss: 0.15451492369174957
val-epoch-step: 75-632 -- Loss: 0.2100885957479477
val-epoch-step: 75-633 -- Loss: 0.15798062086105347
val-epoch-step: 75-634 -- Loss: 0.15205121040344238
val-epoch-step: 75-635 -- Loss: 0.1205117255449295
val-epoch-step: 75-636 -- Loss: 0.17379945516586304
val-epoch-step: 75-637 -- Loss: 0.19138650596141815
val-epoch-step: 75-638 -- Loss: 0.1541464924812317
val-epoch-step: 75-639 -- Loss: 0.28460198640823364
val-epoch-step: 75-640 -- Loss: 0.27910035848617554
val-epoch-step: 75-641 -- Loss: 0.14269009232521057
val-epoch-step: 75-642 -- Loss: 0.19906769692897797
val-epoch-step: 75-643 -- Loss: 0.20712435245513916
val-epoch-step: 75-644 -- Loss: 0.16965563595294952
val-epoch-step: 75-645 -- Loss: 0.2251962572336197
val-epoch-step: 75-646 -- Loss: 0.13510802388191223
val-epoch-step: 75-647 -- Loss: 0.13457244634628296
val-epoch-step: 75-648 -- Loss: 0.15925277769565582
val-epoch-step: 75-649 -- Loss: 0.24229662120342255
val-epoch-step: 75-650 -- Loss: 0.2544921934604645
val-epoch-step: 75-651 -- Loss: 0.14958634972572327
val-epoch-step: 75-652 -- Loss: 0.16743676364421844
val-epoch-step: 75-653 -- Loss: 0.22253113985061646
val-epoch-step: 75-654 -- Loss: 0.11712972819805145
Epoch: 75 -- Train Loss: tensor(0.1512, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 76-0 -- Loss: 0.24270087480545044
train-epoch-step: 76-1 -- Loss: 0.1578313410282135
train-epoch-step: 76-2 -- Loss: 0.2017754167318344
train-epoch-step: 76-3 -- Loss: 0.15546686947345734
train-epoch-step: 76-4 -- Loss: 0.17632080614566803
train-epoch-step: 76-5 -- Loss: 0.2128147929906845
train-epoch-step: 76-6 -- Loss: 0.3111887276172638
train-epoch-step: 76-7 -- Loss: 0.17641115188598633
train-epoch-step: 76-8 -- Loss: 0.2142619490623474
train-epoch-step: 76-9 -- Loss: 0.28673791885375977
train-epoch-step: 76-10 -- Loss: 0.22042638063430786
train-epoch-step: 76-11 -- Loss: 0.19844824075698853
train-epoch-step: 76-12 -- Loss: 0.16544777154922485
train-epoch-step: 76-13 -- Loss: 0.20938576757907867
train-epoch-step: 76-14 -- Loss: 0.20472607016563416
train-epoch-step: 76-15 -- Loss: 0.17285537719726562
train-epoch-step: 76-16 -- Loss: 0.18637841939926147
train-epoch-step: 76-17 -- Loss: 0.3245110809803009
train-epoch-step: 76-18 -- Loss: 0.20823651552200317
train-epoch-step: 76-19 -- Loss: 0.1496916264295578
train-epoch-step: 76-20 -- Loss: 0.2987448573112488
train-epoch-step: 76-21 -- Loss: 0.3964170515537262
train-epoch-step: 76-22 -- Loss: 0.16023997962474823
train-epoch-step: 76-23 -- Loss: 0.1828419715166092
train-epoch-step: 76-24 -- Loss: 0.15178686380386353
train-epoch-step: 76-25 -- Loss: 0.3198503851890564
train-epoch-step: 76-26 -- Loss: 0.25487810373306274
train-epoch-step: 76-27 -- Loss: 0.3613802492618561
train-epoch-step: 76-28 -- Loss: 0.14489327371120453
train-epoch-step: 76-29 -- Loss: 0.2673116624355316
train-epoch-step: 76-30 -- Loss: 0.11729489266872406
train-epoch-step: 76-31 -- Loss: 0.15347710251808167
train-epoch-step: 76-32 -- Loss: 0.19470083713531494
train-epoch-step: 76-33 -- Loss: 0.31417107582092285
train-epoch-step: 76-34 -- Loss: 0.22779449820518494
train-epoch-step: 76-35 -- Loss: 0.2792513370513916
train-epoch-step: 76-36 -- Loss: 0.15371114015579224
train-epoch-step: 76-37 -- Loss: 0.15248800814151764
train-epoch-step: 76-38 -- Loss: 0.1949979066848755
train-epoch-step: 76-39 -- Loss: 0.2691212594509125
train-epoch-step: 76-40 -- Loss: 0.22352610528469086
train-epoch-step: 76-41 -- Loss: 0.2538619339466095
train-epoch-step: 76-42 -- Loss: 0.1735459864139557
train-epoch-step: 76-43 -- Loss: 0.29927515983581543
train-epoch-step: 76-44 -- Loss: 0.14494775235652924
train-epoch-step: 76-45 -- Loss: 0.1329915076494217
train-epoch-step: 76-46 -- Loss: 0.2622276246547699
train-epoch-step: 76-47 -- Loss: 0.23109199106693268
train-epoch-step: 76-48 -- Loss: 0.17238634824752808
train-epoch-step: 76-49 -- Loss: 0.23185402154922485
train-epoch-step: 76-50 -- Loss: 0.12696191668510437
train-epoch-step: 76-51 -- Loss: 0.21291795372962952
train-epoch-step: 76-52 -- Loss: 0.16944821178913116
train-epoch-step: 76-53 -- Loss: 0.2426205426454544
train-epoch-step: 76-54 -- Loss: 0.3178148567676544
train-epoch-step: 76-55 -- Loss: 0.18962444365024567
train-epoch-step: 76-56 -- Loss: 0.21875987946987152
train-epoch-step: 76-57 -- Loss: 0.2648632526397705
train-epoch-step: 76-58 -- Loss: 0.3034963607788086
train-epoch-step: 76-59 -- Loss: 0.29190075397491455
train-epoch-step: 76-60 -- Loss: 0.13857588171958923
train-epoch-step: 76-61 -- Loss: 0.2504303455352783
train-epoch-step: 76-62 -- Loss: 0.1980157196521759
train-epoch-step: 76-63 -- Loss: 0.16539862751960754
train-epoch-step: 76-64 -- Loss: 0.1636098474264145
train-epoch-step: 76-65 -- Loss: 0.21603669226169586
train-epoch-step: 76-66 -- Loss: 0.11894487589597702
train-epoch-step: 76-67 -- Loss: 0.13500964641571045
train-epoch-step: 76-68 -- Loss: 0.25172722339630127
train-epoch-step: 76-69 -- Loss: 0.13404883444309235
train-epoch-step: 76-70 -- Loss: 0.24620285630226135
train-epoch-step: 76-71 -- Loss: 0.30347126722335815
train-epoch-step: 76-72 -- Loss: 0.18559233844280243
train-epoch-step: 76-73 -- Loss: 0.22942674160003662
train-epoch-step: 76-74 -- Loss: 0.10924210399389267
train-epoch-step: 76-75 -- Loss: 0.13352884352207184
train-epoch-step: 76-76 -- Loss: 0.16127774119377136
train-epoch-step: 76-77 -- Loss: 0.2456558346748352
train-epoch-step: 76-78 -- Loss: 0.32456880807876587
train-epoch-step: 76-79 -- Loss: 0.21975739300251007
train-epoch-step: 76-80 -- Loss: 0.31238338351249695
train-epoch-step: 76-81 -- Loss: 0.1732538938522339
train-epoch-step: 76-82 -- Loss: 0.26240527629852295
train-epoch-step: 76-83 -- Loss: 0.2019999474287033
train-epoch-step: 76-84 -- Loss: 0.2011895775794983
train-epoch-step: 76-85 -- Loss: 0.18366187810897827
train-epoch-step: 76-86 -- Loss: 0.13341978192329407
train-epoch-step: 76-87 -- Loss: 0.23067359626293182
train-epoch-step: 76-88 -- Loss: 0.1503112018108368
train-epoch-step: 76-89 -- Loss: 0.19574964046478271
train-epoch-step: 76-90 -- Loss: 0.2033970057964325
train-epoch-step: 76-91 -- Loss: 0.25791144371032715
train-epoch-step: 76-92 -- Loss: 0.16358180344104767
train-epoch-step: 76-93 -- Loss: 0.2378998100757599
train-epoch-step: 76-94 -- Loss: 0.2981720268726349
train-epoch-step: 76-95 -- Loss: 0.19111298024654388
train-epoch-step: 76-96 -- Loss: 0.2279643714427948
train-epoch-step: 76-97 -- Loss: 0.19037048518657684
train-epoch-step: 76-98 -- Loss: 0.15922528505325317
train-epoch-step: 76-99 -- Loss: 0.20110149681568146
train-epoch-step: 76-100 -- Loss: 0.21480537950992584
train-epoch-step: 76-101 -- Loss: 0.29554522037506104
train-epoch-step: 76-102 -- Loss: 0.2752836346626282
train-epoch-step: 76-103 -- Loss: 0.1902274489402771
train-epoch-step: 76-104 -- Loss: 0.162557452917099
train-epoch-step: 76-105 -- Loss: 0.3201410174369812
train-epoch-step: 76-106 -- Loss: 0.1827223002910614
train-epoch-step: 76-107 -- Loss: 0.22760728001594543
train-epoch-step: 76-108 -- Loss: 0.19652001559734344
train-epoch-step: 76-109 -- Loss: 0.14904525876045227
train-epoch-step: 76-110 -- Loss: 0.19914765655994415
train-epoch-step: 76-111 -- Loss: 0.18389055132865906
train-epoch-step: 76-112 -- Loss: 0.20496022701263428
train-epoch-step: 76-113 -- Loss: 0.1839134395122528
train-epoch-step: 76-114 -- Loss: 0.21448221802711487
train-epoch-step: 76-115 -- Loss: 0.17042814195156097
train-epoch-step: 76-116 -- Loss: 0.14444521069526672
train-epoch-step: 76-117 -- Loss: 0.13701987266540527
train-epoch-step: 76-118 -- Loss: 0.214141845703125
train-epoch-step: 76-119 -- Loss: 0.16774402558803558
train-epoch-step: 76-120 -- Loss: 0.2904307544231415
train-epoch-step: 76-121 -- Loss: 0.2693917453289032
train-epoch-step: 76-122 -- Loss: 0.23614290356636047
train-epoch-step: 76-123 -- Loss: 0.21785509586334229
train-epoch-step: 76-124 -- Loss: 0.131244957447052
train-epoch-step: 76-125 -- Loss: 0.1589631289243698
train-epoch-step: 76-126 -- Loss: 0.24541211128234863
train-epoch-step: 76-127 -- Loss: 0.18950685858726501
train-epoch-step: 76-128 -- Loss: 0.182772696018219
train-epoch-step: 76-129 -- Loss: 0.15757998824119568
train-epoch-step: 76-130 -- Loss: 0.19930368661880493
train-epoch-step: 76-131 -- Loss: 0.14364679157733917
train-epoch-step: 76-132 -- Loss: 0.20166027545928955
train-epoch-step: 76-133 -- Loss: 0.13176408410072327
train-epoch-step: 76-134 -- Loss: 0.20167015492916107
train-epoch-step: 76-135 -- Loss: 0.1444581300020218
train-epoch-step: 76-136 -- Loss: 0.13262341916561127
train-epoch-step: 76-137 -- Loss: 0.26999208331108093
train-epoch-step: 76-138 -- Loss: 0.2722381055355072
train-epoch-step: 76-139 -- Loss: 0.13742852210998535
train-epoch-step: 76-140 -- Loss: 0.22300195693969727
train-epoch-step: 76-141 -- Loss: 0.2507845461368561
train-epoch-step: 76-142 -- Loss: 0.20663964748382568
train-epoch-step: 76-143 -- Loss: 0.1821126639842987
train-epoch-step: 76-144 -- Loss: 0.2092273235321045
train-epoch-step: 76-145 -- Loss: 0.1428166925907135
train-epoch-step: 76-146 -- Loss: 0.18949931859970093
train-epoch-step: 76-147 -- Loss: 0.17505547404289246
train-epoch-step: 76-148 -- Loss: 0.1789858043193817
train-epoch-step: 76-149 -- Loss: 0.13576526939868927
train-epoch-step: 76-150 -- Loss: 0.19625237584114075
train-epoch-step: 76-151 -- Loss: 0.19077876210212708
train-epoch-step: 76-152 -- Loss: 0.20466548204421997
train-epoch-step: 76-153 -- Loss: 0.2729700803756714
train-epoch-step: 76-154 -- Loss: 0.1381242424249649
train-epoch-step: 76-155 -- Loss: 0.13844873011112213
train-epoch-step: 76-156 -- Loss: 0.12655723094940186
train-epoch-step: 76-157 -- Loss: 0.16772088408470154
train-epoch-step: 76-158 -- Loss: 0.16991324722766876
train-epoch-step: 76-159 -- Loss: 0.18132388591766357
train-epoch-step: 76-160 -- Loss: 0.23334309458732605
train-epoch-step: 76-161 -- Loss: 0.21266575157642365
train-epoch-step: 76-162 -- Loss: 0.214632049202919
train-epoch-step: 76-163 -- Loss: 0.18879076838493347
train-epoch-step: 76-164 -- Loss: 0.1908200979232788
train-epoch-step: 76-165 -- Loss: 0.16353128850460052
train-epoch-step: 76-166 -- Loss: 0.1246815174818039
train-epoch-step: 76-167 -- Loss: 0.13160479068756104
train-epoch-step: 76-168 -- Loss: 0.21743160486221313
train-epoch-step: 76-169 -- Loss: 0.1395384520292282
train-epoch-step: 76-170 -- Loss: 0.20303212106227875
train-epoch-step: 76-171 -- Loss: 0.1484726071357727
train-epoch-step: 76-172 -- Loss: 0.2644091844558716
train-epoch-step: 76-173 -- Loss: 0.13567405939102173
train-epoch-step: 76-174 -- Loss: 0.24675559997558594
train-epoch-step: 76-175 -- Loss: 0.18895235657691956
train-epoch-step: 76-176 -- Loss: 0.13373015820980072
train-epoch-step: 76-177 -- Loss: 0.18403306603431702
train-epoch-step: 76-178 -- Loss: 0.18942175805568695
train-epoch-step: 76-179 -- Loss: 0.16085588932037354
train-epoch-step: 76-180 -- Loss: 0.15891802310943604
train-epoch-step: 76-181 -- Loss: 0.1746935397386551
train-epoch-step: 76-182 -- Loss: 0.19518019258975983
train-epoch-step: 76-183 -- Loss: 0.2782096266746521
train-epoch-step: 76-184 -- Loss: 0.13856664299964905
train-epoch-step: 76-185 -- Loss: 0.14352761209011078
train-epoch-step: 76-186 -- Loss: 0.1887432485818863
train-epoch-step: 76-187 -- Loss: 0.212111696600914
train-epoch-step: 76-188 -- Loss: 0.17695224285125732
train-epoch-step: 76-189 -- Loss: 0.10618863999843597
train-epoch-step: 76-190 -- Loss: 0.18385113775730133
train-epoch-step: 76-191 -- Loss: 0.16070690751075745
train-epoch-step: 76-192 -- Loss: 0.23856589198112488
train-epoch-step: 76-193 -- Loss: 0.21660387516021729
train-epoch-step: 76-194 -- Loss: 0.18799972534179688
train-epoch-step: 76-195 -- Loss: 0.1702512502670288
train-epoch-step: 76-196 -- Loss: 0.17021091282367706
train-epoch-step: 76-197 -- Loss: 0.13566739857196808
train-epoch-step: 76-198 -- Loss: 0.13044047355651855
train-epoch-step: 76-199 -- Loss: 0.15199245512485504
train-epoch-step: 76-200 -- Loss: 0.12431152164936066
train-epoch-step: 76-201 -- Loss: 0.19994431734085083
train-epoch-step: 76-202 -- Loss: 0.1355375498533249
train-epoch-step: 76-203 -- Loss: 0.19597066938877106
train-epoch-step: 76-204 -- Loss: 0.1392924040555954
train-epoch-step: 76-205 -- Loss: 0.18467476963996887
train-epoch-step: 76-206 -- Loss: 0.20793728530406952
train-epoch-step: 76-207 -- Loss: 0.1382783204317093
train-epoch-step: 76-208 -- Loss: 0.1785879284143448
train-epoch-step: 76-209 -- Loss: 0.14829884469509125
train-epoch-step: 76-210 -- Loss: 0.13763023912906647
train-epoch-step: 76-211 -- Loss: 0.21847674250602722
train-epoch-step: 76-212 -- Loss: 0.21421727538108826
train-epoch-step: 76-213 -- Loss: 0.12905322015285492
train-epoch-step: 76-214 -- Loss: 0.1519937962293625
train-epoch-step: 76-215 -- Loss: 0.12603725492954254
train-epoch-step: 76-216 -- Loss: 0.20285415649414062
train-epoch-step: 76-217 -- Loss: 0.21917255222797394
train-epoch-step: 76-218 -- Loss: 0.15180453658103943
train-epoch-step: 76-219 -- Loss: 0.18740102648735046
train-epoch-step: 76-220 -- Loss: 0.12887708842754364
train-epoch-step: 76-221 -- Loss: 0.20466157793998718
train-epoch-step: 76-222 -- Loss: 0.12375998497009277
train-epoch-step: 76-223 -- Loss: 0.17402416467666626
train-epoch-step: 76-224 -- Loss: 0.2015373706817627
train-epoch-step: 76-225 -- Loss: 0.27068835496902466
train-epoch-step: 76-226 -- Loss: 0.20890775322914124
train-epoch-step: 76-227 -- Loss: 0.23276400566101074
train-epoch-step: 76-228 -- Loss: 0.17744766175746918
train-epoch-step: 76-229 -- Loss: 0.17619286477565765
train-epoch-step: 76-230 -- Loss: 0.16142959892749786
train-epoch-step: 76-231 -- Loss: 0.17535316944122314
train-epoch-step: 76-232 -- Loss: 0.190863236784935
train-epoch-step: 76-233 -- Loss: 0.08555044233798981
train-epoch-step: 76-234 -- Loss: 0.17680694162845612
train-epoch-step: 76-235 -- Loss: 0.17001447081565857
train-epoch-step: 76-236 -- Loss: 0.19156414270401
train-epoch-step: 76-237 -- Loss: 0.23962226510047913
train-epoch-step: 76-238 -- Loss: 0.1575065553188324
train-epoch-step: 76-239 -- Loss: 0.13214318454265594
train-epoch-step: 76-240 -- Loss: 0.22721579670906067
train-epoch-step: 76-241 -- Loss: 0.15616865456104279
train-epoch-step: 76-242 -- Loss: 0.22576643526554108
train-epoch-step: 76-243 -- Loss: 0.2388879954814911
train-epoch-step: 76-244 -- Loss: 0.21266493201255798
train-epoch-step: 76-245 -- Loss: 0.21727272868156433
train-epoch-step: 76-246 -- Loss: 0.21983125805854797
train-epoch-step: 76-247 -- Loss: 0.21481510996818542
train-epoch-step: 76-248 -- Loss: 0.1871950775384903
train-epoch-step: 76-249 -- Loss: 0.13926219940185547
train-epoch-step: 76-250 -- Loss: 0.20278316736221313
train-epoch-step: 76-251 -- Loss: 0.1120062917470932
train-epoch-step: 76-252 -- Loss: 0.21209955215454102
train-epoch-step: 76-253 -- Loss: 0.14126935601234436
train-epoch-step: 76-254 -- Loss: 0.22258736193180084
train-epoch-step: 76-255 -- Loss: 0.14332862198352814
train-epoch-step: 76-256 -- Loss: 0.16962051391601562
train-epoch-step: 76-257 -- Loss: 0.1913411021232605
train-epoch-step: 76-258 -- Loss: 0.15127816796302795
train-epoch-step: 76-259 -- Loss: 0.13230527937412262
train-epoch-step: 76-260 -- Loss: 0.20417511463165283
train-epoch-step: 76-261 -- Loss: 0.17973282933235168
train-epoch-step: 76-262 -- Loss: 0.3223133683204651
train-epoch-step: 76-263 -- Loss: 0.26754212379455566
train-epoch-step: 76-264 -- Loss: 0.17427462339401245
train-epoch-step: 76-265 -- Loss: 0.13932624459266663
train-epoch-step: 76-266 -- Loss: 0.17086447775363922
train-epoch-step: 76-267 -- Loss: 0.13676486909389496
train-epoch-step: 76-268 -- Loss: 0.12133096903562546
train-epoch-step: 76-269 -- Loss: 0.171232208609581
train-epoch-step: 76-270 -- Loss: 0.10839591175317764
train-epoch-step: 76-271 -- Loss: 0.15582169592380524
train-epoch-step: 76-272 -- Loss: 0.1232365071773529
train-epoch-step: 76-273 -- Loss: 0.13075976073741913
train-epoch-step: 76-274 -- Loss: 0.2128056287765503
train-epoch-step: 76-275 -- Loss: 0.22456912696361542
train-epoch-step: 76-276 -- Loss: 0.17145217955112457
train-epoch-step: 76-277 -- Loss: 0.16067078709602356
train-epoch-step: 76-278 -- Loss: 0.14317938685417175
train-epoch-step: 76-279 -- Loss: 0.14364279806613922
train-epoch-step: 76-280 -- Loss: 0.2200607806444168
train-epoch-step: 76-281 -- Loss: 0.1810532808303833
train-epoch-step: 76-282 -- Loss: 0.14012861251831055
train-epoch-step: 76-283 -- Loss: 0.11806906014680862
train-epoch-step: 76-284 -- Loss: 0.1642874777317047
train-epoch-step: 76-285 -- Loss: 0.19921362400054932
train-epoch-step: 76-286 -- Loss: 0.160703644156456
train-epoch-step: 76-287 -- Loss: 0.22187699377536774
train-epoch-step: 76-288 -- Loss: 0.09921853989362717
train-epoch-step: 76-289 -- Loss: 0.126090407371521
train-epoch-step: 76-290 -- Loss: 0.1834971308708191
train-epoch-step: 76-291 -- Loss: 0.12074705958366394
train-epoch-step: 76-292 -- Loss: 0.17345184087753296
train-epoch-step: 76-293 -- Loss: 0.1371471881866455
train-epoch-step: 76-294 -- Loss: 0.16895583271980286
train-epoch-step: 76-295 -- Loss: 0.27058953046798706
train-epoch-step: 76-296 -- Loss: 0.17621444165706635
train-epoch-step: 76-297 -- Loss: 0.17596030235290527
train-epoch-step: 76-298 -- Loss: 0.23098653554916382
train-epoch-step: 76-299 -- Loss: 0.15048235654830933
train-epoch-step: 76-300 -- Loss: 0.17818675935268402
train-epoch-step: 76-301 -- Loss: 0.17450006306171417
train-epoch-step: 76-302 -- Loss: 0.2262658029794693
train-epoch-step: 76-303 -- Loss: 0.20499099791049957
train-epoch-step: 76-304 -- Loss: 0.14347843825817108
train-epoch-step: 76-305 -- Loss: 0.1445864886045456
train-epoch-step: 76-306 -- Loss: 0.23267687857151031
train-epoch-step: 76-307 -- Loss: 0.1724408119916916
train-epoch-step: 76-308 -- Loss: 0.2337382435798645
train-epoch-step: 76-309 -- Loss: 0.15851134061813354
train-epoch-step: 76-310 -- Loss: 0.17187926173210144
train-epoch-step: 76-311 -- Loss: 0.15775948762893677
train-epoch-step: 76-312 -- Loss: 0.2185676395893097
train-epoch-step: 76-313 -- Loss: 0.09906192868947983
train-epoch-step: 76-314 -- Loss: 0.19452783465385437
train-epoch-step: 76-315 -- Loss: 0.16601493954658508
train-epoch-step: 76-316 -- Loss: 0.15366412699222565
train-epoch-step: 76-317 -- Loss: 0.14160332083702087
train-epoch-step: 76-318 -- Loss: 0.17375755310058594
train-epoch-step: 76-319 -- Loss: 0.1714858114719391
train-epoch-step: 76-320 -- Loss: 0.11971324682235718
train-epoch-step: 76-321 -- Loss: 0.13900160789489746
train-epoch-step: 76-322 -- Loss: 0.21174493432044983
train-epoch-step: 76-323 -- Loss: 0.1656983494758606
train-epoch-step: 76-324 -- Loss: 0.25836414098739624
train-epoch-step: 76-325 -- Loss: 0.15596601366996765
train-epoch-step: 76-326 -- Loss: 0.18401417136192322
train-epoch-step: 76-327 -- Loss: 0.20462071895599365
train-epoch-step: 76-328 -- Loss: 0.20046614110469818
train-epoch-step: 76-329 -- Loss: 0.349987655878067
train-epoch-step: 76-330 -- Loss: 0.3636566996574402
train-epoch-step: 76-331 -- Loss: 0.20722314715385437
train-epoch-step: 76-332 -- Loss: 0.10111598670482635
train-epoch-step: 76-333 -- Loss: 0.18582630157470703
train-epoch-step: 76-334 -- Loss: 0.1598222851753235
train-epoch-step: 76-335 -- Loss: 0.1743859350681305
train-epoch-step: 76-336 -- Loss: 0.15262684226036072
train-epoch-step: 76-337 -- Loss: 0.2106926441192627
train-epoch-step: 76-338 -- Loss: 0.1606922745704651
train-epoch-step: 76-339 -- Loss: 0.15331575274467468
train-epoch-step: 76-340 -- Loss: 0.20069722831249237
train-epoch-step: 76-341 -- Loss: 0.1406104862689972
train-epoch-step: 76-342 -- Loss: 0.16262087225914001
train-epoch-step: 76-343 -- Loss: 0.1552588939666748
train-epoch-step: 76-344 -- Loss: 0.16652575135231018
train-epoch-step: 76-345 -- Loss: 0.12645715475082397
train-epoch-step: 76-346 -- Loss: 0.22329451143741608
train-epoch-step: 76-347 -- Loss: 0.1530504822731018
train-epoch-step: 76-348 -- Loss: 0.21383525431156158
train-epoch-step: 76-349 -- Loss: 0.2027236521244049
train-epoch-step: 76-350 -- Loss: 0.26025718450546265
train-epoch-step: 76-351 -- Loss: 0.19541305303573608
train-epoch-step: 76-352 -- Loss: 0.12425892800092697
train-epoch-step: 76-353 -- Loss: 0.19637566804885864
train-epoch-step: 76-354 -- Loss: 0.2810863256454468
train-epoch-step: 76-355 -- Loss: 0.11886635422706604
train-epoch-step: 76-356 -- Loss: 0.1165056824684143
train-epoch-step: 76-357 -- Loss: 0.1900789737701416
train-epoch-step: 76-358 -- Loss: 0.1903492510318756
train-epoch-step: 76-359 -- Loss: 0.1375652551651001
train-epoch-step: 76-360 -- Loss: 0.128016397356987
train-epoch-step: 76-361 -- Loss: 0.2395973950624466
train-epoch-step: 76-362 -- Loss: 0.16977126896381378
train-epoch-step: 76-363 -- Loss: 0.11207498610019684
train-epoch-step: 76-364 -- Loss: 0.18196214735507965
train-epoch-step: 76-365 -- Loss: 0.17971163988113403
train-epoch-step: 76-366 -- Loss: 0.2016243040561676
train-epoch-step: 76-367 -- Loss: 0.2335033118724823
train-epoch-step: 76-368 -- Loss: 0.20287713408470154
train-epoch-step: 76-369 -- Loss: 0.28564849495887756
train-epoch-step: 76-370 -- Loss: 0.12626473605632782
train-epoch-step: 76-371 -- Loss: 0.12333253026008606
train-epoch-step: 76-372 -- Loss: 0.14892403781414032
train-epoch-step: 76-373 -- Loss: 0.21979495882987976
train-epoch-step: 76-374 -- Loss: 0.16302409768104553
train-epoch-step: 76-375 -- Loss: 0.2703095078468323
train-epoch-step: 76-376 -- Loss: 0.16030630469322205
train-epoch-step: 76-377 -- Loss: 0.28773629665374756
train-epoch-step: 76-378 -- Loss: 0.20681461691856384
train-epoch-step: 76-379 -- Loss: 0.11939232051372528
train-epoch-step: 76-380 -- Loss: 0.10051503777503967
train-epoch-step: 76-381 -- Loss: 0.24598820507526398
train-epoch-step: 76-382 -- Loss: 0.2566494345664978
train-epoch-step: 76-383 -- Loss: 0.19535228610038757
train-epoch-step: 76-384 -- Loss: 0.21895837783813477
train-epoch-step: 76-385 -- Loss: 0.21508735418319702
train-epoch-step: 76-386 -- Loss: 0.22935613989830017
train-epoch-step: 76-387 -- Loss: 0.21831171214580536
train-epoch-step: 76-388 -- Loss: 0.22686615586280823
train-epoch-step: 76-389 -- Loss: 0.2110845297574997
train-epoch-step: 76-390 -- Loss: 0.16043564677238464
train-epoch-step: 76-391 -- Loss: 0.15329495072364807
train-epoch-step: 76-392 -- Loss: 0.19157272577285767
train-epoch-step: 76-393 -- Loss: 0.1604747325181961
train-epoch-step: 76-394 -- Loss: 0.2105657011270523
train-epoch-step: 76-395 -- Loss: 0.18281294405460358
train-epoch-step: 76-396 -- Loss: 0.1323557049036026
train-epoch-step: 76-397 -- Loss: 0.1330907940864563
train-epoch-step: 76-398 -- Loss: 0.20541217923164368
train-epoch-step: 76-399 -- Loss: 0.18306270241737366
train-epoch-step: 76-400 -- Loss: 0.288147509098053
train-epoch-step: 76-401 -- Loss: 0.12669126689434052
train-epoch-step: 76-402 -- Loss: 0.26072949171066284
train-epoch-step: 76-403 -- Loss: 0.1645340621471405
train-epoch-step: 76-404 -- Loss: 0.14201593399047852
train-epoch-step: 76-405 -- Loss: 0.14806319773197174
train-epoch-step: 76-406 -- Loss: 0.18813806772232056
train-epoch-step: 76-407 -- Loss: 0.11538831889629364
train-epoch-step: 76-408 -- Loss: 0.1777002364397049
train-epoch-step: 76-409 -- Loss: 0.18218722939491272
train-epoch-step: 76-410 -- Loss: 0.1813913881778717
train-epoch-step: 76-411 -- Loss: 0.21570219099521637
train-epoch-step: 76-412 -- Loss: 0.1324492245912552
train-epoch-step: 76-413 -- Loss: 0.1482541263103485
train-epoch-step: 76-414 -- Loss: 0.14456787705421448
train-epoch-step: 76-415 -- Loss: 0.13615839183330536
train-epoch-step: 76-416 -- Loss: 0.28344830870628357
train-epoch-step: 76-417 -- Loss: 0.20299863815307617
train-epoch-step: 76-418 -- Loss: 0.24502119421958923
train-epoch-step: 76-419 -- Loss: 0.17467442154884338
train-epoch-step: 76-420 -- Loss: 0.1565636396408081
train-epoch-step: 76-421 -- Loss: 0.18105903267860413
train-epoch-step: 76-422 -- Loss: 0.1471535712480545
train-epoch-step: 76-423 -- Loss: 0.17783719301223755
train-epoch-step: 76-424 -- Loss: 0.142867311835289
train-epoch-step: 76-425 -- Loss: 0.18893010914325714
train-epoch-step: 76-426 -- Loss: 0.1767999529838562
train-epoch-step: 76-427 -- Loss: 0.13640399277210236
train-epoch-step: 76-428 -- Loss: 0.20379213988780975
train-epoch-step: 76-429 -- Loss: 0.17898909747600555
train-epoch-step: 76-430 -- Loss: 0.14388588070869446
train-epoch-step: 76-431 -- Loss: 0.17804856598377228
train-epoch-step: 76-432 -- Loss: 0.24812552332878113
train-epoch-step: 76-433 -- Loss: 0.13726894557476044
train-epoch-step: 76-434 -- Loss: 0.13219089806079865
train-epoch-step: 76-435 -- Loss: 0.1649666577577591
train-epoch-step: 76-436 -- Loss: 0.16743385791778564
train-epoch-step: 76-437 -- Loss: 0.13304577767848969
train-epoch-step: 76-438 -- Loss: 0.17282119393348694
train-epoch-step: 76-439 -- Loss: 0.27649518847465515
train-epoch-step: 76-440 -- Loss: 0.13261637091636658
train-epoch-step: 76-441 -- Loss: 0.20098204910755157
train-epoch-step: 76-442 -- Loss: 0.18040744960308075
train-epoch-step: 76-443 -- Loss: 0.17815880477428436
train-epoch-step: 76-444 -- Loss: 0.17428138852119446
train-epoch-step: 76-445 -- Loss: 0.18298667669296265
train-epoch-step: 76-446 -- Loss: 0.1534290909767151
train-epoch-step: 76-447 -- Loss: 0.19477787613868713
train-epoch-step: 76-448 -- Loss: 0.23724837601184845
train-epoch-step: 76-449 -- Loss: 0.20101216435432434
train-epoch-step: 76-450 -- Loss: 0.19679944217205048
train-epoch-step: 76-451 -- Loss: 0.14969012141227722
train-epoch-step: 76-452 -- Loss: 0.13081398606300354
train-epoch-step: 76-453 -- Loss: 0.09612845629453659
train-epoch-step: 76-454 -- Loss: 0.23359259963035583
train-epoch-step: 76-455 -- Loss: 0.12447522580623627
train-epoch-step: 76-456 -- Loss: 0.12127340584993362
train-epoch-step: 76-457 -- Loss: 0.22315898537635803
train-epoch-step: 76-458 -- Loss: 0.2056792676448822
train-epoch-step: 76-459 -- Loss: 0.22012241184711456
train-epoch-step: 76-460 -- Loss: 0.12622693181037903
train-epoch-step: 76-461 -- Loss: 0.15085642039775848
train-epoch-step: 76-462 -- Loss: 0.16341377794742584
train-epoch-step: 76-463 -- Loss: 0.15235958993434906
train-epoch-step: 76-464 -- Loss: 0.17701517045497894
train-epoch-step: 76-465 -- Loss: 0.27190113067626953
train-epoch-step: 76-466 -- Loss: 0.21085278689861298
train-epoch-step: 76-467 -- Loss: 0.13151970505714417
train-epoch-step: 76-468 -- Loss: 0.18404310941696167
train-epoch-step: 76-469 -- Loss: 0.21473447978496552
train-epoch-step: 76-470 -- Loss: 0.1935223788022995
train-epoch-step: 76-471 -- Loss: 0.16693446040153503
train-epoch-step: 76-472 -- Loss: 0.17078723013401031
train-epoch-step: 76-473 -- Loss: 0.17023780941963196
train-epoch-step: 76-474 -- Loss: 0.13327066600322723
train-epoch-step: 76-475 -- Loss: 0.12623298168182373
train-epoch-step: 76-476 -- Loss: 0.2045416533946991
train-epoch-step: 76-477 -- Loss: 0.20961926877498627
train-epoch-step: 76-478 -- Loss: 0.20296993851661682
train-epoch-step: 76-479 -- Loss: 0.14601361751556396
train-epoch-step: 76-480 -- Loss: 0.1992482841014862
train-epoch-step: 76-481 -- Loss: 0.29441893100738525
train-epoch-step: 76-482 -- Loss: 0.282333642244339
train-epoch-step: 76-483 -- Loss: 0.18419373035430908
train-epoch-step: 76-484 -- Loss: 0.21780967712402344
train-epoch-step: 76-485 -- Loss: 0.13176366686820984
train-epoch-step: 76-486 -- Loss: 0.2587079703807831
train-epoch-step: 76-487 -- Loss: 0.23457252979278564
train-epoch-step: 76-488 -- Loss: 0.22632423043251038
train-epoch-step: 76-489 -- Loss: 0.22005099058151245
train-epoch-step: 76-490 -- Loss: 0.14298872649669647
train-epoch-step: 76-491 -- Loss: 0.13861054182052612
train-epoch-step: 76-492 -- Loss: 0.12908075749874115
train-epoch-step: 76-493 -- Loss: 0.2019769698381424
train-epoch-step: 76-494 -- Loss: 0.20719440281391144
train-epoch-step: 76-495 -- Loss: 0.20542797446250916
train-epoch-step: 76-496 -- Loss: 0.14143256843090057
train-epoch-step: 76-497 -- Loss: 0.21836917102336884
train-epoch-step: 76-498 -- Loss: 0.14927658438682556
train-epoch-step: 76-499 -- Loss: 0.17144112288951874
train-epoch-step: 76-500 -- Loss: 0.16936996579170227
train-epoch-step: 76-501 -- Loss: 0.2194051593542099
train-epoch-step: 76-502 -- Loss: 0.17716936767101288
train-epoch-step: 76-503 -- Loss: 0.23918285965919495
train-epoch-step: 76-504 -- Loss: 0.12463343888521194
train-epoch-step: 76-505 -- Loss: 0.18584927916526794
train-epoch-step: 76-506 -- Loss: 0.11680744588375092
train-epoch-step: 76-507 -- Loss: 0.18965701758861542
train-epoch-step: 76-508 -- Loss: 0.19162188470363617
train-epoch-step: 76-509 -- Loss: 0.1716897040605545
train-epoch-step: 76-510 -- Loss: 0.13042938709259033
train-epoch-step: 76-511 -- Loss: 0.22211438417434692
train-epoch-step: 76-512 -- Loss: 0.18637771904468536
train-epoch-step: 76-513 -- Loss: 0.19564953446388245
train-epoch-step: 76-514 -- Loss: 0.14704301953315735
train-epoch-step: 76-515 -- Loss: 0.15492838621139526
train-epoch-step: 76-516 -- Loss: 0.18239450454711914
train-epoch-step: 76-517 -- Loss: 0.17656035721302032
train-epoch-step: 76-518 -- Loss: 0.14288964867591858
train-epoch-step: 76-519 -- Loss: 0.13873332738876343
train-epoch-step: 76-520 -- Loss: 0.1913858950138092
train-epoch-step: 76-521 -- Loss: 0.23724240064620972
train-epoch-step: 76-522 -- Loss: 0.18776684999465942
train-epoch-step: 76-523 -- Loss: 0.16204625368118286
train-epoch-step: 76-524 -- Loss: 0.16882024705410004
train-epoch-step: 76-525 -- Loss: 0.19195698201656342
train-epoch-step: 76-526 -- Loss: 0.1334981620311737
train-epoch-step: 76-527 -- Loss: 0.15294870734214783
train-epoch-step: 76-528 -- Loss: 0.15610763430595398
train-epoch-step: 76-529 -- Loss: 0.16121527552604675
train-epoch-step: 76-530 -- Loss: 0.16925601661205292
train-epoch-step: 76-531 -- Loss: 0.20735639333724976
train-epoch-step: 76-532 -- Loss: 0.17543649673461914
train-epoch-step: 76-533 -- Loss: 0.1731189787387848
train-epoch-step: 76-534 -- Loss: 0.12634873390197754
train-epoch-step: 76-535 -- Loss: 0.25333279371261597
train-epoch-step: 76-536 -- Loss: 0.1595694124698639
train-epoch-step: 76-537 -- Loss: 0.15436670184135437
train-epoch-step: 76-538 -- Loss: 0.10476130247116089
train-epoch-step: 76-539 -- Loss: 0.17972028255462646
train-epoch-step: 76-540 -- Loss: 0.13656345009803772
train-epoch-step: 76-541 -- Loss: 0.21292230486869812
train-epoch-step: 76-542 -- Loss: 0.2298024743795395
train-epoch-step: 76-543 -- Loss: 0.1752186417579651
train-epoch-step: 76-544 -- Loss: 0.22435042262077332
train-epoch-step: 76-545 -- Loss: 0.19998548924922943
train-epoch-step: 76-546 -- Loss: 0.21294105052947998
train-epoch-step: 76-547 -- Loss: 0.18441063165664673
train-epoch-step: 76-548 -- Loss: 0.09101716428995132
train-epoch-step: 76-549 -- Loss: 0.15117058157920837
train-epoch-step: 76-550 -- Loss: 0.20800715684890747
train-epoch-step: 76-551 -- Loss: 0.15368230640888214
train-epoch-step: 76-552 -- Loss: 0.12596994638442993
train-epoch-step: 76-553 -- Loss: 0.19742938876152039
train-epoch-step: 76-554 -- Loss: 0.18632075190544128
train-epoch-step: 76-555 -- Loss: 0.21341446042060852
train-epoch-step: 76-556 -- Loss: 0.14834435284137726
train-epoch-step: 76-557 -- Loss: 0.23244944214820862
train-epoch-step: 76-558 -- Loss: 0.2741926610469818
train-epoch-step: 76-559 -- Loss: 0.14403656125068665
train-epoch-step: 76-560 -- Loss: 0.20598247647285461
train-epoch-step: 76-561 -- Loss: 0.18363291025161743
train-epoch-step: 76-562 -- Loss: 0.1652197539806366
train-epoch-step: 76-563 -- Loss: 0.1872188299894333
train-epoch-step: 76-564 -- Loss: 0.10202966630458832
train-epoch-step: 76-565 -- Loss: 0.18401040136814117
train-epoch-step: 76-566 -- Loss: 0.15226802229881287
train-epoch-step: 76-567 -- Loss: 0.21252039074897766
train-epoch-step: 76-568 -- Loss: 0.1650511920452118
train-epoch-step: 76-569 -- Loss: 0.2422695904970169
train-epoch-step: 76-570 -- Loss: 0.16611456871032715
train-epoch-step: 76-571 -- Loss: 0.21305154263973236
train-epoch-step: 76-572 -- Loss: 0.2412835955619812
train-epoch-step: 76-573 -- Loss: 0.19896794855594635
train-epoch-step: 76-574 -- Loss: 0.2421717643737793
train-epoch-step: 76-575 -- Loss: 0.293939471244812
train-epoch-step: 76-576 -- Loss: 0.117069311439991
train-epoch-step: 76-577 -- Loss: 0.1680806577205658
train-epoch-step: 76-578 -- Loss: 0.21201813220977783
train-epoch-step: 76-579 -- Loss: 0.16550149023532867
train-epoch-step: 76-580 -- Loss: 0.1711960881948471
train-epoch-step: 76-581 -- Loss: 0.14022184908390045
train-epoch-step: 76-582 -- Loss: 0.20353509485721588
train-epoch-step: 76-583 -- Loss: 0.2224934697151184
train-epoch-step: 76-584 -- Loss: 0.17702145874500275
train-epoch-step: 76-585 -- Loss: 0.19565141201019287
train-epoch-step: 76-586 -- Loss: 0.2521861791610718
train-epoch-step: 76-587 -- Loss: 0.15822328627109528
train-epoch-step: 76-588 -- Loss: 0.1249847412109375
val-epoch-step: 76-589 -- Loss: 0.2152707576751709
val-epoch-step: 76-590 -- Loss: 0.14983509480953217
val-epoch-step: 76-591 -- Loss: 0.2586708664894104
val-epoch-step: 76-592 -- Loss: 0.17237475514411926
val-epoch-step: 76-593 -- Loss: 0.15440182387828827
val-epoch-step: 76-594 -- Loss: 0.36570748686790466
val-epoch-step: 76-595 -- Loss: 0.17932583391666412
val-epoch-step: 76-596 -- Loss: 0.1935248076915741
val-epoch-step: 76-597 -- Loss: 0.1717270314693451
val-epoch-step: 76-598 -- Loss: 0.14825639128684998
val-epoch-step: 76-599 -- Loss: 0.18540513515472412
val-epoch-step: 76-600 -- Loss: 0.2042091339826584
val-epoch-step: 76-601 -- Loss: 0.15174096822738647
val-epoch-step: 76-602 -- Loss: 0.1349104344844818
val-epoch-step: 76-603 -- Loss: 0.22695599496364594
val-epoch-step: 76-604 -- Loss: 0.14549902081489563
val-epoch-step: 76-605 -- Loss: 0.14478667080402374
val-epoch-step: 76-606 -- Loss: 0.28076261281967163
val-epoch-step: 76-607 -- Loss: 0.12778839468955994
val-epoch-step: 76-608 -- Loss: 0.24557586014270782
val-epoch-step: 76-609 -- Loss: 0.15855972468852997
val-epoch-step: 76-610 -- Loss: 0.17699553072452545
val-epoch-step: 76-611 -- Loss: 0.1550651639699936
val-epoch-step: 76-612 -- Loss: 0.43469566106796265
val-epoch-step: 76-613 -- Loss: 0.1828511357307434
val-epoch-step: 76-614 -- Loss: 0.17842665314674377
val-epoch-step: 76-615 -- Loss: 0.1702955663204193
val-epoch-step: 76-616 -- Loss: 0.15051579475402832
val-epoch-step: 76-617 -- Loss: 0.19554418325424194
val-epoch-step: 76-618 -- Loss: 0.1813167929649353
val-epoch-step: 76-619 -- Loss: 0.2189083993434906
val-epoch-step: 76-620 -- Loss: 0.1366206407546997
val-epoch-step: 76-621 -- Loss: 0.1304611712694168
val-epoch-step: 76-622 -- Loss: 0.1401451826095581
val-epoch-step: 76-623 -- Loss: 0.14925801753997803
val-epoch-step: 76-624 -- Loss: 0.14094127714633942
val-epoch-step: 76-625 -- Loss: 0.16334325075149536
val-epoch-step: 76-626 -- Loss: 0.1484794169664383
val-epoch-step: 76-627 -- Loss: 0.18523329496383667
val-epoch-step: 76-628 -- Loss: 0.6726149320602417
val-epoch-step: 76-629 -- Loss: 0.1947104036808014
val-epoch-step: 76-630 -- Loss: 0.3413316011428833
val-epoch-step: 76-631 -- Loss: 0.16655784845352173
val-epoch-step: 76-632 -- Loss: 0.20226000249385834
val-epoch-step: 76-633 -- Loss: 0.1511022001504898
val-epoch-step: 76-634 -- Loss: 0.14284829795360565
val-epoch-step: 76-635 -- Loss: 0.11108428239822388
val-epoch-step: 76-636 -- Loss: 0.16797317564487457
val-epoch-step: 76-637 -- Loss: 0.17946794629096985
val-epoch-step: 76-638 -- Loss: 0.14961230754852295
val-epoch-step: 76-639 -- Loss: 0.2614930272102356
val-epoch-step: 76-640 -- Loss: 0.2645343840122223
val-epoch-step: 76-641 -- Loss: 0.13153810799121857
val-epoch-step: 76-642 -- Loss: 0.1839381754398346
val-epoch-step: 76-643 -- Loss: 0.2072601467370987
val-epoch-step: 76-644 -- Loss: 0.16998176276683807
val-epoch-step: 76-645 -- Loss: 0.2167280614376068
val-epoch-step: 76-646 -- Loss: 0.13254237174987793
val-epoch-step: 76-647 -- Loss: 0.1272113174200058
val-epoch-step: 76-648 -- Loss: 0.1532374918460846
val-epoch-step: 76-649 -- Loss: 0.2006312906742096
val-epoch-step: 76-650 -- Loss: 0.24922767281532288
val-epoch-step: 76-651 -- Loss: 0.14391160011291504
val-epoch-step: 76-652 -- Loss: 0.1697901487350464
val-epoch-step: 76-653 -- Loss: 0.20386859774589539
val-epoch-step: 76-654 -- Loss: 0.10864202678203583
Epoch: 76 -- Train Loss: tensor(0.1437, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 77-0 -- Loss: 0.22031381726264954
train-epoch-step: 77-1 -- Loss: 0.151076540350914
train-epoch-step: 77-2 -- Loss: 0.20344030857086182
train-epoch-step: 77-3 -- Loss: 0.14844702184200287
train-epoch-step: 77-4 -- Loss: 0.15948809683322906
train-epoch-step: 77-5 -- Loss: 0.19023746252059937
train-epoch-step: 77-6 -- Loss: 0.22753557562828064
train-epoch-step: 77-7 -- Loss: 0.16478611528873444
train-epoch-step: 77-8 -- Loss: 0.18318474292755127
train-epoch-step: 77-9 -- Loss: 0.23305124044418335
train-epoch-step: 77-10 -- Loss: 0.2406332641839981
train-epoch-step: 77-11 -- Loss: 0.1850808709859848
train-epoch-step: 77-12 -- Loss: 0.1506064385175705
train-epoch-step: 77-13 -- Loss: 0.1838197112083435
train-epoch-step: 77-14 -- Loss: 0.16336959600448608
train-epoch-step: 77-15 -- Loss: 0.17332997918128967
train-epoch-step: 77-16 -- Loss: 0.16157126426696777
train-epoch-step: 77-17 -- Loss: 0.23172986507415771
train-epoch-step: 77-18 -- Loss: 0.19930613040924072
train-epoch-step: 77-19 -- Loss: 0.13263006508350372
train-epoch-step: 77-20 -- Loss: 0.22720281779766083
train-epoch-step: 77-21 -- Loss: 0.2693435549736023
train-epoch-step: 77-22 -- Loss: 0.15212364494800568
train-epoch-step: 77-23 -- Loss: 0.1416565626859665
train-epoch-step: 77-24 -- Loss: 0.12917494773864746
train-epoch-step: 77-25 -- Loss: 0.2247299700975418
train-epoch-step: 77-26 -- Loss: 0.1900099664926529
train-epoch-step: 77-27 -- Loss: 0.2437223643064499
train-epoch-step: 77-28 -- Loss: 0.12448697537183762
train-epoch-step: 77-29 -- Loss: 0.24367991089820862
train-epoch-step: 77-30 -- Loss: 0.10962527245283127
train-epoch-step: 77-31 -- Loss: 0.15204232931137085
train-epoch-step: 77-32 -- Loss: 0.1733911633491516
train-epoch-step: 77-33 -- Loss: 0.27159056067466736
train-epoch-step: 77-34 -- Loss: 0.16813069581985474
train-epoch-step: 77-35 -- Loss: 0.2539675235748291
train-epoch-step: 77-36 -- Loss: 0.13524000346660614
train-epoch-step: 77-37 -- Loss: 0.14081290364265442
train-epoch-step: 77-38 -- Loss: 0.1800244003534317
train-epoch-step: 77-39 -- Loss: 0.22161385416984558
train-epoch-step: 77-40 -- Loss: 0.200566828250885
train-epoch-step: 77-41 -- Loss: 0.2198227047920227
train-epoch-step: 77-42 -- Loss: 0.1510116457939148
train-epoch-step: 77-43 -- Loss: 0.2586410939693451
train-epoch-step: 77-44 -- Loss: 0.1303955763578415
train-epoch-step: 77-45 -- Loss: 0.11892211437225342
train-epoch-step: 77-46 -- Loss: 0.19721157848834991
train-epoch-step: 77-47 -- Loss: 0.22024685144424438
train-epoch-step: 77-48 -- Loss: 0.15271835029125214
train-epoch-step: 77-49 -- Loss: 0.2253117561340332
train-epoch-step: 77-50 -- Loss: 0.11568304151296616
train-epoch-step: 77-51 -- Loss: 0.18419426679611206
train-epoch-step: 77-52 -- Loss: 0.1549239605665207
train-epoch-step: 77-53 -- Loss: 0.21391671895980835
train-epoch-step: 77-54 -- Loss: 0.2932932674884796
train-epoch-step: 77-55 -- Loss: 0.16896569728851318
train-epoch-step: 77-56 -- Loss: 0.18972449004650116
train-epoch-step: 77-57 -- Loss: 0.2446276843547821
train-epoch-step: 77-58 -- Loss: 0.2834356427192688
train-epoch-step: 77-59 -- Loss: 0.24487338960170746
train-epoch-step: 77-60 -- Loss: 0.12828607857227325
train-epoch-step: 77-61 -- Loss: 0.19578410685062408
train-epoch-step: 77-62 -- Loss: 0.18326179683208466
train-epoch-step: 77-63 -- Loss: 0.15216238796710968
train-epoch-step: 77-64 -- Loss: 0.14601817727088928
train-epoch-step: 77-65 -- Loss: 0.17862188816070557
train-epoch-step: 77-66 -- Loss: 0.1110672652721405
train-epoch-step: 77-67 -- Loss: 0.12599562108516693
train-epoch-step: 77-68 -- Loss: 0.23907750844955444
train-epoch-step: 77-69 -- Loss: 0.12378432601690292
train-epoch-step: 77-70 -- Loss: 0.23466098308563232
train-epoch-step: 77-71 -- Loss: 0.2587270736694336
train-epoch-step: 77-72 -- Loss: 0.1742708832025528
train-epoch-step: 77-73 -- Loss: 0.2054257094860077
train-epoch-step: 77-74 -- Loss: 0.09631481766700745
train-epoch-step: 77-75 -- Loss: 0.13311322033405304
train-epoch-step: 77-76 -- Loss: 0.15118443965911865
train-epoch-step: 77-77 -- Loss: 0.2280220240354538
train-epoch-step: 77-78 -- Loss: 0.3195149898529053
train-epoch-step: 77-79 -- Loss: 0.19604331254959106
train-epoch-step: 77-80 -- Loss: 0.2608860433101654
train-epoch-step: 77-81 -- Loss: 0.17045274376869202
train-epoch-step: 77-82 -- Loss: 0.2599697411060333
train-epoch-step: 77-83 -- Loss: 0.1777709275484085
train-epoch-step: 77-84 -- Loss: 0.18398982286453247
train-epoch-step: 77-85 -- Loss: 0.18147620558738708
train-epoch-step: 77-86 -- Loss: 0.12001898884773254
train-epoch-step: 77-87 -- Loss: 0.22346721589565277
train-epoch-step: 77-88 -- Loss: 0.138665571808815
train-epoch-step: 77-89 -- Loss: 0.18538782000541687
train-epoch-step: 77-90 -- Loss: 0.1935884803533554
train-epoch-step: 77-91 -- Loss: 0.2503124475479126
train-epoch-step: 77-92 -- Loss: 0.15488266944885254
train-epoch-step: 77-93 -- Loss: 0.1914629191160202
train-epoch-step: 77-94 -- Loss: 0.24174214899539948
train-epoch-step: 77-95 -- Loss: 0.19987799227237701
train-epoch-step: 77-96 -- Loss: 0.2787664532661438
train-epoch-step: 77-97 -- Loss: 0.19662445783615112
train-epoch-step: 77-98 -- Loss: 0.1602211594581604
train-epoch-step: 77-99 -- Loss: 0.19256660342216492
train-epoch-step: 77-100 -- Loss: 0.21318219602108002
train-epoch-step: 77-101 -- Loss: 0.3449874222278595
train-epoch-step: 77-102 -- Loss: 0.3094705045223236
train-epoch-step: 77-103 -- Loss: 0.20419436693191528
train-epoch-step: 77-104 -- Loss: 0.1660163849592209
train-epoch-step: 77-105 -- Loss: 0.36274129152297974
train-epoch-step: 77-106 -- Loss: 0.21295207738876343
train-epoch-step: 77-107 -- Loss: 0.21706531941890717
train-epoch-step: 77-108 -- Loss: 0.22741442918777466
train-epoch-step: 77-109 -- Loss: 0.1620667576789856
train-epoch-step: 77-110 -- Loss: 0.20800766348838806
train-epoch-step: 77-111 -- Loss: 0.21567770838737488
train-epoch-step: 77-112 -- Loss: 0.24708479642868042
train-epoch-step: 77-113 -- Loss: 0.18375393748283386
train-epoch-step: 77-114 -- Loss: 0.20815768837928772
train-epoch-step: 77-115 -- Loss: 0.21336646378040314
train-epoch-step: 77-116 -- Loss: 0.15865692496299744
train-epoch-step: 77-117 -- Loss: 0.13908040523529053
train-epoch-step: 77-118 -- Loss: 0.2500985264778137
train-epoch-step: 77-119 -- Loss: 0.17432940006256104
train-epoch-step: 77-120 -- Loss: 0.33791446685791016
train-epoch-step: 77-121 -- Loss: 0.31493037939071655
train-epoch-step: 77-122 -- Loss: 0.2721717655658722
train-epoch-step: 77-123 -- Loss: 0.21779757738113403
train-epoch-step: 77-124 -- Loss: 0.13172470033168793
train-epoch-step: 77-125 -- Loss: 0.16104964911937714
train-epoch-step: 77-126 -- Loss: 0.2551407814025879
train-epoch-step: 77-127 -- Loss: 0.1980399787425995
train-epoch-step: 77-128 -- Loss: 0.17690323293209076
train-epoch-step: 77-129 -- Loss: 0.1501367688179016
train-epoch-step: 77-130 -- Loss: 0.24365460872650146
train-epoch-step: 77-131 -- Loss: 0.1446511447429657
train-epoch-step: 77-132 -- Loss: 0.22252590954303741
train-epoch-step: 77-133 -- Loss: 0.13897773623466492
train-epoch-step: 77-134 -- Loss: 0.2455279529094696
train-epoch-step: 77-135 -- Loss: 0.15175923705101013
train-epoch-step: 77-136 -- Loss: 0.14405205845832825
train-epoch-step: 77-137 -- Loss: 0.27237415313720703
train-epoch-step: 77-138 -- Loss: 0.3424009084701538
train-epoch-step: 77-139 -- Loss: 0.13868507742881775
train-epoch-step: 77-140 -- Loss: 0.2573055326938629
train-epoch-step: 77-141 -- Loss: 0.2975560426712036
train-epoch-step: 77-142 -- Loss: 0.22432777285575867
train-epoch-step: 77-143 -- Loss: 0.19836166501045227
train-epoch-step: 77-144 -- Loss: 0.2121427208185196
train-epoch-step: 77-145 -- Loss: 0.16340991854667664
train-epoch-step: 77-146 -- Loss: 0.1937781125307083
train-epoch-step: 77-147 -- Loss: 0.18823015689849854
train-epoch-step: 77-148 -- Loss: 0.17520645260810852
train-epoch-step: 77-149 -- Loss: 0.1299113631248474
train-epoch-step: 77-150 -- Loss: 0.22001904249191284
train-epoch-step: 77-151 -- Loss: 0.21277961134910583
train-epoch-step: 77-152 -- Loss: 0.21119990944862366
train-epoch-step: 77-153 -- Loss: 0.2845994830131531
train-epoch-step: 77-154 -- Loss: 0.1527009904384613
train-epoch-step: 77-155 -- Loss: 0.1596803367137909
train-epoch-step: 77-156 -- Loss: 0.13865800201892853
train-epoch-step: 77-157 -- Loss: 0.19298478960990906
train-epoch-step: 77-158 -- Loss: 0.1778351068496704
train-epoch-step: 77-159 -- Loss: 0.1863223910331726
train-epoch-step: 77-160 -- Loss: 0.247990682721138
train-epoch-step: 77-161 -- Loss: 0.21896059811115265
train-epoch-step: 77-162 -- Loss: 0.2105836570262909
train-epoch-step: 77-163 -- Loss: 0.18930423259735107
train-epoch-step: 77-164 -- Loss: 0.198974609375
train-epoch-step: 77-165 -- Loss: 0.1696970909833908
train-epoch-step: 77-166 -- Loss: 0.1296370029449463
train-epoch-step: 77-167 -- Loss: 0.12448486685752869
train-epoch-step: 77-168 -- Loss: 0.21327292919158936
train-epoch-step: 77-169 -- Loss: 0.14489856362342834
train-epoch-step: 77-170 -- Loss: 0.20552900433540344
train-epoch-step: 77-171 -- Loss: 0.14887508749961853
train-epoch-step: 77-172 -- Loss: 0.25975874066352844
train-epoch-step: 77-173 -- Loss: 0.13570278882980347
train-epoch-step: 77-174 -- Loss: 0.25724855065345764
train-epoch-step: 77-175 -- Loss: 0.1973046064376831
train-epoch-step: 77-176 -- Loss: 0.1356649100780487
train-epoch-step: 77-177 -- Loss: 0.20170295238494873
train-epoch-step: 77-178 -- Loss: 0.18508967757225037
train-epoch-step: 77-179 -- Loss: 0.14740784466266632
train-epoch-step: 77-180 -- Loss: 0.15646164119243622
train-epoch-step: 77-181 -- Loss: 0.17061857879161835
train-epoch-step: 77-182 -- Loss: 0.18924596905708313
train-epoch-step: 77-183 -- Loss: 0.2829219400882721
train-epoch-step: 77-184 -- Loss: 0.14225681126117706
train-epoch-step: 77-185 -- Loss: 0.1475716531276703
train-epoch-step: 77-186 -- Loss: 0.1946205049753189
train-epoch-step: 77-187 -- Loss: 0.2078443020582199
train-epoch-step: 77-188 -- Loss: 0.1808454692363739
train-epoch-step: 77-189 -- Loss: 0.10615625977516174
train-epoch-step: 77-190 -- Loss: 0.18826137483119965
train-epoch-step: 77-191 -- Loss: 0.16517877578735352
train-epoch-step: 77-192 -- Loss: 0.23078042268753052
train-epoch-step: 77-193 -- Loss: 0.21117788553237915
train-epoch-step: 77-194 -- Loss: 0.18133658170700073
train-epoch-step: 77-195 -- Loss: 0.16832636296749115
train-epoch-step: 77-196 -- Loss: 0.17849420011043549
train-epoch-step: 77-197 -- Loss: 0.13502417504787445
train-epoch-step: 77-198 -- Loss: 0.1310095191001892
train-epoch-step: 77-199 -- Loss: 0.14994248747825623
train-epoch-step: 77-200 -- Loss: 0.12463495880365372
train-epoch-step: 77-201 -- Loss: 0.19123415648937225
train-epoch-step: 77-202 -- Loss: 0.13632388412952423
train-epoch-step: 77-203 -- Loss: 0.19000999629497528
train-epoch-step: 77-204 -- Loss: 0.13581998646259308
train-epoch-step: 77-205 -- Loss: 0.19373677670955658
train-epoch-step: 77-206 -- Loss: 0.1998322755098343
train-epoch-step: 77-207 -- Loss: 0.1406191885471344
train-epoch-step: 77-208 -- Loss: 0.18509995937347412
train-epoch-step: 77-209 -- Loss: 0.14450107514858246
train-epoch-step: 77-210 -- Loss: 0.13591496646404266
train-epoch-step: 77-211 -- Loss: 0.2357858419418335
train-epoch-step: 77-212 -- Loss: 0.20295308530330658
train-epoch-step: 77-213 -- Loss: 0.12604117393493652
train-epoch-step: 77-214 -- Loss: 0.14565040171146393
train-epoch-step: 77-215 -- Loss: 0.12798330187797546
train-epoch-step: 77-216 -- Loss: 0.20019099116325378
train-epoch-step: 77-217 -- Loss: 0.21416187286376953
train-epoch-step: 77-218 -- Loss: 0.15074071288108826
train-epoch-step: 77-219 -- Loss: 0.16968029737472534
train-epoch-step: 77-220 -- Loss: 0.1309884488582611
train-epoch-step: 77-221 -- Loss: 0.21389824151992798
train-epoch-step: 77-222 -- Loss: 0.1151626855134964
train-epoch-step: 77-223 -- Loss: 0.17579802870750427
train-epoch-step: 77-224 -- Loss: 0.19876597821712494
train-epoch-step: 77-225 -- Loss: 0.2804242968559265
train-epoch-step: 77-226 -- Loss: 0.2062252163887024
train-epoch-step: 77-227 -- Loss: 0.2257564663887024
train-epoch-step: 77-228 -- Loss: 0.17406682670116425
train-epoch-step: 77-229 -- Loss: 0.1767771989107132
train-epoch-step: 77-230 -- Loss: 0.1649501472711563
train-epoch-step: 77-231 -- Loss: 0.1594170778989792
train-epoch-step: 77-232 -- Loss: 0.19136394560337067
train-epoch-step: 77-233 -- Loss: 0.08436933904886246
train-epoch-step: 77-234 -- Loss: 0.17372019588947296
train-epoch-step: 77-235 -- Loss: 0.14430075883865356
train-epoch-step: 77-236 -- Loss: 0.18687207996845245
train-epoch-step: 77-237 -- Loss: 0.23413626849651337
train-epoch-step: 77-238 -- Loss: 0.15930189192295074
train-epoch-step: 77-239 -- Loss: 0.1325494349002838
train-epoch-step: 77-240 -- Loss: 0.22501631081104279
train-epoch-step: 77-241 -- Loss: 0.15827146172523499
train-epoch-step: 77-242 -- Loss: 0.22104743123054504
train-epoch-step: 77-243 -- Loss: 0.2358020693063736
train-epoch-step: 77-244 -- Loss: 0.20475144684314728
train-epoch-step: 77-245 -- Loss: 0.22535549104213715
train-epoch-step: 77-246 -- Loss: 0.21998544037342072
train-epoch-step: 77-247 -- Loss: 0.2168571949005127
train-epoch-step: 77-248 -- Loss: 0.18551525473594666
train-epoch-step: 77-249 -- Loss: 0.14691495895385742
train-epoch-step: 77-250 -- Loss: 0.20154231786727905
train-epoch-step: 77-251 -- Loss: 0.11358723044395447
train-epoch-step: 77-252 -- Loss: 0.20148330926895142
train-epoch-step: 77-253 -- Loss: 0.14205753803253174
train-epoch-step: 77-254 -- Loss: 0.21697048842906952
train-epoch-step: 77-255 -- Loss: 0.14380347728729248
train-epoch-step: 77-256 -- Loss: 0.15303032100200653
train-epoch-step: 77-257 -- Loss: 0.19452904164791107
train-epoch-step: 77-258 -- Loss: 0.14670473337173462
train-epoch-step: 77-259 -- Loss: 0.12090316414833069
train-epoch-step: 77-260 -- Loss: 0.205020934343338
train-epoch-step: 77-261 -- Loss: 0.17445296049118042
train-epoch-step: 77-262 -- Loss: 0.3078363537788391
train-epoch-step: 77-263 -- Loss: 0.22437584400177002
train-epoch-step: 77-264 -- Loss: 0.17390736937522888
train-epoch-step: 77-265 -- Loss: 0.12322860956192017
train-epoch-step: 77-266 -- Loss: 0.15319885313510895
train-epoch-step: 77-267 -- Loss: 0.13529916107654572
train-epoch-step: 77-268 -- Loss: 0.12346448004245758
train-epoch-step: 77-269 -- Loss: 0.17051005363464355
train-epoch-step: 77-270 -- Loss: 0.10840556025505066
train-epoch-step: 77-271 -- Loss: 0.15169237554073334
train-epoch-step: 77-272 -- Loss: 0.12231389433145523
train-epoch-step: 77-273 -- Loss: 0.12623760104179382
train-epoch-step: 77-274 -- Loss: 0.1867620050907135
train-epoch-step: 77-275 -- Loss: 0.2147674262523651
train-epoch-step: 77-276 -- Loss: 0.1534913033246994
train-epoch-step: 77-277 -- Loss: 0.15706773102283478
train-epoch-step: 77-278 -- Loss: 0.14476777613162994
train-epoch-step: 77-279 -- Loss: 0.1405007541179657
train-epoch-step: 77-280 -- Loss: 0.2233935445547104
train-epoch-step: 77-281 -- Loss: 0.17899250984191895
train-epoch-step: 77-282 -- Loss: 0.13992449641227722
train-epoch-step: 77-283 -- Loss: 0.11633464694023132
train-epoch-step: 77-284 -- Loss: 0.1582418531179428
train-epoch-step: 77-285 -- Loss: 0.19516481459140778
train-epoch-step: 77-286 -- Loss: 0.15194767713546753
train-epoch-step: 77-287 -- Loss: 0.2100994884967804
train-epoch-step: 77-288 -- Loss: 0.09446867555379868
train-epoch-step: 77-289 -- Loss: 0.1188960075378418
train-epoch-step: 77-290 -- Loss: 0.18027493357658386
train-epoch-step: 77-291 -- Loss: 0.1160389631986618
train-epoch-step: 77-292 -- Loss: 0.15600447356700897
train-epoch-step: 77-293 -- Loss: 0.13781563937664032
train-epoch-step: 77-294 -- Loss: 0.159666046500206
train-epoch-step: 77-295 -- Loss: 0.3053036332130432
train-epoch-step: 77-296 -- Loss: 0.1802147626876831
train-epoch-step: 77-297 -- Loss: 0.1702350676059723
train-epoch-step: 77-298 -- Loss: 0.22735632956027985
train-epoch-step: 77-299 -- Loss: 0.14978349208831787
train-epoch-step: 77-300 -- Loss: 0.1670651137828827
train-epoch-step: 77-301 -- Loss: 0.1773652285337448
train-epoch-step: 77-302 -- Loss: 0.21683429181575775
train-epoch-step: 77-303 -- Loss: 0.208468496799469
train-epoch-step: 77-304 -- Loss: 0.13287390768527985
train-epoch-step: 77-305 -- Loss: 0.14272435009479523
train-epoch-step: 77-306 -- Loss: 0.23596429824829102
train-epoch-step: 77-307 -- Loss: 0.1688045710325241
train-epoch-step: 77-308 -- Loss: 0.2252378612756729
train-epoch-step: 77-309 -- Loss: 0.1545003056526184
train-epoch-step: 77-310 -- Loss: 0.16072562336921692
train-epoch-step: 77-311 -- Loss: 0.16245320439338684
train-epoch-step: 77-312 -- Loss: 0.2054685354232788
train-epoch-step: 77-313 -- Loss: 0.10047311335802078
train-epoch-step: 77-314 -- Loss: 0.19629091024398804
train-epoch-step: 77-315 -- Loss: 0.168790802359581
train-epoch-step: 77-316 -- Loss: 0.14910683035850525
train-epoch-step: 77-317 -- Loss: 0.1425715684890747
train-epoch-step: 77-318 -- Loss: 0.15836171805858612
train-epoch-step: 77-319 -- Loss: 0.17503389716148376
train-epoch-step: 77-320 -- Loss: 0.114061139523983
train-epoch-step: 77-321 -- Loss: 0.13790099322795868
train-epoch-step: 77-322 -- Loss: 0.21812111139297485
train-epoch-step: 77-323 -- Loss: 0.1674952507019043
train-epoch-step: 77-324 -- Loss: 0.2605612277984619
train-epoch-step: 77-325 -- Loss: 0.16039098799228668
train-epoch-step: 77-326 -- Loss: 0.17192821204662323
train-epoch-step: 77-327 -- Loss: 0.20907743275165558
train-epoch-step: 77-328 -- Loss: 0.19387629628181458
train-epoch-step: 77-329 -- Loss: 0.3505643606185913
train-epoch-step: 77-330 -- Loss: 0.3756178617477417
train-epoch-step: 77-331 -- Loss: 0.21580901741981506
train-epoch-step: 77-332 -- Loss: 0.10185979306697845
train-epoch-step: 77-333 -- Loss: 0.18709734082221985
train-epoch-step: 77-334 -- Loss: 0.1542588770389557
train-epoch-step: 77-335 -- Loss: 0.17331251502037048
train-epoch-step: 77-336 -- Loss: 0.1486961543560028
train-epoch-step: 77-337 -- Loss: 0.20017850399017334
train-epoch-step: 77-338 -- Loss: 0.1639910489320755
train-epoch-step: 77-339 -- Loss: 0.1412031352519989
train-epoch-step: 77-340 -- Loss: 0.19757220149040222
train-epoch-step: 77-341 -- Loss: 0.1385282278060913
train-epoch-step: 77-342 -- Loss: 0.16516411304473877
train-epoch-step: 77-343 -- Loss: 0.1506771594285965
train-epoch-step: 77-344 -- Loss: 0.1688438057899475
train-epoch-step: 77-345 -- Loss: 0.1405143439769745
train-epoch-step: 77-346 -- Loss: 0.21069073677062988
train-epoch-step: 77-347 -- Loss: 0.15838341414928436
train-epoch-step: 77-348 -- Loss: 0.20693783462047577
train-epoch-step: 77-349 -- Loss: 0.20726871490478516
train-epoch-step: 77-350 -- Loss: 0.29125404357910156
train-epoch-step: 77-351 -- Loss: 0.19804933667182922
train-epoch-step: 77-352 -- Loss: 0.12942811846733093
train-epoch-step: 77-353 -- Loss: 0.19489188492298126
train-epoch-step: 77-354 -- Loss: 0.2829464077949524
train-epoch-step: 77-355 -- Loss: 0.11961213499307632
train-epoch-step: 77-356 -- Loss: 0.11884279549121857
train-epoch-step: 77-357 -- Loss: 0.19338777661323547
train-epoch-step: 77-358 -- Loss: 0.18431225419044495
train-epoch-step: 77-359 -- Loss: 0.14197924733161926
train-epoch-step: 77-360 -- Loss: 0.12339537590742111
train-epoch-step: 77-361 -- Loss: 0.2565932869911194
train-epoch-step: 77-362 -- Loss: 0.16987542808055878
train-epoch-step: 77-363 -- Loss: 0.11598426848649979
train-epoch-step: 77-364 -- Loss: 0.17989790439605713
train-epoch-step: 77-365 -- Loss: 0.1787867695093155
train-epoch-step: 77-366 -- Loss: 0.20500114560127258
train-epoch-step: 77-367 -- Loss: 0.23074902594089508
train-epoch-step: 77-368 -- Loss: 0.20561711490154266
train-epoch-step: 77-369 -- Loss: 0.28881698846817017
train-epoch-step: 77-370 -- Loss: 0.12394687533378601
train-epoch-step: 77-371 -- Loss: 0.12300215661525726
train-epoch-step: 77-372 -- Loss: 0.14706148207187653
train-epoch-step: 77-373 -- Loss: 0.18283452093601227
train-epoch-step: 77-374 -- Loss: 0.15764889121055603
train-epoch-step: 77-375 -- Loss: 0.26381683349609375
train-epoch-step: 77-376 -- Loss: 0.1627015471458435
train-epoch-step: 77-377 -- Loss: 0.22899332642555237
train-epoch-step: 77-378 -- Loss: 0.19962836802005768
train-epoch-step: 77-379 -- Loss: 0.12070386856794357
train-epoch-step: 77-380 -- Loss: 0.09231910854578018
train-epoch-step: 77-381 -- Loss: 0.24942922592163086
train-epoch-step: 77-382 -- Loss: 0.23344570398330688
train-epoch-step: 77-383 -- Loss: 0.17935147881507874
train-epoch-step: 77-384 -- Loss: 0.2196352183818817
train-epoch-step: 77-385 -- Loss: 0.18844076991081238
train-epoch-step: 77-386 -- Loss: 0.2005135715007782
train-epoch-step: 77-387 -- Loss: 0.24420210719108582
train-epoch-step: 77-388 -- Loss: 0.19773343205451965
train-epoch-step: 77-389 -- Loss: 0.16544219851493835
train-epoch-step: 77-390 -- Loss: 0.1474335491657257
train-epoch-step: 77-391 -- Loss: 0.15332800149917603
train-epoch-step: 77-392 -- Loss: 0.18813902139663696
train-epoch-step: 77-393 -- Loss: 0.15518057346343994
train-epoch-step: 77-394 -- Loss: 0.19959403574466705
train-epoch-step: 77-395 -- Loss: 0.17570485174655914
train-epoch-step: 77-396 -- Loss: 0.12775330245494843
train-epoch-step: 77-397 -- Loss: 0.124384306371212
train-epoch-step: 77-398 -- Loss: 0.21149803698062897
train-epoch-step: 77-399 -- Loss: 0.1731812059879303
train-epoch-step: 77-400 -- Loss: 0.2829597294330597
train-epoch-step: 77-401 -- Loss: 0.1284724771976471
train-epoch-step: 77-402 -- Loss: 0.2608886659145355
train-epoch-step: 77-403 -- Loss: 0.15994969010353088
train-epoch-step: 77-404 -- Loss: 0.1355864405632019
train-epoch-step: 77-405 -- Loss: 0.14628596603870392
train-epoch-step: 77-406 -- Loss: 0.16573891043663025
train-epoch-step: 77-407 -- Loss: 0.11132828891277313
train-epoch-step: 77-408 -- Loss: 0.16648808121681213
train-epoch-step: 77-409 -- Loss: 0.16974204778671265
train-epoch-step: 77-410 -- Loss: 0.17601987719535828
train-epoch-step: 77-411 -- Loss: 0.1938253939151764
train-epoch-step: 77-412 -- Loss: 0.1309400200843811
train-epoch-step: 77-413 -- Loss: 0.1456969976425171
train-epoch-step: 77-414 -- Loss: 0.13124439120292664
train-epoch-step: 77-415 -- Loss: 0.13489754498004913
train-epoch-step: 77-416 -- Loss: 0.27029240131378174
train-epoch-step: 77-417 -- Loss: 0.19091537594795227
train-epoch-step: 77-418 -- Loss: 0.23308125138282776
train-epoch-step: 77-419 -- Loss: 0.16879183053970337
train-epoch-step: 77-420 -- Loss: 0.1535048484802246
train-epoch-step: 77-421 -- Loss: 0.17647460103034973
train-epoch-step: 77-422 -- Loss: 0.14445646107196808
train-epoch-step: 77-423 -- Loss: 0.18045398592948914
train-epoch-step: 77-424 -- Loss: 0.1417429894208908
train-epoch-step: 77-425 -- Loss: 0.18093740940093994
train-epoch-step: 77-426 -- Loss: 0.16626405715942383
train-epoch-step: 77-427 -- Loss: 0.12596012651920319
train-epoch-step: 77-428 -- Loss: 0.2020476758480072
train-epoch-step: 77-429 -- Loss: 0.1746351569890976
train-epoch-step: 77-430 -- Loss: 0.14144331216812134
train-epoch-step: 77-431 -- Loss: 0.1599368155002594
train-epoch-step: 77-432 -- Loss: 0.2437983602285385
train-epoch-step: 77-433 -- Loss: 0.1344563215970993
train-epoch-step: 77-434 -- Loss: 0.13256719708442688
train-epoch-step: 77-435 -- Loss: 0.1585044115781784
train-epoch-step: 77-436 -- Loss: 0.15560469031333923
train-epoch-step: 77-437 -- Loss: 0.13281406462192535
train-epoch-step: 77-438 -- Loss: 0.16550371050834656
train-epoch-step: 77-439 -- Loss: 0.2598978579044342
train-epoch-step: 77-440 -- Loss: 0.13265728950500488
train-epoch-step: 77-441 -- Loss: 0.20278938114643097
train-epoch-step: 77-442 -- Loss: 0.17339132726192474
train-epoch-step: 77-443 -- Loss: 0.16596853733062744
train-epoch-step: 77-444 -- Loss: 0.1913636028766632
train-epoch-step: 77-445 -- Loss: 0.17679117619991302
train-epoch-step: 77-446 -- Loss: 0.14926886558532715
train-epoch-step: 77-447 -- Loss: 0.1888582706451416
train-epoch-step: 77-448 -- Loss: 0.2282763123512268
train-epoch-step: 77-449 -- Loss: 0.1890365332365036
train-epoch-step: 77-450 -- Loss: 0.17888207733631134
train-epoch-step: 77-451 -- Loss: 0.14692538976669312
train-epoch-step: 77-452 -- Loss: 0.13829217851161957
train-epoch-step: 77-453 -- Loss: 0.09114772081375122
train-epoch-step: 77-454 -- Loss: 0.22989986836910248
train-epoch-step: 77-455 -- Loss: 0.12265674024820328
train-epoch-step: 77-456 -- Loss: 0.1156776174902916
train-epoch-step: 77-457 -- Loss: 0.21065756678581238
train-epoch-step: 77-458 -- Loss: 0.1590195596218109
train-epoch-step: 77-459 -- Loss: 0.2188165932893753
train-epoch-step: 77-460 -- Loss: 0.12913654744625092
train-epoch-step: 77-461 -- Loss: 0.13610199093818665
train-epoch-step: 77-462 -- Loss: 0.15166915953159332
train-epoch-step: 77-463 -- Loss: 0.13506236672401428
train-epoch-step: 77-464 -- Loss: 0.17488539218902588
train-epoch-step: 77-465 -- Loss: 0.23501867055892944
train-epoch-step: 77-466 -- Loss: 0.20853665471076965
train-epoch-step: 77-467 -- Loss: 0.11227300763130188
train-epoch-step: 77-468 -- Loss: 0.1676662117242813
train-epoch-step: 77-469 -- Loss: 0.25658902525901794
train-epoch-step: 77-470 -- Loss: 0.1809171587228775
train-epoch-step: 77-471 -- Loss: 0.15450634062290192
train-epoch-step: 77-472 -- Loss: 0.15985770523548126
train-epoch-step: 77-473 -- Loss: 0.16662299633026123
train-epoch-step: 77-474 -- Loss: 0.12179400026798248
train-epoch-step: 77-475 -- Loss: 0.1168823167681694
train-epoch-step: 77-476 -- Loss: 0.25390946865081787
train-epoch-step: 77-477 -- Loss: 0.2354775071144104
train-epoch-step: 77-478 -- Loss: 0.2100750207901001
train-epoch-step: 77-479 -- Loss: 0.1536683291196823
train-epoch-step: 77-480 -- Loss: 0.21405300498008728
train-epoch-step: 77-481 -- Loss: 0.3370341658592224
train-epoch-step: 77-482 -- Loss: 0.2521239221096039
train-epoch-step: 77-483 -- Loss: 0.2094995677471161
train-epoch-step: 77-484 -- Loss: 0.21834099292755127
train-epoch-step: 77-485 -- Loss: 0.1370122730731964
train-epoch-step: 77-486 -- Loss: 0.23989371955394745
train-epoch-step: 77-487 -- Loss: 0.23489569127559662
train-epoch-step: 77-488 -- Loss: 0.2074669450521469
train-epoch-step: 77-489 -- Loss: 0.228468120098114
train-epoch-step: 77-490 -- Loss: 0.15513262152671814
train-epoch-step: 77-491 -- Loss: 0.13734844326972961
train-epoch-step: 77-492 -- Loss: 0.1367499828338623
train-epoch-step: 77-493 -- Loss: 0.20673063397407532
train-epoch-step: 77-494 -- Loss: 0.22769227623939514
train-epoch-step: 77-495 -- Loss: 0.2127087414264679
train-epoch-step: 77-496 -- Loss: 0.1466217041015625
train-epoch-step: 77-497 -- Loss: 0.2131911814212799
train-epoch-step: 77-498 -- Loss: 0.15357476472854614
train-epoch-step: 77-499 -- Loss: 0.17804419994354248
train-epoch-step: 77-500 -- Loss: 0.16103190183639526
train-epoch-step: 77-501 -- Loss: 0.22850263118743896
train-epoch-step: 77-502 -- Loss: 0.21990109980106354
train-epoch-step: 77-503 -- Loss: 0.22811336815357208
train-epoch-step: 77-504 -- Loss: 0.13128642737865448
train-epoch-step: 77-505 -- Loss: 0.18183045089244843
train-epoch-step: 77-506 -- Loss: 0.12423457205295563
train-epoch-step: 77-507 -- Loss: 0.21759778261184692
train-epoch-step: 77-508 -- Loss: 0.18030434846878052
train-epoch-step: 77-509 -- Loss: 0.1697632521390915
train-epoch-step: 77-510 -- Loss: 0.1287371814250946
train-epoch-step: 77-511 -- Loss: 0.23043575882911682
train-epoch-step: 77-512 -- Loss: 0.1841282695531845
train-epoch-step: 77-513 -- Loss: 0.19844594597816467
train-epoch-step: 77-514 -- Loss: 0.15841200947761536
train-epoch-step: 77-515 -- Loss: 0.15569381415843964
train-epoch-step: 77-516 -- Loss: 0.1810297667980194
train-epoch-step: 77-517 -- Loss: 0.19407469034194946
train-epoch-step: 77-518 -- Loss: 0.14190030097961426
train-epoch-step: 77-519 -- Loss: 0.14233608543872833
train-epoch-step: 77-520 -- Loss: 0.18400748074054718
train-epoch-step: 77-521 -- Loss: 0.23654989898204803
train-epoch-step: 77-522 -- Loss: 0.18708598613739014
train-epoch-step: 77-523 -- Loss: 0.16482603549957275
train-epoch-step: 77-524 -- Loss: 0.1771940141916275
train-epoch-step: 77-525 -- Loss: 0.19040825963020325
train-epoch-step: 77-526 -- Loss: 0.13575685024261475
train-epoch-step: 77-527 -- Loss: 0.15168190002441406
train-epoch-step: 77-528 -- Loss: 0.15469293296337128
train-epoch-step: 77-529 -- Loss: 0.16863006353378296
train-epoch-step: 77-530 -- Loss: 0.17054018378257751
train-epoch-step: 77-531 -- Loss: 0.21090900897979736
train-epoch-step: 77-532 -- Loss: 0.17329762876033783
train-epoch-step: 77-533 -- Loss: 0.17576166987419128
train-epoch-step: 77-534 -- Loss: 0.13770531117916107
train-epoch-step: 77-535 -- Loss: 0.27889519929885864
train-epoch-step: 77-536 -- Loss: 0.16222962737083435
train-epoch-step: 77-537 -- Loss: 0.16166794300079346
train-epoch-step: 77-538 -- Loss: 0.10469500720500946
train-epoch-step: 77-539 -- Loss: 0.2270759642124176
train-epoch-step: 77-540 -- Loss: 0.14083005487918854
train-epoch-step: 77-541 -- Loss: 0.21373644471168518
train-epoch-step: 77-542 -- Loss: 0.23149779438972473
train-epoch-step: 77-543 -- Loss: 0.17540395259857178
train-epoch-step: 77-544 -- Loss: 0.23490853607654572
train-epoch-step: 77-545 -- Loss: 0.19749295711517334
train-epoch-step: 77-546 -- Loss: 0.20974969863891602
train-epoch-step: 77-547 -- Loss: 0.1860564649105072
train-epoch-step: 77-548 -- Loss: 0.09313052892684937
train-epoch-step: 77-549 -- Loss: 0.15336541831493378
train-epoch-step: 77-550 -- Loss: 0.20193588733673096
train-epoch-step: 77-551 -- Loss: 0.15536442399024963
train-epoch-step: 77-552 -- Loss: 0.12975727021694183
train-epoch-step: 77-553 -- Loss: 0.18781113624572754
train-epoch-step: 77-554 -- Loss: 0.18754065036773682
train-epoch-step: 77-555 -- Loss: 0.21469658613204956
train-epoch-step: 77-556 -- Loss: 0.14732500910758972
train-epoch-step: 77-557 -- Loss: 0.24686576426029205
train-epoch-step: 77-558 -- Loss: 0.2899514436721802
train-epoch-step: 77-559 -- Loss: 0.14010488986968994
train-epoch-step: 77-560 -- Loss: 0.20720677077770233
train-epoch-step: 77-561 -- Loss: 0.1898006647825241
train-epoch-step: 77-562 -- Loss: 0.17139241099357605
train-epoch-step: 77-563 -- Loss: 0.18405410647392273
train-epoch-step: 77-564 -- Loss: 0.10273517668247223
train-epoch-step: 77-565 -- Loss: 0.17942355573177338
train-epoch-step: 77-566 -- Loss: 0.15127311646938324
train-epoch-step: 77-567 -- Loss: 0.21442310512065887
train-epoch-step: 77-568 -- Loss: 0.16694433987140656
train-epoch-step: 77-569 -- Loss: 0.24481597542762756
train-epoch-step: 77-570 -- Loss: 0.17851783335208893
train-epoch-step: 77-571 -- Loss: 0.22212788462638855
train-epoch-step: 77-572 -- Loss: 0.2475632280111313
train-epoch-step: 77-573 -- Loss: 0.19980348646640778
train-epoch-step: 77-574 -- Loss: 0.24962735176086426
train-epoch-step: 77-575 -- Loss: 0.30713096261024475
train-epoch-step: 77-576 -- Loss: 0.1220925971865654
train-epoch-step: 77-577 -- Loss: 0.16528156399726868
train-epoch-step: 77-578 -- Loss: 0.21702663600444794
train-epoch-step: 77-579 -- Loss: 0.1652393937110901
train-epoch-step: 77-580 -- Loss: 0.17553013563156128
train-epoch-step: 77-581 -- Loss: 0.13898257911205292
train-epoch-step: 77-582 -- Loss: 0.2060747891664505
train-epoch-step: 77-583 -- Loss: 0.22005102038383484
train-epoch-step: 77-584 -- Loss: 0.16349852085113525
train-epoch-step: 77-585 -- Loss: 0.19192911684513092
train-epoch-step: 77-586 -- Loss: 0.2595612108707428
train-epoch-step: 77-587 -- Loss: 0.15530818700790405
train-epoch-step: 77-588 -- Loss: 0.1262410581111908
val-epoch-step: 77-589 -- Loss: 0.209477499127388
val-epoch-step: 77-590 -- Loss: 0.1525859832763672
val-epoch-step: 77-591 -- Loss: 0.24422813951969147
val-epoch-step: 77-592 -- Loss: 0.17511890828609467
val-epoch-step: 77-593 -- Loss: 0.1565842628479004
val-epoch-step: 77-594 -- Loss: 0.36393478512763977
val-epoch-step: 77-595 -- Loss: 0.17577621340751648
val-epoch-step: 77-596 -- Loss: 0.20522519946098328
val-epoch-step: 77-597 -- Loss: 0.1777985692024231
val-epoch-step: 77-598 -- Loss: 0.15277883410453796
val-epoch-step: 77-599 -- Loss: 0.18722978234291077
val-epoch-step: 77-600 -- Loss: 0.1667238473892212
val-epoch-step: 77-601 -- Loss: 0.1566503643989563
val-epoch-step: 77-602 -- Loss: 0.13502031564712524
val-epoch-step: 77-603 -- Loss: 0.20541010797023773
val-epoch-step: 77-604 -- Loss: 0.14680060744285583
val-epoch-step: 77-605 -- Loss: 0.14688000082969666
val-epoch-step: 77-606 -- Loss: 0.26778626441955566
val-epoch-step: 77-607 -- Loss: 0.13262513279914856
val-epoch-step: 77-608 -- Loss: 0.24723976850509644
val-epoch-step: 77-609 -- Loss: 0.1707824468612671
val-epoch-step: 77-610 -- Loss: 0.17631997168064117
val-epoch-step: 77-611 -- Loss: 0.1536765694618225
val-epoch-step: 77-612 -- Loss: 0.4097104072570801
val-epoch-step: 77-613 -- Loss: 0.18179406225681305
val-epoch-step: 77-614 -- Loss: 0.18664461374282837
val-epoch-step: 77-615 -- Loss: 0.17938774824142456
val-epoch-step: 77-616 -- Loss: 0.14962607622146606
val-epoch-step: 77-617 -- Loss: 0.1874845325946808
val-epoch-step: 77-618 -- Loss: 0.17838677763938904
val-epoch-step: 77-619 -- Loss: 0.20477230846881866
val-epoch-step: 77-620 -- Loss: 0.13531360030174255
val-epoch-step: 77-621 -- Loss: 0.1274787187576294
val-epoch-step: 77-622 -- Loss: 0.14426738023757935
val-epoch-step: 77-623 -- Loss: 0.14989033341407776
val-epoch-step: 77-624 -- Loss: 0.1420765519142151
val-epoch-step: 77-625 -- Loss: 0.16228783130645752
val-epoch-step: 77-626 -- Loss: 0.16675637662410736
val-epoch-step: 77-627 -- Loss: 0.18966427445411682
val-epoch-step: 77-628 -- Loss: 0.4369027614593506
val-epoch-step: 77-629 -- Loss: 0.20713640749454498
val-epoch-step: 77-630 -- Loss: 0.33556458353996277
val-epoch-step: 77-631 -- Loss: 0.14964042603969574
val-epoch-step: 77-632 -- Loss: 0.20088082551956177
val-epoch-step: 77-633 -- Loss: 0.15776300430297852
val-epoch-step: 77-634 -- Loss: 0.14310051500797272
val-epoch-step: 77-635 -- Loss: 0.12341056764125824
val-epoch-step: 77-636 -- Loss: 0.15970641374588013
val-epoch-step: 77-637 -- Loss: 0.18189330399036407
val-epoch-step: 77-638 -- Loss: 0.1443379521369934
val-epoch-step: 77-639 -- Loss: 0.26522570848464966
val-epoch-step: 77-640 -- Loss: 0.2598191499710083
val-epoch-step: 77-641 -- Loss: 0.1253288835287094
val-epoch-step: 77-642 -- Loss: 0.19636285305023193
val-epoch-step: 77-643 -- Loss: 0.20425286889076233
val-epoch-step: 77-644 -- Loss: 0.17687620222568512
val-epoch-step: 77-645 -- Loss: 0.21784399449825287
val-epoch-step: 77-646 -- Loss: 0.1314268708229065
val-epoch-step: 77-647 -- Loss: 0.12516513466835022
val-epoch-step: 77-648 -- Loss: 0.15473699569702148
val-epoch-step: 77-649 -- Loss: 0.2049540877342224
val-epoch-step: 77-650 -- Loss: 0.24948441982269287
val-epoch-step: 77-651 -- Loss: 0.14966824650764465
val-epoch-step: 77-652 -- Loss: 0.1536891609430313
val-epoch-step: 77-653 -- Loss: 0.20491206645965576
val-epoch-step: 77-654 -- Loss: 0.11204399913549423
Epoch: 77 -- Train Loss: tensor(0.1424, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 78-0 -- Loss: 0.22588202357292175
train-epoch-step: 78-1 -- Loss: 0.14737801253795624
train-epoch-step: 78-2 -- Loss: 0.19947341084480286
train-epoch-step: 78-3 -- Loss: 0.15391778945922852
train-epoch-step: 78-4 -- Loss: 0.15968386828899384
train-epoch-step: 78-5 -- Loss: 0.18252944946289062
train-epoch-step: 78-6 -- Loss: 0.22385229170322418
train-epoch-step: 78-7 -- Loss: 0.16456320881843567
train-epoch-step: 78-8 -- Loss: 0.18767304718494415
train-epoch-step: 78-9 -- Loss: 0.2357361912727356
train-epoch-step: 78-10 -- Loss: 0.19795328378677368
train-epoch-step: 78-11 -- Loss: 0.17419670522212982
train-epoch-step: 78-12 -- Loss: 0.1464519053697586
train-epoch-step: 78-13 -- Loss: 0.18119098246097565
train-epoch-step: 78-14 -- Loss: 0.16596338152885437
train-epoch-step: 78-15 -- Loss: 0.16758206486701965
train-epoch-step: 78-16 -- Loss: 0.17127493023872375
train-epoch-step: 78-17 -- Loss: 0.23146302998065948
train-epoch-step: 78-18 -- Loss: 0.1923748403787613
train-epoch-step: 78-19 -- Loss: 0.13793295621871948
train-epoch-step: 78-20 -- Loss: 0.20821158587932587
train-epoch-step: 78-21 -- Loss: 0.25245150923728943
train-epoch-step: 78-22 -- Loss: 0.14169475436210632
train-epoch-step: 78-23 -- Loss: 0.14120809733867645
train-epoch-step: 78-24 -- Loss: 0.12622255086898804
train-epoch-step: 78-25 -- Loss: 0.22960017621517181
train-epoch-step: 78-26 -- Loss: 0.1876351684331894
train-epoch-step: 78-27 -- Loss: 0.2259180098772049
train-epoch-step: 78-28 -- Loss: 0.13067059218883514
train-epoch-step: 78-29 -- Loss: 0.24771608412265778
train-epoch-step: 78-30 -- Loss: 0.1084701269865036
train-epoch-step: 78-31 -- Loss: 0.1325070559978485
train-epoch-step: 78-32 -- Loss: 0.17284661531448364
train-epoch-step: 78-33 -- Loss: 0.27072256803512573
train-epoch-step: 78-34 -- Loss: 0.17873066663742065
train-epoch-step: 78-35 -- Loss: 0.23876796662807465
train-epoch-step: 78-36 -- Loss: 0.142355814576149
train-epoch-step: 78-37 -- Loss: 0.13909697532653809
train-epoch-step: 78-38 -- Loss: 0.1702386438846588
train-epoch-step: 78-39 -- Loss: 0.223383367061615
train-epoch-step: 78-40 -- Loss: 0.18987959623336792
train-epoch-step: 78-41 -- Loss: 0.2114473432302475
train-epoch-step: 78-42 -- Loss: 0.1464279294013977
train-epoch-step: 78-43 -- Loss: 0.26338857412338257
train-epoch-step: 78-44 -- Loss: 0.1346742808818817
train-epoch-step: 78-45 -- Loss: 0.11748574674129486
train-epoch-step: 78-46 -- Loss: 0.17265555262565613
train-epoch-step: 78-47 -- Loss: 0.21254679560661316
train-epoch-step: 78-48 -- Loss: 0.15296325087547302
train-epoch-step: 78-49 -- Loss: 0.22624418139457703
train-epoch-step: 78-50 -- Loss: 0.11913004517555237
train-epoch-step: 78-51 -- Loss: 0.19214066863059998
train-epoch-step: 78-52 -- Loss: 0.15808255970478058
train-epoch-step: 78-53 -- Loss: 0.21071793138980865
train-epoch-step: 78-54 -- Loss: 0.2833310067653656
train-epoch-step: 78-55 -- Loss: 0.17481736838817596
train-epoch-step: 78-56 -- Loss: 0.17690834403038025
train-epoch-step: 78-57 -- Loss: 0.23709580302238464
train-epoch-step: 78-58 -- Loss: 0.2808528542518616
train-epoch-step: 78-59 -- Loss: 0.23549067974090576
train-epoch-step: 78-60 -- Loss: 0.13145461678504944
train-epoch-step: 78-61 -- Loss: 0.1996987760066986
train-epoch-step: 78-62 -- Loss: 0.18177813291549683
train-epoch-step: 78-63 -- Loss: 0.13936331868171692
train-epoch-step: 78-64 -- Loss: 0.14133033156394958
train-epoch-step: 78-65 -- Loss: 0.17984981834888458
train-epoch-step: 78-66 -- Loss: 0.11111361533403397
train-epoch-step: 78-67 -- Loss: 0.12088267505168915
train-epoch-step: 78-68 -- Loss: 0.2176382839679718
train-epoch-step: 78-69 -- Loss: 0.12380850315093994
train-epoch-step: 78-70 -- Loss: 0.23290695250034332
train-epoch-step: 78-71 -- Loss: 0.26334530115127563
train-epoch-step: 78-72 -- Loss: 0.17611004412174225
train-epoch-step: 78-73 -- Loss: 0.19956903159618378
train-epoch-step: 78-74 -- Loss: 0.09362708777189255
train-epoch-step: 78-75 -- Loss: 0.12586727738380432
train-epoch-step: 78-76 -- Loss: 0.15159326791763306
train-epoch-step: 78-77 -- Loss: 0.2278253585100174
train-epoch-step: 78-78 -- Loss: 0.2547767758369446
train-epoch-step: 78-79 -- Loss: 0.18491433560848236
train-epoch-step: 78-80 -- Loss: 0.25440073013305664
train-epoch-step: 78-81 -- Loss: 0.1214386448264122
train-epoch-step: 78-82 -- Loss: 0.24428032338619232
train-epoch-step: 78-83 -- Loss: 0.17411744594573975
train-epoch-step: 78-84 -- Loss: 0.18483781814575195
train-epoch-step: 78-85 -- Loss: 0.1711527407169342
train-epoch-step: 78-86 -- Loss: 0.11815270781517029
train-epoch-step: 78-87 -- Loss: 0.21352910995483398
train-epoch-step: 78-88 -- Loss: 0.13323193788528442
train-epoch-step: 78-89 -- Loss: 0.18136966228485107
train-epoch-step: 78-90 -- Loss: 0.19032549858093262
train-epoch-step: 78-91 -- Loss: 0.23983725905418396
train-epoch-step: 78-92 -- Loss: 0.14981187880039215
train-epoch-step: 78-93 -- Loss: 0.1925174742937088
train-epoch-step: 78-94 -- Loss: 0.2215106189250946
train-epoch-step: 78-95 -- Loss: 0.1842890977859497
train-epoch-step: 78-96 -- Loss: 0.21368414163589478
train-epoch-step: 78-97 -- Loss: 0.17489147186279297
train-epoch-step: 78-98 -- Loss: 0.15097732841968536
train-epoch-step: 78-99 -- Loss: 0.18437334895133972
train-epoch-step: 78-100 -- Loss: 0.18531782925128937
train-epoch-step: 78-101 -- Loss: 0.2625967264175415
train-epoch-step: 78-102 -- Loss: 0.22096867859363556
train-epoch-step: 78-103 -- Loss: 0.18382376432418823
train-epoch-step: 78-104 -- Loss: 0.151457741856575
train-epoch-step: 78-105 -- Loss: 0.2620638906955719
train-epoch-step: 78-106 -- Loss: 0.17748582363128662
train-epoch-step: 78-107 -- Loss: 0.18486523628234863
train-epoch-step: 78-108 -- Loss: 0.19121424853801727
train-epoch-step: 78-109 -- Loss: 0.16347874701023102
train-epoch-step: 78-110 -- Loss: 0.17873837053775787
train-epoch-step: 78-111 -- Loss: 0.17937584221363068
train-epoch-step: 78-112 -- Loss: 0.17987361550331116
train-epoch-step: 78-113 -- Loss: 0.15919768810272217
train-epoch-step: 78-114 -- Loss: 0.19167788326740265
train-epoch-step: 78-115 -- Loss: 0.1598086655139923
train-epoch-step: 78-116 -- Loss: 0.1489609181880951
train-epoch-step: 78-117 -- Loss: 0.13647185266017914
train-epoch-step: 78-118 -- Loss: 0.19495126605033875
train-epoch-step: 78-119 -- Loss: 0.14920690655708313
train-epoch-step: 78-120 -- Loss: 0.25079700350761414
train-epoch-step: 78-121 -- Loss: 0.24721665680408478
train-epoch-step: 78-122 -- Loss: 0.2171122133731842
train-epoch-step: 78-123 -- Loss: 0.204925537109375
train-epoch-step: 78-124 -- Loss: 0.12433560937643051
train-epoch-step: 78-125 -- Loss: 0.1507308930158615
train-epoch-step: 78-126 -- Loss: 0.22289007902145386
train-epoch-step: 78-127 -- Loss: 0.1737181842327118
train-epoch-step: 78-128 -- Loss: 0.16975054144859314
train-epoch-step: 78-129 -- Loss: 0.13955259323120117
train-epoch-step: 78-130 -- Loss: 0.19307076930999756
train-epoch-step: 78-131 -- Loss: 0.133426234126091
train-epoch-step: 78-132 -- Loss: 0.189999520778656
train-epoch-step: 78-133 -- Loss: 0.12082787603139877
train-epoch-step: 78-134 -- Loss: 0.19654379785060883
train-epoch-step: 78-135 -- Loss: 0.1400621235370636
train-epoch-step: 78-136 -- Loss: 0.12604069709777832
train-epoch-step: 78-137 -- Loss: 0.2348587065935135
train-epoch-step: 78-138 -- Loss: 0.25479304790496826
train-epoch-step: 78-139 -- Loss: 0.13036483526229858
train-epoch-step: 78-140 -- Loss: 0.20699721574783325
train-epoch-step: 78-141 -- Loss: 0.2285262942314148
train-epoch-step: 78-142 -- Loss: 0.19807292520999908
train-epoch-step: 78-143 -- Loss: 0.16937033832073212
train-epoch-step: 78-144 -- Loss: 0.18051674962043762
train-epoch-step: 78-145 -- Loss: 0.1416974514722824
train-epoch-step: 78-146 -- Loss: 0.17542380094528198
train-epoch-step: 78-147 -- Loss: 0.17553381621837616
train-epoch-step: 78-148 -- Loss: 0.1578724980354309
train-epoch-step: 78-149 -- Loss: 0.12239187955856323
train-epoch-step: 78-150 -- Loss: 0.17994095385074615
train-epoch-step: 78-151 -- Loss: 0.1869712769985199
train-epoch-step: 78-152 -- Loss: 0.18639974296092987
train-epoch-step: 78-153 -- Loss: 0.2723250985145569
train-epoch-step: 78-154 -- Loss: 0.1277320683002472
train-epoch-step: 78-155 -- Loss: 0.13767632842063904
train-epoch-step: 78-156 -- Loss: 0.11975904554128647
train-epoch-step: 78-157 -- Loss: 0.1601812243461609
train-epoch-step: 78-158 -- Loss: 0.164142906665802
train-epoch-step: 78-159 -- Loss: 0.17509302496910095
train-epoch-step: 78-160 -- Loss: 0.2216717153787613
train-epoch-step: 78-161 -- Loss: 0.20202791690826416
train-epoch-step: 78-162 -- Loss: 0.2090354561805725
train-epoch-step: 78-163 -- Loss: 0.18669472634792328
train-epoch-step: 78-164 -- Loss: 0.18870528042316437
train-epoch-step: 78-165 -- Loss: 0.16185949742794037
train-epoch-step: 78-166 -- Loss: 0.12455527484416962
train-epoch-step: 78-167 -- Loss: 0.12423089891672134
train-epoch-step: 78-168 -- Loss: 0.20095661282539368
train-epoch-step: 78-169 -- Loss: 0.13559967279434204
train-epoch-step: 78-170 -- Loss: 0.19687014818191528
train-epoch-step: 78-171 -- Loss: 0.14150741696357727
train-epoch-step: 78-172 -- Loss: 0.26016855239868164
train-epoch-step: 78-173 -- Loss: 0.12850651144981384
train-epoch-step: 78-174 -- Loss: 0.24890294671058655
train-epoch-step: 78-175 -- Loss: 0.1828884780406952
train-epoch-step: 78-176 -- Loss: 0.1270207166671753
train-epoch-step: 78-177 -- Loss: 0.17760565876960754
train-epoch-step: 78-178 -- Loss: 0.17674481868743896
train-epoch-step: 78-179 -- Loss: 0.16891451179981232
train-epoch-step: 78-180 -- Loss: 0.14892248809337616
train-epoch-step: 78-181 -- Loss: 0.16208431124687195
train-epoch-step: 78-182 -- Loss: 0.17692813277244568
train-epoch-step: 78-183 -- Loss: 0.26333385705947876
train-epoch-step: 78-184 -- Loss: 0.1336023509502411
train-epoch-step: 78-185 -- Loss: 0.1353478729724884
train-epoch-step: 78-186 -- Loss: 0.1891971230506897
train-epoch-step: 78-187 -- Loss: 0.2112456113100052
train-epoch-step: 78-188 -- Loss: 0.1711193174123764
train-epoch-step: 78-189 -- Loss: 0.10806603729724884
train-epoch-step: 78-190 -- Loss: 0.17900696396827698
train-epoch-step: 78-191 -- Loss: 0.1561608910560608
train-epoch-step: 78-192 -- Loss: 0.22680053114891052
train-epoch-step: 78-193 -- Loss: 0.19973905384540558
train-epoch-step: 78-194 -- Loss: 0.18022091686725616
train-epoch-step: 78-195 -- Loss: 0.16514280438423157
train-epoch-step: 78-196 -- Loss: 0.16381558775901794
train-epoch-step: 78-197 -- Loss: 0.11977943778038025
train-epoch-step: 78-198 -- Loss: 0.12463195621967316
train-epoch-step: 78-199 -- Loss: 0.14357630908489227
train-epoch-step: 78-200 -- Loss: 0.12339089810848236
train-epoch-step: 78-201 -- Loss: 0.18930986523628235
train-epoch-step: 78-202 -- Loss: 0.13227087259292603
train-epoch-step: 78-203 -- Loss: 0.17415456473827362
train-epoch-step: 78-204 -- Loss: 0.13791188597679138
train-epoch-step: 78-205 -- Loss: 0.1878736913204193
train-epoch-step: 78-206 -- Loss: 0.19582776725292206
train-epoch-step: 78-207 -- Loss: 0.13103200495243073
train-epoch-step: 78-208 -- Loss: 0.1809379756450653
train-epoch-step: 78-209 -- Loss: 0.14660653471946716
train-epoch-step: 78-210 -- Loss: 0.13188131153583527
train-epoch-step: 78-211 -- Loss: 0.20769745111465454
train-epoch-step: 78-212 -- Loss: 0.19269227981567383
train-epoch-step: 78-213 -- Loss: 0.12436065822839737
train-epoch-step: 78-214 -- Loss: 0.14734509587287903
train-epoch-step: 78-215 -- Loss: 0.1274486482143402
train-epoch-step: 78-216 -- Loss: 0.1936531364917755
train-epoch-step: 78-217 -- Loss: 0.20842254161834717
train-epoch-step: 78-218 -- Loss: 0.1423005908727646
train-epoch-step: 78-219 -- Loss: 0.1684822142124176
train-epoch-step: 78-220 -- Loss: 0.12544453144073486
train-epoch-step: 78-221 -- Loss: 0.20581716299057007
train-epoch-step: 78-222 -- Loss: 0.11565853655338287
train-epoch-step: 78-223 -- Loss: 0.1747441291809082
train-epoch-step: 78-224 -- Loss: 0.18434777855873108
train-epoch-step: 78-225 -- Loss: 0.2633853852748871
train-epoch-step: 78-226 -- Loss: 0.20835328102111816
train-epoch-step: 78-227 -- Loss: 0.21632929146289825
train-epoch-step: 78-228 -- Loss: 0.17199130356311798
train-epoch-step: 78-229 -- Loss: 0.1707451343536377
train-epoch-step: 78-230 -- Loss: 0.15992963314056396
train-epoch-step: 78-231 -- Loss: 0.15498226881027222
train-epoch-step: 78-232 -- Loss: 0.18355804681777954
train-epoch-step: 78-233 -- Loss: 0.08299621939659119
train-epoch-step: 78-234 -- Loss: 0.1691368818283081
train-epoch-step: 78-235 -- Loss: 0.14340345561504364
train-epoch-step: 78-236 -- Loss: 0.17623476684093475
train-epoch-step: 78-237 -- Loss: 0.23154696822166443
train-epoch-step: 78-238 -- Loss: 0.14973977208137512
train-epoch-step: 78-239 -- Loss: 0.13400545716285706
train-epoch-step: 78-240 -- Loss: 0.22367241978645325
train-epoch-step: 78-241 -- Loss: 0.14977113902568817
train-epoch-step: 78-242 -- Loss: 0.2161579132080078
train-epoch-step: 78-243 -- Loss: 0.23523619771003723
train-epoch-step: 78-244 -- Loss: 0.2030249387025833
train-epoch-step: 78-245 -- Loss: 0.2055140733718872
train-epoch-step: 78-246 -- Loss: 0.21480296552181244
train-epoch-step: 78-247 -- Loss: 0.20817478001117706
train-epoch-step: 78-248 -- Loss: 0.17868968844413757
train-epoch-step: 78-249 -- Loss: 0.1389153003692627
train-epoch-step: 78-250 -- Loss: 0.1933998167514801
train-epoch-step: 78-251 -- Loss: 0.1085098460316658
train-epoch-step: 78-252 -- Loss: 0.18982374668121338
train-epoch-step: 78-253 -- Loss: 0.133773535490036
train-epoch-step: 78-254 -- Loss: 0.21534579992294312
train-epoch-step: 78-255 -- Loss: 0.14765675365924835
train-epoch-step: 78-256 -- Loss: 0.14849244058132172
train-epoch-step: 78-257 -- Loss: 0.18401508033275604
train-epoch-step: 78-258 -- Loss: 0.14452999830245972
train-epoch-step: 78-259 -- Loss: 0.11038699001073837
train-epoch-step: 78-260 -- Loss: 0.1956961452960968
train-epoch-step: 78-261 -- Loss: 0.17354710400104523
train-epoch-step: 78-262 -- Loss: 0.30687910318374634
train-epoch-step: 78-263 -- Loss: 0.20410533249378204
train-epoch-step: 78-264 -- Loss: 0.17824172973632812
train-epoch-step: 78-265 -- Loss: 0.11202051490545273
train-epoch-step: 78-266 -- Loss: 0.15311536192893982
train-epoch-step: 78-267 -- Loss: 0.13783957064151764
train-epoch-step: 78-268 -- Loss: 0.11901645362377167
train-epoch-step: 78-269 -- Loss: 0.16814453899860382
train-epoch-step: 78-270 -- Loss: 0.10411076247692108
train-epoch-step: 78-271 -- Loss: 0.14443285763263702
train-epoch-step: 78-272 -- Loss: 0.1139916181564331
train-epoch-step: 78-273 -- Loss: 0.1334485411643982
train-epoch-step: 78-274 -- Loss: 0.18708613514900208
train-epoch-step: 78-275 -- Loss: 0.1978297084569931
train-epoch-step: 78-276 -- Loss: 0.15096811950206757
train-epoch-step: 78-277 -- Loss: 0.15446725487709045
train-epoch-step: 78-278 -- Loss: 0.14781314134597778
train-epoch-step: 78-279 -- Loss: 0.1423385739326477
train-epoch-step: 78-280 -- Loss: 0.21284502744674683
train-epoch-step: 78-281 -- Loss: 0.17461377382278442
train-epoch-step: 78-282 -- Loss: 0.13950347900390625
train-epoch-step: 78-283 -- Loss: 0.1147828996181488
train-epoch-step: 78-284 -- Loss: 0.23949307203292847
train-epoch-step: 78-285 -- Loss: 0.1914099007844925
train-epoch-step: 78-286 -- Loss: 0.15276676416397095
train-epoch-step: 78-287 -- Loss: 0.20287609100341797
train-epoch-step: 78-288 -- Loss: 0.09852729737758636
train-epoch-step: 78-289 -- Loss: 0.12847286462783813
train-epoch-step: 78-290 -- Loss: 0.1870999038219452
train-epoch-step: 78-291 -- Loss: 0.11910188943147659
train-epoch-step: 78-292 -- Loss: 0.19400086998939514
train-epoch-step: 78-293 -- Loss: 0.14773553609848022
train-epoch-step: 78-294 -- Loss: 0.17262238264083862
train-epoch-step: 78-295 -- Loss: 0.34451064467430115
train-epoch-step: 78-296 -- Loss: 0.20942068099975586
train-epoch-step: 78-297 -- Loss: 0.17678382992744446
train-epoch-step: 78-298 -- Loss: 0.2298603653907776
train-epoch-step: 78-299 -- Loss: 0.1768515408039093
train-epoch-step: 78-300 -- Loss: 0.17354348301887512
train-epoch-step: 78-301 -- Loss: 0.201266810297966
train-epoch-step: 78-302 -- Loss: 0.23515412211418152
train-epoch-step: 78-303 -- Loss: 0.21320810914039612
train-epoch-step: 78-304 -- Loss: 0.20190945267677307
train-epoch-step: 78-305 -- Loss: 0.15531642735004425
train-epoch-step: 78-306 -- Loss: 0.2488824725151062
train-epoch-step: 78-307 -- Loss: 0.18868955969810486
train-epoch-step: 78-308 -- Loss: 0.24519771337509155
train-epoch-step: 78-309 -- Loss: 0.1654149293899536
train-epoch-step: 78-310 -- Loss: 0.17101213335990906
train-epoch-step: 78-311 -- Loss: 0.18414287269115448
train-epoch-step: 78-312 -- Loss: 0.32035213708877563
train-epoch-step: 78-313 -- Loss: 0.103129081428051
train-epoch-step: 78-314 -- Loss: 0.21862749755382538
train-epoch-step: 78-315 -- Loss: 0.18696510791778564
train-epoch-step: 78-316 -- Loss: 0.15591125190258026
train-epoch-step: 78-317 -- Loss: 0.16752232611179352
train-epoch-step: 78-318 -- Loss: 0.20434696972370148
train-epoch-step: 78-319 -- Loss: 0.2026696503162384
train-epoch-step: 78-320 -- Loss: 0.1216772273182869
train-epoch-step: 78-321 -- Loss: 0.15758506953716278
train-epoch-step: 78-322 -- Loss: 0.24252299964427948
train-epoch-step: 78-323 -- Loss: 0.17108625173568726
train-epoch-step: 78-324 -- Loss: 0.2664054334163666
train-epoch-step: 78-325 -- Loss: 0.16420787572860718
train-epoch-step: 78-326 -- Loss: 0.19660885632038116
train-epoch-step: 78-327 -- Loss: 0.2189650684595108
train-epoch-step: 78-328 -- Loss: 0.2216874659061432
train-epoch-step: 78-329 -- Loss: 0.42431315779685974
train-epoch-step: 78-330 -- Loss: 0.4237636625766754
train-epoch-step: 78-331 -- Loss: 0.25874269008636475
train-epoch-step: 78-332 -- Loss: 0.1068689227104187
train-epoch-step: 78-333 -- Loss: 0.19322186708450317
train-epoch-step: 78-334 -- Loss: 0.17224887013435364
train-epoch-step: 78-335 -- Loss: 0.17811255156993866
train-epoch-step: 78-336 -- Loss: 0.1911235749721527
train-epoch-step: 78-337 -- Loss: 0.2224062979221344
train-epoch-step: 78-338 -- Loss: 0.1713590919971466
train-epoch-step: 78-339 -- Loss: 0.15432099997997284
train-epoch-step: 78-340 -- Loss: 0.20228096842765808
train-epoch-step: 78-341 -- Loss: 0.14226172864437103
train-epoch-step: 78-342 -- Loss: 0.17389538884162903
train-epoch-step: 78-343 -- Loss: 0.16616521775722504
train-epoch-step: 78-344 -- Loss: 0.1725258231163025
train-epoch-step: 78-345 -- Loss: 0.1344221830368042
train-epoch-step: 78-346 -- Loss: 0.20763061940670013
train-epoch-step: 78-347 -- Loss: 0.1556863933801651
train-epoch-step: 78-348 -- Loss: 0.21462641656398773
train-epoch-step: 78-349 -- Loss: 0.2382013201713562
train-epoch-step: 78-350 -- Loss: 0.2795664668083191
train-epoch-step: 78-351 -- Loss: 0.21626579761505127
train-epoch-step: 78-352 -- Loss: 0.1381675899028778
train-epoch-step: 78-353 -- Loss: 0.2010771632194519
train-epoch-step: 78-354 -- Loss: 0.27942541241645813
train-epoch-step: 78-355 -- Loss: 0.12253040075302124
train-epoch-step: 78-356 -- Loss: 0.12081556767225266
train-epoch-step: 78-357 -- Loss: 0.1914224773645401
train-epoch-step: 78-358 -- Loss: 0.19138747453689575
train-epoch-step: 78-359 -- Loss: 0.13800135254859924
train-epoch-step: 78-360 -- Loss: 0.12206307798624039
train-epoch-step: 78-361 -- Loss: 0.24266839027404785
train-epoch-step: 78-362 -- Loss: 0.17144522070884705
train-epoch-step: 78-363 -- Loss: 0.12445276230573654
train-epoch-step: 78-364 -- Loss: 0.17761193215847015
train-epoch-step: 78-365 -- Loss: 0.18573054671287537
train-epoch-step: 78-366 -- Loss: 0.21175768971443176
train-epoch-step: 78-367 -- Loss: 0.23903080821037292
train-epoch-step: 78-368 -- Loss: 0.20047956705093384
train-epoch-step: 78-369 -- Loss: 0.2777314782142639
train-epoch-step: 78-370 -- Loss: 0.12753669917583466
train-epoch-step: 78-371 -- Loss: 0.12215949594974518
train-epoch-step: 78-372 -- Loss: 0.1500374972820282
train-epoch-step: 78-373 -- Loss: 0.19327279925346375
train-epoch-step: 78-374 -- Loss: 0.157635897397995
train-epoch-step: 78-375 -- Loss: 0.2654819190502167
train-epoch-step: 78-376 -- Loss: 0.18483561277389526
train-epoch-step: 78-377 -- Loss: 0.23683485388755798
train-epoch-step: 78-378 -- Loss: 0.19980207085609436
train-epoch-step: 78-379 -- Loss: 0.117760568857193
train-epoch-step: 78-380 -- Loss: 0.09145857393741608
train-epoch-step: 78-381 -- Loss: 0.24522611498832703
train-epoch-step: 78-382 -- Loss: 0.24633854627609253
train-epoch-step: 78-383 -- Loss: 0.18140017986297607
train-epoch-step: 78-384 -- Loss: 0.22149203717708588
train-epoch-step: 78-385 -- Loss: 0.1943117082118988
train-epoch-step: 78-386 -- Loss: 0.19999957084655762
train-epoch-step: 78-387 -- Loss: 0.21657900512218475
train-epoch-step: 78-388 -- Loss: 0.20392291247844696
train-epoch-step: 78-389 -- Loss: 0.16695618629455566
train-epoch-step: 78-390 -- Loss: 0.14084061980247498
train-epoch-step: 78-391 -- Loss: 0.14921312034130096
train-epoch-step: 78-392 -- Loss: 0.19171142578125
train-epoch-step: 78-393 -- Loss: 0.15279369056224823
train-epoch-step: 78-394 -- Loss: 0.19661305844783783
train-epoch-step: 78-395 -- Loss: 0.16172254085540771
train-epoch-step: 78-396 -- Loss: 0.12377159297466278
train-epoch-step: 78-397 -- Loss: 0.12455511838197708
train-epoch-step: 78-398 -- Loss: 0.2014596164226532
train-epoch-step: 78-399 -- Loss: 0.17434753477573395
train-epoch-step: 78-400 -- Loss: 0.27552831172943115
train-epoch-step: 78-401 -- Loss: 0.12705349922180176
train-epoch-step: 78-402 -- Loss: 0.2757132649421692
train-epoch-step: 78-403 -- Loss: 0.15574617683887482
train-epoch-step: 78-404 -- Loss: 0.13702362775802612
train-epoch-step: 78-405 -- Loss: 0.14410407841205597
train-epoch-step: 78-406 -- Loss: 0.17931011319160461
train-epoch-step: 78-407 -- Loss: 0.11158087849617004
train-epoch-step: 78-408 -- Loss: 0.1652105152606964
train-epoch-step: 78-409 -- Loss: 0.1705264002084732
train-epoch-step: 78-410 -- Loss: 0.17766448855400085
train-epoch-step: 78-411 -- Loss: 0.20583896338939667
train-epoch-step: 78-412 -- Loss: 0.1287699043750763
train-epoch-step: 78-413 -- Loss: 0.14372995495796204
train-epoch-step: 78-414 -- Loss: 0.1314929723739624
train-epoch-step: 78-415 -- Loss: 0.13462142646312714
train-epoch-step: 78-416 -- Loss: 0.26382726430892944
train-epoch-step: 78-417 -- Loss: 0.18772637844085693
train-epoch-step: 78-418 -- Loss: 0.22873583436012268
train-epoch-step: 78-419 -- Loss: 0.19501656293869019
train-epoch-step: 78-420 -- Loss: 0.1538352519273758
train-epoch-step: 78-421 -- Loss: 0.18232449889183044
train-epoch-step: 78-422 -- Loss: 0.15206727385520935
train-epoch-step: 78-423 -- Loss: 0.1769009679555893
train-epoch-step: 78-424 -- Loss: 0.1373962014913559
train-epoch-step: 78-425 -- Loss: 0.18260371685028076
train-epoch-step: 78-426 -- Loss: 0.16299031674861908
train-epoch-step: 78-427 -- Loss: 0.11882032454013824
train-epoch-step: 78-428 -- Loss: 0.18463660776615143
train-epoch-step: 78-429 -- Loss: 0.1755889654159546
train-epoch-step: 78-430 -- Loss: 0.14209936559200287
train-epoch-step: 78-431 -- Loss: 0.1585986465215683
train-epoch-step: 78-432 -- Loss: 0.23875942826271057
train-epoch-step: 78-433 -- Loss: 0.13671499490737915
train-epoch-step: 78-434 -- Loss: 0.13330507278442383
train-epoch-step: 78-435 -- Loss: 0.15906471014022827
train-epoch-step: 78-436 -- Loss: 0.1585412323474884
train-epoch-step: 78-437 -- Loss: 0.12953506410121918
train-epoch-step: 78-438 -- Loss: 0.16809284687042236
train-epoch-step: 78-439 -- Loss: 0.2585238516330719
train-epoch-step: 78-440 -- Loss: 0.1315019428730011
train-epoch-step: 78-441 -- Loss: 0.2095772922039032
train-epoch-step: 78-442 -- Loss: 0.17259874939918518
train-epoch-step: 78-443 -- Loss: 0.1609019786119461
train-epoch-step: 78-444 -- Loss: 0.22531095147132874
train-epoch-step: 78-445 -- Loss: 0.1797751486301422
train-epoch-step: 78-446 -- Loss: 0.16210952401161194
train-epoch-step: 78-447 -- Loss: 0.18712647259235382
train-epoch-step: 78-448 -- Loss: 0.23162323236465454
train-epoch-step: 78-449 -- Loss: 0.1909317970275879
train-epoch-step: 78-450 -- Loss: 0.18258604407310486
train-epoch-step: 78-451 -- Loss: 0.16189323365688324
train-epoch-step: 78-452 -- Loss: 0.1300499141216278
train-epoch-step: 78-453 -- Loss: 0.08993038535118103
train-epoch-step: 78-454 -- Loss: 0.22625383734703064
train-epoch-step: 78-455 -- Loss: 0.12092538177967072
train-epoch-step: 78-456 -- Loss: 0.1160886138677597
train-epoch-step: 78-457 -- Loss: 0.21586404740810394
train-epoch-step: 78-458 -- Loss: 0.174125075340271
train-epoch-step: 78-459 -- Loss: 0.21824461221694946
train-epoch-step: 78-460 -- Loss: 0.12531395256519318
train-epoch-step: 78-461 -- Loss: 0.13887016475200653
train-epoch-step: 78-462 -- Loss: 0.1650274693965912
train-epoch-step: 78-463 -- Loss: 0.13636678457260132
train-epoch-step: 78-464 -- Loss: 0.16817428171634674
train-epoch-step: 78-465 -- Loss: 0.2544250786304474
train-epoch-step: 78-466 -- Loss: 0.20436425507068634
train-epoch-step: 78-467 -- Loss: 0.11512728035449982
train-epoch-step: 78-468 -- Loss: 0.19375720620155334
train-epoch-step: 78-469 -- Loss: 0.2097458392381668
train-epoch-step: 78-470 -- Loss: 0.17820829153060913
train-epoch-step: 78-471 -- Loss: 0.15528683364391327
train-epoch-step: 78-472 -- Loss: 0.15632279217243195
train-epoch-step: 78-473 -- Loss: 0.15754646062850952
train-epoch-step: 78-474 -- Loss: 0.12597128748893738
train-epoch-step: 78-475 -- Loss: 0.11213237047195435
train-epoch-step: 78-476 -- Loss: 0.20318402349948883
train-epoch-step: 78-477 -- Loss: 0.20706185698509216
train-epoch-step: 78-478 -- Loss: 0.21916285157203674
train-epoch-step: 78-479 -- Loss: 0.14176568388938904
train-epoch-step: 78-480 -- Loss: 0.18285076320171356
train-epoch-step: 78-481 -- Loss: 0.2831704914569855
train-epoch-step: 78-482 -- Loss: 0.28339171409606934
train-epoch-step: 78-483 -- Loss: 0.1833387017250061
train-epoch-step: 78-484 -- Loss: 0.21650007367134094
train-epoch-step: 78-485 -- Loss: 0.14531143009662628
train-epoch-step: 78-486 -- Loss: 0.23387780785560608
train-epoch-step: 78-487 -- Loss: 0.23458901047706604
train-epoch-step: 78-488 -- Loss: 0.20016562938690186
train-epoch-step: 78-489 -- Loss: 0.22302953898906708
train-epoch-step: 78-490 -- Loss: 0.13687355816364288
train-epoch-step: 78-491 -- Loss: 0.13806204497814178
train-epoch-step: 78-492 -- Loss: 0.12441901862621307
train-epoch-step: 78-493 -- Loss: 0.2020808309316635
train-epoch-step: 78-494 -- Loss: 0.1990898847579956
train-epoch-step: 78-495 -- Loss: 0.2096160501241684
train-epoch-step: 78-496 -- Loss: 0.1389046013355255
train-epoch-step: 78-497 -- Loss: 0.19863662123680115
train-epoch-step: 78-498 -- Loss: 0.14792320132255554
train-epoch-step: 78-499 -- Loss: 0.17017008364200592
train-epoch-step: 78-500 -- Loss: 0.15579257905483246
train-epoch-step: 78-501 -- Loss: 0.21544913947582245
train-epoch-step: 78-502 -- Loss: 0.17329025268554688
train-epoch-step: 78-503 -- Loss: 0.23219020664691925
train-epoch-step: 78-504 -- Loss: 0.1184777244925499
train-epoch-step: 78-505 -- Loss: 0.17427648603916168
train-epoch-step: 78-506 -- Loss: 0.11815017461776733
train-epoch-step: 78-507 -- Loss: 0.18989376723766327
train-epoch-step: 78-508 -- Loss: 0.17310887575149536
train-epoch-step: 78-509 -- Loss: 0.17883053421974182
train-epoch-step: 78-510 -- Loss: 0.128586545586586
train-epoch-step: 78-511 -- Loss: 0.22541874647140503
train-epoch-step: 78-512 -- Loss: 0.17933158576488495
train-epoch-step: 78-513 -- Loss: 0.18687915802001953
train-epoch-step: 78-514 -- Loss: 0.1389426589012146
train-epoch-step: 78-515 -- Loss: 0.15173663198947906
train-epoch-step: 78-516 -- Loss: 0.17628198862075806
train-epoch-step: 78-517 -- Loss: 0.17150749266147614
train-epoch-step: 78-518 -- Loss: 0.13890820741653442
train-epoch-step: 78-519 -- Loss: 0.13782136142253876
train-epoch-step: 78-520 -- Loss: 0.18617159128189087
train-epoch-step: 78-521 -- Loss: 0.23068353533744812
train-epoch-step: 78-522 -- Loss: 0.17697617411613464
train-epoch-step: 78-523 -- Loss: 0.16060608625411987
train-epoch-step: 78-524 -- Loss: 0.16643206775188446
train-epoch-step: 78-525 -- Loss: 0.19134314358234406
train-epoch-step: 78-526 -- Loss: 0.13003312051296234
train-epoch-step: 78-527 -- Loss: 0.1538749486207962
train-epoch-step: 78-528 -- Loss: 0.15138772130012512
train-epoch-step: 78-529 -- Loss: 0.15858955681324005
train-epoch-step: 78-530 -- Loss: 0.16697686910629272
train-epoch-step: 78-531 -- Loss: 0.20313140749931335
train-epoch-step: 78-532 -- Loss: 0.16599491238594055
train-epoch-step: 78-533 -- Loss: 0.1704273819923401
train-epoch-step: 78-534 -- Loss: 0.13400331139564514
train-epoch-step: 78-535 -- Loss: 0.248148575425148
train-epoch-step: 78-536 -- Loss: 0.15319792926311493
train-epoch-step: 78-537 -- Loss: 0.15785972774028778
train-epoch-step: 78-538 -- Loss: 0.10485337674617767
train-epoch-step: 78-539 -- Loss: 0.18204884231090546
train-epoch-step: 78-540 -- Loss: 0.13849760591983795
train-epoch-step: 78-541 -- Loss: 0.20948526263237
train-epoch-step: 78-542 -- Loss: 0.22573202848434448
train-epoch-step: 78-543 -- Loss: 0.1658797413110733
train-epoch-step: 78-544 -- Loss: 0.22061003744602203
train-epoch-step: 78-545 -- Loss: 0.18960356712341309
train-epoch-step: 78-546 -- Loss: 0.20795217156410217
train-epoch-step: 78-547 -- Loss: 0.18081285059452057
train-epoch-step: 78-548 -- Loss: 0.08928202092647552
train-epoch-step: 78-549 -- Loss: 0.14911824464797974
train-epoch-step: 78-550 -- Loss: 0.1958940029144287
train-epoch-step: 78-551 -- Loss: 0.14805641770362854
train-epoch-step: 78-552 -- Loss: 0.12623955309391022
train-epoch-step: 78-553 -- Loss: 0.18524204194545746
train-epoch-step: 78-554 -- Loss: 0.18248715996742249
train-epoch-step: 78-555 -- Loss: 0.20651113986968994
train-epoch-step: 78-556 -- Loss: 0.15315668284893036
train-epoch-step: 78-557 -- Loss: 0.23362624645233154
train-epoch-step: 78-558 -- Loss: 0.24080336093902588
train-epoch-step: 78-559 -- Loss: 0.1370670348405838
train-epoch-step: 78-560 -- Loss: 0.2050243616104126
train-epoch-step: 78-561 -- Loss: 0.1836811900138855
train-epoch-step: 78-562 -- Loss: 0.16237926483154297
train-epoch-step: 78-563 -- Loss: 0.1804286241531372
train-epoch-step: 78-564 -- Loss: 0.10111480951309204
train-epoch-step: 78-565 -- Loss: 0.18054305016994476
train-epoch-step: 78-566 -- Loss: 0.14686524868011475
train-epoch-step: 78-567 -- Loss: 0.20566777884960175
train-epoch-step: 78-568 -- Loss: 0.1549070030450821
train-epoch-step: 78-569 -- Loss: 0.23910029232501984
train-epoch-step: 78-570 -- Loss: 0.16092930734157562
train-epoch-step: 78-571 -- Loss: 0.20825250446796417
train-epoch-step: 78-572 -- Loss: 0.2371310591697693
train-epoch-step: 78-573 -- Loss: 0.19159133732318878
train-epoch-step: 78-574 -- Loss: 0.25307849049568176
train-epoch-step: 78-575 -- Loss: 0.3212570548057556
train-epoch-step: 78-576 -- Loss: 0.11780743300914764
train-epoch-step: 78-577 -- Loss: 0.16255268454551697
train-epoch-step: 78-578 -- Loss: 0.21095554530620575
train-epoch-step: 78-579 -- Loss: 0.16442745923995972
train-epoch-step: 78-580 -- Loss: 0.1800338327884674
train-epoch-step: 78-581 -- Loss: 0.1476888358592987
train-epoch-step: 78-582 -- Loss: 0.2051178216934204
train-epoch-step: 78-583 -- Loss: 0.22700484097003937
train-epoch-step: 78-584 -- Loss: 0.16379527747631073
train-epoch-step: 78-585 -- Loss: 0.19381976127624512
train-epoch-step: 78-586 -- Loss: 0.2484264373779297
train-epoch-step: 78-587 -- Loss: 0.16150909662246704
train-epoch-step: 78-588 -- Loss: 0.1295769065618515
val-epoch-step: 78-589 -- Loss: 0.22198815643787384
val-epoch-step: 78-590 -- Loss: 0.15646256506443024
val-epoch-step: 78-591 -- Loss: 0.24612820148468018
val-epoch-step: 78-592 -- Loss: 0.17043906450271606
val-epoch-step: 78-593 -- Loss: 0.21343164145946503
val-epoch-step: 78-594 -- Loss: 0.3693937659263611
val-epoch-step: 78-595 -- Loss: 0.18464846909046173
val-epoch-step: 78-596 -- Loss: 0.1931149959564209
val-epoch-step: 78-597 -- Loss: 0.17450381815433502
val-epoch-step: 78-598 -- Loss: 0.14843957126140594
val-epoch-step: 78-599 -- Loss: 0.189082533121109
val-epoch-step: 78-600 -- Loss: 0.17702463269233704
val-epoch-step: 78-601 -- Loss: 0.1614534556865692
val-epoch-step: 78-602 -- Loss: 0.13618041574954987
val-epoch-step: 78-603 -- Loss: 0.19532980024814606
val-epoch-step: 78-604 -- Loss: 0.14337055385112762
val-epoch-step: 78-605 -- Loss: 0.14650671184062958
val-epoch-step: 78-606 -- Loss: 0.28376466035842896
val-epoch-step: 78-607 -- Loss: 0.13124476373195648
val-epoch-step: 78-608 -- Loss: 0.24546143412590027
val-epoch-step: 78-609 -- Loss: 0.174647718667984
val-epoch-step: 78-610 -- Loss: 0.17725732922554016
val-epoch-step: 78-611 -- Loss: 0.15991464257240295
val-epoch-step: 78-612 -- Loss: 0.39091765880584717
val-epoch-step: 78-613 -- Loss: 0.1768481284379959
val-epoch-step: 78-614 -- Loss: 0.16310231387615204
val-epoch-step: 78-615 -- Loss: 0.17197607457637787
val-epoch-step: 78-616 -- Loss: 0.15491074323654175
val-epoch-step: 78-617 -- Loss: 0.19381871819496155
val-epoch-step: 78-618 -- Loss: 0.1780375838279724
val-epoch-step: 78-619 -- Loss: 0.2016494870185852
val-epoch-step: 78-620 -- Loss: 0.13495226204395294
val-epoch-step: 78-621 -- Loss: 0.12433008849620819
val-epoch-step: 78-622 -- Loss: 0.14241652190685272
val-epoch-step: 78-623 -- Loss: 0.15001797676086426
val-epoch-step: 78-624 -- Loss: 0.13693177700042725
val-epoch-step: 78-625 -- Loss: 0.15671496093273163
val-epoch-step: 78-626 -- Loss: 0.17527402937412262
val-epoch-step: 78-627 -- Loss: 0.18221858143806458
val-epoch-step: 78-628 -- Loss: 0.4330648183822632
val-epoch-step: 78-629 -- Loss: 0.20350927114486694
val-epoch-step: 78-630 -- Loss: 0.34915727376937866
val-epoch-step: 78-631 -- Loss: 0.14519032835960388
val-epoch-step: 78-632 -- Loss: 0.20756494998931885
val-epoch-step: 78-633 -- Loss: 0.14971156418323517
val-epoch-step: 78-634 -- Loss: 0.15153704583644867
val-epoch-step: 78-635 -- Loss: 0.1158287301659584
val-epoch-step: 78-636 -- Loss: 0.16686858236789703
val-epoch-step: 78-637 -- Loss: 0.18339332938194275
val-epoch-step: 78-638 -- Loss: 0.15297111868858337
val-epoch-step: 78-639 -- Loss: 0.25017958879470825
val-epoch-step: 78-640 -- Loss: 0.2526510953903198
val-epoch-step: 78-641 -- Loss: 0.12210971117019653
val-epoch-step: 78-642 -- Loss: 0.1811598837375641
val-epoch-step: 78-643 -- Loss: 0.20487159490585327
val-epoch-step: 78-644 -- Loss: 0.16478797793388367
val-epoch-step: 78-645 -- Loss: 0.2153741866350174
val-epoch-step: 78-646 -- Loss: 0.13083235919475555
val-epoch-step: 78-647 -- Loss: 0.1301858127117157
val-epoch-step: 78-648 -- Loss: 0.1561388522386551
val-epoch-step: 78-649 -- Loss: 0.2122897207736969
val-epoch-step: 78-650 -- Loss: 0.25055480003356934
val-epoch-step: 78-651 -- Loss: 0.14618179202079773
val-epoch-step: 78-652 -- Loss: 0.15423516929149628
val-epoch-step: 78-653 -- Loss: 0.2043098509311676
val-epoch-step: 78-654 -- Loss: 0.11823274195194244
Epoch: 78 -- Train Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 79-0 -- Loss: 0.22747471928596497
train-epoch-step: 79-1 -- Loss: 0.14288288354873657
train-epoch-step: 79-2 -- Loss: 0.2024821937084198
train-epoch-step: 79-3 -- Loss: 0.14371055364608765
train-epoch-step: 79-4 -- Loss: 0.15610063076019287
train-epoch-step: 79-5 -- Loss: 0.18369466066360474
train-epoch-step: 79-6 -- Loss: 0.23492135107517242
train-epoch-step: 79-7 -- Loss: 0.16827157139778137
train-epoch-step: 79-8 -- Loss: 0.1912897229194641
train-epoch-step: 79-9 -- Loss: 0.22013621032238007
train-epoch-step: 79-10 -- Loss: 0.19383053481578827
train-epoch-step: 79-11 -- Loss: 0.1760856956243515
train-epoch-step: 79-12 -- Loss: 0.14671216905117035
train-epoch-step: 79-13 -- Loss: 0.18120789527893066
train-epoch-step: 79-14 -- Loss: 0.17152643203735352
train-epoch-step: 79-15 -- Loss: 0.15524230897426605
train-epoch-step: 79-16 -- Loss: 0.17516911029815674
train-epoch-step: 79-17 -- Loss: 0.2289121150970459
train-epoch-step: 79-18 -- Loss: 0.20756953954696655
train-epoch-step: 79-19 -- Loss: 0.12939944863319397
train-epoch-step: 79-20 -- Loss: 0.2100357860326767
train-epoch-step: 79-21 -- Loss: 0.3413277268409729
train-epoch-step: 79-22 -- Loss: 0.15172284841537476
train-epoch-step: 79-23 -- Loss: 0.14919844269752502
train-epoch-step: 79-24 -- Loss: 0.12375836074352264
train-epoch-step: 79-25 -- Loss: 0.26153719425201416
train-epoch-step: 79-26 -- Loss: 0.20362374186515808
train-epoch-step: 79-27 -- Loss: 0.23964126408100128
train-epoch-step: 79-28 -- Loss: 0.13301284611225128
train-epoch-step: 79-29 -- Loss: 0.25604331493377686
train-epoch-step: 79-30 -- Loss: 0.11235614120960236
train-epoch-step: 79-31 -- Loss: 0.1477750837802887
train-epoch-step: 79-32 -- Loss: 0.1715134084224701
train-epoch-step: 79-33 -- Loss: 0.2879142463207245
train-epoch-step: 79-34 -- Loss: 0.1706712692975998
train-epoch-step: 79-35 -- Loss: 0.2437131702899933
train-epoch-step: 79-36 -- Loss: 0.14193189144134521
train-epoch-step: 79-37 -- Loss: 0.14090053737163544
train-epoch-step: 79-38 -- Loss: 0.17058591544628143
train-epoch-step: 79-39 -- Loss: 0.217983677983284
train-epoch-step: 79-40 -- Loss: 0.19368523359298706
train-epoch-step: 79-41 -- Loss: 0.22543732821941376
train-epoch-step: 79-42 -- Loss: 0.14718344807624817
train-epoch-step: 79-43 -- Loss: 0.26539143919944763
train-epoch-step: 79-44 -- Loss: 0.12298032641410828
train-epoch-step: 79-45 -- Loss: 0.11979130655527115
train-epoch-step: 79-46 -- Loss: 0.1783435046672821
train-epoch-step: 79-47 -- Loss: 0.20534032583236694
train-epoch-step: 79-48 -- Loss: 0.15365499258041382
train-epoch-step: 79-49 -- Loss: 0.22981157898902893
train-epoch-step: 79-50 -- Loss: 0.12005116045475006
train-epoch-step: 79-51 -- Loss: 0.18675097823143005
train-epoch-step: 79-52 -- Loss: 0.15885858237743378
train-epoch-step: 79-53 -- Loss: 0.20943810045719147
train-epoch-step: 79-54 -- Loss: 0.2899286150932312
train-epoch-step: 79-55 -- Loss: 0.16343599557876587
train-epoch-step: 79-56 -- Loss: 0.17339563369750977
train-epoch-step: 79-57 -- Loss: 0.23475904762744904
train-epoch-step: 79-58 -- Loss: 0.28243640065193176
train-epoch-step: 79-59 -- Loss: 0.2428305298089981
train-epoch-step: 79-60 -- Loss: 0.13363558053970337
train-epoch-step: 79-61 -- Loss: 0.20414073765277863
train-epoch-step: 79-62 -- Loss: 0.18707402050495148
train-epoch-step: 79-63 -- Loss: 0.14973381161689758
train-epoch-step: 79-64 -- Loss: 0.14425961673259735
train-epoch-step: 79-65 -- Loss: 0.17757752537727356
train-epoch-step: 79-66 -- Loss: 0.10877399146556854
train-epoch-step: 79-67 -- Loss: 0.13318926095962524
train-epoch-step: 79-68 -- Loss: 0.21661630272865295
train-epoch-step: 79-69 -- Loss: 0.1316666156053543
train-epoch-step: 79-70 -- Loss: 0.28874433040618896
train-epoch-step: 79-71 -- Loss: 0.27160143852233887
train-epoch-step: 79-72 -- Loss: 0.17884479463100433
train-epoch-step: 79-73 -- Loss: 0.20202630758285522
train-epoch-step: 79-74 -- Loss: 0.09457643330097198
train-epoch-step: 79-75 -- Loss: 0.1290622055530548
train-epoch-step: 79-76 -- Loss: 0.15143361687660217
train-epoch-step: 79-77 -- Loss: 0.23921027779579163
train-epoch-step: 79-78 -- Loss: 0.3596647381782532
train-epoch-step: 79-79 -- Loss: 0.19232746958732605
train-epoch-step: 79-80 -- Loss: 0.26617196202278137
train-epoch-step: 79-81 -- Loss: 0.12369538098573685
train-epoch-step: 79-82 -- Loss: 0.25052589178085327
train-epoch-step: 79-83 -- Loss: 0.17997309565544128
train-epoch-step: 79-84 -- Loss: 0.18663279712200165
train-epoch-step: 79-85 -- Loss: 0.17301490902900696
train-epoch-step: 79-86 -- Loss: 0.1223948523402214
train-epoch-step: 79-87 -- Loss: 0.22647765278816223
train-epoch-step: 79-88 -- Loss: 0.1413102149963379
train-epoch-step: 79-89 -- Loss: 0.18615290522575378
train-epoch-step: 79-90 -- Loss: 0.19596850872039795
train-epoch-step: 79-91 -- Loss: 0.24177880585193634
train-epoch-step: 79-92 -- Loss: 0.1528620421886444
train-epoch-step: 79-93 -- Loss: 0.1800166368484497
train-epoch-step: 79-94 -- Loss: 0.250582218170166
train-epoch-step: 79-95 -- Loss: 0.18458674848079681
train-epoch-step: 79-96 -- Loss: 0.2146492302417755
train-epoch-step: 79-97 -- Loss: 0.17307451367378235
train-epoch-step: 79-98 -- Loss: 0.1519692838191986
train-epoch-step: 79-99 -- Loss: 0.1822425127029419
train-epoch-step: 79-100 -- Loss: 0.18594077229499817
train-epoch-step: 79-101 -- Loss: 0.25982317328453064
train-epoch-step: 79-102 -- Loss: 0.2379029542207718
train-epoch-step: 79-103 -- Loss: 0.18110962212085724
train-epoch-step: 79-104 -- Loss: 0.1476593017578125
train-epoch-step: 79-105 -- Loss: 0.2787074148654938
train-epoch-step: 79-106 -- Loss: 0.17664550244808197
train-epoch-step: 79-107 -- Loss: 0.194807231426239
train-epoch-step: 79-108 -- Loss: 0.1868841052055359
train-epoch-step: 79-109 -- Loss: 0.14326225221157074
train-epoch-step: 79-110 -- Loss: 0.1778556853532791
train-epoch-step: 79-111 -- Loss: 0.17906010150909424
train-epoch-step: 79-112 -- Loss: 0.16639386117458344
train-epoch-step: 79-113 -- Loss: 0.16527390480041504
train-epoch-step: 79-114 -- Loss: 0.18809741735458374
train-epoch-step: 79-115 -- Loss: 0.15933939814567566
train-epoch-step: 79-116 -- Loss: 0.13347598910331726
train-epoch-step: 79-117 -- Loss: 0.12892001867294312
train-epoch-step: 79-118 -- Loss: 0.19413240253925323
train-epoch-step: 79-119 -- Loss: 0.15080654621124268
train-epoch-step: 79-120 -- Loss: 0.24659159779548645
train-epoch-step: 79-121 -- Loss: 0.24839381873607635
train-epoch-step: 79-122 -- Loss: 0.21374940872192383
train-epoch-step: 79-123 -- Loss: 0.19680407643318176
train-epoch-step: 79-124 -- Loss: 0.12033706903457642
train-epoch-step: 79-125 -- Loss: 0.15113487839698792
train-epoch-step: 79-126 -- Loss: 0.22649359703063965
train-epoch-step: 79-127 -- Loss: 0.17138367891311646
train-epoch-step: 79-128 -- Loss: 0.16664044559001923
train-epoch-step: 79-129 -- Loss: 0.1357252150774002
train-epoch-step: 79-130 -- Loss: 0.1973264515399933
train-epoch-step: 79-131 -- Loss: 0.13603775203227997
train-epoch-step: 79-132 -- Loss: 0.19901448488235474
train-epoch-step: 79-133 -- Loss: 0.11524015665054321
train-epoch-step: 79-134 -- Loss: 0.1857561469078064
train-epoch-step: 79-135 -- Loss: 0.12952981889247894
train-epoch-step: 79-136 -- Loss: 0.1253693699836731
train-epoch-step: 79-137 -- Loss: 0.23700620234012604
train-epoch-step: 79-138 -- Loss: 0.25296396017074585
train-epoch-step: 79-139 -- Loss: 0.1289016306400299
train-epoch-step: 79-140 -- Loss: 0.20422889292240143
train-epoch-step: 79-141 -- Loss: 0.2330777943134308
train-epoch-step: 79-142 -- Loss: 0.19644030928611755
train-epoch-step: 79-143 -- Loss: 0.1728914976119995
train-epoch-step: 79-144 -- Loss: 0.17947058379650116
train-epoch-step: 79-145 -- Loss: 0.1455148160457611
train-epoch-step: 79-146 -- Loss: 0.1761377453804016
train-epoch-step: 79-147 -- Loss: 0.17056208848953247
train-epoch-step: 79-148 -- Loss: 0.1568407416343689
train-epoch-step: 79-149 -- Loss: 0.12059338390827179
train-epoch-step: 79-150 -- Loss: 0.1799885779619217
train-epoch-step: 79-151 -- Loss: 0.1847224235534668
train-epoch-step: 79-152 -- Loss: 0.18742594122886658
train-epoch-step: 79-153 -- Loss: 0.2651044726371765
train-epoch-step: 79-154 -- Loss: 0.13653935492038727
train-epoch-step: 79-155 -- Loss: 0.13650472462177277
train-epoch-step: 79-156 -- Loss: 0.11468575894832611
train-epoch-step: 79-157 -- Loss: 0.16498661041259766
train-epoch-step: 79-158 -- Loss: 0.16256606578826904
train-epoch-step: 79-159 -- Loss: 0.17822150886058807
train-epoch-step: 79-160 -- Loss: 0.2116324007511139
train-epoch-step: 79-161 -- Loss: 0.20144014060497284
train-epoch-step: 79-162 -- Loss: 0.2068498134613037
train-epoch-step: 79-163 -- Loss: 0.18263070285320282
train-epoch-step: 79-164 -- Loss: 0.18673090636730194
train-epoch-step: 79-165 -- Loss: 0.1627216786146164
train-epoch-step: 79-166 -- Loss: 0.1195545494556427
train-epoch-step: 79-167 -- Loss: 0.13330349326133728
train-epoch-step: 79-168 -- Loss: 0.20221936702728271
train-epoch-step: 79-169 -- Loss: 0.1374591737985611
train-epoch-step: 79-170 -- Loss: 0.19572439789772034
train-epoch-step: 79-171 -- Loss: 0.1411365121603012
train-epoch-step: 79-172 -- Loss: 0.25131750106811523
train-epoch-step: 79-173 -- Loss: 0.1269282102584839
train-epoch-step: 79-174 -- Loss: 0.24135532975196838
train-epoch-step: 79-175 -- Loss: 0.18062712252140045
train-epoch-step: 79-176 -- Loss: 0.13181737065315247
train-epoch-step: 79-177 -- Loss: 0.17546489834785461
train-epoch-step: 79-178 -- Loss: 0.17571648955345154
train-epoch-step: 79-179 -- Loss: 0.16723281145095825
train-epoch-step: 79-180 -- Loss: 0.14918385446071625
train-epoch-step: 79-181 -- Loss: 0.168730691075325
train-epoch-step: 79-182 -- Loss: 0.18233895301818848
train-epoch-step: 79-183 -- Loss: 0.26479431986808777
train-epoch-step: 79-184 -- Loss: 0.13864481449127197
train-epoch-step: 79-185 -- Loss: 0.139357328414917
train-epoch-step: 79-186 -- Loss: 0.1908557415008545
train-epoch-step: 79-187 -- Loss: 0.20848484337329865
train-epoch-step: 79-188 -- Loss: 0.1721433401107788
train-epoch-step: 79-189 -- Loss: 0.10458146035671234
train-epoch-step: 79-190 -- Loss: 0.17931661009788513
train-epoch-step: 79-191 -- Loss: 0.15541453659534454
train-epoch-step: 79-192 -- Loss: 0.22444215416908264
train-epoch-step: 79-193 -- Loss: 0.20739075541496277
train-epoch-step: 79-194 -- Loss: 0.18004024028778076
train-epoch-step: 79-195 -- Loss: 0.16130976378917694
train-epoch-step: 79-196 -- Loss: 0.16814982891082764
train-epoch-step: 79-197 -- Loss: 0.12406492233276367
train-epoch-step: 79-198 -- Loss: 0.12723559141159058
train-epoch-step: 79-199 -- Loss: 0.1444520801305771
train-epoch-step: 79-200 -- Loss: 0.12434426695108414
train-epoch-step: 79-201 -- Loss: 0.19405223429203033
train-epoch-step: 79-202 -- Loss: 0.13331392407417297
train-epoch-step: 79-203 -- Loss: 0.1725197583436966
train-epoch-step: 79-204 -- Loss: 0.1286584734916687
train-epoch-step: 79-205 -- Loss: 0.18653960525989532
train-epoch-step: 79-206 -- Loss: 0.2029576301574707
train-epoch-step: 79-207 -- Loss: 0.15074430406093597
train-epoch-step: 79-208 -- Loss: 0.1765059232711792
train-epoch-step: 79-209 -- Loss: 0.14380060136318207
train-epoch-step: 79-210 -- Loss: 0.12956371903419495
train-epoch-step: 79-211 -- Loss: 0.20927932858467102
train-epoch-step: 79-212 -- Loss: 0.19949597120285034
train-epoch-step: 79-213 -- Loss: 0.12469395995140076
train-epoch-step: 79-214 -- Loss: 0.14629733562469482
train-epoch-step: 79-215 -- Loss: 0.125994473695755
train-epoch-step: 79-216 -- Loss: 0.19604066014289856
train-epoch-step: 79-217 -- Loss: 0.2075050324201584
train-epoch-step: 79-218 -- Loss: 0.14135606586933136
train-epoch-step: 79-219 -- Loss: 0.16264596581459045
train-epoch-step: 79-220 -- Loss: 0.12887826561927795
train-epoch-step: 79-221 -- Loss: 0.20070821046829224
train-epoch-step: 79-222 -- Loss: 0.11597641557455063
train-epoch-step: 79-223 -- Loss: 0.1697130650281906
train-epoch-step: 79-224 -- Loss: 0.18639034032821655
train-epoch-step: 79-225 -- Loss: 0.2666236162185669
train-epoch-step: 79-226 -- Loss: 0.2000756710767746
train-epoch-step: 79-227 -- Loss: 0.21462726593017578
train-epoch-step: 79-228 -- Loss: 0.1745041310787201
train-epoch-step: 79-229 -- Loss: 0.16795971989631653
train-epoch-step: 79-230 -- Loss: 0.15986327826976776
train-epoch-step: 79-231 -- Loss: 0.15796321630477905
train-epoch-step: 79-232 -- Loss: 0.1816934049129486
train-epoch-step: 79-233 -- Loss: 0.08331754058599472
train-epoch-step: 79-234 -- Loss: 0.17674490809440613
train-epoch-step: 79-235 -- Loss: 0.14611847698688507
train-epoch-step: 79-236 -- Loss: 0.18457350134849548
train-epoch-step: 79-237 -- Loss: 0.23021888732910156
train-epoch-step: 79-238 -- Loss: 0.15230703353881836
train-epoch-step: 79-239 -- Loss: 0.12465149909257889
train-epoch-step: 79-240 -- Loss: 0.2229674756526947
train-epoch-step: 79-241 -- Loss: 0.1512967050075531
train-epoch-step: 79-242 -- Loss: 0.21808353066444397
train-epoch-step: 79-243 -- Loss: 0.23044978082180023
train-epoch-step: 79-244 -- Loss: 0.20698954164981842
train-epoch-step: 79-245 -- Loss: 0.20904676616191864
train-epoch-step: 79-246 -- Loss: 0.21486623585224152
train-epoch-step: 79-247 -- Loss: 0.2051278054714203
train-epoch-step: 79-248 -- Loss: 0.18288499116897583
train-epoch-step: 79-249 -- Loss: 0.1356702297925949
train-epoch-step: 79-250 -- Loss: 0.19500985741615295
train-epoch-step: 79-251 -- Loss: 0.10825343430042267
train-epoch-step: 79-252 -- Loss: 0.192195862531662
train-epoch-step: 79-253 -- Loss: 0.1395292431116104
train-epoch-step: 79-254 -- Loss: 0.21122859418392181
train-epoch-step: 79-255 -- Loss: 0.14391739666461945
train-epoch-step: 79-256 -- Loss: 0.1510845422744751
train-epoch-step: 79-257 -- Loss: 0.1910603940486908
train-epoch-step: 79-258 -- Loss: 0.1386701762676239
train-epoch-step: 79-259 -- Loss: 0.11191457509994507
train-epoch-step: 79-260 -- Loss: 0.19555199146270752
train-epoch-step: 79-261 -- Loss: 0.1649523228406906
train-epoch-step: 79-262 -- Loss: 0.29055848717689514
train-epoch-step: 79-263 -- Loss: 0.24557650089263916
train-epoch-step: 79-264 -- Loss: 0.16709598898887634
train-epoch-step: 79-265 -- Loss: 0.12393896281719208
train-epoch-step: 79-266 -- Loss: 0.16970743238925934
train-epoch-step: 79-267 -- Loss: 0.1413886994123459
train-epoch-step: 79-268 -- Loss: 0.12980856001377106
train-epoch-step: 79-269 -- Loss: 0.17451955378055573
train-epoch-step: 79-270 -- Loss: 0.10931670665740967
train-epoch-step: 79-271 -- Loss: 0.1544358730316162
train-epoch-step: 79-272 -- Loss: 0.12569236755371094
train-epoch-step: 79-273 -- Loss: 0.12849973142147064
train-epoch-step: 79-274 -- Loss: 0.19484205543994904
train-epoch-step: 79-275 -- Loss: 0.189272940158844
train-epoch-step: 79-276 -- Loss: 0.15210604667663574
train-epoch-step: 79-277 -- Loss: 0.15202711522579193
train-epoch-step: 79-278 -- Loss: 0.1395125538110733
train-epoch-step: 79-279 -- Loss: 0.139119952917099
train-epoch-step: 79-280 -- Loss: 0.2129703015089035
train-epoch-step: 79-281 -- Loss: 0.17417335510253906
train-epoch-step: 79-282 -- Loss: 0.14225366711616516
train-epoch-step: 79-283 -- Loss: 0.11405099928379059
train-epoch-step: 79-284 -- Loss: 0.135197252035141
train-epoch-step: 79-285 -- Loss: 0.19917556643486023
train-epoch-step: 79-286 -- Loss: 0.1565791815519333
train-epoch-step: 79-287 -- Loss: 0.21559080481529236
train-epoch-step: 79-288 -- Loss: 0.09391845762729645
train-epoch-step: 79-289 -- Loss: 0.11809195578098297
train-epoch-step: 79-290 -- Loss: 0.18087376654148102
train-epoch-step: 79-291 -- Loss: 0.1160343587398529
train-epoch-step: 79-292 -- Loss: 0.16334660351276398
train-epoch-step: 79-293 -- Loss: 0.13593627512454987
train-epoch-step: 79-294 -- Loss: 0.15730422735214233
train-epoch-step: 79-295 -- Loss: 0.2599785327911377
train-epoch-step: 79-296 -- Loss: 0.15724650025367737
train-epoch-step: 79-297 -- Loss: 0.16994285583496094
train-epoch-step: 79-298 -- Loss: 0.22988837957382202
train-epoch-step: 79-299 -- Loss: 0.14341752231121063
train-epoch-step: 79-300 -- Loss: 0.15730145573616028
train-epoch-step: 79-301 -- Loss: 0.1685870885848999
train-epoch-step: 79-302 -- Loss: 0.21002301573753357
train-epoch-step: 79-303 -- Loss: 0.2084398716688156
train-epoch-step: 79-304 -- Loss: 0.12870410084724426
train-epoch-step: 79-305 -- Loss: 0.13936300575733185
train-epoch-step: 79-306 -- Loss: 0.21965165436267853
train-epoch-step: 79-307 -- Loss: 0.1612565517425537
train-epoch-step: 79-308 -- Loss: 0.22290310263633728
train-epoch-step: 79-309 -- Loss: 0.1537945717573166
train-epoch-step: 79-310 -- Loss: 0.1632126122713089
train-epoch-step: 79-311 -- Loss: 0.16315728425979614
train-epoch-step: 79-312 -- Loss: 0.20445479452610016
train-epoch-step: 79-313 -- Loss: 0.0940549224615097
train-epoch-step: 79-314 -- Loss: 0.18952055275440216
train-epoch-step: 79-315 -- Loss: 0.16853776574134827
train-epoch-step: 79-316 -- Loss: 0.15027207136154175
train-epoch-step: 79-317 -- Loss: 0.1408366560935974
train-epoch-step: 79-318 -- Loss: 0.1614515483379364
train-epoch-step: 79-319 -- Loss: 0.17628523707389832
train-epoch-step: 79-320 -- Loss: 0.11867116391658783
train-epoch-step: 79-321 -- Loss: 0.13801054656505585
train-epoch-step: 79-322 -- Loss: 0.2100333571434021
train-epoch-step: 79-323 -- Loss: 0.15866884589195251
train-epoch-step: 79-324 -- Loss: 0.25393980741500854
train-epoch-step: 79-325 -- Loss: 0.1524764448404312
train-epoch-step: 79-326 -- Loss: 0.17193244397640228
train-epoch-step: 79-327 -- Loss: 0.2035980075597763
train-epoch-step: 79-328 -- Loss: 0.198111891746521
train-epoch-step: 79-329 -- Loss: 0.3313779830932617
train-epoch-step: 79-330 -- Loss: 0.35389575362205505
train-epoch-step: 79-331 -- Loss: 0.2454008162021637
train-epoch-step: 79-332 -- Loss: 0.09811223298311234
train-epoch-step: 79-333 -- Loss: 0.18305687606334686
train-epoch-step: 79-334 -- Loss: 0.14963282644748688
train-epoch-step: 79-335 -- Loss: 0.1734556257724762
train-epoch-step: 79-336 -- Loss: 0.14766265451908112
train-epoch-step: 79-337 -- Loss: 0.19619059562683105
train-epoch-step: 79-338 -- Loss: 0.15619385242462158
train-epoch-step: 79-339 -- Loss: 0.14352065324783325
train-epoch-step: 79-340 -- Loss: 0.19308795034885406
train-epoch-step: 79-341 -- Loss: 0.13671274483203888
train-epoch-step: 79-342 -- Loss: 0.15990644693374634
train-epoch-step: 79-343 -- Loss: 0.15067395567893982
train-epoch-step: 79-344 -- Loss: 0.15974819660186768
train-epoch-step: 79-345 -- Loss: 0.1261632740497589
train-epoch-step: 79-346 -- Loss: 0.20165306329727173
train-epoch-step: 79-347 -- Loss: 0.15029291808605194
train-epoch-step: 79-348 -- Loss: 0.20104745030403137
train-epoch-step: 79-349 -- Loss: 0.2006906270980835
train-epoch-step: 79-350 -- Loss: 0.2543163001537323
train-epoch-step: 79-351 -- Loss: 0.19878599047660828
train-epoch-step: 79-352 -- Loss: 0.1468709111213684
train-epoch-step: 79-353 -- Loss: 0.1915169060230255
train-epoch-step: 79-354 -- Loss: 0.2916085422039032
train-epoch-step: 79-355 -- Loss: 0.11739622801542282
train-epoch-step: 79-356 -- Loss: 0.11359702795743942
train-epoch-step: 79-357 -- Loss: 0.18595796823501587
train-epoch-step: 79-358 -- Loss: 0.1855597198009491
train-epoch-step: 79-359 -- Loss: 0.1341353803873062
train-epoch-step: 79-360 -- Loss: 0.12291834503412247
train-epoch-step: 79-361 -- Loss: 0.24104587733745575
train-epoch-step: 79-362 -- Loss: 0.17076432704925537
train-epoch-step: 79-363 -- Loss: 0.1192975863814354
train-epoch-step: 79-364 -- Loss: 0.1787901371717453
train-epoch-step: 79-365 -- Loss: 0.1667238473892212
train-epoch-step: 79-366 -- Loss: 0.2037861943244934
train-epoch-step: 79-367 -- Loss: 0.22788631916046143
train-epoch-step: 79-368 -- Loss: 0.2000221610069275
train-epoch-step: 79-369 -- Loss: 0.28186941146850586
train-epoch-step: 79-370 -- Loss: 0.13242949545383453
train-epoch-step: 79-371 -- Loss: 0.12901508808135986
train-epoch-step: 79-372 -- Loss: 0.15225356817245483
train-epoch-step: 79-373 -- Loss: 0.2044699788093567
train-epoch-step: 79-374 -- Loss: 0.15504129230976105
train-epoch-step: 79-375 -- Loss: 0.2628503739833832
train-epoch-step: 79-376 -- Loss: 0.1647767275571823
train-epoch-step: 79-377 -- Loss: 0.2221987396478653
train-epoch-step: 79-378 -- Loss: 0.1946939080953598
train-epoch-step: 79-379 -- Loss: 0.11742348223924637
train-epoch-step: 79-380 -- Loss: 0.09254191070795059
train-epoch-step: 79-381 -- Loss: 0.25163447856903076
train-epoch-step: 79-382 -- Loss: 0.2319554090499878
train-epoch-step: 79-383 -- Loss: 0.1750062108039856
train-epoch-step: 79-384 -- Loss: 0.21037432551383972
train-epoch-step: 79-385 -- Loss: 0.18728286027908325
train-epoch-step: 79-386 -- Loss: 0.1907438486814499
train-epoch-step: 79-387 -- Loss: 0.19620954990386963
train-epoch-step: 79-388 -- Loss: 0.20254579186439514
train-epoch-step: 79-389 -- Loss: 0.16637572646141052
train-epoch-step: 79-390 -- Loss: 0.1416371762752533
train-epoch-step: 79-391 -- Loss: 0.14391128718852997
train-epoch-step: 79-392 -- Loss: 0.1848069429397583
train-epoch-step: 79-393 -- Loss: 0.15237995982170105
train-epoch-step: 79-394 -- Loss: 0.19509755074977875
train-epoch-step: 79-395 -- Loss: 0.16978903114795685
train-epoch-step: 79-396 -- Loss: 0.12516029179096222
train-epoch-step: 79-397 -- Loss: 0.12238110601902008
train-epoch-step: 79-398 -- Loss: 0.19572646915912628
train-epoch-step: 79-399 -- Loss: 0.17665092647075653
train-epoch-step: 79-400 -- Loss: 0.2742859125137329
train-epoch-step: 79-401 -- Loss: 0.12549199163913727
train-epoch-step: 79-402 -- Loss: 0.25436726212501526
train-epoch-step: 79-403 -- Loss: 0.16538730263710022
train-epoch-step: 79-404 -- Loss: 0.13551825284957886
train-epoch-step: 79-405 -- Loss: 0.1419772058725357
train-epoch-step: 79-406 -- Loss: 0.16338138282299042
train-epoch-step: 79-407 -- Loss: 0.11044611781835556
train-epoch-step: 79-408 -- Loss: 0.1628648042678833
train-epoch-step: 79-409 -- Loss: 0.16662365198135376
train-epoch-step: 79-410 -- Loss: 0.17289461195468903
train-epoch-step: 79-411 -- Loss: 0.19659408926963806
train-epoch-step: 79-412 -- Loss: 0.129134863615036
train-epoch-step: 79-413 -- Loss: 0.1449209451675415
train-epoch-step: 79-414 -- Loss: 0.13151055574417114
train-epoch-step: 79-415 -- Loss: 0.13415323197841644
train-epoch-step: 79-416 -- Loss: 0.26539599895477295
train-epoch-step: 79-417 -- Loss: 0.19157089293003082
train-epoch-step: 79-418 -- Loss: 0.22618898749351501
train-epoch-step: 79-419 -- Loss: 0.18417882919311523
train-epoch-step: 79-420 -- Loss: 0.1495768427848816
train-epoch-step: 79-421 -- Loss: 0.17472298443317413
train-epoch-step: 79-422 -- Loss: 0.14597195386886597
train-epoch-step: 79-423 -- Loss: 0.17548251152038574
train-epoch-step: 79-424 -- Loss: 0.13952480256557465
train-epoch-step: 79-425 -- Loss: 0.18289031088352203
train-epoch-step: 79-426 -- Loss: 0.16921670734882355
train-epoch-step: 79-427 -- Loss: 0.12180407345294952
train-epoch-step: 79-428 -- Loss: 0.1880049854516983
train-epoch-step: 79-429 -- Loss: 0.17458516359329224
train-epoch-step: 79-430 -- Loss: 0.1422038972377777
train-epoch-step: 79-431 -- Loss: 0.16675475239753723
train-epoch-step: 79-432 -- Loss: 0.23274102807044983
train-epoch-step: 79-433 -- Loss: 0.13482050597667694
train-epoch-step: 79-434 -- Loss: 0.12903732061386108
train-epoch-step: 79-435 -- Loss: 0.15655766427516937
train-epoch-step: 79-436 -- Loss: 0.16747310757637024
train-epoch-step: 79-437 -- Loss: 0.1307804137468338
train-epoch-step: 79-438 -- Loss: 0.17213556170463562
train-epoch-step: 79-439 -- Loss: 0.25688910484313965
train-epoch-step: 79-440 -- Loss: 0.13108696043491364
train-epoch-step: 79-441 -- Loss: 0.19703584909439087
train-epoch-step: 79-442 -- Loss: 0.17221660912036896
train-epoch-step: 79-443 -- Loss: 0.1584666669368744
train-epoch-step: 79-444 -- Loss: 0.19171319901943207
train-epoch-step: 79-445 -- Loss: 0.17816230654716492
train-epoch-step: 79-446 -- Loss: 0.15019965171813965
train-epoch-step: 79-447 -- Loss: 0.1895226538181305
train-epoch-step: 79-448 -- Loss: 0.22118456661701202
train-epoch-step: 79-449 -- Loss: 0.19558990001678467
train-epoch-step: 79-450 -- Loss: 0.18150612711906433
train-epoch-step: 79-451 -- Loss: 0.14518722891807556
train-epoch-step: 79-452 -- Loss: 0.13578297197818756
train-epoch-step: 79-453 -- Loss: 0.09020386636257172
train-epoch-step: 79-454 -- Loss: 0.2198542207479477
train-epoch-step: 79-455 -- Loss: 0.12003956735134125
train-epoch-step: 79-456 -- Loss: 0.11823368072509766
train-epoch-step: 79-457 -- Loss: 0.2139173150062561
train-epoch-step: 79-458 -- Loss: 0.16038338840007782
train-epoch-step: 79-459 -- Loss: 0.2082272469997406
train-epoch-step: 79-460 -- Loss: 0.1205352246761322
train-epoch-step: 79-461 -- Loss: 0.132699117064476
train-epoch-step: 79-462 -- Loss: 0.15165652334690094
train-epoch-step: 79-463 -- Loss: 0.13441036641597748
train-epoch-step: 79-464 -- Loss: 0.1594911366701126
train-epoch-step: 79-465 -- Loss: 0.23218494653701782
train-epoch-step: 79-466 -- Loss: 0.20757822692394257
train-epoch-step: 79-467 -- Loss: 0.11089315265417099
train-epoch-step: 79-468 -- Loss: 0.16339175403118134
train-epoch-step: 79-469 -- Loss: 0.20424635708332062
train-epoch-step: 79-470 -- Loss: 0.1666242480278015
train-epoch-step: 79-471 -- Loss: 0.1536071002483368
train-epoch-step: 79-472 -- Loss: 0.15148596465587616
train-epoch-step: 79-473 -- Loss: 0.14754223823547363
train-epoch-step: 79-474 -- Loss: 0.11390166729688644
train-epoch-step: 79-475 -- Loss: 0.10842105746269226
train-epoch-step: 79-476 -- Loss: 0.19936597347259521
train-epoch-step: 79-477 -- Loss: 0.18804654479026794
train-epoch-step: 79-478 -- Loss: 0.18490365147590637
train-epoch-step: 79-479 -- Loss: 0.14038939774036407
train-epoch-step: 79-480 -- Loss: 0.19287003576755524
train-epoch-step: 79-481 -- Loss: 0.2770801782608032
train-epoch-step: 79-482 -- Loss: 0.25614050030708313
train-epoch-step: 79-483 -- Loss: 0.18102143704891205
train-epoch-step: 79-484 -- Loss: 0.20607317984104156
train-epoch-step: 79-485 -- Loss: 0.1289123296737671
train-epoch-step: 79-486 -- Loss: 0.22517365217208862
train-epoch-step: 79-487 -- Loss: 0.22980011999607086
train-epoch-step: 79-488 -- Loss: 0.19248972833156586
train-epoch-step: 79-489 -- Loss: 0.2213640660047531
train-epoch-step: 79-490 -- Loss: 0.13445651531219482
train-epoch-step: 79-491 -- Loss: 0.1326209008693695
train-epoch-step: 79-492 -- Loss: 0.12391985207796097
train-epoch-step: 79-493 -- Loss: 0.1911260187625885
train-epoch-step: 79-494 -- Loss: 0.1926848590373993
train-epoch-step: 79-495 -- Loss: 0.19380608201026917
train-epoch-step: 79-496 -- Loss: 0.13830333948135376
train-epoch-step: 79-497 -- Loss: 0.1825873702764511
train-epoch-step: 79-498 -- Loss: 0.148400217294693
train-epoch-step: 79-499 -- Loss: 0.16504991054534912
train-epoch-step: 79-500 -- Loss: 0.14970697462558746
train-epoch-step: 79-501 -- Loss: 0.2064703106880188
train-epoch-step: 79-502 -- Loss: 0.1556215137243271
train-epoch-step: 79-503 -- Loss: 0.2122097611427307
train-epoch-step: 79-504 -- Loss: 0.11442502588033676
train-epoch-step: 79-505 -- Loss: 0.17807084321975708
train-epoch-step: 79-506 -- Loss: 0.11800917983055115
train-epoch-step: 79-507 -- Loss: 0.1743583083152771
train-epoch-step: 79-508 -- Loss: 0.17171958088874817
train-epoch-step: 79-509 -- Loss: 0.16534960269927979
train-epoch-step: 79-510 -- Loss: 0.13114894926548004
train-epoch-step: 79-511 -- Loss: 0.21339118480682373
train-epoch-step: 79-512 -- Loss: 0.17561352252960205
train-epoch-step: 79-513 -- Loss: 0.18388958275318146
train-epoch-step: 79-514 -- Loss: 0.14298513531684875
train-epoch-step: 79-515 -- Loss: 0.15021085739135742
train-epoch-step: 79-516 -- Loss: 0.17007441818714142
train-epoch-step: 79-517 -- Loss: 0.17326293885707855
train-epoch-step: 79-518 -- Loss: 0.1374114751815796
train-epoch-step: 79-519 -- Loss: 0.13681377470493317
train-epoch-step: 79-520 -- Loss: 0.18086062371730804
train-epoch-step: 79-521 -- Loss: 0.23369593918323517
train-epoch-step: 79-522 -- Loss: 0.17486786842346191
train-epoch-step: 79-523 -- Loss: 0.15524044632911682
train-epoch-step: 79-524 -- Loss: 0.16212016344070435
train-epoch-step: 79-525 -- Loss: 0.1874639093875885
train-epoch-step: 79-526 -- Loss: 0.1285133957862854
train-epoch-step: 79-527 -- Loss: 0.14485150575637817
train-epoch-step: 79-528 -- Loss: 0.1627352088689804
train-epoch-step: 79-529 -- Loss: 0.15172772109508514
train-epoch-step: 79-530 -- Loss: 0.16340573132038116
train-epoch-step: 79-531 -- Loss: 0.20006337761878967
train-epoch-step: 79-532 -- Loss: 0.16976019740104675
train-epoch-step: 79-533 -- Loss: 0.17389754951000214
train-epoch-step: 79-534 -- Loss: 0.12716467678546906
train-epoch-step: 79-535 -- Loss: 0.24790841341018677
train-epoch-step: 79-536 -- Loss: 0.161564439535141
train-epoch-step: 79-537 -- Loss: 0.14143501222133636
train-epoch-step: 79-538 -- Loss: 0.10495169460773468
train-epoch-step: 79-539 -- Loss: 0.18115253746509552
train-epoch-step: 79-540 -- Loss: 0.13437281548976898
train-epoch-step: 79-541 -- Loss: 0.20582374930381775
train-epoch-step: 79-542 -- Loss: 0.2286415696144104
train-epoch-step: 79-543 -- Loss: 0.16926538944244385
train-epoch-step: 79-544 -- Loss: 0.21882228553295135
train-epoch-step: 79-545 -- Loss: 0.192361518740654
train-epoch-step: 79-546 -- Loss: 0.20853084325790405
train-epoch-step: 79-547 -- Loss: 0.18925030529499054
train-epoch-step: 79-548 -- Loss: 0.08998233079910278
train-epoch-step: 79-549 -- Loss: 0.14476117491722107
train-epoch-step: 79-550 -- Loss: 0.19677099585533142
train-epoch-step: 79-551 -- Loss: 0.14668507874011993
train-epoch-step: 79-552 -- Loss: 0.1250925213098526
train-epoch-step: 79-553 -- Loss: 0.18754756450653076
train-epoch-step: 79-554 -- Loss: 0.18255610764026642
train-epoch-step: 79-555 -- Loss: 0.2089536041021347
train-epoch-step: 79-556 -- Loss: 0.1485534906387329
train-epoch-step: 79-557 -- Loss: 0.22979362308979034
train-epoch-step: 79-558 -- Loss: 0.2302752435207367
train-epoch-step: 79-559 -- Loss: 0.13409599661827087
train-epoch-step: 79-560 -- Loss: 0.19986678659915924
train-epoch-step: 79-561 -- Loss: 0.17219489812850952
train-epoch-step: 79-562 -- Loss: 0.15904827415943146
train-epoch-step: 79-563 -- Loss: 0.180746391415596
train-epoch-step: 79-564 -- Loss: 0.09807846695184708
train-epoch-step: 79-565 -- Loss: 0.17616534233093262
train-epoch-step: 79-566 -- Loss: 0.1482056826353073
train-epoch-step: 79-567 -- Loss: 0.20009706914424896
train-epoch-step: 79-568 -- Loss: 0.15589168667793274
train-epoch-step: 79-569 -- Loss: 0.23623959720134735
train-epoch-step: 79-570 -- Loss: 0.1726434826850891
train-epoch-step: 79-571 -- Loss: 0.20670637488365173
train-epoch-step: 79-572 -- Loss: 0.23707996308803558
train-epoch-step: 79-573 -- Loss: 0.1934451460838318
train-epoch-step: 79-574 -- Loss: 0.2463097870349884
train-epoch-step: 79-575 -- Loss: 0.2924671471118927
train-epoch-step: 79-576 -- Loss: 0.11323610693216324
train-epoch-step: 79-577 -- Loss: 0.16070839762687683
train-epoch-step: 79-578 -- Loss: 0.20721668004989624
train-epoch-step: 79-579 -- Loss: 0.164584219455719
train-epoch-step: 79-580 -- Loss: 0.1696254312992096
train-epoch-step: 79-581 -- Loss: 0.13727116584777832
train-epoch-step: 79-582 -- Loss: 0.20242030918598175
train-epoch-step: 79-583 -- Loss: 0.21018657088279724
train-epoch-step: 79-584 -- Loss: 0.1588931530714035
train-epoch-step: 79-585 -- Loss: 0.19093036651611328
train-epoch-step: 79-586 -- Loss: 0.243686705827713
train-epoch-step: 79-587 -- Loss: 0.1525537669658661
train-epoch-step: 79-588 -- Loss: 0.12557508051395416
val-epoch-step: 79-589 -- Loss: 0.2060631513595581
val-epoch-step: 79-590 -- Loss: 0.15328195691108704
val-epoch-step: 79-591 -- Loss: 0.24805180728435516
val-epoch-step: 79-592 -- Loss: 0.17066797614097595
val-epoch-step: 79-593 -- Loss: 0.16271069645881653
val-epoch-step: 79-594 -- Loss: 0.4184497594833374
val-epoch-step: 79-595 -- Loss: 0.17825423181056976
val-epoch-step: 79-596 -- Loss: 0.2134309858083725
val-epoch-step: 79-597 -- Loss: 0.16678835451602936
val-epoch-step: 79-598 -- Loss: 0.14328975975513458
val-epoch-step: 79-599 -- Loss: 0.18591374158859253
val-epoch-step: 79-600 -- Loss: 0.1719796359539032
val-epoch-step: 79-601 -- Loss: 0.16543832421302795
val-epoch-step: 79-602 -- Loss: 0.13459067046642303
val-epoch-step: 79-603 -- Loss: 0.2102338969707489
val-epoch-step: 79-604 -- Loss: 0.15857703983783722
val-epoch-step: 79-605 -- Loss: 0.14793993532657623
val-epoch-step: 79-606 -- Loss: 0.27663785219192505
val-epoch-step: 79-607 -- Loss: 0.1283639669418335
val-epoch-step: 79-608 -- Loss: 0.24481499195098877
val-epoch-step: 79-609 -- Loss: 0.17722254991531372
val-epoch-step: 79-610 -- Loss: 0.1717166006565094
val-epoch-step: 79-611 -- Loss: 0.15049681067466736
val-epoch-step: 79-612 -- Loss: 0.4068463146686554
val-epoch-step: 79-613 -- Loss: 0.1687670350074768
val-epoch-step: 79-614 -- Loss: 0.17485857009887695
val-epoch-step: 79-615 -- Loss: 0.17169834673404694
val-epoch-step: 79-616 -- Loss: 0.15388691425323486
val-epoch-step: 79-617 -- Loss: 0.19656747579574585
val-epoch-step: 79-618 -- Loss: 0.17368784546852112
val-epoch-step: 79-619 -- Loss: 0.19708719849586487
val-epoch-step: 79-620 -- Loss: 0.1527710109949112
val-epoch-step: 79-621 -- Loss: 0.12175887823104858
val-epoch-step: 79-622 -- Loss: 0.14428384602069855
val-epoch-step: 79-623 -- Loss: 0.15848299860954285
val-epoch-step: 79-624 -- Loss: 0.1385008543729782
val-epoch-step: 79-625 -- Loss: 0.15559251606464386
val-epoch-step: 79-626 -- Loss: 0.14413034915924072
val-epoch-step: 79-627 -- Loss: 0.18921081721782684
val-epoch-step: 79-628 -- Loss: 0.581445574760437
val-epoch-step: 79-629 -- Loss: 0.20685610175132751
val-epoch-step: 79-630 -- Loss: 0.3388887345790863
val-epoch-step: 79-631 -- Loss: 0.14180760085582733
val-epoch-step: 79-632 -- Loss: 0.20717449486255646
val-epoch-step: 79-633 -- Loss: 0.15060466527938843
val-epoch-step: 79-634 -- Loss: 0.1479332596063614
val-epoch-step: 79-635 -- Loss: 0.11671629548072815
val-epoch-step: 79-636 -- Loss: 0.16640916466712952
val-epoch-step: 79-637 -- Loss: 0.17739331722259521
val-epoch-step: 79-638 -- Loss: 0.15386071801185608
val-epoch-step: 79-639 -- Loss: 0.2529333829879761
val-epoch-step: 79-640 -- Loss: 0.25744932889938354
val-epoch-step: 79-641 -- Loss: 0.13170623779296875
val-epoch-step: 79-642 -- Loss: 0.18464452028274536
val-epoch-step: 79-643 -- Loss: 0.20409566164016724
val-epoch-step: 79-644 -- Loss: 0.15857011079788208
val-epoch-step: 79-645 -- Loss: 0.21745586395263672
val-epoch-step: 79-646 -- Loss: 0.12653127312660217
val-epoch-step: 79-647 -- Loss: 0.12621191143989563
val-epoch-step: 79-648 -- Loss: 0.15527476370334625
val-epoch-step: 79-649 -- Loss: 0.21557649970054626
val-epoch-step: 79-650 -- Loss: 0.2495240867137909
val-epoch-step: 79-651 -- Loss: 0.16262267529964447
val-epoch-step: 79-652 -- Loss: 0.15007250010967255
val-epoch-step: 79-653 -- Loss: 0.19750702381134033
val-epoch-step: 79-654 -- Loss: 0.10995002835988998
Epoch: 79 -- Train Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 80-0 -- Loss: 0.21746627986431122
train-epoch-step: 80-1 -- Loss: 0.14148829877376556
train-epoch-step: 80-2 -- Loss: 0.20175351202487946
train-epoch-step: 80-3 -- Loss: 0.15470097959041595
train-epoch-step: 80-4 -- Loss: 0.15253306925296783
train-epoch-step: 80-5 -- Loss: 0.1734422892332077
train-epoch-step: 80-6 -- Loss: 0.2145272195339203
train-epoch-step: 80-7 -- Loss: 0.1622704714536667
train-epoch-step: 80-8 -- Loss: 0.17672108113765717
train-epoch-step: 80-9 -- Loss: 0.2207484096288681
train-epoch-step: 80-10 -- Loss: 0.20058785378932953
train-epoch-step: 80-11 -- Loss: 0.17064686119556427
train-epoch-step: 80-12 -- Loss: 0.145702064037323
train-epoch-step: 80-13 -- Loss: 0.1773938685655594
train-epoch-step: 80-14 -- Loss: 0.16231295466423035
train-epoch-step: 80-15 -- Loss: 0.15351547300815582
train-epoch-step: 80-16 -- Loss: 0.1593218743801117
train-epoch-step: 80-17 -- Loss: 0.21552419662475586
train-epoch-step: 80-18 -- Loss: 0.1877489537000656
train-epoch-step: 80-19 -- Loss: 0.12774580717086792
train-epoch-step: 80-20 -- Loss: 0.20728200674057007
train-epoch-step: 80-21 -- Loss: 0.2419496476650238
train-epoch-step: 80-22 -- Loss: 0.13589316606521606
train-epoch-step: 80-23 -- Loss: 0.13851375877857208
train-epoch-step: 80-24 -- Loss: 0.12215711176395416
train-epoch-step: 80-25 -- Loss: 0.21674486994743347
train-epoch-step: 80-26 -- Loss: 0.18628597259521484
train-epoch-step: 80-27 -- Loss: 0.22510138154029846
train-epoch-step: 80-28 -- Loss: 0.11907357722520828
train-epoch-step: 80-29 -- Loss: 0.23550987243652344
train-epoch-step: 80-30 -- Loss: 0.10677292197942734
train-epoch-step: 80-31 -- Loss: 0.1320371925830841
train-epoch-step: 80-32 -- Loss: 0.16636483371257782
train-epoch-step: 80-33 -- Loss: 0.2714308500289917
train-epoch-step: 80-34 -- Loss: 0.17045709490776062
train-epoch-step: 80-35 -- Loss: 0.2394537627696991
train-epoch-step: 80-36 -- Loss: 0.14386610686779022
train-epoch-step: 80-37 -- Loss: 0.13604111969470978
train-epoch-step: 80-38 -- Loss: 0.16975858807563782
train-epoch-step: 80-39 -- Loss: 0.21220196783542633
train-epoch-step: 80-40 -- Loss: 0.1942211091518402
train-epoch-step: 80-41 -- Loss: 0.2161896824836731
train-epoch-step: 80-42 -- Loss: 0.1448785960674286
train-epoch-step: 80-43 -- Loss: 0.2513534724712372
train-epoch-step: 80-44 -- Loss: 0.12471060454845428
train-epoch-step: 80-45 -- Loss: 0.12349089235067368
train-epoch-step: 80-46 -- Loss: 0.1672266274690628
train-epoch-step: 80-47 -- Loss: 0.212074413895607
train-epoch-step: 80-48 -- Loss: 0.15535257756710052
train-epoch-step: 80-49 -- Loss: 0.21912714838981628
train-epoch-step: 80-50 -- Loss: 0.10975362360477448
train-epoch-step: 80-51 -- Loss: 0.17811021208763123
train-epoch-step: 80-52 -- Loss: 0.15844881534576416
train-epoch-step: 80-53 -- Loss: 0.20808273553848267
train-epoch-step: 80-54 -- Loss: 0.2937171757221222
train-epoch-step: 80-55 -- Loss: 0.19211189448833466
train-epoch-step: 80-56 -- Loss: 0.1913120150566101
train-epoch-step: 80-57 -- Loss: 0.2459556609392166
train-epoch-step: 80-58 -- Loss: 0.2903654873371124
train-epoch-step: 80-59 -- Loss: 0.23752909898757935
train-epoch-step: 80-60 -- Loss: 0.13169552385807037
train-epoch-step: 80-61 -- Loss: 0.20451796054840088
train-epoch-step: 80-62 -- Loss: 0.18907995522022247
train-epoch-step: 80-63 -- Loss: 0.1418958157300949
train-epoch-step: 80-64 -- Loss: 0.14295102655887604
train-epoch-step: 80-65 -- Loss: 0.20826345682144165
train-epoch-step: 80-66 -- Loss: 0.10848387330770493
train-epoch-step: 80-67 -- Loss: 0.13511905074119568
train-epoch-step: 80-68 -- Loss: 0.23857174813747406
train-epoch-step: 80-69 -- Loss: 0.14021562039852142
train-epoch-step: 80-70 -- Loss: 0.28032004833221436
train-epoch-step: 80-71 -- Loss: 0.2660529315471649
train-epoch-step: 80-72 -- Loss: 0.1911572962999344
train-epoch-step: 80-73 -- Loss: 0.24161523580551147
train-epoch-step: 80-74 -- Loss: 0.09778722375631332
train-epoch-step: 80-75 -- Loss: 0.13343222439289093
train-epoch-step: 80-76 -- Loss: 0.15119922161102295
train-epoch-step: 80-77 -- Loss: 0.23236125707626343
train-epoch-step: 80-78 -- Loss: 0.25575995445251465
train-epoch-step: 80-79 -- Loss: 0.19870635867118835
train-epoch-step: 80-80 -- Loss: 0.2762202024459839
train-epoch-step: 80-81 -- Loss: 0.1323697566986084
train-epoch-step: 80-82 -- Loss: 0.25033053755760193
train-epoch-step: 80-83 -- Loss: 0.18268653750419617
train-epoch-step: 80-84 -- Loss: 0.19834470748901367
train-epoch-step: 80-85 -- Loss: 0.19085803627967834
train-epoch-step: 80-86 -- Loss: 0.12123846262693405
train-epoch-step: 80-87 -- Loss: 0.20886895060539246
train-epoch-step: 80-88 -- Loss: 0.14455285668373108
train-epoch-step: 80-89 -- Loss: 0.20196589827537537
train-epoch-step: 80-90 -- Loss: 0.19079230725765228
train-epoch-step: 80-91 -- Loss: 0.23908719420433044
train-epoch-step: 80-92 -- Loss: 0.15247181057929993
train-epoch-step: 80-93 -- Loss: 0.18199679255485535
train-epoch-step: 80-94 -- Loss: 0.24369126558303833
train-epoch-step: 80-95 -- Loss: 0.18234901130199432
train-epoch-step: 80-96 -- Loss: 0.22005879878997803
train-epoch-step: 80-97 -- Loss: 0.18467533588409424
train-epoch-step: 80-98 -- Loss: 0.15562088787555695
train-epoch-step: 80-99 -- Loss: 0.19593068957328796
train-epoch-step: 80-100 -- Loss: 0.18568271398544312
train-epoch-step: 80-101 -- Loss: 0.2774466276168823
train-epoch-step: 80-102 -- Loss: 0.22761067748069763
train-epoch-step: 80-103 -- Loss: 0.1835457682609558
train-epoch-step: 80-104 -- Loss: 0.15174372494220734
train-epoch-step: 80-105 -- Loss: 0.26819074153900146
train-epoch-step: 80-106 -- Loss: 0.1795470118522644
train-epoch-step: 80-107 -- Loss: 0.1859150528907776
train-epoch-step: 80-108 -- Loss: 0.1928926706314087
train-epoch-step: 80-109 -- Loss: 0.14494548738002777
train-epoch-step: 80-110 -- Loss: 0.19079002737998962
train-epoch-step: 80-111 -- Loss: 0.17960447072982788
train-epoch-step: 80-112 -- Loss: 0.17075152695178986
train-epoch-step: 80-113 -- Loss: 0.15946006774902344
train-epoch-step: 80-114 -- Loss: 0.1888469159603119
train-epoch-step: 80-115 -- Loss: 0.15962344408035278
train-epoch-step: 80-116 -- Loss: 0.13619783520698547
train-epoch-step: 80-117 -- Loss: 0.12588092684745789
train-epoch-step: 80-118 -- Loss: 0.1926010102033615
train-epoch-step: 80-119 -- Loss: 0.14874793589115143
train-epoch-step: 80-120 -- Loss: 0.2522512376308441
train-epoch-step: 80-121 -- Loss: 0.24968485534191132
train-epoch-step: 80-122 -- Loss: 0.21933779120445251
train-epoch-step: 80-123 -- Loss: 0.20351028442382812
train-epoch-step: 80-124 -- Loss: 0.12881672382354736
train-epoch-step: 80-125 -- Loss: 0.1541121006011963
train-epoch-step: 80-126 -- Loss: 0.22506234049797058
train-epoch-step: 80-127 -- Loss: 0.18030096590518951
train-epoch-step: 80-128 -- Loss: 0.17368468642234802
train-epoch-step: 80-129 -- Loss: 0.14857953786849976
train-epoch-step: 80-130 -- Loss: 0.19002312421798706
train-epoch-step: 80-131 -- Loss: 0.13416609168052673
train-epoch-step: 80-132 -- Loss: 0.18621452152729034
train-epoch-step: 80-133 -- Loss: 0.11420024931430817
train-epoch-step: 80-134 -- Loss: 0.1856403350830078
train-epoch-step: 80-135 -- Loss: 0.13504785299301147
train-epoch-step: 80-136 -- Loss: 0.12444926053285599
train-epoch-step: 80-137 -- Loss: 0.24073809385299683
train-epoch-step: 80-138 -- Loss: 0.26744985580444336
train-epoch-step: 80-139 -- Loss: 0.1301310956478119
train-epoch-step: 80-140 -- Loss: 0.20964138209819794
train-epoch-step: 80-141 -- Loss: 0.22510457038879395
train-epoch-step: 80-142 -- Loss: 0.19759884476661682
train-epoch-step: 80-143 -- Loss: 0.1797984540462494
train-epoch-step: 80-144 -- Loss: 0.19788017868995667
train-epoch-step: 80-145 -- Loss: 0.143177792429924
train-epoch-step: 80-146 -- Loss: 0.17623522877693176
train-epoch-step: 80-147 -- Loss: 0.16750192642211914
train-epoch-step: 80-148 -- Loss: 0.16124898195266724
train-epoch-step: 80-149 -- Loss: 0.11925247311592102
train-epoch-step: 80-150 -- Loss: 0.18028222024440765
train-epoch-step: 80-151 -- Loss: 0.1900739073753357
train-epoch-step: 80-152 -- Loss: 0.18768519163131714
train-epoch-step: 80-153 -- Loss: 0.2584732174873352
train-epoch-step: 80-154 -- Loss: 0.13102707266807556
train-epoch-step: 80-155 -- Loss: 0.13367155194282532
train-epoch-step: 80-156 -- Loss: 0.11606945842504501
train-epoch-step: 80-157 -- Loss: 0.16266357898712158
train-epoch-step: 80-158 -- Loss: 0.15886470675468445
train-epoch-step: 80-159 -- Loss: 0.17752724885940552
train-epoch-step: 80-160 -- Loss: 0.21439562737941742
train-epoch-step: 80-161 -- Loss: 0.20386824011802673
train-epoch-step: 80-162 -- Loss: 0.20615530014038086
train-epoch-step: 80-163 -- Loss: 0.18948772549629211
train-epoch-step: 80-164 -- Loss: 0.19281354546546936
train-epoch-step: 80-165 -- Loss: 0.16013656556606293
train-epoch-step: 80-166 -- Loss: 0.12838277220726013
train-epoch-step: 80-167 -- Loss: 0.1333506852388382
train-epoch-step: 80-168 -- Loss: 0.19863033294677734
train-epoch-step: 80-169 -- Loss: 0.1360313892364502
train-epoch-step: 80-170 -- Loss: 0.1930118203163147
train-epoch-step: 80-171 -- Loss: 0.1395929902791977
train-epoch-step: 80-172 -- Loss: 0.25529173016548157
train-epoch-step: 80-173 -- Loss: 0.13445626199245453
train-epoch-step: 80-174 -- Loss: 0.24628287553787231
train-epoch-step: 80-175 -- Loss: 0.18948781490325928
train-epoch-step: 80-176 -- Loss: 0.1397968828678131
train-epoch-step: 80-177 -- Loss: 0.1768312007188797
train-epoch-step: 80-178 -- Loss: 0.17705297470092773
train-epoch-step: 80-179 -- Loss: 0.16326485574245453
train-epoch-step: 80-180 -- Loss: 0.1474495828151703
train-epoch-step: 80-181 -- Loss: 0.16447654366493225
train-epoch-step: 80-182 -- Loss: 0.18815089762210846
train-epoch-step: 80-183 -- Loss: 0.26852914690971375
train-epoch-step: 80-184 -- Loss: 0.1341102123260498
train-epoch-step: 80-185 -- Loss: 0.14512696862220764
train-epoch-step: 80-186 -- Loss: 0.21155397593975067
train-epoch-step: 80-187 -- Loss: 0.209629088640213
train-epoch-step: 80-188 -- Loss: 0.16424152255058289
train-epoch-step: 80-189 -- Loss: 0.10783784836530685
train-epoch-step: 80-190 -- Loss: 0.1857990026473999
train-epoch-step: 80-191 -- Loss: 0.1561652421951294
train-epoch-step: 80-192 -- Loss: 0.22340542078018188
train-epoch-step: 80-193 -- Loss: 0.2070416361093521
train-epoch-step: 80-194 -- Loss: 0.17828555405139923
train-epoch-step: 80-195 -- Loss: 0.16353528201580048
train-epoch-step: 80-196 -- Loss: 0.1643345057964325
train-epoch-step: 80-197 -- Loss: 0.12834486365318298
train-epoch-step: 80-198 -- Loss: 0.12477001547813416
train-epoch-step: 80-199 -- Loss: 0.14829692244529724
train-epoch-step: 80-200 -- Loss: 0.1254960149526596
train-epoch-step: 80-201 -- Loss: 0.18316839635372162
train-epoch-step: 80-202 -- Loss: 0.13390763103961945
train-epoch-step: 80-203 -- Loss: 0.17634811997413635
train-epoch-step: 80-204 -- Loss: 0.13342882692813873
train-epoch-step: 80-205 -- Loss: 0.18197600543498993
train-epoch-step: 80-206 -- Loss: 0.193967804312706
train-epoch-step: 80-207 -- Loss: 0.1507989764213562
train-epoch-step: 80-208 -- Loss: 0.18133148550987244
train-epoch-step: 80-209 -- Loss: 0.1405712515115738
train-epoch-step: 80-210 -- Loss: 0.133881613612175
train-epoch-step: 80-211 -- Loss: 0.2122281938791275
train-epoch-step: 80-212 -- Loss: 0.1995772421360016
train-epoch-step: 80-213 -- Loss: 0.12695781886577606
train-epoch-step: 80-214 -- Loss: 0.14575691521167755
train-epoch-step: 80-215 -- Loss: 0.12341666221618652
train-epoch-step: 80-216 -- Loss: 0.19629526138305664
train-epoch-step: 80-217 -- Loss: 0.20792557299137115
train-epoch-step: 80-218 -- Loss: 0.14733117818832397
train-epoch-step: 80-219 -- Loss: 0.17533740401268005
train-epoch-step: 80-220 -- Loss: 0.12606187164783478
train-epoch-step: 80-221 -- Loss: 0.2032785415649414
train-epoch-step: 80-222 -- Loss: 0.11745025217533112
train-epoch-step: 80-223 -- Loss: 0.16935734450817108
train-epoch-step: 80-224 -- Loss: 0.1854369342327118
train-epoch-step: 80-225 -- Loss: 0.26118338108062744
train-epoch-step: 80-226 -- Loss: 0.20348402857780457
train-epoch-step: 80-227 -- Loss: 0.21454161405563354
train-epoch-step: 80-228 -- Loss: 0.1747666895389557
train-epoch-step: 80-229 -- Loss: 0.1700192093849182
train-epoch-step: 80-230 -- Loss: 0.15634208917617798
train-epoch-step: 80-231 -- Loss: 0.1538398265838623
train-epoch-step: 80-232 -- Loss: 0.18268197774887085
train-epoch-step: 80-233 -- Loss: 0.08412764221429825
train-epoch-step: 80-234 -- Loss: 0.17141024768352509
train-epoch-step: 80-235 -- Loss: 0.1504886895418167
train-epoch-step: 80-236 -- Loss: 0.1831241250038147
train-epoch-step: 80-237 -- Loss: 0.2306302934885025
train-epoch-step: 80-238 -- Loss: 0.15150325000286102
train-epoch-step: 80-239 -- Loss: 0.12466009706258774
train-epoch-step: 80-240 -- Loss: 0.2167082279920578
train-epoch-step: 80-241 -- Loss: 0.15368586778640747
train-epoch-step: 80-242 -- Loss: 0.21308264136314392
train-epoch-step: 80-243 -- Loss: 0.23698173463344574
train-epoch-step: 80-244 -- Loss: 0.20188428461551666
train-epoch-step: 80-245 -- Loss: 0.219036266207695
train-epoch-step: 80-246 -- Loss: 0.22069406509399414
train-epoch-step: 80-247 -- Loss: 0.2033725529909134
train-epoch-step: 80-248 -- Loss: 0.1863611936569214
train-epoch-step: 80-249 -- Loss: 0.1358475238084793
train-epoch-step: 80-250 -- Loss: 0.19532424211502075
train-epoch-step: 80-251 -- Loss: 0.10489857941865921
train-epoch-step: 80-252 -- Loss: 0.1884157806634903
train-epoch-step: 80-253 -- Loss: 0.1364104151725769
train-epoch-step: 80-254 -- Loss: 0.21587295830249786
train-epoch-step: 80-255 -- Loss: 0.14708790183067322
train-epoch-step: 80-256 -- Loss: 0.15221533179283142
train-epoch-step: 80-257 -- Loss: 0.1903776228427887
train-epoch-step: 80-258 -- Loss: 0.14512905478477478
train-epoch-step: 80-259 -- Loss: 0.13204920291900635
train-epoch-step: 80-260 -- Loss: 0.19278354942798615
train-epoch-step: 80-261 -- Loss: 0.167914018034935
train-epoch-step: 80-262 -- Loss: 0.29636314511299133
train-epoch-step: 80-263 -- Loss: 0.20507462322711945
train-epoch-step: 80-264 -- Loss: 0.17231740057468414
train-epoch-step: 80-265 -- Loss: 0.11502476781606674
train-epoch-step: 80-266 -- Loss: 0.15236763656139374
train-epoch-step: 80-267 -- Loss: 0.13119155168533325
train-epoch-step: 80-268 -- Loss: 0.12547333538532257
train-epoch-step: 80-269 -- Loss: 0.1723504364490509
train-epoch-step: 80-270 -- Loss: 0.11550723016262054
train-epoch-step: 80-271 -- Loss: 0.14526434242725372
train-epoch-step: 80-272 -- Loss: 0.11300887167453766
train-epoch-step: 80-273 -- Loss: 0.12419842183589935
train-epoch-step: 80-274 -- Loss: 0.17368382215499878
train-epoch-step: 80-275 -- Loss: 0.19535014033317566
train-epoch-step: 80-276 -- Loss: 0.15775755047798157
train-epoch-step: 80-277 -- Loss: 0.15624889731407166
train-epoch-step: 80-278 -- Loss: 0.13696229457855225
train-epoch-step: 80-279 -- Loss: 0.1439763605594635
train-epoch-step: 80-280 -- Loss: 0.2193261981010437
train-epoch-step: 80-281 -- Loss: 0.17613771557807922
train-epoch-step: 80-282 -- Loss: 0.14006362855434418
train-epoch-step: 80-283 -- Loss: 0.1158519983291626
train-epoch-step: 80-284 -- Loss: 0.14128237962722778
train-epoch-step: 80-285 -- Loss: 0.18669889867305756
train-epoch-step: 80-286 -- Loss: 0.1494983583688736
train-epoch-step: 80-287 -- Loss: 0.19728976488113403
train-epoch-step: 80-288 -- Loss: 0.0908251702785492
train-epoch-step: 80-289 -- Loss: 0.12012570351362228
train-epoch-step: 80-290 -- Loss: 0.17815226316452026
train-epoch-step: 80-291 -- Loss: 0.11502382159233093
train-epoch-step: 80-292 -- Loss: 0.15482714772224426
train-epoch-step: 80-293 -- Loss: 0.13514570891857147
train-epoch-step: 80-294 -- Loss: 0.15302467346191406
train-epoch-step: 80-295 -- Loss: 0.2608887255191803
train-epoch-step: 80-296 -- Loss: 0.16472762823104858
train-epoch-step: 80-297 -- Loss: 0.16894413530826569
train-epoch-step: 80-298 -- Loss: 0.22453570365905762
train-epoch-step: 80-299 -- Loss: 0.14088375866413116
train-epoch-step: 80-300 -- Loss: 0.15923814475536346
train-epoch-step: 80-301 -- Loss: 0.16509991884231567
train-epoch-step: 80-302 -- Loss: 0.21467672288417816
train-epoch-step: 80-303 -- Loss: 0.20038673281669617
train-epoch-step: 80-304 -- Loss: 0.12556958198547363
train-epoch-step: 80-305 -- Loss: 0.13937947154045105
train-epoch-step: 80-306 -- Loss: 0.2131364345550537
train-epoch-step: 80-307 -- Loss: 0.16319237649440765
train-epoch-step: 80-308 -- Loss: 0.21207812428474426
train-epoch-step: 80-309 -- Loss: 0.15576404333114624
train-epoch-step: 80-310 -- Loss: 0.15990343689918518
train-epoch-step: 80-311 -- Loss: 0.15177759528160095
train-epoch-step: 80-312 -- Loss: 0.20148761570453644
train-epoch-step: 80-313 -- Loss: 0.09417663514614105
train-epoch-step: 80-314 -- Loss: 0.1905806064605713
train-epoch-step: 80-315 -- Loss: 0.16267797350883484
train-epoch-step: 80-316 -- Loss: 0.14652808010578156
train-epoch-step: 80-317 -- Loss: 0.13806314766407013
train-epoch-step: 80-318 -- Loss: 0.1545967161655426
train-epoch-step: 80-319 -- Loss: 0.17185795307159424
train-epoch-step: 80-320 -- Loss: 0.1148163378238678
train-epoch-step: 80-321 -- Loss: 0.12675929069519043
train-epoch-step: 80-322 -- Loss: 0.20380747318267822
train-epoch-step: 80-323 -- Loss: 0.15157575905323029
train-epoch-step: 80-324 -- Loss: 0.24582603573799133
train-epoch-step: 80-325 -- Loss: 0.15234805643558502
train-epoch-step: 80-326 -- Loss: 0.16924047470092773
train-epoch-step: 80-327 -- Loss: 0.20841024816036224
train-epoch-step: 80-328 -- Loss: 0.19558115303516388
train-epoch-step: 80-329 -- Loss: 0.3398621082305908
train-epoch-step: 80-330 -- Loss: 0.3622339367866516
train-epoch-step: 80-331 -- Loss: 0.2062782496213913
train-epoch-step: 80-332 -- Loss: 0.09667322039604187
train-epoch-step: 80-333 -- Loss: 0.18117225170135498
train-epoch-step: 80-334 -- Loss: 0.15554308891296387
train-epoch-step: 80-335 -- Loss: 0.17449474334716797
train-epoch-step: 80-336 -- Loss: 0.14741460978984833
train-epoch-step: 80-337 -- Loss: 0.2030901163816452
train-epoch-step: 80-338 -- Loss: 0.15879660844802856
train-epoch-step: 80-339 -- Loss: 0.1367516666650772
train-epoch-step: 80-340 -- Loss: 0.19209957122802734
train-epoch-step: 80-341 -- Loss: 0.13792911171913147
train-epoch-step: 80-342 -- Loss: 0.15888486802577972
train-epoch-step: 80-343 -- Loss: 0.15065748989582062
train-epoch-step: 80-344 -- Loss: 0.16417543590068817
train-epoch-step: 80-345 -- Loss: 0.1397886574268341
train-epoch-step: 80-346 -- Loss: 0.2116827815771103
train-epoch-step: 80-347 -- Loss: 0.15431912243366241
train-epoch-step: 80-348 -- Loss: 0.2022087424993515
train-epoch-step: 80-349 -- Loss: 0.2050684690475464
train-epoch-step: 80-350 -- Loss: 0.28616243600845337
train-epoch-step: 80-351 -- Loss: 0.1912151277065277
train-epoch-step: 80-352 -- Loss: 0.1259169578552246
train-epoch-step: 80-353 -- Loss: 0.19066332280635834
train-epoch-step: 80-354 -- Loss: 0.2815895676612854
train-epoch-step: 80-355 -- Loss: 0.12257659435272217
train-epoch-step: 80-356 -- Loss: 0.11763123422861099
train-epoch-step: 80-357 -- Loss: 0.19551050662994385
train-epoch-step: 80-358 -- Loss: 0.18751993775367737
train-epoch-step: 80-359 -- Loss: 0.15902020037174225
train-epoch-step: 80-360 -- Loss: 0.12917755544185638
train-epoch-step: 80-361 -- Loss: 0.25285840034484863
train-epoch-step: 80-362 -- Loss: 0.17568439245224
train-epoch-step: 80-363 -- Loss: 0.15509763360023499
train-epoch-step: 80-364 -- Loss: 0.18755246698856354
train-epoch-step: 80-365 -- Loss: 0.17597121000289917
train-epoch-step: 80-366 -- Loss: 0.23321077227592468
train-epoch-step: 80-367 -- Loss: 0.22682012617588043
train-epoch-step: 80-368 -- Loss: 0.19910024106502533
train-epoch-step: 80-369 -- Loss: 0.2818673253059387
train-epoch-step: 80-370 -- Loss: 0.12497209012508392
train-epoch-step: 80-371 -- Loss: 0.12146452069282532
train-epoch-step: 80-372 -- Loss: 0.14677655696868896
train-epoch-step: 80-373 -- Loss: 0.19247934222221375
train-epoch-step: 80-374 -- Loss: 0.16056373715400696
train-epoch-step: 80-375 -- Loss: 0.2617030143737793
train-epoch-step: 80-376 -- Loss: 0.1688045859336853
train-epoch-step: 80-377 -- Loss: 0.2244061827659607
train-epoch-step: 80-378 -- Loss: 0.19595104455947876
train-epoch-step: 80-379 -- Loss: 0.11786339432001114
train-epoch-step: 80-380 -- Loss: 0.08818915486335754
train-epoch-step: 80-381 -- Loss: 0.2490142285823822
train-epoch-step: 80-382 -- Loss: 0.2349180281162262
train-epoch-step: 80-383 -- Loss: 0.17599688470363617
train-epoch-step: 80-384 -- Loss: 0.24265897274017334
train-epoch-step: 80-385 -- Loss: 0.19526273012161255
train-epoch-step: 80-386 -- Loss: 0.19601725041866302
train-epoch-step: 80-387 -- Loss: 0.20379912853240967
train-epoch-step: 80-388 -- Loss: 0.19134165346622467
train-epoch-step: 80-389 -- Loss: 0.16776296496391296
train-epoch-step: 80-390 -- Loss: 0.15365508198738098
train-epoch-step: 80-391 -- Loss: 0.147178515791893
train-epoch-step: 80-392 -- Loss: 0.18484701216220856
train-epoch-step: 80-393 -- Loss: 0.15651942789554596
train-epoch-step: 80-394 -- Loss: 0.20338091254234314
train-epoch-step: 80-395 -- Loss: 0.1657068431377411
train-epoch-step: 80-396 -- Loss: 0.12642914056777954
train-epoch-step: 80-397 -- Loss: 0.1243487298488617
train-epoch-step: 80-398 -- Loss: 0.20821842551231384
train-epoch-step: 80-399 -- Loss: 0.17603999376296997
train-epoch-step: 80-400 -- Loss: 0.27749136090278625
train-epoch-step: 80-401 -- Loss: 0.12369188666343689
train-epoch-step: 80-402 -- Loss: 0.25867950916290283
train-epoch-step: 80-403 -- Loss: 0.15578541159629822
train-epoch-step: 80-404 -- Loss: 0.1360081434249878
train-epoch-step: 80-405 -- Loss: 0.1481502652168274
train-epoch-step: 80-406 -- Loss: 0.1760074645280838
train-epoch-step: 80-407 -- Loss: 0.1112462654709816
train-epoch-step: 80-408 -- Loss: 0.160756453871727
train-epoch-step: 80-409 -- Loss: 0.1710844784975052
train-epoch-step: 80-410 -- Loss: 0.17932070791721344
train-epoch-step: 80-411 -- Loss: 0.20765741169452667
train-epoch-step: 80-412 -- Loss: 0.13178405165672302
train-epoch-step: 80-413 -- Loss: 0.14366647601127625
train-epoch-step: 80-414 -- Loss: 0.1300966590642929
train-epoch-step: 80-415 -- Loss: 0.13436317443847656
train-epoch-step: 80-416 -- Loss: 0.2602421045303345
train-epoch-step: 80-417 -- Loss: 0.1966179758310318
train-epoch-step: 80-418 -- Loss: 0.2257707417011261
train-epoch-step: 80-419 -- Loss: 0.16458359360694885
train-epoch-step: 80-420 -- Loss: 0.1473092883825302
train-epoch-step: 80-421 -- Loss: 0.17554564774036407
train-epoch-step: 80-422 -- Loss: 0.14335685968399048
train-epoch-step: 80-423 -- Loss: 0.17301544547080994
train-epoch-step: 80-424 -- Loss: 0.14241522550582886
train-epoch-step: 80-425 -- Loss: 0.1842217594385147
train-epoch-step: 80-426 -- Loss: 0.1661655455827713
train-epoch-step: 80-427 -- Loss: 0.11940950900316238
train-epoch-step: 80-428 -- Loss: 0.21213631331920624
train-epoch-step: 80-429 -- Loss: 0.17654484510421753
train-epoch-step: 80-430 -- Loss: 0.1466195285320282
train-epoch-step: 80-431 -- Loss: 0.15791615843772888
train-epoch-step: 80-432 -- Loss: 0.23851731419563293
train-epoch-step: 80-433 -- Loss: 0.14074896275997162
train-epoch-step: 80-434 -- Loss: 0.12584620714187622
train-epoch-step: 80-435 -- Loss: 0.15563632547855377
train-epoch-step: 80-436 -- Loss: 0.16136154532432556
train-epoch-step: 80-437 -- Loss: 0.1309768706560135
train-epoch-step: 80-438 -- Loss: 0.16885292530059814
train-epoch-step: 80-439 -- Loss: 0.26091182231903076
train-epoch-step: 80-440 -- Loss: 0.12825509905815125
train-epoch-step: 80-441 -- Loss: 0.19845160841941833
train-epoch-step: 80-442 -- Loss: 0.16868868470191956
train-epoch-step: 80-443 -- Loss: 0.157709538936615
train-epoch-step: 80-444 -- Loss: 0.23279699683189392
train-epoch-step: 80-445 -- Loss: 0.17342928051948547
train-epoch-step: 80-446 -- Loss: 0.160223126411438
train-epoch-step: 80-447 -- Loss: 0.1866459995508194
train-epoch-step: 80-448 -- Loss: 0.22102703154087067
train-epoch-step: 80-449 -- Loss: 0.19137661159038544
train-epoch-step: 80-450 -- Loss: 0.179470494389534
train-epoch-step: 80-451 -- Loss: 0.14580696821212769
train-epoch-step: 80-452 -- Loss: 0.13536331057548523
train-epoch-step: 80-453 -- Loss: 0.09226080030202866
train-epoch-step: 80-454 -- Loss: 0.22262108325958252
train-epoch-step: 80-455 -- Loss: 0.12202486395835876
train-epoch-step: 80-456 -- Loss: 0.12031415849924088
train-epoch-step: 80-457 -- Loss: 0.2170165777206421
train-epoch-step: 80-458 -- Loss: 0.2620372176170349
train-epoch-step: 80-459 -- Loss: 0.25717782974243164
train-epoch-step: 80-460 -- Loss: 0.15458649396896362
train-epoch-step: 80-461 -- Loss: 0.13475823402404785
train-epoch-step: 80-462 -- Loss: 0.15916763246059418
train-epoch-step: 80-463 -- Loss: 0.14671820402145386
train-epoch-step: 80-464 -- Loss: 0.17140012979507446
train-epoch-step: 80-465 -- Loss: 0.23690995573997498
train-epoch-step: 80-466 -- Loss: 0.21080635488033295
train-epoch-step: 80-467 -- Loss: 0.116541288793087
train-epoch-step: 80-468 -- Loss: 0.18937967717647552
train-epoch-step: 80-469 -- Loss: 0.21273793280124664
train-epoch-step: 80-470 -- Loss: 0.16689351201057434
train-epoch-step: 80-471 -- Loss: 0.1713874191045761
train-epoch-step: 80-472 -- Loss: 0.16030211746692657
train-epoch-step: 80-473 -- Loss: 0.1546204388141632
train-epoch-step: 80-474 -- Loss: 0.12266635149717331
train-epoch-step: 80-475 -- Loss: 0.10985051840543747
train-epoch-step: 80-476 -- Loss: 0.20026257634162903
train-epoch-step: 80-477 -- Loss: 0.20082390308380127
train-epoch-step: 80-478 -- Loss: 0.1930060088634491
train-epoch-step: 80-479 -- Loss: 0.14096805453300476
train-epoch-step: 80-480 -- Loss: 0.18960294127464294
train-epoch-step: 80-481 -- Loss: 0.2913828492164612
train-epoch-step: 80-482 -- Loss: 0.2614138722419739
train-epoch-step: 80-483 -- Loss: 0.18191349506378174
train-epoch-step: 80-484 -- Loss: 0.20814234018325806
train-epoch-step: 80-485 -- Loss: 0.1629558503627777
train-epoch-step: 80-486 -- Loss: 0.23445960879325867
train-epoch-step: 80-487 -- Loss: 0.22868026793003082
train-epoch-step: 80-488 -- Loss: 0.19836768507957458
train-epoch-step: 80-489 -- Loss: 0.22931423783302307
train-epoch-step: 80-490 -- Loss: 0.13554875552654266
train-epoch-step: 80-491 -- Loss: 0.13974890112876892
train-epoch-step: 80-492 -- Loss: 0.1351393163204193
train-epoch-step: 80-493 -- Loss: 0.2031709849834442
train-epoch-step: 80-494 -- Loss: 0.2058238685131073
train-epoch-step: 80-495 -- Loss: 0.200452983379364
train-epoch-step: 80-496 -- Loss: 0.14496687054634094
train-epoch-step: 80-497 -- Loss: 0.18838825821876526
train-epoch-step: 80-498 -- Loss: 0.14958812296390533
train-epoch-step: 80-499 -- Loss: 0.17468899488449097
train-epoch-step: 80-500 -- Loss: 0.1544445902109146
train-epoch-step: 80-501 -- Loss: 0.21170508861541748
train-epoch-step: 80-502 -- Loss: 0.15775133669376373
train-epoch-step: 80-503 -- Loss: 0.21918100118637085
train-epoch-step: 80-504 -- Loss: 0.126537024974823
train-epoch-step: 80-505 -- Loss: 0.17914611101150513
train-epoch-step: 80-506 -- Loss: 0.11686274409294128
train-epoch-step: 80-507 -- Loss: 0.18725618720054626
train-epoch-step: 80-508 -- Loss: 0.17046760022640228
train-epoch-step: 80-509 -- Loss: 0.16487114131450653
train-epoch-step: 80-510 -- Loss: 0.12783163785934448
train-epoch-step: 80-511 -- Loss: 0.2224259227514267
train-epoch-step: 80-512 -- Loss: 0.18694578111171722
train-epoch-step: 80-513 -- Loss: 0.1987379491329193
train-epoch-step: 80-514 -- Loss: 0.1409795731306076
train-epoch-step: 80-515 -- Loss: 0.15090639889240265
train-epoch-step: 80-516 -- Loss: 0.17659272253513336
train-epoch-step: 80-517 -- Loss: 0.17354688048362732
train-epoch-step: 80-518 -- Loss: 0.1404019445180893
train-epoch-step: 80-519 -- Loss: 0.13463513553142548
train-epoch-step: 80-520 -- Loss: 0.18304765224456787
train-epoch-step: 80-521 -- Loss: 0.2305697798728943
train-epoch-step: 80-522 -- Loss: 0.17542532086372375
train-epoch-step: 80-523 -- Loss: 0.15648891031742096
train-epoch-step: 80-524 -- Loss: 0.16630181670188904
train-epoch-step: 80-525 -- Loss: 0.2000376135110855
train-epoch-step: 80-526 -- Loss: 0.13645219802856445
train-epoch-step: 80-527 -- Loss: 0.1508311778306961
train-epoch-step: 80-528 -- Loss: 0.15464042127132416
train-epoch-step: 80-529 -- Loss: 0.1585155725479126
train-epoch-step: 80-530 -- Loss: 0.16986826062202454
train-epoch-step: 80-531 -- Loss: 0.1963856816291809
train-epoch-step: 80-532 -- Loss: 0.17019380629062653
train-epoch-step: 80-533 -- Loss: 0.16982853412628174
train-epoch-step: 80-534 -- Loss: 0.1355932652950287
train-epoch-step: 80-535 -- Loss: 0.26508694887161255
train-epoch-step: 80-536 -- Loss: 0.16307386755943298
train-epoch-step: 80-537 -- Loss: 0.14911417663097382
train-epoch-step: 80-538 -- Loss: 0.10687019675970078
train-epoch-step: 80-539 -- Loss: 0.20730817317962646
train-epoch-step: 80-540 -- Loss: 0.13589726388454437
train-epoch-step: 80-541 -- Loss: 0.21501971781253815
train-epoch-step: 80-542 -- Loss: 0.2237546741962433
train-epoch-step: 80-543 -- Loss: 0.17340689897537231
train-epoch-step: 80-544 -- Loss: 0.23063087463378906
train-epoch-step: 80-545 -- Loss: 0.20634306967258453
train-epoch-step: 80-546 -- Loss: 0.19889318943023682
train-epoch-step: 80-547 -- Loss: 0.1832093596458435
train-epoch-step: 80-548 -- Loss: 0.09576188027858734
train-epoch-step: 80-549 -- Loss: 0.14708608388900757
train-epoch-step: 80-550 -- Loss: 0.20422415435314178
train-epoch-step: 80-551 -- Loss: 0.1588120311498642
train-epoch-step: 80-552 -- Loss: 0.12665152549743652
train-epoch-step: 80-553 -- Loss: 0.18994563817977905
train-epoch-step: 80-554 -- Loss: 0.19305413961410522
train-epoch-step: 80-555 -- Loss: 0.24019014835357666
train-epoch-step: 80-556 -- Loss: 0.15792547166347504
train-epoch-step: 80-557 -- Loss: 0.23251891136169434
train-epoch-step: 80-558 -- Loss: 0.22875939309597015
train-epoch-step: 80-559 -- Loss: 0.1473737508058548
train-epoch-step: 80-560 -- Loss: 0.20329853892326355
train-epoch-step: 80-561 -- Loss: 0.18696478009223938
train-epoch-step: 80-562 -- Loss: 0.16018354892730713
train-epoch-step: 80-563 -- Loss: 0.19476422667503357
train-epoch-step: 80-564 -- Loss: 0.09787385910749435
train-epoch-step: 80-565 -- Loss: 0.18106399476528168
train-epoch-step: 80-566 -- Loss: 0.15276162326335907
train-epoch-step: 80-567 -- Loss: 0.2097901850938797
train-epoch-step: 80-568 -- Loss: 0.16422811150550842
train-epoch-step: 80-569 -- Loss: 0.24152551591396332
train-epoch-step: 80-570 -- Loss: 0.17741583287715912
train-epoch-step: 80-571 -- Loss: 0.2167954444885254
train-epoch-step: 80-572 -- Loss: 0.24384789168834686
train-epoch-step: 80-573 -- Loss: 0.20151981711387634
train-epoch-step: 80-574 -- Loss: 0.24037152528762817
train-epoch-step: 80-575 -- Loss: 0.2899426519870758
train-epoch-step: 80-576 -- Loss: 0.11561337113380432
train-epoch-step: 80-577 -- Loss: 0.16384008526802063
train-epoch-step: 80-578 -- Loss: 0.2131526917219162
train-epoch-step: 80-579 -- Loss: 0.16381557285785675
train-epoch-step: 80-580 -- Loss: 0.17073090374469757
train-epoch-step: 80-581 -- Loss: 0.14588379859924316
train-epoch-step: 80-582 -- Loss: 0.2031760811805725
train-epoch-step: 80-583 -- Loss: 0.22239017486572266
train-epoch-step: 80-584 -- Loss: 0.16222412884235382
train-epoch-step: 80-585 -- Loss: 0.19162434339523315
train-epoch-step: 80-586 -- Loss: 0.25927820801734924
train-epoch-step: 80-587 -- Loss: 0.15761014819145203
train-epoch-step: 80-588 -- Loss: 0.1281816065311432
val-epoch-step: 80-589 -- Loss: 0.2507613003253937
val-epoch-step: 80-590 -- Loss: 0.15712419152259827
val-epoch-step: 80-591 -- Loss: 0.24439027905464172
val-epoch-step: 80-592 -- Loss: 0.17777976393699646
val-epoch-step: 80-593 -- Loss: 0.16663521528244019
val-epoch-step: 80-594 -- Loss: 0.3609064817428589
val-epoch-step: 80-595 -- Loss: 0.17956647276878357
val-epoch-step: 80-596 -- Loss: 0.19538410007953644
val-epoch-step: 80-597 -- Loss: 0.17631061375141144
val-epoch-step: 80-598 -- Loss: 0.1504274159669876
val-epoch-step: 80-599 -- Loss: 0.18337124586105347
val-epoch-step: 80-600 -- Loss: 0.17051252722740173
val-epoch-step: 80-601 -- Loss: 0.15918898582458496
val-epoch-step: 80-602 -- Loss: 0.13992707431316376
val-epoch-step: 80-603 -- Loss: 0.19787847995758057
val-epoch-step: 80-604 -- Loss: 0.1578444540500641
val-epoch-step: 80-605 -- Loss: 0.14935460686683655
val-epoch-step: 80-606 -- Loss: 0.2644839286804199
val-epoch-step: 80-607 -- Loss: 0.1269885003566742
val-epoch-step: 80-608 -- Loss: 0.24428774416446686
val-epoch-step: 80-609 -- Loss: 0.18590691685676575
val-epoch-step: 80-610 -- Loss: 0.17854808270931244
val-epoch-step: 80-611 -- Loss: 0.15183815360069275
val-epoch-step: 80-612 -- Loss: 0.29997795820236206
val-epoch-step: 80-613 -- Loss: 0.1782199591398239
val-epoch-step: 80-614 -- Loss: 0.17643965780735016
val-epoch-step: 80-615 -- Loss: 0.17684921622276306
val-epoch-step: 80-616 -- Loss: 0.15053947269916534
val-epoch-step: 80-617 -- Loss: 0.19287452101707458
val-epoch-step: 80-618 -- Loss: 0.17583920061588287
val-epoch-step: 80-619 -- Loss: 0.2004481554031372
val-epoch-step: 80-620 -- Loss: 0.1406363993883133
val-epoch-step: 80-621 -- Loss: 0.12490329146385193
val-epoch-step: 80-622 -- Loss: 0.1492888182401657
val-epoch-step: 80-623 -- Loss: 0.15293137729167938
val-epoch-step: 80-624 -- Loss: 0.1385204941034317
val-epoch-step: 80-625 -- Loss: 0.1561870574951172
val-epoch-step: 80-626 -- Loss: 0.14800599217414856
val-epoch-step: 80-627 -- Loss: 0.19808577001094818
val-epoch-step: 80-628 -- Loss: 0.5622053742408752
val-epoch-step: 80-629 -- Loss: 0.20798546075820923
val-epoch-step: 80-630 -- Loss: 0.34640276432037354
val-epoch-step: 80-631 -- Loss: 0.14915038645267487
val-epoch-step: 80-632 -- Loss: 0.21792484819889069
val-epoch-step: 80-633 -- Loss: 0.1542450487613678
val-epoch-step: 80-634 -- Loss: 0.15572689473628998
val-epoch-step: 80-635 -- Loss: 0.12385290861129761
val-epoch-step: 80-636 -- Loss: 0.16020351648330688
val-epoch-step: 80-637 -- Loss: 0.1821615993976593
val-epoch-step: 80-638 -- Loss: 0.15277718007564545
val-epoch-step: 80-639 -- Loss: 0.26330453157424927
val-epoch-step: 80-640 -- Loss: 0.24871425330638885
val-epoch-step: 80-641 -- Loss: 0.13891306519508362
val-epoch-step: 80-642 -- Loss: 0.18003223836421967
val-epoch-step: 80-643 -- Loss: 0.20777110755443573
val-epoch-step: 80-644 -- Loss: 0.1687062680721283
val-epoch-step: 80-645 -- Loss: 0.22160957753658295
val-epoch-step: 80-646 -- Loss: 0.1274774819612503
val-epoch-step: 80-647 -- Loss: 0.13598453998565674
val-epoch-step: 80-648 -- Loss: 0.15792372822761536
val-epoch-step: 80-649 -- Loss: 0.20561867952346802
val-epoch-step: 80-650 -- Loss: 0.25373685359954834
val-epoch-step: 80-651 -- Loss: 0.15085801482200623
val-epoch-step: 80-652 -- Loss: 0.16821566224098206
val-epoch-step: 80-653 -- Loss: 0.20396344363689423
val-epoch-step: 80-654 -- Loss: 0.11171269416809082
Epoch: 80 -- Train Loss: tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.43 -- Val Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.43
                         Test Loss: 0.0 -- Test Acc: 75.43
train-epoch-step: 81-0 -- Loss: 0.22560963034629822
train-epoch-step: 81-1 -- Loss: 0.1446538269519806
train-epoch-step: 81-2 -- Loss: 0.19686083495616913
train-epoch-step: 81-3 -- Loss: 0.1396442949771881
train-epoch-step: 81-4 -- Loss: 0.16020649671554565
train-epoch-step: 81-5 -- Loss: 0.17757591605186462
train-epoch-step: 81-6 -- Loss: 0.22391444444656372
train-epoch-step: 81-7 -- Loss: 0.16953933238983154
train-epoch-step: 81-8 -- Loss: 0.20083752274513245
train-epoch-step: 81-9 -- Loss: 0.2286774218082428
train-epoch-step: 81-10 -- Loss: 0.1899932324886322
train-epoch-step: 81-11 -- Loss: 0.1688484251499176
train-epoch-step: 81-12 -- Loss: 0.1478181779384613
train-epoch-step: 81-13 -- Loss: 0.17460758984088898
train-epoch-step: 81-14 -- Loss: 0.1655321568250656
train-epoch-step: 81-15 -- Loss: 0.15639758110046387
train-epoch-step: 81-16 -- Loss: 0.16802483797073364
train-epoch-step: 81-17 -- Loss: 0.23137027025222778
train-epoch-step: 81-18 -- Loss: 0.1941029280424118
train-epoch-step: 81-19 -- Loss: 0.13253432512283325
train-epoch-step: 81-20 -- Loss: 0.20784467458724976
train-epoch-step: 81-21 -- Loss: 0.2489180862903595
train-epoch-step: 81-22 -- Loss: 0.14531317353248596
train-epoch-step: 81-23 -- Loss: 0.14719650149345398
train-epoch-step: 81-24 -- Loss: 0.12457769364118576
train-epoch-step: 81-25 -- Loss: 0.2337770015001297
train-epoch-step: 81-26 -- Loss: 0.1895683854818344
train-epoch-step: 81-27 -- Loss: 0.2221388816833496
train-epoch-step: 81-28 -- Loss: 0.12589134275913239
train-epoch-step: 81-29 -- Loss: 0.24272873997688293
train-epoch-step: 81-30 -- Loss: 0.10677915811538696
train-epoch-step: 81-31 -- Loss: 0.1355799436569214
train-epoch-step: 81-32 -- Loss: 0.16972258687019348
train-epoch-step: 81-33 -- Loss: 0.2646278142929077
train-epoch-step: 81-34 -- Loss: 0.17540457844734192
train-epoch-step: 81-35 -- Loss: 0.24240395426750183
train-epoch-step: 81-36 -- Loss: 0.1530660092830658
train-epoch-step: 81-37 -- Loss: 0.13746050000190735
train-epoch-step: 81-38 -- Loss: 0.19277359545230865
train-epoch-step: 81-39 -- Loss: 0.22603310644626617
train-epoch-step: 81-40 -- Loss: 0.19980674982070923
train-epoch-step: 81-41 -- Loss: 0.21958914399147034
train-epoch-step: 81-42 -- Loss: 0.1532885730266571
train-epoch-step: 81-43 -- Loss: 0.25683778524398804
train-epoch-step: 81-44 -- Loss: 0.1223110556602478
train-epoch-step: 81-45 -- Loss: 0.11811800301074982
train-epoch-step: 81-46 -- Loss: 0.16521617770195007
train-epoch-step: 81-47 -- Loss: 0.23187470436096191
train-epoch-step: 81-48 -- Loss: 0.15094727277755737
train-epoch-step: 81-49 -- Loss: 0.2243676483631134
train-epoch-step: 81-50 -- Loss: 0.10912679880857468
train-epoch-step: 81-51 -- Loss: 0.17633585631847382
train-epoch-step: 81-52 -- Loss: 0.15901578962802887
train-epoch-step: 81-53 -- Loss: 0.20828285813331604
train-epoch-step: 81-54 -- Loss: 0.305117666721344
train-epoch-step: 81-55 -- Loss: 0.19434240460395813
train-epoch-step: 81-56 -- Loss: 0.19442889094352722
train-epoch-step: 81-57 -- Loss: 0.29439815878868103
train-epoch-step: 81-58 -- Loss: 0.33505260944366455
train-epoch-step: 81-59 -- Loss: 0.27569514513015747
train-epoch-step: 81-60 -- Loss: 0.13406683504581451
train-epoch-step: 81-61 -- Loss: 0.22783976793289185
train-epoch-step: 81-62 -- Loss: 0.19230186939239502
train-epoch-step: 81-63 -- Loss: 0.1413823664188385
train-epoch-step: 81-64 -- Loss: 0.18694743514060974
train-epoch-step: 81-65 -- Loss: 0.20589648187160492
train-epoch-step: 81-66 -- Loss: 0.10949467867612839
train-epoch-step: 81-67 -- Loss: 0.13151615858078003
train-epoch-step: 81-68 -- Loss: 0.2658120393753052
train-epoch-step: 81-69 -- Loss: 0.13761155307292938
train-epoch-step: 81-70 -- Loss: 0.24669653177261353
train-epoch-step: 81-71 -- Loss: 0.266956627368927
train-epoch-step: 81-72 -- Loss: 0.17680548131465912
train-epoch-step: 81-73 -- Loss: 0.20377041399478912
train-epoch-step: 81-74 -- Loss: 0.09516210854053497
train-epoch-step: 81-75 -- Loss: 0.13813266158103943
train-epoch-step: 81-76 -- Loss: 0.15290921926498413
train-epoch-step: 81-77 -- Loss: 0.24354805052280426
train-epoch-step: 81-78 -- Loss: 0.26200559735298157
train-epoch-step: 81-79 -- Loss: 0.19028517603874207
train-epoch-step: 81-80 -- Loss: 0.25261545181274414
train-epoch-step: 81-81 -- Loss: 0.12833629548549652
train-epoch-step: 81-82 -- Loss: 0.2580749988555908
train-epoch-step: 81-83 -- Loss: 0.17517328262329102
train-epoch-step: 81-84 -- Loss: 0.18814149498939514
train-epoch-step: 81-85 -- Loss: 0.1757848709821701
train-epoch-step: 81-86 -- Loss: 0.12164714932441711
train-epoch-step: 81-87 -- Loss: 0.22654634714126587
train-epoch-step: 81-88 -- Loss: 0.14976225793361664
train-epoch-step: 81-89 -- Loss: 0.184298574924469
train-epoch-step: 81-90 -- Loss: 0.18999402225017548
train-epoch-step: 81-91 -- Loss: 0.24687808752059937
train-epoch-step: 81-92 -- Loss: 0.1512194275856018
train-epoch-step: 81-93 -- Loss: 0.18516455590724945
train-epoch-step: 81-94 -- Loss: 0.23248766362667084
train-epoch-step: 81-95 -- Loss: 0.18857865035533905
train-epoch-step: 81-96 -- Loss: 0.2172732651233673
train-epoch-step: 81-97 -- Loss: 0.17833250761032104
train-epoch-step: 81-98 -- Loss: 0.15285608172416687
train-epoch-step: 81-99 -- Loss: 0.19367358088493347
train-epoch-step: 81-100 -- Loss: 0.18818029761314392
train-epoch-step: 81-101 -- Loss: 0.26954954862594604
train-epoch-step: 81-102 -- Loss: 0.23116976022720337
train-epoch-step: 81-103 -- Loss: 0.1881447583436966
train-epoch-step: 81-104 -- Loss: 0.1482313573360443
train-epoch-step: 81-105 -- Loss: 0.2735685706138611
train-epoch-step: 81-106 -- Loss: 0.17429302632808685
train-epoch-step: 81-107 -- Loss: 0.18979313969612122
train-epoch-step: 81-108 -- Loss: 0.18889173865318298
train-epoch-step: 81-109 -- Loss: 0.1494554579257965
train-epoch-step: 81-110 -- Loss: 0.18135982751846313
train-epoch-step: 81-111 -- Loss: 0.1832985281944275
train-epoch-step: 81-112 -- Loss: 0.17598477005958557
train-epoch-step: 81-113 -- Loss: 0.16376248002052307
train-epoch-step: 81-114 -- Loss: 0.19581124186515808
train-epoch-step: 81-115 -- Loss: 0.15995606780052185
train-epoch-step: 81-116 -- Loss: 0.13861118257045746
train-epoch-step: 81-117 -- Loss: 0.13157472014427185
train-epoch-step: 81-118 -- Loss: 0.19649505615234375
train-epoch-step: 81-119 -- Loss: 0.15312771499156952
train-epoch-step: 81-120 -- Loss: 0.24465057253837585
train-epoch-step: 81-121 -- Loss: 0.251986563205719
train-epoch-step: 81-122 -- Loss: 0.2197227030992508
train-epoch-step: 81-123 -- Loss: 0.20973169803619385
train-epoch-step: 81-124 -- Loss: 0.12728263437747955
train-epoch-step: 81-125 -- Loss: 0.15024235844612122
train-epoch-step: 81-126 -- Loss: 0.22685740888118744
train-epoch-step: 81-127 -- Loss: 0.17194782197475433
train-epoch-step: 81-128 -- Loss: 0.17190533876419067
train-epoch-step: 81-129 -- Loss: 0.14031624794006348
train-epoch-step: 81-130 -- Loss: 0.19582337141036987
train-epoch-step: 81-131 -- Loss: 0.1365511566400528
train-epoch-step: 81-132 -- Loss: 0.18701285123825073
train-epoch-step: 81-133 -- Loss: 0.11969068646430969
train-epoch-step: 81-134 -- Loss: 0.1856333166360855
train-epoch-step: 81-135 -- Loss: 0.13674071431159973
train-epoch-step: 81-136 -- Loss: 0.1322244554758072
train-epoch-step: 81-137 -- Loss: 0.23854491114616394
train-epoch-step: 81-138 -- Loss: 0.2642163634300232
train-epoch-step: 81-139 -- Loss: 0.131069615483284
train-epoch-step: 81-140 -- Loss: 0.20891597867012024
train-epoch-step: 81-141 -- Loss: 0.22796586155891418
train-epoch-step: 81-142 -- Loss: 0.19873130321502686
train-epoch-step: 81-143 -- Loss: 0.18411527574062347
train-epoch-step: 81-144 -- Loss: 0.18421988189220428
train-epoch-step: 81-145 -- Loss: 0.1432201862335205
train-epoch-step: 81-146 -- Loss: 0.17601801455020905
train-epoch-step: 81-147 -- Loss: 0.1657598912715912
train-epoch-step: 81-148 -- Loss: 0.16524019837379456
train-epoch-step: 81-149 -- Loss: 0.11921393871307373
train-epoch-step: 81-150 -- Loss: 0.17942732572555542
train-epoch-step: 81-151 -- Loss: 0.1828634887933731
train-epoch-step: 81-152 -- Loss: 0.18401780724525452
train-epoch-step: 81-153 -- Loss: 0.2621981203556061
train-epoch-step: 81-154 -- Loss: 0.13090205192565918
train-epoch-step: 81-155 -- Loss: 0.13619810342788696
train-epoch-step: 81-156 -- Loss: 0.11509011685848236
train-epoch-step: 81-157 -- Loss: 0.1803199052810669
train-epoch-step: 81-158 -- Loss: 0.16140078008174896
train-epoch-step: 81-159 -- Loss: 0.17731288075447083
train-epoch-step: 81-160 -- Loss: 0.21862921118736267
train-epoch-step: 81-161 -- Loss: 0.20101645588874817
train-epoch-step: 81-162 -- Loss: 0.2138078659772873
train-epoch-step: 81-163 -- Loss: 0.185526505112648
train-epoch-step: 81-164 -- Loss: 0.1884515881538391
train-epoch-step: 81-165 -- Loss: 0.15775716304779053
train-epoch-step: 81-166 -- Loss: 0.11701339483261108
train-epoch-step: 81-167 -- Loss: 0.13176099956035614
train-epoch-step: 81-168 -- Loss: 0.19865275919437408
train-epoch-step: 81-169 -- Loss: 0.1332739293575287
train-epoch-step: 81-170 -- Loss: 0.19636136293411255
train-epoch-step: 81-171 -- Loss: 0.14162151515483856
train-epoch-step: 81-172 -- Loss: 0.2579144835472107
train-epoch-step: 81-173 -- Loss: 0.1327459216117859
train-epoch-step: 81-174 -- Loss: 0.24880531430244446
train-epoch-step: 81-175 -- Loss: 0.18323859572410583
train-epoch-step: 81-176 -- Loss: 0.13230712711811066
train-epoch-step: 81-177 -- Loss: 0.18008984625339508
train-epoch-step: 81-178 -- Loss: 0.17506130039691925
train-epoch-step: 81-179 -- Loss: 0.14747285842895508
train-epoch-step: 81-180 -- Loss: 0.14707189798355103
train-epoch-step: 81-181 -- Loss: 0.16698873043060303
train-epoch-step: 81-182 -- Loss: 0.1771770417690277
train-epoch-step: 81-183 -- Loss: 0.26237988471984863
train-epoch-step: 81-184 -- Loss: 0.13576041162014008
train-epoch-step: 81-185 -- Loss: 0.1398022323846817
train-epoch-step: 81-186 -- Loss: 0.19123287498950958
train-epoch-step: 81-187 -- Loss: 0.206268310546875
train-epoch-step: 81-188 -- Loss: 0.17151501774787903
train-epoch-step: 81-189 -- Loss: 0.11787022650241852
train-epoch-step: 81-190 -- Loss: 0.17706945538520813
train-epoch-step: 81-191 -- Loss: 0.16343288123607635
train-epoch-step: 81-192 -- Loss: 0.22348526120185852
train-epoch-step: 81-193 -- Loss: 0.20921814441680908
train-epoch-step: 81-194 -- Loss: 0.17863552272319794
train-epoch-step: 81-195 -- Loss: 0.16531014442443848
train-epoch-step: 81-196 -- Loss: 0.16333571076393127
train-epoch-step: 81-197 -- Loss: 0.12161381542682648
train-epoch-step: 81-198 -- Loss: 0.12315388023853302
train-epoch-step: 81-199 -- Loss: 0.14958839118480682
train-epoch-step: 81-200 -- Loss: 0.12216717004776001
train-epoch-step: 81-201 -- Loss: 0.18139423429965973
train-epoch-step: 81-202 -- Loss: 0.13871699571609497
train-epoch-step: 81-203 -- Loss: 0.177853524684906
train-epoch-step: 81-204 -- Loss: 0.13603518903255463
train-epoch-step: 81-205 -- Loss: 0.18799567222595215
train-epoch-step: 81-206 -- Loss: 0.20736609399318695
train-epoch-step: 81-207 -- Loss: 0.13922764360904694
train-epoch-step: 81-208 -- Loss: 0.17501002550125122
train-epoch-step: 81-209 -- Loss: 0.14377577602863312
train-epoch-step: 81-210 -- Loss: 0.13413815200328827
train-epoch-step: 81-211 -- Loss: 0.20767371356487274
train-epoch-step: 81-212 -- Loss: 0.2031460851430893
train-epoch-step: 81-213 -- Loss: 0.1241360753774643
train-epoch-step: 81-214 -- Loss: 0.15124791860580444
train-epoch-step: 81-215 -- Loss: 0.12454085052013397
train-epoch-step: 81-216 -- Loss: 0.19522278010845184
train-epoch-step: 81-217 -- Loss: 0.22115027904510498
train-epoch-step: 81-218 -- Loss: 0.1439134180545807
train-epoch-step: 81-219 -- Loss: 0.1668991595506668
train-epoch-step: 81-220 -- Loss: 0.1289520561695099
train-epoch-step: 81-221 -- Loss: 0.20026887953281403
train-epoch-step: 81-222 -- Loss: 0.1124974936246872
train-epoch-step: 81-223 -- Loss: 0.16906286776065826
train-epoch-step: 81-224 -- Loss: 0.19099688529968262
train-epoch-step: 81-225 -- Loss: 0.26506298780441284
train-epoch-step: 81-226 -- Loss: 0.20175813138484955
train-epoch-step: 81-227 -- Loss: 0.21945235133171082
train-epoch-step: 81-228 -- Loss: 0.1739342361688614
train-epoch-step: 81-229 -- Loss: 0.1705755591392517
train-epoch-step: 81-230 -- Loss: 0.15838246047496796
train-epoch-step: 81-231 -- Loss: 0.1569989174604416
train-epoch-step: 81-232 -- Loss: 0.18923033773899078
train-epoch-step: 81-233 -- Loss: 0.0822635143995285
train-epoch-step: 81-234 -- Loss: 0.17036749422550201
train-epoch-step: 81-235 -- Loss: 0.14402583241462708
train-epoch-step: 81-236 -- Loss: 0.1823120415210724
train-epoch-step: 81-237 -- Loss: 0.2297636717557907
train-epoch-step: 81-238 -- Loss: 0.1516311764717102
train-epoch-step: 81-239 -- Loss: 0.1265222281217575
train-epoch-step: 81-240 -- Loss: 0.22216033935546875
train-epoch-step: 81-241 -- Loss: 0.1500055491924286
train-epoch-step: 81-242 -- Loss: 0.21615952253341675
train-epoch-step: 81-243 -- Loss: 0.2337389588356018
train-epoch-step: 81-244 -- Loss: 0.20465637743473053
train-epoch-step: 81-245 -- Loss: 0.20693834125995636
train-epoch-step: 81-246 -- Loss: 0.22465470433235168
train-epoch-step: 81-247 -- Loss: 0.20615805685520172
train-epoch-step: 81-248 -- Loss: 0.18421049416065216
train-epoch-step: 81-249 -- Loss: 0.13574984669685364
train-epoch-step: 81-250 -- Loss: 0.1978956013917923
train-epoch-step: 81-251 -- Loss: 0.10334348678588867
train-epoch-step: 81-252 -- Loss: 0.19088181853294373
train-epoch-step: 81-253 -- Loss: 0.13655796647071838
train-epoch-step: 81-254 -- Loss: 0.21731235086917877
train-epoch-step: 81-255 -- Loss: 0.1445557326078415
train-epoch-step: 81-256 -- Loss: 0.1483858972787857
train-epoch-step: 81-257 -- Loss: 0.1830291450023651
train-epoch-step: 81-258 -- Loss: 0.14225445687770844
train-epoch-step: 81-259 -- Loss: 0.11144521087408066
train-epoch-step: 81-260 -- Loss: 0.19080615043640137
train-epoch-step: 81-261 -- Loss: 0.16765174269676208
train-epoch-step: 81-262 -- Loss: 0.28369131684303284
train-epoch-step: 81-263 -- Loss: 0.20640641450881958
train-epoch-step: 81-264 -- Loss: 0.16736045479774475
train-epoch-step: 81-265 -- Loss: 0.11373066902160645
train-epoch-step: 81-266 -- Loss: 0.15024910867214203
train-epoch-step: 81-267 -- Loss: 0.12686194479465485
train-epoch-step: 81-268 -- Loss: 0.1163586676120758
train-epoch-step: 81-269 -- Loss: 0.16646400094032288
train-epoch-step: 81-270 -- Loss: 0.10818164050579071
train-epoch-step: 81-271 -- Loss: 0.15264907479286194
train-epoch-step: 81-272 -- Loss: 0.11622278392314911
train-epoch-step: 81-273 -- Loss: 0.13091205060482025
train-epoch-step: 81-274 -- Loss: 0.17725862562656403
train-epoch-step: 81-275 -- Loss: 0.18801522254943848
train-epoch-step: 81-276 -- Loss: 0.15150457620620728
train-epoch-step: 81-277 -- Loss: 0.15101417899131775
train-epoch-step: 81-278 -- Loss: 0.1366262137889862
train-epoch-step: 81-279 -- Loss: 0.1319294571876526
train-epoch-step: 81-280 -- Loss: 0.2128838300704956
train-epoch-step: 81-281 -- Loss: 0.17508922517299652
train-epoch-step: 81-282 -- Loss: 0.13918672502040863
train-epoch-step: 81-283 -- Loss: 0.11652490496635437
train-epoch-step: 81-284 -- Loss: 0.1282845139503479
train-epoch-step: 81-285 -- Loss: 0.18263748288154602
train-epoch-step: 81-286 -- Loss: 0.15002982318401337
train-epoch-step: 81-287 -- Loss: 0.2035985291004181
train-epoch-step: 81-288 -- Loss: 0.09362253546714783
train-epoch-step: 81-289 -- Loss: 0.11453282833099365
train-epoch-step: 81-290 -- Loss: 0.18217507004737854
train-epoch-step: 81-291 -- Loss: 0.11505603790283203
train-epoch-step: 81-292 -- Loss: 0.15634366869926453
train-epoch-step: 81-293 -- Loss: 0.134353369474411
train-epoch-step: 81-294 -- Loss: 0.15433348715305328
train-epoch-step: 81-295 -- Loss: 0.2578604519367218
train-epoch-step: 81-296 -- Loss: 0.16091236472129822
train-epoch-step: 81-297 -- Loss: 0.1658484786748886
train-epoch-step: 81-298 -- Loss: 0.220793679356575
train-epoch-step: 81-299 -- Loss: 0.14658327400684357
train-epoch-step: 81-300 -- Loss: 0.16212767362594604
train-epoch-step: 81-301 -- Loss: 0.16851262748241425
train-epoch-step: 81-302 -- Loss: 0.20908406376838684
train-epoch-step: 81-303 -- Loss: 0.20625686645507812
train-epoch-step: 81-304 -- Loss: 0.12914526462554932
train-epoch-step: 81-305 -- Loss: 0.15034447610378265
train-epoch-step: 81-306 -- Loss: 0.2081964910030365
train-epoch-step: 81-307 -- Loss: 0.16287094354629517
train-epoch-step: 81-308 -- Loss: 0.22024473547935486
train-epoch-step: 81-309 -- Loss: 0.1493072360754013
train-epoch-step: 81-310 -- Loss: 0.15976901352405548
train-epoch-step: 81-311 -- Loss: 0.15527409315109253
train-epoch-step: 81-312 -- Loss: 0.20637869834899902
train-epoch-step: 81-313 -- Loss: 0.09584426879882812
train-epoch-step: 81-314 -- Loss: 0.19370417296886444
train-epoch-step: 81-315 -- Loss: 0.17782831192016602
train-epoch-step: 81-316 -- Loss: 0.14600089192390442
train-epoch-step: 81-317 -- Loss: 0.13921111822128296
train-epoch-step: 81-318 -- Loss: 0.1537536084651947
train-epoch-step: 81-319 -- Loss: 0.17150145769119263
train-epoch-step: 81-320 -- Loss: 0.11614741384983063
train-epoch-step: 81-321 -- Loss: 0.12770090997219086
train-epoch-step: 81-322 -- Loss: 0.20653095841407776
train-epoch-step: 81-323 -- Loss: 0.15665295720100403
train-epoch-step: 81-324 -- Loss: 0.2526005506515503
train-epoch-step: 81-325 -- Loss: 0.1521424800157547
train-epoch-step: 81-326 -- Loss: 0.17211192846298218
train-epoch-step: 81-327 -- Loss: 0.20280112326145172
train-epoch-step: 81-328 -- Loss: 0.1881178915500641
train-epoch-step: 81-329 -- Loss: 0.340154230594635
train-epoch-step: 81-330 -- Loss: 0.35165244340896606
train-epoch-step: 81-331 -- Loss: 0.2054884284734726
train-epoch-step: 81-332 -- Loss: 0.1131066232919693
train-epoch-step: 81-333 -- Loss: 0.17941315472126007
train-epoch-step: 81-334 -- Loss: 0.15079768002033234
train-epoch-step: 81-335 -- Loss: 0.17063917219638824
train-epoch-step: 81-336 -- Loss: 0.14636212587356567
train-epoch-step: 81-337 -- Loss: 0.19931182265281677
train-epoch-step: 81-338 -- Loss: 0.15992489457130432
train-epoch-step: 81-339 -- Loss: 0.14316688477993011
train-epoch-step: 81-340 -- Loss: 0.1934223771095276
train-epoch-step: 81-341 -- Loss: 0.13765743374824524
train-epoch-step: 81-342 -- Loss: 0.16423559188842773
train-epoch-step: 81-343 -- Loss: 0.1507233828306198
train-epoch-step: 81-344 -- Loss: 0.16177919507026672
train-epoch-step: 81-345 -- Loss: 0.12162446975708008
train-epoch-step: 81-346 -- Loss: 0.20168358087539673
train-epoch-step: 81-347 -- Loss: 0.1498076468706131
train-epoch-step: 81-348 -- Loss: 0.198484867811203
train-epoch-step: 81-349 -- Loss: 0.1976950615644455
train-epoch-step: 81-350 -- Loss: 0.24780866503715515
train-epoch-step: 81-351 -- Loss: 0.1890006959438324
train-epoch-step: 81-352 -- Loss: 0.12137797474861145
train-epoch-step: 81-353 -- Loss: 0.1893327534198761
train-epoch-step: 81-354 -- Loss: 0.2741924822330475
train-epoch-step: 81-355 -- Loss: 0.12120934575796127
train-epoch-step: 81-356 -- Loss: 0.11370416730642319
train-epoch-step: 81-357 -- Loss: 0.18820072710514069
train-epoch-step: 81-358 -- Loss: 0.18060414493083954
train-epoch-step: 81-359 -- Loss: 0.1398884356021881
train-epoch-step: 81-360 -- Loss: 0.12089484930038452
train-epoch-step: 81-361 -- Loss: 0.2318730652332306
train-epoch-step: 81-362 -- Loss: 0.16504622995853424
train-epoch-step: 81-363 -- Loss: 0.1093464344739914
train-epoch-step: 81-364 -- Loss: 0.17425419390201569
train-epoch-step: 81-365 -- Loss: 0.16307280957698822
train-epoch-step: 81-366 -- Loss: 0.19471541047096252
train-epoch-step: 81-367 -- Loss: 0.2244517207145691
train-epoch-step: 81-368 -- Loss: 0.20482435822486877
train-epoch-step: 81-369 -- Loss: 0.2712215781211853
train-epoch-step: 81-370 -- Loss: 0.12463875114917755
train-epoch-step: 81-371 -- Loss: 0.11963960528373718
train-epoch-step: 81-372 -- Loss: 0.14570169150829315
train-epoch-step: 81-373 -- Loss: 0.18506768345832825
train-epoch-step: 81-374 -- Loss: 0.1507691740989685
train-epoch-step: 81-375 -- Loss: 0.2568449378013611
train-epoch-step: 81-376 -- Loss: 0.15993282198905945
train-epoch-step: 81-377 -- Loss: 0.23519891500473022
train-epoch-step: 81-378 -- Loss: 0.19602540135383606
train-epoch-step: 81-379 -- Loss: 0.11534396559000015
train-epoch-step: 81-380 -- Loss: 0.08997023850679398
train-epoch-step: 81-381 -- Loss: 0.24620705842971802
train-epoch-step: 81-382 -- Loss: 0.2299012541770935
train-epoch-step: 81-383 -- Loss: 0.1781422346830368
train-epoch-step: 81-384 -- Loss: 0.20847710967063904
train-epoch-step: 81-385 -- Loss: 0.18364545702934265
train-epoch-step: 81-386 -- Loss: 0.17995958030223846
train-epoch-step: 81-387 -- Loss: 0.19513562321662903
train-epoch-step: 81-388 -- Loss: 0.18464331328868866
train-epoch-step: 81-389 -- Loss: 0.16343574225902557
train-epoch-step: 81-390 -- Loss: 0.14317454397678375
train-epoch-step: 81-391 -- Loss: 0.1419864296913147
train-epoch-step: 81-392 -- Loss: 0.18069903552532196
train-epoch-step: 81-393 -- Loss: 0.15700984001159668
train-epoch-step: 81-394 -- Loss: 0.1967763453722
train-epoch-step: 81-395 -- Loss: 0.1489316076040268
train-epoch-step: 81-396 -- Loss: 0.12022390216588974
train-epoch-step: 81-397 -- Loss: 0.12207400798797607
train-epoch-step: 81-398 -- Loss: 0.19183021783828735
train-epoch-step: 81-399 -- Loss: 0.16919001936912537
train-epoch-step: 81-400 -- Loss: 0.26542121171951294
train-epoch-step: 81-401 -- Loss: 0.11758914589881897
train-epoch-step: 81-402 -- Loss: 0.24868814647197723
train-epoch-step: 81-403 -- Loss: 0.15296640992164612
train-epoch-step: 81-404 -- Loss: 0.13592161238193512
train-epoch-step: 81-405 -- Loss: 0.13759928941726685
train-epoch-step: 81-406 -- Loss: 0.16012710332870483
train-epoch-step: 81-407 -- Loss: 0.10934919118881226
train-epoch-step: 81-408 -- Loss: 0.1578654795885086
train-epoch-step: 81-409 -- Loss: 0.1648116558790207
train-epoch-step: 81-410 -- Loss: 0.1704682558774948
train-epoch-step: 81-411 -- Loss: 0.1981317102909088
train-epoch-step: 81-412 -- Loss: 0.12768720090389252
train-epoch-step: 81-413 -- Loss: 0.14424806833267212
train-epoch-step: 81-414 -- Loss: 0.13052904605865479
train-epoch-step: 81-415 -- Loss: 0.13121946156024933
train-epoch-step: 81-416 -- Loss: 0.25955161452293396
train-epoch-step: 81-417 -- Loss: 0.18574601411819458
train-epoch-step: 81-418 -- Loss: 0.22731351852416992
train-epoch-step: 81-419 -- Loss: 0.16049708425998688
train-epoch-step: 81-420 -- Loss: 0.14912036061286926
train-epoch-step: 81-421 -- Loss: 0.17975780367851257
train-epoch-step: 81-422 -- Loss: 0.14842303097248077
train-epoch-step: 81-423 -- Loss: 0.17197328805923462
train-epoch-step: 81-424 -- Loss: 0.13387173414230347
train-epoch-step: 81-425 -- Loss: 0.17843401432037354
train-epoch-step: 81-426 -- Loss: 0.16475069522857666
train-epoch-step: 81-427 -- Loss: 0.12467208504676819
train-epoch-step: 81-428 -- Loss: 0.21141460537910461
train-epoch-step: 81-429 -- Loss: 0.1703018695116043
train-epoch-step: 81-430 -- Loss: 0.13827639818191528
train-epoch-step: 81-431 -- Loss: 0.15629525482654572
train-epoch-step: 81-432 -- Loss: 0.2367423176765442
train-epoch-step: 81-433 -- Loss: 0.13293591141700745
train-epoch-step: 81-434 -- Loss: 0.12391311675310135
train-epoch-step: 81-435 -- Loss: 0.15004023909568787
train-epoch-step: 81-436 -- Loss: 0.15225616097450256
train-epoch-step: 81-437 -- Loss: 0.12839040160179138
train-epoch-step: 81-438 -- Loss: 0.16685444116592407
train-epoch-step: 81-439 -- Loss: 0.2545841932296753
train-epoch-step: 81-440 -- Loss: 0.1280997395515442
train-epoch-step: 81-441 -- Loss: 0.19468674063682556
train-epoch-step: 81-442 -- Loss: 0.16848590970039368
train-epoch-step: 81-443 -- Loss: 0.16214407980442047
train-epoch-step: 81-444 -- Loss: 0.1691613644361496
train-epoch-step: 81-445 -- Loss: 0.17583389580249786
train-epoch-step: 81-446 -- Loss: 0.15131708979606628
train-epoch-step: 81-447 -- Loss: 0.18802997469902039
train-epoch-step: 81-448 -- Loss: 0.22054801881313324
train-epoch-step: 81-449 -- Loss: 0.18474338948726654
train-epoch-step: 81-450 -- Loss: 0.1738976538181305
train-epoch-step: 81-451 -- Loss: 0.14005224406719208
train-epoch-step: 81-452 -- Loss: 0.12853984534740448
train-epoch-step: 81-453 -- Loss: 0.0902835801243782
train-epoch-step: 81-454 -- Loss: 0.22403311729431152
train-epoch-step: 81-455 -- Loss: 0.12014308571815491
train-epoch-step: 81-456 -- Loss: 0.11839652061462402
train-epoch-step: 81-457 -- Loss: 0.20925769209861755
train-epoch-step: 81-458 -- Loss: 0.14568911492824554
train-epoch-step: 81-459 -- Loss: 0.2075963020324707
train-epoch-step: 81-460 -- Loss: 0.12633034586906433
train-epoch-step: 81-461 -- Loss: 0.13235355913639069
train-epoch-step: 81-462 -- Loss: 0.15822187066078186
train-epoch-step: 81-463 -- Loss: 0.13432802259922028
train-epoch-step: 81-464 -- Loss: 0.15646515786647797
train-epoch-step: 81-465 -- Loss: 0.2324574589729309
train-epoch-step: 81-466 -- Loss: 0.2034987211227417
train-epoch-step: 81-467 -- Loss: 0.11031527817249298
train-epoch-step: 81-468 -- Loss: 0.15946075320243835
train-epoch-step: 81-469 -- Loss: 0.20321649312973022
train-epoch-step: 81-470 -- Loss: 0.16449514031410217
train-epoch-step: 81-471 -- Loss: 0.15461230278015137
train-epoch-step: 81-472 -- Loss: 0.1566811501979828
train-epoch-step: 81-473 -- Loss: 0.15453459322452545
train-epoch-step: 81-474 -- Loss: 0.1186937540769577
train-epoch-step: 81-475 -- Loss: 0.10672804713249207
train-epoch-step: 81-476 -- Loss: 0.1936449408531189
train-epoch-step: 81-477 -- Loss: 0.18986067175865173
train-epoch-step: 81-478 -- Loss: 0.18518218398094177
train-epoch-step: 81-479 -- Loss: 0.13636232912540436
train-epoch-step: 81-480 -- Loss: 0.18400296568870544
train-epoch-step: 81-481 -- Loss: 0.270084947347641
train-epoch-step: 81-482 -- Loss: 0.2495591938495636
train-epoch-step: 81-483 -- Loss: 0.17730537056922913
train-epoch-step: 81-484 -- Loss: 0.21015754342079163
train-epoch-step: 81-485 -- Loss: 0.12755101919174194
train-epoch-step: 81-486 -- Loss: 0.226003959774971
train-epoch-step: 81-487 -- Loss: 0.2301962673664093
train-epoch-step: 81-488 -- Loss: 0.1810643970966339
train-epoch-step: 81-489 -- Loss: 0.21163880825042725
train-epoch-step: 81-490 -- Loss: 0.13386176526546478
train-epoch-step: 81-491 -- Loss: 0.13472504913806915
train-epoch-step: 81-492 -- Loss: 0.12251918762922287
train-epoch-step: 81-493 -- Loss: 0.19131797552108765
train-epoch-step: 81-494 -- Loss: 0.19924712181091309
train-epoch-step: 81-495 -- Loss: 0.1928158402442932
train-epoch-step: 81-496 -- Loss: 0.13673648238182068
train-epoch-step: 81-497 -- Loss: 0.17875786125659943
train-epoch-step: 81-498 -- Loss: 0.1467149555683136
train-epoch-step: 81-499 -- Loss: 0.16056594252586365
train-epoch-step: 81-500 -- Loss: 0.14804832637310028
train-epoch-step: 81-501 -- Loss: 0.21044614911079407
train-epoch-step: 81-502 -- Loss: 0.1505112648010254
train-epoch-step: 81-503 -- Loss: 0.21206757426261902
train-epoch-step: 81-504 -- Loss: 0.12298093736171722
train-epoch-step: 81-505 -- Loss: 0.17094996571540833
train-epoch-step: 81-506 -- Loss: 0.12209916114807129
train-epoch-step: 81-507 -- Loss: 0.1769174486398697
train-epoch-step: 81-508 -- Loss: 0.168748676776886
train-epoch-step: 81-509 -- Loss: 0.16610193252563477
train-epoch-step: 81-510 -- Loss: 0.12435372918844223
train-epoch-step: 81-511 -- Loss: 0.2126043438911438
train-epoch-step: 81-512 -- Loss: 0.1700010895729065
train-epoch-step: 81-513 -- Loss: 0.1799389123916626
train-epoch-step: 81-514 -- Loss: 0.14410528540611267
train-epoch-step: 81-515 -- Loss: 0.14976797997951508
train-epoch-step: 81-516 -- Loss: 0.16737963259220123
train-epoch-step: 81-517 -- Loss: 0.16852277517318726
train-epoch-step: 81-518 -- Loss: 0.1391637623310089
train-epoch-step: 81-519 -- Loss: 0.13035234808921814
train-epoch-step: 81-520 -- Loss: 0.17758388817310333
train-epoch-step: 81-521 -- Loss: 0.22864975035190582
train-epoch-step: 81-522 -- Loss: 0.16714975237846375
train-epoch-step: 81-523 -- Loss: 0.1516399085521698
train-epoch-step: 81-524 -- Loss: 0.16052663326263428
train-epoch-step: 81-525 -- Loss: 0.1840529888868332
train-epoch-step: 81-526 -- Loss: 0.12893107533454895
train-epoch-step: 81-527 -- Loss: 0.14399760961532593
train-epoch-step: 81-528 -- Loss: 0.15274527668952942
train-epoch-step: 81-529 -- Loss: 0.15179406106472015
train-epoch-step: 81-530 -- Loss: 0.16689956188201904
train-epoch-step: 81-531 -- Loss: 0.1921243667602539
train-epoch-step: 81-532 -- Loss: 0.16560566425323486
train-epoch-step: 81-533 -- Loss: 0.16994225978851318
train-epoch-step: 81-534 -- Loss: 0.12614805996418
train-epoch-step: 81-535 -- Loss: 0.24343356490135193
train-epoch-step: 81-536 -- Loss: 0.14853379130363464
train-epoch-step: 81-537 -- Loss: 0.14798176288604736
train-epoch-step: 81-538 -- Loss: 0.10173647850751877
train-epoch-step: 81-539 -- Loss: 0.1819894015789032
train-epoch-step: 81-540 -- Loss: 0.13566865026950836
train-epoch-step: 81-541 -- Loss: 0.20521710813045502
train-epoch-step: 81-542 -- Loss: 0.20993167161941528
train-epoch-step: 81-543 -- Loss: 0.16466489434242249
train-epoch-step: 81-544 -- Loss: 0.22127284109592438
train-epoch-step: 81-545 -- Loss: 0.18825973570346832
train-epoch-step: 81-546 -- Loss: 0.21256373822689056
train-epoch-step: 81-547 -- Loss: 0.17879986763000488
train-epoch-step: 81-548 -- Loss: 0.09286824613809586
train-epoch-step: 81-549 -- Loss: 0.14478936791419983
train-epoch-step: 81-550 -- Loss: 0.19177430868148804
train-epoch-step: 81-551 -- Loss: 0.1500890702009201
train-epoch-step: 81-552 -- Loss: 0.12443230301141739
train-epoch-step: 81-553 -- Loss: 0.18619215488433838
train-epoch-step: 81-554 -- Loss: 0.18478044867515564
train-epoch-step: 81-555 -- Loss: 0.20158492028713226
train-epoch-step: 81-556 -- Loss: 0.1485125571489334
train-epoch-step: 81-557 -- Loss: 0.22933003306388855
train-epoch-step: 81-558 -- Loss: 0.24692681431770325
train-epoch-step: 81-559 -- Loss: 0.133310005068779
train-epoch-step: 81-560 -- Loss: 0.2032518982887268
train-epoch-step: 81-561 -- Loss: 0.2080528438091278
train-epoch-step: 81-562 -- Loss: 0.16966575384140015
train-epoch-step: 81-563 -- Loss: 0.19143599271774292
train-epoch-step: 81-564 -- Loss: 0.09778463840484619
train-epoch-step: 81-565 -- Loss: 0.1765306293964386
train-epoch-step: 81-566 -- Loss: 0.14472070336341858
train-epoch-step: 81-567 -- Loss: 0.20739687979221344
train-epoch-step: 81-568 -- Loss: 0.16248628497123718
train-epoch-step: 81-569 -- Loss: 0.24600321054458618
train-epoch-step: 81-570 -- Loss: 0.16545477509498596
train-epoch-step: 81-571 -- Loss: 0.213170126080513
train-epoch-step: 81-572 -- Loss: 0.23775503039360046
train-epoch-step: 81-573 -- Loss: 0.19189174473285675
train-epoch-step: 81-574 -- Loss: 0.256006121635437
train-epoch-step: 81-575 -- Loss: 0.29252904653549194
train-epoch-step: 81-576 -- Loss: 0.11798747628927231
train-epoch-step: 81-577 -- Loss: 0.1644456386566162
train-epoch-step: 81-578 -- Loss: 0.21983912587165833
train-epoch-step: 81-579 -- Loss: 0.17381958663463593
train-epoch-step: 81-580 -- Loss: 0.1800604909658432
train-epoch-step: 81-581 -- Loss: 0.13503822684288025
train-epoch-step: 81-582 -- Loss: 0.20244601368904114
train-epoch-step: 81-583 -- Loss: 0.21235176920890808
train-epoch-step: 81-584 -- Loss: 0.15820804238319397
train-epoch-step: 81-585 -- Loss: 0.19515055418014526
train-epoch-step: 81-586 -- Loss: 0.24538946151733398
train-epoch-step: 81-587 -- Loss: 0.15800124406814575
train-epoch-step: 81-588 -- Loss: 0.12859369814395905
val-epoch-step: 81-589 -- Loss: 0.2061072736978531
val-epoch-step: 81-590 -- Loss: 0.15052206814289093
val-epoch-step: 81-591 -- Loss: 0.24209168553352356
val-epoch-step: 81-592 -- Loss: 0.172798290848732
val-epoch-step: 81-593 -- Loss: 0.15700705349445343
val-epoch-step: 81-594 -- Loss: 0.3898395895957947
val-epoch-step: 81-595 -- Loss: 0.1821085810661316
val-epoch-step: 81-596 -- Loss: 0.2211359739303589
val-epoch-step: 81-597 -- Loss: 0.1708698272705078
val-epoch-step: 81-598 -- Loss: 0.14729276299476624
val-epoch-step: 81-599 -- Loss: 0.1792735606431961
val-epoch-step: 81-600 -- Loss: 0.16473931074142456
val-epoch-step: 81-601 -- Loss: 0.1508910208940506
val-epoch-step: 81-602 -- Loss: 0.13436076045036316
val-epoch-step: 81-603 -- Loss: 0.19489233195781708
val-epoch-step: 81-604 -- Loss: 0.1529844105243683
val-epoch-step: 81-605 -- Loss: 0.14391285181045532
val-epoch-step: 81-606 -- Loss: 0.24846073985099792
val-epoch-step: 81-607 -- Loss: 0.12169362604618073
val-epoch-step: 81-608 -- Loss: 0.24322108924388885
val-epoch-step: 81-609 -- Loss: 0.17096999287605286
val-epoch-step: 81-610 -- Loss: 0.17513233423233032
val-epoch-step: 81-611 -- Loss: 0.1628352403640747
val-epoch-step: 81-612 -- Loss: 0.41117534041404724
val-epoch-step: 81-613 -- Loss: 0.18533089756965637
val-epoch-step: 81-614 -- Loss: 0.1743028163909912
val-epoch-step: 81-615 -- Loss: 0.17101144790649414
val-epoch-step: 81-616 -- Loss: 0.14691244065761566
val-epoch-step: 81-617 -- Loss: 0.18925732374191284
val-epoch-step: 81-618 -- Loss: 0.1727839559316635
val-epoch-step: 81-619 -- Loss: 0.19877301156520844
val-epoch-step: 81-620 -- Loss: 0.13569648563861847
val-epoch-step: 81-621 -- Loss: 0.12410005182027817
val-epoch-step: 81-622 -- Loss: 0.14152173697948456
val-epoch-step: 81-623 -- Loss: 0.14662209153175354
val-epoch-step: 81-624 -- Loss: 0.1409449726343155
val-epoch-step: 81-625 -- Loss: 0.15307508409023285
val-epoch-step: 81-626 -- Loss: 0.14570999145507812
val-epoch-step: 81-627 -- Loss: 0.1868583709001541
val-epoch-step: 81-628 -- Loss: 0.6816039681434631
val-epoch-step: 81-629 -- Loss: 0.22886350750923157
val-epoch-step: 81-630 -- Loss: 0.33391883969306946
val-epoch-step: 81-631 -- Loss: 0.13912436366081238
val-epoch-step: 81-632 -- Loss: 0.1946350336074829
val-epoch-step: 81-633 -- Loss: 0.1494860053062439
val-epoch-step: 81-634 -- Loss: 0.14297644793987274
val-epoch-step: 81-635 -- Loss: 0.11238743364810944
val-epoch-step: 81-636 -- Loss: 0.16403400897979736
val-epoch-step: 81-637 -- Loss: 0.17830878496170044
val-epoch-step: 81-638 -- Loss: 0.16418474912643433
val-epoch-step: 81-639 -- Loss: 0.2524181604385376
val-epoch-step: 81-640 -- Loss: 0.2549416422843933
val-epoch-step: 81-641 -- Loss: 0.12929102778434753
val-epoch-step: 81-642 -- Loss: 0.18823936581611633
val-epoch-step: 81-643 -- Loss: 0.21153514087200165
val-epoch-step: 81-644 -- Loss: 0.16521310806274414
val-epoch-step: 81-645 -- Loss: 0.219866544008255
val-epoch-step: 81-646 -- Loss: 0.1252191811800003
val-epoch-step: 81-647 -- Loss: 0.1265914887189865
val-epoch-step: 81-648 -- Loss: 0.15415272116661072
val-epoch-step: 81-649 -- Loss: 0.19746188819408417
val-epoch-step: 81-650 -- Loss: 0.24874970316886902
val-epoch-step: 81-651 -- Loss: 0.1436685472726822
val-epoch-step: 81-652 -- Loss: 0.1582569032907486
val-epoch-step: 81-653 -- Loss: 0.19468258321285248
val-epoch-step: 81-654 -- Loss: 0.10660616308450699
Epoch: 81 -- Train Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 82-0 -- Loss: 0.2163853794336319
train-epoch-step: 82-1 -- Loss: 0.14122599363327026
train-epoch-step: 82-2 -- Loss: 0.19834214448928833
train-epoch-step: 82-3 -- Loss: 0.15107500553131104
train-epoch-step: 82-4 -- Loss: 0.15312570333480835
train-epoch-step: 82-5 -- Loss: 0.18859641253948212
train-epoch-step: 82-6 -- Loss: 0.21096943318843842
train-epoch-step: 82-7 -- Loss: 0.16210798919200897
train-epoch-step: 82-8 -- Loss: 0.17296519875526428
train-epoch-step: 82-9 -- Loss: 0.21766220033168793
train-epoch-step: 82-10 -- Loss: 0.19060292840003967
train-epoch-step: 82-11 -- Loss: 0.18116238713264465
train-epoch-step: 82-12 -- Loss: 0.14441311359405518
train-epoch-step: 82-13 -- Loss: 0.1730813980102539
train-epoch-step: 82-14 -- Loss: 0.15881948173046112
train-epoch-step: 82-15 -- Loss: 0.15323437750339508
train-epoch-step: 82-16 -- Loss: 0.16138312220573425
train-epoch-step: 82-17 -- Loss: 0.2255207598209381
train-epoch-step: 82-18 -- Loss: 0.18651236593723297
train-epoch-step: 82-19 -- Loss: 0.12530918419361115
train-epoch-step: 82-20 -- Loss: 0.21084973216056824
train-epoch-step: 82-21 -- Loss: 0.2413133680820465
train-epoch-step: 82-22 -- Loss: 0.14760056138038635
train-epoch-step: 82-23 -- Loss: 0.13860876858234406
train-epoch-step: 82-24 -- Loss: 0.12715104222297668
train-epoch-step: 82-25 -- Loss: 0.23058031499385834
train-epoch-step: 82-26 -- Loss: 0.19155043363571167
train-epoch-step: 82-27 -- Loss: 0.23430603742599487
train-epoch-step: 82-28 -- Loss: 0.12379971146583557
train-epoch-step: 82-29 -- Loss: 0.23256012797355652
train-epoch-step: 82-30 -- Loss: 0.10770825296640396
train-epoch-step: 82-31 -- Loss: 0.13114473223686218
train-epoch-step: 82-32 -- Loss: 0.16978931427001953
train-epoch-step: 82-33 -- Loss: 0.2619023323059082
train-epoch-step: 82-34 -- Loss: 0.16729280352592468
train-epoch-step: 82-35 -- Loss: 0.2422609180212021
train-epoch-step: 82-36 -- Loss: 0.13818012177944183
train-epoch-step: 82-37 -- Loss: 0.13282771408557892
train-epoch-step: 82-38 -- Loss: 0.1703164428472519
train-epoch-step: 82-39 -- Loss: 0.2107928842306137
train-epoch-step: 82-40 -- Loss: 0.18648239970207214
train-epoch-step: 82-41 -- Loss: 0.21244768798351288
train-epoch-step: 82-42 -- Loss: 0.14438721537590027
train-epoch-step: 82-43 -- Loss: 0.2549573481082916
train-epoch-step: 82-44 -- Loss: 0.11934445798397064
train-epoch-step: 82-45 -- Loss: 0.11300142109394073
train-epoch-step: 82-46 -- Loss: 0.16378918290138245
train-epoch-step: 82-47 -- Loss: 0.1993185579776764
train-epoch-step: 82-48 -- Loss: 0.15378083288669586
train-epoch-step: 82-49 -- Loss: 0.22218655049800873
train-epoch-step: 82-50 -- Loss: 0.11559350788593292
train-epoch-step: 82-51 -- Loss: 0.17304351925849915
train-epoch-step: 82-52 -- Loss: 0.1536865085363388
train-epoch-step: 82-53 -- Loss: 0.2141532450914383
train-epoch-step: 82-54 -- Loss: 0.2903459072113037
train-epoch-step: 82-55 -- Loss: 0.16121788322925568
train-epoch-step: 82-56 -- Loss: 0.17411626875400543
train-epoch-step: 82-57 -- Loss: 0.23287433385849
train-epoch-step: 82-58 -- Loss: 0.2818802297115326
train-epoch-step: 82-59 -- Loss: 0.2320309579372406
train-epoch-step: 82-60 -- Loss: 0.13403820991516113
train-epoch-step: 82-61 -- Loss: 0.19655200839042664
train-epoch-step: 82-62 -- Loss: 0.18074814975261688
train-epoch-step: 82-63 -- Loss: 0.13061043620109558
train-epoch-step: 82-64 -- Loss: 0.14224693179130554
train-epoch-step: 82-65 -- Loss: 0.17633545398712158
train-epoch-step: 82-66 -- Loss: 0.10697981715202332
train-epoch-step: 82-67 -- Loss: 0.11964401602745056
train-epoch-step: 82-68 -- Loss: 0.21696004271507263
train-epoch-step: 82-69 -- Loss: 0.11869227141141891
train-epoch-step: 82-70 -- Loss: 0.22302520275115967
train-epoch-step: 82-71 -- Loss: 0.25190287828445435
train-epoch-step: 82-72 -- Loss: 0.17470566928386688
train-epoch-step: 82-73 -- Loss: 0.2028302252292633
train-epoch-step: 82-74 -- Loss: 0.0918237566947937
train-epoch-step: 82-75 -- Loss: 0.12447530031204224
train-epoch-step: 82-76 -- Loss: 0.1448875367641449
train-epoch-step: 82-77 -- Loss: 0.21960614621639252
train-epoch-step: 82-78 -- Loss: 0.25314462184906006
train-epoch-step: 82-79 -- Loss: 0.18425270915031433
train-epoch-step: 82-80 -- Loss: 0.24720263481140137
train-epoch-step: 82-81 -- Loss: 0.12454384565353394
train-epoch-step: 82-82 -- Loss: 0.2557225823402405
train-epoch-step: 82-83 -- Loss: 0.17595124244689941
train-epoch-step: 82-84 -- Loss: 0.20932452380657196
train-epoch-step: 82-85 -- Loss: 0.17645522952079773
train-epoch-step: 82-86 -- Loss: 0.11657963693141937
train-epoch-step: 82-87 -- Loss: 0.21154598891735077
train-epoch-step: 82-88 -- Loss: 0.1393916755914688
train-epoch-step: 82-89 -- Loss: 0.1856699138879776
train-epoch-step: 82-90 -- Loss: 0.18385250866413116
train-epoch-step: 82-91 -- Loss: 0.2353530377149582
train-epoch-step: 82-92 -- Loss: 0.14826536178588867
train-epoch-step: 82-93 -- Loss: 0.20450958609580994
train-epoch-step: 82-94 -- Loss: 0.22888410091400146
train-epoch-step: 82-95 -- Loss: 0.19089728593826294
train-epoch-step: 82-96 -- Loss: 0.21512584388256073
train-epoch-step: 82-97 -- Loss: 0.17211683094501495
train-epoch-step: 82-98 -- Loss: 0.15257763862609863
train-epoch-step: 82-99 -- Loss: 0.17937153577804565
train-epoch-step: 82-100 -- Loss: 0.1829501986503601
train-epoch-step: 82-101 -- Loss: 0.26850298047065735
train-epoch-step: 82-102 -- Loss: 0.21307697892189026
train-epoch-step: 82-103 -- Loss: 0.18064209818840027
train-epoch-step: 82-104 -- Loss: 0.14405140280723572
train-epoch-step: 82-105 -- Loss: 0.25336766242980957
train-epoch-step: 82-106 -- Loss: 0.1722351610660553
train-epoch-step: 82-107 -- Loss: 0.18533766269683838
train-epoch-step: 82-108 -- Loss: 0.18394215404987335
train-epoch-step: 82-109 -- Loss: 0.14223456382751465
train-epoch-step: 82-110 -- Loss: 0.17637139558792114
train-epoch-step: 82-111 -- Loss: 0.18499477207660675
train-epoch-step: 82-112 -- Loss: 0.17110660672187805
train-epoch-step: 82-113 -- Loss: 0.15839044749736786
train-epoch-step: 82-114 -- Loss: 0.19150559604167938
train-epoch-step: 82-115 -- Loss: 0.15650281310081482
train-epoch-step: 82-116 -- Loss: 0.13556332886219025
train-epoch-step: 82-117 -- Loss: 0.12556615471839905
train-epoch-step: 82-118 -- Loss: 0.1908637285232544
train-epoch-step: 82-119 -- Loss: 0.14957201480865479
train-epoch-step: 82-120 -- Loss: 0.243346706032753
train-epoch-step: 82-121 -- Loss: 0.23189100623130798
train-epoch-step: 82-122 -- Loss: 0.209261953830719
train-epoch-step: 82-123 -- Loss: 0.19257377088069916
train-epoch-step: 82-124 -- Loss: 0.12071941047906876
train-epoch-step: 82-125 -- Loss: 0.14990611374378204
train-epoch-step: 82-126 -- Loss: 0.22507914900779724
train-epoch-step: 82-127 -- Loss: 0.17438602447509766
train-epoch-step: 82-128 -- Loss: 0.16932277381420135
train-epoch-step: 82-129 -- Loss: 0.13628092408180237
train-epoch-step: 82-130 -- Loss: 0.18888452649116516
train-epoch-step: 82-131 -- Loss: 0.13834825158119202
train-epoch-step: 82-132 -- Loss: 0.1881418228149414
train-epoch-step: 82-133 -- Loss: 0.11929263174533844
train-epoch-step: 82-134 -- Loss: 0.18565279245376587
train-epoch-step: 82-135 -- Loss: 0.12876498699188232
train-epoch-step: 82-136 -- Loss: 0.12315532565116882
train-epoch-step: 82-137 -- Loss: 0.23719020187854767
train-epoch-step: 82-138 -- Loss: 0.25001123547554016
train-epoch-step: 82-139 -- Loss: 0.1315610408782959
train-epoch-step: 82-140 -- Loss: 0.20837149024009705
train-epoch-step: 82-141 -- Loss: 0.23172040283679962
train-epoch-step: 82-142 -- Loss: 0.1943025141954422
train-epoch-step: 82-143 -- Loss: 0.16644136607646942
train-epoch-step: 82-144 -- Loss: 0.17796270549297333
train-epoch-step: 82-145 -- Loss: 0.14308561384677887
train-epoch-step: 82-146 -- Loss: 0.17685697972774506
train-epoch-step: 82-147 -- Loss: 0.16886481642723083
train-epoch-step: 82-148 -- Loss: 0.15499120950698853
train-epoch-step: 82-149 -- Loss: 0.1172834038734436
train-epoch-step: 82-150 -- Loss: 0.17714276909828186
train-epoch-step: 82-151 -- Loss: 0.18493376672267914
train-epoch-step: 82-152 -- Loss: 0.18812784552574158
train-epoch-step: 82-153 -- Loss: 0.25674599409103394
train-epoch-step: 82-154 -- Loss: 0.12768231332302094
train-epoch-step: 82-155 -- Loss: 0.1349542737007141
train-epoch-step: 82-156 -- Loss: 0.11264730244874954
train-epoch-step: 82-157 -- Loss: 0.1575610190629959
train-epoch-step: 82-158 -- Loss: 0.16207024455070496
train-epoch-step: 82-159 -- Loss: 0.1703414022922516
train-epoch-step: 82-160 -- Loss: 0.21558067202568054
train-epoch-step: 82-161 -- Loss: 0.1967540979385376
train-epoch-step: 82-162 -- Loss: 0.20965862274169922
train-epoch-step: 82-163 -- Loss: 0.18066543340682983
train-epoch-step: 82-164 -- Loss: 0.18854515254497528
train-epoch-step: 82-165 -- Loss: 0.1561368852853775
train-epoch-step: 82-166 -- Loss: 0.11887111514806747
train-epoch-step: 82-167 -- Loss: 0.12376963347196579
train-epoch-step: 82-168 -- Loss: 0.19221916794776917
train-epoch-step: 82-169 -- Loss: 0.1372111439704895
train-epoch-step: 82-170 -- Loss: 0.19621047377586365
train-epoch-step: 82-171 -- Loss: 0.13913758099079132
train-epoch-step: 82-172 -- Loss: 0.2499561607837677
train-epoch-step: 82-173 -- Loss: 0.1269887387752533
train-epoch-step: 82-174 -- Loss: 0.2450026571750641
train-epoch-step: 82-175 -- Loss: 0.18496598303318024
train-epoch-step: 82-176 -- Loss: 0.13270612061023712
train-epoch-step: 82-177 -- Loss: 0.17212778329849243
train-epoch-step: 82-178 -- Loss: 0.17179569602012634
train-epoch-step: 82-179 -- Loss: 0.15637212991714478
train-epoch-step: 82-180 -- Loss: 0.15253284573554993
train-epoch-step: 82-181 -- Loss: 0.16678881645202637
train-epoch-step: 82-182 -- Loss: 0.18125037848949432
train-epoch-step: 82-183 -- Loss: 0.2642431855201721
train-epoch-step: 82-184 -- Loss: 0.13840599358081818
train-epoch-step: 82-185 -- Loss: 0.14052337408065796
train-epoch-step: 82-186 -- Loss: 0.18539147078990936
train-epoch-step: 82-187 -- Loss: 0.20673991739749908
train-epoch-step: 82-188 -- Loss: 0.17369729280471802
train-epoch-step: 82-189 -- Loss: 0.10300155729055405
train-epoch-step: 82-190 -- Loss: 0.17824003100395203
train-epoch-step: 82-191 -- Loss: 0.15475162863731384
train-epoch-step: 82-192 -- Loss: 0.22634604573249817
train-epoch-step: 82-193 -- Loss: 0.20207366347312927
train-epoch-step: 82-194 -- Loss: 0.17450663447380066
train-epoch-step: 82-195 -- Loss: 0.161868616938591
train-epoch-step: 82-196 -- Loss: 0.16219760477542877
train-epoch-step: 82-197 -- Loss: 0.12619762122631073
train-epoch-step: 82-198 -- Loss: 0.12321369349956512
train-epoch-step: 82-199 -- Loss: 0.1445385068655014
train-epoch-step: 82-200 -- Loss: 0.12865914404392242
train-epoch-step: 82-201 -- Loss: 0.18959194421768188
train-epoch-step: 82-202 -- Loss: 0.13273414969444275
train-epoch-step: 82-203 -- Loss: 0.16973991692066193
train-epoch-step: 82-204 -- Loss: 0.13498008251190186
train-epoch-step: 82-205 -- Loss: 0.18196360766887665
train-epoch-step: 82-206 -- Loss: 0.19520345330238342
train-epoch-step: 82-207 -- Loss: 0.143217995762825
train-epoch-step: 82-208 -- Loss: 0.1747061312198639
train-epoch-step: 82-209 -- Loss: 0.13760440051555634
train-epoch-step: 82-210 -- Loss: 0.12839742004871368
train-epoch-step: 82-211 -- Loss: 0.19761040806770325
train-epoch-step: 82-212 -- Loss: 0.19349704682826996
train-epoch-step: 82-213 -- Loss: 0.12436924874782562
train-epoch-step: 82-214 -- Loss: 0.1458486020565033
train-epoch-step: 82-215 -- Loss: 0.12450557202100754
train-epoch-step: 82-216 -- Loss: 0.19628006219863892
train-epoch-step: 82-217 -- Loss: 0.20207688212394714
train-epoch-step: 82-218 -- Loss: 0.1415681391954422
train-epoch-step: 82-219 -- Loss: 0.1630372554063797
train-epoch-step: 82-220 -- Loss: 0.1266917735338211
train-epoch-step: 82-221 -- Loss: 0.2006874680519104
train-epoch-step: 82-222 -- Loss: 0.11365368217229843
train-epoch-step: 82-223 -- Loss: 0.16519957780838013
train-epoch-step: 82-224 -- Loss: 0.1853269338607788
train-epoch-step: 82-225 -- Loss: 0.26838526129722595
train-epoch-step: 82-226 -- Loss: 0.20122554898262024
train-epoch-step: 82-227 -- Loss: 0.2116788923740387
train-epoch-step: 82-228 -- Loss: 0.17588414251804352
train-epoch-step: 82-229 -- Loss: 0.16578857600688934
train-epoch-step: 82-230 -- Loss: 0.1611226350069046
train-epoch-step: 82-231 -- Loss: 0.1515163630247116
train-epoch-step: 82-232 -- Loss: 0.1821436882019043
train-epoch-step: 82-233 -- Loss: 0.08176062256097794
train-epoch-step: 82-234 -- Loss: 0.16973644495010376
train-epoch-step: 82-235 -- Loss: 0.1424369215965271
train-epoch-step: 82-236 -- Loss: 0.17331208288669586
train-epoch-step: 82-237 -- Loss: 0.2272648811340332
train-epoch-step: 82-238 -- Loss: 0.15255650877952576
train-epoch-step: 82-239 -- Loss: 0.12409363687038422
train-epoch-step: 82-240 -- Loss: 0.21527253091335297
train-epoch-step: 82-241 -- Loss: 0.1493200659751892
train-epoch-step: 82-242 -- Loss: 0.21407504379749298
train-epoch-step: 82-243 -- Loss: 0.2317243218421936
train-epoch-step: 82-244 -- Loss: 0.20432929694652557
train-epoch-step: 82-245 -- Loss: 0.20922696590423584
train-epoch-step: 82-246 -- Loss: 0.20979414880275726
train-epoch-step: 82-247 -- Loss: 0.1982940286397934
train-epoch-step: 82-248 -- Loss: 0.18142472207546234
train-epoch-step: 82-249 -- Loss: 0.13491195440292358
train-epoch-step: 82-250 -- Loss: 0.18824957311153412
train-epoch-step: 82-251 -- Loss: 0.10236170887947083
train-epoch-step: 82-252 -- Loss: 0.1954527199268341
train-epoch-step: 82-253 -- Loss: 0.13266116380691528
train-epoch-step: 82-254 -- Loss: 0.2059520035982132
train-epoch-step: 82-255 -- Loss: 0.14085757732391357
train-epoch-step: 82-256 -- Loss: 0.1449640691280365
train-epoch-step: 82-257 -- Loss: 0.19436854124069214
train-epoch-step: 82-258 -- Loss: 0.1432722806930542
train-epoch-step: 82-259 -- Loss: 0.11807122826576233
train-epoch-step: 82-260 -- Loss: 0.19976158440113068
train-epoch-step: 82-261 -- Loss: 0.16789114475250244
train-epoch-step: 82-262 -- Loss: 0.2805935740470886
train-epoch-step: 82-263 -- Loss: 0.20932406187057495
train-epoch-step: 82-264 -- Loss: 0.1718350350856781
train-epoch-step: 82-265 -- Loss: 0.12476469576358795
train-epoch-step: 82-266 -- Loss: 0.18663328886032104
train-epoch-step: 82-267 -- Loss: 0.13175974786281586
train-epoch-step: 82-268 -- Loss: 0.1192096620798111
train-epoch-step: 82-269 -- Loss: 0.16963663697242737
train-epoch-step: 82-270 -- Loss: 0.11012241244316101
train-epoch-step: 82-271 -- Loss: 0.16417363286018372
train-epoch-step: 82-272 -- Loss: 0.12717744708061218
train-epoch-step: 82-273 -- Loss: 0.12957938015460968
train-epoch-step: 82-274 -- Loss: 0.19102787971496582
train-epoch-step: 82-275 -- Loss: 0.19647403061389923
train-epoch-step: 82-276 -- Loss: 0.15593156218528748
train-epoch-step: 82-277 -- Loss: 0.1598961055278778
train-epoch-step: 82-278 -- Loss: 0.1613800823688507
train-epoch-step: 82-279 -- Loss: 0.14974625408649445
train-epoch-step: 82-280 -- Loss: 0.2261272668838501
train-epoch-step: 82-281 -- Loss: 0.1830822378396988
train-epoch-step: 82-282 -- Loss: 0.14523997902870178
train-epoch-step: 82-283 -- Loss: 0.11596378684043884
train-epoch-step: 82-284 -- Loss: 0.14259299635887146
train-epoch-step: 82-285 -- Loss: 0.19345688819885254
train-epoch-step: 82-286 -- Loss: 0.1547897756099701
train-epoch-step: 82-287 -- Loss: 0.22783292829990387
train-epoch-step: 82-288 -- Loss: 0.09889291971921921
train-epoch-step: 82-289 -- Loss: 0.12100204825401306
train-epoch-step: 82-290 -- Loss: 0.19777357578277588
train-epoch-step: 82-291 -- Loss: 0.11714988946914673
train-epoch-step: 82-292 -- Loss: 0.16335180401802063
train-epoch-step: 82-293 -- Loss: 0.1359202265739441
train-epoch-step: 82-294 -- Loss: 0.15396927297115326
train-epoch-step: 82-295 -- Loss: 0.2813689112663269
train-epoch-step: 82-296 -- Loss: 0.16374589502811432
train-epoch-step: 82-297 -- Loss: 0.1711963713169098
train-epoch-step: 82-298 -- Loss: 0.230310320854187
train-epoch-step: 82-299 -- Loss: 0.1518799066543579
train-epoch-step: 82-300 -- Loss: 0.1692396104335785
train-epoch-step: 82-301 -- Loss: 0.18234091997146606
train-epoch-step: 82-302 -- Loss: 0.215762197971344
train-epoch-step: 82-303 -- Loss: 0.20459169149398804
train-epoch-step: 82-304 -- Loss: 0.12453388422727585
train-epoch-step: 82-305 -- Loss: 0.1459539830684662
train-epoch-step: 82-306 -- Loss: 0.21607853472232819
train-epoch-step: 82-307 -- Loss: 0.16524304449558258
train-epoch-step: 82-308 -- Loss: 0.21860383450984955
train-epoch-step: 82-309 -- Loss: 0.16378280520439148
train-epoch-step: 82-310 -- Loss: 0.1624799221754074
train-epoch-step: 82-311 -- Loss: 0.15721260011196136
train-epoch-step: 82-312 -- Loss: 0.20371250808238983
train-epoch-step: 82-313 -- Loss: 0.0956634059548378
train-epoch-step: 82-314 -- Loss: 0.18802610039710999
train-epoch-step: 82-315 -- Loss: 0.1654277890920639
train-epoch-step: 82-316 -- Loss: 0.14756135642528534
train-epoch-step: 82-317 -- Loss: 0.14064925909042358
train-epoch-step: 82-318 -- Loss: 0.16065318882465363
train-epoch-step: 82-319 -- Loss: 0.17189688980579376
train-epoch-step: 82-320 -- Loss: 0.11703125387430191
train-epoch-step: 82-321 -- Loss: 0.13368356227874756
train-epoch-step: 82-322 -- Loss: 0.2122194468975067
train-epoch-step: 82-323 -- Loss: 0.16410809755325317
train-epoch-step: 82-324 -- Loss: 0.25747746229171753
train-epoch-step: 82-325 -- Loss: 0.15146836638450623
train-epoch-step: 82-326 -- Loss: 0.16587601602077484
train-epoch-step: 82-327 -- Loss: 0.2011846899986267
train-epoch-step: 82-328 -- Loss: 0.1961509883403778
train-epoch-step: 82-329 -- Loss: 0.33443567156791687
train-epoch-step: 82-330 -- Loss: 0.3661539852619171
train-epoch-step: 82-331 -- Loss: 0.20735633373260498
train-epoch-step: 82-332 -- Loss: 0.09965242445468903
train-epoch-step: 82-333 -- Loss: 0.18005764484405518
train-epoch-step: 82-334 -- Loss: 0.15301883220672607
train-epoch-step: 82-335 -- Loss: 0.17146947979927063
train-epoch-step: 82-336 -- Loss: 0.15354983508586884
train-epoch-step: 82-337 -- Loss: 0.20432354509830475
train-epoch-step: 82-338 -- Loss: 0.16167111694812775
train-epoch-step: 82-339 -- Loss: 0.14255401492118835
train-epoch-step: 82-340 -- Loss: 0.19146670401096344
train-epoch-step: 82-341 -- Loss: 0.1388586163520813
train-epoch-step: 82-342 -- Loss: 0.16145505011081696
train-epoch-step: 82-343 -- Loss: 0.1506892591714859
train-epoch-step: 82-344 -- Loss: 0.16258208453655243
train-epoch-step: 82-345 -- Loss: 0.12749773263931274
train-epoch-step: 82-346 -- Loss: 0.2010311782360077
train-epoch-step: 82-347 -- Loss: 0.1456374228000641
train-epoch-step: 82-348 -- Loss: 0.20359212160110474
train-epoch-step: 82-349 -- Loss: 0.20297181606292725
train-epoch-step: 82-350 -- Loss: 0.24610725045204163
train-epoch-step: 82-351 -- Loss: 0.18973004817962646
train-epoch-step: 82-352 -- Loss: 0.1228838637471199
train-epoch-step: 82-353 -- Loss: 0.18913356959819794
train-epoch-step: 82-354 -- Loss: 0.2792843282222748
train-epoch-step: 82-355 -- Loss: 0.11726834625005722
train-epoch-step: 82-356 -- Loss: 0.11313004046678543
train-epoch-step: 82-357 -- Loss: 0.1816866546869278
train-epoch-step: 82-358 -- Loss: 0.17984353005886078
train-epoch-step: 82-359 -- Loss: 0.13422323763370514
train-epoch-step: 82-360 -- Loss: 0.12118639051914215
train-epoch-step: 82-361 -- Loss: 0.26804986596107483
train-epoch-step: 82-362 -- Loss: 0.16735872626304626
train-epoch-step: 82-363 -- Loss: 0.10792440921068192
train-epoch-step: 82-364 -- Loss: 0.17518162727355957
train-epoch-step: 82-365 -- Loss: 0.16877199709415436
train-epoch-step: 82-366 -- Loss: 0.2401725947856903
train-epoch-step: 82-367 -- Loss: 0.2275131344795227
train-epoch-step: 82-368 -- Loss: 0.19644680619239807
train-epoch-step: 82-369 -- Loss: 0.276399165391922
train-epoch-step: 82-370 -- Loss: 0.12688028812408447
train-epoch-step: 82-371 -- Loss: 0.13716603815555573
train-epoch-step: 82-372 -- Loss: 0.1499261111021042
train-epoch-step: 82-373 -- Loss: 0.1905638724565506
train-epoch-step: 82-374 -- Loss: 0.15417401492595673
train-epoch-step: 82-375 -- Loss: 0.2631224989891052
train-epoch-step: 82-376 -- Loss: 0.15459856390953064
train-epoch-step: 82-377 -- Loss: 0.22804857790470123
train-epoch-step: 82-378 -- Loss: 0.19488616287708282
train-epoch-step: 82-379 -- Loss: 0.11826615035533905
train-epoch-step: 82-380 -- Loss: 0.09206437319517136
train-epoch-step: 82-381 -- Loss: 0.24551907181739807
train-epoch-step: 82-382 -- Loss: 0.2262728214263916
train-epoch-step: 82-383 -- Loss: 0.17494280636310577
train-epoch-step: 82-384 -- Loss: 0.21025919914245605
train-epoch-step: 82-385 -- Loss: 0.18734386563301086
train-epoch-step: 82-386 -- Loss: 0.18286189436912537
train-epoch-step: 82-387 -- Loss: 0.20137247443199158
train-epoch-step: 82-388 -- Loss: 0.1950043886899948
train-epoch-step: 82-389 -- Loss: 0.16530175507068634
train-epoch-step: 82-390 -- Loss: 0.13883744180202484
train-epoch-step: 82-391 -- Loss: 0.14448760449886322
train-epoch-step: 82-392 -- Loss: 0.18305978178977966
train-epoch-step: 82-393 -- Loss: 0.16341494023799896
train-epoch-step: 82-394 -- Loss: 0.19839432835578918
train-epoch-step: 82-395 -- Loss: 0.1599351465702057
train-epoch-step: 82-396 -- Loss: 0.1226934939622879
train-epoch-step: 82-397 -- Loss: 0.12552297115325928
train-epoch-step: 82-398 -- Loss: 0.20165163278579712
train-epoch-step: 82-399 -- Loss: 0.17138034105300903
train-epoch-step: 82-400 -- Loss: 0.26745277643203735
train-epoch-step: 82-401 -- Loss: 0.12196646630764008
train-epoch-step: 82-402 -- Loss: 0.2563118636608124
train-epoch-step: 82-403 -- Loss: 0.16436447203159332
train-epoch-step: 82-404 -- Loss: 0.13780784606933594
train-epoch-step: 82-405 -- Loss: 0.13932417333126068
train-epoch-step: 82-406 -- Loss: 0.16815239191055298
train-epoch-step: 82-407 -- Loss: 0.10932272672653198
train-epoch-step: 82-408 -- Loss: 0.1604488044977188
train-epoch-step: 82-409 -- Loss: 0.16824927926063538
train-epoch-step: 82-410 -- Loss: 0.17120781540870667
train-epoch-step: 82-411 -- Loss: 0.195011705160141
train-epoch-step: 82-412 -- Loss: 0.12840011715888977
train-epoch-step: 82-413 -- Loss: 0.14405062794685364
train-epoch-step: 82-414 -- Loss: 0.13477033376693726
train-epoch-step: 82-415 -- Loss: 0.13370762765407562
train-epoch-step: 82-416 -- Loss: 0.25654101371765137
train-epoch-step: 82-417 -- Loss: 0.193049818277359
train-epoch-step: 82-418 -- Loss: 0.22093239426612854
train-epoch-step: 82-419 -- Loss: 0.17024503648281097
train-epoch-step: 82-420 -- Loss: 0.1497625708580017
train-epoch-step: 82-421 -- Loss: 0.17184072732925415
train-epoch-step: 82-422 -- Loss: 0.14499229192733765
train-epoch-step: 82-423 -- Loss: 0.1728995442390442
train-epoch-step: 82-424 -- Loss: 0.13779640197753906
train-epoch-step: 82-425 -- Loss: 0.18379783630371094
train-epoch-step: 82-426 -- Loss: 0.16132070124149323
train-epoch-step: 82-427 -- Loss: 0.11989206075668335
train-epoch-step: 82-428 -- Loss: 0.21088111400604248
train-epoch-step: 82-429 -- Loss: 0.1730736941099167
train-epoch-step: 82-430 -- Loss: 0.15060168504714966
train-epoch-step: 82-431 -- Loss: 0.1618020385503769
train-epoch-step: 82-432 -- Loss: 0.23537185788154602
train-epoch-step: 82-433 -- Loss: 0.13076990842819214
train-epoch-step: 82-434 -- Loss: 0.13075467944145203
train-epoch-step: 82-435 -- Loss: 0.15518973767757416
train-epoch-step: 82-436 -- Loss: 0.1566523313522339
train-epoch-step: 82-437 -- Loss: 0.12947586178779602
train-epoch-step: 82-438 -- Loss: 0.16320182383060455
train-epoch-step: 82-439 -- Loss: 0.2608094811439514
train-epoch-step: 82-440 -- Loss: 0.12975367903709412
train-epoch-step: 82-441 -- Loss: 0.19299425184726715
train-epoch-step: 82-442 -- Loss: 0.16960947215557098
train-epoch-step: 82-443 -- Loss: 0.15792325139045715
train-epoch-step: 82-444 -- Loss: 0.2612363398075104
train-epoch-step: 82-445 -- Loss: 0.18691083788871765
train-epoch-step: 82-446 -- Loss: 0.1807807981967926
train-epoch-step: 82-447 -- Loss: 0.20548853278160095
train-epoch-step: 82-448 -- Loss: 0.23768895864486694
train-epoch-step: 82-449 -- Loss: 0.2028663605451584
train-epoch-step: 82-450 -- Loss: 0.19392071664333344
train-epoch-step: 82-451 -- Loss: 0.1715770661830902
train-epoch-step: 82-452 -- Loss: 0.1505894660949707
train-epoch-step: 82-453 -- Loss: 0.11414949595928192
train-epoch-step: 82-454 -- Loss: 0.2755974531173706
train-epoch-step: 82-455 -- Loss: 0.14084598422050476
train-epoch-step: 82-456 -- Loss: 0.1460796594619751
train-epoch-step: 82-457 -- Loss: 0.25545138120651245
train-epoch-step: 82-458 -- Loss: 0.19951491057872772
train-epoch-step: 82-459 -- Loss: 0.254067987203598
train-epoch-step: 82-460 -- Loss: 0.14333361387252808
train-epoch-step: 82-461 -- Loss: 0.14853185415267944
train-epoch-step: 82-462 -- Loss: 0.1891554594039917
train-epoch-step: 82-463 -- Loss: 0.14864897727966309
train-epoch-step: 82-464 -- Loss: 0.19844447076320648
train-epoch-step: 82-465 -- Loss: 0.4330836534500122
train-epoch-step: 82-466 -- Loss: 0.21960847079753876
train-epoch-step: 82-467 -- Loss: 0.12573818862438202
train-epoch-step: 82-468 -- Loss: 0.22698667645454407
train-epoch-step: 82-469 -- Loss: 0.2938310503959656
train-epoch-step: 82-470 -- Loss: 0.17912743985652924
train-epoch-step: 82-471 -- Loss: 0.16530577838420868
train-epoch-step: 82-472 -- Loss: 0.20221397280693054
train-epoch-step: 82-473 -- Loss: 0.17803087830543518
train-epoch-step: 82-474 -- Loss: 0.13534334301948547
train-epoch-step: 82-475 -- Loss: 0.13212132453918457
train-epoch-step: 82-476 -- Loss: 0.20548607409000397
train-epoch-step: 82-477 -- Loss: 0.28725481033325195
train-epoch-step: 82-478 -- Loss: 0.2110486477613449
train-epoch-step: 82-479 -- Loss: 0.16246289014816284
train-epoch-step: 82-480 -- Loss: 0.21206924319267273
train-epoch-step: 82-481 -- Loss: 0.3330894112586975
train-epoch-step: 82-482 -- Loss: 0.32602667808532715
train-epoch-step: 82-483 -- Loss: 0.19953173398971558
train-epoch-step: 82-484 -- Loss: 0.23199594020843506
train-epoch-step: 82-485 -- Loss: 0.17056748270988464
train-epoch-step: 82-486 -- Loss: 0.23667621612548828
train-epoch-step: 82-487 -- Loss: 0.26896345615386963
train-epoch-step: 82-488 -- Loss: 0.23204882442951202
train-epoch-step: 82-489 -- Loss: 0.23487351834774017
train-epoch-step: 82-490 -- Loss: 0.15697254240512848
train-epoch-step: 82-491 -- Loss: 0.15551604330539703
train-epoch-step: 82-492 -- Loss: 0.1403837949037552
train-epoch-step: 82-493 -- Loss: 0.2148759365081787
train-epoch-step: 82-494 -- Loss: 0.21604156494140625
train-epoch-step: 82-495 -- Loss: 0.2142634093761444
train-epoch-step: 82-496 -- Loss: 0.16027578711509705
train-epoch-step: 82-497 -- Loss: 0.20681613683700562
train-epoch-step: 82-498 -- Loss: 0.15693655610084534
train-epoch-step: 82-499 -- Loss: 0.1929633915424347
train-epoch-step: 82-500 -- Loss: 0.1608741581439972
train-epoch-step: 82-501 -- Loss: 0.24024991691112518
train-epoch-step: 82-502 -- Loss: 0.23261825740337372
train-epoch-step: 82-503 -- Loss: 0.27624762058258057
train-epoch-step: 82-504 -- Loss: 0.13764658570289612
train-epoch-step: 82-505 -- Loss: 0.19271935522556305
train-epoch-step: 82-506 -- Loss: 0.13680019974708557
train-epoch-step: 82-507 -- Loss: 0.2011938840150833
train-epoch-step: 82-508 -- Loss: 0.19656653702259064
train-epoch-step: 82-509 -- Loss: 0.18441882729530334
train-epoch-step: 82-510 -- Loss: 0.14614060521125793
train-epoch-step: 82-511 -- Loss: 0.2323199212551117
train-epoch-step: 82-512 -- Loss: 0.2157794088125229
train-epoch-step: 82-513 -- Loss: 0.23018738627433777
train-epoch-step: 82-514 -- Loss: 0.15689536929130554
train-epoch-step: 82-515 -- Loss: 0.17126186192035675
train-epoch-step: 82-516 -- Loss: 0.18012550473213196
train-epoch-step: 82-517 -- Loss: 0.18108296394348145
train-epoch-step: 82-518 -- Loss: 0.13788405060768127
train-epoch-step: 82-519 -- Loss: 0.14117959141731262
train-epoch-step: 82-520 -- Loss: 0.18569573760032654
train-epoch-step: 82-521 -- Loss: 0.2488260269165039
train-epoch-step: 82-522 -- Loss: 0.19920966029167175
train-epoch-step: 82-523 -- Loss: 0.1629350632429123
train-epoch-step: 82-524 -- Loss: 0.17216891050338745
train-epoch-step: 82-525 -- Loss: 0.20400071144104004
train-epoch-step: 82-526 -- Loss: 0.1345273107290268
train-epoch-step: 82-527 -- Loss: 0.16500791907310486
train-epoch-step: 82-528 -- Loss: 0.160487100481987
train-epoch-step: 82-529 -- Loss: 0.16338706016540527
train-epoch-step: 82-530 -- Loss: 0.17880204319953918
train-epoch-step: 82-531 -- Loss: 0.2113932967185974
train-epoch-step: 82-532 -- Loss: 0.17621544003486633
train-epoch-step: 82-533 -- Loss: 0.17878922820091248
train-epoch-step: 82-534 -- Loss: 0.13513337075710297
train-epoch-step: 82-535 -- Loss: 0.33560192584991455
train-epoch-step: 82-536 -- Loss: 0.1644088625907898
train-epoch-step: 82-537 -- Loss: 0.14937348663806915
train-epoch-step: 82-538 -- Loss: 0.1101529449224472
train-epoch-step: 82-539 -- Loss: 0.1860027015209198
train-epoch-step: 82-540 -- Loss: 0.13724489510059357
train-epoch-step: 82-541 -- Loss: 0.22067002952098846
train-epoch-step: 82-542 -- Loss: 0.2702208459377289
train-epoch-step: 82-543 -- Loss: 0.17061391472816467
train-epoch-step: 82-544 -- Loss: 0.22753402590751648
train-epoch-step: 82-545 -- Loss: 0.21146215498447418
train-epoch-step: 82-546 -- Loss: 0.2213507890701294
train-epoch-step: 82-547 -- Loss: 0.21129253506660461
train-epoch-step: 82-548 -- Loss: 0.09252062439918518
train-epoch-step: 82-549 -- Loss: 0.14928798377513885
train-epoch-step: 82-550 -- Loss: 0.19947516918182373
train-epoch-step: 82-551 -- Loss: 0.15480385720729828
train-epoch-step: 82-552 -- Loss: 0.13259977102279663
train-epoch-step: 82-553 -- Loss: 0.1949792206287384
train-epoch-step: 82-554 -- Loss: 0.20205152034759521
train-epoch-step: 82-555 -- Loss: 0.27629518508911133
train-epoch-step: 82-556 -- Loss: 0.16460132598876953
train-epoch-step: 82-557 -- Loss: 0.2380261868238449
train-epoch-step: 82-558 -- Loss: 0.2671442925930023
train-epoch-step: 82-559 -- Loss: 0.1549401432275772
train-epoch-step: 82-560 -- Loss: 0.20829841494560242
train-epoch-step: 82-561 -- Loss: 0.1978922039270401
train-epoch-step: 82-562 -- Loss: 0.16951116919517517
train-epoch-step: 82-563 -- Loss: 0.1919350028038025
train-epoch-step: 82-564 -- Loss: 0.10604344308376312
train-epoch-step: 82-565 -- Loss: 0.18379604816436768
train-epoch-step: 82-566 -- Loss: 0.151858389377594
train-epoch-step: 82-567 -- Loss: 0.21553170680999756
train-epoch-step: 82-568 -- Loss: 0.16370761394500732
train-epoch-step: 82-569 -- Loss: 0.25935831665992737
train-epoch-step: 82-570 -- Loss: 0.18109147250652313
train-epoch-step: 82-571 -- Loss: 0.21644006669521332
train-epoch-step: 82-572 -- Loss: 0.23954996466636658
train-epoch-step: 82-573 -- Loss: 0.19911636412143707
train-epoch-step: 82-574 -- Loss: 0.2697462737560272
train-epoch-step: 82-575 -- Loss: 0.30780133605003357
train-epoch-step: 82-576 -- Loss: 0.12046309560537338
train-epoch-step: 82-577 -- Loss: 0.16614361107349396
train-epoch-step: 82-578 -- Loss: 0.21519628167152405
train-epoch-step: 82-579 -- Loss: 0.17043854296207428
train-epoch-step: 82-580 -- Loss: 0.17846961319446564
train-epoch-step: 82-581 -- Loss: 0.14306750893592834
train-epoch-step: 82-582 -- Loss: 0.21054241061210632
train-epoch-step: 82-583 -- Loss: 0.21848420798778534
train-epoch-step: 82-584 -- Loss: 0.16899414360523224
train-epoch-step: 82-585 -- Loss: 0.19263163208961487
train-epoch-step: 82-586 -- Loss: 0.2585863173007965
train-epoch-step: 82-587 -- Loss: 0.1582302749156952
train-epoch-step: 82-588 -- Loss: 0.12941527366638184
val-epoch-step: 82-589 -- Loss: 0.21775288879871368
val-epoch-step: 82-590 -- Loss: 0.16209012269973755
val-epoch-step: 82-591 -- Loss: 0.23717284202575684
val-epoch-step: 82-592 -- Loss: 0.17279385030269623
val-epoch-step: 82-593 -- Loss: 0.1597663164138794
val-epoch-step: 82-594 -- Loss: 0.36710605025291443
val-epoch-step: 82-595 -- Loss: 0.17875543236732483
val-epoch-step: 82-596 -- Loss: 0.23668187856674194
val-epoch-step: 82-597 -- Loss: 0.17442889511585236
val-epoch-step: 82-598 -- Loss: 0.1627051681280136
val-epoch-step: 82-599 -- Loss: 0.19556371867656708
val-epoch-step: 82-600 -- Loss: 0.1749677062034607
val-epoch-step: 82-601 -- Loss: 0.15447960793972015
val-epoch-step: 82-602 -- Loss: 0.13599622249603271
val-epoch-step: 82-603 -- Loss: 0.20542362332344055
val-epoch-step: 82-604 -- Loss: 0.14916113018989563
val-epoch-step: 82-605 -- Loss: 0.14803989231586456
val-epoch-step: 82-606 -- Loss: 0.3353411555290222
val-epoch-step: 82-607 -- Loss: 0.1507234275341034
val-epoch-step: 82-608 -- Loss: 0.2544323205947876
val-epoch-step: 82-609 -- Loss: 0.1735077202320099
val-epoch-step: 82-610 -- Loss: 0.1911296546459198
val-epoch-step: 82-611 -- Loss: 0.15985597670078278
val-epoch-step: 82-612 -- Loss: 0.39079225063323975
val-epoch-step: 82-613 -- Loss: 0.18026721477508545
val-epoch-step: 82-614 -- Loss: 0.18535681068897247
val-epoch-step: 82-615 -- Loss: 0.17268724739551544
val-epoch-step: 82-616 -- Loss: 0.14960266649723053
val-epoch-step: 82-617 -- Loss: 0.2018132358789444
val-epoch-step: 82-618 -- Loss: 0.18018180131912231
val-epoch-step: 82-619 -- Loss: 0.2100123167037964
val-epoch-step: 82-620 -- Loss: 0.1418651044368744
val-epoch-step: 82-621 -- Loss: 0.13152174651622772
val-epoch-step: 82-622 -- Loss: 0.14416424930095673
val-epoch-step: 82-623 -- Loss: 0.15159156918525696
val-epoch-step: 82-624 -- Loss: 0.14324602484703064
val-epoch-step: 82-625 -- Loss: 0.1627615988254547
val-epoch-step: 82-626 -- Loss: 0.19964073598384857
val-epoch-step: 82-627 -- Loss: 0.18243665993213654
val-epoch-step: 82-628 -- Loss: 0.44104135036468506
val-epoch-step: 82-629 -- Loss: 0.25131070613861084
val-epoch-step: 82-630 -- Loss: 0.347304105758667
val-epoch-step: 82-631 -- Loss: 0.153443843126297
val-epoch-step: 82-632 -- Loss: 0.212083637714386
val-epoch-step: 82-633 -- Loss: 0.15980412065982819
val-epoch-step: 82-634 -- Loss: 0.16446122527122498
val-epoch-step: 82-635 -- Loss: 0.12127562612295151
val-epoch-step: 82-636 -- Loss: 0.16818022727966309
val-epoch-step: 82-637 -- Loss: 0.19055482745170593
val-epoch-step: 82-638 -- Loss: 0.15553593635559082
val-epoch-step: 82-639 -- Loss: 0.2775431275367737
val-epoch-step: 82-640 -- Loss: 0.25419551134109497
val-epoch-step: 82-641 -- Loss: 0.15910959243774414
val-epoch-step: 82-642 -- Loss: 0.19767358899116516
val-epoch-step: 82-643 -- Loss: 0.20493535697460175
val-epoch-step: 82-644 -- Loss: 0.165357768535614
val-epoch-step: 82-645 -- Loss: 0.22934052348136902
val-epoch-step: 82-646 -- Loss: 0.13451386988162994
val-epoch-step: 82-647 -- Loss: 0.13183853030204773
val-epoch-step: 82-648 -- Loss: 0.15498167276382446
val-epoch-step: 82-649 -- Loss: 0.23038330674171448
val-epoch-step: 82-650 -- Loss: 0.2535390853881836
val-epoch-step: 82-651 -- Loss: 0.14125916361808777
val-epoch-step: 82-652 -- Loss: 0.15232443809509277
val-epoch-step: 82-653 -- Loss: 0.2136811763048172
val-epoch-step: 82-654 -- Loss: 0.12513810396194458
Epoch: 82 -- Train Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 83-0 -- Loss: 0.22964544594287872
train-epoch-step: 83-1 -- Loss: 0.14983460307121277
train-epoch-step: 83-2 -- Loss: 0.20164330303668976
train-epoch-step: 83-3 -- Loss: 0.14478091895580292
train-epoch-step: 83-4 -- Loss: 0.1571069061756134
train-epoch-step: 83-5 -- Loss: 0.19638226926326752
train-epoch-step: 83-6 -- Loss: 0.2305760532617569
train-epoch-step: 83-7 -- Loss: 0.16896426677703857
train-epoch-step: 83-8 -- Loss: 0.17457188665866852
train-epoch-step: 83-9 -- Loss: 0.2599671185016632
train-epoch-step: 83-10 -- Loss: 0.19966349005699158
train-epoch-step: 83-11 -- Loss: 0.1922129988670349
train-epoch-step: 83-12 -- Loss: 0.15686360001564026
train-epoch-step: 83-13 -- Loss: 0.19772019982337952
train-epoch-step: 83-14 -- Loss: 0.1635802537202835
train-epoch-step: 83-15 -- Loss: 0.17777441442012787
train-epoch-step: 83-16 -- Loss: 0.1658070832490921
train-epoch-step: 83-17 -- Loss: 0.24424514174461365
train-epoch-step: 83-18 -- Loss: 0.21457603573799133
train-epoch-step: 83-19 -- Loss: 0.1368427872657776
train-epoch-step: 83-20 -- Loss: 0.23892076313495636
train-epoch-step: 83-21 -- Loss: 0.2828083634376526
train-epoch-step: 83-22 -- Loss: 0.16216188669204712
train-epoch-step: 83-23 -- Loss: 0.1480344831943512
train-epoch-step: 83-24 -- Loss: 0.13041849434375763
train-epoch-step: 83-25 -- Loss: 0.22313235700130463
train-epoch-step: 83-26 -- Loss: 0.19109457731246948
train-epoch-step: 83-27 -- Loss: 0.24677367508411407
train-epoch-step: 83-28 -- Loss: 0.12623301148414612
train-epoch-step: 83-29 -- Loss: 0.24450337886810303
train-epoch-step: 83-30 -- Loss: 0.11117242276668549
train-epoch-step: 83-31 -- Loss: 0.16114442050457
train-epoch-step: 83-32 -- Loss: 0.17477266490459442
train-epoch-step: 83-33 -- Loss: 0.2870425581932068
train-epoch-step: 83-34 -- Loss: 0.1789359748363495
train-epoch-step: 83-35 -- Loss: 0.25241804122924805
train-epoch-step: 83-36 -- Loss: 0.13912540674209595
train-epoch-step: 83-37 -- Loss: 0.13756506145000458
train-epoch-step: 83-38 -- Loss: 0.17973539233207703
train-epoch-step: 83-39 -- Loss: 0.2552148103713989
train-epoch-step: 83-40 -- Loss: 0.21466417610645294
train-epoch-step: 83-41 -- Loss: 0.22223907709121704
train-epoch-step: 83-42 -- Loss: 0.15462985634803772
train-epoch-step: 83-43 -- Loss: 0.2969399690628052
train-epoch-step: 83-44 -- Loss: 0.12462890148162842
train-epoch-step: 83-45 -- Loss: 0.12814249098300934
train-epoch-step: 83-46 -- Loss: 0.19434507191181183
train-epoch-step: 83-47 -- Loss: 0.2104284018278122
train-epoch-step: 83-48 -- Loss: 0.1594155877828598
train-epoch-step: 83-49 -- Loss: 0.22587591409683228
train-epoch-step: 83-50 -- Loss: 0.11326545476913452
train-epoch-step: 83-51 -- Loss: 0.20250961184501648
train-epoch-step: 83-52 -- Loss: 0.15452197194099426
train-epoch-step: 83-53 -- Loss: 0.21219642460346222
train-epoch-step: 83-54 -- Loss: 0.2815624475479126
train-epoch-step: 83-55 -- Loss: 0.16893205046653748
train-epoch-step: 83-56 -- Loss: 0.18275079131126404
train-epoch-step: 83-57 -- Loss: 0.2410578429698944
train-epoch-step: 83-58 -- Loss: 0.28948742151260376
train-epoch-step: 83-59 -- Loss: 0.23979555070400238
train-epoch-step: 83-60 -- Loss: 0.12754306197166443
train-epoch-step: 83-61 -- Loss: 0.1973351538181305
train-epoch-step: 83-62 -- Loss: 0.18930168449878693
train-epoch-step: 83-63 -- Loss: 0.140432670712471
train-epoch-step: 83-64 -- Loss: 0.14606407284736633
train-epoch-step: 83-65 -- Loss: 0.18156856298446655
train-epoch-step: 83-66 -- Loss: 0.11201842129230499
train-epoch-step: 83-67 -- Loss: 0.1259007602930069
train-epoch-step: 83-68 -- Loss: 0.2238258421421051
train-epoch-step: 83-69 -- Loss: 0.12135167419910431
train-epoch-step: 83-70 -- Loss: 0.2441069334745407
train-epoch-step: 83-71 -- Loss: 0.2589755058288574
train-epoch-step: 83-72 -- Loss: 0.18091543018817902
train-epoch-step: 83-73 -- Loss: 0.2061360478401184
train-epoch-step: 83-74 -- Loss: 0.09970779716968536
train-epoch-step: 83-75 -- Loss: 0.13228142261505127
train-epoch-step: 83-76 -- Loss: 0.15028204023838043
train-epoch-step: 83-77 -- Loss: 0.22612620890140533
train-epoch-step: 83-78 -- Loss: 0.2675136923789978
train-epoch-step: 83-79 -- Loss: 0.1901552528142929
train-epoch-step: 83-80 -- Loss: 0.25334101915359497
train-epoch-step: 83-81 -- Loss: 0.12901246547698975
train-epoch-step: 83-82 -- Loss: 0.2538030743598938
train-epoch-step: 83-83 -- Loss: 0.17843270301818848
train-epoch-step: 83-84 -- Loss: 0.1880471110343933
train-epoch-step: 83-85 -- Loss: 0.17281439900398254
train-epoch-step: 83-86 -- Loss: 0.12330776453018188
train-epoch-step: 83-87 -- Loss: 0.22340872883796692
train-epoch-step: 83-88 -- Loss: 0.13667353987693787
train-epoch-step: 83-89 -- Loss: 0.1853235363960266
train-epoch-step: 83-90 -- Loss: 0.18869192898273468
train-epoch-step: 83-91 -- Loss: 0.2436412274837494
train-epoch-step: 83-92 -- Loss: 0.15150760114192963
train-epoch-step: 83-93 -- Loss: 0.20070359110832214
train-epoch-step: 83-94 -- Loss: 0.23233270645141602
train-epoch-step: 83-95 -- Loss: 0.19036124646663666
train-epoch-step: 83-96 -- Loss: 0.22107142210006714
train-epoch-step: 83-97 -- Loss: 0.18257635831832886
train-epoch-step: 83-98 -- Loss: 0.15354357659816742
train-epoch-step: 83-99 -- Loss: 0.18406951427459717
train-epoch-step: 83-100 -- Loss: 0.1833227425813675
train-epoch-step: 83-101 -- Loss: 0.2790861129760742
train-epoch-step: 83-102 -- Loss: 0.23863005638122559
train-epoch-step: 83-103 -- Loss: 0.18028020858764648
train-epoch-step: 83-104 -- Loss: 0.15630212426185608
train-epoch-step: 83-105 -- Loss: 0.2847878932952881
train-epoch-step: 83-106 -- Loss: 0.17166973650455475
train-epoch-step: 83-107 -- Loss: 0.18812675774097443
train-epoch-step: 83-108 -- Loss: 0.18721903860569
train-epoch-step: 83-109 -- Loss: 0.14442166686058044
train-epoch-step: 83-110 -- Loss: 0.17810659110546112
train-epoch-step: 83-111 -- Loss: 0.17583417892456055
train-epoch-step: 83-112 -- Loss: 0.17094089090824127
train-epoch-step: 83-113 -- Loss: 0.16506515443325043
train-epoch-step: 83-114 -- Loss: 0.19344499707221985
train-epoch-step: 83-115 -- Loss: 0.15803705155849457
train-epoch-step: 83-116 -- Loss: 0.13710571825504303
train-epoch-step: 83-117 -- Loss: 0.13243383169174194
train-epoch-step: 83-118 -- Loss: 0.18928730487823486
train-epoch-step: 83-119 -- Loss: 0.15209785103797913
train-epoch-step: 83-120 -- Loss: 0.24491259455680847
train-epoch-step: 83-121 -- Loss: 0.2347574383020401
train-epoch-step: 83-122 -- Loss: 0.21179121732711792
train-epoch-step: 83-123 -- Loss: 0.20961406826972961
train-epoch-step: 83-124 -- Loss: 0.12005626410245895
train-epoch-step: 83-125 -- Loss: 0.1491907685995102
train-epoch-step: 83-126 -- Loss: 0.2230849415063858
train-epoch-step: 83-127 -- Loss: 0.17054513096809387
train-epoch-step: 83-128 -- Loss: 0.17011898756027222
train-epoch-step: 83-129 -- Loss: 0.13919717073440552
train-epoch-step: 83-130 -- Loss: 0.20462007820606232
train-epoch-step: 83-131 -- Loss: 0.12973052263259888
train-epoch-step: 83-132 -- Loss: 0.1922871619462967
train-epoch-step: 83-133 -- Loss: 0.11498899012804031
train-epoch-step: 83-134 -- Loss: 0.19328682124614716
train-epoch-step: 83-135 -- Loss: 0.13225604593753815
train-epoch-step: 83-136 -- Loss: 0.1313333809375763
train-epoch-step: 83-137 -- Loss: 0.24025751650333405
train-epoch-step: 83-138 -- Loss: 0.25690901279449463
train-epoch-step: 83-139 -- Loss: 0.13043001294136047
train-epoch-step: 83-140 -- Loss: 0.20631004869937897
train-epoch-step: 83-141 -- Loss: 0.23160824179649353
train-epoch-step: 83-142 -- Loss: 0.20028364658355713
train-epoch-step: 83-143 -- Loss: 0.1706569641828537
train-epoch-step: 83-144 -- Loss: 0.20698262751102448
train-epoch-step: 83-145 -- Loss: 0.14048564434051514
train-epoch-step: 83-146 -- Loss: 0.17841391265392303
train-epoch-step: 83-147 -- Loss: 0.16997113823890686
train-epoch-step: 83-148 -- Loss: 0.16325441002845764
train-epoch-step: 83-149 -- Loss: 0.11672842502593994
train-epoch-step: 83-150 -- Loss: 0.18353059887886047
train-epoch-step: 83-151 -- Loss: 0.1872578114271164
train-epoch-step: 83-152 -- Loss: 0.19379767775535583
train-epoch-step: 83-153 -- Loss: 0.26011982560157776
train-epoch-step: 83-154 -- Loss: 0.1313938945531845
train-epoch-step: 83-155 -- Loss: 0.13227121531963348
train-epoch-step: 83-156 -- Loss: 0.11757630854845047
train-epoch-step: 83-157 -- Loss: 0.16200143098831177
train-epoch-step: 83-158 -- Loss: 0.1614454984664917
train-epoch-step: 83-159 -- Loss: 0.17803944647312164
train-epoch-step: 83-160 -- Loss: 0.20996512472629547
train-epoch-step: 83-161 -- Loss: 0.2026500403881073
train-epoch-step: 83-162 -- Loss: 0.20423480868339539
train-epoch-step: 83-163 -- Loss: 0.18580755591392517
train-epoch-step: 83-164 -- Loss: 0.19185644388198853
train-epoch-step: 83-165 -- Loss: 0.15755873918533325
train-epoch-step: 83-166 -- Loss: 0.1283932626247406
train-epoch-step: 83-167 -- Loss: 0.11924224346876144
train-epoch-step: 83-168 -- Loss: 0.20040267705917358
train-epoch-step: 83-169 -- Loss: 0.13851845264434814
train-epoch-step: 83-170 -- Loss: 0.19424590468406677
train-epoch-step: 83-171 -- Loss: 0.14561891555786133
train-epoch-step: 83-172 -- Loss: 0.25801628828048706
train-epoch-step: 83-173 -- Loss: 0.13383005559444427
train-epoch-step: 83-174 -- Loss: 0.2425919473171234
train-epoch-step: 83-175 -- Loss: 0.17950719594955444
train-epoch-step: 83-176 -- Loss: 0.13520552217960358
train-epoch-step: 83-177 -- Loss: 0.17760249972343445
train-epoch-step: 83-178 -- Loss: 0.1748228222131729
train-epoch-step: 83-179 -- Loss: 0.16074463725090027
train-epoch-step: 83-180 -- Loss: 0.14674367010593414
train-epoch-step: 83-181 -- Loss: 0.16365361213684082
train-epoch-step: 83-182 -- Loss: 0.19475437700748444
train-epoch-step: 83-183 -- Loss: 0.27924972772598267
train-epoch-step: 83-184 -- Loss: 0.1403389573097229
train-epoch-step: 83-185 -- Loss: 0.14629922807216644
train-epoch-step: 83-186 -- Loss: 0.18750059604644775
train-epoch-step: 83-187 -- Loss: 0.20465487241744995
train-epoch-step: 83-188 -- Loss: 0.16838940978050232
train-epoch-step: 83-189 -- Loss: 0.10144970566034317
train-epoch-step: 83-190 -- Loss: 0.18052934110164642
train-epoch-step: 83-191 -- Loss: 0.15678918361663818
train-epoch-step: 83-192 -- Loss: 0.23020456731319427
train-epoch-step: 83-193 -- Loss: 0.20471471548080444
train-epoch-step: 83-194 -- Loss: 0.1817307323217392
train-epoch-step: 83-195 -- Loss: 0.16024470329284668
train-epoch-step: 83-196 -- Loss: 0.16256004571914673
train-epoch-step: 83-197 -- Loss: 0.12442309409379959
train-epoch-step: 83-198 -- Loss: 0.12406763434410095
train-epoch-step: 83-199 -- Loss: 0.14370957016944885
train-epoch-step: 83-200 -- Loss: 0.12265212088823318
train-epoch-step: 83-201 -- Loss: 0.18324440717697144
train-epoch-step: 83-202 -- Loss: 0.13497893512248993
train-epoch-step: 83-203 -- Loss: 0.1743190586566925
train-epoch-step: 83-204 -- Loss: 0.13459455966949463
train-epoch-step: 83-205 -- Loss: 0.18604502081871033
train-epoch-step: 83-206 -- Loss: 0.1961517333984375
train-epoch-step: 83-207 -- Loss: 0.131117582321167
train-epoch-step: 83-208 -- Loss: 0.18679702281951904
train-epoch-step: 83-209 -- Loss: 0.14112365245819092
train-epoch-step: 83-210 -- Loss: 0.13258415460586548
train-epoch-step: 83-211 -- Loss: 0.20690956711769104
train-epoch-step: 83-212 -- Loss: 0.19869017601013184
train-epoch-step: 83-213 -- Loss: 0.12605297565460205
train-epoch-step: 83-214 -- Loss: 0.1471918523311615
train-epoch-step: 83-215 -- Loss: 0.12667402625083923
train-epoch-step: 83-216 -- Loss: 0.19670209288597107
train-epoch-step: 83-217 -- Loss: 0.21716095507144928
train-epoch-step: 83-218 -- Loss: 0.1434435099363327
train-epoch-step: 83-219 -- Loss: 0.16238319873809814
train-epoch-step: 83-220 -- Loss: 0.12544135749340057
train-epoch-step: 83-221 -- Loss: 0.1985827386379242
train-epoch-step: 83-222 -- Loss: 0.11619454622268677
train-epoch-step: 83-223 -- Loss: 0.17229004204273224
train-epoch-step: 83-224 -- Loss: 0.20736947655677795
train-epoch-step: 83-225 -- Loss: 0.2606233060359955
train-epoch-step: 83-226 -- Loss: 0.2124868631362915
train-epoch-step: 83-227 -- Loss: 0.21599090099334717
train-epoch-step: 83-228 -- Loss: 0.19096605479717255
train-epoch-step: 83-229 -- Loss: 0.17350850999355316
train-epoch-step: 83-230 -- Loss: 0.18765698373317719
train-epoch-step: 83-231 -- Loss: 0.15912684798240662
train-epoch-step: 83-232 -- Loss: 0.18288758397102356
train-epoch-step: 83-233 -- Loss: 0.08420909196138382
train-epoch-step: 83-234 -- Loss: 0.17785242199897766
train-epoch-step: 83-235 -- Loss: 0.15087777376174927
train-epoch-step: 83-236 -- Loss: 0.1815270632505417
train-epoch-step: 83-237 -- Loss: 0.22794349491596222
train-epoch-step: 83-238 -- Loss: 0.1591154932975769
train-epoch-step: 83-239 -- Loss: 0.12738226354122162
train-epoch-step: 83-240 -- Loss: 0.22762352228164673
train-epoch-step: 83-241 -- Loss: 0.15479908883571625
train-epoch-step: 83-242 -- Loss: 0.2153923511505127
train-epoch-step: 83-243 -- Loss: 0.25809064507484436
train-epoch-step: 83-244 -- Loss: 0.20848006010055542
train-epoch-step: 83-245 -- Loss: 0.22401049733161926
train-epoch-step: 83-246 -- Loss: 0.2200092375278473
train-epoch-step: 83-247 -- Loss: 0.20942729711532593
train-epoch-step: 83-248 -- Loss: 0.1851823627948761
train-epoch-step: 83-249 -- Loss: 0.13525758683681488
train-epoch-step: 83-250 -- Loss: 0.19814851880073547
train-epoch-step: 83-251 -- Loss: 0.10404131561517715
train-epoch-step: 83-252 -- Loss: 0.2215731143951416
train-epoch-step: 83-253 -- Loss: 0.1392877995967865
train-epoch-step: 83-254 -- Loss: 0.22443819046020508
train-epoch-step: 83-255 -- Loss: 0.14581556618213654
train-epoch-step: 83-256 -- Loss: 0.15558722615242004
train-epoch-step: 83-257 -- Loss: 0.20763957500457764
train-epoch-step: 83-258 -- Loss: 0.14759045839309692
train-epoch-step: 83-259 -- Loss: 0.11230353266000748
train-epoch-step: 83-260 -- Loss: 0.20206311345100403
train-epoch-step: 83-261 -- Loss: 0.17209510505199432
train-epoch-step: 83-262 -- Loss: 0.2884187698364258
train-epoch-step: 83-263 -- Loss: 0.20196424424648285
train-epoch-step: 83-264 -- Loss: 0.17359572649002075
train-epoch-step: 83-265 -- Loss: 0.12445177882909775
train-epoch-step: 83-266 -- Loss: 0.1528186947107315
train-epoch-step: 83-267 -- Loss: 0.13435861468315125
train-epoch-step: 83-268 -- Loss: 0.12865179777145386
train-epoch-step: 83-269 -- Loss: 0.16896679997444153
train-epoch-step: 83-270 -- Loss: 0.11178214848041534
train-epoch-step: 83-271 -- Loss: 0.1513356864452362
train-epoch-step: 83-272 -- Loss: 0.11709807068109512
train-epoch-step: 83-273 -- Loss: 0.12367172539234161
train-epoch-step: 83-274 -- Loss: 0.1772107034921646
train-epoch-step: 83-275 -- Loss: 0.19519317150115967
train-epoch-step: 83-276 -- Loss: 0.15228864550590515
train-epoch-step: 83-277 -- Loss: 0.15253837406635284
train-epoch-step: 83-278 -- Loss: 0.14666011929512024
train-epoch-step: 83-279 -- Loss: 0.13845661282539368
train-epoch-step: 83-280 -- Loss: 0.2158573567867279
train-epoch-step: 83-281 -- Loss: 0.17716044187545776
train-epoch-step: 83-282 -- Loss: 0.13843262195587158
train-epoch-step: 83-283 -- Loss: 0.11854805797338486
train-epoch-step: 83-284 -- Loss: 0.19145306944847107
train-epoch-step: 83-285 -- Loss: 0.1882423311471939
train-epoch-step: 83-286 -- Loss: 0.14932525157928467
train-epoch-step: 83-287 -- Loss: 0.21077774465084076
train-epoch-step: 83-288 -- Loss: 0.0942501574754715
train-epoch-step: 83-289 -- Loss: 0.11983607709407806
train-epoch-step: 83-290 -- Loss: 0.17527824640274048
train-epoch-step: 83-291 -- Loss: 0.12133203446865082
train-epoch-step: 83-292 -- Loss: 0.1826850324869156
train-epoch-step: 83-293 -- Loss: 0.1362944096326828
train-epoch-step: 83-294 -- Loss: 0.16099625825881958
train-epoch-step: 83-295 -- Loss: 0.4437297582626343
train-epoch-step: 83-296 -- Loss: 0.1714831292629242
train-epoch-step: 83-297 -- Loss: 0.20839987695217133
train-epoch-step: 83-298 -- Loss: 0.22744068503379822
train-epoch-step: 83-299 -- Loss: 0.16377142071723938
train-epoch-step: 83-300 -- Loss: 0.18028570711612701
train-epoch-step: 83-301 -- Loss: 0.1639045923948288
train-epoch-step: 83-302 -- Loss: 0.24517637491226196
train-epoch-step: 83-303 -- Loss: 0.22881954908370972
train-epoch-step: 83-304 -- Loss: 0.1647314578294754
train-epoch-step: 83-305 -- Loss: 0.15002089738845825
train-epoch-step: 83-306 -- Loss: 0.2619309425354004
train-epoch-step: 83-307 -- Loss: 0.1724545806646347
train-epoch-step: 83-308 -- Loss: 0.2519453167915344
train-epoch-step: 83-309 -- Loss: 0.16041888296604156
train-epoch-step: 83-310 -- Loss: 0.19060024619102478
train-epoch-step: 83-311 -- Loss: 0.16403613984584808
train-epoch-step: 83-312 -- Loss: 0.22808778285980225
train-epoch-step: 83-313 -- Loss: 0.0985192060470581
train-epoch-step: 83-314 -- Loss: 0.19362688064575195
train-epoch-step: 83-315 -- Loss: 0.16796138882637024
train-epoch-step: 83-316 -- Loss: 0.17718647420406342
train-epoch-step: 83-317 -- Loss: 0.14546072483062744
train-epoch-step: 83-318 -- Loss: 0.17974314093589783
train-epoch-step: 83-319 -- Loss: 0.18497063219547272
train-epoch-step: 83-320 -- Loss: 0.12023431062698364
train-epoch-step: 83-321 -- Loss: 0.13538751006126404
train-epoch-step: 83-322 -- Loss: 0.21850521862506866
train-epoch-step: 83-323 -- Loss: 0.166636660695076
train-epoch-step: 83-324 -- Loss: 0.2746809422969818
train-epoch-step: 83-325 -- Loss: 0.15777979791164398
train-epoch-step: 83-326 -- Loss: 0.18233564496040344
train-epoch-step: 83-327 -- Loss: 0.21564391255378723
train-epoch-step: 83-328 -- Loss: 0.20152859389781952
train-epoch-step: 83-329 -- Loss: 0.3700963854789734
train-epoch-step: 83-330 -- Loss: 0.3995151221752167
train-epoch-step: 83-331 -- Loss: 0.21287134289741516
train-epoch-step: 83-332 -- Loss: 0.10278361290693283
train-epoch-step: 83-333 -- Loss: 0.18562555313110352
train-epoch-step: 83-334 -- Loss: 0.1557529717683792
train-epoch-step: 83-335 -- Loss: 0.1729722023010254
train-epoch-step: 83-336 -- Loss: 0.1550990343093872
train-epoch-step: 83-337 -- Loss: 0.20370855927467346
train-epoch-step: 83-338 -- Loss: 0.16967721283435822
train-epoch-step: 83-339 -- Loss: 0.14336128532886505
train-epoch-step: 83-340 -- Loss: 0.2027868926525116
train-epoch-step: 83-341 -- Loss: 0.14332357048988342
train-epoch-step: 83-342 -- Loss: 0.16815365850925446
train-epoch-step: 83-343 -- Loss: 0.1525428593158722
train-epoch-step: 83-344 -- Loss: 0.16637538373470306
train-epoch-step: 83-345 -- Loss: 0.15058891475200653
train-epoch-step: 83-346 -- Loss: 0.20496709644794464
train-epoch-step: 83-347 -- Loss: 0.15473192930221558
train-epoch-step: 83-348 -- Loss: 0.20752198994159698
train-epoch-step: 83-349 -- Loss: 0.2152526080608368
train-epoch-step: 83-350 -- Loss: 0.26395392417907715
train-epoch-step: 83-351 -- Loss: 0.19441905617713928
train-epoch-step: 83-352 -- Loss: 0.12678657472133636
train-epoch-step: 83-353 -- Loss: 0.1944655030965805
train-epoch-step: 83-354 -- Loss: 0.278389573097229
train-epoch-step: 83-355 -- Loss: 0.1156504824757576
train-epoch-step: 83-356 -- Loss: 0.11540737003087997
train-epoch-step: 83-357 -- Loss: 0.19634473323822021
train-epoch-step: 83-358 -- Loss: 0.18364645540714264
train-epoch-step: 83-359 -- Loss: 0.14126810431480408
train-epoch-step: 83-360 -- Loss: 0.12477567791938782
train-epoch-step: 83-361 -- Loss: 0.2436937689781189
train-epoch-step: 83-362 -- Loss: 0.16729000210762024
train-epoch-step: 83-363 -- Loss: 0.10722360014915466
train-epoch-step: 83-364 -- Loss: 0.1807180643081665
train-epoch-step: 83-365 -- Loss: 0.1714784950017929
train-epoch-step: 83-366 -- Loss: 0.219847172498703
train-epoch-step: 83-367 -- Loss: 0.23063251376152039
train-epoch-step: 83-368 -- Loss: 0.19146165251731873
train-epoch-step: 83-369 -- Loss: 0.2875749468803406
train-epoch-step: 83-370 -- Loss: 0.12434831261634827
train-epoch-step: 83-371 -- Loss: 0.12064817547798157
train-epoch-step: 83-372 -- Loss: 0.14713144302368164
train-epoch-step: 83-373 -- Loss: 0.1969674825668335
train-epoch-step: 83-374 -- Loss: 0.15395519137382507
train-epoch-step: 83-375 -- Loss: 0.26646149158477783
train-epoch-step: 83-376 -- Loss: 0.16519929468631744
train-epoch-step: 83-377 -- Loss: 0.22584375739097595
train-epoch-step: 83-378 -- Loss: 0.19591861963272095
train-epoch-step: 83-379 -- Loss: 0.11790168285369873
train-epoch-step: 83-380 -- Loss: 0.09129000455141068
train-epoch-step: 83-381 -- Loss: 0.24535919725894928
train-epoch-step: 83-382 -- Loss: 0.2383347898721695
train-epoch-step: 83-383 -- Loss: 0.18022605776786804
train-epoch-step: 83-384 -- Loss: 0.23235656321048737
train-epoch-step: 83-385 -- Loss: 0.1898420751094818
train-epoch-step: 83-386 -- Loss: 0.19897431135177612
train-epoch-step: 83-387 -- Loss: 0.2043183147907257
train-epoch-step: 83-388 -- Loss: 0.20484934747219086
train-epoch-step: 83-389 -- Loss: 0.1743801385164261
train-epoch-step: 83-390 -- Loss: 0.17608332633972168
train-epoch-step: 83-391 -- Loss: 0.14505663514137268
train-epoch-step: 83-392 -- Loss: 0.1823086142539978
train-epoch-step: 83-393 -- Loss: 0.15409399569034576
train-epoch-step: 83-394 -- Loss: 0.2071908712387085
train-epoch-step: 83-395 -- Loss: 0.16191984713077545
train-epoch-step: 83-396 -- Loss: 0.12533919513225555
train-epoch-step: 83-397 -- Loss: 0.12114302068948746
train-epoch-step: 83-398 -- Loss: 0.20048648118972778
train-epoch-step: 83-399 -- Loss: 0.17296069860458374
train-epoch-step: 83-400 -- Loss: 0.2764579951763153
train-epoch-step: 83-401 -- Loss: 0.12404866516590118
train-epoch-step: 83-402 -- Loss: 0.2609136700630188
train-epoch-step: 83-403 -- Loss: 0.15558937191963196
train-epoch-step: 83-404 -- Loss: 0.1360035389661789
train-epoch-step: 83-405 -- Loss: 0.14319951832294464
train-epoch-step: 83-406 -- Loss: 0.18033023178577423
train-epoch-step: 83-407 -- Loss: 0.11070002615451813
train-epoch-step: 83-408 -- Loss: 0.1631740778684616
train-epoch-step: 83-409 -- Loss: 0.16774828732013702
train-epoch-step: 83-410 -- Loss: 0.1673153042793274
train-epoch-step: 83-411 -- Loss: 0.2034614384174347
train-epoch-step: 83-412 -- Loss: 0.13164739310741425
train-epoch-step: 83-413 -- Loss: 0.14312177896499634
train-epoch-step: 83-414 -- Loss: 0.13255424797534943
train-epoch-step: 83-415 -- Loss: 0.1346803456544876
train-epoch-step: 83-416 -- Loss: 0.2731466293334961
train-epoch-step: 83-417 -- Loss: 0.19875751435756683
train-epoch-step: 83-418 -- Loss: 0.23129022121429443
train-epoch-step: 83-419 -- Loss: 0.1684543937444687
train-epoch-step: 83-420 -- Loss: 0.1504233181476593
train-epoch-step: 83-421 -- Loss: 0.1784212589263916
train-epoch-step: 83-422 -- Loss: 0.1462523490190506
train-epoch-step: 83-423 -- Loss: 0.17139370739459991
train-epoch-step: 83-424 -- Loss: 0.13769614696502686
train-epoch-step: 83-425 -- Loss: 0.17741480469703674
train-epoch-step: 83-426 -- Loss: 0.16620761156082153
train-epoch-step: 83-427 -- Loss: 0.11768140643835068
train-epoch-step: 83-428 -- Loss: 0.19546230137348175
train-epoch-step: 83-429 -- Loss: 0.17446884512901306
train-epoch-step: 83-430 -- Loss: 0.1400313824415207
train-epoch-step: 83-431 -- Loss: 0.1599637120962143
train-epoch-step: 83-432 -- Loss: 0.23892340064048767
train-epoch-step: 83-433 -- Loss: 0.1341117024421692
train-epoch-step: 83-434 -- Loss: 0.12841251492500305
train-epoch-step: 83-435 -- Loss: 0.16061511635780334
train-epoch-step: 83-436 -- Loss: 0.15406766533851624
train-epoch-step: 83-437 -- Loss: 0.1288997083902359
train-epoch-step: 83-438 -- Loss: 0.16688959300518036
train-epoch-step: 83-439 -- Loss: 0.25768181681632996
train-epoch-step: 83-440 -- Loss: 0.12734661996364594
train-epoch-step: 83-441 -- Loss: 0.1954537332057953
train-epoch-step: 83-442 -- Loss: 0.1703708916902542
train-epoch-step: 83-443 -- Loss: 0.15492689609527588
train-epoch-step: 83-444 -- Loss: 0.19222509860992432
train-epoch-step: 83-445 -- Loss: 0.17493653297424316
train-epoch-step: 83-446 -- Loss: 0.14430908858776093
train-epoch-step: 83-447 -- Loss: 0.18552890419960022
train-epoch-step: 83-448 -- Loss: 0.22143439948558807
train-epoch-step: 83-449 -- Loss: 0.18709181249141693
train-epoch-step: 83-450 -- Loss: 0.17473095655441284
train-epoch-step: 83-451 -- Loss: 0.14108392596244812
train-epoch-step: 83-452 -- Loss: 0.1402226835489273
train-epoch-step: 83-453 -- Loss: 0.08968035131692886
train-epoch-step: 83-454 -- Loss: 0.23385852575302124
train-epoch-step: 83-455 -- Loss: 0.12098182737827301
train-epoch-step: 83-456 -- Loss: 0.11873885244131088
train-epoch-step: 83-457 -- Loss: 0.21655121445655823
train-epoch-step: 83-458 -- Loss: 0.181989848613739
train-epoch-step: 83-459 -- Loss: 0.21042540669441223
train-epoch-step: 83-460 -- Loss: 0.12751908600330353
train-epoch-step: 83-461 -- Loss: 0.13418760895729065
train-epoch-step: 83-462 -- Loss: 0.16542252898216248
train-epoch-step: 83-463 -- Loss: 0.13405583798885345
train-epoch-step: 83-464 -- Loss: 0.1761241853237152
train-epoch-step: 83-465 -- Loss: 0.2558797597885132
train-epoch-step: 83-466 -- Loss: 0.21244817972183228
train-epoch-step: 83-467 -- Loss: 0.11451521515846252
train-epoch-step: 83-468 -- Loss: 0.16821210086345673
train-epoch-step: 83-469 -- Loss: 0.20722545683383942
train-epoch-step: 83-470 -- Loss: 0.16740931570529938
train-epoch-step: 83-471 -- Loss: 0.15054969489574432
train-epoch-step: 83-472 -- Loss: 0.15769293904304504
train-epoch-step: 83-473 -- Loss: 0.16161765158176422
train-epoch-step: 83-474 -- Loss: 0.12209724634885788
train-epoch-step: 83-475 -- Loss: 0.1076045036315918
train-epoch-step: 83-476 -- Loss: 0.19957450032234192
train-epoch-step: 83-477 -- Loss: 0.19407795369625092
train-epoch-step: 83-478 -- Loss: 0.18372292816638947
train-epoch-step: 83-479 -- Loss: 0.13723458349704742
train-epoch-step: 83-480 -- Loss: 0.19182449579238892
train-epoch-step: 83-481 -- Loss: 0.28251832723617554
train-epoch-step: 83-482 -- Loss: 0.2750566601753235
train-epoch-step: 83-483 -- Loss: 0.17855507135391235
train-epoch-step: 83-484 -- Loss: 0.21210354566574097
train-epoch-step: 83-485 -- Loss: 0.12880191206932068
train-epoch-step: 83-486 -- Loss: 0.29020625352859497
train-epoch-step: 83-487 -- Loss: 0.22832220792770386
train-epoch-step: 83-488 -- Loss: 0.18711233139038086
train-epoch-step: 83-489 -- Loss: 0.2223220020532608
train-epoch-step: 83-490 -- Loss: 0.13460730016231537
train-epoch-step: 83-491 -- Loss: 0.13637736439704895
train-epoch-step: 83-492 -- Loss: 0.12626434862613678
train-epoch-step: 83-493 -- Loss: 0.19275128841400146
train-epoch-step: 83-494 -- Loss: 0.2023763358592987
train-epoch-step: 83-495 -- Loss: 0.1961379051208496
train-epoch-step: 83-496 -- Loss: 0.14665524661540985
train-epoch-step: 83-497 -- Loss: 0.18540480732917786
train-epoch-step: 83-498 -- Loss: 0.14740322530269623
train-epoch-step: 83-499 -- Loss: 0.17067785561084747
train-epoch-step: 83-500 -- Loss: 0.14924407005310059
train-epoch-step: 83-501 -- Loss: 0.2126477211713791
train-epoch-step: 83-502 -- Loss: 0.17419332265853882
train-epoch-step: 83-503 -- Loss: 0.21526546776294708
train-epoch-step: 83-504 -- Loss: 0.12885400652885437
train-epoch-step: 83-505 -- Loss: 0.17504985630512238
train-epoch-step: 83-506 -- Loss: 0.11830753087997437
train-epoch-step: 83-507 -- Loss: 0.18004639446735382
train-epoch-step: 83-508 -- Loss: 0.17589184641838074
train-epoch-step: 83-509 -- Loss: 0.16443918645381927
train-epoch-step: 83-510 -- Loss: 0.12440831959247589
train-epoch-step: 83-511 -- Loss: 0.21430368721485138
train-epoch-step: 83-512 -- Loss: 0.17314596474170685
train-epoch-step: 83-513 -- Loss: 0.1867704689502716
train-epoch-step: 83-514 -- Loss: 0.14519068598747253
train-epoch-step: 83-515 -- Loss: 0.14668694138526917
train-epoch-step: 83-516 -- Loss: 0.17984803020954132
train-epoch-step: 83-517 -- Loss: 0.17228350043296814
train-epoch-step: 83-518 -- Loss: 0.13729621469974518
train-epoch-step: 83-519 -- Loss: 0.1339055746793747
train-epoch-step: 83-520 -- Loss: 0.18533337116241455
train-epoch-step: 83-521 -- Loss: 0.22454537451267242
train-epoch-step: 83-522 -- Loss: 0.17274582386016846
train-epoch-step: 83-523 -- Loss: 0.1571149230003357
train-epoch-step: 83-524 -- Loss: 0.17386046051979065
train-epoch-step: 83-525 -- Loss: 0.1945142298936844
train-epoch-step: 83-526 -- Loss: 0.12749646604061127
train-epoch-step: 83-527 -- Loss: 0.14450769126415253
train-epoch-step: 83-528 -- Loss: 0.15646198391914368
train-epoch-step: 83-529 -- Loss: 0.15203194320201874
train-epoch-step: 83-530 -- Loss: 0.16800421476364136
train-epoch-step: 83-531 -- Loss: 0.19166207313537598
train-epoch-step: 83-532 -- Loss: 0.16805584728717804
train-epoch-step: 83-533 -- Loss: 0.17567795515060425
train-epoch-step: 83-534 -- Loss: 0.1300521343946457
train-epoch-step: 83-535 -- Loss: 0.2500886917114258
train-epoch-step: 83-536 -- Loss: 0.15504197776317596
train-epoch-step: 83-537 -- Loss: 0.16947126388549805
train-epoch-step: 83-538 -- Loss: 0.10253343731164932
train-epoch-step: 83-539 -- Loss: 0.1863645762205124
train-epoch-step: 83-540 -- Loss: 0.140677809715271
train-epoch-step: 83-541 -- Loss: 0.20631296932697296
train-epoch-step: 83-542 -- Loss: 0.21701663732528687
train-epoch-step: 83-543 -- Loss: 0.1635439544916153
train-epoch-step: 83-544 -- Loss: 0.22457139194011688
train-epoch-step: 83-545 -- Loss: 0.19724638760089874
train-epoch-step: 83-546 -- Loss: 0.20665259659290314
train-epoch-step: 83-547 -- Loss: 0.17700406908988953
train-epoch-step: 83-548 -- Loss: 0.08972256630659103
train-epoch-step: 83-549 -- Loss: 0.14431801438331604
train-epoch-step: 83-550 -- Loss: 0.19555525481700897
train-epoch-step: 83-551 -- Loss: 0.15515831112861633
train-epoch-step: 83-552 -- Loss: 0.12451127171516418
train-epoch-step: 83-553 -- Loss: 0.18454663455486298
train-epoch-step: 83-554 -- Loss: 0.18704606592655182
train-epoch-step: 83-555 -- Loss: 0.2112974226474762
train-epoch-step: 83-556 -- Loss: 0.15213511884212494
train-epoch-step: 83-557 -- Loss: 0.22608819603919983
train-epoch-step: 83-558 -- Loss: 0.2560722231864929
train-epoch-step: 83-559 -- Loss: 0.14531728625297546
train-epoch-step: 83-560 -- Loss: 0.2028014212846756
train-epoch-step: 83-561 -- Loss: 0.18423467874526978
train-epoch-step: 83-562 -- Loss: 0.16052713990211487
train-epoch-step: 83-563 -- Loss: 0.19396932423114777
train-epoch-step: 83-564 -- Loss: 0.10069043934345245
train-epoch-step: 83-565 -- Loss: 0.1840670108795166
train-epoch-step: 83-566 -- Loss: 0.15223217010498047
train-epoch-step: 83-567 -- Loss: 0.20821379125118256
train-epoch-step: 83-568 -- Loss: 0.15870575606822968
train-epoch-step: 83-569 -- Loss: 0.24041259288787842
train-epoch-step: 83-570 -- Loss: 0.17538982629776
train-epoch-step: 83-571 -- Loss: 0.20869965851306915
train-epoch-step: 83-572 -- Loss: 0.23765338957309723
train-epoch-step: 83-573 -- Loss: 0.194093257188797
train-epoch-step: 83-574 -- Loss: 0.2448926717042923
train-epoch-step: 83-575 -- Loss: 0.31167417764663696
train-epoch-step: 83-576 -- Loss: 0.11679599434137344
train-epoch-step: 83-577 -- Loss: 0.16501624882221222
train-epoch-step: 83-578 -- Loss: 0.21032431721687317
train-epoch-step: 83-579 -- Loss: 0.16144166886806488
train-epoch-step: 83-580 -- Loss: 0.16874119639396667
train-epoch-step: 83-581 -- Loss: 0.13315097987651825
train-epoch-step: 83-582 -- Loss: 0.20238596200942993
train-epoch-step: 83-583 -- Loss: 0.22386139631271362
train-epoch-step: 83-584 -- Loss: 0.16036471724510193
train-epoch-step: 83-585 -- Loss: 0.19078415632247925
train-epoch-step: 83-586 -- Loss: 0.2582833766937256
train-epoch-step: 83-587 -- Loss: 0.16063757240772247
train-epoch-step: 83-588 -- Loss: 0.1259908527135849
val-epoch-step: 83-589 -- Loss: 0.20893600583076477
val-epoch-step: 83-590 -- Loss: 0.15225568413734436
val-epoch-step: 83-591 -- Loss: 0.23310568928718567
val-epoch-step: 83-592 -- Loss: 0.17455844581127167
val-epoch-step: 83-593 -- Loss: 0.15224723517894745
val-epoch-step: 83-594 -- Loss: 0.32966944575309753
val-epoch-step: 83-595 -- Loss: 0.17085732519626617
val-epoch-step: 83-596 -- Loss: 0.2199307531118393
val-epoch-step: 83-597 -- Loss: 0.16954827308654785
val-epoch-step: 83-598 -- Loss: 0.14212702214717865
val-epoch-step: 83-599 -- Loss: 0.18118104338645935
val-epoch-step: 83-600 -- Loss: 0.17849025130271912
val-epoch-step: 83-601 -- Loss: 0.15981797873973846
val-epoch-step: 83-602 -- Loss: 0.13896028697490692
val-epoch-step: 83-603 -- Loss: 0.18541648983955383
val-epoch-step: 83-604 -- Loss: 0.16463613510131836
val-epoch-step: 83-605 -- Loss: 0.14453233778476715
val-epoch-step: 83-606 -- Loss: 0.29381048679351807
val-epoch-step: 83-607 -- Loss: 0.13669666647911072
val-epoch-step: 83-608 -- Loss: 0.24661576747894287
val-epoch-step: 83-609 -- Loss: 0.16173937916755676
val-epoch-step: 83-610 -- Loss: 0.17743872106075287
val-epoch-step: 83-611 -- Loss: 0.15459217131137848
val-epoch-step: 83-612 -- Loss: 0.4118664264678955
val-epoch-step: 83-613 -- Loss: 0.17915955185890198
val-epoch-step: 83-614 -- Loss: 0.16655904054641724
val-epoch-step: 83-615 -- Loss: 0.17441144585609436
val-epoch-step: 83-616 -- Loss: 0.1525055468082428
val-epoch-step: 83-617 -- Loss: 0.19841770827770233
val-epoch-step: 83-618 -- Loss: 0.20257335901260376
val-epoch-step: 83-619 -- Loss: 0.21020814776420593
val-epoch-step: 83-620 -- Loss: 0.14177128672599792
val-epoch-step: 83-621 -- Loss: 0.13226500153541565
val-epoch-step: 83-622 -- Loss: 0.14032921195030212
val-epoch-step: 83-623 -- Loss: 0.1460665911436081
val-epoch-step: 83-624 -- Loss: 0.13965056836605072
val-epoch-step: 83-625 -- Loss: 0.1639474779367447
val-epoch-step: 83-626 -- Loss: 0.14867550134658813
val-epoch-step: 83-627 -- Loss: 0.1819676160812378
val-epoch-step: 83-628 -- Loss: 0.4792870879173279
val-epoch-step: 83-629 -- Loss: 0.2067708671092987
val-epoch-step: 83-630 -- Loss: 0.3463188111782074
val-epoch-step: 83-631 -- Loss: 0.1508905440568924
val-epoch-step: 83-632 -- Loss: 0.19799257814884186
val-epoch-step: 83-633 -- Loss: 0.1516510546207428
val-epoch-step: 83-634 -- Loss: 0.14420703053474426
val-epoch-step: 83-635 -- Loss: 0.10946538299322128
val-epoch-step: 83-636 -- Loss: 0.16432730853557587
val-epoch-step: 83-637 -- Loss: 0.18172085285186768
val-epoch-step: 83-638 -- Loss: 0.15524567663669586
val-epoch-step: 83-639 -- Loss: 0.2591358423233032
val-epoch-step: 83-640 -- Loss: 0.2531130909919739
val-epoch-step: 83-641 -- Loss: 0.12339644134044647
val-epoch-step: 83-642 -- Loss: 0.18136847019195557
val-epoch-step: 83-643 -- Loss: 0.20614995062351227
val-epoch-step: 83-644 -- Loss: 0.16327700018882751
val-epoch-step: 83-645 -- Loss: 0.2225273847579956
val-epoch-step: 83-646 -- Loss: 0.1360965371131897
val-epoch-step: 83-647 -- Loss: 0.12571503221988678
val-epoch-step: 83-648 -- Loss: 0.15589173138141632
val-epoch-step: 83-649 -- Loss: 0.20660412311553955
val-epoch-step: 83-650 -- Loss: 0.2590007185935974
val-epoch-step: 83-651 -- Loss: 0.14827467501163483
val-epoch-step: 83-652 -- Loss: 0.14990437030792236
val-epoch-step: 83-653 -- Loss: 0.19436010718345642
val-epoch-step: 83-654 -- Loss: 0.11628501117229462
Epoch: 83 -- Train Loss: tensor(0.1409, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 84-0 -- Loss: 0.21841779351234436
train-epoch-step: 84-1 -- Loss: 0.13991641998291016
train-epoch-step: 84-2 -- Loss: 0.1989305317401886
train-epoch-step: 84-3 -- Loss: 0.14413291215896606
train-epoch-step: 84-4 -- Loss: 0.15360461175441742
train-epoch-step: 84-5 -- Loss: 0.17451101541519165
train-epoch-step: 84-6 -- Loss: 0.22431814670562744
train-epoch-step: 84-7 -- Loss: 0.16629426181316376
train-epoch-step: 84-8 -- Loss: 0.1790410727262497
train-epoch-step: 84-9 -- Loss: 0.22766302525997162
train-epoch-step: 84-10 -- Loss: 0.18822386860847473
train-epoch-step: 84-11 -- Loss: 0.1673583984375
train-epoch-step: 84-12 -- Loss: 0.14332103729248047
train-epoch-step: 84-13 -- Loss: 0.17521388828754425
train-epoch-step: 84-14 -- Loss: 0.15803998708724976
train-epoch-step: 84-15 -- Loss: 0.15578505396842957
train-epoch-step: 84-16 -- Loss: 0.161601722240448
train-epoch-step: 84-17 -- Loss: 0.23363465070724487
train-epoch-step: 84-18 -- Loss: 0.1892317831516266
train-epoch-step: 84-19 -- Loss: 0.13272683322429657
train-epoch-step: 84-20 -- Loss: 0.20999200642108917
train-epoch-step: 84-21 -- Loss: 0.24912402033805847
train-epoch-step: 84-22 -- Loss: 0.13992805778980255
train-epoch-step: 84-23 -- Loss: 0.13846473395824432
train-epoch-step: 84-24 -- Loss: 0.12344930320978165
train-epoch-step: 84-25 -- Loss: 0.23493705689907074
train-epoch-step: 84-26 -- Loss: 0.20528122782707214
train-epoch-step: 84-27 -- Loss: 0.22090014815330505
train-epoch-step: 84-28 -- Loss: 0.1221931055188179
train-epoch-step: 84-29 -- Loss: 0.23928943276405334
train-epoch-step: 84-30 -- Loss: 0.10590634495019913
train-epoch-step: 84-31 -- Loss: 0.13235081732273102
train-epoch-step: 84-32 -- Loss: 0.16938422620296478
train-epoch-step: 84-33 -- Loss: 0.2671550214290619
train-epoch-step: 84-34 -- Loss: 0.17162194848060608
train-epoch-step: 84-35 -- Loss: 0.2349720448255539
train-epoch-step: 84-36 -- Loss: 0.1403370201587677
train-epoch-step: 84-37 -- Loss: 0.13603076338768005
train-epoch-step: 84-38 -- Loss: 0.17631542682647705
train-epoch-step: 84-39 -- Loss: 0.2112310528755188
train-epoch-step: 84-40 -- Loss: 0.19318562746047974
train-epoch-step: 84-41 -- Loss: 0.21337684988975525
train-epoch-step: 84-42 -- Loss: 0.14692805707454681
train-epoch-step: 84-43 -- Loss: 0.2527265250682831
train-epoch-step: 84-44 -- Loss: 0.12177346646785736
train-epoch-step: 84-45 -- Loss: 0.12152723968029022
train-epoch-step: 84-46 -- Loss: 0.1680055409669876
train-epoch-step: 84-47 -- Loss: 0.20609699189662933
train-epoch-step: 84-48 -- Loss: 0.1500309854745865
train-epoch-step: 84-49 -- Loss: 0.2195044755935669
train-epoch-step: 84-50 -- Loss: 0.1154235452413559
train-epoch-step: 84-51 -- Loss: 0.16921588778495789
train-epoch-step: 84-52 -- Loss: 0.15863656997680664
train-epoch-step: 84-53 -- Loss: 0.21769647300243378
train-epoch-step: 84-54 -- Loss: 0.27909374237060547
train-epoch-step: 84-55 -- Loss: 0.16716966032981873
train-epoch-step: 84-56 -- Loss: 0.17192113399505615
train-epoch-step: 84-57 -- Loss: 0.22621798515319824
train-epoch-step: 84-58 -- Loss: 0.27918902039527893
train-epoch-step: 84-59 -- Loss: 0.22768144309520721
train-epoch-step: 84-60 -- Loss: 0.1329396367073059
train-epoch-step: 84-61 -- Loss: 0.19528146088123322
train-epoch-step: 84-62 -- Loss: 0.1794424057006836
train-epoch-step: 84-63 -- Loss: 0.1460292637348175
train-epoch-step: 84-64 -- Loss: 0.14271055161952972
train-epoch-step: 84-65 -- Loss: 0.17695307731628418
train-epoch-step: 84-66 -- Loss: 0.10518388450145721
train-epoch-step: 84-67 -- Loss: 0.1210578978061676
train-epoch-step: 84-68 -- Loss: 0.21510295569896698
train-epoch-step: 84-69 -- Loss: 0.13139984011650085
train-epoch-step: 84-70 -- Loss: 0.22057367861270905
train-epoch-step: 84-71 -- Loss: 0.25465503334999084
train-epoch-step: 84-72 -- Loss: 0.17176388204097748
train-epoch-step: 84-73 -- Loss: 0.2013128697872162
train-epoch-step: 84-74 -- Loss: 0.09343338012695312
train-epoch-step: 84-75 -- Loss: 0.125982865691185
train-epoch-step: 84-76 -- Loss: 0.14218521118164062
train-epoch-step: 84-77 -- Loss: 0.22776639461517334
train-epoch-step: 84-78 -- Loss: 0.26759952306747437
train-epoch-step: 84-79 -- Loss: 0.18515357375144958
train-epoch-step: 84-80 -- Loss: 0.24368999898433685
train-epoch-step: 84-81 -- Loss: 0.13831496238708496
train-epoch-step: 84-82 -- Loss: 0.24460846185684204
train-epoch-step: 84-83 -- Loss: 0.17285943031311035
train-epoch-step: 84-84 -- Loss: 0.18277382850646973
train-epoch-step: 84-85 -- Loss: 0.17760181427001953
train-epoch-step: 84-86 -- Loss: 0.12188094109296799
train-epoch-step: 84-87 -- Loss: 0.21472734212875366
train-epoch-step: 84-88 -- Loss: 0.1485777199268341
train-epoch-step: 84-89 -- Loss: 0.18875426054000854
train-epoch-step: 84-90 -- Loss: 0.19427789747714996
train-epoch-step: 84-91 -- Loss: 0.2593470811843872
train-epoch-step: 84-92 -- Loss: 0.15653720498085022
train-epoch-step: 84-93 -- Loss: 0.18317626416683197
train-epoch-step: 84-94 -- Loss: 0.24234160780906677
train-epoch-step: 84-95 -- Loss: 0.18873700499534607
train-epoch-step: 84-96 -- Loss: 0.2406253218650818
train-epoch-step: 84-97 -- Loss: 0.1757643073797226
train-epoch-step: 84-98 -- Loss: 0.1549164354801178
train-epoch-step: 84-99 -- Loss: 0.23089224100112915
train-epoch-step: 84-100 -- Loss: 0.40926146507263184
train-epoch-step: 84-101 -- Loss: 0.2879025340080261
train-epoch-step: 84-102 -- Loss: 0.2782125473022461
train-epoch-step: 84-103 -- Loss: 0.1851750761270523
train-epoch-step: 84-104 -- Loss: 0.1537349820137024
train-epoch-step: 84-105 -- Loss: 0.2580004036426544
train-epoch-step: 84-106 -- Loss: 0.18185555934906006
train-epoch-step: 84-107 -- Loss: 0.18867182731628418
train-epoch-step: 84-108 -- Loss: 0.19735971093177795
train-epoch-step: 84-109 -- Loss: 0.14709390699863434
train-epoch-step: 84-110 -- Loss: 0.18060408532619476
train-epoch-step: 84-111 -- Loss: 0.18946495652198792
train-epoch-step: 84-112 -- Loss: 0.1734357476234436
train-epoch-step: 84-113 -- Loss: 0.1620817333459854
train-epoch-step: 84-114 -- Loss: 0.1943838894367218
train-epoch-step: 84-115 -- Loss: 0.16098318994045258
train-epoch-step: 84-116 -- Loss: 0.13591521978378296
train-epoch-step: 84-117 -- Loss: 0.13309374451637268
train-epoch-step: 84-118 -- Loss: 0.22382752597332
train-epoch-step: 84-119 -- Loss: 0.15193402767181396
train-epoch-step: 84-120 -- Loss: 0.327178955078125
train-epoch-step: 84-121 -- Loss: 0.24678462743759155
train-epoch-step: 84-122 -- Loss: 0.24618208408355713
train-epoch-step: 84-123 -- Loss: 0.20306721329689026
train-epoch-step: 84-124 -- Loss: 0.11890238523483276
train-epoch-step: 84-125 -- Loss: 0.16291514039039612
train-epoch-step: 84-126 -- Loss: 0.22203174233436584
train-epoch-step: 84-127 -- Loss: 0.17075985670089722
train-epoch-step: 84-128 -- Loss: 0.17036505043506622
train-epoch-step: 84-129 -- Loss: 0.13991443812847137
train-epoch-step: 84-130 -- Loss: 0.20742017030715942
train-epoch-step: 84-131 -- Loss: 0.1366741955280304
train-epoch-step: 84-132 -- Loss: 0.1966327428817749
train-epoch-step: 84-133 -- Loss: 0.11994138360023499
train-epoch-step: 84-134 -- Loss: 0.19783440232276917
train-epoch-step: 84-135 -- Loss: 0.14054685831069946
train-epoch-step: 84-136 -- Loss: 0.13749311864376068
train-epoch-step: 84-137 -- Loss: 0.2577132284641266
train-epoch-step: 84-138 -- Loss: 0.2877127230167389
train-epoch-step: 84-139 -- Loss: 0.13255886733531952
train-epoch-step: 84-140 -- Loss: 0.22985197603702545
train-epoch-step: 84-141 -- Loss: 0.24279871582984924
train-epoch-step: 84-142 -- Loss: 0.20682509243488312
train-epoch-step: 84-143 -- Loss: 0.1703672707080841
train-epoch-step: 84-144 -- Loss: 0.1846141517162323
train-epoch-step: 84-145 -- Loss: 0.15368971228599548
train-epoch-step: 84-146 -- Loss: 0.18325842916965485
train-epoch-step: 84-147 -- Loss: 0.17366252839565277
train-epoch-step: 84-148 -- Loss: 0.1638847291469574
train-epoch-step: 84-149 -- Loss: 0.12210815399885178
train-epoch-step: 84-150 -- Loss: 0.18499575555324554
train-epoch-step: 84-151 -- Loss: 0.20817577838897705
train-epoch-step: 84-152 -- Loss: 0.18797114491462708
train-epoch-step: 84-153 -- Loss: 0.27825143933296204
train-epoch-step: 84-154 -- Loss: 0.12922725081443787
train-epoch-step: 84-155 -- Loss: 0.14425882697105408
train-epoch-step: 84-156 -- Loss: 0.11473017185926437
train-epoch-step: 84-157 -- Loss: 0.16602998971939087
train-epoch-step: 84-158 -- Loss: 0.16013485193252563
train-epoch-step: 84-159 -- Loss: 0.17182748019695282
train-epoch-step: 84-160 -- Loss: 0.21380169689655304
train-epoch-step: 84-161 -- Loss: 0.2050406038761139
train-epoch-step: 84-162 -- Loss: 0.2062327116727829
train-epoch-step: 84-163 -- Loss: 0.1836540699005127
train-epoch-step: 84-164 -- Loss: 0.18983271718025208
train-epoch-step: 84-165 -- Loss: 0.15581439435482025
train-epoch-step: 84-166 -- Loss: 0.11801241338253021
train-epoch-step: 84-167 -- Loss: 0.12345422804355621
train-epoch-step: 84-168 -- Loss: 0.20014092326164246
train-epoch-step: 84-169 -- Loss: 0.14647839963436127
train-epoch-step: 84-170 -- Loss: 0.20455564558506012
train-epoch-step: 84-171 -- Loss: 0.14229029417037964
train-epoch-step: 84-172 -- Loss: 0.2550157308578491
train-epoch-step: 84-173 -- Loss: 0.13029968738555908
train-epoch-step: 84-174 -- Loss: 0.23826831579208374
train-epoch-step: 84-175 -- Loss: 0.18425902724266052
train-epoch-step: 84-176 -- Loss: 0.1345284879207611
train-epoch-step: 84-177 -- Loss: 0.1872624158859253
train-epoch-step: 84-178 -- Loss: 0.1810327023267746
train-epoch-step: 84-179 -- Loss: 0.15937712788581848
train-epoch-step: 84-180 -- Loss: 0.15106505155563354
train-epoch-step: 84-181 -- Loss: 0.16905617713928223
train-epoch-step: 84-182 -- Loss: 0.18406839668750763
train-epoch-step: 84-183 -- Loss: 0.2728939652442932
train-epoch-step: 84-184 -- Loss: 0.13699324429035187
train-epoch-step: 84-185 -- Loss: 0.1382204294204712
train-epoch-step: 84-186 -- Loss: 0.19732137024402618
train-epoch-step: 84-187 -- Loss: 0.2055436074733734
train-epoch-step: 84-188 -- Loss: 0.16610930860042572
train-epoch-step: 84-189 -- Loss: 0.10365264117717743
train-epoch-step: 84-190 -- Loss: 0.18250389397144318
train-epoch-step: 84-191 -- Loss: 0.1588711440563202
train-epoch-step: 84-192 -- Loss: 0.22173720598220825
train-epoch-step: 84-193 -- Loss: 0.20038020610809326
train-epoch-step: 84-194 -- Loss: 0.18579135835170746
train-epoch-step: 84-195 -- Loss: 0.16233082115650177
train-epoch-step: 84-196 -- Loss: 0.1834859997034073
train-epoch-step: 84-197 -- Loss: 0.1264306902885437
train-epoch-step: 84-198 -- Loss: 0.1297481656074524
train-epoch-step: 84-199 -- Loss: 0.14101926982402802
train-epoch-step: 84-200 -- Loss: 0.12421409040689468
train-epoch-step: 84-201 -- Loss: 0.18117780983448029
train-epoch-step: 84-202 -- Loss: 0.13429442048072815
train-epoch-step: 84-203 -- Loss: 0.17064788937568665
train-epoch-step: 84-204 -- Loss: 0.13651913404464722
train-epoch-step: 84-205 -- Loss: 0.18865108489990234
train-epoch-step: 84-206 -- Loss: 0.19671417772769928
train-epoch-step: 84-207 -- Loss: 0.13241294026374817
train-epoch-step: 84-208 -- Loss: 0.1800762265920639
train-epoch-step: 84-209 -- Loss: 0.14115002751350403
train-epoch-step: 84-210 -- Loss: 0.13816817104816437
train-epoch-step: 84-211 -- Loss: 0.21700644493103027
train-epoch-step: 84-212 -- Loss: 0.202385812997818
train-epoch-step: 84-213 -- Loss: 0.12745581567287445
train-epoch-step: 84-214 -- Loss: 0.1448439210653305
train-epoch-step: 84-215 -- Loss: 0.12589463591575623
train-epoch-step: 84-216 -- Loss: 0.20137566328048706
train-epoch-step: 84-217 -- Loss: 0.21088477969169617
train-epoch-step: 84-218 -- Loss: 0.14499269425868988
train-epoch-step: 84-219 -- Loss: 0.16764432191848755
train-epoch-step: 84-220 -- Loss: 0.12849411368370056
train-epoch-step: 84-221 -- Loss: 0.2115187644958496
train-epoch-step: 84-222 -- Loss: 0.1153818890452385
train-epoch-step: 84-223 -- Loss: 0.17146575450897217
train-epoch-step: 84-224 -- Loss: 0.18889714777469635
train-epoch-step: 84-225 -- Loss: 0.2659047245979309
train-epoch-step: 84-226 -- Loss: 0.20317237079143524
train-epoch-step: 84-227 -- Loss: 0.2148786336183548
train-epoch-step: 84-228 -- Loss: 0.17202767729759216
train-epoch-step: 84-229 -- Loss: 0.16969382762908936
train-epoch-step: 84-230 -- Loss: 0.16000348329544067
train-epoch-step: 84-231 -- Loss: 0.15217337012290955
train-epoch-step: 84-232 -- Loss: 0.18213646113872528
train-epoch-step: 84-233 -- Loss: 0.08277352154254913
train-epoch-step: 84-234 -- Loss: 0.1682761162519455
train-epoch-step: 84-235 -- Loss: 0.14682480692863464
train-epoch-step: 84-236 -- Loss: 0.18155492842197418
train-epoch-step: 84-237 -- Loss: 0.22995012998580933
train-epoch-step: 84-238 -- Loss: 0.15037040412425995
train-epoch-step: 84-239 -- Loss: 0.12739045917987823
train-epoch-step: 84-240 -- Loss: 0.22754855453968048
train-epoch-step: 84-241 -- Loss: 0.15339064598083496
train-epoch-step: 84-242 -- Loss: 0.22232884168624878
train-epoch-step: 84-243 -- Loss: 0.2343367487192154
train-epoch-step: 84-244 -- Loss: 0.2008851021528244
train-epoch-step: 84-245 -- Loss: 0.20067933201789856
train-epoch-step: 84-246 -- Loss: 0.21844515204429626
train-epoch-step: 84-247 -- Loss: 0.2058376669883728
train-epoch-step: 84-248 -- Loss: 0.18127581477165222
train-epoch-step: 84-249 -- Loss: 0.13536763191223145
train-epoch-step: 84-250 -- Loss: 0.20169228315353394
train-epoch-step: 84-251 -- Loss: 0.10334141552448273
train-epoch-step: 84-252 -- Loss: 0.19483685493469238
train-epoch-step: 84-253 -- Loss: 0.133696049451828
train-epoch-step: 84-254 -- Loss: 0.2072020322084427
train-epoch-step: 84-255 -- Loss: 0.14075300097465515
train-epoch-step: 84-256 -- Loss: 0.14426924288272858
train-epoch-step: 84-257 -- Loss: 0.1847854107618332
train-epoch-step: 84-258 -- Loss: 0.141591414809227
train-epoch-step: 84-259 -- Loss: 0.10899302363395691
train-epoch-step: 84-260 -- Loss: 0.19698525965213776
train-epoch-step: 84-261 -- Loss: 0.17157074809074402
train-epoch-step: 84-262 -- Loss: 0.28214719891548157
train-epoch-step: 84-263 -- Loss: 0.19561435282230377
train-epoch-step: 84-264 -- Loss: 0.17135296761989594
train-epoch-step: 84-265 -- Loss: 0.10824601352214813
train-epoch-step: 84-266 -- Loss: 0.15340478718280792
train-epoch-step: 84-267 -- Loss: 0.13184770941734314
train-epoch-step: 84-268 -- Loss: 0.11656457185745239
train-epoch-step: 84-269 -- Loss: 0.17312787473201752
train-epoch-step: 84-270 -- Loss: 0.10454938560724258
train-epoch-step: 84-271 -- Loss: 0.14462243020534515
train-epoch-step: 84-272 -- Loss: 0.11833922564983368
train-epoch-step: 84-273 -- Loss: 0.12518180906772614
train-epoch-step: 84-274 -- Loss: 0.18522003293037415
train-epoch-step: 84-275 -- Loss: 0.19459208846092224
train-epoch-step: 84-276 -- Loss: 0.15186385810375214
train-epoch-step: 84-277 -- Loss: 0.1527751386165619
train-epoch-step: 84-278 -- Loss: 0.13464437425136566
train-epoch-step: 84-279 -- Loss: 0.13495871424674988
train-epoch-step: 84-280 -- Loss: 0.2122013121843338
train-epoch-step: 84-281 -- Loss: 0.1709969937801361
train-epoch-step: 84-282 -- Loss: 0.13549083471298218
train-epoch-step: 84-283 -- Loss: 0.11290544271469116
train-epoch-step: 84-284 -- Loss: 0.12771986424922943
train-epoch-step: 84-285 -- Loss: 0.18294493854045868
train-epoch-step: 84-286 -- Loss: 0.1515311896800995
train-epoch-step: 84-287 -- Loss: 0.19847334921360016
train-epoch-step: 84-288 -- Loss: 0.09200981259346008
train-epoch-step: 84-289 -- Loss: 0.11710342019796371
train-epoch-step: 84-290 -- Loss: 0.17770671844482422
train-epoch-step: 84-291 -- Loss: 0.11632460355758667
train-epoch-step: 84-292 -- Loss: 0.16038715839385986
train-epoch-step: 84-293 -- Loss: 0.13769742846488953
train-epoch-step: 84-294 -- Loss: 0.1805986762046814
train-epoch-step: 84-295 -- Loss: 0.2599506974220276
train-epoch-step: 84-296 -- Loss: 0.15362577140331268
train-epoch-step: 84-297 -- Loss: 0.16558872163295746
train-epoch-step: 84-298 -- Loss: 0.23005308210849762
train-epoch-step: 84-299 -- Loss: 0.14218860864639282
train-epoch-step: 84-300 -- Loss: 0.1645049899816513
train-epoch-step: 84-301 -- Loss: 0.1752251386642456
train-epoch-step: 84-302 -- Loss: 0.22350917756557465
train-epoch-step: 84-303 -- Loss: 0.2040322870016098
train-epoch-step: 84-304 -- Loss: 0.1279158741235733
train-epoch-step: 84-305 -- Loss: 0.1383819878101349
train-epoch-step: 84-306 -- Loss: 0.21551087498664856
train-epoch-step: 84-307 -- Loss: 0.1637297421693802
train-epoch-step: 84-308 -- Loss: 0.22509866952896118
train-epoch-step: 84-309 -- Loss: 0.1547117531299591
train-epoch-step: 84-310 -- Loss: 0.1574609875679016
train-epoch-step: 84-311 -- Loss: 0.15534207224845886
train-epoch-step: 84-312 -- Loss: 0.20574159920215607
train-epoch-step: 84-313 -- Loss: 0.09759702533483505
train-epoch-step: 84-314 -- Loss: 0.19209234416484833
train-epoch-step: 84-315 -- Loss: 0.16448360681533813
train-epoch-step: 84-316 -- Loss: 0.14832022786140442
train-epoch-step: 84-317 -- Loss: 0.13560347259044647
train-epoch-step: 84-318 -- Loss: 0.14965808391571045
train-epoch-step: 84-319 -- Loss: 0.16124843060970306
train-epoch-step: 84-320 -- Loss: 0.11527630686759949
train-epoch-step: 84-321 -- Loss: 0.13116313517093658
train-epoch-step: 84-322 -- Loss: 0.20313234627246857
train-epoch-step: 84-323 -- Loss: 0.15570542216300964
train-epoch-step: 84-324 -- Loss: 0.25784367322921753
train-epoch-step: 84-325 -- Loss: 0.15034618973731995
train-epoch-step: 84-326 -- Loss: 0.16629719734191895
train-epoch-step: 84-327 -- Loss: 0.20102745294570923
train-epoch-step: 84-328 -- Loss: 0.1923736035823822
train-epoch-step: 84-329 -- Loss: 0.3373384475708008
train-epoch-step: 84-330 -- Loss: 0.36247748136520386
train-epoch-step: 84-331 -- Loss: 0.21318310499191284
train-epoch-step: 84-332 -- Loss: 0.09922874718904495
train-epoch-step: 84-333 -- Loss: 0.1813441514968872
train-epoch-step: 84-334 -- Loss: 0.1502017378807068
train-epoch-step: 84-335 -- Loss: 0.17060640454292297
train-epoch-step: 84-336 -- Loss: 0.1488492637872696
train-epoch-step: 84-337 -- Loss: 0.20424360036849976
train-epoch-step: 84-338 -- Loss: 0.15476632118225098
train-epoch-step: 84-339 -- Loss: 0.14087983965873718
train-epoch-step: 84-340 -- Loss: 0.1982642412185669
train-epoch-step: 84-341 -- Loss: 0.13592283427715302
train-epoch-step: 84-342 -- Loss: 0.16844451427459717
train-epoch-step: 84-343 -- Loss: 0.14972788095474243
train-epoch-step: 84-344 -- Loss: 0.16178855299949646
train-epoch-step: 84-345 -- Loss: 0.12172305583953857
train-epoch-step: 84-346 -- Loss: 0.20973892509937286
train-epoch-step: 84-347 -- Loss: 0.1516861617565155
train-epoch-step: 84-348 -- Loss: 0.19456322491168976
train-epoch-step: 84-349 -- Loss: 0.20072904229164124
train-epoch-step: 84-350 -- Loss: 0.25208982825279236
train-epoch-step: 84-351 -- Loss: 0.19472810626029968
train-epoch-step: 84-352 -- Loss: 0.12625375390052795
train-epoch-step: 84-353 -- Loss: 0.18984057009220123
train-epoch-step: 84-354 -- Loss: 0.2776884436607361
train-epoch-step: 84-355 -- Loss: 0.12251770496368408
train-epoch-step: 84-356 -- Loss: 0.11677520722150803
train-epoch-step: 84-357 -- Loss: 0.1875113546848297
train-epoch-step: 84-358 -- Loss: 0.18506178259849548
train-epoch-step: 84-359 -- Loss: 0.1359121948480606
train-epoch-step: 84-360 -- Loss: 0.12311667948961258
train-epoch-step: 84-361 -- Loss: 0.22833837568759918
train-epoch-step: 84-362 -- Loss: 0.16591742634773254
train-epoch-step: 84-363 -- Loss: 0.10892882198095322
train-epoch-step: 84-364 -- Loss: 0.18024811148643494
train-epoch-step: 84-365 -- Loss: 0.16713875532150269
train-epoch-step: 84-366 -- Loss: 0.1947481632232666
train-epoch-step: 84-367 -- Loss: 0.2339164912700653
train-epoch-step: 84-368 -- Loss: 0.1989000141620636
train-epoch-step: 84-369 -- Loss: 0.27651751041412354
train-epoch-step: 84-370 -- Loss: 0.12306094914674759
train-epoch-step: 84-371 -- Loss: 0.12109517306089401
train-epoch-step: 84-372 -- Loss: 0.1435377299785614
train-epoch-step: 84-373 -- Loss: 0.1954050213098526
train-epoch-step: 84-374 -- Loss: 0.15036049485206604
train-epoch-step: 84-375 -- Loss: 0.2561643123626709
train-epoch-step: 84-376 -- Loss: 0.1599215865135193
train-epoch-step: 84-377 -- Loss: 0.23394936323165894
train-epoch-step: 84-378 -- Loss: 0.21299754083156586
train-epoch-step: 84-379 -- Loss: 0.11900673061609268
train-epoch-step: 84-380 -- Loss: 0.09306987375020981
train-epoch-step: 84-381 -- Loss: 0.24697768688201904
train-epoch-step: 84-382 -- Loss: 0.23111788928508759
train-epoch-step: 84-383 -- Loss: 0.1779821366071701
train-epoch-step: 84-384 -- Loss: 0.2144617885351181
train-epoch-step: 84-385 -- Loss: 0.1834423989057541
train-epoch-step: 84-386 -- Loss: 0.1836632788181305
train-epoch-step: 84-387 -- Loss: 0.19900670647621155
train-epoch-step: 84-388 -- Loss: 0.1830778568983078
train-epoch-step: 84-389 -- Loss: 0.16867077350616455
train-epoch-step: 84-390 -- Loss: 0.14255492389202118
train-epoch-step: 84-391 -- Loss: 0.14276954531669617
train-epoch-step: 84-392 -- Loss: 0.18044589459896088
train-epoch-step: 84-393 -- Loss: 0.15153753757476807
train-epoch-step: 84-394 -- Loss: 0.198103129863739
train-epoch-step: 84-395 -- Loss: 0.1515280306339264
train-epoch-step: 84-396 -- Loss: 0.12436696141958237
train-epoch-step: 84-397 -- Loss: 0.12187553942203522
train-epoch-step: 84-398 -- Loss: 0.19077494740486145
train-epoch-step: 84-399 -- Loss: 0.1698867827653885
train-epoch-step: 84-400 -- Loss: 0.26759687066078186
train-epoch-step: 84-401 -- Loss: 0.12067735940217972
train-epoch-step: 84-402 -- Loss: 0.2524389922618866
train-epoch-step: 84-403 -- Loss: 0.15552547574043274
train-epoch-step: 84-404 -- Loss: 0.1336047649383545
train-epoch-step: 84-405 -- Loss: 0.1403978317975998
train-epoch-step: 84-406 -- Loss: 0.1615680307149887
train-epoch-step: 84-407 -- Loss: 0.11050291359424591
train-epoch-step: 84-408 -- Loss: 0.16017675399780273
train-epoch-step: 84-409 -- Loss: 0.16773657500743866
train-epoch-step: 84-410 -- Loss: 0.17300544679164886
train-epoch-step: 84-411 -- Loss: 0.19754095375537872
train-epoch-step: 84-412 -- Loss: 0.1268957257270813
train-epoch-step: 84-413 -- Loss: 0.14472277462482452
train-epoch-step: 84-414 -- Loss: 0.1288478821516037
train-epoch-step: 84-415 -- Loss: 0.1315278857946396
train-epoch-step: 84-416 -- Loss: 0.259378045797348
train-epoch-step: 84-417 -- Loss: 0.1888940930366516
train-epoch-step: 84-418 -- Loss: 0.22245603799819946
train-epoch-step: 84-419 -- Loss: 0.17051339149475098
train-epoch-step: 84-420 -- Loss: 0.14747783541679382
train-epoch-step: 84-421 -- Loss: 0.1715063899755478
train-epoch-step: 84-422 -- Loss: 0.14707273244857788
train-epoch-step: 84-423 -- Loss: 0.1721886396408081
train-epoch-step: 84-424 -- Loss: 0.1329953521490097
train-epoch-step: 84-425 -- Loss: 0.1801043450832367
train-epoch-step: 84-426 -- Loss: 0.16417454183101654
train-epoch-step: 84-427 -- Loss: 0.11556227505207062
train-epoch-step: 84-428 -- Loss: 0.20816214382648468
train-epoch-step: 84-429 -- Loss: 0.17204692959785461
train-epoch-step: 84-430 -- Loss: 0.14242535829544067
train-epoch-step: 84-431 -- Loss: 0.1593918353319168
train-epoch-step: 84-432 -- Loss: 0.2356875091791153
train-epoch-step: 84-433 -- Loss: 0.14221814274787903
train-epoch-step: 84-434 -- Loss: 0.12849991023540497
train-epoch-step: 84-435 -- Loss: 0.15968167781829834
train-epoch-step: 84-436 -- Loss: 0.14745807647705078
train-epoch-step: 84-437 -- Loss: 0.12752023339271545
train-epoch-step: 84-438 -- Loss: 0.16400542855262756
train-epoch-step: 84-439 -- Loss: 0.25682681798934937
train-epoch-step: 84-440 -- Loss: 0.13034164905548096
train-epoch-step: 84-441 -- Loss: 0.1948113739490509
train-epoch-step: 84-442 -- Loss: 0.17358076572418213
train-epoch-step: 84-443 -- Loss: 0.16112768650054932
train-epoch-step: 84-444 -- Loss: 0.1720869094133377
train-epoch-step: 84-445 -- Loss: 0.17235305905342102
train-epoch-step: 84-446 -- Loss: 0.14792205393314362
train-epoch-step: 84-447 -- Loss: 0.18742477893829346
train-epoch-step: 84-448 -- Loss: 0.21894413232803345
train-epoch-step: 84-449 -- Loss: 0.1887192279100418
train-epoch-step: 84-450 -- Loss: 0.17745622992515564
train-epoch-step: 84-451 -- Loss: 0.14035063982009888
train-epoch-step: 84-452 -- Loss: 0.13001206517219543
train-epoch-step: 84-453 -- Loss: 0.08802760392427444
train-epoch-step: 84-454 -- Loss: 0.22976359724998474
train-epoch-step: 84-455 -- Loss: 0.11969640851020813
train-epoch-step: 84-456 -- Loss: 0.12010039389133453
train-epoch-step: 84-457 -- Loss: 0.2093692123889923
train-epoch-step: 84-458 -- Loss: 0.14234714210033417
train-epoch-step: 84-459 -- Loss: 0.20733711123466492
train-epoch-step: 84-460 -- Loss: 0.12417192757129669
train-epoch-step: 84-461 -- Loss: 0.1328466236591339
train-epoch-step: 84-462 -- Loss: 0.15039296448230743
train-epoch-step: 84-463 -- Loss: 0.13122351467609406
train-epoch-step: 84-464 -- Loss: 0.15919823944568634
train-epoch-step: 84-465 -- Loss: 0.2388666421175003
train-epoch-step: 84-466 -- Loss: 0.19742891192436218
train-epoch-step: 84-467 -- Loss: 0.10899266600608826
train-epoch-step: 84-468 -- Loss: 0.1597703993320465
train-epoch-step: 84-469 -- Loss: 0.20400749146938324
train-epoch-step: 84-470 -- Loss: 0.16525593400001526
train-epoch-step: 84-471 -- Loss: 0.15628352761268616
train-epoch-step: 84-472 -- Loss: 0.15623562037944794
train-epoch-step: 84-473 -- Loss: 0.15858910977840424
train-epoch-step: 84-474 -- Loss: 0.1247294545173645
train-epoch-step: 84-475 -- Loss: 0.10857100039720535
train-epoch-step: 84-476 -- Loss: 0.19390273094177246
train-epoch-step: 84-477 -- Loss: 0.19298191368579865
train-epoch-step: 84-478 -- Loss: 0.1801997423171997
train-epoch-step: 84-479 -- Loss: 0.1337956041097641
train-epoch-step: 84-480 -- Loss: 0.1914922297000885
train-epoch-step: 84-481 -- Loss: 0.28074389696121216
train-epoch-step: 84-482 -- Loss: 0.2685772776603699
train-epoch-step: 84-483 -- Loss: 0.17455901205539703
train-epoch-step: 84-484 -- Loss: 0.2086409628391266
train-epoch-step: 84-485 -- Loss: 0.12237628549337387
train-epoch-step: 84-486 -- Loss: 0.22501306235790253
train-epoch-step: 84-487 -- Loss: 0.23401880264282227
train-epoch-step: 84-488 -- Loss: 0.1888529658317566
train-epoch-step: 84-489 -- Loss: 0.2232293337583542
train-epoch-step: 84-490 -- Loss: 0.13375268876552582
train-epoch-step: 84-491 -- Loss: 0.13286742568016052
train-epoch-step: 84-492 -- Loss: 0.12348601222038269
train-epoch-step: 84-493 -- Loss: 0.19299404323101044
train-epoch-step: 84-494 -- Loss: 0.19980934262275696
train-epoch-step: 84-495 -- Loss: 0.19196008145809174
train-epoch-step: 84-496 -- Loss: 0.13804630935192108
train-epoch-step: 84-497 -- Loss: 0.1899152249097824
train-epoch-step: 84-498 -- Loss: 0.1424894630908966
train-epoch-step: 84-499 -- Loss: 0.17219197750091553
train-epoch-step: 84-500 -- Loss: 0.15038920938968658
train-epoch-step: 84-501 -- Loss: 0.2061673402786255
train-epoch-step: 84-502 -- Loss: 0.15248313546180725
train-epoch-step: 84-503 -- Loss: 0.21951068937778473
train-epoch-step: 84-504 -- Loss: 0.11487323045730591
train-epoch-step: 84-505 -- Loss: 0.17302313446998596
train-epoch-step: 84-506 -- Loss: 0.11542972922325134
train-epoch-step: 84-507 -- Loss: 0.1845940202474594
train-epoch-step: 84-508 -- Loss: 0.17355993390083313
train-epoch-step: 84-509 -- Loss: 0.16208529472351074
train-epoch-step: 84-510 -- Loss: 0.1265246421098709
train-epoch-step: 84-511 -- Loss: 0.20967866480350494
train-epoch-step: 84-512 -- Loss: 0.17334486544132233
train-epoch-step: 84-513 -- Loss: 0.18632596731185913
train-epoch-step: 84-514 -- Loss: 0.1417253464460373
train-epoch-step: 84-515 -- Loss: 0.15248937904834747
train-epoch-step: 84-516 -- Loss: 0.1660313606262207
train-epoch-step: 84-517 -- Loss: 0.16962678730487823
train-epoch-step: 84-518 -- Loss: 0.13528409600257874
train-epoch-step: 84-519 -- Loss: 0.13256359100341797
train-epoch-step: 84-520 -- Loss: 0.18277078866958618
train-epoch-step: 84-521 -- Loss: 0.23009033501148224
train-epoch-step: 84-522 -- Loss: 0.1663215458393097
train-epoch-step: 84-523 -- Loss: 0.15520861744880676
train-epoch-step: 84-524 -- Loss: 0.16157551109790802
train-epoch-step: 84-525 -- Loss: 0.1844705194234848
train-epoch-step: 84-526 -- Loss: 0.12995994091033936
train-epoch-step: 84-527 -- Loss: 0.14750123023986816
train-epoch-step: 84-528 -- Loss: 0.15032413601875305
train-epoch-step: 84-529 -- Loss: 0.14951346814632416
train-epoch-step: 84-530 -- Loss: 0.16048845648765564
train-epoch-step: 84-531 -- Loss: 0.19568711519241333
train-epoch-step: 84-532 -- Loss: 0.17008070647716522
train-epoch-step: 84-533 -- Loss: 0.17493614554405212
train-epoch-step: 84-534 -- Loss: 0.12476105988025665
train-epoch-step: 84-535 -- Loss: 0.24899646639823914
train-epoch-step: 84-536 -- Loss: 0.15915745496749878
train-epoch-step: 84-537 -- Loss: 0.14514897763729095
train-epoch-step: 84-538 -- Loss: 0.1023065447807312
train-epoch-step: 84-539 -- Loss: 0.19670185446739197
train-epoch-step: 84-540 -- Loss: 0.13057871162891388
train-epoch-step: 84-541 -- Loss: 0.21233680844306946
train-epoch-step: 84-542 -- Loss: 0.21559357643127441
train-epoch-step: 84-543 -- Loss: 0.16121868789196014
train-epoch-step: 84-544 -- Loss: 0.21957482397556305
train-epoch-step: 84-545 -- Loss: 0.1939135193824768
train-epoch-step: 84-546 -- Loss: 0.20268894731998444
train-epoch-step: 84-547 -- Loss: 0.17623649537563324
train-epoch-step: 84-548 -- Loss: 0.09343172609806061
train-epoch-step: 84-549 -- Loss: 0.1455746591091156
train-epoch-step: 84-550 -- Loss: 0.196370929479599
train-epoch-step: 84-551 -- Loss: 0.15163195133209229
train-epoch-step: 84-552 -- Loss: 0.12582197785377502
train-epoch-step: 84-553 -- Loss: 0.18308621644973755
train-epoch-step: 84-554 -- Loss: 0.18207675218582153
train-epoch-step: 84-555 -- Loss: 0.2114390730857849
train-epoch-step: 84-556 -- Loss: 0.15052101016044617
train-epoch-step: 84-557 -- Loss: 0.23077958822250366
train-epoch-step: 84-558 -- Loss: 0.2239699810743332
train-epoch-step: 84-559 -- Loss: 0.14170736074447632
train-epoch-step: 84-560 -- Loss: 0.19927054643630981
train-epoch-step: 84-561 -- Loss: 0.1688324511051178
train-epoch-step: 84-562 -- Loss: 0.15795424580574036
train-epoch-step: 84-563 -- Loss: 0.17573338747024536
train-epoch-step: 84-564 -- Loss: 0.0987924337387085
train-epoch-step: 84-565 -- Loss: 0.1789271980524063
train-epoch-step: 84-566 -- Loss: 0.14488857984542847
train-epoch-step: 84-567 -- Loss: 0.20697200298309326
train-epoch-step: 84-568 -- Loss: 0.15643621981143951
train-epoch-step: 84-569 -- Loss: 0.2358008176088333
train-epoch-step: 84-570 -- Loss: 0.15845079720020294
train-epoch-step: 84-571 -- Loss: 0.21405422687530518
train-epoch-step: 84-572 -- Loss: 0.23548443615436554
train-epoch-step: 84-573 -- Loss: 0.19255907833576202
train-epoch-step: 84-574 -- Loss: 0.23990057408809662
train-epoch-step: 84-575 -- Loss: 0.2938907742500305
train-epoch-step: 84-576 -- Loss: 0.11524789035320282
train-epoch-step: 84-577 -- Loss: 0.16240552067756653
train-epoch-step: 84-578 -- Loss: 0.20766395330429077
train-epoch-step: 84-579 -- Loss: 0.16186955571174622
train-epoch-step: 84-580 -- Loss: 0.16997310519218445
train-epoch-step: 84-581 -- Loss: 0.133535698056221
train-epoch-step: 84-582 -- Loss: 0.19951598346233368
train-epoch-step: 84-583 -- Loss: 0.21195395290851593
train-epoch-step: 84-584 -- Loss: 0.1592523604631424
train-epoch-step: 84-585 -- Loss: 0.19174179434776306
train-epoch-step: 84-586 -- Loss: 0.25163373351097107
train-epoch-step: 84-587 -- Loss: 0.15651224553585052
train-epoch-step: 84-588 -- Loss: 0.12261734157800674
val-epoch-step: 84-589 -- Loss: 0.21391409635543823
val-epoch-step: 84-590 -- Loss: 0.15328718721866608
val-epoch-step: 84-591 -- Loss: 0.23307466506958008
val-epoch-step: 84-592 -- Loss: 0.1708325445652008
val-epoch-step: 84-593 -- Loss: 0.14115405082702637
val-epoch-step: 84-594 -- Loss: 0.33120349049568176
val-epoch-step: 84-595 -- Loss: 0.17835089564323425
val-epoch-step: 84-596 -- Loss: 0.19424128532409668
val-epoch-step: 84-597 -- Loss: 0.17331132292747498
val-epoch-step: 84-598 -- Loss: 0.147813081741333
val-epoch-step: 84-599 -- Loss: 0.1806863248348236
val-epoch-step: 84-600 -- Loss: 0.1644749641418457
val-epoch-step: 84-601 -- Loss: 0.15040309727191925
val-epoch-step: 84-602 -- Loss: 0.13381697237491608
val-epoch-step: 84-603 -- Loss: 0.20353372395038605
val-epoch-step: 84-604 -- Loss: 0.14576151967048645
val-epoch-step: 84-605 -- Loss: 0.1420232057571411
val-epoch-step: 84-606 -- Loss: 0.2666325569152832
val-epoch-step: 84-607 -- Loss: 0.12006732821464539
val-epoch-step: 84-608 -- Loss: 0.23700430989265442
val-epoch-step: 84-609 -- Loss: 0.16141363978385925
val-epoch-step: 84-610 -- Loss: 0.17551791667938232
val-epoch-step: 84-611 -- Loss: 0.15342596173286438
val-epoch-step: 84-612 -- Loss: 0.4075610041618347
val-epoch-step: 84-613 -- Loss: 0.1876067817211151
val-epoch-step: 84-614 -- Loss: 0.16975674033164978
val-epoch-step: 84-615 -- Loss: 0.17113903164863586
val-epoch-step: 84-616 -- Loss: 0.1472339928150177
val-epoch-step: 84-617 -- Loss: 0.1869601011276245
val-epoch-step: 84-618 -- Loss: 0.17432817816734314
val-epoch-step: 84-619 -- Loss: 0.19948609173297882
val-epoch-step: 84-620 -- Loss: 0.13417671620845795
val-epoch-step: 84-621 -- Loss: 0.1241343542933464
val-epoch-step: 84-622 -- Loss: 0.14608469605445862
val-epoch-step: 84-623 -- Loss: 0.1427888125181198
val-epoch-step: 84-624 -- Loss: 0.14027714729309082
val-epoch-step: 84-625 -- Loss: 0.15747582912445068
val-epoch-step: 84-626 -- Loss: 0.14550362527370453
val-epoch-step: 84-627 -- Loss: 0.17829684913158417
val-epoch-step: 84-628 -- Loss: 0.5277979969978333
val-epoch-step: 84-629 -- Loss: 0.2079726606607437
val-epoch-step: 84-630 -- Loss: 0.3404722511768341
val-epoch-step: 84-631 -- Loss: 0.142217218875885
val-epoch-step: 84-632 -- Loss: 0.20669159293174744
val-epoch-step: 84-633 -- Loss: 0.15138106048107147
val-epoch-step: 84-634 -- Loss: 0.1537458598613739
val-epoch-step: 84-635 -- Loss: 0.1095985397696495
val-epoch-step: 84-636 -- Loss: 0.16012981534004211
val-epoch-step: 84-637 -- Loss: 0.18277710676193237
val-epoch-step: 84-638 -- Loss: 0.14476251602172852
val-epoch-step: 84-639 -- Loss: 0.2616206705570221
val-epoch-step: 84-640 -- Loss: 0.24180950224399567
val-epoch-step: 84-641 -- Loss: 0.12562407553195953
val-epoch-step: 84-642 -- Loss: 0.17636226117610931
val-epoch-step: 84-643 -- Loss: 0.2092554271221161
val-epoch-step: 84-644 -- Loss: 0.1641564667224884
val-epoch-step: 84-645 -- Loss: 0.22158440947532654
val-epoch-step: 84-646 -- Loss: 0.12515923380851746
val-epoch-step: 84-647 -- Loss: 0.12681223452091217
val-epoch-step: 84-648 -- Loss: 0.15103185176849365
val-epoch-step: 84-649 -- Loss: 0.20658372342586517
val-epoch-step: 84-650 -- Loss: 0.25350460410118103
val-epoch-step: 84-651 -- Loss: 0.14261075854301453
val-epoch-step: 84-652 -- Loss: 0.1489478200674057
val-epoch-step: 84-653 -- Loss: 0.21382874250411987
val-epoch-step: 84-654 -- Loss: 0.11786479502916336
Epoch: 84 -- Train Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 85-0 -- Loss: 0.2199995517730713
train-epoch-step: 85-1 -- Loss: 0.14457274973392487
train-epoch-step: 85-2 -- Loss: 0.19745862483978271
train-epoch-step: 85-3 -- Loss: 0.13918262720108032
train-epoch-step: 85-4 -- Loss: 0.15767958760261536
train-epoch-step: 85-5 -- Loss: 0.17616307735443115
train-epoch-step: 85-6 -- Loss: 0.2151460498571396
train-epoch-step: 85-7 -- Loss: 0.1636219322681427
train-epoch-step: 85-8 -- Loss: 0.19006375968456268
train-epoch-step: 85-9 -- Loss: 0.2236645370721817
train-epoch-step: 85-10 -- Loss: 0.1928166002035141
train-epoch-step: 85-11 -- Loss: 0.1702640801668167
train-epoch-step: 85-12 -- Loss: 0.14655888080596924
train-epoch-step: 85-13 -- Loss: 0.17621852457523346
train-epoch-step: 85-14 -- Loss: 0.1685488522052765
train-epoch-step: 85-15 -- Loss: 0.1596882939338684
train-epoch-step: 85-16 -- Loss: 0.164297953248024
train-epoch-step: 85-17 -- Loss: 0.24265065789222717
train-epoch-step: 85-18 -- Loss: 0.1853305995464325
train-epoch-step: 85-19 -- Loss: 0.12715402245521545
train-epoch-step: 85-20 -- Loss: 0.21015337109565735
train-epoch-step: 85-21 -- Loss: 0.28659987449645996
train-epoch-step: 85-22 -- Loss: 0.14770114421844482
train-epoch-step: 85-23 -- Loss: 0.14661721885204315
train-epoch-step: 85-24 -- Loss: 0.13362634181976318
train-epoch-step: 85-25 -- Loss: 0.24344509840011597
train-epoch-step: 85-26 -- Loss: 0.22426074743270874
train-epoch-step: 85-27 -- Loss: 0.34218883514404297
train-epoch-step: 85-28 -- Loss: 0.16994571685791016
train-epoch-step: 85-29 -- Loss: 0.25857800245285034
train-epoch-step: 85-30 -- Loss: 0.1278025358915329
train-epoch-step: 85-31 -- Loss: 0.151930570602417
train-epoch-step: 85-32 -- Loss: 0.1850142776966095
train-epoch-step: 85-33 -- Loss: 0.323544979095459
train-epoch-step: 85-34 -- Loss: 0.21800348162651062
train-epoch-step: 85-35 -- Loss: 0.2585821747779846
train-epoch-step: 85-36 -- Loss: 0.15449848771095276
train-epoch-step: 85-37 -- Loss: 0.1444871723651886
train-epoch-step: 85-38 -- Loss: 0.1824989765882492
train-epoch-step: 85-39 -- Loss: 0.24872224032878876
train-epoch-step: 85-40 -- Loss: 0.22196996212005615
train-epoch-step: 85-41 -- Loss: 0.23632022738456726
train-epoch-step: 85-42 -- Loss: 0.1841883659362793
train-epoch-step: 85-43 -- Loss: 0.27712443470954895
train-epoch-step: 85-44 -- Loss: 0.13040554523468018
train-epoch-step: 85-45 -- Loss: 0.12702058255672455
train-epoch-step: 85-46 -- Loss: 0.1858685314655304
train-epoch-step: 85-47 -- Loss: 0.22130882740020752
train-epoch-step: 85-48 -- Loss: 0.16548636555671692
train-epoch-step: 85-49 -- Loss: 0.2384965717792511
train-epoch-step: 85-50 -- Loss: 0.11268032342195511
train-epoch-step: 85-51 -- Loss: 0.17865657806396484
train-epoch-step: 85-52 -- Loss: 0.1631976217031479
train-epoch-step: 85-53 -- Loss: 0.22311663627624512
train-epoch-step: 85-54 -- Loss: 0.2915838658809662
train-epoch-step: 85-55 -- Loss: 0.16957350075244904
train-epoch-step: 85-56 -- Loss: 0.19745482504367828
train-epoch-step: 85-57 -- Loss: 0.24049124121665955
train-epoch-step: 85-58 -- Loss: 0.2859175503253937
train-epoch-step: 85-59 -- Loss: 0.2560461759567261
train-epoch-step: 85-60 -- Loss: 0.1292298436164856
train-epoch-step: 85-61 -- Loss: 0.20415952801704407
train-epoch-step: 85-62 -- Loss: 0.18208882212638855
train-epoch-step: 85-63 -- Loss: 0.13208477199077606
train-epoch-step: 85-64 -- Loss: 0.15067830681800842
train-epoch-step: 85-65 -- Loss: 0.1841059923171997
train-epoch-step: 85-66 -- Loss: 0.11125625669956207
train-epoch-step: 85-67 -- Loss: 0.1215183213353157
train-epoch-step: 85-68 -- Loss: 0.2226666808128357
train-epoch-step: 85-69 -- Loss: 0.12281907349824905
train-epoch-step: 85-70 -- Loss: 0.24097999930381775
train-epoch-step: 85-71 -- Loss: 0.26667502522468567
train-epoch-step: 85-72 -- Loss: 0.18149441480636597
train-epoch-step: 85-73 -- Loss: 0.2068166881799698
train-epoch-step: 85-74 -- Loss: 0.09662969410419464
train-epoch-step: 85-75 -- Loss: 0.12799739837646484
train-epoch-step: 85-76 -- Loss: 0.15154001116752625
train-epoch-step: 85-77 -- Loss: 0.23071390390396118
train-epoch-step: 85-78 -- Loss: 0.2625279128551483
train-epoch-step: 85-79 -- Loss: 0.20467619597911835
train-epoch-step: 85-80 -- Loss: 0.25309205055236816
train-epoch-step: 85-81 -- Loss: 0.1255538910627365
train-epoch-step: 85-82 -- Loss: 0.2538257837295532
train-epoch-step: 85-83 -- Loss: 0.17900756001472473
train-epoch-step: 85-84 -- Loss: 0.18978244066238403
train-epoch-step: 85-85 -- Loss: 0.17376868426799774
train-epoch-step: 85-86 -- Loss: 0.1177511215209961
train-epoch-step: 85-87 -- Loss: 0.21588850021362305
train-epoch-step: 85-88 -- Loss: 0.13981908559799194
train-epoch-step: 85-89 -- Loss: 0.18714676797389984
train-epoch-step: 85-90 -- Loss: 0.1897978037595749
train-epoch-step: 85-91 -- Loss: 0.24169889092445374
train-epoch-step: 85-92 -- Loss: 0.15072911977767944
train-epoch-step: 85-93 -- Loss: 0.1789989024400711
train-epoch-step: 85-94 -- Loss: 0.22993406653404236
train-epoch-step: 85-95 -- Loss: 0.18718867003917694
train-epoch-step: 85-96 -- Loss: 0.21432502567768097
train-epoch-step: 85-97 -- Loss: 0.16789186000823975
train-epoch-step: 85-98 -- Loss: 0.15537166595458984
train-epoch-step: 85-99 -- Loss: 0.17900288105010986
train-epoch-step: 85-100 -- Loss: 0.18369705975055695
train-epoch-step: 85-101 -- Loss: 0.26676711440086365
train-epoch-step: 85-102 -- Loss: 0.23006363213062286
train-epoch-step: 85-103 -- Loss: 0.18005144596099854
train-epoch-step: 85-104 -- Loss: 0.1472041755914688
train-epoch-step: 85-105 -- Loss: 0.2791619598865509
train-epoch-step: 85-106 -- Loss: 0.17717811465263367
train-epoch-step: 85-107 -- Loss: 0.18559402227401733
train-epoch-step: 85-108 -- Loss: 0.18710440397262573
train-epoch-step: 85-109 -- Loss: 0.14212241768836975
train-epoch-step: 85-110 -- Loss: 0.18007494509220123
train-epoch-step: 85-111 -- Loss: 0.18021488189697266
train-epoch-step: 85-112 -- Loss: 0.16927216947078705
train-epoch-step: 85-113 -- Loss: 0.16687753796577454
train-epoch-step: 85-114 -- Loss: 0.1967388540506363
train-epoch-step: 85-115 -- Loss: 0.1606949269771576
train-epoch-step: 85-116 -- Loss: 0.1395779848098755
train-epoch-step: 85-117 -- Loss: 0.12491898238658905
train-epoch-step: 85-118 -- Loss: 0.1911914348602295
train-epoch-step: 85-119 -- Loss: 0.15170373022556305
train-epoch-step: 85-120 -- Loss: 0.24532592296600342
train-epoch-step: 85-121 -- Loss: 0.29993999004364014
train-epoch-step: 85-122 -- Loss: 0.2154790610074997
train-epoch-step: 85-123 -- Loss: 0.19687774777412415
train-epoch-step: 85-124 -- Loss: 0.1226223036646843
train-epoch-step: 85-125 -- Loss: 0.15169984102249146
train-epoch-step: 85-126 -- Loss: 0.22919298708438873
train-epoch-step: 85-127 -- Loss: 0.17261578142642975
train-epoch-step: 85-128 -- Loss: 0.16788627207279205
train-epoch-step: 85-129 -- Loss: 0.14251431822776794
train-epoch-step: 85-130 -- Loss: 0.211042582988739
train-epoch-step: 85-131 -- Loss: 0.13596628606319427
train-epoch-step: 85-132 -- Loss: 0.1832635998725891
train-epoch-step: 85-133 -- Loss: 0.12393646687269211
train-epoch-step: 85-134 -- Loss: 0.19927608966827393
train-epoch-step: 85-135 -- Loss: 0.13825364410877228
train-epoch-step: 85-136 -- Loss: 0.13739772140979767
train-epoch-step: 85-137 -- Loss: 0.25455090403556824
train-epoch-step: 85-138 -- Loss: 0.2883106470108032
train-epoch-step: 85-139 -- Loss: 0.12741097807884216
train-epoch-step: 85-140 -- Loss: 0.2305414378643036
train-epoch-step: 85-141 -- Loss: 0.2317146509885788
train-epoch-step: 85-142 -- Loss: 0.209959477186203
train-epoch-step: 85-143 -- Loss: 0.17840898036956787
train-epoch-step: 85-144 -- Loss: 0.20222696661949158
train-epoch-step: 85-145 -- Loss: 0.15553055703639984
train-epoch-step: 85-146 -- Loss: 0.17808714509010315
train-epoch-step: 85-147 -- Loss: 0.17067861557006836
train-epoch-step: 85-148 -- Loss: 0.16216999292373657
train-epoch-step: 85-149 -- Loss: 0.1239287257194519
train-epoch-step: 85-150 -- Loss: 0.19002632796764374
train-epoch-step: 85-151 -- Loss: 0.18477804958820343
train-epoch-step: 85-152 -- Loss: 0.23013722896575928
train-epoch-step: 85-153 -- Loss: 0.26764997839927673
train-epoch-step: 85-154 -- Loss: 0.13581958413124084
train-epoch-step: 85-155 -- Loss: 0.13832685351371765
train-epoch-step: 85-156 -- Loss: 0.12202155590057373
train-epoch-step: 85-157 -- Loss: 0.16379696130752563
train-epoch-step: 85-158 -- Loss: 0.16162894666194916
train-epoch-step: 85-159 -- Loss: 0.1759990155696869
train-epoch-step: 85-160 -- Loss: 0.22381223738193512
train-epoch-step: 85-161 -- Loss: 0.2044578194618225
train-epoch-step: 85-162 -- Loss: 0.21243271231651306
train-epoch-step: 85-163 -- Loss: 0.19542473554611206
train-epoch-step: 85-164 -- Loss: 0.19088786840438843
train-epoch-step: 85-165 -- Loss: 0.16095581650733948
train-epoch-step: 85-166 -- Loss: 0.12117457389831543
train-epoch-step: 85-167 -- Loss: 0.13989436626434326
train-epoch-step: 85-168 -- Loss: 0.199031263589859
train-epoch-step: 85-169 -- Loss: 0.1381041258573532
train-epoch-step: 85-170 -- Loss: 0.19884169101715088
train-epoch-step: 85-171 -- Loss: 0.14276787638664246
train-epoch-step: 85-172 -- Loss: 0.2580972909927368
train-epoch-step: 85-173 -- Loss: 0.13180403411388397
train-epoch-step: 85-174 -- Loss: 0.24450962245464325
train-epoch-step: 85-175 -- Loss: 0.2076340913772583
train-epoch-step: 85-176 -- Loss: 0.12936848402023315
train-epoch-step: 85-177 -- Loss: 0.17789451777935028
train-epoch-step: 85-178 -- Loss: 0.17905808985233307
train-epoch-step: 85-179 -- Loss: 0.16118241846561432
train-epoch-step: 85-180 -- Loss: 0.14953169226646423
train-epoch-step: 85-181 -- Loss: 0.16819311678409576
train-epoch-step: 85-182 -- Loss: 0.18912118673324585
train-epoch-step: 85-183 -- Loss: 0.2696041762828827
train-epoch-step: 85-184 -- Loss: 0.1397179812192917
train-epoch-step: 85-185 -- Loss: 0.14786608517169952
train-epoch-step: 85-186 -- Loss: 0.1886829137802124
train-epoch-step: 85-187 -- Loss: 0.20581743121147156
train-epoch-step: 85-188 -- Loss: 0.1671503782272339
train-epoch-step: 85-189 -- Loss: 0.10324423015117645
train-epoch-step: 85-190 -- Loss: 0.18365679681301117
train-epoch-step: 85-191 -- Loss: 0.1694899946451187
train-epoch-step: 85-192 -- Loss: 0.2285221964120865
train-epoch-step: 85-193 -- Loss: 0.28141412138938904
train-epoch-step: 85-194 -- Loss: 0.1791234314441681
train-epoch-step: 85-195 -- Loss: 0.16579057276248932
train-epoch-step: 85-196 -- Loss: 0.16316843032836914
train-epoch-step: 85-197 -- Loss: 0.12886033952236176
train-epoch-step: 85-198 -- Loss: 0.12915799021720886
train-epoch-step: 85-199 -- Loss: 0.15115445852279663
train-epoch-step: 85-200 -- Loss: 0.1257697492837906
train-epoch-step: 85-201 -- Loss: 0.19039827585220337
train-epoch-step: 85-202 -- Loss: 0.13536588847637177
train-epoch-step: 85-203 -- Loss: 0.1826251745223999
train-epoch-step: 85-204 -- Loss: 0.1369345784187317
train-epoch-step: 85-205 -- Loss: 0.18618297576904297
train-epoch-step: 85-206 -- Loss: 0.20225268602371216
train-epoch-step: 85-207 -- Loss: 0.1414814591407776
train-epoch-step: 85-208 -- Loss: 0.17602422833442688
train-epoch-step: 85-209 -- Loss: 0.1430380940437317
train-epoch-step: 85-210 -- Loss: 0.12785643339157104
train-epoch-step: 85-211 -- Loss: 0.2090892791748047
train-epoch-step: 85-212 -- Loss: 0.19683119654655457
train-epoch-step: 85-213 -- Loss: 0.12811118364334106
train-epoch-step: 85-214 -- Loss: 0.1454496830701828
train-epoch-step: 85-215 -- Loss: 0.12701772153377533
train-epoch-step: 85-216 -- Loss: 0.20123565196990967
train-epoch-step: 85-217 -- Loss: 0.2170507311820984
train-epoch-step: 85-218 -- Loss: 0.1404709815979004
train-epoch-step: 85-219 -- Loss: 0.16423514485359192
train-epoch-step: 85-220 -- Loss: 0.133274108171463
train-epoch-step: 85-221 -- Loss: 0.20756378769874573
train-epoch-step: 85-222 -- Loss: 0.11787281930446625
train-epoch-step: 85-223 -- Loss: 0.17010709643363953
train-epoch-step: 85-224 -- Loss: 0.18590371310710907
train-epoch-step: 85-225 -- Loss: 0.27160578966140747
train-epoch-step: 85-226 -- Loss: 0.2045362889766693
train-epoch-step: 85-227 -- Loss: 0.21560926735401154
train-epoch-step: 85-228 -- Loss: 0.17591474950313568
train-epoch-step: 85-229 -- Loss: 0.17236416041851044
train-epoch-step: 85-230 -- Loss: 0.16542452573776245
train-epoch-step: 85-231 -- Loss: 0.1518481969833374
train-epoch-step: 85-232 -- Loss: 0.18274155259132385
train-epoch-step: 85-233 -- Loss: 0.08304919302463531
train-epoch-step: 85-234 -- Loss: 0.17311963438987732
train-epoch-step: 85-235 -- Loss: 0.14214719831943512
train-epoch-step: 85-236 -- Loss: 0.1800035536289215
train-epoch-step: 85-237 -- Loss: 0.2271476536989212
train-epoch-step: 85-238 -- Loss: 0.1551980972290039
train-epoch-step: 85-239 -- Loss: 0.12262649834156036
train-epoch-step: 85-240 -- Loss: 0.22304227948188782
train-epoch-step: 85-241 -- Loss: 0.15189491212368011
train-epoch-step: 85-242 -- Loss: 0.21222619712352753
train-epoch-step: 85-243 -- Loss: 0.2332760989665985
train-epoch-step: 85-244 -- Loss: 0.2045089304447174
train-epoch-step: 85-245 -- Loss: 0.20029382407665253
train-epoch-step: 85-246 -- Loss: 0.21188196539878845
train-epoch-step: 85-247 -- Loss: 0.21126870810985565
train-epoch-step: 85-248 -- Loss: 0.18415072560310364
train-epoch-step: 85-249 -- Loss: 0.13385683298110962
train-epoch-step: 85-250 -- Loss: 0.19392843544483185
train-epoch-step: 85-251 -- Loss: 0.10386300832033157
train-epoch-step: 85-252 -- Loss: 0.19480615854263306
train-epoch-step: 85-253 -- Loss: 0.132937952876091
train-epoch-step: 85-254 -- Loss: 0.21139562129974365
train-epoch-step: 85-255 -- Loss: 0.14464253187179565
train-epoch-step: 85-256 -- Loss: 0.1400233805179596
train-epoch-step: 85-257 -- Loss: 0.1855693906545639
train-epoch-step: 85-258 -- Loss: 0.1428310126066208
train-epoch-step: 85-259 -- Loss: 0.11038118600845337
train-epoch-step: 85-260 -- Loss: 0.19994564354419708
train-epoch-step: 85-261 -- Loss: 0.16780108213424683
train-epoch-step: 85-262 -- Loss: 0.28014129400253296
train-epoch-step: 85-263 -- Loss: 0.20110827684402466
train-epoch-step: 85-264 -- Loss: 0.16758829355239868
train-epoch-step: 85-265 -- Loss: 0.1141168475151062
train-epoch-step: 85-266 -- Loss: 0.15013207495212555
train-epoch-step: 85-267 -- Loss: 0.12854743003845215
train-epoch-step: 85-268 -- Loss: 0.11336071789264679
train-epoch-step: 85-269 -- Loss: 0.16776816546916962
train-epoch-step: 85-270 -- Loss: 0.10615956783294678
train-epoch-step: 85-271 -- Loss: 0.14773492515087128
train-epoch-step: 85-272 -- Loss: 0.12332642823457718
train-epoch-step: 85-273 -- Loss: 0.12297040969133377
train-epoch-step: 85-274 -- Loss: 0.18046505749225616
train-epoch-step: 85-275 -- Loss: 0.1835130751132965
train-epoch-step: 85-276 -- Loss: 0.15360334515571594
train-epoch-step: 85-277 -- Loss: 0.15446582436561584
train-epoch-step: 85-278 -- Loss: 0.1341463029384613
train-epoch-step: 85-279 -- Loss: 0.1338636577129364
train-epoch-step: 85-280 -- Loss: 0.21569156646728516
train-epoch-step: 85-281 -- Loss: 0.17359954118728638
train-epoch-step: 85-282 -- Loss: 0.13746728003025055
train-epoch-step: 85-283 -- Loss: 0.11297985911369324
train-epoch-step: 85-284 -- Loss: 0.13410092890262604
train-epoch-step: 85-285 -- Loss: 0.1859716773033142
train-epoch-step: 85-286 -- Loss: 0.15205466747283936
train-epoch-step: 85-287 -- Loss: 0.19853505492210388
train-epoch-step: 85-288 -- Loss: 0.09149927645921707
train-epoch-step: 85-289 -- Loss: 0.1144077479839325
train-epoch-step: 85-290 -- Loss: 0.17579737305641174
train-epoch-step: 85-291 -- Loss: 0.11995591223239899
train-epoch-step: 85-292 -- Loss: 0.15691719949245453
train-epoch-step: 85-293 -- Loss: 0.13161017000675201
train-epoch-step: 85-294 -- Loss: 0.1544562429189682
train-epoch-step: 85-295 -- Loss: 0.25661617517471313
train-epoch-step: 85-296 -- Loss: 0.15561939775943756
train-epoch-step: 85-297 -- Loss: 0.17130641639232635
train-epoch-step: 85-298 -- Loss: 0.2227795124053955
train-epoch-step: 85-299 -- Loss: 0.1427498608827591
train-epoch-step: 85-300 -- Loss: 0.15988218784332275
train-epoch-step: 85-301 -- Loss: 0.16420507431030273
train-epoch-step: 85-302 -- Loss: 0.21081827580928802
train-epoch-step: 85-303 -- Loss: 0.20135186612606049
train-epoch-step: 85-304 -- Loss: 0.1266104280948639
train-epoch-step: 85-305 -- Loss: 0.1394580602645874
train-epoch-step: 85-306 -- Loss: 0.2132864147424698
train-epoch-step: 85-307 -- Loss: 0.1610303372144699
train-epoch-step: 85-308 -- Loss: 0.21813809871673584
train-epoch-step: 85-309 -- Loss: 0.15158168971538544
train-epoch-step: 85-310 -- Loss: 0.16634991765022278
train-epoch-step: 85-311 -- Loss: 0.15881365537643433
train-epoch-step: 85-312 -- Loss: 0.20762404799461365
train-epoch-step: 85-313 -- Loss: 0.09960105270147324
train-epoch-step: 85-314 -- Loss: 0.19980406761169434
train-epoch-step: 85-315 -- Loss: 0.16450905799865723
train-epoch-step: 85-316 -- Loss: 0.15066702663898468
train-epoch-step: 85-317 -- Loss: 0.1325998157262802
train-epoch-step: 85-318 -- Loss: 0.1596960425376892
train-epoch-step: 85-319 -- Loss: 0.16044679284095764
train-epoch-step: 85-320 -- Loss: 0.12433221191167831
train-epoch-step: 85-321 -- Loss: 0.1307363212108612
train-epoch-step: 85-322 -- Loss: 0.2092493176460266
train-epoch-step: 85-323 -- Loss: 0.15961194038391113
train-epoch-step: 85-324 -- Loss: 0.24946430325508118
train-epoch-step: 85-325 -- Loss: 0.15090171992778778
train-epoch-step: 85-326 -- Loss: 0.17485058307647705
train-epoch-step: 85-327 -- Loss: 0.1970343291759491
train-epoch-step: 85-328 -- Loss: 0.19135403633117676
train-epoch-step: 85-329 -- Loss: 0.33191606402397156
train-epoch-step: 85-330 -- Loss: 0.36327430605888367
train-epoch-step: 85-331 -- Loss: 0.20706219971179962
train-epoch-step: 85-332 -- Loss: 0.10005994886159897
train-epoch-step: 85-333 -- Loss: 0.1852041631937027
train-epoch-step: 85-334 -- Loss: 0.15057991445064545
train-epoch-step: 85-335 -- Loss: 0.16706296801567078
train-epoch-step: 85-336 -- Loss: 0.145037442445755
train-epoch-step: 85-337 -- Loss: 0.19500821828842163
train-epoch-step: 85-338 -- Loss: 0.15580064058303833
train-epoch-step: 85-339 -- Loss: 0.13617943227291107
train-epoch-step: 85-340 -- Loss: 0.19911128282546997
train-epoch-step: 85-341 -- Loss: 0.13588988780975342
train-epoch-step: 85-342 -- Loss: 0.1674668937921524
train-epoch-step: 85-343 -- Loss: 0.15290714800357819
train-epoch-step: 85-344 -- Loss: 0.1654062271118164
train-epoch-step: 85-345 -- Loss: 0.12460488080978394
train-epoch-step: 85-346 -- Loss: 0.2042624056339264
train-epoch-step: 85-347 -- Loss: 0.15329936146736145
train-epoch-step: 85-348 -- Loss: 0.19844506680965424
train-epoch-step: 85-349 -- Loss: 0.20268100500106812
train-epoch-step: 85-350 -- Loss: 0.24822884798049927
train-epoch-step: 85-351 -- Loss: 0.1843823939561844
train-epoch-step: 85-352 -- Loss: 0.12772436439990997
train-epoch-step: 85-353 -- Loss: 0.18590320646762848
train-epoch-step: 85-354 -- Loss: 0.2818433940410614
train-epoch-step: 85-355 -- Loss: 0.1162106841802597
train-epoch-step: 85-356 -- Loss: 0.11224812269210815
train-epoch-step: 85-357 -- Loss: 0.18180808424949646
train-epoch-step: 85-358 -- Loss: 0.1824122965335846
train-epoch-step: 85-359 -- Loss: 0.13491447269916534
train-epoch-step: 85-360 -- Loss: 0.12433257699012756
train-epoch-step: 85-361 -- Loss: 0.23547345399856567
train-epoch-step: 85-362 -- Loss: 0.16596108675003052
train-epoch-step: 85-363 -- Loss: 0.1376386135816574
train-epoch-step: 85-364 -- Loss: 0.1781010925769806
train-epoch-step: 85-365 -- Loss: 0.1703353226184845
train-epoch-step: 85-366 -- Loss: 0.20960673689842224
train-epoch-step: 85-367 -- Loss: 0.2222827970981598
train-epoch-step: 85-368 -- Loss: 0.19828581809997559
train-epoch-step: 85-369 -- Loss: 0.27513235807418823
train-epoch-step: 85-370 -- Loss: 0.12421157956123352
train-epoch-step: 85-371 -- Loss: 0.11929697543382645
train-epoch-step: 85-372 -- Loss: 0.14793993532657623
train-epoch-step: 85-373 -- Loss: 0.19359174370765686
train-epoch-step: 85-374 -- Loss: 0.15040916204452515
train-epoch-step: 85-375 -- Loss: 0.25811389088630676
train-epoch-step: 85-376 -- Loss: 0.1532493382692337
train-epoch-step: 85-377 -- Loss: 0.23458851873874664
train-epoch-step: 85-378 -- Loss: 0.19499816000461578
train-epoch-step: 85-379 -- Loss: 0.11783412098884583
train-epoch-step: 85-380 -- Loss: 0.08930128812789917
train-epoch-step: 85-381 -- Loss: 0.23868121206760406
train-epoch-step: 85-382 -- Loss: 0.23253187537193298
train-epoch-step: 85-383 -- Loss: 0.181845024228096
train-epoch-step: 85-384 -- Loss: 0.23162463307380676
train-epoch-step: 85-385 -- Loss: 0.18927623331546783
train-epoch-step: 85-386 -- Loss: 0.18617507815361023
train-epoch-step: 85-387 -- Loss: 0.20016326010227203
train-epoch-step: 85-388 -- Loss: 0.2113112062215805
train-epoch-step: 85-389 -- Loss: 0.16661036014556885
train-epoch-step: 85-390 -- Loss: 0.15360820293426514
train-epoch-step: 85-391 -- Loss: 0.15436862409114838
train-epoch-step: 85-392 -- Loss: 0.17715245485305786
train-epoch-step: 85-393 -- Loss: 0.15518450736999512
train-epoch-step: 85-394 -- Loss: 0.19427824020385742
train-epoch-step: 85-395 -- Loss: 0.1548897922039032
train-epoch-step: 85-396 -- Loss: 0.122653529047966
train-epoch-step: 85-397 -- Loss: 0.12194739282131195
train-epoch-step: 85-398 -- Loss: 0.20286807417869568
train-epoch-step: 85-399 -- Loss: 0.1684204488992691
train-epoch-step: 85-400 -- Loss: 0.2911813259124756
train-epoch-step: 85-401 -- Loss: 0.12146010994911194
train-epoch-step: 85-402 -- Loss: 0.2508780062198639
train-epoch-step: 85-403 -- Loss: 0.15490864217281342
train-epoch-step: 85-404 -- Loss: 0.14714248478412628
train-epoch-step: 85-405 -- Loss: 0.14151260256767273
train-epoch-step: 85-406 -- Loss: 0.16577766835689545
train-epoch-step: 85-407 -- Loss: 0.1141236200928688
train-epoch-step: 85-408 -- Loss: 0.16242976486682892
train-epoch-step: 85-409 -- Loss: 0.18238067626953125
train-epoch-step: 85-410 -- Loss: 0.17661529779434204
train-epoch-step: 85-411 -- Loss: 0.19559061527252197
train-epoch-step: 85-412 -- Loss: 0.1318836212158203
train-epoch-step: 85-413 -- Loss: 0.14270628988742828
train-epoch-step: 85-414 -- Loss: 0.13052622973918915
train-epoch-step: 85-415 -- Loss: 0.13566960394382477
train-epoch-step: 85-416 -- Loss: 0.26078957319259644
train-epoch-step: 85-417 -- Loss: 0.19031189382076263
train-epoch-step: 85-418 -- Loss: 0.23716235160827637
train-epoch-step: 85-419 -- Loss: 0.16752225160598755
train-epoch-step: 85-420 -- Loss: 0.14961397647857666
train-epoch-step: 85-421 -- Loss: 0.17994754016399384
train-epoch-step: 85-422 -- Loss: 0.1538289338350296
train-epoch-step: 85-423 -- Loss: 0.18099798262119293
train-epoch-step: 85-424 -- Loss: 0.1372433304786682
train-epoch-step: 85-425 -- Loss: 0.18380248546600342
train-epoch-step: 85-426 -- Loss: 0.16145072877407074
train-epoch-step: 85-427 -- Loss: 0.12175223231315613
train-epoch-step: 85-428 -- Loss: 0.19882065057754517
train-epoch-step: 85-429 -- Loss: 0.17759433388710022
train-epoch-step: 85-430 -- Loss: 0.14563032984733582
train-epoch-step: 85-431 -- Loss: 0.16225242614746094
train-epoch-step: 85-432 -- Loss: 0.24208924174308777
train-epoch-step: 85-433 -- Loss: 0.1447327584028244
train-epoch-step: 85-434 -- Loss: 0.1258770078420639
train-epoch-step: 85-435 -- Loss: 0.16380730271339417
train-epoch-step: 85-436 -- Loss: 0.15411077439785004
train-epoch-step: 85-437 -- Loss: 0.13813897967338562
train-epoch-step: 85-438 -- Loss: 0.22398170828819275
train-epoch-step: 85-439 -- Loss: 0.27167829871177673
train-epoch-step: 85-440 -- Loss: 0.13105891644954681
train-epoch-step: 85-441 -- Loss: 0.20223280787467957
train-epoch-step: 85-442 -- Loss: 0.17298343777656555
train-epoch-step: 85-443 -- Loss: 0.16309267282485962
train-epoch-step: 85-444 -- Loss: 0.18433620035648346
train-epoch-step: 85-445 -- Loss: 0.1794019341468811
train-epoch-step: 85-446 -- Loss: 0.15163704752922058
train-epoch-step: 85-447 -- Loss: 0.18583260476589203
train-epoch-step: 85-448 -- Loss: 0.22009629011154175
train-epoch-step: 85-449 -- Loss: 0.20923006534576416
train-epoch-step: 85-450 -- Loss: 0.18616332113742828
train-epoch-step: 85-451 -- Loss: 0.15120649337768555
train-epoch-step: 85-452 -- Loss: 0.13611775636672974
train-epoch-step: 85-453 -- Loss: 0.09042336791753769
train-epoch-step: 85-454 -- Loss: 0.231176495552063
train-epoch-step: 85-455 -- Loss: 0.1255146712064743
train-epoch-step: 85-456 -- Loss: 0.11674089729785919
train-epoch-step: 85-457 -- Loss: 0.2177252322435379
train-epoch-step: 85-458 -- Loss: 0.15650337934494019
train-epoch-step: 85-459 -- Loss: 0.2155214101076126
train-epoch-step: 85-460 -- Loss: 0.13100436329841614
train-epoch-step: 85-461 -- Loss: 0.13233545422554016
train-epoch-step: 85-462 -- Loss: 0.15452268719673157
train-epoch-step: 85-463 -- Loss: 0.13913245499134064
train-epoch-step: 85-464 -- Loss: 0.16611847281455994
train-epoch-step: 85-465 -- Loss: 0.2420019805431366
train-epoch-step: 85-466 -- Loss: 0.20093417167663574
train-epoch-step: 85-467 -- Loss: 0.10927217453718185
train-epoch-step: 85-468 -- Loss: 0.16383858025074005
train-epoch-step: 85-469 -- Loss: 0.205617755651474
train-epoch-step: 85-470 -- Loss: 0.17614999413490295
train-epoch-step: 85-471 -- Loss: 0.15640410780906677
train-epoch-step: 85-472 -- Loss: 0.15397873520851135
train-epoch-step: 85-473 -- Loss: 0.15226280689239502
train-epoch-step: 85-474 -- Loss: 0.11739753931760788
train-epoch-step: 85-475 -- Loss: 0.10690862685441971
train-epoch-step: 85-476 -- Loss: 0.1986861377954483
train-epoch-step: 85-477 -- Loss: 0.19694024324417114
train-epoch-step: 85-478 -- Loss: 0.18475502729415894
train-epoch-step: 85-479 -- Loss: 0.13953115046024323
train-epoch-step: 85-480 -- Loss: 0.18522296845912933
train-epoch-step: 85-481 -- Loss: 0.2713674306869507
train-epoch-step: 85-482 -- Loss: 0.2527850568294525
train-epoch-step: 85-483 -- Loss: 0.17590533196926117
train-epoch-step: 85-484 -- Loss: 0.2161276787519455
train-epoch-step: 85-485 -- Loss: 0.12426398694515228
train-epoch-step: 85-486 -- Loss: 0.22688552737236023
train-epoch-step: 85-487 -- Loss: 0.22994288802146912
train-epoch-step: 85-488 -- Loss: 0.18782085180282593
train-epoch-step: 85-489 -- Loss: 0.2187572568655014
train-epoch-step: 85-490 -- Loss: 0.13677960634231567
train-epoch-step: 85-491 -- Loss: 0.13519708812236786
train-epoch-step: 85-492 -- Loss: 0.12557213008403778
train-epoch-step: 85-493 -- Loss: 0.19904489815235138
train-epoch-step: 85-494 -- Loss: 0.19845899939537048
train-epoch-step: 85-495 -- Loss: 0.19668185710906982
train-epoch-step: 85-496 -- Loss: 0.14192837476730347
train-epoch-step: 85-497 -- Loss: 0.1871076077222824
train-epoch-step: 85-498 -- Loss: 0.14549317955970764
train-epoch-step: 85-499 -- Loss: 0.16248250007629395
train-epoch-step: 85-500 -- Loss: 0.1497841775417328
train-epoch-step: 85-501 -- Loss: 0.20915359258651733
train-epoch-step: 85-502 -- Loss: 0.15485447645187378
train-epoch-step: 85-503 -- Loss: 0.21280711889266968
train-epoch-step: 85-504 -- Loss: 0.11497041583061218
train-epoch-step: 85-505 -- Loss: 0.1687498390674591
train-epoch-step: 85-506 -- Loss: 0.11235229671001434
train-epoch-step: 85-507 -- Loss: 0.19265690445899963
train-epoch-step: 85-508 -- Loss: 0.1775830239057541
train-epoch-step: 85-509 -- Loss: 0.16364258527755737
train-epoch-step: 85-510 -- Loss: 0.12439242005348206
train-epoch-step: 85-511 -- Loss: 0.2201937735080719
train-epoch-step: 85-512 -- Loss: 0.17238476872444153
train-epoch-step: 85-513 -- Loss: 0.18923920392990112
train-epoch-step: 85-514 -- Loss: 0.14729246497154236
train-epoch-step: 85-515 -- Loss: 0.1508747935295105
train-epoch-step: 85-516 -- Loss: 0.16897667944431305
train-epoch-step: 85-517 -- Loss: 0.17145909368991852
train-epoch-step: 85-518 -- Loss: 0.13641105592250824
train-epoch-step: 85-519 -- Loss: 0.13257361948490143
train-epoch-step: 85-520 -- Loss: 0.18246665596961975
train-epoch-step: 85-521 -- Loss: 0.22356192767620087
train-epoch-step: 85-522 -- Loss: 0.17145121097564697
train-epoch-step: 85-523 -- Loss: 0.15488392114639282
train-epoch-step: 85-524 -- Loss: 0.16883862018585205
train-epoch-step: 85-525 -- Loss: 0.18607603013515472
train-epoch-step: 85-526 -- Loss: 0.1277088224887848
train-epoch-step: 85-527 -- Loss: 0.14717954397201538
train-epoch-step: 85-528 -- Loss: 0.15318594872951508
train-epoch-step: 85-529 -- Loss: 0.15423369407653809
train-epoch-step: 85-530 -- Loss: 0.16589871048927307
train-epoch-step: 85-531 -- Loss: 0.1921023726463318
train-epoch-step: 85-532 -- Loss: 0.16352546215057373
train-epoch-step: 85-533 -- Loss: 0.17381718754768372
train-epoch-step: 85-534 -- Loss: 0.126298725605011
train-epoch-step: 85-535 -- Loss: 0.2642592787742615
train-epoch-step: 85-536 -- Loss: 0.15276454389095306
train-epoch-step: 85-537 -- Loss: 0.1446046531200409
train-epoch-step: 85-538 -- Loss: 0.1055523231625557
train-epoch-step: 85-539 -- Loss: 0.1865634024143219
train-epoch-step: 85-540 -- Loss: 0.147842139005661
train-epoch-step: 85-541 -- Loss: 0.2158478945493698
train-epoch-step: 85-542 -- Loss: 0.23282167315483093
train-epoch-step: 85-543 -- Loss: 0.16515369713306427
train-epoch-step: 85-544 -- Loss: 0.23102587461471558
train-epoch-step: 85-545 -- Loss: 0.1925259679555893
train-epoch-step: 85-546 -- Loss: 0.20651419460773468
train-epoch-step: 85-547 -- Loss: 0.17942935228347778
train-epoch-step: 85-548 -- Loss: 0.09144679456949234
train-epoch-step: 85-549 -- Loss: 0.14764109253883362
train-epoch-step: 85-550 -- Loss: 0.19945013523101807
train-epoch-step: 85-551 -- Loss: 0.1567053645849228
train-epoch-step: 85-552 -- Loss: 0.12822817265987396
train-epoch-step: 85-553 -- Loss: 0.18801209330558777
train-epoch-step: 85-554 -- Loss: 0.19420062005519867
train-epoch-step: 85-555 -- Loss: 0.2061636745929718
train-epoch-step: 85-556 -- Loss: 0.15824133157730103
train-epoch-step: 85-557 -- Loss: 0.23080354928970337
train-epoch-step: 85-558 -- Loss: 0.2295071929693222
train-epoch-step: 85-559 -- Loss: 0.13711793720722198
train-epoch-step: 85-560 -- Loss: 0.20247448980808258
train-epoch-step: 85-561 -- Loss: 0.2211015224456787
train-epoch-step: 85-562 -- Loss: 0.19012793898582458
train-epoch-step: 85-563 -- Loss: 0.39235860109329224
train-epoch-step: 85-564 -- Loss: 0.10967236757278442
train-epoch-step: 85-565 -- Loss: 0.18470609188079834
train-epoch-step: 85-566 -- Loss: 0.15578828752040863
train-epoch-step: 85-567 -- Loss: 0.2141115814447403
train-epoch-step: 85-568 -- Loss: 0.1848233938217163
train-epoch-step: 85-569 -- Loss: 0.24704214930534363
train-epoch-step: 85-570 -- Loss: 0.16653814911842346
train-epoch-step: 85-571 -- Loss: 0.2154083251953125
train-epoch-step: 85-572 -- Loss: 0.254241943359375
train-epoch-step: 85-573 -- Loss: 0.20079389214515686
train-epoch-step: 85-574 -- Loss: 0.3022145926952362
train-epoch-step: 85-575 -- Loss: 0.3274915814399719
train-epoch-step: 85-576 -- Loss: 0.11953198164701462
train-epoch-step: 85-577 -- Loss: 0.17135533690452576
train-epoch-step: 85-578 -- Loss: 0.23722651600837708
train-epoch-step: 85-579 -- Loss: 0.16722078621387482
train-epoch-step: 85-580 -- Loss: 0.18463630974292755
train-epoch-step: 85-581 -- Loss: 0.1425705999135971
train-epoch-step: 85-582 -- Loss: 0.21435701847076416
train-epoch-step: 85-583 -- Loss: 0.23087313771247864
train-epoch-step: 85-584 -- Loss: 0.17699569463729858
train-epoch-step: 85-585 -- Loss: 0.19581905007362366
train-epoch-step: 85-586 -- Loss: 0.2531917691230774
train-epoch-step: 85-587 -- Loss: 0.16639326512813568
train-epoch-step: 85-588 -- Loss: 0.1327487677335739
val-epoch-step: 85-589 -- Loss: 0.22679975628852844
val-epoch-step: 85-590 -- Loss: 0.16069866716861725
val-epoch-step: 85-591 -- Loss: 0.2575765550136566
val-epoch-step: 85-592 -- Loss: 0.18154089152812958
val-epoch-step: 85-593 -- Loss: 0.19063225388526917
val-epoch-step: 85-594 -- Loss: 0.38392990827560425
val-epoch-step: 85-595 -- Loss: 0.18738818168640137
val-epoch-step: 85-596 -- Loss: 0.2438521832227707
val-epoch-step: 85-597 -- Loss: 0.17485082149505615
val-epoch-step: 85-598 -- Loss: 0.1548141986131668
val-epoch-step: 85-599 -- Loss: 0.18601256608963013
val-epoch-step: 85-600 -- Loss: 0.17315298318862915
val-epoch-step: 85-601 -- Loss: 0.15475982427597046
val-epoch-step: 85-602 -- Loss: 0.1432589292526245
val-epoch-step: 85-603 -- Loss: 0.205049067735672
val-epoch-step: 85-604 -- Loss: 0.1492232382297516
val-epoch-step: 85-605 -- Loss: 0.15113845467567444
val-epoch-step: 85-606 -- Loss: 0.2794741690158844
val-epoch-step: 85-607 -- Loss: 0.15232381224632263
val-epoch-step: 85-608 -- Loss: 0.2595072388648987
val-epoch-step: 85-609 -- Loss: 0.16857215762138367
val-epoch-step: 85-610 -- Loss: 0.187680184841156
val-epoch-step: 85-611 -- Loss: 0.19386208057403564
val-epoch-step: 85-612 -- Loss: 0.40570586919784546
val-epoch-step: 85-613 -- Loss: 0.1872270703315735
val-epoch-step: 85-614 -- Loss: 0.17302164435386658
val-epoch-step: 85-615 -- Loss: 0.18084552884101868
val-epoch-step: 85-616 -- Loss: 0.14283761382102966
val-epoch-step: 85-617 -- Loss: 0.2086937427520752
val-epoch-step: 85-618 -- Loss: 0.2682913541793823
val-epoch-step: 85-619 -- Loss: 0.22802239656448364
val-epoch-step: 85-620 -- Loss: 0.1360379457473755
val-epoch-step: 85-621 -- Loss: 0.12544094026088715
val-epoch-step: 85-622 -- Loss: 0.15434367954730988
val-epoch-step: 85-623 -- Loss: 0.14880071580410004
val-epoch-step: 85-624 -- Loss: 0.14068548381328583
val-epoch-step: 85-625 -- Loss: 0.1628829538822174
val-epoch-step: 85-626 -- Loss: 0.14960066974163055
val-epoch-step: 85-627 -- Loss: 0.1891084760427475
val-epoch-step: 85-628 -- Loss: 0.48469704389572144
val-epoch-step: 85-629 -- Loss: 0.2640622854232788
val-epoch-step: 85-630 -- Loss: 0.34959346055984497
val-epoch-step: 85-631 -- Loss: 0.14784806966781616
val-epoch-step: 85-632 -- Loss: 0.19888809323310852
val-epoch-step: 85-633 -- Loss: 0.1567123532295227
val-epoch-step: 85-634 -- Loss: 0.1384236216545105
val-epoch-step: 85-635 -- Loss: 0.11828608810901642
val-epoch-step: 85-636 -- Loss: 0.18919812142848969
val-epoch-step: 85-637 -- Loss: 0.19114619493484497
val-epoch-step: 85-638 -- Loss: 0.15692365169525146
val-epoch-step: 85-639 -- Loss: 0.2644377648830414
val-epoch-step: 85-640 -- Loss: 0.25776559114456177
val-epoch-step: 85-641 -- Loss: 0.13947243988513947
val-epoch-step: 85-642 -- Loss: 0.20611454546451569
val-epoch-step: 85-643 -- Loss: 0.21541133522987366
val-epoch-step: 85-644 -- Loss: 0.17264404892921448
val-epoch-step: 85-645 -- Loss: 0.22664444148540497
val-epoch-step: 85-646 -- Loss: 0.13230088353157043
val-epoch-step: 85-647 -- Loss: 0.13001497089862823
val-epoch-step: 85-648 -- Loss: 0.1564655900001526
val-epoch-step: 85-649 -- Loss: 0.28844553232192993
val-epoch-step: 85-650 -- Loss: 0.2579357922077179
val-epoch-step: 85-651 -- Loss: 0.1499677151441574
val-epoch-step: 85-652 -- Loss: 0.1633484959602356
val-epoch-step: 85-653 -- Loss: 0.2034228891134262
val-epoch-step: 85-654 -- Loss: 0.10992161184549332
Epoch: 85 -- Train Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 86-0 -- Loss: 0.2294011265039444
train-epoch-step: 86-1 -- Loss: 0.1442578136920929
train-epoch-step: 86-2 -- Loss: 0.19899949431419373
train-epoch-step: 86-3 -- Loss: 0.14777298271656036
train-epoch-step: 86-4 -- Loss: 0.1713697612285614
train-epoch-step: 86-5 -- Loss: 0.19168585538864136
train-epoch-step: 86-6 -- Loss: 0.2916277050971985
train-epoch-step: 86-7 -- Loss: 0.16891786456108093
train-epoch-step: 86-8 -- Loss: 0.22064006328582764
train-epoch-step: 86-9 -- Loss: 0.22876594960689545
train-epoch-step: 86-10 -- Loss: 0.19717010855674744
train-epoch-step: 86-11 -- Loss: 0.17990314960479736
train-epoch-step: 86-12 -- Loss: 0.15137557685375214
train-epoch-step: 86-13 -- Loss: 0.18148981034755707
train-epoch-step: 86-14 -- Loss: 0.1630450189113617
train-epoch-step: 86-15 -- Loss: 0.16552934050559998
train-epoch-step: 86-16 -- Loss: 0.16576513648033142
train-epoch-step: 86-17 -- Loss: 0.2445565015077591
train-epoch-step: 86-18 -- Loss: 0.19454841315746307
train-epoch-step: 86-19 -- Loss: 0.13224303722381592
train-epoch-step: 86-20 -- Loss: 0.23760046064853668
train-epoch-step: 86-21 -- Loss: 0.2376067340373993
train-epoch-step: 86-22 -- Loss: 0.14140331745147705
train-epoch-step: 86-23 -- Loss: 0.15261590480804443
train-epoch-step: 86-24 -- Loss: 0.12742164731025696
train-epoch-step: 86-25 -- Loss: 0.2226109802722931
train-epoch-step: 86-26 -- Loss: 0.19434456527233124
train-epoch-step: 86-27 -- Loss: 0.24307028949260712
train-epoch-step: 86-28 -- Loss: 0.12454795837402344
train-epoch-step: 86-29 -- Loss: 0.2467285394668579
train-epoch-step: 86-30 -- Loss: 0.11218702793121338
train-epoch-step: 86-31 -- Loss: 0.1348307728767395
train-epoch-step: 86-32 -- Loss: 0.17387746274471283
train-epoch-step: 86-33 -- Loss: 0.27476391196250916
train-epoch-step: 86-34 -- Loss: 0.1753353327512741
train-epoch-step: 86-35 -- Loss: 0.24451741576194763
train-epoch-step: 86-36 -- Loss: 0.13909611105918884
train-epoch-step: 86-37 -- Loss: 0.139581099152565
train-epoch-step: 86-38 -- Loss: 0.17727163434028625
train-epoch-step: 86-39 -- Loss: 0.2250429391860962
train-epoch-step: 86-40 -- Loss: 0.2016901969909668
train-epoch-step: 86-41 -- Loss: 0.20910392701625824
train-epoch-step: 86-42 -- Loss: 0.15043257176876068
train-epoch-step: 86-43 -- Loss: 0.2568635940551758
train-epoch-step: 86-44 -- Loss: 0.1231694370508194
train-epoch-step: 86-45 -- Loss: 0.1214061751961708
train-epoch-step: 86-46 -- Loss: 0.17874440550804138
train-epoch-step: 86-47 -- Loss: 0.20047512650489807
train-epoch-step: 86-48 -- Loss: 0.1555861085653305
train-epoch-step: 86-49 -- Loss: 0.22851644456386566
train-epoch-step: 86-50 -- Loss: 0.11005306243896484
train-epoch-step: 86-51 -- Loss: 0.2206641286611557
train-epoch-step: 86-52 -- Loss: 0.16215455532073975
train-epoch-step: 86-53 -- Loss: 0.2087174504995346
train-epoch-step: 86-54 -- Loss: 0.2877020239830017
train-epoch-step: 86-55 -- Loss: 0.16275255382061005
train-epoch-step: 86-56 -- Loss: 0.18086884915828705
train-epoch-step: 86-57 -- Loss: 0.23363138735294342
train-epoch-step: 86-58 -- Loss: 0.285244345664978
train-epoch-step: 86-59 -- Loss: 0.24080851674079895
train-epoch-step: 86-60 -- Loss: 0.1336154192686081
train-epoch-step: 86-61 -- Loss: 0.19581495225429535
train-epoch-step: 86-62 -- Loss: 0.1853291541337967
train-epoch-step: 86-63 -- Loss: 0.13149844110012054
train-epoch-step: 86-64 -- Loss: 0.1493634581565857
train-epoch-step: 86-65 -- Loss: 0.18733267486095428
train-epoch-step: 86-66 -- Loss: 0.11490900069475174
train-epoch-step: 86-67 -- Loss: 0.12427110224962234
train-epoch-step: 86-68 -- Loss: 0.21537038683891296
train-epoch-step: 86-69 -- Loss: 0.11989352107048035
train-epoch-step: 86-70 -- Loss: 0.23998665809631348
train-epoch-step: 86-71 -- Loss: 0.25272896885871887
train-epoch-step: 86-72 -- Loss: 0.16889457404613495
train-epoch-step: 86-73 -- Loss: 0.20336681604385376
train-epoch-step: 86-74 -- Loss: 0.09448264539241791
train-epoch-step: 86-75 -- Loss: 0.12238220870494843
train-epoch-step: 86-76 -- Loss: 0.15052121877670288
train-epoch-step: 86-77 -- Loss: 0.2267812341451645
train-epoch-step: 86-78 -- Loss: 0.2607148587703705
train-epoch-step: 86-79 -- Loss: 0.20638781785964966
train-epoch-step: 86-80 -- Loss: 0.2550897002220154
train-epoch-step: 86-81 -- Loss: 0.12896239757537842
train-epoch-step: 86-82 -- Loss: 0.24378716945648193
train-epoch-step: 86-83 -- Loss: 0.17855235934257507
train-epoch-step: 86-84 -- Loss: 0.18745756149291992
train-epoch-step: 86-85 -- Loss: 0.17843887209892273
train-epoch-step: 86-86 -- Loss: 0.1169726699590683
train-epoch-step: 86-87 -- Loss: 0.21162444353103638
train-epoch-step: 86-88 -- Loss: 0.14577598869800568
train-epoch-step: 86-89 -- Loss: 0.22986876964569092
train-epoch-step: 86-90 -- Loss: 0.1872175931930542
train-epoch-step: 86-91 -- Loss: 0.24878570437431335
train-epoch-step: 86-92 -- Loss: 0.19521911442279816
train-epoch-step: 86-93 -- Loss: 0.1804600954055786
train-epoch-step: 86-94 -- Loss: 0.2178693562746048
train-epoch-step: 86-95 -- Loss: 0.1959763765335083
train-epoch-step: 86-96 -- Loss: 0.2157079577445984
train-epoch-step: 86-97 -- Loss: 0.17434532940387726
train-epoch-step: 86-98 -- Loss: 0.15314272046089172
train-epoch-step: 86-99 -- Loss: 0.18670418858528137
train-epoch-step: 86-100 -- Loss: 0.18888838589191437
train-epoch-step: 86-101 -- Loss: 0.2853556275367737
train-epoch-step: 86-102 -- Loss: 0.2231830507516861
train-epoch-step: 86-103 -- Loss: 0.1817639172077179
train-epoch-step: 86-104 -- Loss: 0.14586138725280762
train-epoch-step: 86-105 -- Loss: 0.2705230414867401
train-epoch-step: 86-106 -- Loss: 0.17262545228004456
train-epoch-step: 86-107 -- Loss: 0.19215291738510132
train-epoch-step: 86-108 -- Loss: 0.19012492895126343
train-epoch-step: 86-109 -- Loss: 0.14251700043678284
train-epoch-step: 86-110 -- Loss: 0.18222323060035706
train-epoch-step: 86-111 -- Loss: 0.18101295828819275
train-epoch-step: 86-112 -- Loss: 0.1784381866455078
train-epoch-step: 86-113 -- Loss: 0.16688284277915955
train-epoch-step: 86-114 -- Loss: 0.19418282806873322
train-epoch-step: 86-115 -- Loss: 0.15933364629745483
train-epoch-step: 86-116 -- Loss: 0.1444648802280426
train-epoch-step: 86-117 -- Loss: 0.12758789956569672
train-epoch-step: 86-118 -- Loss: 0.1925557255744934
train-epoch-step: 86-119 -- Loss: 0.1505940556526184
train-epoch-step: 86-120 -- Loss: 0.24331456422805786
train-epoch-step: 86-121 -- Loss: 0.2399328500032425
train-epoch-step: 86-122 -- Loss: 0.20982736349105835
train-epoch-step: 86-123 -- Loss: 0.19925116002559662
train-epoch-step: 86-124 -- Loss: 0.12164828926324844
train-epoch-step: 86-125 -- Loss: 0.15069790184497833
train-epoch-step: 86-126 -- Loss: 0.22785484790802002
train-epoch-step: 86-127 -- Loss: 0.1777191162109375
train-epoch-step: 86-128 -- Loss: 0.16727769374847412
train-epoch-step: 86-129 -- Loss: 0.14443263411521912
train-epoch-step: 86-130 -- Loss: 0.19382861256599426
train-epoch-step: 86-131 -- Loss: 0.13371336460113525
train-epoch-step: 86-132 -- Loss: 0.18779803812503815
train-epoch-step: 86-133 -- Loss: 0.11911678314208984
train-epoch-step: 86-134 -- Loss: 0.18590883910655975
train-epoch-step: 86-135 -- Loss: 0.13087047636508942
train-epoch-step: 86-136 -- Loss: 0.1248149573802948
train-epoch-step: 86-137 -- Loss: 0.23926089704036713
train-epoch-step: 86-138 -- Loss: 0.25013482570648193
train-epoch-step: 86-139 -- Loss: 0.12644106149673462
train-epoch-step: 86-140 -- Loss: 0.20450028777122498
train-epoch-step: 86-141 -- Loss: 0.2314811646938324
train-epoch-step: 86-142 -- Loss: 0.19697237014770508
train-epoch-step: 86-143 -- Loss: 0.17964524030685425
train-epoch-step: 86-144 -- Loss: 0.17942573130130768
train-epoch-step: 86-145 -- Loss: 0.1394520401954651
train-epoch-step: 86-146 -- Loss: 0.17668640613555908
train-epoch-step: 86-147 -- Loss: 0.1713971644639969
train-epoch-step: 86-148 -- Loss: 0.1736505776643753
train-epoch-step: 86-149 -- Loss: 0.11989466845989227
train-epoch-step: 86-150 -- Loss: 0.1845511794090271
train-epoch-step: 86-151 -- Loss: 0.18771480023860931
train-epoch-step: 86-152 -- Loss: 0.19099126756191254
train-epoch-step: 86-153 -- Loss: 0.2626280188560486
train-epoch-step: 86-154 -- Loss: 0.12693016231060028
train-epoch-step: 86-155 -- Loss: 0.13417987525463104
train-epoch-step: 86-156 -- Loss: 0.11373943835496902
train-epoch-step: 86-157 -- Loss: 0.16431653499603271
train-epoch-step: 86-158 -- Loss: 0.16068710386753082
train-epoch-step: 86-159 -- Loss: 0.18146371841430664
train-epoch-step: 86-160 -- Loss: 0.20975427329540253
train-epoch-step: 86-161 -- Loss: 0.19411975145339966
train-epoch-step: 86-162 -- Loss: 0.2050207406282425
train-epoch-step: 86-163 -- Loss: 0.18160051107406616
train-epoch-step: 86-164 -- Loss: 0.19147665798664093
train-epoch-step: 86-165 -- Loss: 0.15970531105995178
train-epoch-step: 86-166 -- Loss: 0.11793224513530731
train-epoch-step: 86-167 -- Loss: 0.11841557919979095
train-epoch-step: 86-168 -- Loss: 0.20321694016456604
train-epoch-step: 86-169 -- Loss: 0.13732808828353882
train-epoch-step: 86-170 -- Loss: 0.19990697503089905
train-epoch-step: 86-171 -- Loss: 0.14269959926605225
train-epoch-step: 86-172 -- Loss: 0.25313931703567505
train-epoch-step: 86-173 -- Loss: 0.13170698285102844
train-epoch-step: 86-174 -- Loss: 0.2394915521144867
train-epoch-step: 86-175 -- Loss: 0.18637672066688538
train-epoch-step: 86-176 -- Loss: 0.12932394444942474
train-epoch-step: 86-177 -- Loss: 0.18096113204956055
train-epoch-step: 86-178 -- Loss: 0.1800178438425064
train-epoch-step: 86-179 -- Loss: 0.15137770771980286
train-epoch-step: 86-180 -- Loss: 0.14830729365348816
train-epoch-step: 86-181 -- Loss: 0.16605593264102936
train-epoch-step: 86-182 -- Loss: 0.20078235864639282
train-epoch-step: 86-183 -- Loss: 0.2718471586704254
train-epoch-step: 86-184 -- Loss: 0.13702674210071564
train-epoch-step: 86-185 -- Loss: 0.140094593167305
train-epoch-step: 86-186 -- Loss: 0.1840253323316574
train-epoch-step: 86-187 -- Loss: 0.20337018370628357
train-epoch-step: 86-188 -- Loss: 0.16642890870571136
train-epoch-step: 86-189 -- Loss: 0.10190138965845108
train-epoch-step: 86-190 -- Loss: 0.18155957758426666
train-epoch-step: 86-191 -- Loss: 0.16318437457084656
train-epoch-step: 86-192 -- Loss: 0.2234845906496048
train-epoch-step: 86-193 -- Loss: 0.20752672851085663
train-epoch-step: 86-194 -- Loss: 0.1796383410692215
train-epoch-step: 86-195 -- Loss: 0.15949973464012146
train-epoch-step: 86-196 -- Loss: 0.1636124700307846
train-epoch-step: 86-197 -- Loss: 0.13469073176383972
train-epoch-step: 86-198 -- Loss: 0.1260257363319397
train-epoch-step: 86-199 -- Loss: 0.14278775453567505
train-epoch-step: 86-200 -- Loss: 0.1231711208820343
train-epoch-step: 86-201 -- Loss: 0.18356524407863617
train-epoch-step: 86-202 -- Loss: 0.13308852910995483
train-epoch-step: 86-203 -- Loss: 0.18065354228019714
train-epoch-step: 86-204 -- Loss: 0.13698628544807434
train-epoch-step: 86-205 -- Loss: 0.17739692330360413
train-epoch-step: 86-206 -- Loss: 0.1965516358613968
train-epoch-step: 86-207 -- Loss: 0.12925204634666443
train-epoch-step: 86-208 -- Loss: 0.1756903976202011
train-epoch-step: 86-209 -- Loss: 0.14420364797115326
train-epoch-step: 86-210 -- Loss: 0.13648396730422974
train-epoch-step: 86-211 -- Loss: 0.20658822357654572
train-epoch-step: 86-212 -- Loss: 0.1949237883090973
train-epoch-step: 86-213 -- Loss: 0.12546047568321228
train-epoch-step: 86-214 -- Loss: 0.14338530600070953
train-epoch-step: 86-215 -- Loss: 0.12455766648054123
train-epoch-step: 86-216 -- Loss: 0.19588424265384674
train-epoch-step: 86-217 -- Loss: 0.20674081146717072
train-epoch-step: 86-218 -- Loss: 0.1397804617881775
train-epoch-step: 86-219 -- Loss: 0.16451109945774078
train-epoch-step: 86-220 -- Loss: 0.1340053528547287
train-epoch-step: 86-221 -- Loss: 0.20058169960975647
train-epoch-step: 86-222 -- Loss: 0.11676289141178131
train-epoch-step: 86-223 -- Loss: 0.17178231477737427
train-epoch-step: 86-224 -- Loss: 0.18533603847026825
train-epoch-step: 86-225 -- Loss: 0.26531368494033813
train-epoch-step: 86-226 -- Loss: 0.20289532840251923
train-epoch-step: 86-227 -- Loss: 0.2157009243965149
train-epoch-step: 86-228 -- Loss: 0.17200052738189697
train-epoch-step: 86-229 -- Loss: 0.17530913650989532
train-epoch-step: 86-230 -- Loss: 0.16025611758232117
train-epoch-step: 86-231 -- Loss: 0.15471190214157104
train-epoch-step: 86-232 -- Loss: 0.18440458178520203
train-epoch-step: 86-233 -- Loss: 0.0826466828584671
train-epoch-step: 86-234 -- Loss: 0.1724412590265274
train-epoch-step: 86-235 -- Loss: 0.1454697847366333
train-epoch-step: 86-236 -- Loss: 0.17705748975276947
train-epoch-step: 86-237 -- Loss: 0.2261446714401245
train-epoch-step: 86-238 -- Loss: 0.15544773638248444
train-epoch-step: 86-239 -- Loss: 0.12328062206506729
train-epoch-step: 86-240 -- Loss: 0.21991920471191406
train-epoch-step: 86-241 -- Loss: 0.15024611353874207
train-epoch-step: 86-242 -- Loss: 0.21223050355911255
train-epoch-step: 86-243 -- Loss: 0.231273353099823
train-epoch-step: 86-244 -- Loss: 0.20031604170799255
train-epoch-step: 86-245 -- Loss: 0.21031597256660461
train-epoch-step: 86-246 -- Loss: 0.21364328265190125
train-epoch-step: 86-247 -- Loss: 0.20387476682662964
train-epoch-step: 86-248 -- Loss: 0.18476973474025726
train-epoch-step: 86-249 -- Loss: 0.1355389654636383
train-epoch-step: 86-250 -- Loss: 0.19300708174705505
train-epoch-step: 86-251 -- Loss: 0.10146009922027588
train-epoch-step: 86-252 -- Loss: 0.19092386960983276
train-epoch-step: 86-253 -- Loss: 0.13335998356342316
train-epoch-step: 86-254 -- Loss: 0.20895034074783325
train-epoch-step: 86-255 -- Loss: 0.13976016640663147
train-epoch-step: 86-256 -- Loss: 0.16002394258975983
train-epoch-step: 86-257 -- Loss: 0.18515461683273315
train-epoch-step: 86-258 -- Loss: 0.13816848397254944
train-epoch-step: 86-259 -- Loss: 0.13168439269065857
train-epoch-step: 86-260 -- Loss: 0.20072908699512482
train-epoch-step: 86-261 -- Loss: 0.17885173857212067
train-epoch-step: 86-262 -- Loss: 0.29212725162506104
train-epoch-step: 86-263 -- Loss: 0.20923864841461182
train-epoch-step: 86-264 -- Loss: 0.17433032393455505
train-epoch-step: 86-265 -- Loss: 0.12673169374465942
train-epoch-step: 86-266 -- Loss: 0.16053098440170288
train-epoch-step: 86-267 -- Loss: 0.13047488033771515
train-epoch-step: 86-268 -- Loss: 0.1231643557548523
train-epoch-step: 86-269 -- Loss: 0.16722798347473145
train-epoch-step: 86-270 -- Loss: 0.1161603331565857
train-epoch-step: 86-271 -- Loss: 0.15008126199245453
train-epoch-step: 86-272 -- Loss: 0.12338203191757202
train-epoch-step: 86-273 -- Loss: 0.12406697869300842
train-epoch-step: 86-274 -- Loss: 0.18081651628017426
train-epoch-step: 86-275 -- Loss: 0.19147059321403503
train-epoch-step: 86-276 -- Loss: 0.1519913524389267
train-epoch-step: 86-277 -- Loss: 0.1525002121925354
train-epoch-step: 86-278 -- Loss: 0.13715296983718872
train-epoch-step: 86-279 -- Loss: 0.14094161987304688
train-epoch-step: 86-280 -- Loss: 0.2163296788930893
train-epoch-step: 86-281 -- Loss: 0.17426306009292603
train-epoch-step: 86-282 -- Loss: 0.14267262816429138
train-epoch-step: 86-283 -- Loss: 0.11280684918165207
train-epoch-step: 86-284 -- Loss: 0.13494421541690826
train-epoch-step: 86-285 -- Loss: 0.18599650263786316
train-epoch-step: 86-286 -- Loss: 0.15341816842556
train-epoch-step: 86-287 -- Loss: 0.206536665558815
train-epoch-step: 86-288 -- Loss: 0.09273981302976608
train-epoch-step: 86-289 -- Loss: 0.11780546605587006
train-epoch-step: 86-290 -- Loss: 0.17666922509670258
train-epoch-step: 86-291 -- Loss: 0.11699135601520538
train-epoch-step: 86-292 -- Loss: 0.15408802032470703
train-epoch-step: 86-293 -- Loss: 0.1342824250459671
train-epoch-step: 86-294 -- Loss: 0.16407284140586853
train-epoch-step: 86-295 -- Loss: 0.26926717162132263
train-epoch-step: 86-296 -- Loss: 0.15564163029193878
train-epoch-step: 86-297 -- Loss: 0.1717187911272049
train-epoch-step: 86-298 -- Loss: 0.22899754345417023
train-epoch-step: 86-299 -- Loss: 0.17825430631637573
train-epoch-step: 86-300 -- Loss: 0.19328640401363373
train-epoch-step: 86-301 -- Loss: 0.2102452516555786
train-epoch-step: 86-302 -- Loss: 0.2229691743850708
train-epoch-step: 86-303 -- Loss: 0.23697756230831146
train-epoch-step: 86-304 -- Loss: 0.1371915340423584
train-epoch-step: 86-305 -- Loss: 0.1650105118751526
train-epoch-step: 86-306 -- Loss: 0.26647046208381653
train-epoch-step: 86-307 -- Loss: 0.1746959090232849
train-epoch-step: 86-308 -- Loss: 0.25484707951545715
train-epoch-step: 86-309 -- Loss: 0.15457092225551605
train-epoch-step: 86-310 -- Loss: 0.16080184280872345
train-epoch-step: 86-311 -- Loss: 0.17856107652187347
train-epoch-step: 86-312 -- Loss: 0.2124325931072235
train-epoch-step: 86-313 -- Loss: 0.10354619473218918
train-epoch-step: 86-314 -- Loss: 0.19622045755386353
train-epoch-step: 86-315 -- Loss: 0.180201455950737
train-epoch-step: 86-316 -- Loss: 0.1737428605556488
train-epoch-step: 86-317 -- Loss: 0.13462229073047638
train-epoch-step: 86-318 -- Loss: 0.17074763774871826
train-epoch-step: 86-319 -- Loss: 0.1708354949951172
train-epoch-step: 86-320 -- Loss: 0.1179272010922432
train-epoch-step: 86-321 -- Loss: 0.13604040443897247
train-epoch-step: 86-322 -- Loss: 0.21886563301086426
train-epoch-step: 86-323 -- Loss: 0.157895028591156
train-epoch-step: 86-324 -- Loss: 0.2547568380832672
train-epoch-step: 86-325 -- Loss: 0.1659468114376068
train-epoch-step: 86-326 -- Loss: 0.20380376279354095
train-epoch-step: 86-327 -- Loss: 0.20525915920734406
train-epoch-step: 86-328 -- Loss: 0.19275672733783722
train-epoch-step: 86-329 -- Loss: 0.34635892510414124
train-epoch-step: 86-330 -- Loss: 0.37042906880378723
train-epoch-step: 86-331 -- Loss: 0.2240268588066101
train-epoch-step: 86-332 -- Loss: 0.09917636215686798
train-epoch-step: 86-333 -- Loss: 0.18421383202075958
train-epoch-step: 86-334 -- Loss: 0.1570628583431244
train-epoch-step: 86-335 -- Loss: 0.17218351364135742
train-epoch-step: 86-336 -- Loss: 0.15585507452487946
train-epoch-step: 86-337 -- Loss: 0.2130754590034485
train-epoch-step: 86-338 -- Loss: 0.1586395800113678
train-epoch-step: 86-339 -- Loss: 0.1433299332857132
train-epoch-step: 86-340 -- Loss: 0.19873854517936707
train-epoch-step: 86-341 -- Loss: 0.13899481296539307
train-epoch-step: 86-342 -- Loss: 0.16242249310016632
train-epoch-step: 86-343 -- Loss: 0.15510129928588867
train-epoch-step: 86-344 -- Loss: 0.16677311062812805
train-epoch-step: 86-345 -- Loss: 0.15329958498477936
train-epoch-step: 86-346 -- Loss: 0.21011969447135925
train-epoch-step: 86-347 -- Loss: 0.15473829209804535
train-epoch-step: 86-348 -- Loss: 0.20227734744548798
train-epoch-step: 86-349 -- Loss: 0.21092939376831055
train-epoch-step: 86-350 -- Loss: 0.27774184942245483
train-epoch-step: 86-351 -- Loss: 0.18910431861877441
train-epoch-step: 86-352 -- Loss: 0.12321807444095612
train-epoch-step: 86-353 -- Loss: 0.1945149451494217
train-epoch-step: 86-354 -- Loss: 0.2853774428367615
train-epoch-step: 86-355 -- Loss: 0.11747358739376068
train-epoch-step: 86-356 -- Loss: 0.11394467949867249
train-epoch-step: 86-357 -- Loss: 0.1849452257156372
train-epoch-step: 86-358 -- Loss: 0.19081126153469086
train-epoch-step: 86-359 -- Loss: 0.14290818572044373
train-epoch-step: 86-360 -- Loss: 0.12030824273824692
train-epoch-step: 86-361 -- Loss: 0.2305460274219513
train-epoch-step: 86-362 -- Loss: 0.1693706512451172
train-epoch-step: 86-363 -- Loss: 0.10843149572610855
train-epoch-step: 86-364 -- Loss: 0.1781933754682541
train-epoch-step: 86-365 -- Loss: 0.1717545986175537
train-epoch-step: 86-366 -- Loss: 0.2024490088224411
train-epoch-step: 86-367 -- Loss: 0.22665810585021973
train-epoch-step: 86-368 -- Loss: 0.19950687885284424
train-epoch-step: 86-369 -- Loss: 0.2747018337249756
train-epoch-step: 86-370 -- Loss: 0.12406724691390991
train-epoch-step: 86-371 -- Loss: 0.1207825243473053
train-epoch-step: 86-372 -- Loss: 0.14220009744167328
train-epoch-step: 86-373 -- Loss: 0.18710315227508545
train-epoch-step: 86-374 -- Loss: 0.1547473818063736
train-epoch-step: 86-375 -- Loss: 0.26264581084251404
train-epoch-step: 86-376 -- Loss: 0.15547724068164825
train-epoch-step: 86-377 -- Loss: 0.22141358256340027
train-epoch-step: 86-378 -- Loss: 0.20562544465065002
train-epoch-step: 86-379 -- Loss: 0.11606643348932266
train-epoch-step: 86-380 -- Loss: 0.08794201910495758
train-epoch-step: 86-381 -- Loss: 0.24294424057006836
train-epoch-step: 86-382 -- Loss: 0.22816720604896545
train-epoch-step: 86-383 -- Loss: 0.16914501786231995
train-epoch-step: 86-384 -- Loss: 0.22076039016246796
train-epoch-step: 86-385 -- Loss: 0.18891796469688416
train-epoch-step: 86-386 -- Loss: 0.1983010619878769
train-epoch-step: 86-387 -- Loss: 0.19794948399066925
train-epoch-step: 86-388 -- Loss: 0.19062919914722443
train-epoch-step: 86-389 -- Loss: 0.163741797208786
train-epoch-step: 86-390 -- Loss: 0.1382438838481903
train-epoch-step: 86-391 -- Loss: 0.14729560911655426
train-epoch-step: 86-392 -- Loss: 0.18454603850841522
train-epoch-step: 86-393 -- Loss: 0.15175893902778625
train-epoch-step: 86-394 -- Loss: 0.1975104808807373
train-epoch-step: 86-395 -- Loss: 0.15366263687610626
train-epoch-step: 86-396 -- Loss: 0.12587225437164307
train-epoch-step: 86-397 -- Loss: 0.12281450629234314
train-epoch-step: 86-398 -- Loss: 0.19393381476402283
train-epoch-step: 86-399 -- Loss: 0.1735730767250061
train-epoch-step: 86-400 -- Loss: 0.2695482075214386
train-epoch-step: 86-401 -- Loss: 0.12166859209537506
train-epoch-step: 86-402 -- Loss: 0.2495705932378769
train-epoch-step: 86-403 -- Loss: 0.16042672097682953
train-epoch-step: 86-404 -- Loss: 0.1366405487060547
train-epoch-step: 86-405 -- Loss: 0.1420990228652954
train-epoch-step: 86-406 -- Loss: 0.1623326689004898
train-epoch-step: 86-407 -- Loss: 0.11097142845392227
train-epoch-step: 86-408 -- Loss: 0.16017836332321167
train-epoch-step: 86-409 -- Loss: 0.16620460152626038
train-epoch-step: 86-410 -- Loss: 0.17779254913330078
train-epoch-step: 86-411 -- Loss: 0.20339983701705933
train-epoch-step: 86-412 -- Loss: 0.1355723887681961
train-epoch-step: 86-413 -- Loss: 0.14466547966003418
train-epoch-step: 86-414 -- Loss: 0.1297779232263565
train-epoch-step: 86-415 -- Loss: 0.1352529525756836
train-epoch-step: 86-416 -- Loss: 0.2665976881980896
train-epoch-step: 86-417 -- Loss: 0.18513965606689453
train-epoch-step: 86-418 -- Loss: 0.2295188307762146
train-epoch-step: 86-419 -- Loss: 0.16468000411987305
train-epoch-step: 86-420 -- Loss: 0.15186618268489838
train-epoch-step: 86-421 -- Loss: 0.1708415448665619
train-epoch-step: 86-422 -- Loss: 0.14660269021987915
train-epoch-step: 86-423 -- Loss: 0.1654675453901291
train-epoch-step: 86-424 -- Loss: 0.1373213678598404
train-epoch-step: 86-425 -- Loss: 0.1785978376865387
train-epoch-step: 86-426 -- Loss: 0.1632869690656662
train-epoch-step: 86-427 -- Loss: 0.1172097772359848
train-epoch-step: 86-428 -- Loss: 0.196824848651886
train-epoch-step: 86-429 -- Loss: 0.1729217767715454
train-epoch-step: 86-430 -- Loss: 0.14982610940933228
train-epoch-step: 86-431 -- Loss: 0.17121373116970062
train-epoch-step: 86-432 -- Loss: 0.23953229188919067
train-epoch-step: 86-433 -- Loss: 0.13860096037387848
train-epoch-step: 86-434 -- Loss: 0.1321118026971817
train-epoch-step: 86-435 -- Loss: 0.15337009727954865
train-epoch-step: 86-436 -- Loss: 0.15557856857776642
train-epoch-step: 86-437 -- Loss: 0.13263651728630066
train-epoch-step: 86-438 -- Loss: 0.16284115612506866
train-epoch-step: 86-439 -- Loss: 0.25698548555374146
train-epoch-step: 86-440 -- Loss: 0.1306641548871994
train-epoch-step: 86-441 -- Loss: 0.19247554242610931
train-epoch-step: 86-442 -- Loss: 0.1898472011089325
train-epoch-step: 86-443 -- Loss: 0.1519724428653717
train-epoch-step: 86-444 -- Loss: 0.1679631620645523
train-epoch-step: 86-445 -- Loss: 0.17177997529506683
train-epoch-step: 86-446 -- Loss: 0.1462976336479187
train-epoch-step: 86-447 -- Loss: 0.19069230556488037
train-epoch-step: 86-448 -- Loss: 0.21867099404335022
train-epoch-step: 86-449 -- Loss: 0.18327836692333221
train-epoch-step: 86-450 -- Loss: 0.17538702487945557
train-epoch-step: 86-451 -- Loss: 0.1411282867193222
train-epoch-step: 86-452 -- Loss: 0.12619559466838837
train-epoch-step: 86-453 -- Loss: 0.09073002636432648
train-epoch-step: 86-454 -- Loss: 0.22541408240795135
train-epoch-step: 86-455 -- Loss: 0.12031903117895126
train-epoch-step: 86-456 -- Loss: 0.11695413291454315
train-epoch-step: 86-457 -- Loss: 0.21159744262695312
train-epoch-step: 86-458 -- Loss: 0.1592772901058197
train-epoch-step: 86-459 -- Loss: 0.20926246047019958
train-epoch-step: 86-460 -- Loss: 0.12304557859897614
train-epoch-step: 86-461 -- Loss: 0.14482930302619934
train-epoch-step: 86-462 -- Loss: 0.15109652280807495
train-epoch-step: 86-463 -- Loss: 0.13108281791210175
train-epoch-step: 86-464 -- Loss: 0.16025033593177795
train-epoch-step: 86-465 -- Loss: 0.23556971549987793
train-epoch-step: 86-466 -- Loss: 0.19878549873828888
train-epoch-step: 86-467 -- Loss: 0.11463645100593567
train-epoch-step: 86-468 -- Loss: 0.16095373034477234
train-epoch-step: 86-469 -- Loss: 0.19845378398895264
train-epoch-step: 86-470 -- Loss: 0.17115998268127441
train-epoch-step: 86-471 -- Loss: 0.1498774290084839
train-epoch-step: 86-472 -- Loss: 0.14931467175483704
train-epoch-step: 86-473 -- Loss: 0.149319127202034
train-epoch-step: 86-474 -- Loss: 0.12360216677188873
train-epoch-step: 86-475 -- Loss: 0.1092924103140831
train-epoch-step: 86-476 -- Loss: 0.1962830126285553
train-epoch-step: 86-477 -- Loss: 0.19234967231750488
train-epoch-step: 86-478 -- Loss: 0.18480250239372253
train-epoch-step: 86-479 -- Loss: 0.14979085326194763
train-epoch-step: 86-480 -- Loss: 0.18453910946846008
train-epoch-step: 86-481 -- Loss: 0.2833510637283325
train-epoch-step: 86-482 -- Loss: 0.24725955724716187
train-epoch-step: 86-483 -- Loss: 0.17330119013786316
train-epoch-step: 86-484 -- Loss: 0.20853742957115173
train-epoch-step: 86-485 -- Loss: 0.13212032616138458
train-epoch-step: 86-486 -- Loss: 0.2272396981716156
train-epoch-step: 86-487 -- Loss: 0.22140948474407196
train-epoch-step: 86-488 -- Loss: 0.18425767123699188
train-epoch-step: 86-489 -- Loss: 0.2224469780921936
train-epoch-step: 86-490 -- Loss: 0.13722464442253113
train-epoch-step: 86-491 -- Loss: 0.1348891407251358
train-epoch-step: 86-492 -- Loss: 0.12969888746738434
train-epoch-step: 86-493 -- Loss: 0.19032034277915955
train-epoch-step: 86-494 -- Loss: 0.23229724168777466
train-epoch-step: 86-495 -- Loss: 0.19382517039775848
train-epoch-step: 86-496 -- Loss: 0.14023718237876892
train-epoch-step: 86-497 -- Loss: 0.1840434968471527
train-epoch-step: 86-498 -- Loss: 0.14408600330352783
train-epoch-step: 86-499 -- Loss: 0.16300231218338013
train-epoch-step: 86-500 -- Loss: 0.1488676369190216
train-epoch-step: 86-501 -- Loss: 0.20921050012111664
train-epoch-step: 86-502 -- Loss: 0.15271729230880737
train-epoch-step: 86-503 -- Loss: 0.21461933851242065
train-epoch-step: 86-504 -- Loss: 0.1251874417066574
train-epoch-step: 86-505 -- Loss: 0.17219553887844086
train-epoch-step: 86-506 -- Loss: 0.11415930092334747
train-epoch-step: 86-507 -- Loss: 0.18069861829280853
train-epoch-step: 86-508 -- Loss: 0.17214561998844147
train-epoch-step: 86-509 -- Loss: 0.1636224240064621
train-epoch-step: 86-510 -- Loss: 0.13308490812778473
train-epoch-step: 86-511 -- Loss: 0.23580819368362427
train-epoch-step: 86-512 -- Loss: 0.18029619753360748
train-epoch-step: 86-513 -- Loss: 0.19711549580097198
train-epoch-step: 86-514 -- Loss: 0.1463066041469574
train-epoch-step: 86-515 -- Loss: 0.14681783318519592
train-epoch-step: 86-516 -- Loss: 0.1749139130115509
train-epoch-step: 86-517 -- Loss: 0.17336657643318176
train-epoch-step: 86-518 -- Loss: 0.13556769490242004
train-epoch-step: 86-519 -- Loss: 0.13361531496047974
train-epoch-step: 86-520 -- Loss: 0.18251267075538635
train-epoch-step: 86-521 -- Loss: 0.22214078903198242
train-epoch-step: 86-522 -- Loss: 0.1740064024925232
train-epoch-step: 86-523 -- Loss: 0.18054962158203125
train-epoch-step: 86-524 -- Loss: 0.16742555797100067
train-epoch-step: 86-525 -- Loss: 0.18836471438407898
train-epoch-step: 86-526 -- Loss: 0.13747626543045044
train-epoch-step: 86-527 -- Loss: 0.14597086608409882
train-epoch-step: 86-528 -- Loss: 0.15717583894729614
train-epoch-step: 86-529 -- Loss: 0.1537407487630844
train-epoch-step: 86-530 -- Loss: 0.16404351592063904
train-epoch-step: 86-531 -- Loss: 0.19553816318511963
train-epoch-step: 86-532 -- Loss: 0.1704803854227066
train-epoch-step: 86-533 -- Loss: 0.17140242457389832
train-epoch-step: 86-534 -- Loss: 0.12769493460655212
train-epoch-step: 86-535 -- Loss: 0.24441243708133698
train-epoch-step: 86-536 -- Loss: 0.16059377789497375
train-epoch-step: 86-537 -- Loss: 0.1628863513469696
train-epoch-step: 86-538 -- Loss: 0.10469207912683487
train-epoch-step: 86-539 -- Loss: 0.19160276651382446
train-epoch-step: 86-540 -- Loss: 0.13669346272945404
train-epoch-step: 86-541 -- Loss: 0.20688870549201965
train-epoch-step: 86-542 -- Loss: 0.2214399129152298
train-epoch-step: 86-543 -- Loss: 0.1674835979938507
train-epoch-step: 86-544 -- Loss: 0.2227342277765274
train-epoch-step: 86-545 -- Loss: 0.19665762782096863
train-epoch-step: 86-546 -- Loss: 0.2049282342195511
train-epoch-step: 86-547 -- Loss: 0.17994895577430725
train-epoch-step: 86-548 -- Loss: 0.09198196232318878
train-epoch-step: 86-549 -- Loss: 0.14870986342430115
train-epoch-step: 86-550 -- Loss: 0.19690726697444916
train-epoch-step: 86-551 -- Loss: 0.14978989958763123
train-epoch-step: 86-552 -- Loss: 0.125540092587471
train-epoch-step: 86-553 -- Loss: 0.18508867919445038
train-epoch-step: 86-554 -- Loss: 0.1914190798997879
train-epoch-step: 86-555 -- Loss: 0.20278680324554443
train-epoch-step: 86-556 -- Loss: 0.14098775386810303
train-epoch-step: 86-557 -- Loss: 0.2255186140537262
train-epoch-step: 86-558 -- Loss: 0.22152447700500488
train-epoch-step: 86-559 -- Loss: 0.13587062060832977
train-epoch-step: 86-560 -- Loss: 0.20105504989624023
train-epoch-step: 86-561 -- Loss: 0.1756383329629898
train-epoch-step: 86-562 -- Loss: 0.16209301352500916
train-epoch-step: 86-563 -- Loss: 0.1821316033601761
train-epoch-step: 86-564 -- Loss: 0.09804011136293411
train-epoch-step: 86-565 -- Loss: 0.18397358059883118
train-epoch-step: 86-566 -- Loss: 0.14610739052295685
train-epoch-step: 86-567 -- Loss: 0.21156993508338928
train-epoch-step: 86-568 -- Loss: 0.15469856560230255
train-epoch-step: 86-569 -- Loss: 0.23562027513980865
train-epoch-step: 86-570 -- Loss: 0.16326233744621277
train-epoch-step: 86-571 -- Loss: 0.20340101420879364
train-epoch-step: 86-572 -- Loss: 0.23457539081573486
train-epoch-step: 86-573 -- Loss: 0.19542327523231506
train-epoch-step: 86-574 -- Loss: 0.23583845794200897
train-epoch-step: 86-575 -- Loss: 0.29635608196258545
train-epoch-step: 86-576 -- Loss: 0.11647312343120575
train-epoch-step: 86-577 -- Loss: 0.16339607536792755
train-epoch-step: 86-578 -- Loss: 0.2142922282218933
train-epoch-step: 86-579 -- Loss: 0.16527317464351654
train-epoch-step: 86-580 -- Loss: 0.1671237051486969
train-epoch-step: 86-581 -- Loss: 0.14066092669963837
train-epoch-step: 86-582 -- Loss: 0.20113857090473175
train-epoch-step: 86-583 -- Loss: 0.21126185357570648
train-epoch-step: 86-584 -- Loss: 0.1577586978673935
train-epoch-step: 86-585 -- Loss: 0.18868614733219147
train-epoch-step: 86-586 -- Loss: 0.2547733783721924
train-epoch-step: 86-587 -- Loss: 0.155666783452034
train-epoch-step: 86-588 -- Loss: 0.12726439535617828
val-epoch-step: 86-589 -- Loss: 0.21177011728286743
val-epoch-step: 86-590 -- Loss: 0.14962148666381836
val-epoch-step: 86-591 -- Loss: 0.2420378029346466
val-epoch-step: 86-592 -- Loss: 0.16964854300022125
val-epoch-step: 86-593 -- Loss: 0.1571960151195526
val-epoch-step: 86-594 -- Loss: 0.31806284189224243
val-epoch-step: 86-595 -- Loss: 0.1834835708141327
val-epoch-step: 86-596 -- Loss: 0.1899242401123047
val-epoch-step: 86-597 -- Loss: 0.16754500567913055
val-epoch-step: 86-598 -- Loss: 0.14563211798667908
val-epoch-step: 86-599 -- Loss: 0.177132248878479
val-epoch-step: 86-600 -- Loss: 0.16778898239135742
val-epoch-step: 86-601 -- Loss: 0.151719868183136
val-epoch-step: 86-602 -- Loss: 0.13482697308063507
val-epoch-step: 86-603 -- Loss: 0.19531075656414032
val-epoch-step: 86-604 -- Loss: 0.15026068687438965
val-epoch-step: 86-605 -- Loss: 0.14531101286411285
val-epoch-step: 86-606 -- Loss: 0.29340535402297974
val-epoch-step: 86-607 -- Loss: 0.12317393720149994
val-epoch-step: 86-608 -- Loss: 0.2467573881149292
val-epoch-step: 86-609 -- Loss: 0.1736944019794464
val-epoch-step: 86-610 -- Loss: 0.17711322009563446
val-epoch-step: 86-611 -- Loss: 0.15719056129455566
val-epoch-step: 86-612 -- Loss: 0.35303282737731934
val-epoch-step: 86-613 -- Loss: 0.17086587846279144
val-epoch-step: 86-614 -- Loss: 0.17261384427547455
val-epoch-step: 86-615 -- Loss: 0.16852760314941406
val-epoch-step: 86-616 -- Loss: 0.15694427490234375
val-epoch-step: 86-617 -- Loss: 0.1919277012348175
val-epoch-step: 86-618 -- Loss: 0.17432188987731934
val-epoch-step: 86-619 -- Loss: 0.19877897202968597
val-epoch-step: 86-620 -- Loss: 0.12770801782608032
val-epoch-step: 86-621 -- Loss: 0.1224728524684906
val-epoch-step: 86-622 -- Loss: 0.14374136924743652
val-epoch-step: 86-623 -- Loss: 0.14470112323760986
val-epoch-step: 86-624 -- Loss: 0.13724274933338165
val-epoch-step: 86-625 -- Loss: 0.15425461530685425
val-epoch-step: 86-626 -- Loss: 0.147696852684021
val-epoch-step: 86-627 -- Loss: 0.18450330197811127
val-epoch-step: 86-628 -- Loss: 0.4716193675994873
val-epoch-step: 86-629 -- Loss: 0.19136784970760345
val-epoch-step: 86-630 -- Loss: 0.33738401532173157
val-epoch-step: 86-631 -- Loss: 0.14114248752593994
val-epoch-step: 86-632 -- Loss: 0.19929541647434235
val-epoch-step: 86-633 -- Loss: 0.15497350692749023
val-epoch-step: 86-634 -- Loss: 0.13745228946208954
val-epoch-step: 86-635 -- Loss: 0.11598348617553711
val-epoch-step: 86-636 -- Loss: 0.16035136580467224
val-epoch-step: 86-637 -- Loss: 0.18700075149536133
val-epoch-step: 86-638 -- Loss: 0.1452760398387909
val-epoch-step: 86-639 -- Loss: 0.2578077018260956
val-epoch-step: 86-640 -- Loss: 0.24733440577983856
val-epoch-step: 86-641 -- Loss: 0.12392507493495941
val-epoch-step: 86-642 -- Loss: 0.17410272359848022
val-epoch-step: 86-643 -- Loss: 0.2025478631258011
val-epoch-step: 86-644 -- Loss: 0.16469278931617737
val-epoch-step: 86-645 -- Loss: 0.21203771233558655
val-epoch-step: 86-646 -- Loss: 0.12552501261234283
val-epoch-step: 86-647 -- Loss: 0.12953907251358032
val-epoch-step: 86-648 -- Loss: 0.14745426177978516
val-epoch-step: 86-649 -- Loss: 0.20321649312973022
val-epoch-step: 86-650 -- Loss: 0.24652943015098572
val-epoch-step: 86-651 -- Loss: 0.13916589319705963
val-epoch-step: 86-652 -- Loss: 0.15085777640342712
val-epoch-step: 86-653 -- Loss: 0.20606274902820587
val-epoch-step: 86-654 -- Loss: 0.11702540516853333
Epoch: 86 -- Train Loss: tensor(0.1403, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 87-0 -- Loss: 0.21323363482952118
train-epoch-step: 87-1 -- Loss: 0.1397043615579605
train-epoch-step: 87-2 -- Loss: 0.19399532675743103
train-epoch-step: 87-3 -- Loss: 0.14088237285614014
train-epoch-step: 87-4 -- Loss: 0.15450899302959442
train-epoch-step: 87-5 -- Loss: 0.1777113974094391
train-epoch-step: 87-6 -- Loss: 0.21514427661895752
train-epoch-step: 87-7 -- Loss: 0.1614527404308319
train-epoch-step: 87-8 -- Loss: 0.17254939675331116
train-epoch-step: 87-9 -- Loss: 0.22158801555633545
train-epoch-step: 87-10 -- Loss: 0.23508533835411072
train-epoch-step: 87-11 -- Loss: 0.1750606745481491
train-epoch-step: 87-12 -- Loss: 0.14553102850914001
train-epoch-step: 87-13 -- Loss: 0.18750646710395813
train-epoch-step: 87-14 -- Loss: 0.16364142298698425
train-epoch-step: 87-15 -- Loss: 0.15537287294864655
train-epoch-step: 87-16 -- Loss: 0.17459437251091003
train-epoch-step: 87-17 -- Loss: 0.23932993412017822
train-epoch-step: 87-18 -- Loss: 0.20113855600357056
train-epoch-step: 87-19 -- Loss: 0.13190068304538727
train-epoch-step: 87-20 -- Loss: 0.23326674103736877
train-epoch-step: 87-21 -- Loss: 0.2465778887271881
train-epoch-step: 87-22 -- Loss: 0.1376761645078659
train-epoch-step: 87-23 -- Loss: 0.14266158640384674
train-epoch-step: 87-24 -- Loss: 0.12108799815177917
train-epoch-step: 87-25 -- Loss: 0.2419866919517517
train-epoch-step: 87-26 -- Loss: 0.24590802192687988
train-epoch-step: 87-27 -- Loss: 0.22647282481193542
train-epoch-step: 87-28 -- Loss: 0.12258399277925491
train-epoch-step: 87-29 -- Loss: 0.24745608866214752
train-epoch-step: 87-30 -- Loss: 0.10964785516262054
train-epoch-step: 87-31 -- Loss: 0.14041191339492798
train-epoch-step: 87-32 -- Loss: 0.17462489008903503
train-epoch-step: 87-33 -- Loss: 0.27163267135620117
train-epoch-step: 87-34 -- Loss: 0.18170778453350067
train-epoch-step: 87-35 -- Loss: 0.2513279318809509
train-epoch-step: 87-36 -- Loss: 0.14540515840053558
train-epoch-step: 87-37 -- Loss: 0.13880585134029388
train-epoch-step: 87-38 -- Loss: 0.17249345779418945
train-epoch-step: 87-39 -- Loss: 0.22717270255088806
train-epoch-step: 87-40 -- Loss: 0.19768624007701874
train-epoch-step: 87-41 -- Loss: 0.21573621034622192
train-epoch-step: 87-42 -- Loss: 0.1477895826101303
train-epoch-step: 87-43 -- Loss: 0.2569279074668884
train-epoch-step: 87-44 -- Loss: 0.12089988589286804
train-epoch-step: 87-45 -- Loss: 0.12362275272607803
train-epoch-step: 87-46 -- Loss: 0.17385157942771912
train-epoch-step: 87-47 -- Loss: 0.20776575803756714
train-epoch-step: 87-48 -- Loss: 0.15186505019664764
train-epoch-step: 87-49 -- Loss: 0.225529283285141
train-epoch-step: 87-50 -- Loss: 0.10893233120441437
train-epoch-step: 87-51 -- Loss: 0.18065515160560608
train-epoch-step: 87-52 -- Loss: 0.1546613574028015
train-epoch-step: 87-53 -- Loss: 0.21064159274101257
train-epoch-step: 87-54 -- Loss: 0.2856203615665436
train-epoch-step: 87-55 -- Loss: 0.16574783623218536
train-epoch-step: 87-56 -- Loss: 0.1742604672908783
train-epoch-step: 87-57 -- Loss: 0.23176929354667664
train-epoch-step: 87-58 -- Loss: 0.27704888582229614
train-epoch-step: 87-59 -- Loss: 0.2501126527786255
train-epoch-step: 87-60 -- Loss: 0.12798908352851868
train-epoch-step: 87-61 -- Loss: 0.19932447373867035
train-epoch-step: 87-62 -- Loss: 0.1802079826593399
train-epoch-step: 87-63 -- Loss: 0.12961964309215546
train-epoch-step: 87-64 -- Loss: 0.14240457117557526
train-epoch-step: 87-65 -- Loss: 0.1808788925409317
train-epoch-step: 87-66 -- Loss: 0.10562750697135925
train-epoch-step: 87-67 -- Loss: 0.12079430371522903
train-epoch-step: 87-68 -- Loss: 0.2165607064962387
train-epoch-step: 87-69 -- Loss: 0.12503796815872192
train-epoch-step: 87-70 -- Loss: 0.2195742279291153
train-epoch-step: 87-71 -- Loss: 0.25231701135635376
train-epoch-step: 87-72 -- Loss: 0.16996684670448303
train-epoch-step: 87-73 -- Loss: 0.20761916041374207
train-epoch-step: 87-74 -- Loss: 0.094440758228302
train-epoch-step: 87-75 -- Loss: 0.12210623919963837
train-epoch-step: 87-76 -- Loss: 0.14401128888130188
train-epoch-step: 87-77 -- Loss: 0.2241845577955246
train-epoch-step: 87-78 -- Loss: 0.2541521489620209
train-epoch-step: 87-79 -- Loss: 0.18864665925502777
train-epoch-step: 87-80 -- Loss: 0.24910029768943787
train-epoch-step: 87-81 -- Loss: 0.1223892793059349
train-epoch-step: 87-82 -- Loss: 0.23866063356399536
train-epoch-step: 87-83 -- Loss: 0.1724744439125061
train-epoch-step: 87-84 -- Loss: 0.18137523531913757
train-epoch-step: 87-85 -- Loss: 0.16901364922523499
train-epoch-step: 87-86 -- Loss: 0.11854385584592819
train-epoch-step: 87-87 -- Loss: 0.21028703451156616
train-epoch-step: 87-88 -- Loss: 0.1377437561750412
train-epoch-step: 87-89 -- Loss: 0.17914019525051117
train-epoch-step: 87-90 -- Loss: 0.1860884726047516
train-epoch-step: 87-91 -- Loss: 0.24375271797180176
train-epoch-step: 87-92 -- Loss: 0.15052220225334167
train-epoch-step: 87-93 -- Loss: 0.1717684268951416
train-epoch-step: 87-94 -- Loss: 0.226374089717865
train-epoch-step: 87-95 -- Loss: 0.1820075511932373
train-epoch-step: 87-96 -- Loss: 0.2089926302433014
train-epoch-step: 87-97 -- Loss: 0.1790056675672531
train-epoch-step: 87-98 -- Loss: 0.1529281735420227
train-epoch-step: 87-99 -- Loss: 0.18202990293502808
train-epoch-step: 87-100 -- Loss: 0.18339921534061432
train-epoch-step: 87-101 -- Loss: 0.25702494382858276
train-epoch-step: 87-102 -- Loss: 0.21487683057785034
train-epoch-step: 87-103 -- Loss: 0.18125325441360474
train-epoch-step: 87-104 -- Loss: 0.14520730078220367
train-epoch-step: 87-105 -- Loss: 0.26477208733558655
train-epoch-step: 87-106 -- Loss: 0.17180892825126648
train-epoch-step: 87-107 -- Loss: 0.18479575216770172
train-epoch-step: 87-108 -- Loss: 0.18562330305576324
train-epoch-step: 87-109 -- Loss: 0.14293597638607025
train-epoch-step: 87-110 -- Loss: 0.17651593685150146
train-epoch-step: 87-111 -- Loss: 0.17799997329711914
train-epoch-step: 87-112 -- Loss: 0.1656501442193985
train-epoch-step: 87-113 -- Loss: 0.1610035002231598
train-epoch-step: 87-114 -- Loss: 0.19323842227458954
train-epoch-step: 87-115 -- Loss: 0.15668421983718872
train-epoch-step: 87-116 -- Loss: 0.1432126760482788
train-epoch-step: 87-117 -- Loss: 0.12878072261810303
train-epoch-step: 87-118 -- Loss: 0.1927562654018402
train-epoch-step: 87-119 -- Loss: 0.14778871834278107
train-epoch-step: 87-120 -- Loss: 0.24057143926620483
train-epoch-step: 87-121 -- Loss: 0.23398877680301666
train-epoch-step: 87-122 -- Loss: 0.21591244637966156
train-epoch-step: 87-123 -- Loss: 0.19734278321266174
train-epoch-step: 87-124 -- Loss: 0.11999869346618652
train-epoch-step: 87-125 -- Loss: 0.15337210893630981
train-epoch-step: 87-126 -- Loss: 0.21946589648723602
train-epoch-step: 87-127 -- Loss: 0.17460855841636658
train-epoch-step: 87-128 -- Loss: 0.17188413441181183
train-epoch-step: 87-129 -- Loss: 0.14192043244838715
train-epoch-step: 87-130 -- Loss: 0.19595490396022797
train-epoch-step: 87-131 -- Loss: 0.13407015800476074
train-epoch-step: 87-132 -- Loss: 0.18436092138290405
train-epoch-step: 87-133 -- Loss: 0.11491002887487411
train-epoch-step: 87-134 -- Loss: 0.18875586986541748
train-epoch-step: 87-135 -- Loss: 0.13030816614627838
train-epoch-step: 87-136 -- Loss: 0.12433700263500214
train-epoch-step: 87-137 -- Loss: 0.2340066283941269
train-epoch-step: 87-138 -- Loss: 0.254278302192688
train-epoch-step: 87-139 -- Loss: 0.1254327893257141
train-epoch-step: 87-140 -- Loss: 0.2026943564414978
train-epoch-step: 87-141 -- Loss: 0.22277316451072693
train-epoch-step: 87-142 -- Loss: 0.20690928399562836
train-epoch-step: 87-143 -- Loss: 0.17184609174728394
train-epoch-step: 87-144 -- Loss: 0.17392189800739288
train-epoch-step: 87-145 -- Loss: 0.15320830047130585
train-epoch-step: 87-146 -- Loss: 0.17484983801841736
train-epoch-step: 87-147 -- Loss: 0.16740432381629944
train-epoch-step: 87-148 -- Loss: 0.16029025614261627
train-epoch-step: 87-149 -- Loss: 0.11836078763008118
train-epoch-step: 87-150 -- Loss: 0.1811898797750473
train-epoch-step: 87-151 -- Loss: 0.18232980370521545
train-epoch-step: 87-152 -- Loss: 0.19018539786338806
train-epoch-step: 87-153 -- Loss: 0.2520309090614319
train-epoch-step: 87-154 -- Loss: 0.12608389556407928
train-epoch-step: 87-155 -- Loss: 0.13529035449028015
train-epoch-step: 87-156 -- Loss: 0.1219889372587204
train-epoch-step: 87-157 -- Loss: 0.16151855885982513
train-epoch-step: 87-158 -- Loss: 0.16585157811641693
train-epoch-step: 87-159 -- Loss: 0.17902937531471252
train-epoch-step: 87-160 -- Loss: 0.2177354097366333
train-epoch-step: 87-161 -- Loss: 0.19813916087150574
train-epoch-step: 87-162 -- Loss: 0.20856264233589172
train-epoch-step: 87-163 -- Loss: 0.1904906928539276
train-epoch-step: 87-164 -- Loss: 0.19480983912944794
train-epoch-step: 87-165 -- Loss: 0.1592986136674881
train-epoch-step: 87-166 -- Loss: 0.1169123500585556
train-epoch-step: 87-167 -- Loss: 0.1204226091504097
train-epoch-step: 87-168 -- Loss: 0.20359721779823303
train-epoch-step: 87-169 -- Loss: 0.13426998257637024
train-epoch-step: 87-170 -- Loss: 0.19612301886081696
train-epoch-step: 87-171 -- Loss: 0.1407282054424286
train-epoch-step: 87-172 -- Loss: 0.2525380849838257
train-epoch-step: 87-173 -- Loss: 0.123987577855587
train-epoch-step: 87-174 -- Loss: 0.24412140250205994
train-epoch-step: 87-175 -- Loss: 0.18617096543312073
train-epoch-step: 87-176 -- Loss: 0.1288624107837677
train-epoch-step: 87-177 -- Loss: 0.1788870394229889
train-epoch-step: 87-178 -- Loss: 0.17535650730133057
train-epoch-step: 87-179 -- Loss: 0.16382533311843872
train-epoch-step: 87-180 -- Loss: 0.1508273482322693
train-epoch-step: 87-181 -- Loss: 0.17553077638149261
train-epoch-step: 87-182 -- Loss: 0.18376995623111725
train-epoch-step: 87-183 -- Loss: 0.27661964297294617
train-epoch-step: 87-184 -- Loss: 0.13827677071094513
train-epoch-step: 87-185 -- Loss: 0.1391199827194214
train-epoch-step: 87-186 -- Loss: 0.1899416446685791
train-epoch-step: 87-187 -- Loss: 0.20724833011627197
train-epoch-step: 87-188 -- Loss: 0.1689523458480835
train-epoch-step: 87-189 -- Loss: 0.11087757349014282
train-epoch-step: 87-190 -- Loss: 0.17819711565971375
train-epoch-step: 87-191 -- Loss: 0.15376342833042145
train-epoch-step: 87-192 -- Loss: 0.2259816825389862
train-epoch-step: 87-193 -- Loss: 0.2089555859565735
train-epoch-step: 87-194 -- Loss: 0.18255050480365753
train-epoch-step: 87-195 -- Loss: 0.15853258967399597
train-epoch-step: 87-196 -- Loss: 0.16178233921527863
train-epoch-step: 87-197 -- Loss: 0.12517425417900085
train-epoch-step: 87-198 -- Loss: 0.1344860941171646
train-epoch-step: 87-199 -- Loss: 0.14799338579177856
train-epoch-step: 87-200 -- Loss: 0.12196771055459976
train-epoch-step: 87-201 -- Loss: 0.18799671530723572
train-epoch-step: 87-202 -- Loss: 0.1356753259897232
train-epoch-step: 87-203 -- Loss: 0.17256028950214386
train-epoch-step: 87-204 -- Loss: 0.13284064829349518
train-epoch-step: 87-205 -- Loss: 0.1784689724445343
train-epoch-step: 87-206 -- Loss: 0.20735374093055725
train-epoch-step: 87-207 -- Loss: 0.13519352674484253
train-epoch-step: 87-208 -- Loss: 0.1779610514640808
train-epoch-step: 87-209 -- Loss: 0.141426220536232
train-epoch-step: 87-210 -- Loss: 0.1358102262020111
train-epoch-step: 87-211 -- Loss: 0.21437250077724457
train-epoch-step: 87-212 -- Loss: 0.20230576395988464
train-epoch-step: 87-213 -- Loss: 0.129272922873497
train-epoch-step: 87-214 -- Loss: 0.14297962188720703
train-epoch-step: 87-215 -- Loss: 0.12434121966362
train-epoch-step: 87-216 -- Loss: 0.18938620388507843
train-epoch-step: 87-217 -- Loss: 0.20510618388652802
train-epoch-step: 87-218 -- Loss: 0.14951598644256592
train-epoch-step: 87-219 -- Loss: 0.17438344657421112
train-epoch-step: 87-220 -- Loss: 0.12373463064432144
train-epoch-step: 87-221 -- Loss: 0.20375333726406097
train-epoch-step: 87-222 -- Loss: 0.1150449737906456
train-epoch-step: 87-223 -- Loss: 0.17573539912700653
train-epoch-step: 87-224 -- Loss: 0.2036745846271515
train-epoch-step: 87-225 -- Loss: 0.2666996121406555
train-epoch-step: 87-226 -- Loss: 0.21539489924907684
train-epoch-step: 87-227 -- Loss: 0.23595987260341644
train-epoch-step: 87-228 -- Loss: 0.17590604722499847
train-epoch-step: 87-229 -- Loss: 0.18324369192123413
train-epoch-step: 87-230 -- Loss: 0.1708308458328247
train-epoch-step: 87-231 -- Loss: 0.15314267575740814
train-epoch-step: 87-232 -- Loss: 0.1847790777683258
train-epoch-step: 87-233 -- Loss: 0.0837506353855133
train-epoch-step: 87-234 -- Loss: 0.19312995672225952
train-epoch-step: 87-235 -- Loss: 0.14343413710594177
train-epoch-step: 87-236 -- Loss: 0.17630288004875183
train-epoch-step: 87-237 -- Loss: 0.22961708903312683
train-epoch-step: 87-238 -- Loss: 0.1579347848892212
train-epoch-step: 87-239 -- Loss: 0.12627321481704712
train-epoch-step: 87-240 -- Loss: 0.22510987520217896
train-epoch-step: 87-241 -- Loss: 0.15624092519283295
train-epoch-step: 87-242 -- Loss: 0.2179790735244751
train-epoch-step: 87-243 -- Loss: 0.23935872316360474
train-epoch-step: 87-244 -- Loss: 0.2041899859905243
train-epoch-step: 87-245 -- Loss: 0.2122463583946228
train-epoch-step: 87-246 -- Loss: 0.2416391223669052
train-epoch-step: 87-247 -- Loss: 0.22798433899879456
train-epoch-step: 87-248 -- Loss: 0.18331165611743927
train-epoch-step: 87-249 -- Loss: 0.13675501942634583
train-epoch-step: 87-250 -- Loss: 0.20502969622612
train-epoch-step: 87-251 -- Loss: 0.1043889969587326
train-epoch-step: 87-252 -- Loss: 0.2280604988336563
train-epoch-step: 87-253 -- Loss: 0.14299607276916504
train-epoch-step: 87-254 -- Loss: 0.2374023199081421
train-epoch-step: 87-255 -- Loss: 0.16855214536190033
train-epoch-step: 87-256 -- Loss: 0.19905845820903778
train-epoch-step: 87-257 -- Loss: 0.21618619561195374
train-epoch-step: 87-258 -- Loss: 0.14724348485469818
train-epoch-step: 87-259 -- Loss: 0.12827524542808533
train-epoch-step: 87-260 -- Loss: 0.21595105528831482
train-epoch-step: 87-261 -- Loss: 0.1807314157485962
train-epoch-step: 87-262 -- Loss: 0.2923666834831238
train-epoch-step: 87-263 -- Loss: 0.2145683914422989
train-epoch-step: 87-264 -- Loss: 0.17229683697223663
train-epoch-step: 87-265 -- Loss: 0.13075679540634155
train-epoch-step: 87-266 -- Loss: 0.1541868895292282
train-epoch-step: 87-267 -- Loss: 0.1355084329843521
train-epoch-step: 87-268 -- Loss: 0.11756709963083267
train-epoch-step: 87-269 -- Loss: 0.23176375031471252
train-epoch-step: 87-270 -- Loss: 0.10884455591440201
train-epoch-step: 87-271 -- Loss: 0.15752655267715454
train-epoch-step: 87-272 -- Loss: 0.11866097897291183
train-epoch-step: 87-273 -- Loss: 0.12971459329128265
train-epoch-step: 87-274 -- Loss: 0.19074171781539917
train-epoch-step: 87-275 -- Loss: 0.19433647394180298
train-epoch-step: 87-276 -- Loss: 0.15900357067584991
train-epoch-step: 87-277 -- Loss: 0.155878946185112
train-epoch-step: 87-278 -- Loss: 0.14491420984268188
train-epoch-step: 87-279 -- Loss: 0.1427766978740692
train-epoch-step: 87-280 -- Loss: 0.21214236319065094
train-epoch-step: 87-281 -- Loss: 0.18542948365211487
train-epoch-step: 87-282 -- Loss: 0.14613717794418335
train-epoch-step: 87-283 -- Loss: 0.11347628384828568
train-epoch-step: 87-284 -- Loss: 0.14600512385368347
train-epoch-step: 87-285 -- Loss: 0.21055033802986145
train-epoch-step: 87-286 -- Loss: 0.15366233885288239
train-epoch-step: 87-287 -- Loss: 0.21435068547725677
train-epoch-step: 87-288 -- Loss: 0.09405606240034103
train-epoch-step: 87-289 -- Loss: 0.11762281507253647
train-epoch-step: 87-290 -- Loss: 0.17901873588562012
train-epoch-step: 87-291 -- Loss: 0.11802776902914047
train-epoch-step: 87-292 -- Loss: 0.15759192407131195
train-epoch-step: 87-293 -- Loss: 0.13778828084468842
train-epoch-step: 87-294 -- Loss: 0.16235724091529846
train-epoch-step: 87-295 -- Loss: 0.2591225206851959
train-epoch-step: 87-296 -- Loss: 0.15854927897453308
train-epoch-step: 87-297 -- Loss: 0.16944600641727448
train-epoch-step: 87-298 -- Loss: 0.23233628273010254
train-epoch-step: 87-299 -- Loss: 0.14186741411685944
train-epoch-step: 87-300 -- Loss: 0.16527138650417328
train-epoch-step: 87-301 -- Loss: 0.18755264580249786
train-epoch-step: 87-302 -- Loss: 0.22305266559123993
train-epoch-step: 87-303 -- Loss: 0.20002271234989166
train-epoch-step: 87-304 -- Loss: 0.12581709027290344
train-epoch-step: 87-305 -- Loss: 0.13956019282341003
train-epoch-step: 87-306 -- Loss: 0.22064891457557678
train-epoch-step: 87-307 -- Loss: 0.1692034900188446
train-epoch-step: 87-308 -- Loss: 0.22240716218948364
train-epoch-step: 87-309 -- Loss: 0.14886468648910522
train-epoch-step: 87-310 -- Loss: 0.1632499396800995
train-epoch-step: 87-311 -- Loss: 0.15604625642299652
train-epoch-step: 87-312 -- Loss: 0.20344802737236023
train-epoch-step: 87-313 -- Loss: 0.10216300934553146
train-epoch-step: 87-314 -- Loss: 0.20152191817760468
train-epoch-step: 87-315 -- Loss: 0.16769853234291077
train-epoch-step: 87-316 -- Loss: 0.15531864762306213
train-epoch-step: 87-317 -- Loss: 0.13670802116394043
train-epoch-step: 87-318 -- Loss: 0.1685788929462433
train-epoch-step: 87-319 -- Loss: 0.17095644772052765
train-epoch-step: 87-320 -- Loss: 0.11423572897911072
train-epoch-step: 87-321 -- Loss: 0.1291733980178833
train-epoch-step: 87-322 -- Loss: 0.21272477507591248
train-epoch-step: 87-323 -- Loss: 0.16076254844665527
train-epoch-step: 87-324 -- Loss: 0.24829716980457306
train-epoch-step: 87-325 -- Loss: 0.1545405387878418
train-epoch-step: 87-326 -- Loss: 0.1729675829410553
train-epoch-step: 87-327 -- Loss: 0.20390720665454865
train-epoch-step: 87-328 -- Loss: 0.19098562002182007
train-epoch-step: 87-329 -- Loss: 0.34026360511779785
train-epoch-step: 87-330 -- Loss: 0.3578672409057617
train-epoch-step: 87-331 -- Loss: 0.20264391601085663
train-epoch-step: 87-332 -- Loss: 0.09603741019964218
train-epoch-step: 87-333 -- Loss: 0.1819460391998291
train-epoch-step: 87-334 -- Loss: 0.1484174132347107
train-epoch-step: 87-335 -- Loss: 0.17096497118473053
train-epoch-step: 87-336 -- Loss: 0.1489039659500122
train-epoch-step: 87-337 -- Loss: 0.20066200196743011
train-epoch-step: 87-338 -- Loss: 0.15437839925289154
train-epoch-step: 87-339 -- Loss: 0.14031676948070526
train-epoch-step: 87-340 -- Loss: 0.19631867110729218
train-epoch-step: 87-341 -- Loss: 0.13807696104049683
train-epoch-step: 87-342 -- Loss: 0.15865153074264526
train-epoch-step: 87-343 -- Loss: 0.15327219665050507
train-epoch-step: 87-344 -- Loss: 0.164539635181427
train-epoch-step: 87-345 -- Loss: 0.15992741286754608
train-epoch-step: 87-346 -- Loss: 0.20549936592578888
train-epoch-step: 87-347 -- Loss: 0.1483619660139084
train-epoch-step: 87-348 -- Loss: 0.19823870062828064
train-epoch-step: 87-349 -- Loss: 0.19879743456840515
train-epoch-step: 87-350 -- Loss: 0.25178277492523193
train-epoch-step: 87-351 -- Loss: 0.18626868724822998
train-epoch-step: 87-352 -- Loss: 0.12126946449279785
train-epoch-step: 87-353 -- Loss: 0.18842443823814392
train-epoch-step: 87-354 -- Loss: 0.27632230520248413
train-epoch-step: 87-355 -- Loss: 0.11745526641607285
train-epoch-step: 87-356 -- Loss: 0.11462640762329102
train-epoch-step: 87-357 -- Loss: 0.18512305617332458
train-epoch-step: 87-358 -- Loss: 0.18293187022209167
train-epoch-step: 87-359 -- Loss: 0.1486072540283203
train-epoch-step: 87-360 -- Loss: 0.12053736299276352
train-epoch-step: 87-361 -- Loss: 0.23629844188690186
train-epoch-step: 87-362 -- Loss: 0.16530759632587433
train-epoch-step: 87-363 -- Loss: 0.10821657627820969
train-epoch-step: 87-364 -- Loss: 0.17227241396903992
train-epoch-step: 87-365 -- Loss: 0.18318668007850647
train-epoch-step: 87-366 -- Loss: 0.19746167957782745
train-epoch-step: 87-367 -- Loss: 0.2312658429145813
train-epoch-step: 87-368 -- Loss: 0.20563387870788574
train-epoch-step: 87-369 -- Loss: 0.27887430787086487
train-epoch-step: 87-370 -- Loss: 0.12140430510044098
train-epoch-step: 87-371 -- Loss: 0.12015984207391739
train-epoch-step: 87-372 -- Loss: 0.1464826762676239
train-epoch-step: 87-373 -- Loss: 0.1923590451478958
train-epoch-step: 87-374 -- Loss: 0.15730522572994232
train-epoch-step: 87-375 -- Loss: 0.2656387388706207
train-epoch-step: 87-376 -- Loss: 0.16329039633274078
train-epoch-step: 87-377 -- Loss: 0.2213417887687683
train-epoch-step: 87-378 -- Loss: 0.19547629356384277
train-epoch-step: 87-379 -- Loss: 0.11842837929725647
train-epoch-step: 87-380 -- Loss: 0.09024576842784882
train-epoch-step: 87-381 -- Loss: 0.23781254887580872
train-epoch-step: 87-382 -- Loss: 0.2274457812309265
train-epoch-step: 87-383 -- Loss: 0.17352645099163055
train-epoch-step: 87-384 -- Loss: 0.21715056896209717
train-epoch-step: 87-385 -- Loss: 0.18846279382705688
train-epoch-step: 87-386 -- Loss: 0.17881877720355988
train-epoch-step: 87-387 -- Loss: 0.2031906545162201
train-epoch-step: 87-388 -- Loss: 0.17558889091014862
train-epoch-step: 87-389 -- Loss: 0.16341929137706757
train-epoch-step: 87-390 -- Loss: 0.13927918672561646
train-epoch-step: 87-391 -- Loss: 0.1440247744321823
train-epoch-step: 87-392 -- Loss: 0.1790676862001419
train-epoch-step: 87-393 -- Loss: 0.15301702916622162
train-epoch-step: 87-394 -- Loss: 0.1915425807237625
train-epoch-step: 87-395 -- Loss: 0.1560823768377304
train-epoch-step: 87-396 -- Loss: 0.12443355470895767
train-epoch-step: 87-397 -- Loss: 0.11953344941139221
train-epoch-step: 87-398 -- Loss: 0.19848167896270752
train-epoch-step: 87-399 -- Loss: 0.1709533929824829
train-epoch-step: 87-400 -- Loss: 0.27073079347610474
train-epoch-step: 87-401 -- Loss: 0.11814902722835541
train-epoch-step: 87-402 -- Loss: 0.25516778230667114
train-epoch-step: 87-403 -- Loss: 0.15297576785087585
train-epoch-step: 87-404 -- Loss: 0.13958638906478882
train-epoch-step: 87-405 -- Loss: 0.14441712200641632
train-epoch-step: 87-406 -- Loss: 0.16110141575336456
train-epoch-step: 87-407 -- Loss: 0.10852450877428055
train-epoch-step: 87-408 -- Loss: 0.15925158560276031
train-epoch-step: 87-409 -- Loss: 0.16739818453788757
train-epoch-step: 87-410 -- Loss: 0.17534543573856354
train-epoch-step: 87-411 -- Loss: 0.19701224565505981
train-epoch-step: 87-412 -- Loss: 0.12893986701965332
train-epoch-step: 87-413 -- Loss: 0.14250826835632324
train-epoch-step: 87-414 -- Loss: 0.13008859753608704
train-epoch-step: 87-415 -- Loss: 0.13342857360839844
train-epoch-step: 87-416 -- Loss: 0.25363942980766296
train-epoch-step: 87-417 -- Loss: 0.18861235678195953
train-epoch-step: 87-418 -- Loss: 0.22558879852294922
train-epoch-step: 87-419 -- Loss: 0.1631026268005371
train-epoch-step: 87-420 -- Loss: 0.14964225888252258
train-epoch-step: 87-421 -- Loss: 0.1698421984910965
train-epoch-step: 87-422 -- Loss: 0.14597004652023315
train-epoch-step: 87-423 -- Loss: 0.1688878834247589
train-epoch-step: 87-424 -- Loss: 0.1328982710838318
train-epoch-step: 87-425 -- Loss: 0.17939630150794983
train-epoch-step: 87-426 -- Loss: 0.15987788140773773
train-epoch-step: 87-427 -- Loss: 0.1172465831041336
train-epoch-step: 87-428 -- Loss: 0.19207710027694702
train-epoch-step: 87-429 -- Loss: 0.17410758137702942
train-epoch-step: 87-430 -- Loss: 0.13852286338806152
train-epoch-step: 87-431 -- Loss: 0.156753271818161
train-epoch-step: 87-432 -- Loss: 0.23369158804416656
train-epoch-step: 87-433 -- Loss: 0.13742493093013763
train-epoch-step: 87-434 -- Loss: 0.12766854465007782
train-epoch-step: 87-435 -- Loss: 0.15061253309249878
train-epoch-step: 87-436 -- Loss: 0.15025918185710907
train-epoch-step: 87-437 -- Loss: 0.12910744547843933
train-epoch-step: 87-438 -- Loss: 0.16400736570358276
train-epoch-step: 87-439 -- Loss: 0.25525784492492676
train-epoch-step: 87-440 -- Loss: 0.13112659752368927
train-epoch-step: 87-441 -- Loss: 0.19459280371665955
train-epoch-step: 87-442 -- Loss: 0.1711004227399826
train-epoch-step: 87-443 -- Loss: 0.15384884178638458
train-epoch-step: 87-444 -- Loss: 0.1747332364320755
train-epoch-step: 87-445 -- Loss: 0.17281979322433472
train-epoch-step: 87-446 -- Loss: 0.15438392758369446
train-epoch-step: 87-447 -- Loss: 0.18781057000160217
train-epoch-step: 87-448 -- Loss: 0.22049948573112488
train-epoch-step: 87-449 -- Loss: 0.1905379593372345
train-epoch-step: 87-450 -- Loss: 0.17630323767662048
train-epoch-step: 87-451 -- Loss: 0.13960236310958862
train-epoch-step: 87-452 -- Loss: 0.13834290206432343
train-epoch-step: 87-453 -- Loss: 0.09041521698236465
train-epoch-step: 87-454 -- Loss: 0.2298322319984436
train-epoch-step: 87-455 -- Loss: 0.1215151995420456
train-epoch-step: 87-456 -- Loss: 0.12311752885580063
train-epoch-step: 87-457 -- Loss: 0.2076008915901184
train-epoch-step: 87-458 -- Loss: 0.15411114692687988
train-epoch-step: 87-459 -- Loss: 0.20442628860473633
train-epoch-step: 87-460 -- Loss: 0.12617993354797363
train-epoch-step: 87-461 -- Loss: 0.13166314363479614
train-epoch-step: 87-462 -- Loss: 0.15302152931690216
train-epoch-step: 87-463 -- Loss: 0.13081473112106323
train-epoch-step: 87-464 -- Loss: 0.1589224487543106
train-epoch-step: 87-465 -- Loss: 0.24241957068443298
train-epoch-step: 87-466 -- Loss: 0.20431452989578247
train-epoch-step: 87-467 -- Loss: 0.11124375462532043
train-epoch-step: 87-468 -- Loss: 0.15899130702018738
train-epoch-step: 87-469 -- Loss: 0.2034962773323059
train-epoch-step: 87-470 -- Loss: 0.16932842135429382
train-epoch-step: 87-471 -- Loss: 0.15648329257965088
train-epoch-step: 87-472 -- Loss: 0.15365242958068848
train-epoch-step: 87-473 -- Loss: 0.15691201388835907
train-epoch-step: 87-474 -- Loss: 0.12175408005714417
train-epoch-step: 87-475 -- Loss: 0.10881547629833221
train-epoch-step: 87-476 -- Loss: 0.19926634430885315
train-epoch-step: 87-477 -- Loss: 0.1942637711763382
train-epoch-step: 87-478 -- Loss: 0.18080125749111176
train-epoch-step: 87-479 -- Loss: 0.13573536276817322
train-epoch-step: 87-480 -- Loss: 0.18978746235370636
train-epoch-step: 87-481 -- Loss: 0.2738689184188843
train-epoch-step: 87-482 -- Loss: 0.2536218762397766
train-epoch-step: 87-483 -- Loss: 0.1809931993484497
train-epoch-step: 87-484 -- Loss: 0.2195044457912445
train-epoch-step: 87-485 -- Loss: 0.12533283233642578
train-epoch-step: 87-486 -- Loss: 0.23594462871551514
train-epoch-step: 87-487 -- Loss: 0.2292863130569458
train-epoch-step: 87-488 -- Loss: 0.1898680031299591
train-epoch-step: 87-489 -- Loss: 0.21370071172714233
train-epoch-step: 87-490 -- Loss: 0.13473060727119446
train-epoch-step: 87-491 -- Loss: 0.13493821024894714
train-epoch-step: 87-492 -- Loss: 0.1296156495809555
train-epoch-step: 87-493 -- Loss: 0.19438910484313965
train-epoch-step: 87-494 -- Loss: 0.19976896047592163
train-epoch-step: 87-495 -- Loss: 0.19162413477897644
train-epoch-step: 87-496 -- Loss: 0.14354147017002106
train-epoch-step: 87-497 -- Loss: 0.1798970103263855
train-epoch-step: 87-498 -- Loss: 0.1451740562915802
train-epoch-step: 87-499 -- Loss: 0.16692568361759186
train-epoch-step: 87-500 -- Loss: 0.15086182951927185
train-epoch-step: 87-501 -- Loss: 0.20846378803253174
train-epoch-step: 87-502 -- Loss: 0.14846964180469513
train-epoch-step: 87-503 -- Loss: 0.21563519537448883
train-epoch-step: 87-504 -- Loss: 0.12196069955825806
train-epoch-step: 87-505 -- Loss: 0.1742354929447174
train-epoch-step: 87-506 -- Loss: 0.11449020355939865
train-epoch-step: 87-507 -- Loss: 0.18212482333183289
train-epoch-step: 87-508 -- Loss: 0.18232637643814087
train-epoch-step: 87-509 -- Loss: 0.16365790367126465
train-epoch-step: 87-510 -- Loss: 0.12729427218437195
train-epoch-step: 87-511 -- Loss: 0.21113112568855286
train-epoch-step: 87-512 -- Loss: 0.1771254539489746
train-epoch-step: 87-513 -- Loss: 0.18852123618125916
train-epoch-step: 87-514 -- Loss: 0.14838123321533203
train-epoch-step: 87-515 -- Loss: 0.14969846606254578
train-epoch-step: 87-516 -- Loss: 0.16979561746120453
train-epoch-step: 87-517 -- Loss: 0.16963911056518555
train-epoch-step: 87-518 -- Loss: 0.13512103259563446
train-epoch-step: 87-519 -- Loss: 0.13552381098270416
train-epoch-step: 87-520 -- Loss: 0.17874790728092194
train-epoch-step: 87-521 -- Loss: 0.22666068375110626
train-epoch-step: 87-522 -- Loss: 0.16818152368068695
train-epoch-step: 87-523 -- Loss: 0.15351176261901855
train-epoch-step: 87-524 -- Loss: 0.16267158091068268
train-epoch-step: 87-525 -- Loss: 0.1879783272743225
train-epoch-step: 87-526 -- Loss: 0.13419604301452637
train-epoch-step: 87-527 -- Loss: 0.14418072998523712
train-epoch-step: 87-528 -- Loss: 0.15210559964179993
train-epoch-step: 87-529 -- Loss: 0.15608136355876923
train-epoch-step: 87-530 -- Loss: 0.16502498090267181
train-epoch-step: 87-531 -- Loss: 0.19535525143146515
train-epoch-step: 87-532 -- Loss: 0.16774298250675201
train-epoch-step: 87-533 -- Loss: 0.17224512994289398
train-epoch-step: 87-534 -- Loss: 0.1250341236591339
train-epoch-step: 87-535 -- Loss: 0.2548357844352722
train-epoch-step: 87-536 -- Loss: 0.15641072392463684
train-epoch-step: 87-537 -- Loss: 0.15795448422431946
train-epoch-step: 87-538 -- Loss: 0.10071615129709244
train-epoch-step: 87-539 -- Loss: 0.17798025906085968
train-epoch-step: 87-540 -- Loss: 0.1313634216785431
train-epoch-step: 87-541 -- Loss: 0.21008023619651794
train-epoch-step: 87-542 -- Loss: 0.2190786898136139
train-epoch-step: 87-543 -- Loss: 0.16354990005493164
train-epoch-step: 87-544 -- Loss: 0.22271540760993958
train-epoch-step: 87-545 -- Loss: 0.19602814316749573
train-epoch-step: 87-546 -- Loss: 0.19952529668807983
train-epoch-step: 87-547 -- Loss: 0.18264532089233398
train-epoch-step: 87-548 -- Loss: 0.09047845005989075
train-epoch-step: 87-549 -- Loss: 0.14562880992889404
train-epoch-step: 87-550 -- Loss: 0.19537696242332458
train-epoch-step: 87-551 -- Loss: 0.1492912322282791
train-epoch-step: 87-552 -- Loss: 0.1228298470377922
train-epoch-step: 87-553 -- Loss: 0.18380987644195557
train-epoch-step: 87-554 -- Loss: 0.17989124357700348
train-epoch-step: 87-555 -- Loss: 0.20334425568580627
train-epoch-step: 87-556 -- Loss: 0.1431661993265152
train-epoch-step: 87-557 -- Loss: 0.22793428599834442
train-epoch-step: 87-558 -- Loss: 0.22162708640098572
train-epoch-step: 87-559 -- Loss: 0.14326636493206024
train-epoch-step: 87-560 -- Loss: 0.20515966415405273
train-epoch-step: 87-561 -- Loss: 0.1800951063632965
train-epoch-step: 87-562 -- Loss: 0.16336439549922943
train-epoch-step: 87-563 -- Loss: 0.1759616732597351
train-epoch-step: 87-564 -- Loss: 0.09656248986721039
train-epoch-step: 87-565 -- Loss: 0.1752396821975708
train-epoch-step: 87-566 -- Loss: 0.14909029006958008
train-epoch-step: 87-567 -- Loss: 0.20573537051677704
train-epoch-step: 87-568 -- Loss: 0.15558688342571259
train-epoch-step: 87-569 -- Loss: 0.23887963593006134
train-epoch-step: 87-570 -- Loss: 0.16164469718933105
train-epoch-step: 87-571 -- Loss: 0.20476555824279785
train-epoch-step: 87-572 -- Loss: 0.23098397254943848
train-epoch-step: 87-573 -- Loss: 0.1911717802286148
train-epoch-step: 87-574 -- Loss: 0.24087779223918915
train-epoch-step: 87-575 -- Loss: 0.29170289635658264
train-epoch-step: 87-576 -- Loss: 0.11488255113363266
train-epoch-step: 87-577 -- Loss: 0.1699383556842804
train-epoch-step: 87-578 -- Loss: 0.21199700236320496
train-epoch-step: 87-579 -- Loss: 0.16122138500213623
train-epoch-step: 87-580 -- Loss: 0.1693476438522339
train-epoch-step: 87-581 -- Loss: 0.14867031574249268
train-epoch-step: 87-582 -- Loss: 0.2062394917011261
train-epoch-step: 87-583 -- Loss: 0.23642867803573608
train-epoch-step: 87-584 -- Loss: 0.1568685919046402
train-epoch-step: 87-585 -- Loss: 0.19434291124343872
train-epoch-step: 87-586 -- Loss: 0.25419744849205017
train-epoch-step: 87-587 -- Loss: 0.16167792677879333
train-epoch-step: 87-588 -- Loss: 0.12930026650428772
val-epoch-step: 87-589 -- Loss: 0.206217423081398
val-epoch-step: 87-590 -- Loss: 0.15262633562088013
val-epoch-step: 87-591 -- Loss: 0.24658046662807465
val-epoch-step: 87-592 -- Loss: 0.17060023546218872
val-epoch-step: 87-593 -- Loss: 0.15304064750671387
val-epoch-step: 87-594 -- Loss: 0.3724658489227295
val-epoch-step: 87-595 -- Loss: 0.18617917597293854
val-epoch-step: 87-596 -- Loss: 0.21439851820468903
val-epoch-step: 87-597 -- Loss: 0.17312857508659363
val-epoch-step: 87-598 -- Loss: 0.1479945033788681
val-epoch-step: 87-599 -- Loss: 0.18969744443893433
val-epoch-step: 87-600 -- Loss: 0.16658915579319
val-epoch-step: 87-601 -- Loss: 0.15462198853492737
val-epoch-step: 87-602 -- Loss: 0.1370367407798767
val-epoch-step: 87-603 -- Loss: 0.210623100399971
val-epoch-step: 87-604 -- Loss: 0.14810042083263397
val-epoch-step: 87-605 -- Loss: 0.14900211989879608
val-epoch-step: 87-606 -- Loss: 0.2651900053024292
val-epoch-step: 87-607 -- Loss: 0.12485931813716888
val-epoch-step: 87-608 -- Loss: 0.24888774752616882
val-epoch-step: 87-609 -- Loss: 0.16466794908046722
val-epoch-step: 87-610 -- Loss: 0.17709465324878693
val-epoch-step: 87-611 -- Loss: 0.15311318635940552
val-epoch-step: 87-612 -- Loss: 0.43412381410598755
val-epoch-step: 87-613 -- Loss: 0.1727927327156067
val-epoch-step: 87-614 -- Loss: 0.1790362298488617
val-epoch-step: 87-615 -- Loss: 0.1711043417453766
val-epoch-step: 87-616 -- Loss: 0.14836999773979187
val-epoch-step: 87-617 -- Loss: 0.19644123315811157
val-epoch-step: 87-618 -- Loss: 0.18237176537513733
val-epoch-step: 87-619 -- Loss: 0.20199301838874817
val-epoch-step: 87-620 -- Loss: 0.13793963193893433
val-epoch-step: 87-621 -- Loss: 0.13018737733364105
val-epoch-step: 87-622 -- Loss: 0.142330139875412
val-epoch-step: 87-623 -- Loss: 0.1461939513683319
val-epoch-step: 87-624 -- Loss: 0.13881774246692657
val-epoch-step: 87-625 -- Loss: 0.15533074736595154
val-epoch-step: 87-626 -- Loss: 0.14917561411857605
val-epoch-step: 87-627 -- Loss: 0.17994707822799683
val-epoch-step: 87-628 -- Loss: 0.5467864274978638
val-epoch-step: 87-629 -- Loss: 0.21689508855342865
val-epoch-step: 87-630 -- Loss: 0.3400651812553406
val-epoch-step: 87-631 -- Loss: 0.14330627024173737
val-epoch-step: 87-632 -- Loss: 0.19688385725021362
val-epoch-step: 87-633 -- Loss: 0.15547308325767517
val-epoch-step: 87-634 -- Loss: 0.14780163764953613
val-epoch-step: 87-635 -- Loss: 0.11629454791545868
val-epoch-step: 87-636 -- Loss: 0.15663236379623413
val-epoch-step: 87-637 -- Loss: 0.18350093066692352
val-epoch-step: 87-638 -- Loss: 0.15338853001594543
val-epoch-step: 87-639 -- Loss: 0.264833927154541
val-epoch-step: 87-640 -- Loss: 0.24795565009117126
val-epoch-step: 87-641 -- Loss: 0.13821130990982056
val-epoch-step: 87-642 -- Loss: 0.17879216372966766
val-epoch-step: 87-643 -- Loss: 0.20657986402511597
val-epoch-step: 87-644 -- Loss: 0.1673942506313324
val-epoch-step: 87-645 -- Loss: 0.21744190156459808
val-epoch-step: 87-646 -- Loss: 0.13043619692325592
val-epoch-step: 87-647 -- Loss: 0.12632142007350922
val-epoch-step: 87-648 -- Loss: 0.15417079627513885
val-epoch-step: 87-649 -- Loss: 0.20583249628543854
val-epoch-step: 87-650 -- Loss: 0.2513124346733093
val-epoch-step: 87-651 -- Loss: 0.14445066452026367
val-epoch-step: 87-652 -- Loss: 0.15242543816566467
val-epoch-step: 87-653 -- Loss: 0.20058445632457733
val-epoch-step: 87-654 -- Loss: 0.11583966016769409
Epoch: 87 -- Train Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 88-0 -- Loss: 0.21975620090961456
train-epoch-step: 88-1 -- Loss: 0.1415865123271942
train-epoch-step: 88-2 -- Loss: 0.19295045733451843
train-epoch-step: 88-3 -- Loss: 0.15464083850383759
train-epoch-step: 88-4 -- Loss: 0.1548868715763092
train-epoch-step: 88-5 -- Loss: 0.18461166322231293
train-epoch-step: 88-6 -- Loss: 0.20661881566047668
train-epoch-step: 88-7 -- Loss: 0.1821863055229187
train-epoch-step: 88-8 -- Loss: 0.17134760320186615
train-epoch-step: 88-9 -- Loss: 0.24150139093399048
train-epoch-step: 88-10 -- Loss: 0.17820525169372559
train-epoch-step: 88-11 -- Loss: 0.18606922030448914
train-epoch-step: 88-12 -- Loss: 0.15141192078590393
train-epoch-step: 88-13 -- Loss: 0.17417718470096588
train-epoch-step: 88-14 -- Loss: 0.1620652675628662
train-epoch-step: 88-15 -- Loss: 0.15660586953163147
train-epoch-step: 88-16 -- Loss: 0.16440635919570923
train-epoch-step: 88-17 -- Loss: 0.2305232435464859
train-epoch-step: 88-18 -- Loss: 0.1838957667350769
train-epoch-step: 88-19 -- Loss: 0.1304706335067749
train-epoch-step: 88-20 -- Loss: 0.20989060401916504
train-epoch-step: 88-21 -- Loss: 0.2461356669664383
train-epoch-step: 88-22 -- Loss: 0.14300693571567535
train-epoch-step: 88-23 -- Loss: 0.1392594873905182
train-epoch-step: 88-24 -- Loss: 0.12394024431705475
train-epoch-step: 88-25 -- Loss: 0.22227616608142853
train-epoch-step: 88-26 -- Loss: 0.1879812777042389
train-epoch-step: 88-27 -- Loss: 0.23425543308258057
train-epoch-step: 88-28 -- Loss: 0.12071917951107025
train-epoch-step: 88-29 -- Loss: 0.23998795449733734
train-epoch-step: 88-30 -- Loss: 0.10809964686632156
train-epoch-step: 88-31 -- Loss: 0.13390310108661652
train-epoch-step: 88-32 -- Loss: 0.16851171851158142
train-epoch-step: 88-33 -- Loss: 0.2722151577472687
train-epoch-step: 88-34 -- Loss: 0.1682458072900772
train-epoch-step: 88-35 -- Loss: 0.25024425983428955
train-epoch-step: 88-36 -- Loss: 0.13212941586971283
train-epoch-step: 88-37 -- Loss: 0.1360451877117157
train-epoch-step: 88-38 -- Loss: 0.1665804237127304
train-epoch-step: 88-39 -- Loss: 0.20463427901268005
train-epoch-step: 88-40 -- Loss: 0.19500379264354706
train-epoch-step: 88-41 -- Loss: 0.21982216835021973
train-epoch-step: 88-42 -- Loss: 0.1521977186203003
train-epoch-step: 88-43 -- Loss: 0.2472582459449768
train-epoch-step: 88-44 -- Loss: 0.12325979769229889
train-epoch-step: 88-45 -- Loss: 0.11236472427845001
train-epoch-step: 88-46 -- Loss: 0.17228777706623077
train-epoch-step: 88-47 -- Loss: 0.1937047243118286
train-epoch-step: 88-48 -- Loss: 0.15237823128700256
train-epoch-step: 88-49 -- Loss: 0.21853825449943542
train-epoch-step: 88-50 -- Loss: 0.10863827913999557
train-epoch-step: 88-51 -- Loss: 0.18870025873184204
train-epoch-step: 88-52 -- Loss: 0.15454068779945374
train-epoch-step: 88-53 -- Loss: 0.2084100842475891
train-epoch-step: 88-54 -- Loss: 0.28777432441711426
train-epoch-step: 88-55 -- Loss: 0.16016478836536407
train-epoch-step: 88-56 -- Loss: 0.1753046214580536
train-epoch-step: 88-57 -- Loss: 0.22945202887058258
train-epoch-step: 88-58 -- Loss: 0.2751157879829407
train-epoch-step: 88-59 -- Loss: 0.2367226928472519
train-epoch-step: 88-60 -- Loss: 0.1317901760339737
train-epoch-step: 88-61 -- Loss: 0.2071194052696228
train-epoch-step: 88-62 -- Loss: 0.18473073840141296
train-epoch-step: 88-63 -- Loss: 0.12991465628147125
train-epoch-step: 88-64 -- Loss: 0.1455971896648407
train-epoch-step: 88-65 -- Loss: 0.18536487221717834
train-epoch-step: 88-66 -- Loss: 0.1060037761926651
train-epoch-step: 88-67 -- Loss: 0.12270258367061615
train-epoch-step: 88-68 -- Loss: 0.20034313201904297
train-epoch-step: 88-69 -- Loss: 0.11993712931871414
train-epoch-step: 88-70 -- Loss: 0.21370583772659302
train-epoch-step: 88-71 -- Loss: 0.2507065534591675
train-epoch-step: 88-72 -- Loss: 0.16947971284389496
train-epoch-step: 88-73 -- Loss: 0.21544399857521057
train-epoch-step: 88-74 -- Loss: 0.09246765077114105
train-epoch-step: 88-75 -- Loss: 0.12376583367586136
train-epoch-step: 88-76 -- Loss: 0.14669916033744812
train-epoch-step: 88-77 -- Loss: 0.21814237534999847
train-epoch-step: 88-78 -- Loss: 0.25201094150543213
train-epoch-step: 88-79 -- Loss: 0.18249328434467316
train-epoch-step: 88-80 -- Loss: 0.2665793299674988
train-epoch-step: 88-81 -- Loss: 0.12116380035877228
train-epoch-step: 88-82 -- Loss: 0.2465798705816269
train-epoch-step: 88-83 -- Loss: 0.17438407242298126
train-epoch-step: 88-84 -- Loss: 0.1806647628545761
train-epoch-step: 88-85 -- Loss: 0.17083695530891418
train-epoch-step: 88-86 -- Loss: 0.11731214076280594
train-epoch-step: 88-87 -- Loss: 0.23700395226478577
train-epoch-step: 88-88 -- Loss: 0.13695210218429565
train-epoch-step: 88-89 -- Loss: 0.18237435817718506
train-epoch-step: 88-90 -- Loss: 0.1837879717350006
train-epoch-step: 88-91 -- Loss: 0.24449440836906433
train-epoch-step: 88-92 -- Loss: 0.1527794897556305
train-epoch-step: 88-93 -- Loss: 0.16735424101352692
train-epoch-step: 88-94 -- Loss: 0.21654631197452545
train-epoch-step: 88-95 -- Loss: 0.18268455564975739
train-epoch-step: 88-96 -- Loss: 0.20920097827911377
train-epoch-step: 88-97 -- Loss: 0.17857970297336578
train-epoch-step: 88-98 -- Loss: 0.15594786405563354
train-epoch-step: 88-99 -- Loss: 0.18044190108776093
train-epoch-step: 88-100 -- Loss: 0.1814914494752884
train-epoch-step: 88-101 -- Loss: 0.2781887352466583
train-epoch-step: 88-102 -- Loss: 0.22097164392471313
train-epoch-step: 88-103 -- Loss: 0.17835474014282227
train-epoch-step: 88-104 -- Loss: 0.14469772577285767
train-epoch-step: 88-105 -- Loss: 0.2666427791118622
train-epoch-step: 88-106 -- Loss: 0.17490659654140472
train-epoch-step: 88-107 -- Loss: 0.1818319857120514
train-epoch-step: 88-108 -- Loss: 0.18593940138816833
train-epoch-step: 88-109 -- Loss: 0.14675340056419373
train-epoch-step: 88-110 -- Loss: 0.18183888494968414
train-epoch-step: 88-111 -- Loss: 0.18146435916423798
train-epoch-step: 88-112 -- Loss: 0.16946765780448914
train-epoch-step: 88-113 -- Loss: 0.16160471737384796
train-epoch-step: 88-114 -- Loss: 0.18906277418136597
train-epoch-step: 88-115 -- Loss: 0.1582586169242859
train-epoch-step: 88-116 -- Loss: 0.13654351234436035
train-epoch-step: 88-117 -- Loss: 0.12355463951826096
train-epoch-step: 88-118 -- Loss: 0.18795737624168396
train-epoch-step: 88-119 -- Loss: 0.14841952919960022
train-epoch-step: 88-120 -- Loss: 0.24506886303424835
train-epoch-step: 88-121 -- Loss: 0.2317776381969452
train-epoch-step: 88-122 -- Loss: 0.2099689394235611
train-epoch-step: 88-123 -- Loss: 0.19751715660095215
train-epoch-step: 88-124 -- Loss: 0.11775874346494675
train-epoch-step: 88-125 -- Loss: 0.1505986601114273
train-epoch-step: 88-126 -- Loss: 0.22436901926994324
train-epoch-step: 88-127 -- Loss: 0.16339358687400818
train-epoch-step: 88-128 -- Loss: 0.17065003514289856
train-epoch-step: 88-129 -- Loss: 0.1410798579454422
train-epoch-step: 88-130 -- Loss: 0.19745022058486938
train-epoch-step: 88-131 -- Loss: 0.1331465244293213
train-epoch-step: 88-132 -- Loss: 0.18408715724945068
train-epoch-step: 88-133 -- Loss: 0.11717790365219116
train-epoch-step: 88-134 -- Loss: 0.18559657037258148
train-epoch-step: 88-135 -- Loss: 0.13358208537101746
train-epoch-step: 88-136 -- Loss: 0.12113340198993683
train-epoch-step: 88-137 -- Loss: 0.24346716701984406
train-epoch-step: 88-138 -- Loss: 0.250456303358078
train-epoch-step: 88-139 -- Loss: 0.1286453753709793
train-epoch-step: 88-140 -- Loss: 0.20315858721733093
train-epoch-step: 88-141 -- Loss: 0.22605714201927185
train-epoch-step: 88-142 -- Loss: 0.19838741421699524
train-epoch-step: 88-143 -- Loss: 0.16366234421730042
train-epoch-step: 88-144 -- Loss: 0.18058016896247864
train-epoch-step: 88-145 -- Loss: 0.14171598851680756
train-epoch-step: 88-146 -- Loss: 0.17430788278579712
train-epoch-step: 88-147 -- Loss: 0.16830161213874817
train-epoch-step: 88-148 -- Loss: 0.16332606971263885
train-epoch-step: 88-149 -- Loss: 0.11585598438978195
train-epoch-step: 88-150 -- Loss: 0.18111999332904816
train-epoch-step: 88-151 -- Loss: 0.18469956517219543
train-epoch-step: 88-152 -- Loss: 0.1867838352918625
train-epoch-step: 88-153 -- Loss: 0.26507362723350525
train-epoch-step: 88-154 -- Loss: 0.12685032188892365
train-epoch-step: 88-155 -- Loss: 0.13673487305641174
train-epoch-step: 88-156 -- Loss: 0.11393344402313232
train-epoch-step: 88-157 -- Loss: 0.16368694603443146
train-epoch-step: 88-158 -- Loss: 0.15996097028255463
train-epoch-step: 88-159 -- Loss: 0.1897319257259369
train-epoch-step: 88-160 -- Loss: 0.21270054578781128
train-epoch-step: 88-161 -- Loss: 0.20352816581726074
train-epoch-step: 88-162 -- Loss: 0.21435478329658508
train-epoch-step: 88-163 -- Loss: 0.18176165223121643
train-epoch-step: 88-164 -- Loss: 0.19465163350105286
train-epoch-step: 88-165 -- Loss: 0.1572023332118988
train-epoch-step: 88-166 -- Loss: 0.12521186470985413
train-epoch-step: 88-167 -- Loss: 0.12248896062374115
train-epoch-step: 88-168 -- Loss: 0.19840583205223083
train-epoch-step: 88-169 -- Loss: 0.13748745620250702
train-epoch-step: 88-170 -- Loss: 0.19346168637275696
train-epoch-step: 88-171 -- Loss: 0.1429021954536438
train-epoch-step: 88-172 -- Loss: 0.25625932216644287
train-epoch-step: 88-173 -- Loss: 0.13261882960796356
train-epoch-step: 88-174 -- Loss: 0.24258412420749664
train-epoch-step: 88-175 -- Loss: 0.182882621884346
train-epoch-step: 88-176 -- Loss: 0.13215288519859314
train-epoch-step: 88-177 -- Loss: 0.17987261712551117
train-epoch-step: 88-178 -- Loss: 0.17427106201648712
train-epoch-step: 88-179 -- Loss: 0.15335926413536072
train-epoch-step: 88-180 -- Loss: 0.14862334728240967
train-epoch-step: 88-181 -- Loss: 0.16495749354362488
train-epoch-step: 88-182 -- Loss: 0.1854424774646759
train-epoch-step: 88-183 -- Loss: 0.27122873067855835
train-epoch-step: 88-184 -- Loss: 0.13353346288204193
train-epoch-step: 88-185 -- Loss: 0.13753527402877808
train-epoch-step: 88-186 -- Loss: 0.1829703003168106
train-epoch-step: 88-187 -- Loss: 0.20378383994102478
train-epoch-step: 88-188 -- Loss: 0.16912831366062164
train-epoch-step: 88-189 -- Loss: 0.10711739957332611
train-epoch-step: 88-190 -- Loss: 0.1788782924413681
train-epoch-step: 88-191 -- Loss: 0.1593877077102661
train-epoch-step: 88-192 -- Loss: 0.22743354737758636
train-epoch-step: 88-193 -- Loss: 0.20476654171943665
train-epoch-step: 88-194 -- Loss: 0.17580407857894897
train-epoch-step: 88-195 -- Loss: 0.16324350237846375
train-epoch-step: 88-196 -- Loss: 0.16119563579559326
train-epoch-step: 88-197 -- Loss: 0.13820600509643555
train-epoch-step: 88-198 -- Loss: 0.12429255992174149
train-epoch-step: 88-199 -- Loss: 0.1441945731639862
train-epoch-step: 88-200 -- Loss: 0.12210401147603989
train-epoch-step: 88-201 -- Loss: 0.18383753299713135
train-epoch-step: 88-202 -- Loss: 0.13404633104801178
train-epoch-step: 88-203 -- Loss: 0.17352402210235596
train-epoch-step: 88-204 -- Loss: 0.1313934326171875
train-epoch-step: 88-205 -- Loss: 0.17747823894023895
train-epoch-step: 88-206 -- Loss: 0.1937514990568161
train-epoch-step: 88-207 -- Loss: 0.12846525013446808
train-epoch-step: 88-208 -- Loss: 0.17488180100917816
train-epoch-step: 88-209 -- Loss: 0.14362339675426483
train-epoch-step: 88-210 -- Loss: 0.12919506430625916
train-epoch-step: 88-211 -- Loss: 0.2021547555923462
train-epoch-step: 88-212 -- Loss: 0.19976750016212463
train-epoch-step: 88-213 -- Loss: 0.12551338970661163
train-epoch-step: 88-214 -- Loss: 0.143926739692688
train-epoch-step: 88-215 -- Loss: 0.12285920232534409
train-epoch-step: 88-216 -- Loss: 0.1961771845817566
train-epoch-step: 88-217 -- Loss: 0.20234577357769012
train-epoch-step: 88-218 -- Loss: 0.14031767845153809
train-epoch-step: 88-219 -- Loss: 0.16575349867343903
train-epoch-step: 88-220 -- Loss: 0.12415924668312073
train-epoch-step: 88-221 -- Loss: 0.19953367114067078
train-epoch-step: 88-222 -- Loss: 0.11567848175764084
train-epoch-step: 88-223 -- Loss: 0.16574381291866302
train-epoch-step: 88-224 -- Loss: 0.18337775766849518
train-epoch-step: 88-225 -- Loss: 0.262289822101593
train-epoch-step: 88-226 -- Loss: 0.2035311758518219
train-epoch-step: 88-227 -- Loss: 0.21661946177482605
train-epoch-step: 88-228 -- Loss: 0.17314209043979645
train-epoch-step: 88-229 -- Loss: 0.1655358374118805
train-epoch-step: 88-230 -- Loss: 0.1559821367263794
train-epoch-step: 88-231 -- Loss: 0.15167608857154846
train-epoch-step: 88-232 -- Loss: 0.1801501363515854
train-epoch-step: 88-233 -- Loss: 0.0836714506149292
train-epoch-step: 88-234 -- Loss: 0.17146849632263184
train-epoch-step: 88-235 -- Loss: 0.13446179032325745
train-epoch-step: 88-236 -- Loss: 0.1801343411207199
train-epoch-step: 88-237 -- Loss: 0.2275494486093521
train-epoch-step: 88-238 -- Loss: 0.15281513333320618
train-epoch-step: 88-239 -- Loss: 0.12481556087732315
train-epoch-step: 88-240 -- Loss: 0.2217492014169693
train-epoch-step: 88-241 -- Loss: 0.1517280638217926
train-epoch-step: 88-242 -- Loss: 0.2110987901687622
train-epoch-step: 88-243 -- Loss: 0.2272661328315735
train-epoch-step: 88-244 -- Loss: 0.2027258276939392
train-epoch-step: 88-245 -- Loss: 0.20211932063102722
train-epoch-step: 88-246 -- Loss: 0.21651332080364227
train-epoch-step: 88-247 -- Loss: 0.21090729534626007
train-epoch-step: 88-248 -- Loss: 0.1839720904827118
train-epoch-step: 88-249 -- Loss: 0.1391686499118805
train-epoch-step: 88-250 -- Loss: 0.1912909746170044
train-epoch-step: 88-251 -- Loss: 0.10402415692806244
train-epoch-step: 88-252 -- Loss: 0.19468684494495392
train-epoch-step: 88-253 -- Loss: 0.13111315667629242
train-epoch-step: 88-254 -- Loss: 0.20441529154777527
train-epoch-step: 88-255 -- Loss: 0.14208762347698212
train-epoch-step: 88-256 -- Loss: 0.1640070080757141
train-epoch-step: 88-257 -- Loss: 0.186702698469162
train-epoch-step: 88-258 -- Loss: 0.13991966843605042
train-epoch-step: 88-259 -- Loss: 0.10881190001964569
train-epoch-step: 88-260 -- Loss: 0.19559960067272186
train-epoch-step: 88-261 -- Loss: 0.17105259001255035
train-epoch-step: 88-262 -- Loss: 0.28781163692474365
train-epoch-step: 88-263 -- Loss: 0.2015462964773178
train-epoch-step: 88-264 -- Loss: 0.17407706379890442
train-epoch-step: 88-265 -- Loss: 0.1456790417432785
train-epoch-step: 88-266 -- Loss: 0.15452313423156738
train-epoch-step: 88-267 -- Loss: 0.12410019338130951
train-epoch-step: 88-268 -- Loss: 0.11859995126724243
train-epoch-step: 88-269 -- Loss: 0.17036695778369904
train-epoch-step: 88-270 -- Loss: 0.10514955222606659
train-epoch-step: 88-271 -- Loss: 0.1446080356836319
train-epoch-step: 88-272 -- Loss: 0.11584176123142242
train-epoch-step: 88-273 -- Loss: 0.1232723519206047
train-epoch-step: 88-274 -- Loss: 0.17691883444786072
train-epoch-step: 88-275 -- Loss: 0.18695156276226044
train-epoch-step: 88-276 -- Loss: 0.152964249253273
train-epoch-step: 88-277 -- Loss: 0.1492687463760376
train-epoch-step: 88-278 -- Loss: 0.14019477367401123
train-epoch-step: 88-279 -- Loss: 0.13448180258274078
train-epoch-step: 88-280 -- Loss: 0.2108612060546875
train-epoch-step: 88-281 -- Loss: 0.17369875311851501
train-epoch-step: 88-282 -- Loss: 0.1378987431526184
train-epoch-step: 88-283 -- Loss: 0.11556660383939743
train-epoch-step: 88-284 -- Loss: 0.13549643754959106
train-epoch-step: 88-285 -- Loss: 0.18918314576148987
train-epoch-step: 88-286 -- Loss: 0.15078379213809967
train-epoch-step: 88-287 -- Loss: 0.19979636371135712
train-epoch-step: 88-288 -- Loss: 0.09549229592084885
train-epoch-step: 88-289 -- Loss: 0.13532696664333344
train-epoch-step: 88-290 -- Loss: 0.17399552464485168
train-epoch-step: 88-291 -- Loss: 0.11563112586736679
train-epoch-step: 88-292 -- Loss: 0.15334001183509827
train-epoch-step: 88-293 -- Loss: 0.1358347237110138
train-epoch-step: 88-294 -- Loss: 0.16454875469207764
train-epoch-step: 88-295 -- Loss: 0.2522334158420563
train-epoch-step: 88-296 -- Loss: 0.15847145020961761
train-epoch-step: 88-297 -- Loss: 0.1684829443693161
train-epoch-step: 88-298 -- Loss: 0.2300778478384018
train-epoch-step: 88-299 -- Loss: 0.14126643538475037
train-epoch-step: 88-300 -- Loss: 0.18099534511566162
train-epoch-step: 88-301 -- Loss: 0.1764887273311615
train-epoch-step: 88-302 -- Loss: 0.22240212559700012
train-epoch-step: 88-303 -- Loss: 0.200705423951149
train-epoch-step: 88-304 -- Loss: 0.12862104177474976
train-epoch-step: 88-305 -- Loss: 0.14911726117134094
train-epoch-step: 88-306 -- Loss: 0.21998625993728638
train-epoch-step: 88-307 -- Loss: 0.17368458211421967
train-epoch-step: 88-308 -- Loss: 0.2209007740020752
train-epoch-step: 88-309 -- Loss: 0.15739178657531738
train-epoch-step: 88-310 -- Loss: 0.15957526862621307
train-epoch-step: 88-311 -- Loss: 0.15982584655284882
train-epoch-step: 88-312 -- Loss: 0.2121337652206421
train-epoch-step: 88-313 -- Loss: 0.09760700166225433
train-epoch-step: 88-314 -- Loss: 0.18982717394828796
train-epoch-step: 88-315 -- Loss: 0.16622388362884521
train-epoch-step: 88-316 -- Loss: 0.1471564918756485
train-epoch-step: 88-317 -- Loss: 0.13597990572452545
train-epoch-step: 88-318 -- Loss: 0.15263552963733673
train-epoch-step: 88-319 -- Loss: 0.1608160436153412
train-epoch-step: 88-320 -- Loss: 0.11617371439933777
train-epoch-step: 88-321 -- Loss: 0.1282086968421936
train-epoch-step: 88-322 -- Loss: 0.21024952828884125
train-epoch-step: 88-323 -- Loss: 0.16302713751792908
train-epoch-step: 88-324 -- Loss: 0.24805662035942078
train-epoch-step: 88-325 -- Loss: 0.1546318233013153
train-epoch-step: 88-326 -- Loss: 0.1704758256673813
train-epoch-step: 88-327 -- Loss: 0.2077494114637375
train-epoch-step: 88-328 -- Loss: 0.19313305616378784
train-epoch-step: 88-329 -- Loss: 0.3325949013233185
train-epoch-step: 88-330 -- Loss: 0.34711840748786926
train-epoch-step: 88-331 -- Loss: 0.20419542491436005
train-epoch-step: 88-332 -- Loss: 0.099374920129776
train-epoch-step: 88-333 -- Loss: 0.1912021040916443
train-epoch-step: 88-334 -- Loss: 0.15276014804840088
train-epoch-step: 88-335 -- Loss: 0.171214759349823
train-epoch-step: 88-336 -- Loss: 0.1475965976715088
train-epoch-step: 88-337 -- Loss: 0.19714604318141937
train-epoch-step: 88-338 -- Loss: 0.15748564898967743
train-epoch-step: 88-339 -- Loss: 0.14976777136325836
train-epoch-step: 88-340 -- Loss: 0.1988004893064499
train-epoch-step: 88-341 -- Loss: 0.13988623023033142
train-epoch-step: 88-342 -- Loss: 0.1632009595632553
train-epoch-step: 88-343 -- Loss: 0.15959343314170837
train-epoch-step: 88-344 -- Loss: 0.16107377409934998
train-epoch-step: 88-345 -- Loss: 0.12540195882320404
train-epoch-step: 88-346 -- Loss: 0.21084937453269958
train-epoch-step: 88-347 -- Loss: 0.1545465588569641
train-epoch-step: 88-348 -- Loss: 0.20082667469978333
train-epoch-step: 88-349 -- Loss: 0.19413764774799347
train-epoch-step: 88-350 -- Loss: 0.24753031134605408
train-epoch-step: 88-351 -- Loss: 0.18668678402900696
train-epoch-step: 88-352 -- Loss: 0.13147519528865814
train-epoch-step: 88-353 -- Loss: 0.18840384483337402
train-epoch-step: 88-354 -- Loss: 0.2722721993923187
train-epoch-step: 88-355 -- Loss: 0.11710385978221893
train-epoch-step: 88-356 -- Loss: 0.11683366447687149
train-epoch-step: 88-357 -- Loss: 0.18165376782417297
train-epoch-step: 88-358 -- Loss: 0.17917722463607788
train-epoch-step: 88-359 -- Loss: 0.13711166381835938
train-epoch-step: 88-360 -- Loss: 0.11940955370664597
train-epoch-step: 88-361 -- Loss: 0.23292505741119385
train-epoch-step: 88-362 -- Loss: 0.16518311202526093
train-epoch-step: 88-363 -- Loss: 0.1105128601193428
train-epoch-step: 88-364 -- Loss: 0.17541585862636566
train-epoch-step: 88-365 -- Loss: 0.16289299726486206
train-epoch-step: 88-366 -- Loss: 0.19910544157028198
train-epoch-step: 88-367 -- Loss: 0.21961289644241333
train-epoch-step: 88-368 -- Loss: 0.1982167810201645
train-epoch-step: 88-369 -- Loss: 0.27675795555114746
train-epoch-step: 88-370 -- Loss: 0.12226830422878265
train-epoch-step: 88-371 -- Loss: 0.11965116858482361
train-epoch-step: 88-372 -- Loss: 0.14366565644741058
train-epoch-step: 88-373 -- Loss: 0.18358923494815826
train-epoch-step: 88-374 -- Loss: 0.15039366483688354
train-epoch-step: 88-375 -- Loss: 0.2585446238517761
train-epoch-step: 88-376 -- Loss: 0.1569657325744629
train-epoch-step: 88-377 -- Loss: 0.21551012992858887
train-epoch-step: 88-378 -- Loss: 0.19172775745391846
train-epoch-step: 88-379 -- Loss: 0.11936718225479126
train-epoch-step: 88-380 -- Loss: 0.08965616673231125
train-epoch-step: 88-381 -- Loss: 0.2375374436378479
train-epoch-step: 88-382 -- Loss: 0.22221799194812775
train-epoch-step: 88-383 -- Loss: 0.17311957478523254
train-epoch-step: 88-384 -- Loss: 0.20517820119857788
train-epoch-step: 88-385 -- Loss: 0.18348847329616547
train-epoch-step: 88-386 -- Loss: 0.19829553365707397
train-epoch-step: 88-387 -- Loss: 0.20065097510814667
train-epoch-step: 88-388 -- Loss: 0.2137875109910965
train-epoch-step: 88-389 -- Loss: 0.16300909221172333
train-epoch-step: 88-390 -- Loss: 0.14140281081199646
train-epoch-step: 88-391 -- Loss: 0.1464775651693344
train-epoch-step: 88-392 -- Loss: 0.18524257838726044
train-epoch-step: 88-393 -- Loss: 0.16674275696277618
train-epoch-step: 88-394 -- Loss: 0.200778990983963
train-epoch-step: 88-395 -- Loss: 0.16529306769371033
train-epoch-step: 88-396 -- Loss: 0.12502284348011017
train-epoch-step: 88-397 -- Loss: 0.12624913454055786
train-epoch-step: 88-398 -- Loss: 0.2017902135848999
train-epoch-step: 88-399 -- Loss: 0.1773950755596161
train-epoch-step: 88-400 -- Loss: 0.284970760345459
train-epoch-step: 88-401 -- Loss: 0.11935660243034363
train-epoch-step: 88-402 -- Loss: 0.25891873240470886
train-epoch-step: 88-403 -- Loss: 0.16204982995986938
train-epoch-step: 88-404 -- Loss: 0.13581582903862
train-epoch-step: 88-405 -- Loss: 0.14436572790145874
train-epoch-step: 88-406 -- Loss: 0.17075777053833008
train-epoch-step: 88-407 -- Loss: 0.11457519233226776
train-epoch-step: 88-408 -- Loss: 0.16243213415145874
train-epoch-step: 88-409 -- Loss: 0.16527794301509857
train-epoch-step: 88-410 -- Loss: 0.1756473034620285
train-epoch-step: 88-411 -- Loss: 0.19539520144462585
train-epoch-step: 88-412 -- Loss: 0.1272990107536316
train-epoch-step: 88-413 -- Loss: 0.1456035077571869
train-epoch-step: 88-414 -- Loss: 0.13077379763126373
train-epoch-step: 88-415 -- Loss: 0.12915146350860596
train-epoch-step: 88-416 -- Loss: 0.2613147795200348
train-epoch-step: 88-417 -- Loss: 0.19529210031032562
train-epoch-step: 88-418 -- Loss: 0.22359773516654968
train-epoch-step: 88-419 -- Loss: 0.16958586871623993
train-epoch-step: 88-420 -- Loss: 0.15030203759670258
train-epoch-step: 88-421 -- Loss: 0.17322447896003723
train-epoch-step: 88-422 -- Loss: 0.14799411594867706
train-epoch-step: 88-423 -- Loss: 0.16720816493034363
train-epoch-step: 88-424 -- Loss: 0.13568681478500366
train-epoch-step: 88-425 -- Loss: 0.17990896105766296
train-epoch-step: 88-426 -- Loss: 0.16381864249706268
train-epoch-step: 88-427 -- Loss: 0.11679472774267197
train-epoch-step: 88-428 -- Loss: 0.18754690885543823
train-epoch-step: 88-429 -- Loss: 0.17306391894817352
train-epoch-step: 88-430 -- Loss: 0.13847701251506805
train-epoch-step: 88-431 -- Loss: 0.15775099396705627
train-epoch-step: 88-432 -- Loss: 0.23510897159576416
train-epoch-step: 88-433 -- Loss: 0.1357681155204773
train-epoch-step: 88-434 -- Loss: 0.125428706407547
train-epoch-step: 88-435 -- Loss: 0.15078487992286682
train-epoch-step: 88-436 -- Loss: 0.15154528617858887
train-epoch-step: 88-437 -- Loss: 0.12833242118358612
train-epoch-step: 88-438 -- Loss: 0.16305972635746002
train-epoch-step: 88-439 -- Loss: 0.2588304281234741
train-epoch-step: 88-440 -- Loss: 0.12857456505298615
train-epoch-step: 88-441 -- Loss: 0.19642774760723114
train-epoch-step: 88-442 -- Loss: 0.16914409399032593
train-epoch-step: 88-443 -- Loss: 0.16410695016384125
train-epoch-step: 88-444 -- Loss: 0.17658120393753052
train-epoch-step: 88-445 -- Loss: 0.17234298586845398
train-epoch-step: 88-446 -- Loss: 0.14623452723026276
train-epoch-step: 88-447 -- Loss: 0.1884382665157318
train-epoch-step: 88-448 -- Loss: 0.22129476070404053
train-epoch-step: 88-449 -- Loss: 0.1873043179512024
train-epoch-step: 88-450 -- Loss: 0.17727407813072205
train-epoch-step: 88-451 -- Loss: 0.1399097740650177
train-epoch-step: 88-452 -- Loss: 0.13269281387329102
train-epoch-step: 88-453 -- Loss: 0.08836682140827179
train-epoch-step: 88-454 -- Loss: 0.2200453132390976
train-epoch-step: 88-455 -- Loss: 0.11773444712162018
train-epoch-step: 88-456 -- Loss: 0.11530368030071259
train-epoch-step: 88-457 -- Loss: 0.211963951587677
train-epoch-step: 88-458 -- Loss: 0.1479698121547699
train-epoch-step: 88-459 -- Loss: 0.20312345027923584
train-epoch-step: 88-460 -- Loss: 0.12332537025213242
train-epoch-step: 88-461 -- Loss: 0.13298353552818298
train-epoch-step: 88-462 -- Loss: 0.15736685693264008
train-epoch-step: 88-463 -- Loss: 0.13261950016021729
train-epoch-step: 88-464 -- Loss: 0.15717813372612
train-epoch-step: 88-465 -- Loss: 0.23050588369369507
train-epoch-step: 88-466 -- Loss: 0.1979091465473175
train-epoch-step: 88-467 -- Loss: 0.10868760943412781
train-epoch-step: 88-468 -- Loss: 0.1612718105316162
train-epoch-step: 88-469 -- Loss: 0.2046956717967987
train-epoch-step: 88-470 -- Loss: 0.1737438142299652
train-epoch-step: 88-471 -- Loss: 0.14911343157291412
train-epoch-step: 88-472 -- Loss: 0.1568487286567688
train-epoch-step: 88-473 -- Loss: 0.15023693442344666
train-epoch-step: 88-474 -- Loss: 0.1166682243347168
train-epoch-step: 88-475 -- Loss: 0.10663126409053802
train-epoch-step: 88-476 -- Loss: 0.1929621398448944
train-epoch-step: 88-477 -- Loss: 0.18993674218654633
train-epoch-step: 88-478 -- Loss: 0.18320994079113007
train-epoch-step: 88-479 -- Loss: 0.13817410171031952
train-epoch-step: 88-480 -- Loss: 0.1870400309562683
train-epoch-step: 88-481 -- Loss: 0.27845367789268494
train-epoch-step: 88-482 -- Loss: 0.24599876999855042
train-epoch-step: 88-483 -- Loss: 0.17368528246879578
train-epoch-step: 88-484 -- Loss: 0.21437004208564758
train-epoch-step: 88-485 -- Loss: 0.12314726412296295
train-epoch-step: 88-486 -- Loss: 0.22757402062416077
train-epoch-step: 88-487 -- Loss: 0.22656795382499695
train-epoch-step: 88-488 -- Loss: 0.18018661439418793
train-epoch-step: 88-489 -- Loss: 0.22137026488780975
train-epoch-step: 88-490 -- Loss: 0.13164231181144714
train-epoch-step: 88-491 -- Loss: 0.13232451677322388
train-epoch-step: 88-492 -- Loss: 0.12633083760738373
train-epoch-step: 88-493 -- Loss: 0.19329780340194702
train-epoch-step: 88-494 -- Loss: 0.19840501248836517
train-epoch-step: 88-495 -- Loss: 0.1914803683757782
train-epoch-step: 88-496 -- Loss: 0.13914212584495544
train-epoch-step: 88-497 -- Loss: 0.1845095455646515
train-epoch-step: 88-498 -- Loss: 0.14347630739212036
train-epoch-step: 88-499 -- Loss: 0.1625969111919403
train-epoch-step: 88-500 -- Loss: 0.15135550498962402
train-epoch-step: 88-501 -- Loss: 0.20473389327526093
train-epoch-step: 88-502 -- Loss: 0.15275992453098297
train-epoch-step: 88-503 -- Loss: 0.21069516241550446
train-epoch-step: 88-504 -- Loss: 0.12292299419641495
train-epoch-step: 88-505 -- Loss: 0.1683921068906784
train-epoch-step: 88-506 -- Loss: 0.11364264786243439
train-epoch-step: 88-507 -- Loss: 0.17426612973213196
train-epoch-step: 88-508 -- Loss: 0.17361865937709808
train-epoch-step: 88-509 -- Loss: 0.16352538764476776
train-epoch-step: 88-510 -- Loss: 0.12824003398418427
train-epoch-step: 88-511 -- Loss: 0.21239514648914337
train-epoch-step: 88-512 -- Loss: 0.1752195656299591
train-epoch-step: 88-513 -- Loss: 0.17580729722976685
train-epoch-step: 88-514 -- Loss: 0.1397668421268463
train-epoch-step: 88-515 -- Loss: 0.14806662499904633
train-epoch-step: 88-516 -- Loss: 0.16783955693244934
train-epoch-step: 88-517 -- Loss: 0.16790206730365753
train-epoch-step: 88-518 -- Loss: 0.13655303418636322
train-epoch-step: 88-519 -- Loss: 0.13447803258895874
train-epoch-step: 88-520 -- Loss: 0.18187184631824493
train-epoch-step: 88-521 -- Loss: 0.22989608347415924
train-epoch-step: 88-522 -- Loss: 0.16888085007667542
train-epoch-step: 88-523 -- Loss: 0.15153880417346954
train-epoch-step: 88-524 -- Loss: 0.16364850103855133
train-epoch-step: 88-525 -- Loss: 0.1892576366662979
train-epoch-step: 88-526 -- Loss: 0.1315314620733261
train-epoch-step: 88-527 -- Loss: 0.14583531022071838
train-epoch-step: 88-528 -- Loss: 0.15101996064186096
train-epoch-step: 88-529 -- Loss: 0.16014903783798218
train-epoch-step: 88-530 -- Loss: 0.16603493690490723
train-epoch-step: 88-531 -- Loss: 0.19440704584121704
train-epoch-step: 88-532 -- Loss: 0.1699211597442627
train-epoch-step: 88-533 -- Loss: 0.17188145220279694
train-epoch-step: 88-534 -- Loss: 0.12479200214147568
train-epoch-step: 88-535 -- Loss: 0.24725626409053802
train-epoch-step: 88-536 -- Loss: 0.15331493318080902
train-epoch-step: 88-537 -- Loss: 0.14945247769355774
train-epoch-step: 88-538 -- Loss: 0.0984923467040062
train-epoch-step: 88-539 -- Loss: 0.18032345175743103
train-epoch-step: 88-540 -- Loss: 0.13272725045681
train-epoch-step: 88-541 -- Loss: 0.20217987895011902
train-epoch-step: 88-542 -- Loss: 0.21510514616966248
train-epoch-step: 88-543 -- Loss: 0.16745032370090485
train-epoch-step: 88-544 -- Loss: 0.22361664474010468
train-epoch-step: 88-545 -- Loss: 0.19145546853542328
train-epoch-step: 88-546 -- Loss: 0.20449793338775635
train-epoch-step: 88-547 -- Loss: 0.17800623178482056
train-epoch-step: 88-548 -- Loss: 0.09001971036195755
train-epoch-step: 88-549 -- Loss: 0.15120331943035126
train-epoch-step: 88-550 -- Loss: 0.1905335932970047
train-epoch-step: 88-551 -- Loss: 0.1484207957983017
train-epoch-step: 88-552 -- Loss: 0.123210608959198
train-epoch-step: 88-553 -- Loss: 0.18139000236988068
train-epoch-step: 88-554 -- Loss: 0.17704370617866516
train-epoch-step: 88-555 -- Loss: 0.203934445977211
train-epoch-step: 88-556 -- Loss: 0.14010025560855865
train-epoch-step: 88-557 -- Loss: 0.22264364361763
train-epoch-step: 88-558 -- Loss: 0.2215447723865509
train-epoch-step: 88-559 -- Loss: 0.13785451650619507
train-epoch-step: 88-560 -- Loss: 0.20595164597034454
train-epoch-step: 88-561 -- Loss: 0.16780924797058105
train-epoch-step: 88-562 -- Loss: 0.15891987085342407
train-epoch-step: 88-563 -- Loss: 0.18091832101345062
train-epoch-step: 88-564 -- Loss: 0.09704530984163284
train-epoch-step: 88-565 -- Loss: 0.17664256691932678
train-epoch-step: 88-566 -- Loss: 0.14619742333889008
train-epoch-step: 88-567 -- Loss: 0.20013536512851715
train-epoch-step: 88-568 -- Loss: 0.15043777227401733
train-epoch-step: 88-569 -- Loss: 0.23781587183475494
train-epoch-step: 88-570 -- Loss: 0.16037526726722717
train-epoch-step: 88-571 -- Loss: 0.20300477743148804
train-epoch-step: 88-572 -- Loss: 0.2327653467655182
train-epoch-step: 88-573 -- Loss: 0.19428619742393494
train-epoch-step: 88-574 -- Loss: 0.2385881096124649
train-epoch-step: 88-575 -- Loss: 0.2879144549369812
train-epoch-step: 88-576 -- Loss: 0.11525243520736694
train-epoch-step: 88-577 -- Loss: 0.1583438217639923
train-epoch-step: 88-578 -- Loss: 0.21167919039726257
train-epoch-step: 88-579 -- Loss: 0.16097471117973328
train-epoch-step: 88-580 -- Loss: 0.16562215983867645
train-epoch-step: 88-581 -- Loss: 0.13783173263072968
train-epoch-step: 88-582 -- Loss: 0.2023705542087555
train-epoch-step: 88-583 -- Loss: 0.2134120613336563
train-epoch-step: 88-584 -- Loss: 0.1631443202495575
train-epoch-step: 88-585 -- Loss: 0.18685708940029144
train-epoch-step: 88-586 -- Loss: 0.24558889865875244
train-epoch-step: 88-587 -- Loss: 0.16971784830093384
train-epoch-step: 88-588 -- Loss: 0.12743228673934937
val-epoch-step: 88-589 -- Loss: 0.3323831558227539
val-epoch-step: 88-590 -- Loss: 0.20133796334266663
val-epoch-step: 88-591 -- Loss: 0.24425970017910004
val-epoch-step: 88-592 -- Loss: 0.17781728506088257
val-epoch-step: 88-593 -- Loss: 0.19077607989311218
val-epoch-step: 88-594 -- Loss: 0.34161823987960815
val-epoch-step: 88-595 -- Loss: 0.19526471197605133
val-epoch-step: 88-596 -- Loss: 0.20362281799316406
val-epoch-step: 88-597 -- Loss: 0.1798253357410431
val-epoch-step: 88-598 -- Loss: 0.15960386395454407
val-epoch-step: 88-599 -- Loss: 0.1914418637752533
val-epoch-step: 88-600 -- Loss: 0.16678869724273682
val-epoch-step: 88-601 -- Loss: 0.16141363978385925
val-epoch-step: 88-602 -- Loss: 0.19592595100402832
val-epoch-step: 88-603 -- Loss: 0.25554871559143066
val-epoch-step: 88-604 -- Loss: 0.15038610994815826
val-epoch-step: 88-605 -- Loss: 0.14398056268692017
val-epoch-step: 88-606 -- Loss: 0.4370537996292114
val-epoch-step: 88-607 -- Loss: 0.18493859469890594
val-epoch-step: 88-608 -- Loss: 0.25175943970680237
val-epoch-step: 88-609 -- Loss: 0.18000134825706482
val-epoch-step: 88-610 -- Loss: 0.23171855509281158
val-epoch-step: 88-611 -- Loss: 0.16286349296569824
val-epoch-step: 88-612 -- Loss: 0.3419882357120514
val-epoch-step: 88-613 -- Loss: 0.24850116670131683
val-epoch-step: 88-614 -- Loss: 0.18757829070091248
val-epoch-step: 88-615 -- Loss: 0.18091905117034912
val-epoch-step: 88-616 -- Loss: 0.1779184639453888
val-epoch-step: 88-617 -- Loss: 0.24817562103271484
val-epoch-step: 88-618 -- Loss: 0.20331254601478577
val-epoch-step: 88-619 -- Loss: 0.25808483362197876
val-epoch-step: 88-620 -- Loss: 0.1407846063375473
val-epoch-step: 88-621 -- Loss: 0.13365229964256287
val-epoch-step: 88-622 -- Loss: 0.18401461839675903
val-epoch-step: 88-623 -- Loss: 0.15438884496688843
val-epoch-step: 88-624 -- Loss: 0.1455477774143219
val-epoch-step: 88-625 -- Loss: 0.15863226354122162
val-epoch-step: 88-626 -- Loss: 0.2145770639181137
val-epoch-step: 88-627 -- Loss: 0.19638830423355103
val-epoch-step: 88-628 -- Loss: 0.5000520348548889
val-epoch-step: 88-629 -- Loss: 0.19223114848136902
val-epoch-step: 88-630 -- Loss: 0.3988993465900421
val-epoch-step: 88-631 -- Loss: 0.19245684146881104
val-epoch-step: 88-632 -- Loss: 0.24465978145599365
val-epoch-step: 88-633 -- Loss: 0.1698301136493683
val-epoch-step: 88-634 -- Loss: 0.15554900467395782
val-epoch-step: 88-635 -- Loss: 0.13758206367492676
val-epoch-step: 88-636 -- Loss: 0.16040527820587158
val-epoch-step: 88-637 -- Loss: 0.19708722829818726
val-epoch-step: 88-638 -- Loss: 0.14381983876228333
val-epoch-step: 88-639 -- Loss: 0.3267645239830017
val-epoch-step: 88-640 -- Loss: 0.25886043906211853
val-epoch-step: 88-641 -- Loss: 0.17468853294849396
val-epoch-step: 88-642 -- Loss: 0.260117769241333
val-epoch-step: 88-643 -- Loss: 0.20564286410808563
val-epoch-step: 88-644 -- Loss: 0.20362651348114014
val-epoch-step: 88-645 -- Loss: 0.3143230080604553
val-epoch-step: 88-646 -- Loss: 0.15259984135627747
val-epoch-step: 88-647 -- Loss: 0.13102152943611145
val-epoch-step: 88-648 -- Loss: 0.1527850180864334
val-epoch-step: 88-649 -- Loss: 0.21462951600551605
val-epoch-step: 88-650 -- Loss: 0.251647025346756
val-epoch-step: 88-651 -- Loss: 0.1582878828048706
val-epoch-step: 88-652 -- Loss: 0.1629180759191513
val-epoch-step: 88-653 -- Loss: 0.27038121223449707
val-epoch-step: 88-654 -- Loss: 0.126326322555542
Epoch: 88 -- Train Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 89-0 -- Loss: 0.233110249042511
train-epoch-step: 89-1 -- Loss: 0.14866957068443298
train-epoch-step: 89-2 -- Loss: 0.1951039731502533
train-epoch-step: 89-3 -- Loss: 0.14234377443790436
train-epoch-step: 89-4 -- Loss: 0.1494770646095276
train-epoch-step: 89-5 -- Loss: 0.18452291190624237
train-epoch-step: 89-6 -- Loss: 0.22682304680347443
train-epoch-step: 89-7 -- Loss: 0.16856126487255096
train-epoch-step: 89-8 -- Loss: 0.17457494139671326
train-epoch-step: 89-9 -- Loss: 0.2253362238407135
train-epoch-step: 89-10 -- Loss: 0.18683591485023499
train-epoch-step: 89-11 -- Loss: 0.17209196090698242
train-epoch-step: 89-12 -- Loss: 0.14465807378292084
train-epoch-step: 89-13 -- Loss: 0.17421495914459229
train-epoch-step: 89-14 -- Loss: 0.1597394347190857
train-epoch-step: 89-15 -- Loss: 0.16206340491771698
train-epoch-step: 89-16 -- Loss: 0.16360995173454285
train-epoch-step: 89-17 -- Loss: 0.2254384458065033
train-epoch-step: 89-18 -- Loss: 0.18623973429203033
train-epoch-step: 89-19 -- Loss: 0.13277870416641235
train-epoch-step: 89-20 -- Loss: 0.20864209532737732
train-epoch-step: 89-21 -- Loss: 0.2374497503042221
train-epoch-step: 89-22 -- Loss: 0.1423158347606659
train-epoch-step: 89-23 -- Loss: 0.13775795698165894
train-epoch-step: 89-24 -- Loss: 0.12032584100961685
train-epoch-step: 89-25 -- Loss: 0.21909962594509125
train-epoch-step: 89-26 -- Loss: 0.18768417835235596
train-epoch-step: 89-27 -- Loss: 0.221757709980011
train-epoch-step: 89-28 -- Loss: 0.12105127424001694
train-epoch-step: 89-29 -- Loss: 0.23474165797233582
train-epoch-step: 89-30 -- Loss: 0.10719245672225952
train-epoch-step: 89-31 -- Loss: 0.13396281003952026
train-epoch-step: 89-32 -- Loss: 0.1696171760559082
train-epoch-step: 89-33 -- Loss: 0.27165645360946655
train-epoch-step: 89-34 -- Loss: 0.1645086258649826
train-epoch-step: 89-35 -- Loss: 0.23921073973178864
train-epoch-step: 89-36 -- Loss: 0.14248600602149963
train-epoch-step: 89-37 -- Loss: 0.13297602534294128
train-epoch-step: 89-38 -- Loss: 0.16851291060447693
train-epoch-step: 89-39 -- Loss: 0.20972855389118195
train-epoch-step: 89-40 -- Loss: 0.18677979707717896
train-epoch-step: 89-41 -- Loss: 0.20844030380249023
train-epoch-step: 89-42 -- Loss: 0.14154152572155
train-epoch-step: 89-43 -- Loss: 0.24782419204711914
train-epoch-step: 89-44 -- Loss: 0.12199973315000534
train-epoch-step: 89-45 -- Loss: 0.11371880769729614
train-epoch-step: 89-46 -- Loss: 0.16206733882427216
train-epoch-step: 89-47 -- Loss: 0.21056091785430908
train-epoch-step: 89-48 -- Loss: 0.151905819773674
train-epoch-step: 89-49 -- Loss: 0.22153614461421967
train-epoch-step: 89-50 -- Loss: 0.10450796037912369
train-epoch-step: 89-51 -- Loss: 0.17631420493125916
train-epoch-step: 89-52 -- Loss: 0.1542036533355713
train-epoch-step: 89-53 -- Loss: 0.2069215476512909
train-epoch-step: 89-54 -- Loss: 0.28286439180374146
train-epoch-step: 89-55 -- Loss: 0.1744207888841629
train-epoch-step: 89-56 -- Loss: 0.17117372155189514
train-epoch-step: 89-57 -- Loss: 0.2298251986503601
train-epoch-step: 89-58 -- Loss: 0.28437674045562744
train-epoch-step: 89-59 -- Loss: 0.23005974292755127
train-epoch-step: 89-60 -- Loss: 0.13060255348682404
train-epoch-step: 89-61 -- Loss: 0.20335114002227783
train-epoch-step: 89-62 -- Loss: 0.18266303837299347
train-epoch-step: 89-63 -- Loss: 0.1449451744556427
train-epoch-step: 89-64 -- Loss: 0.14340652525424957
train-epoch-step: 89-65 -- Loss: 0.180064395070076
train-epoch-step: 89-66 -- Loss: 0.10669577121734619
train-epoch-step: 89-67 -- Loss: 0.12161664664745331
train-epoch-step: 89-68 -- Loss: 0.214141383767128
train-epoch-step: 89-69 -- Loss: 0.11745148152112961
train-epoch-step: 89-70 -- Loss: 0.22503721714019775
train-epoch-step: 89-71 -- Loss: 0.25447532534599304
train-epoch-step: 89-72 -- Loss: 0.17260906100273132
train-epoch-step: 89-73 -- Loss: 0.20574596524238586
train-epoch-step: 89-74 -- Loss: 0.09404545277357101
train-epoch-step: 89-75 -- Loss: 0.12461639940738678
train-epoch-step: 89-76 -- Loss: 0.14323274791240692
train-epoch-step: 89-77 -- Loss: 0.2272571623325348
train-epoch-step: 89-78 -- Loss: 0.24995586276054382
train-epoch-step: 89-79 -- Loss: 0.18653681874275208
train-epoch-step: 89-80 -- Loss: 0.2348187416791916
train-epoch-step: 89-81 -- Loss: 0.12361227720975876
train-epoch-step: 89-82 -- Loss: 0.2552904486656189
train-epoch-step: 89-83 -- Loss: 0.17537516355514526
train-epoch-step: 89-84 -- Loss: 0.18125024437904358
train-epoch-step: 89-85 -- Loss: 0.16571921110153198
train-epoch-step: 89-86 -- Loss: 0.11684522032737732
train-epoch-step: 89-87 -- Loss: 0.27889353036880493
train-epoch-step: 89-88 -- Loss: 0.13884003460407257
train-epoch-step: 89-89 -- Loss: 0.18286976218223572
train-epoch-step: 89-90 -- Loss: 0.18818563222885132
train-epoch-step: 89-91 -- Loss: 0.2426195591688156
train-epoch-step: 89-92 -- Loss: 0.15244711935520172
train-epoch-step: 89-93 -- Loss: 0.19336411356925964
train-epoch-step: 89-94 -- Loss: 0.22011776268482208
train-epoch-step: 89-95 -- Loss: 0.18587414920330048
train-epoch-step: 89-96 -- Loss: 0.2089102566242218
train-epoch-step: 89-97 -- Loss: 0.17270952463150024
train-epoch-step: 89-98 -- Loss: 0.15401311218738556
train-epoch-step: 89-99 -- Loss: 0.17243695259094238
train-epoch-step: 89-100 -- Loss: 0.18436264991760254
train-epoch-step: 89-101 -- Loss: 0.26161664724349976
train-epoch-step: 89-102 -- Loss: 0.22075459361076355
train-epoch-step: 89-103 -- Loss: 0.18023841083049774
train-epoch-step: 89-104 -- Loss: 0.14294572174549103
train-epoch-step: 89-105 -- Loss: 0.26768267154693604
train-epoch-step: 89-106 -- Loss: 0.17550364136695862
train-epoch-step: 89-107 -- Loss: 0.18701224029064178
train-epoch-step: 89-108 -- Loss: 0.18679773807525635
train-epoch-step: 89-109 -- Loss: 0.14321988821029663
train-epoch-step: 89-110 -- Loss: 0.18495087325572968
train-epoch-step: 89-111 -- Loss: 0.17934337258338928
train-epoch-step: 89-112 -- Loss: 0.17262691259384155
train-epoch-step: 89-113 -- Loss: 0.16272208094596863
train-epoch-step: 89-114 -- Loss: 0.19396010041236877
train-epoch-step: 89-115 -- Loss: 0.15880487859249115
train-epoch-step: 89-116 -- Loss: 0.13601987063884735
train-epoch-step: 89-117 -- Loss: 0.1262749582529068
train-epoch-step: 89-118 -- Loss: 0.191029354929924
train-epoch-step: 89-119 -- Loss: 0.1476718932390213
train-epoch-step: 89-120 -- Loss: 0.24397295713424683
train-epoch-step: 89-121 -- Loss: 0.23043879866600037
train-epoch-step: 89-122 -- Loss: 0.21484504640102386
train-epoch-step: 89-123 -- Loss: 0.20449863374233246
train-epoch-step: 89-124 -- Loss: 0.12365858256816864
train-epoch-step: 89-125 -- Loss: 0.15358072519302368
train-epoch-step: 89-126 -- Loss: 0.25203022360801697
train-epoch-step: 89-127 -- Loss: 0.16870154440402985
train-epoch-step: 89-128 -- Loss: 0.16977399587631226
train-epoch-step: 89-129 -- Loss: 0.1421148180961609
train-epoch-step: 89-130 -- Loss: 0.20404750108718872
train-epoch-step: 89-131 -- Loss: 0.14040115475654602
train-epoch-step: 89-132 -- Loss: 0.1838124692440033
train-epoch-step: 89-133 -- Loss: 0.12492179125547409
train-epoch-step: 89-134 -- Loss: 0.1873268187046051
train-epoch-step: 89-135 -- Loss: 0.1335047483444214
train-epoch-step: 89-136 -- Loss: 0.12212128937244415
train-epoch-step: 89-137 -- Loss: 0.24247489869594574
train-epoch-step: 89-138 -- Loss: 0.25375592708587646
train-epoch-step: 89-139 -- Loss: 0.12766548991203308
train-epoch-step: 89-140 -- Loss: 0.2045755833387375
train-epoch-step: 89-141 -- Loss: 0.22786718606948853
train-epoch-step: 89-142 -- Loss: 0.20806662738323212
train-epoch-step: 89-143 -- Loss: 0.174127995967865
train-epoch-step: 89-144 -- Loss: 0.1812863051891327
train-epoch-step: 89-145 -- Loss: 0.14494460821151733
train-epoch-step: 89-146 -- Loss: 0.1775553822517395
train-epoch-step: 89-147 -- Loss: 0.16295592486858368
train-epoch-step: 89-148 -- Loss: 0.16110831499099731
train-epoch-step: 89-149 -- Loss: 0.11847454309463501
train-epoch-step: 89-150 -- Loss: 0.1834826022386551
train-epoch-step: 89-151 -- Loss: 0.18527624011039734
train-epoch-step: 89-152 -- Loss: 0.19174396991729736
train-epoch-step: 89-153 -- Loss: 0.3007739782333374
train-epoch-step: 89-154 -- Loss: 0.134663924574852
train-epoch-step: 89-155 -- Loss: 0.1375325620174408
train-epoch-step: 89-156 -- Loss: 0.11283211410045624
train-epoch-step: 89-157 -- Loss: 0.16394051909446716
train-epoch-step: 89-158 -- Loss: 0.161311537027359
train-epoch-step: 89-159 -- Loss: 0.18601469695568085
train-epoch-step: 89-160 -- Loss: 0.202199324965477
train-epoch-step: 89-161 -- Loss: 0.20280270278453827
train-epoch-step: 89-162 -- Loss: 0.20427921414375305
train-epoch-step: 89-163 -- Loss: 0.1859813928604126
train-epoch-step: 89-164 -- Loss: 0.19137659668922424
train-epoch-step: 89-165 -- Loss: 0.15838035941123962
train-epoch-step: 89-166 -- Loss: 0.12611612677574158
train-epoch-step: 89-167 -- Loss: 0.1309324949979782
train-epoch-step: 89-168 -- Loss: 0.20382465422153473
train-epoch-step: 89-169 -- Loss: 0.14054973423480988
train-epoch-step: 89-170 -- Loss: 0.19579574465751648
train-epoch-step: 89-171 -- Loss: 0.14498473703861237
train-epoch-step: 89-172 -- Loss: 0.25812873244285583
train-epoch-step: 89-173 -- Loss: 0.13282440602779388
train-epoch-step: 89-174 -- Loss: 0.24583762884140015
train-epoch-step: 89-175 -- Loss: 0.18775561451911926
train-epoch-step: 89-176 -- Loss: 0.13902708888053894
train-epoch-step: 89-177 -- Loss: 0.17846320569515228
train-epoch-step: 89-178 -- Loss: 0.17599090933799744
train-epoch-step: 89-179 -- Loss: 0.1563967913389206
train-epoch-step: 89-180 -- Loss: 0.1465049386024475
train-epoch-step: 89-181 -- Loss: 0.1669568568468094
train-epoch-step: 89-182 -- Loss: 0.18509270250797272
train-epoch-step: 89-183 -- Loss: 0.27890247106552124
train-epoch-step: 89-184 -- Loss: 0.13508471846580505
train-epoch-step: 89-185 -- Loss: 0.14109274744987488
train-epoch-step: 89-186 -- Loss: 0.18442876636981964
train-epoch-step: 89-187 -- Loss: 0.21221771836280823
train-epoch-step: 89-188 -- Loss: 0.16584467887878418
train-epoch-step: 89-189 -- Loss: 0.10245604068040848
train-epoch-step: 89-190 -- Loss: 0.18519073724746704
train-epoch-step: 89-191 -- Loss: 0.15872310101985931
train-epoch-step: 89-192 -- Loss: 0.22839072346687317
train-epoch-step: 89-193 -- Loss: 0.20530135929584503
train-epoch-step: 89-194 -- Loss: 0.17405641078948975
train-epoch-step: 89-195 -- Loss: 0.16725778579711914
train-epoch-step: 89-196 -- Loss: 0.16845937073230743
train-epoch-step: 89-197 -- Loss: 0.13587522506713867
train-epoch-step: 89-198 -- Loss: 0.12441550195217133
train-epoch-step: 89-199 -- Loss: 0.14530421793460846
train-epoch-step: 89-200 -- Loss: 0.12376819550991058
train-epoch-step: 89-201 -- Loss: 0.1872297078371048
train-epoch-step: 89-202 -- Loss: 0.13355036079883575
train-epoch-step: 89-203 -- Loss: 0.17361044883728027
train-epoch-step: 89-204 -- Loss: 0.13707734644412994
train-epoch-step: 89-205 -- Loss: 0.18003734946250916
train-epoch-step: 89-206 -- Loss: 0.19154071807861328
train-epoch-step: 89-207 -- Loss: 0.1343066394329071
train-epoch-step: 89-208 -- Loss: 0.17736780643463135
train-epoch-step: 89-209 -- Loss: 0.14144711196422577
train-epoch-step: 89-210 -- Loss: 0.13235799968242645
train-epoch-step: 89-211 -- Loss: 0.2033499777317047
train-epoch-step: 89-212 -- Loss: 0.19390355050563812
train-epoch-step: 89-213 -- Loss: 0.1291339248418808
train-epoch-step: 89-214 -- Loss: 0.1465759575366974
train-epoch-step: 89-215 -- Loss: 0.122939333319664
train-epoch-step: 89-216 -- Loss: 0.19110532104969025
train-epoch-step: 89-217 -- Loss: 0.2137407809495926
train-epoch-step: 89-218 -- Loss: 0.14359427988529205
train-epoch-step: 89-219 -- Loss: 0.16738969087600708
train-epoch-step: 89-220 -- Loss: 0.12522350251674652
train-epoch-step: 89-221 -- Loss: 0.20082801580429077
train-epoch-step: 89-222 -- Loss: 0.114029660820961
train-epoch-step: 89-223 -- Loss: 0.16843613982200623
train-epoch-step: 89-224 -- Loss: 0.19320382177829742
train-epoch-step: 89-225 -- Loss: 0.260516494512558
train-epoch-step: 89-226 -- Loss: 0.20720531046390533
train-epoch-step: 89-227 -- Loss: 0.21389588713645935
train-epoch-step: 89-228 -- Loss: 0.16930507123470306
train-epoch-step: 89-229 -- Loss: 0.16984817385673523
train-epoch-step: 89-230 -- Loss: 0.1602170467376709
train-epoch-step: 89-231 -- Loss: 0.16107091307640076
train-epoch-step: 89-232 -- Loss: 0.18575763702392578
train-epoch-step: 89-233 -- Loss: 0.08586287498474121
train-epoch-step: 89-234 -- Loss: 0.17033562064170837
train-epoch-step: 89-235 -- Loss: 0.14591345191001892
train-epoch-step: 89-236 -- Loss: 0.17939206957817078
train-epoch-step: 89-237 -- Loss: 0.22644467651844025
train-epoch-step: 89-238 -- Loss: 0.153510183095932
train-epoch-step: 89-239 -- Loss: 0.13079693913459778
train-epoch-step: 89-240 -- Loss: 0.21875497698783875
train-epoch-step: 89-241 -- Loss: 0.15389350056648254
train-epoch-step: 89-242 -- Loss: 0.21338170766830444
train-epoch-step: 89-243 -- Loss: 0.23427054286003113
train-epoch-step: 89-244 -- Loss: 0.2015230655670166
train-epoch-step: 89-245 -- Loss: 0.20064324140548706
train-epoch-step: 89-246 -- Loss: 0.21389076113700867
train-epoch-step: 89-247 -- Loss: 0.20397566258907318
train-epoch-step: 89-248 -- Loss: 0.18080323934555054
train-epoch-step: 89-249 -- Loss: 0.13671919703483582
train-epoch-step: 89-250 -- Loss: 0.20763197541236877
train-epoch-step: 89-251 -- Loss: 0.10796590894460678
train-epoch-step: 89-252 -- Loss: 0.19074124097824097
train-epoch-step: 89-253 -- Loss: 0.1381331980228424
train-epoch-step: 89-254 -- Loss: 0.21421606838703156
train-epoch-step: 89-255 -- Loss: 0.14211809635162354
train-epoch-step: 89-256 -- Loss: 0.1748041808605194
train-epoch-step: 89-257 -- Loss: 0.18599791824817657
train-epoch-step: 89-258 -- Loss: 0.13954167068004608
train-epoch-step: 89-259 -- Loss: 0.11180496215820312
train-epoch-step: 89-260 -- Loss: 0.19369792938232422
train-epoch-step: 89-261 -- Loss: 0.1693950891494751
train-epoch-step: 89-262 -- Loss: 0.2699595093727112
train-epoch-step: 89-263 -- Loss: 0.1972842663526535
train-epoch-step: 89-264 -- Loss: 0.17412953078746796
train-epoch-step: 89-265 -- Loss: 0.13091136515140533
train-epoch-step: 89-266 -- Loss: 0.15275175869464874
train-epoch-step: 89-267 -- Loss: 0.1307682991027832
train-epoch-step: 89-268 -- Loss: 0.12774282693862915
train-epoch-step: 89-269 -- Loss: 0.18889138102531433
train-epoch-step: 89-270 -- Loss: 0.11882205307483673
train-epoch-step: 89-271 -- Loss: 0.1719851791858673
train-epoch-step: 89-272 -- Loss: 0.12397488951683044
train-epoch-step: 89-273 -- Loss: 0.13446952402591705
train-epoch-step: 89-274 -- Loss: 0.2489347904920578
train-epoch-step: 89-275 -- Loss: 0.2468280792236328
train-epoch-step: 89-276 -- Loss: 0.1924830973148346
train-epoch-step: 89-277 -- Loss: 0.15735700726509094
train-epoch-step: 89-278 -- Loss: 0.13570749759674072
train-epoch-step: 89-279 -- Loss: 0.14235885441303253
train-epoch-step: 89-280 -- Loss: 0.23931975662708282
train-epoch-step: 89-281 -- Loss: 0.20296990871429443
train-epoch-step: 89-282 -- Loss: 0.14673803746700287
train-epoch-step: 89-283 -- Loss: 0.1325317770242691
train-epoch-step: 89-284 -- Loss: 0.3998159170150757
train-epoch-step: 89-285 -- Loss: 0.19423365592956543
train-epoch-step: 89-286 -- Loss: 0.156699538230896
train-epoch-step: 89-287 -- Loss: 0.1994035840034485
train-epoch-step: 89-288 -- Loss: 0.09729623049497604
train-epoch-step: 89-289 -- Loss: 0.11886600404977798
train-epoch-step: 89-290 -- Loss: 0.19281400740146637
train-epoch-step: 89-291 -- Loss: 0.12448549270629883
train-epoch-step: 89-292 -- Loss: 0.1628873199224472
train-epoch-step: 89-293 -- Loss: 0.14306208491325378
train-epoch-step: 89-294 -- Loss: 0.16607356071472168
train-epoch-step: 89-295 -- Loss: 0.30399686098098755
train-epoch-step: 89-296 -- Loss: 0.18213288486003876
train-epoch-step: 89-297 -- Loss: 0.1730809062719345
train-epoch-step: 89-298 -- Loss: 0.23339679837226868
train-epoch-step: 89-299 -- Loss: 0.15681488811969757
train-epoch-step: 89-300 -- Loss: 0.18211373686790466
train-epoch-step: 89-301 -- Loss: 0.1737988293170929
train-epoch-step: 89-302 -- Loss: 0.22224366664886475
train-epoch-step: 89-303 -- Loss: 0.20416587591171265
train-epoch-step: 89-304 -- Loss: 0.12286997586488724
train-epoch-step: 89-305 -- Loss: 0.14384174346923828
train-epoch-step: 89-306 -- Loss: 0.2242329865694046
train-epoch-step: 89-307 -- Loss: 0.16784265637397766
train-epoch-step: 89-308 -- Loss: 0.24355441331863403
train-epoch-step: 89-309 -- Loss: 0.15864737331867218
train-epoch-step: 89-310 -- Loss: 0.17007263004779816
train-epoch-step: 89-311 -- Loss: 0.16919222474098206
train-epoch-step: 89-312 -- Loss: 0.20290103554725647
train-epoch-step: 89-313 -- Loss: 0.09730632603168488
train-epoch-step: 89-314 -- Loss: 0.19110333919525146
train-epoch-step: 89-315 -- Loss: 0.16788120567798615
train-epoch-step: 89-316 -- Loss: 0.15524722635746002
train-epoch-step: 89-317 -- Loss: 0.14599336683750153
train-epoch-step: 89-318 -- Loss: 0.16154499351978302
train-epoch-step: 89-319 -- Loss: 0.174165278673172
train-epoch-step: 89-320 -- Loss: 0.11825940012931824
train-epoch-step: 89-321 -- Loss: 0.13357412815093994
train-epoch-step: 89-322 -- Loss: 0.218483567237854
train-epoch-step: 89-323 -- Loss: 0.15559104084968567
train-epoch-step: 89-324 -- Loss: 0.25350213050842285
train-epoch-step: 89-325 -- Loss: 0.1568652093410492
train-epoch-step: 89-326 -- Loss: 0.16430509090423584
train-epoch-step: 89-327 -- Loss: 0.20326554775238037
train-epoch-step: 89-328 -- Loss: 0.19329068064689636
train-epoch-step: 89-329 -- Loss: 0.3322935700416565
train-epoch-step: 89-330 -- Loss: 0.350870817899704
train-epoch-step: 89-331 -- Loss: 0.21054957807064056
train-epoch-step: 89-332 -- Loss: 0.0958230048418045
train-epoch-step: 89-333 -- Loss: 0.18041449785232544
train-epoch-step: 89-334 -- Loss: 0.15303032100200653
train-epoch-step: 89-335 -- Loss: 0.17231245338916779
train-epoch-step: 89-336 -- Loss: 0.14360518753528595
train-epoch-step: 89-337 -- Loss: 0.22117625176906586
train-epoch-step: 89-338 -- Loss: 0.16053232550621033
train-epoch-step: 89-339 -- Loss: 0.13781271874904633
train-epoch-step: 89-340 -- Loss: 0.19517669081687927
train-epoch-step: 89-341 -- Loss: 0.1375475525856018
train-epoch-step: 89-342 -- Loss: 0.16323865950107574
train-epoch-step: 89-343 -- Loss: 0.15285739302635193
train-epoch-step: 89-344 -- Loss: 0.16549700498580933
train-epoch-step: 89-345 -- Loss: 0.12611262500286102
train-epoch-step: 89-346 -- Loss: 0.20632310211658478
train-epoch-step: 89-347 -- Loss: 0.15641307830810547
train-epoch-step: 89-348 -- Loss: 0.20044538378715515
train-epoch-step: 89-349 -- Loss: 0.21149542927742004
train-epoch-step: 89-350 -- Loss: 0.2503719627857208
train-epoch-step: 89-351 -- Loss: 0.20357590913772583
train-epoch-step: 89-352 -- Loss: 0.1257363259792328
train-epoch-step: 89-353 -- Loss: 0.18697676062583923
train-epoch-step: 89-354 -- Loss: 0.26969096064567566
train-epoch-step: 89-355 -- Loss: 0.11475101113319397
train-epoch-step: 89-356 -- Loss: 0.12120847404003143
train-epoch-step: 89-357 -- Loss: 0.18928614258766174
train-epoch-step: 89-358 -- Loss: 0.1817082315683365
train-epoch-step: 89-359 -- Loss: 0.13410945236682892
train-epoch-step: 89-360 -- Loss: 0.13007736206054688
train-epoch-step: 89-361 -- Loss: 0.2367180734872818
train-epoch-step: 89-362 -- Loss: 0.16822069883346558
train-epoch-step: 89-363 -- Loss: 0.11145259439945221
train-epoch-step: 89-364 -- Loss: 0.1845245063304901
train-epoch-step: 89-365 -- Loss: 0.17009443044662476
train-epoch-step: 89-366 -- Loss: 0.21678180992603302
train-epoch-step: 89-367 -- Loss: 0.22237031161785126
train-epoch-step: 89-368 -- Loss: 0.19604864716529846
train-epoch-step: 89-369 -- Loss: 0.27536487579345703
train-epoch-step: 89-370 -- Loss: 0.13062874972820282
train-epoch-step: 89-371 -- Loss: 0.1219840794801712
train-epoch-step: 89-372 -- Loss: 0.14616599678993225
train-epoch-step: 89-373 -- Loss: 0.19276228547096252
train-epoch-step: 89-374 -- Loss: 0.15398581326007843
train-epoch-step: 89-375 -- Loss: 0.2646368443965912
train-epoch-step: 89-376 -- Loss: 0.16840261220932007
train-epoch-step: 89-377 -- Loss: 0.22357890009880066
train-epoch-step: 89-378 -- Loss: 0.1925203502178192
train-epoch-step: 89-379 -- Loss: 0.12186945974826813
train-epoch-step: 89-380 -- Loss: 0.09147986024618149
train-epoch-step: 89-381 -- Loss: 0.24559305608272552
train-epoch-step: 89-382 -- Loss: 0.23460328578948975
train-epoch-step: 89-383 -- Loss: 0.176380455493927
train-epoch-step: 89-384 -- Loss: 0.23119893670082092
train-epoch-step: 89-385 -- Loss: 0.19065679609775543
train-epoch-step: 89-386 -- Loss: 0.18397307395935059
train-epoch-step: 89-387 -- Loss: 0.20328673720359802
train-epoch-step: 89-388 -- Loss: 0.20004281401634216
train-epoch-step: 89-389 -- Loss: 0.16230431199073792
train-epoch-step: 89-390 -- Loss: 0.13997197151184082
train-epoch-step: 89-391 -- Loss: 0.14258994162082672
train-epoch-step: 89-392 -- Loss: 0.17766563594341278
train-epoch-step: 89-393 -- Loss: 0.15184184908866882
train-epoch-step: 89-394 -- Loss: 0.20028366148471832
train-epoch-step: 89-395 -- Loss: 0.15617536008358002
train-epoch-step: 89-396 -- Loss: 0.12437812983989716
train-epoch-step: 89-397 -- Loss: 0.12076972424983978
train-epoch-step: 89-398 -- Loss: 0.19889894127845764
train-epoch-step: 89-399 -- Loss: 0.16997158527374268
train-epoch-step: 89-400 -- Loss: 0.271526575088501
train-epoch-step: 89-401 -- Loss: 0.11839844286441803
train-epoch-step: 89-402 -- Loss: 0.2542387545108795
train-epoch-step: 89-403 -- Loss: 0.15578415989875793
train-epoch-step: 89-404 -- Loss: 0.1379486620426178
train-epoch-step: 89-405 -- Loss: 0.1401693969964981
train-epoch-step: 89-406 -- Loss: 0.17116115987300873
train-epoch-step: 89-407 -- Loss: 0.10888507217168808
train-epoch-step: 89-408 -- Loss: 0.15847961604595184
train-epoch-step: 89-409 -- Loss: 0.16638073325157166
train-epoch-step: 89-410 -- Loss: 0.1751060038805008
train-epoch-step: 89-411 -- Loss: 0.19352832436561584
train-epoch-step: 89-412 -- Loss: 0.1317313313484192
train-epoch-step: 89-413 -- Loss: 0.14222431182861328
train-epoch-step: 89-414 -- Loss: 0.127276211977005
train-epoch-step: 89-415 -- Loss: 0.13376428186893463
train-epoch-step: 89-416 -- Loss: 0.2587871551513672
train-epoch-step: 89-417 -- Loss: 0.18972449004650116
train-epoch-step: 89-418 -- Loss: 0.22001907229423523
train-epoch-step: 89-419 -- Loss: 0.20254182815551758
train-epoch-step: 89-420 -- Loss: 0.14856286346912384
train-epoch-step: 89-421 -- Loss: 0.1742068976163864
train-epoch-step: 89-422 -- Loss: 0.14314617216587067
train-epoch-step: 89-423 -- Loss: 0.1688784807920456
train-epoch-step: 89-424 -- Loss: 0.13381610810756683
train-epoch-step: 89-425 -- Loss: 0.1806172877550125
train-epoch-step: 89-426 -- Loss: 0.1702793836593628
train-epoch-step: 89-427 -- Loss: 0.12046957015991211
train-epoch-step: 89-428 -- Loss: 0.21537911891937256
train-epoch-step: 89-429 -- Loss: 0.17214082181453705
train-epoch-step: 89-430 -- Loss: 0.13606102764606476
train-epoch-step: 89-431 -- Loss: 0.1633014976978302
train-epoch-step: 89-432 -- Loss: 0.2420121282339096
train-epoch-step: 89-433 -- Loss: 0.1402476727962494
train-epoch-step: 89-434 -- Loss: 0.12413319945335388
train-epoch-step: 89-435 -- Loss: 0.15411615371704102
train-epoch-step: 89-436 -- Loss: 0.15172842144966125
train-epoch-step: 89-437 -- Loss: 0.12866537272930145
train-epoch-step: 89-438 -- Loss: 0.1656675487756729
train-epoch-step: 89-439 -- Loss: 0.25146374106407166
train-epoch-step: 89-440 -- Loss: 0.12670713663101196
train-epoch-step: 89-441 -- Loss: 0.1945253610610962
train-epoch-step: 89-442 -- Loss: 0.18076330423355103
train-epoch-step: 89-443 -- Loss: 0.15042215585708618
train-epoch-step: 89-444 -- Loss: 0.17154216766357422
train-epoch-step: 89-445 -- Loss: 0.17668940126895905
train-epoch-step: 89-446 -- Loss: 0.14837074279785156
train-epoch-step: 89-447 -- Loss: 0.18586474657058716
train-epoch-step: 89-448 -- Loss: 0.2229021042585373
train-epoch-step: 89-449 -- Loss: 0.18500390648841858
train-epoch-step: 89-450 -- Loss: 0.17781080305576324
train-epoch-step: 89-451 -- Loss: 0.15032240748405457
train-epoch-step: 89-452 -- Loss: 0.12439421564340591
train-epoch-step: 89-453 -- Loss: 0.08874741941690445
train-epoch-step: 89-454 -- Loss: 0.22495728731155396
train-epoch-step: 89-455 -- Loss: 0.12370080500841141
train-epoch-step: 89-456 -- Loss: 0.11495316028594971
train-epoch-step: 89-457 -- Loss: 0.2127125859260559
train-epoch-step: 89-458 -- Loss: 0.1434469223022461
train-epoch-step: 89-459 -- Loss: 0.2110397219657898
train-epoch-step: 89-460 -- Loss: 0.12419328093528748
train-epoch-step: 89-461 -- Loss: 0.13119901716709137
train-epoch-step: 89-462 -- Loss: 0.1494043916463852
train-epoch-step: 89-463 -- Loss: 0.13646936416625977
train-epoch-step: 89-464 -- Loss: 0.15616364777088165
train-epoch-step: 89-465 -- Loss: 0.23265360295772552
train-epoch-step: 89-466 -- Loss: 0.2042730748653412
train-epoch-step: 89-467 -- Loss: 0.11251485347747803
train-epoch-step: 89-468 -- Loss: 0.16744351387023926
train-epoch-step: 89-469 -- Loss: 0.1996651589870453
train-epoch-step: 89-470 -- Loss: 0.16265177726745605
train-epoch-step: 89-471 -- Loss: 0.15017160773277283
train-epoch-step: 89-472 -- Loss: 0.1571938544511795
train-epoch-step: 89-473 -- Loss: 0.15028689801692963
train-epoch-step: 89-474 -- Loss: 0.11827760934829712
train-epoch-step: 89-475 -- Loss: 0.10562346130609512
train-epoch-step: 89-476 -- Loss: 0.19336959719657898
train-epoch-step: 89-477 -- Loss: 0.19110769033432007
train-epoch-step: 89-478 -- Loss: 0.17946508526802063
train-epoch-step: 89-479 -- Loss: 0.1369343101978302
train-epoch-step: 89-480 -- Loss: 0.18726281821727753
train-epoch-step: 89-481 -- Loss: 0.2786456048488617
train-epoch-step: 89-482 -- Loss: 0.24719107151031494
train-epoch-step: 89-483 -- Loss: 0.17659468948841095
train-epoch-step: 89-484 -- Loss: 0.20743153989315033
train-epoch-step: 89-485 -- Loss: 0.12661847472190857
train-epoch-step: 89-486 -- Loss: 0.22817173600196838
train-epoch-step: 89-487 -- Loss: 0.2301451861858368
train-epoch-step: 89-488 -- Loss: 0.1833605021238327
train-epoch-step: 89-489 -- Loss: 0.2159886360168457
train-epoch-step: 89-490 -- Loss: 0.1325838565826416
train-epoch-step: 89-491 -- Loss: 0.1328456997871399
train-epoch-step: 89-492 -- Loss: 0.12297102808952332
train-epoch-step: 89-493 -- Loss: 0.1918637901544571
train-epoch-step: 89-494 -- Loss: 0.1964365392923355
train-epoch-step: 89-495 -- Loss: 0.19400456547737122
train-epoch-step: 89-496 -- Loss: 0.13855990767478943
train-epoch-step: 89-497 -- Loss: 0.17823804914951324
train-epoch-step: 89-498 -- Loss: 0.14656980335712433
train-epoch-step: 89-499 -- Loss: 0.1654302179813385
train-epoch-step: 89-500 -- Loss: 0.15083451569080353
train-epoch-step: 89-501 -- Loss: 0.2085515558719635
train-epoch-step: 89-502 -- Loss: 0.15012361109256744
train-epoch-step: 89-503 -- Loss: 0.21212409436702728
train-epoch-step: 89-504 -- Loss: 0.11933852732181549
train-epoch-step: 89-505 -- Loss: 0.1646493822336197
train-epoch-step: 89-506 -- Loss: 0.11672787368297577
train-epoch-step: 89-507 -- Loss: 0.17906993627548218
train-epoch-step: 89-508 -- Loss: 0.17032578587532043
train-epoch-step: 89-509 -- Loss: 0.16511160135269165
train-epoch-step: 89-510 -- Loss: 0.1266288012266159
train-epoch-step: 89-511 -- Loss: 0.20948010683059692
train-epoch-step: 89-512 -- Loss: 0.1729072630405426
train-epoch-step: 89-513 -- Loss: 0.18453317880630493
train-epoch-step: 89-514 -- Loss: 0.13728977739810944
train-epoch-step: 89-515 -- Loss: 0.14730548858642578
train-epoch-step: 89-516 -- Loss: 0.16309210658073425
train-epoch-step: 89-517 -- Loss: 0.16765952110290527
train-epoch-step: 89-518 -- Loss: 0.1329035758972168
train-epoch-step: 89-519 -- Loss: 0.13000716269016266
train-epoch-step: 89-520 -- Loss: 0.17751240730285645
train-epoch-step: 89-521 -- Loss: 0.21801592409610748
train-epoch-step: 89-522 -- Loss: 0.1668420135974884
train-epoch-step: 89-523 -- Loss: 0.15255525708198547
train-epoch-step: 89-524 -- Loss: 0.16154858469963074
train-epoch-step: 89-525 -- Loss: 0.18425798416137695
train-epoch-step: 89-526 -- Loss: 0.12568217515945435
train-epoch-step: 89-527 -- Loss: 0.1500510275363922
train-epoch-step: 89-528 -- Loss: 0.1496821790933609
train-epoch-step: 89-529 -- Loss: 0.15145577490329742
train-epoch-step: 89-530 -- Loss: 0.16412760317325592
train-epoch-step: 89-531 -- Loss: 0.19786368310451508
train-epoch-step: 89-532 -- Loss: 0.16550312936306
train-epoch-step: 89-533 -- Loss: 0.1765751987695694
train-epoch-step: 89-534 -- Loss: 0.1258644163608551
train-epoch-step: 89-535 -- Loss: 0.24797742068767548
train-epoch-step: 89-536 -- Loss: 0.15580834448337555
train-epoch-step: 89-537 -- Loss: 0.14609436690807343
train-epoch-step: 89-538 -- Loss: 0.10267356783151627
train-epoch-step: 89-539 -- Loss: 0.1787424385547638
train-epoch-step: 89-540 -- Loss: 0.13925278186798096
train-epoch-step: 89-541 -- Loss: 0.20159922540187836
train-epoch-step: 89-542 -- Loss: 0.2209046632051468
train-epoch-step: 89-543 -- Loss: 0.16463156044483185
train-epoch-step: 89-544 -- Loss: 0.22060610353946686
train-epoch-step: 89-545 -- Loss: 0.18954876065254211
train-epoch-step: 89-546 -- Loss: 0.2007943093776703
train-epoch-step: 89-547 -- Loss: 0.1812349259853363
train-epoch-step: 89-548 -- Loss: 0.08830497413873672
train-epoch-step: 89-549 -- Loss: 0.14477543532848358
train-epoch-step: 89-550 -- Loss: 0.19520343840122223
train-epoch-step: 89-551 -- Loss: 0.14897632598876953
train-epoch-step: 89-552 -- Loss: 0.12134947627782822
train-epoch-step: 89-553 -- Loss: 0.1864103376865387
train-epoch-step: 89-554 -- Loss: 0.1816767156124115
train-epoch-step: 89-555 -- Loss: 0.20392495393753052
train-epoch-step: 89-556 -- Loss: 0.13917343318462372
train-epoch-step: 89-557 -- Loss: 0.2292230725288391
train-epoch-step: 89-558 -- Loss: 0.22183699905872345
train-epoch-step: 89-559 -- Loss: 0.13570955395698547
train-epoch-step: 89-560 -- Loss: 0.20161202549934387
train-epoch-step: 89-561 -- Loss: 0.17330129444599152
train-epoch-step: 89-562 -- Loss: 0.15859565138816833
train-epoch-step: 89-563 -- Loss: 0.17737039923667908
train-epoch-step: 89-564 -- Loss: 0.09496092796325684
train-epoch-step: 89-565 -- Loss: 0.17295020818710327
train-epoch-step: 89-566 -- Loss: 0.14479801058769226
train-epoch-step: 89-567 -- Loss: 0.20482036471366882
train-epoch-step: 89-568 -- Loss: 0.15793398022651672
train-epoch-step: 89-569 -- Loss: 0.23846416175365448
train-epoch-step: 89-570 -- Loss: 0.1627340316772461
train-epoch-step: 89-571 -- Loss: 0.20214422047138214
train-epoch-step: 89-572 -- Loss: 0.23845961689949036
train-epoch-step: 89-573 -- Loss: 0.1950513869524002
train-epoch-step: 89-574 -- Loss: 0.23772859573364258
train-epoch-step: 89-575 -- Loss: 0.28980696201324463
train-epoch-step: 89-576 -- Loss: 0.11787431687116623
train-epoch-step: 89-577 -- Loss: 0.16945397853851318
train-epoch-step: 89-578 -- Loss: 0.21777589619159698
train-epoch-step: 89-579 -- Loss: 0.1707373410463333
train-epoch-step: 89-580 -- Loss: 0.16536962985992432
train-epoch-step: 89-581 -- Loss: 0.13711275160312653
train-epoch-step: 89-582 -- Loss: 0.20149172842502594
train-epoch-step: 89-583 -- Loss: 0.2075473964214325
train-epoch-step: 89-584 -- Loss: 0.16443699598312378
train-epoch-step: 89-585 -- Loss: 0.18888099491596222
train-epoch-step: 89-586 -- Loss: 0.24627351760864258
train-epoch-step: 89-587 -- Loss: 0.15888142585754395
train-epoch-step: 89-588 -- Loss: 0.12501412630081177
val-epoch-step: 89-589 -- Loss: 0.2031160295009613
val-epoch-step: 89-590 -- Loss: 0.15369901061058044
val-epoch-step: 89-591 -- Loss: 0.22990106046199799
val-epoch-step: 89-592 -- Loss: 0.165925532579422
val-epoch-step: 89-593 -- Loss: 0.18706762790679932
val-epoch-step: 89-594 -- Loss: 0.3300805985927582
val-epoch-step: 89-595 -- Loss: 0.17300845682621002
val-epoch-step: 89-596 -- Loss: 0.19223535060882568
val-epoch-step: 89-597 -- Loss: 0.17354096472263336
val-epoch-step: 89-598 -- Loss: 0.14731138944625854
val-epoch-step: 89-599 -- Loss: 0.17987066507339478
val-epoch-step: 89-600 -- Loss: 0.16116215288639069
val-epoch-step: 89-601 -- Loss: 0.15149660408496857
val-epoch-step: 89-602 -- Loss: 0.13240952789783478
val-epoch-step: 89-603 -- Loss: 0.21865108609199524
val-epoch-step: 89-604 -- Loss: 0.14357967674732208
val-epoch-step: 89-605 -- Loss: 0.15059790015220642
val-epoch-step: 89-606 -- Loss: 0.273046612739563
val-epoch-step: 89-607 -- Loss: 0.12147726118564606
val-epoch-step: 89-608 -- Loss: 0.24230943620204926
val-epoch-step: 89-609 -- Loss: 0.1641068160533905
val-epoch-step: 89-610 -- Loss: 0.1724359691143036
val-epoch-step: 89-611 -- Loss: 0.15501169860363007
val-epoch-step: 89-612 -- Loss: 0.38958579301834106
val-epoch-step: 89-613 -- Loss: 0.17165972292423248
val-epoch-step: 89-614 -- Loss: 0.16731204092502594
val-epoch-step: 89-615 -- Loss: 0.17633479833602905
val-epoch-step: 89-616 -- Loss: 0.14247922599315643
val-epoch-step: 89-617 -- Loss: 0.19516408443450928
val-epoch-step: 89-618 -- Loss: 0.18353179097175598
val-epoch-step: 89-619 -- Loss: 0.1982744336128235
val-epoch-step: 89-620 -- Loss: 0.13122303783893585
val-epoch-step: 89-621 -- Loss: 0.1257869303226471
val-epoch-step: 89-622 -- Loss: 0.14174875617027283
val-epoch-step: 89-623 -- Loss: 0.1517297327518463
val-epoch-step: 89-624 -- Loss: 0.13475587964057922
val-epoch-step: 89-625 -- Loss: 0.15741291642189026
val-epoch-step: 89-626 -- Loss: 0.14404603838920593
val-epoch-step: 89-627 -- Loss: 0.1810881644487381
val-epoch-step: 89-628 -- Loss: 0.37982410192489624
val-epoch-step: 89-629 -- Loss: 0.22118660807609558
val-epoch-step: 89-630 -- Loss: 0.3467578887939453
val-epoch-step: 89-631 -- Loss: 0.14885443449020386
val-epoch-step: 89-632 -- Loss: 0.20193514227867126
val-epoch-step: 89-633 -- Loss: 0.14942523837089539
val-epoch-step: 89-634 -- Loss: 0.1472376585006714
val-epoch-step: 89-635 -- Loss: 0.11483223736286163
val-epoch-step: 89-636 -- Loss: 0.15724338591098785
val-epoch-step: 89-637 -- Loss: 0.17877323925495148
val-epoch-step: 89-638 -- Loss: 0.14247509837150574
val-epoch-step: 89-639 -- Loss: 0.2463211566209793
val-epoch-step: 89-640 -- Loss: 0.24673905968666077
val-epoch-step: 89-641 -- Loss: 0.1375991702079773
val-epoch-step: 89-642 -- Loss: 0.17823579907417297
val-epoch-step: 89-643 -- Loss: 0.19946518540382385
val-epoch-step: 89-644 -- Loss: 0.16258224844932556
val-epoch-step: 89-645 -- Loss: 0.21824681758880615
val-epoch-step: 89-646 -- Loss: 0.12451881170272827
val-epoch-step: 89-647 -- Loss: 0.12153513729572296
val-epoch-step: 89-648 -- Loss: 0.15063390135765076
val-epoch-step: 89-649 -- Loss: 0.2056094855070114
val-epoch-step: 89-650 -- Loss: 0.24507592618465424
val-epoch-step: 89-651 -- Loss: 0.14131192862987518
val-epoch-step: 89-652 -- Loss: 0.15773506462574005
val-epoch-step: 89-653 -- Loss: 0.18639340996742249
val-epoch-step: 89-654 -- Loss: 0.10999596118927002
Epoch: 89 -- Train Loss: tensor(0.1397, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 90-0 -- Loss: 0.21612873673439026
train-epoch-step: 90-1 -- Loss: 0.1405715048313141
train-epoch-step: 90-2 -- Loss: 0.18867453932762146
train-epoch-step: 90-3 -- Loss: 0.141924649477005
train-epoch-step: 90-4 -- Loss: 0.15132871270179749
train-epoch-step: 90-5 -- Loss: 0.1901133954524994
train-epoch-step: 90-6 -- Loss: 0.22420862317085266
train-epoch-step: 90-7 -- Loss: 0.16187258064746857
train-epoch-step: 90-8 -- Loss: 0.17577579617500305
train-epoch-step: 90-9 -- Loss: 0.21845288574695587
train-epoch-step: 90-10 -- Loss: 0.1873781830072403
train-epoch-step: 90-11 -- Loss: 0.18176507949829102
train-epoch-step: 90-12 -- Loss: 0.1479388326406479
train-epoch-step: 90-13 -- Loss: 0.17231886088848114
train-epoch-step: 90-14 -- Loss: 0.1651722937822342
train-epoch-step: 90-15 -- Loss: 0.16433881223201752
train-epoch-step: 90-16 -- Loss: 0.15967705845832825
train-epoch-step: 90-17 -- Loss: 0.22797101736068726
train-epoch-step: 90-18 -- Loss: 0.18808460235595703
train-epoch-step: 90-19 -- Loss: 0.12777218222618103
train-epoch-step: 90-20 -- Loss: 0.20951634645462036
train-epoch-step: 90-21 -- Loss: 0.24493154883384705
train-epoch-step: 90-22 -- Loss: 0.13788464665412903
train-epoch-step: 90-23 -- Loss: 0.1443931758403778
train-epoch-step: 90-24 -- Loss: 0.11934143304824829
train-epoch-step: 90-25 -- Loss: 0.21484003961086273
train-epoch-step: 90-26 -- Loss: 0.18461257219314575
train-epoch-step: 90-27 -- Loss: 0.23067805171012878
train-epoch-step: 90-28 -- Loss: 0.11937282234430313
train-epoch-step: 90-29 -- Loss: 0.2358587235212326
train-epoch-step: 90-30 -- Loss: 0.1110944151878357
train-epoch-step: 90-31 -- Loss: 0.1302538812160492
train-epoch-step: 90-32 -- Loss: 0.16689591109752655
train-epoch-step: 90-33 -- Loss: 0.2701852321624756
train-epoch-step: 90-34 -- Loss: 0.1722978949546814
train-epoch-step: 90-35 -- Loss: 0.2402065545320511
train-epoch-step: 90-36 -- Loss: 0.15608862042427063
train-epoch-step: 90-37 -- Loss: 0.1304045021533966
train-epoch-step: 90-38 -- Loss: 0.16863586008548737
train-epoch-step: 90-39 -- Loss: 0.2118418961763382
train-epoch-step: 90-40 -- Loss: 0.19030654430389404
train-epoch-step: 90-41 -- Loss: 0.21798908710479736
train-epoch-step: 90-42 -- Loss: 0.14852167665958405
train-epoch-step: 90-43 -- Loss: 0.25247204303741455
train-epoch-step: 90-44 -- Loss: 0.12093064188957214
train-epoch-step: 90-45 -- Loss: 0.11193465441465378
train-epoch-step: 90-46 -- Loss: 0.1743192821741104
train-epoch-step: 90-47 -- Loss: 0.19492119550704956
train-epoch-step: 90-48 -- Loss: 0.15030106902122498
train-epoch-step: 90-49 -- Loss: 0.22129717469215393
train-epoch-step: 90-50 -- Loss: 0.12237153947353363
train-epoch-step: 90-51 -- Loss: 0.16964620351791382
train-epoch-step: 90-52 -- Loss: 0.15453556180000305
train-epoch-step: 90-53 -- Loss: 0.20846867561340332
train-epoch-step: 90-54 -- Loss: 0.2793887257575989
train-epoch-step: 90-55 -- Loss: 0.16233758628368378
train-epoch-step: 90-56 -- Loss: 0.1721397340297699
train-epoch-step: 90-57 -- Loss: 0.2324739545583725
train-epoch-step: 90-58 -- Loss: 0.28082433342933655
train-epoch-step: 90-59 -- Loss: 0.22860105335712433
train-epoch-step: 90-60 -- Loss: 0.12727826833724976
train-epoch-step: 90-61 -- Loss: 0.19467881321907043
train-epoch-step: 90-62 -- Loss: 0.1779928356409073
train-epoch-step: 90-63 -- Loss: 0.1299983263015747
train-epoch-step: 90-64 -- Loss: 0.14318440854549408
train-epoch-step: 90-65 -- Loss: 0.1769011914730072
train-epoch-step: 90-66 -- Loss: 0.105900838971138
train-epoch-step: 90-67 -- Loss: 0.1269410103559494
train-epoch-step: 90-68 -- Loss: 0.20716753602027893
train-epoch-step: 90-69 -- Loss: 0.12022237479686737
train-epoch-step: 90-70 -- Loss: 0.2117723822593689
train-epoch-step: 90-71 -- Loss: 0.2505074143409729
train-epoch-step: 90-72 -- Loss: 0.168904110789299
train-epoch-step: 90-73 -- Loss: 0.2022922933101654
train-epoch-step: 90-74 -- Loss: 0.0930805653333664
train-epoch-step: 90-75 -- Loss: 0.12719221413135529
train-epoch-step: 90-76 -- Loss: 0.1508907973766327
train-epoch-step: 90-77 -- Loss: 0.21958333253860474
train-epoch-step: 90-78 -- Loss: 0.25002533197402954
train-epoch-step: 90-79 -- Loss: 0.18058012425899506
train-epoch-step: 90-80 -- Loss: 0.24123883247375488
train-epoch-step: 90-81 -- Loss: 0.1219540536403656
train-epoch-step: 90-82 -- Loss: 0.24447624385356903
train-epoch-step: 90-83 -- Loss: 0.17082004249095917
train-epoch-step: 90-84 -- Loss: 0.1770033836364746
train-epoch-step: 90-85 -- Loss: 0.1668187975883484
train-epoch-step: 90-86 -- Loss: 0.11400559544563293
train-epoch-step: 90-87 -- Loss: 0.20432612299919128
train-epoch-step: 90-88 -- Loss: 0.13948044180870056
train-epoch-step: 90-89 -- Loss: 0.18158695101737976
train-epoch-step: 90-90 -- Loss: 0.18466202914714813
train-epoch-step: 90-91 -- Loss: 0.23729681968688965
train-epoch-step: 90-92 -- Loss: 0.1483546793460846
train-epoch-step: 90-93 -- Loss: 0.16660720109939575
train-epoch-step: 90-94 -- Loss: 0.2225349098443985
train-epoch-step: 90-95 -- Loss: 0.18537761270999908
train-epoch-step: 90-96 -- Loss: 0.2079439014196396
train-epoch-step: 90-97 -- Loss: 0.1682216227054596
train-epoch-step: 90-98 -- Loss: 0.15122005343437195
train-epoch-step: 90-99 -- Loss: 0.18107104301452637
train-epoch-step: 90-100 -- Loss: 0.1814376264810562
train-epoch-step: 90-101 -- Loss: 0.24812564253807068
train-epoch-step: 90-102 -- Loss: 0.20911452174186707
train-epoch-step: 90-103 -- Loss: 0.175438791513443
train-epoch-step: 90-104 -- Loss: 0.1434095799922943
train-epoch-step: 90-105 -- Loss: 0.2610782980918884
train-epoch-step: 90-106 -- Loss: 0.17121797800064087
train-epoch-step: 90-107 -- Loss: 0.18391470611095428
train-epoch-step: 90-108 -- Loss: 0.18264296650886536
train-epoch-step: 90-109 -- Loss: 0.14329645037651062
train-epoch-step: 90-110 -- Loss: 0.17636318504810333
train-epoch-step: 90-111 -- Loss: 0.17888161540031433
train-epoch-step: 90-112 -- Loss: 0.16675977408885956
train-epoch-step: 90-113 -- Loss: 0.16205810010433197
train-epoch-step: 90-114 -- Loss: 0.195519357919693
train-epoch-step: 90-115 -- Loss: 0.1537417471408844
train-epoch-step: 90-116 -- Loss: 0.1321984827518463
train-epoch-step: 90-117 -- Loss: 0.12392379343509674
train-epoch-step: 90-118 -- Loss: 0.18368470668792725
train-epoch-step: 90-119 -- Loss: 0.14974653720855713
train-epoch-step: 90-120 -- Loss: 0.24179697036743164
train-epoch-step: 90-121 -- Loss: 0.2217216044664383
train-epoch-step: 90-122 -- Loss: 0.2020796239376068
train-epoch-step: 90-123 -- Loss: 0.19878321886062622
train-epoch-step: 90-124 -- Loss: 0.11905523389577866
train-epoch-step: 90-125 -- Loss: 0.1487017720937729
train-epoch-step: 90-126 -- Loss: 0.22281375527381897
train-epoch-step: 90-127 -- Loss: 0.1619991660118103
train-epoch-step: 90-128 -- Loss: 0.1646307110786438
train-epoch-step: 90-129 -- Loss: 0.1397407501935959
train-epoch-step: 90-130 -- Loss: 0.18818676471710205
train-epoch-step: 90-131 -- Loss: 0.13136941194534302
train-epoch-step: 90-132 -- Loss: 0.1869196593761444
train-epoch-step: 90-133 -- Loss: 0.11271815747022629
train-epoch-step: 90-134 -- Loss: 0.1852128952741623
train-epoch-step: 90-135 -- Loss: 0.13373041152954102
train-epoch-step: 90-136 -- Loss: 0.12507788836956024
train-epoch-step: 90-137 -- Loss: 0.2321980595588684
train-epoch-step: 90-138 -- Loss: 0.25362086296081543
train-epoch-step: 90-139 -- Loss: 0.12410857528448105
train-epoch-step: 90-140 -- Loss: 0.20468518137931824
train-epoch-step: 90-141 -- Loss: 0.22672273218631744
train-epoch-step: 90-142 -- Loss: 0.1931608021259308
train-epoch-step: 90-143 -- Loss: 0.16928339004516602
train-epoch-step: 90-144 -- Loss: 0.1826705038547516
train-epoch-step: 90-145 -- Loss: 0.14064817130565643
train-epoch-step: 90-146 -- Loss: 0.18033874034881592
train-epoch-step: 90-147 -- Loss: 0.1617899388074875
train-epoch-step: 90-148 -- Loss: 0.15419161319732666
train-epoch-step: 90-149 -- Loss: 0.12019594758749008
train-epoch-step: 90-150 -- Loss: 0.17933782935142517
train-epoch-step: 90-151 -- Loss: 0.1835036724805832
train-epoch-step: 90-152 -- Loss: 0.1821029633283615
train-epoch-step: 90-153 -- Loss: 0.25480830669403076
train-epoch-step: 90-154 -- Loss: 0.1292533278465271
train-epoch-step: 90-155 -- Loss: 0.1327395737171173
train-epoch-step: 90-156 -- Loss: 0.11075664311647415
train-epoch-step: 90-157 -- Loss: 0.16074024140834808
train-epoch-step: 90-158 -- Loss: 0.15834812819957733
train-epoch-step: 90-159 -- Loss: 0.17953675985336304
train-epoch-step: 90-160 -- Loss: 0.2049819678068161
train-epoch-step: 90-161 -- Loss: 0.20529411733150482
train-epoch-step: 90-162 -- Loss: 0.2093471884727478
train-epoch-step: 90-163 -- Loss: 0.18156588077545166
train-epoch-step: 90-164 -- Loss: 0.1909698098897934
train-epoch-step: 90-165 -- Loss: 0.15561310946941376
train-epoch-step: 90-166 -- Loss: 0.11818362027406693
train-epoch-step: 90-167 -- Loss: 0.11821205914020538
train-epoch-step: 90-168 -- Loss: 0.19905972480773926
train-epoch-step: 90-169 -- Loss: 0.13517774641513824
train-epoch-step: 90-170 -- Loss: 0.19400134682655334
train-epoch-step: 90-171 -- Loss: 0.1404591202735901
train-epoch-step: 90-172 -- Loss: 0.2460712194442749
train-epoch-step: 90-173 -- Loss: 0.13199520111083984
train-epoch-step: 90-174 -- Loss: 0.23829109966754913
train-epoch-step: 90-175 -- Loss: 0.18611501157283783
train-epoch-step: 90-176 -- Loss: 0.12651963531970978
train-epoch-step: 90-177 -- Loss: 0.17406556010246277
train-epoch-step: 90-178 -- Loss: 0.17542815208435059
train-epoch-step: 90-179 -- Loss: 0.1600881814956665
train-epoch-step: 90-180 -- Loss: 0.14898300170898438
train-epoch-step: 90-181 -- Loss: 0.1634444147348404
train-epoch-step: 90-182 -- Loss: 0.1778251826763153
train-epoch-step: 90-183 -- Loss: 0.26257312297821045
train-epoch-step: 90-184 -- Loss: 0.13596980273723602
train-epoch-step: 90-185 -- Loss: 0.14904695749282837
train-epoch-step: 90-186 -- Loss: 0.1835811734199524
train-epoch-step: 90-187 -- Loss: 0.20077824592590332
train-epoch-step: 90-188 -- Loss: 0.1670597791671753
train-epoch-step: 90-189 -- Loss: 0.10013756155967712
train-epoch-step: 90-190 -- Loss: 0.18109968304634094
train-epoch-step: 90-191 -- Loss: 0.15355239808559418
train-epoch-step: 90-192 -- Loss: 0.22771868109703064
train-epoch-step: 90-193 -- Loss: 0.20199400186538696
train-epoch-step: 90-194 -- Loss: 0.1777414232492447
train-epoch-step: 90-195 -- Loss: 0.16735897958278656
train-epoch-step: 90-196 -- Loss: 0.1638425588607788
train-epoch-step: 90-197 -- Loss: 0.12741990387439728
train-epoch-step: 90-198 -- Loss: 0.13539153337478638
train-epoch-step: 90-199 -- Loss: 0.14415386319160461
train-epoch-step: 90-200 -- Loss: 0.12213636934757233
train-epoch-step: 90-201 -- Loss: 0.18872778117656708
train-epoch-step: 90-202 -- Loss: 0.13308332860469818
train-epoch-step: 90-203 -- Loss: 0.17082926630973816
train-epoch-step: 90-204 -- Loss: 0.1336911916732788
train-epoch-step: 90-205 -- Loss: 0.17577305436134338
train-epoch-step: 90-206 -- Loss: 0.1989363431930542
train-epoch-step: 90-207 -- Loss: 0.1328197866678238
train-epoch-step: 90-208 -- Loss: 0.17478977143764496
train-epoch-step: 90-209 -- Loss: 0.13912177085876465
train-epoch-step: 90-210 -- Loss: 0.1382341980934143
train-epoch-step: 90-211 -- Loss: 0.20674434304237366
train-epoch-step: 90-212 -- Loss: 0.19343489408493042
train-epoch-step: 90-213 -- Loss: 0.1235084980726242
train-epoch-step: 90-214 -- Loss: 0.14505437016487122
train-epoch-step: 90-215 -- Loss: 0.12393928319215775
train-epoch-step: 90-216 -- Loss: 0.19122307002544403
train-epoch-step: 90-217 -- Loss: 0.21089500188827515
train-epoch-step: 90-218 -- Loss: 0.13891835510730743
train-epoch-step: 90-219 -- Loss: 0.1637565940618515
train-epoch-step: 90-220 -- Loss: 0.12666676938533783
train-epoch-step: 90-221 -- Loss: 0.20444190502166748
train-epoch-step: 90-222 -- Loss: 0.11651161313056946
train-epoch-step: 90-223 -- Loss: 0.16772425174713135
train-epoch-step: 90-224 -- Loss: 0.19400577247142792
train-epoch-step: 90-225 -- Loss: 0.2607343792915344
train-epoch-step: 90-226 -- Loss: 0.2002706080675125
train-epoch-step: 90-227 -- Loss: 0.21940401196479797
train-epoch-step: 90-228 -- Loss: 0.17151165008544922
train-epoch-step: 90-229 -- Loss: 0.16767439246177673
train-epoch-step: 90-230 -- Loss: 0.15923462808132172
train-epoch-step: 90-231 -- Loss: 0.152708500623703
train-epoch-step: 90-232 -- Loss: 0.18492092192173004
train-epoch-step: 90-233 -- Loss: 0.08063701540231705
train-epoch-step: 90-234 -- Loss: 0.1668722778558731
train-epoch-step: 90-235 -- Loss: 0.13994452357292175
train-epoch-step: 90-236 -- Loss: 0.17718079686164856
train-epoch-step: 90-237 -- Loss: 0.22877056896686554
train-epoch-step: 90-238 -- Loss: 0.1542261391878128
train-epoch-step: 90-239 -- Loss: 0.1222146674990654
train-epoch-step: 90-240 -- Loss: 0.22136735916137695
train-epoch-step: 90-241 -- Loss: 0.14781317114830017
train-epoch-step: 90-242 -- Loss: 0.21685919165611267
train-epoch-step: 90-243 -- Loss: 0.23025187849998474
train-epoch-step: 90-244 -- Loss: 0.19699320197105408
train-epoch-step: 90-245 -- Loss: 0.20492613315582275
train-epoch-step: 90-246 -- Loss: 0.20829454064369202
train-epoch-step: 90-247 -- Loss: 0.20945404469966888
train-epoch-step: 90-248 -- Loss: 0.18380407989025116
train-epoch-step: 90-249 -- Loss: 0.13342221081256866
train-epoch-step: 90-250 -- Loss: 0.19705000519752502
train-epoch-step: 90-251 -- Loss: 0.10530141741037369
train-epoch-step: 90-252 -- Loss: 0.19779276847839355
train-epoch-step: 90-253 -- Loss: 0.1335519701242447
train-epoch-step: 90-254 -- Loss: 0.20953600108623505
train-epoch-step: 90-255 -- Loss: 0.1401529312133789
train-epoch-step: 90-256 -- Loss: 0.14361609518527985
train-epoch-step: 90-257 -- Loss: 0.19675825536251068
train-epoch-step: 90-258 -- Loss: 0.1394905000925064
train-epoch-step: 90-259 -- Loss: 0.1148597002029419
train-epoch-step: 90-260 -- Loss: 0.2061724215745926
train-epoch-step: 90-261 -- Loss: 0.1747649759054184
train-epoch-step: 90-262 -- Loss: 0.27621254324913025
train-epoch-step: 90-263 -- Loss: 0.1979251354932785
train-epoch-step: 90-264 -- Loss: 0.1703411191701889
train-epoch-step: 90-265 -- Loss: 0.10805262625217438
train-epoch-step: 90-266 -- Loss: 0.1519174724817276
train-epoch-step: 90-267 -- Loss: 0.12503746151924133
train-epoch-step: 90-268 -- Loss: 0.11351217329502106
train-epoch-step: 90-269 -- Loss: 0.16964754462242126
train-epoch-step: 90-270 -- Loss: 0.10550201684236526
train-epoch-step: 90-271 -- Loss: 0.1447349488735199
train-epoch-step: 90-272 -- Loss: 0.11038355529308319
train-epoch-step: 90-273 -- Loss: 0.12509630620479584
train-epoch-step: 90-274 -- Loss: 0.18023833632469177
train-epoch-step: 90-275 -- Loss: 0.18402153253555298
train-epoch-step: 90-276 -- Loss: 0.15241681039333344
train-epoch-step: 90-277 -- Loss: 0.15851269662380219
train-epoch-step: 90-278 -- Loss: 0.1322537362575531
train-epoch-step: 90-279 -- Loss: 0.13641665875911713
train-epoch-step: 90-280 -- Loss: 0.22620554268360138
train-epoch-step: 90-281 -- Loss: 0.17588575184345245
train-epoch-step: 90-282 -- Loss: 0.13848868012428284
train-epoch-step: 90-283 -- Loss: 0.11015921831130981
train-epoch-step: 90-284 -- Loss: 0.12854553759098053
train-epoch-step: 90-285 -- Loss: 0.1834661066532135
train-epoch-step: 90-286 -- Loss: 0.1494954377412796
train-epoch-step: 90-287 -- Loss: 0.1999010592699051
train-epoch-step: 90-288 -- Loss: 0.09032382816076279
train-epoch-step: 90-289 -- Loss: 0.11653337627649307
train-epoch-step: 90-290 -- Loss: 0.17575740814208984
train-epoch-step: 90-291 -- Loss: 0.11681520938873291
train-epoch-step: 90-292 -- Loss: 0.15418416261672974
train-epoch-step: 90-293 -- Loss: 0.13529781997203827
train-epoch-step: 90-294 -- Loss: 0.15280085802078247
train-epoch-step: 90-295 -- Loss: 0.25309616327285767
train-epoch-step: 90-296 -- Loss: 0.153670996427536
train-epoch-step: 90-297 -- Loss: 0.16376414895057678
train-epoch-step: 90-298 -- Loss: 0.22052884101867676
train-epoch-step: 90-299 -- Loss: 0.1363288313150406
train-epoch-step: 90-300 -- Loss: 0.15475434064865112
train-epoch-step: 90-301 -- Loss: 0.1646665334701538
train-epoch-step: 90-302 -- Loss: 0.21093213558197021
train-epoch-step: 90-303 -- Loss: 0.19597792625427246
train-epoch-step: 90-304 -- Loss: 0.12159568071365356
train-epoch-step: 90-305 -- Loss: 0.13831427693367004
train-epoch-step: 90-306 -- Loss: 0.20914018154144287
train-epoch-step: 90-307 -- Loss: 0.15844622254371643
train-epoch-step: 90-308 -- Loss: 0.2179989516735077
train-epoch-step: 90-309 -- Loss: 0.14899680018424988
train-epoch-step: 90-310 -- Loss: 0.15774719417095184
train-epoch-step: 90-311 -- Loss: 0.15883664786815643
train-epoch-step: 90-312 -- Loss: 0.2035364806652069
train-epoch-step: 90-313 -- Loss: 0.09301400929689407
train-epoch-step: 90-314 -- Loss: 0.1888483762741089
train-epoch-step: 90-315 -- Loss: 0.1613304764032364
train-epoch-step: 90-316 -- Loss: 0.14643052220344543
train-epoch-step: 90-317 -- Loss: 0.14315688610076904
train-epoch-step: 90-318 -- Loss: 0.1496880203485489
train-epoch-step: 90-319 -- Loss: 0.16088443994522095
train-epoch-step: 90-320 -- Loss: 0.11475468426942825
train-epoch-step: 90-321 -- Loss: 0.12746000289916992
train-epoch-step: 90-322 -- Loss: 0.2085810899734497
train-epoch-step: 90-323 -- Loss: 0.15115903317928314
train-epoch-step: 90-324 -- Loss: 0.24312743544578552
train-epoch-step: 90-325 -- Loss: 0.15113823115825653
train-epoch-step: 90-326 -- Loss: 0.17594623565673828
train-epoch-step: 90-327 -- Loss: 0.20249471068382263
train-epoch-step: 90-328 -- Loss: 0.18728354573249817
train-epoch-step: 90-329 -- Loss: 0.32805031538009644
train-epoch-step: 90-330 -- Loss: 0.35399672389030457
train-epoch-step: 90-331 -- Loss: 0.20832768082618713
train-epoch-step: 90-332 -- Loss: 0.09684757143259048
train-epoch-step: 90-333 -- Loss: 0.1786716729402542
train-epoch-step: 90-334 -- Loss: 0.1515856236219406
train-epoch-step: 90-335 -- Loss: 0.16885416209697723
train-epoch-step: 90-336 -- Loss: 0.14741899073123932
train-epoch-step: 90-337 -- Loss: 0.20164787769317627
train-epoch-step: 90-338 -- Loss: 0.15805236995220184
train-epoch-step: 90-339 -- Loss: 0.1408940553665161
train-epoch-step: 90-340 -- Loss: 0.1886465847492218
train-epoch-step: 90-341 -- Loss: 0.13748455047607422
train-epoch-step: 90-342 -- Loss: 0.16114039719104767
train-epoch-step: 90-343 -- Loss: 0.14630751311779022
train-epoch-step: 90-344 -- Loss: 0.16367065906524658
train-epoch-step: 90-345 -- Loss: 0.12355503439903259
train-epoch-step: 90-346 -- Loss: 0.21649307012557983
train-epoch-step: 90-347 -- Loss: 0.14801420271396637
train-epoch-step: 90-348 -- Loss: 0.1968270242214203
train-epoch-step: 90-349 -- Loss: 0.19348931312561035
train-epoch-step: 90-350 -- Loss: 0.25305888056755066
train-epoch-step: 90-351 -- Loss: 0.18960119783878326
train-epoch-step: 90-352 -- Loss: 0.12222487479448318
train-epoch-step: 90-353 -- Loss: 0.19112065434455872
train-epoch-step: 90-354 -- Loss: 0.27311891317367554
train-epoch-step: 90-355 -- Loss: 0.11586285382509232
train-epoch-step: 90-356 -- Loss: 0.11588068306446075
train-epoch-step: 90-357 -- Loss: 0.18427124619483948
train-epoch-step: 90-358 -- Loss: 0.1840343177318573
train-epoch-step: 90-359 -- Loss: 0.13615450263023376
train-epoch-step: 90-360 -- Loss: 0.12448135018348694
train-epoch-step: 90-361 -- Loss: 0.24471315741539001
train-epoch-step: 90-362 -- Loss: 0.16318732500076294
train-epoch-step: 90-363 -- Loss: 0.10569338500499725
train-epoch-step: 90-364 -- Loss: 0.1766984909772873
train-epoch-step: 90-365 -- Loss: 0.1678818017244339
train-epoch-step: 90-366 -- Loss: 0.19770890474319458
train-epoch-step: 90-367 -- Loss: 0.22580957412719727
train-epoch-step: 90-368 -- Loss: 0.19627001881599426
train-epoch-step: 90-369 -- Loss: 0.2746313214302063
train-epoch-step: 90-370 -- Loss: 0.12472071498632431
train-epoch-step: 90-371 -- Loss: 0.12143310159444809
train-epoch-step: 90-372 -- Loss: 0.14894883334636688
train-epoch-step: 90-373 -- Loss: 0.1894843429327011
train-epoch-step: 90-374 -- Loss: 0.1512841135263443
train-epoch-step: 90-375 -- Loss: 0.2574562132358551
train-epoch-step: 90-376 -- Loss: 0.1569017767906189
train-epoch-step: 90-377 -- Loss: 0.22629624605178833
train-epoch-step: 90-378 -- Loss: 0.19832855463027954
train-epoch-step: 90-379 -- Loss: 0.11510510742664337
train-epoch-step: 90-380 -- Loss: 0.09188690781593323
train-epoch-step: 90-381 -- Loss: 0.23613804578781128
train-epoch-step: 90-382 -- Loss: 0.2301737517118454
train-epoch-step: 90-383 -- Loss: 0.17042312026023865
train-epoch-step: 90-384 -- Loss: 0.20732316374778748
train-epoch-step: 90-385 -- Loss: 0.18490049242973328
train-epoch-step: 90-386 -- Loss: 0.18174654245376587
train-epoch-step: 90-387 -- Loss: 0.19613879919052124
train-epoch-step: 90-388 -- Loss: 0.1851525902748108
train-epoch-step: 90-389 -- Loss: 0.16181372106075287
train-epoch-step: 90-390 -- Loss: 0.1385301649570465
train-epoch-step: 90-391 -- Loss: 0.13944344222545624
train-epoch-step: 90-392 -- Loss: 0.17793412506580353
train-epoch-step: 90-393 -- Loss: 0.15386423468589783
train-epoch-step: 90-394 -- Loss: 0.19533950090408325
train-epoch-step: 90-395 -- Loss: 0.1721390187740326
train-epoch-step: 90-396 -- Loss: 0.12256185710430145
train-epoch-step: 90-397 -- Loss: 0.12261558324098587
train-epoch-step: 90-398 -- Loss: 0.19879606366157532
train-epoch-step: 90-399 -- Loss: 0.1697583794593811
train-epoch-step: 90-400 -- Loss: 0.26578888297080994
train-epoch-step: 90-401 -- Loss: 0.11642498522996902
train-epoch-step: 90-402 -- Loss: 0.24858984351158142
train-epoch-step: 90-403 -- Loss: 0.1528591513633728
train-epoch-step: 90-404 -- Loss: 0.13472244143486023
train-epoch-step: 90-405 -- Loss: 0.14334847033023834
train-epoch-step: 90-406 -- Loss: 0.1658279299736023
train-epoch-step: 90-407 -- Loss: 0.10907784849405289
train-epoch-step: 90-408 -- Loss: 0.15894845128059387
train-epoch-step: 90-409 -- Loss: 0.16923223435878754
train-epoch-step: 90-410 -- Loss: 0.16720075905323029
train-epoch-step: 90-411 -- Loss: 0.18741479516029358
train-epoch-step: 90-412 -- Loss: 0.12307330965995789
train-epoch-step: 90-413 -- Loss: 0.14206819236278534
train-epoch-step: 90-414 -- Loss: 0.12575696408748627
train-epoch-step: 90-415 -- Loss: 0.13058573007583618
train-epoch-step: 90-416 -- Loss: 0.25786206126213074
train-epoch-step: 90-417 -- Loss: 0.1826062947511673
train-epoch-step: 90-418 -- Loss: 0.22477994859218597
train-epoch-step: 90-419 -- Loss: 0.1641736775636673
train-epoch-step: 90-420 -- Loss: 0.1482963263988495
train-epoch-step: 90-421 -- Loss: 0.1795710325241089
train-epoch-step: 90-422 -- Loss: 0.14584477245807648
train-epoch-step: 90-423 -- Loss: 0.17407160997390747
train-epoch-step: 90-424 -- Loss: 0.1361885964870453
train-epoch-step: 90-425 -- Loss: 0.17953191697597504
train-epoch-step: 90-426 -- Loss: 0.16319195926189423
train-epoch-step: 90-427 -- Loss: 0.11671215295791626
train-epoch-step: 90-428 -- Loss: 0.18963737785816193
train-epoch-step: 90-429 -- Loss: 0.17079174518585205
train-epoch-step: 90-430 -- Loss: 0.13886788487434387
train-epoch-step: 90-431 -- Loss: 0.156712144613266
train-epoch-step: 90-432 -- Loss: 0.2319435477256775
train-epoch-step: 90-433 -- Loss: 0.13190843164920807
train-epoch-step: 90-434 -- Loss: 0.1239643394947052
train-epoch-step: 90-435 -- Loss: 0.15582776069641113
train-epoch-step: 90-436 -- Loss: 0.16124245524406433
train-epoch-step: 90-437 -- Loss: 0.12660938501358032
train-epoch-step: 90-438 -- Loss: 0.16124475002288818
train-epoch-step: 90-439 -- Loss: 0.25654539465904236
train-epoch-step: 90-440 -- Loss: 0.12782631814479828
train-epoch-step: 90-441 -- Loss: 0.1997184455394745
train-epoch-step: 90-442 -- Loss: 0.16916722059249878
train-epoch-step: 90-443 -- Loss: 0.14832033216953278
train-epoch-step: 90-444 -- Loss: 0.1683647483587265
train-epoch-step: 90-445 -- Loss: 0.17653462290763855
train-epoch-step: 90-446 -- Loss: 0.15503346920013428
train-epoch-step: 90-447 -- Loss: 0.183311328291893
train-epoch-step: 90-448 -- Loss: 0.22324921190738678
train-epoch-step: 90-449 -- Loss: 0.18786107003688812
train-epoch-step: 90-450 -- Loss: 0.1756037473678589
train-epoch-step: 90-451 -- Loss: 0.14227186143398285
train-epoch-step: 90-452 -- Loss: 0.12683086097240448
train-epoch-step: 90-453 -- Loss: 0.09391691535711288
train-epoch-step: 90-454 -- Loss: 0.24081966280937195
train-epoch-step: 90-455 -- Loss: 0.1247328445315361
train-epoch-step: 90-456 -- Loss: 0.11790461838245392
train-epoch-step: 90-457 -- Loss: 0.21848557889461517
train-epoch-step: 90-458 -- Loss: 0.2198345810174942
train-epoch-step: 90-459 -- Loss: 0.22149065136909485
train-epoch-step: 90-460 -- Loss: 0.12614721059799194
train-epoch-step: 90-461 -- Loss: 0.13061287999153137
train-epoch-step: 90-462 -- Loss: 0.15609389543533325
train-epoch-step: 90-463 -- Loss: 0.13768574595451355
train-epoch-step: 90-464 -- Loss: 0.1615736037492752
train-epoch-step: 90-465 -- Loss: 0.2345706820487976
train-epoch-step: 90-466 -- Loss: 0.20443905889987946
train-epoch-step: 90-467 -- Loss: 0.1131572276353836
train-epoch-step: 90-468 -- Loss: 0.1648532748222351
train-epoch-step: 90-469 -- Loss: 0.20498260855674744
train-epoch-step: 90-470 -- Loss: 0.16650423407554626
train-epoch-step: 90-471 -- Loss: 0.18499526381492615
train-epoch-step: 90-472 -- Loss: 0.15523777902126312
train-epoch-step: 90-473 -- Loss: 0.15102672576904297
train-epoch-step: 90-474 -- Loss: 0.12304219603538513
train-epoch-step: 90-475 -- Loss: 0.10855600237846375
train-epoch-step: 90-476 -- Loss: 0.20148995518684387
train-epoch-step: 90-477 -- Loss: 0.1933297961950302
train-epoch-step: 90-478 -- Loss: 0.1927807480096817
train-epoch-step: 90-479 -- Loss: 0.1396617740392685
train-epoch-step: 90-480 -- Loss: 0.188213050365448
train-epoch-step: 90-481 -- Loss: 0.2814120054244995
train-epoch-step: 90-482 -- Loss: 0.2573856711387634
train-epoch-step: 90-483 -- Loss: 0.1748899668455124
train-epoch-step: 90-484 -- Loss: 0.21213829517364502
train-epoch-step: 90-485 -- Loss: 0.12648449838161469
train-epoch-step: 90-486 -- Loss: 0.22631341218948364
train-epoch-step: 90-487 -- Loss: 0.22577476501464844
train-epoch-step: 90-488 -- Loss: 0.18645545840263367
train-epoch-step: 90-489 -- Loss: 0.21676939725875854
train-epoch-step: 90-490 -- Loss: 0.13225099444389343
train-epoch-step: 90-491 -- Loss: 0.13446944952011108
train-epoch-step: 90-492 -- Loss: 0.12447798997163773
train-epoch-step: 90-493 -- Loss: 0.1884692758321762
train-epoch-step: 90-494 -- Loss: 0.2047475278377533
train-epoch-step: 90-495 -- Loss: 0.19926415383815765
train-epoch-step: 90-496 -- Loss: 0.1386403888463974
train-epoch-step: 90-497 -- Loss: 0.19245979189872742
train-epoch-step: 90-498 -- Loss: 0.14743518829345703
train-epoch-step: 90-499 -- Loss: 0.18494920432567596
train-epoch-step: 90-500 -- Loss: 0.15149815380573273
train-epoch-step: 90-501 -- Loss: 0.21320092678070068
train-epoch-step: 90-502 -- Loss: 0.14934273064136505
train-epoch-step: 90-503 -- Loss: 0.21647505462169647
train-epoch-step: 90-504 -- Loss: 0.13196444511413574
train-epoch-step: 90-505 -- Loss: 0.17314088344573975
train-epoch-step: 90-506 -- Loss: 0.11600635945796967
train-epoch-step: 90-507 -- Loss: 0.1789335012435913
train-epoch-step: 90-508 -- Loss: 0.16828131675720215
train-epoch-step: 90-509 -- Loss: 0.1684625744819641
train-epoch-step: 90-510 -- Loss: 0.12669958174228668
train-epoch-step: 90-511 -- Loss: 0.2104407399892807
train-epoch-step: 90-512 -- Loss: 0.17658722400665283
train-epoch-step: 90-513 -- Loss: 0.18893831968307495
train-epoch-step: 90-514 -- Loss: 0.14538444578647614
train-epoch-step: 90-515 -- Loss: 0.15118466317653656
train-epoch-step: 90-516 -- Loss: 0.18249055743217468
train-epoch-step: 90-517 -- Loss: 0.1684257686138153
train-epoch-step: 90-518 -- Loss: 0.1361931562423706
train-epoch-step: 90-519 -- Loss: 0.1379622370004654
train-epoch-step: 90-520 -- Loss: 0.1811649352312088
train-epoch-step: 90-521 -- Loss: 0.22955282032489777
train-epoch-step: 90-522 -- Loss: 0.1691095381975174
train-epoch-step: 90-523 -- Loss: 0.15777279436588287
train-epoch-step: 90-524 -- Loss: 0.16501159965991974
train-epoch-step: 90-525 -- Loss: 0.1908872425556183
train-epoch-step: 90-526 -- Loss: 0.12652131915092468
train-epoch-step: 90-527 -- Loss: 0.1477629542350769
train-epoch-step: 90-528 -- Loss: 0.1532515287399292
train-epoch-step: 90-529 -- Loss: 0.15356263518333435
train-epoch-step: 90-530 -- Loss: 0.16427990794181824
train-epoch-step: 90-531 -- Loss: 0.19441670179367065
train-epoch-step: 90-532 -- Loss: 0.16600830852985382
train-epoch-step: 90-533 -- Loss: 0.17381851375102997
train-epoch-step: 90-534 -- Loss: 0.1316521316766739
train-epoch-step: 90-535 -- Loss: 0.25527310371398926
train-epoch-step: 90-536 -- Loss: 0.15108969807624817
train-epoch-step: 90-537 -- Loss: 0.15013569593429565
train-epoch-step: 90-538 -- Loss: 0.09890032559633255
train-epoch-step: 90-539 -- Loss: 0.1782328337430954
train-epoch-step: 90-540 -- Loss: 0.13402922451496124
train-epoch-step: 90-541 -- Loss: 0.2057863473892212
train-epoch-step: 90-542 -- Loss: 0.2167789191007614
train-epoch-step: 90-543 -- Loss: 0.16460828483104706
train-epoch-step: 90-544 -- Loss: 0.2368158996105194
train-epoch-step: 90-545 -- Loss: 0.19839182496070862
train-epoch-step: 90-546 -- Loss: 0.20860907435417175
train-epoch-step: 90-547 -- Loss: 0.179742693901062
train-epoch-step: 90-548 -- Loss: 0.08889828622341156
train-epoch-step: 90-549 -- Loss: 0.15204045176506042
train-epoch-step: 90-550 -- Loss: 0.22074376046657562
train-epoch-step: 90-551 -- Loss: 0.1589866280555725
train-epoch-step: 90-552 -- Loss: 0.1280006468296051
train-epoch-step: 90-553 -- Loss: 0.18462347984313965
train-epoch-step: 90-554 -- Loss: 0.1829376518726349
train-epoch-step: 90-555 -- Loss: 0.20605432987213135
train-epoch-step: 90-556 -- Loss: 0.13934969902038574
train-epoch-step: 90-557 -- Loss: 0.22767743468284607
train-epoch-step: 90-558 -- Loss: 0.2368777096271515
train-epoch-step: 90-559 -- Loss: 0.1366952359676361
train-epoch-step: 90-560 -- Loss: 0.20182693004608154
train-epoch-step: 90-561 -- Loss: 0.19846203923225403
train-epoch-step: 90-562 -- Loss: 0.1789671778678894
train-epoch-step: 90-563 -- Loss: 0.18389417231082916
train-epoch-step: 90-564 -- Loss: 0.1123390793800354
train-epoch-step: 90-565 -- Loss: 0.2030266970396042
train-epoch-step: 90-566 -- Loss: 0.16713355481624603
train-epoch-step: 90-567 -- Loss: 0.2103588581085205
train-epoch-step: 90-568 -- Loss: 0.15841856598854065
train-epoch-step: 90-569 -- Loss: 0.2450949251651764
train-epoch-step: 90-570 -- Loss: 0.16743089258670807
train-epoch-step: 90-571 -- Loss: 0.20615963637828827
train-epoch-step: 90-572 -- Loss: 0.23868785798549652
train-epoch-step: 90-573 -- Loss: 0.19182054698467255
train-epoch-step: 90-574 -- Loss: 0.2781853675842285
train-epoch-step: 90-575 -- Loss: 0.300362229347229
train-epoch-step: 90-576 -- Loss: 0.11943977326154709
train-epoch-step: 90-577 -- Loss: 0.16600655019283295
train-epoch-step: 90-578 -- Loss: 0.21679767966270447
train-epoch-step: 90-579 -- Loss: 0.16245073080062866
train-epoch-step: 90-580 -- Loss: 0.17744368314743042
train-epoch-step: 90-581 -- Loss: 0.15602323412895203
train-epoch-step: 90-582 -- Loss: 0.20482608675956726
train-epoch-step: 90-583 -- Loss: 0.23603662848472595
train-epoch-step: 90-584 -- Loss: 0.15646541118621826
train-epoch-step: 90-585 -- Loss: 0.2164933830499649
train-epoch-step: 90-586 -- Loss: 0.2537434697151184
train-epoch-step: 90-587 -- Loss: 0.1549685299396515
train-epoch-step: 90-588 -- Loss: 0.12923172116279602
val-epoch-step: 90-589 -- Loss: 0.21794874966144562
val-epoch-step: 90-590 -- Loss: 0.15220220386981964
val-epoch-step: 90-591 -- Loss: 0.24165257811546326
val-epoch-step: 90-592 -- Loss: 0.17651817202568054
val-epoch-step: 90-593 -- Loss: 0.1748279631137848
val-epoch-step: 90-594 -- Loss: 0.4006195068359375
val-epoch-step: 90-595 -- Loss: 0.1843005120754242
val-epoch-step: 90-596 -- Loss: 0.29402005672454834
val-epoch-step: 90-597 -- Loss: 0.1663961112499237
val-epoch-step: 90-598 -- Loss: 0.15053969621658325
val-epoch-step: 90-599 -- Loss: 0.1883484572172165
val-epoch-step: 90-600 -- Loss: 0.18115437030792236
val-epoch-step: 90-601 -- Loss: 0.16192516684532166
val-epoch-step: 90-602 -- Loss: 0.13579927384853363
val-epoch-step: 90-603 -- Loss: 0.19171932339668274
val-epoch-step: 90-604 -- Loss: 0.15522077679634094
val-epoch-step: 90-605 -- Loss: 0.15724702179431915
val-epoch-step: 90-606 -- Loss: 0.262881338596344
val-epoch-step: 90-607 -- Loss: 0.1429406702518463
val-epoch-step: 90-608 -- Loss: 0.2596745491027832
val-epoch-step: 90-609 -- Loss: 0.17476342618465424
val-epoch-step: 90-610 -- Loss: 0.18668772280216217
val-epoch-step: 90-611 -- Loss: 0.15957842767238617
val-epoch-step: 90-612 -- Loss: 0.4328439235687256
val-epoch-step: 90-613 -- Loss: 0.17954498529434204
val-epoch-step: 90-614 -- Loss: 0.1802607923746109
val-epoch-step: 90-615 -- Loss: 0.16921788454055786
val-epoch-step: 90-616 -- Loss: 0.14736182987689972
val-epoch-step: 90-617 -- Loss: 0.190922811627388
val-epoch-step: 90-618 -- Loss: 0.22541102766990662
val-epoch-step: 90-619 -- Loss: 0.21945182979106903
val-epoch-step: 90-620 -- Loss: 0.15252193808555603
val-epoch-step: 90-621 -- Loss: 0.12377671897411346
val-epoch-step: 90-622 -- Loss: 0.1484878957271576
val-epoch-step: 90-623 -- Loss: 0.1510690450668335
val-epoch-step: 90-624 -- Loss: 0.14446108043193817
val-epoch-step: 90-625 -- Loss: 0.1677912324666977
val-epoch-step: 90-626 -- Loss: 0.15033486485481262
val-epoch-step: 90-627 -- Loss: 0.1823122799396515
val-epoch-step: 90-628 -- Loss: 0.6350588798522949
val-epoch-step: 90-629 -- Loss: 0.22942572832107544
val-epoch-step: 90-630 -- Loss: 0.34893307089805603
val-epoch-step: 90-631 -- Loss: 0.14867380261421204
val-epoch-step: 90-632 -- Loss: 0.20181876420974731
val-epoch-step: 90-633 -- Loss: 0.16842147707939148
val-epoch-step: 90-634 -- Loss: 0.13213574886322021
val-epoch-step: 90-635 -- Loss: 0.11353194713592529
val-epoch-step: 90-636 -- Loss: 0.1741005778312683
val-epoch-step: 90-637 -- Loss: 0.17834870517253876
val-epoch-step: 90-638 -- Loss: 0.1754274070262909
val-epoch-step: 90-639 -- Loss: 0.2595534324645996
val-epoch-step: 90-640 -- Loss: 0.27141618728637695
val-epoch-step: 90-641 -- Loss: 0.13361063599586487
val-epoch-step: 90-642 -- Loss: 0.1816575527191162
val-epoch-step: 90-643 -- Loss: 0.21605920791625977
val-epoch-step: 90-644 -- Loss: 0.16782096028327942
val-epoch-step: 90-645 -- Loss: 0.22061532735824585
val-epoch-step: 90-646 -- Loss: 0.13359294831752777
val-epoch-step: 90-647 -- Loss: 0.13816961646080017
val-epoch-step: 90-648 -- Loss: 0.16205787658691406
val-epoch-step: 90-649 -- Loss: 0.21395963430404663
val-epoch-step: 90-650 -- Loss: 0.2523919939994812
val-epoch-step: 90-651 -- Loss: 0.14701375365257263
val-epoch-step: 90-652 -- Loss: 0.16098317503929138
val-epoch-step: 90-653 -- Loss: 0.1981392800807953
val-epoch-step: 90-654 -- Loss: 0.12293113023042679
Epoch: 90 -- Train Loss: tensor(0.1394, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.04 -- Val Loss: tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.04
                         Test Loss: 0.0 -- Test Acc: 72.04
train-epoch-step: 91-0 -- Loss: 0.21966686844825745
train-epoch-step: 91-1 -- Loss: 0.1439124345779419
train-epoch-step: 91-2 -- Loss: 0.19422519207000732
train-epoch-step: 91-3 -- Loss: 0.15498200058937073
train-epoch-step: 91-4 -- Loss: 0.16974635422229767
train-epoch-step: 91-5 -- Loss: 0.2162686586380005
train-epoch-step: 91-6 -- Loss: 0.2221257984638214
train-epoch-step: 91-7 -- Loss: 0.1672462821006775
train-epoch-step: 91-8 -- Loss: 0.18710863590240479
train-epoch-step: 91-9 -- Loss: 0.2648698389530182
train-epoch-step: 91-10 -- Loss: 0.18847405910491943
train-epoch-step: 91-11 -- Loss: 0.17760556936264038
train-epoch-step: 91-12 -- Loss: 0.15338602662086487
train-epoch-step: 91-13 -- Loss: 0.17457857728004456
train-epoch-step: 91-14 -- Loss: 0.16322919726371765
train-epoch-step: 91-15 -- Loss: 0.1620381623506546
train-epoch-step: 91-16 -- Loss: 0.16195207834243774
train-epoch-step: 91-17 -- Loss: 0.24392379820346832
train-epoch-step: 91-18 -- Loss: 0.1924801766872406
train-epoch-step: 91-19 -- Loss: 0.1320023238658905
train-epoch-step: 91-20 -- Loss: 0.22310306131839752
train-epoch-step: 91-21 -- Loss: 0.2476036548614502
train-epoch-step: 91-22 -- Loss: 0.13672122359275818
train-epoch-step: 91-23 -- Loss: 0.14900657534599304
train-epoch-step: 91-24 -- Loss: 0.12639069557189941
train-epoch-step: 91-25 -- Loss: 0.21439878642559052
train-epoch-step: 91-26 -- Loss: 0.18981465697288513
train-epoch-step: 91-27 -- Loss: 0.22616413235664368
train-epoch-step: 91-28 -- Loss: 0.12053779512643814
train-epoch-step: 91-29 -- Loss: 0.24162177741527557
train-epoch-step: 91-30 -- Loss: 0.10673299431800842
train-epoch-step: 91-31 -- Loss: 0.12995241582393646
train-epoch-step: 91-32 -- Loss: 0.17099489271640778
train-epoch-step: 91-33 -- Loss: 0.2747308015823364
train-epoch-step: 91-34 -- Loss: 0.17396174371242523
train-epoch-step: 91-35 -- Loss: 0.24236081540584564
train-epoch-step: 91-36 -- Loss: 0.13437971472740173
train-epoch-step: 91-37 -- Loss: 0.13352982699871063
train-epoch-step: 91-38 -- Loss: 0.1728726178407669
train-epoch-step: 91-39 -- Loss: 0.21400856971740723
train-epoch-step: 91-40 -- Loss: 0.1939365565776825
train-epoch-step: 91-41 -- Loss: 0.20911824703216553
train-epoch-step: 91-42 -- Loss: 0.14408114552497864
train-epoch-step: 91-43 -- Loss: 0.25625380873680115
train-epoch-step: 91-44 -- Loss: 0.12963619828224182
train-epoch-step: 91-45 -- Loss: 0.11794012784957886
train-epoch-step: 91-46 -- Loss: 0.16600051522254944
train-epoch-step: 91-47 -- Loss: 0.20348665118217468
train-epoch-step: 91-48 -- Loss: 0.15328435599803925
train-epoch-step: 91-49 -- Loss: 0.22483114898204803
train-epoch-step: 91-50 -- Loss: 0.10873137414455414
train-epoch-step: 91-51 -- Loss: 0.17929580807685852
train-epoch-step: 91-52 -- Loss: 0.1581014096736908
train-epoch-step: 91-53 -- Loss: 0.20437957346439362
train-epoch-step: 91-54 -- Loss: 0.2847331166267395
train-epoch-step: 91-55 -- Loss: 0.16041556000709534
train-epoch-step: 91-56 -- Loss: 0.17235764861106873
train-epoch-step: 91-57 -- Loss: 0.23167675733566284
train-epoch-step: 91-58 -- Loss: 0.2767948508262634
train-epoch-step: 91-59 -- Loss: 0.2286292463541031
train-epoch-step: 91-60 -- Loss: 0.12920822203159332
train-epoch-step: 91-61 -- Loss: 0.1965649276971817
train-epoch-step: 91-62 -- Loss: 0.17978321015834808
train-epoch-step: 91-63 -- Loss: 0.13006290793418884
train-epoch-step: 91-64 -- Loss: 0.1412348598241806
train-epoch-step: 91-65 -- Loss: 0.17488029599189758
train-epoch-step: 91-66 -- Loss: 0.10675227642059326
train-epoch-step: 91-67 -- Loss: 0.12205921113491058
train-epoch-step: 91-68 -- Loss: 0.2088903784751892
train-epoch-step: 91-69 -- Loss: 0.12404771149158478
train-epoch-step: 91-70 -- Loss: 0.21894025802612305
train-epoch-step: 91-71 -- Loss: 0.2482883334159851
train-epoch-step: 91-72 -- Loss: 0.16867177188396454
train-epoch-step: 91-73 -- Loss: 0.20031416416168213
train-epoch-step: 91-74 -- Loss: 0.09325669705867767
train-epoch-step: 91-75 -- Loss: 0.12452458590269089
train-epoch-step: 91-76 -- Loss: 0.14799851179122925
train-epoch-step: 91-77 -- Loss: 0.22325915098190308
train-epoch-step: 91-78 -- Loss: 0.26638078689575195
train-epoch-step: 91-79 -- Loss: 0.18277005851268768
train-epoch-step: 91-80 -- Loss: 0.239684596657753
train-epoch-step: 91-81 -- Loss: 0.1236080601811409
train-epoch-step: 91-82 -- Loss: 0.25483691692352295
train-epoch-step: 91-83 -- Loss: 0.18081071972846985
train-epoch-step: 91-84 -- Loss: 0.18589608371257782
train-epoch-step: 91-85 -- Loss: 0.17175984382629395
train-epoch-step: 91-86 -- Loss: 0.11896489560604095
train-epoch-step: 91-87 -- Loss: 0.20943772792816162
train-epoch-step: 91-88 -- Loss: 0.1363207846879959
train-epoch-step: 91-89 -- Loss: 0.1960337907075882
train-epoch-step: 91-90 -- Loss: 0.18485252559185028
train-epoch-step: 91-91 -- Loss: 0.23352153599262238
train-epoch-step: 91-92 -- Loss: 0.15495701134204865
train-epoch-step: 91-93 -- Loss: 0.17627596855163574
train-epoch-step: 91-94 -- Loss: 0.218222975730896
train-epoch-step: 91-95 -- Loss: 0.18495896458625793
train-epoch-step: 91-96 -- Loss: 0.21508660912513733
train-epoch-step: 91-97 -- Loss: 0.17449146509170532
train-epoch-step: 91-98 -- Loss: 0.15177176892757416
train-epoch-step: 91-99 -- Loss: 0.18761920928955078
train-epoch-step: 91-100 -- Loss: 0.18594661355018616
train-epoch-step: 91-101 -- Loss: 0.25329136848449707
train-epoch-step: 91-102 -- Loss: 0.2085854709148407
train-epoch-step: 91-103 -- Loss: 0.18243640661239624
train-epoch-step: 91-104 -- Loss: 0.14374658465385437
train-epoch-step: 91-105 -- Loss: 0.25248050689697266
train-epoch-step: 91-106 -- Loss: 0.18301841616630554
train-epoch-step: 91-107 -- Loss: 0.1834021806716919
train-epoch-step: 91-108 -- Loss: 0.19494709372520447
train-epoch-step: 91-109 -- Loss: 0.14318621158599854
train-epoch-step: 91-110 -- Loss: 0.1831645369529724
train-epoch-step: 91-111 -- Loss: 0.1767645925283432
train-epoch-step: 91-112 -- Loss: 0.17534340918064117
train-epoch-step: 91-113 -- Loss: 0.1607079654932022
train-epoch-step: 91-114 -- Loss: 0.193240687251091
train-epoch-step: 91-115 -- Loss: 0.15664198994636536
train-epoch-step: 91-116 -- Loss: 0.1376783847808838
train-epoch-step: 91-117 -- Loss: 0.1261642724275589
train-epoch-step: 91-118 -- Loss: 0.19193291664123535
train-epoch-step: 91-119 -- Loss: 0.14754045009613037
train-epoch-step: 91-120 -- Loss: 0.25160354375839233
train-epoch-step: 91-121 -- Loss: 0.25096672773361206
train-epoch-step: 91-122 -- Loss: 0.22347520291805267
train-epoch-step: 91-123 -- Loss: 0.20395340025424957
train-epoch-step: 91-124 -- Loss: 0.12225077301263809
train-epoch-step: 91-125 -- Loss: 0.1489650458097458
train-epoch-step: 91-126 -- Loss: 0.22712823748588562
train-epoch-step: 91-127 -- Loss: 0.17063571512699127
train-epoch-step: 91-128 -- Loss: 0.16806969046592712
train-epoch-step: 91-129 -- Loss: 0.14216949045658112
train-epoch-step: 91-130 -- Loss: 0.20510587096214294
train-epoch-step: 91-131 -- Loss: 0.1352873295545578
train-epoch-step: 91-132 -- Loss: 0.18334132432937622
train-epoch-step: 91-133 -- Loss: 0.11336424946784973
train-epoch-step: 91-134 -- Loss: 0.18576397001743317
train-epoch-step: 91-135 -- Loss: 0.13420632481575012
train-epoch-step: 91-136 -- Loss: 0.12509822845458984
train-epoch-step: 91-137 -- Loss: 0.23993352055549622
train-epoch-step: 91-138 -- Loss: 0.2595411241054535
train-epoch-step: 91-139 -- Loss: 0.13145436346530914
train-epoch-step: 91-140 -- Loss: 0.20152990520000458
train-epoch-step: 91-141 -- Loss: 0.23352541029453278
train-epoch-step: 91-142 -- Loss: 0.19753900170326233
train-epoch-step: 91-143 -- Loss: 0.17399249970912933
train-epoch-step: 91-144 -- Loss: 0.1782902479171753
train-epoch-step: 91-145 -- Loss: 0.14414961636066437
train-epoch-step: 91-146 -- Loss: 0.1757814884185791
train-epoch-step: 91-147 -- Loss: 0.16558392345905304
train-epoch-step: 91-148 -- Loss: 0.1586490273475647
train-epoch-step: 91-149 -- Loss: 0.12088818103075027
train-epoch-step: 91-150 -- Loss: 0.1808748096227646
train-epoch-step: 91-151 -- Loss: 0.1874646544456482
train-epoch-step: 91-152 -- Loss: 0.18607304990291595
train-epoch-step: 91-153 -- Loss: 0.2647807002067566
train-epoch-step: 91-154 -- Loss: 0.13054029643535614
train-epoch-step: 91-155 -- Loss: 0.13157537579536438
train-epoch-step: 91-156 -- Loss: 0.11469610035419464
train-epoch-step: 91-157 -- Loss: 0.17593613266944885
train-epoch-step: 91-158 -- Loss: 0.16101861000061035
train-epoch-step: 91-159 -- Loss: 0.17865830659866333
train-epoch-step: 91-160 -- Loss: 0.2118448168039322
train-epoch-step: 91-161 -- Loss: 0.2024877667427063
train-epoch-step: 91-162 -- Loss: 0.20907224714756012
train-epoch-step: 91-163 -- Loss: 0.1833910495042801
train-epoch-step: 91-164 -- Loss: 0.19192200899124146
train-epoch-step: 91-165 -- Loss: 0.15858718752861023
train-epoch-step: 91-166 -- Loss: 0.11706969141960144
train-epoch-step: 91-167 -- Loss: 0.11981292068958282
train-epoch-step: 91-168 -- Loss: 0.19463586807250977
train-epoch-step: 91-169 -- Loss: 0.1368948072195053
train-epoch-step: 91-170 -- Loss: 0.1920160949230194
train-epoch-step: 91-171 -- Loss: 0.1412448137998581
train-epoch-step: 91-172 -- Loss: 0.26185283064842224
train-epoch-step: 91-173 -- Loss: 0.12731586396694183
train-epoch-step: 91-174 -- Loss: 0.2422277331352234
train-epoch-step: 91-175 -- Loss: 0.1840619444847107
train-epoch-step: 91-176 -- Loss: 0.13289761543273926
train-epoch-step: 91-177 -- Loss: 0.17221327126026154
train-epoch-step: 91-178 -- Loss: 0.17780426144599915
train-epoch-step: 91-179 -- Loss: 0.16957123577594757
train-epoch-step: 91-180 -- Loss: 0.1492997258901596
train-epoch-step: 91-181 -- Loss: 0.16231846809387207
train-epoch-step: 91-182 -- Loss: 0.20453527569770813
train-epoch-step: 91-183 -- Loss: 0.28056401014328003
train-epoch-step: 91-184 -- Loss: 0.14277921617031097
train-epoch-step: 91-185 -- Loss: 0.14525598287582397
train-epoch-step: 91-186 -- Loss: 0.21284425258636475
train-epoch-step: 91-187 -- Loss: 0.21310383081436157
train-epoch-step: 91-188 -- Loss: 0.17217788100242615
train-epoch-step: 91-189 -- Loss: 0.10439712554216385
train-epoch-step: 91-190 -- Loss: 0.18396811187267303
train-epoch-step: 91-191 -- Loss: 0.19341617822647095
train-epoch-step: 91-192 -- Loss: 0.22855454683303833
train-epoch-step: 91-193 -- Loss: 0.20805230736732483
train-epoch-step: 91-194 -- Loss: 0.17951807379722595
train-epoch-step: 91-195 -- Loss: 0.16524703800678253
train-epoch-step: 91-196 -- Loss: 0.17836546897888184
train-epoch-step: 91-197 -- Loss: 0.13140226900577545
train-epoch-step: 91-198 -- Loss: 0.1287330538034439
train-epoch-step: 91-199 -- Loss: 0.144130676984787
train-epoch-step: 91-200 -- Loss: 0.12634412944316864
train-epoch-step: 91-201 -- Loss: 0.18496078252792358
train-epoch-step: 91-202 -- Loss: 0.1361353099346161
train-epoch-step: 91-203 -- Loss: 0.1783309429883957
train-epoch-step: 91-204 -- Loss: 0.13141348958015442
train-epoch-step: 91-205 -- Loss: 0.19115543365478516
train-epoch-step: 91-206 -- Loss: 0.20469120144844055
train-epoch-step: 91-207 -- Loss: 0.1472359150648117
train-epoch-step: 91-208 -- Loss: 0.18492284417152405
train-epoch-step: 91-209 -- Loss: 0.14576253294944763
train-epoch-step: 91-210 -- Loss: 0.1307860016822815
train-epoch-step: 91-211 -- Loss: 0.21299153566360474
train-epoch-step: 91-212 -- Loss: 0.1955661177635193
train-epoch-step: 91-213 -- Loss: 0.12628823518753052
train-epoch-step: 91-214 -- Loss: 0.14608274400234222
train-epoch-step: 91-215 -- Loss: 0.1248631626367569
train-epoch-step: 91-216 -- Loss: 0.20313048362731934
train-epoch-step: 91-217 -- Loss: 0.22706033289432526
train-epoch-step: 91-218 -- Loss: 0.14328858256340027
train-epoch-step: 91-219 -- Loss: 0.16228003799915314
train-epoch-step: 91-220 -- Loss: 0.1320917010307312
train-epoch-step: 91-221 -- Loss: 0.20197495818138123
train-epoch-step: 91-222 -- Loss: 0.115963414311409
train-epoch-step: 91-223 -- Loss: 0.1721663475036621
train-epoch-step: 91-224 -- Loss: 0.19151560962200165
train-epoch-step: 91-225 -- Loss: 0.25757846236228943
train-epoch-step: 91-226 -- Loss: 0.20807905495166779
train-epoch-step: 91-227 -- Loss: 0.21984151005744934
train-epoch-step: 91-228 -- Loss: 0.17072634398937225
train-epoch-step: 91-229 -- Loss: 0.16834358870983124
train-epoch-step: 91-230 -- Loss: 0.1611233353614807
train-epoch-step: 91-231 -- Loss: 0.15521059930324554
train-epoch-step: 91-232 -- Loss: 0.20977455377578735
train-epoch-step: 91-233 -- Loss: 0.08377599716186523
train-epoch-step: 91-234 -- Loss: 0.16462719440460205
train-epoch-step: 91-235 -- Loss: 0.14361754059791565
train-epoch-step: 91-236 -- Loss: 0.17562302947044373
train-epoch-step: 91-237 -- Loss: 0.23325368762016296
train-epoch-step: 91-238 -- Loss: 0.1552102416753769
train-epoch-step: 91-239 -- Loss: 0.12701725959777832
train-epoch-step: 91-240 -- Loss: 0.22068652510643005
train-epoch-step: 91-241 -- Loss: 0.15207591652870178
train-epoch-step: 91-242 -- Loss: 0.21716798841953278
train-epoch-step: 91-243 -- Loss: 0.2310064136981964
train-epoch-step: 91-244 -- Loss: 0.200041264295578
train-epoch-step: 91-245 -- Loss: 0.20983698964118958
train-epoch-step: 91-246 -- Loss: 0.21413986384868622
train-epoch-step: 91-247 -- Loss: 0.21863894164562225
train-epoch-step: 91-248 -- Loss: 0.18638642132282257
train-epoch-step: 91-249 -- Loss: 0.13707949221134186
train-epoch-step: 91-250 -- Loss: 0.1910448670387268
train-epoch-step: 91-251 -- Loss: 0.10819374024868011
train-epoch-step: 91-252 -- Loss: 0.19622445106506348
train-epoch-step: 91-253 -- Loss: 0.13535116612911224
train-epoch-step: 91-254 -- Loss: 0.21212640404701233
train-epoch-step: 91-255 -- Loss: 0.1439242959022522
train-epoch-step: 91-256 -- Loss: 0.15109355747699738
train-epoch-step: 91-257 -- Loss: 0.19442768394947052
train-epoch-step: 91-258 -- Loss: 0.14328140020370483
train-epoch-step: 91-259 -- Loss: 0.11004998534917831
train-epoch-step: 91-260 -- Loss: 0.19534693658351898
train-epoch-step: 91-261 -- Loss: 0.1696418821811676
train-epoch-step: 91-262 -- Loss: 0.30530402064323425
train-epoch-step: 91-263 -- Loss: 0.20352265238761902
train-epoch-step: 91-264 -- Loss: 0.17435382306575775
train-epoch-step: 91-265 -- Loss: 0.11476785689592361
train-epoch-step: 91-266 -- Loss: 0.15891097486019135
train-epoch-step: 91-267 -- Loss: 0.13380932807922363
train-epoch-step: 91-268 -- Loss: 0.12806150317192078
train-epoch-step: 91-269 -- Loss: 0.1765419989824295
train-epoch-step: 91-270 -- Loss: 0.10609549283981323
train-epoch-step: 91-271 -- Loss: 0.15640012919902802
train-epoch-step: 91-272 -- Loss: 0.12017954140901566
train-epoch-step: 91-273 -- Loss: 0.1275031417608261
train-epoch-step: 91-274 -- Loss: 0.18422898650169373
train-epoch-step: 91-275 -- Loss: 0.18861274421215057
train-epoch-step: 91-276 -- Loss: 0.1558399498462677
train-epoch-step: 91-277 -- Loss: 0.16509871184825897
train-epoch-step: 91-278 -- Loss: 0.13605563342571259
train-epoch-step: 91-279 -- Loss: 0.1339104175567627
train-epoch-step: 91-280 -- Loss: 0.21460416913032532
train-epoch-step: 91-281 -- Loss: 0.17800074815750122
train-epoch-step: 91-282 -- Loss: 0.14054444432258606
train-epoch-step: 91-283 -- Loss: 0.11624190211296082
train-epoch-step: 91-284 -- Loss: 0.21102550625801086
train-epoch-step: 91-285 -- Loss: 0.18838141858577728
train-epoch-step: 91-286 -- Loss: 0.14936044812202454
train-epoch-step: 91-287 -- Loss: 0.2120501846075058
train-epoch-step: 91-288 -- Loss: 0.09690874814987183
train-epoch-step: 91-289 -- Loss: 0.1193258985877037
train-epoch-step: 91-290 -- Loss: 0.17731890082359314
train-epoch-step: 91-291 -- Loss: 0.11739931255578995
train-epoch-step: 91-292 -- Loss: 0.15714940428733826
train-epoch-step: 91-293 -- Loss: 0.13463608920574188
train-epoch-step: 91-294 -- Loss: 0.15981383621692657
train-epoch-step: 91-295 -- Loss: 0.346191942691803
train-epoch-step: 91-296 -- Loss: 0.21191316843032837
train-epoch-step: 91-297 -- Loss: 0.17456048727035522
train-epoch-step: 91-298 -- Loss: 0.23122857511043549
train-epoch-step: 91-299 -- Loss: 0.18265283107757568
train-epoch-step: 91-300 -- Loss: 0.1637391597032547
train-epoch-step: 91-301 -- Loss: 0.18111756443977356
train-epoch-step: 91-302 -- Loss: 0.22632236778736115
train-epoch-step: 91-303 -- Loss: 0.2058579921722412
train-epoch-step: 91-304 -- Loss: 0.1464810073375702
train-epoch-step: 91-305 -- Loss: 0.14114411175251007
train-epoch-step: 91-306 -- Loss: 0.2472526878118515
train-epoch-step: 91-307 -- Loss: 0.1696920245885849
train-epoch-step: 91-308 -- Loss: 0.23663492500782013
train-epoch-step: 91-309 -- Loss: 0.15442359447479248
train-epoch-step: 91-310 -- Loss: 0.15993019938468933
train-epoch-step: 91-311 -- Loss: 0.16115964949131012
train-epoch-step: 91-312 -- Loss: 0.2011367529630661
train-epoch-step: 91-313 -- Loss: 0.10054682195186615
train-epoch-step: 91-314 -- Loss: 0.21785740554332733
train-epoch-step: 91-315 -- Loss: 0.165805846452713
train-epoch-step: 91-316 -- Loss: 0.1532025933265686
train-epoch-step: 91-317 -- Loss: 0.14166241884231567
train-epoch-step: 91-318 -- Loss: 0.1729898601770401
train-epoch-step: 91-319 -- Loss: 0.17620748281478882
train-epoch-step: 91-320 -- Loss: 0.11619386821985245
train-epoch-step: 91-321 -- Loss: 0.1305011361837387
train-epoch-step: 91-322 -- Loss: 0.21348559856414795
train-epoch-step: 91-323 -- Loss: 0.1671447604894638
train-epoch-step: 91-324 -- Loss: 0.24816617369651794
train-epoch-step: 91-325 -- Loss: 0.16042204201221466
train-epoch-step: 91-326 -- Loss: 0.17794397473335266
train-epoch-step: 91-327 -- Loss: 0.21627700328826904
train-epoch-step: 91-328 -- Loss: 0.1986411213874817
train-epoch-step: 91-329 -- Loss: 0.34169912338256836
train-epoch-step: 91-330 -- Loss: 0.35858243703842163
train-epoch-step: 91-331 -- Loss: 0.20658355951309204
train-epoch-step: 91-332 -- Loss: 0.09818580746650696
train-epoch-step: 91-333 -- Loss: 0.18712539970874786
train-epoch-step: 91-334 -- Loss: 0.15377026796340942
train-epoch-step: 91-335 -- Loss: 0.17382633686065674
train-epoch-step: 91-336 -- Loss: 0.1502131223678589
train-epoch-step: 91-337 -- Loss: 0.21519961953163147
train-epoch-step: 91-338 -- Loss: 0.15702718496322632
train-epoch-step: 91-339 -- Loss: 0.14224927127361298
train-epoch-step: 91-340 -- Loss: 0.1936386525630951
train-epoch-step: 91-341 -- Loss: 0.14013667404651642
train-epoch-step: 91-342 -- Loss: 0.16076119244098663
train-epoch-step: 91-343 -- Loss: 0.15066711604595184
train-epoch-step: 91-344 -- Loss: 0.16340799629688263
train-epoch-step: 91-345 -- Loss: 0.13872110843658447
train-epoch-step: 91-346 -- Loss: 0.20511674880981445
train-epoch-step: 91-347 -- Loss: 0.1511126309633255
train-epoch-step: 91-348 -- Loss: 0.2009553760290146
train-epoch-step: 91-349 -- Loss: 0.21159690618515015
train-epoch-step: 91-350 -- Loss: 0.2626042664051056
train-epoch-step: 91-351 -- Loss: 0.19608812034130096
train-epoch-step: 91-352 -- Loss: 0.14443659782409668
train-epoch-step: 91-353 -- Loss: 0.20690643787384033
train-epoch-step: 91-354 -- Loss: 0.27842751145362854
train-epoch-step: 91-355 -- Loss: 0.11768873035907745
train-epoch-step: 91-356 -- Loss: 0.1174701452255249
train-epoch-step: 91-357 -- Loss: 0.1902574747800827
train-epoch-step: 91-358 -- Loss: 0.18378178775310516
train-epoch-step: 91-359 -- Loss: 0.13732802867889404
train-epoch-step: 91-360 -- Loss: 0.12301415950059891
train-epoch-step: 91-361 -- Loss: 0.24018041789531708
train-epoch-step: 91-362 -- Loss: 0.1715267151594162
train-epoch-step: 91-363 -- Loss: 0.13490954041481018
train-epoch-step: 91-364 -- Loss: 0.17953334748744965
train-epoch-step: 91-365 -- Loss: 0.16583152115345
train-epoch-step: 91-366 -- Loss: 0.22835643589496613
train-epoch-step: 91-367 -- Loss: 0.21902216970920563
train-epoch-step: 91-368 -- Loss: 0.19787897169589996
train-epoch-step: 91-369 -- Loss: 0.27102452516555786
train-epoch-step: 91-370 -- Loss: 0.12255983054637909
train-epoch-step: 91-371 -- Loss: 0.12039114534854889
train-epoch-step: 91-372 -- Loss: 0.14151377975940704
train-epoch-step: 91-373 -- Loss: 0.18525105714797974
train-epoch-step: 91-374 -- Loss: 0.1505701094865799
train-epoch-step: 91-375 -- Loss: 0.26075053215026855
train-epoch-step: 91-376 -- Loss: 0.16154704988002777
train-epoch-step: 91-377 -- Loss: 0.2282683253288269
train-epoch-step: 91-378 -- Loss: 0.19782578945159912
train-epoch-step: 91-379 -- Loss: 0.12277761101722717
train-epoch-step: 91-380 -- Loss: 0.0902051329612732
train-epoch-step: 91-381 -- Loss: 0.25024735927581787
train-epoch-step: 91-382 -- Loss: 0.23250152170658112
train-epoch-step: 91-383 -- Loss: 0.1821746826171875
train-epoch-step: 91-384 -- Loss: 0.2203563004732132
train-epoch-step: 91-385 -- Loss: 0.18883946537971497
train-epoch-step: 91-386 -- Loss: 0.18807196617126465
train-epoch-step: 91-387 -- Loss: 0.2013373076915741
train-epoch-step: 91-388 -- Loss: 0.18435683846473694
train-epoch-step: 91-389 -- Loss: 0.16501560807228088
train-epoch-step: 91-390 -- Loss: 0.14130805432796478
train-epoch-step: 91-391 -- Loss: 0.14710593223571777
train-epoch-step: 91-392 -- Loss: 0.17942354083061218
train-epoch-step: 91-393 -- Loss: 0.16080322861671448
train-epoch-step: 91-394 -- Loss: 0.19322608411312103
train-epoch-step: 91-395 -- Loss: 0.14816515147686005
train-epoch-step: 91-396 -- Loss: 0.12447543442249298
train-epoch-step: 91-397 -- Loss: 0.12425461411476135
train-epoch-step: 91-398 -- Loss: 0.19503840804100037
train-epoch-step: 91-399 -- Loss: 0.1720157414674759
train-epoch-step: 91-400 -- Loss: 0.2732829749584198
train-epoch-step: 91-401 -- Loss: 0.1174720972776413
train-epoch-step: 91-402 -- Loss: 0.2528040409088135
train-epoch-step: 91-403 -- Loss: 0.1543736755847931
train-epoch-step: 91-404 -- Loss: 0.13468903303146362
train-epoch-step: 91-405 -- Loss: 0.14260172843933105
train-epoch-step: 91-406 -- Loss: 0.16506317257881165
train-epoch-step: 91-407 -- Loss: 0.10676640272140503
train-epoch-step: 91-408 -- Loss: 0.161123126745224
train-epoch-step: 91-409 -- Loss: 0.16695933043956757
train-epoch-step: 91-410 -- Loss: 0.18147346377372742
train-epoch-step: 91-411 -- Loss: 0.19613251090049744
train-epoch-step: 91-412 -- Loss: 0.12633243203163147
train-epoch-step: 91-413 -- Loss: 0.14435331523418427
train-epoch-step: 91-414 -- Loss: 0.13156628608703613
train-epoch-step: 91-415 -- Loss: 0.14734101295471191
train-epoch-step: 91-416 -- Loss: 0.2590291500091553
train-epoch-step: 91-417 -- Loss: 0.2041737288236618
train-epoch-step: 91-418 -- Loss: 0.21856850385665894
train-epoch-step: 91-419 -- Loss: 0.1714404970407486
train-epoch-step: 91-420 -- Loss: 0.15017415583133698
train-epoch-step: 91-421 -- Loss: 0.17509980499744415
train-epoch-step: 91-422 -- Loss: 0.14746488630771637
train-epoch-step: 91-423 -- Loss: 0.17033544182777405
train-epoch-step: 91-424 -- Loss: 0.13334029912948608
train-epoch-step: 91-425 -- Loss: 0.18142107129096985
train-epoch-step: 91-426 -- Loss: 0.16356441378593445
train-epoch-step: 91-427 -- Loss: 0.1177796870470047
train-epoch-step: 91-428 -- Loss: 0.18728169798851013
train-epoch-step: 91-429 -- Loss: 0.1716349720954895
train-epoch-step: 91-430 -- Loss: 0.13730503618717194
train-epoch-step: 91-431 -- Loss: 0.16770797967910767
train-epoch-step: 91-432 -- Loss: 0.24723327159881592
train-epoch-step: 91-433 -- Loss: 0.13681313395500183
train-epoch-step: 91-434 -- Loss: 0.12339760363101959
train-epoch-step: 91-435 -- Loss: 0.1553957313299179
train-epoch-step: 91-436 -- Loss: 0.15387043356895447
train-epoch-step: 91-437 -- Loss: 0.13090895116329193
train-epoch-step: 91-438 -- Loss: 0.1624862551689148
train-epoch-step: 91-439 -- Loss: 0.2610679268836975
train-epoch-step: 91-440 -- Loss: 0.12930655479431152
train-epoch-step: 91-441 -- Loss: 0.19759748876094818
train-epoch-step: 91-442 -- Loss: 0.1734418123960495
train-epoch-step: 91-443 -- Loss: 0.15880350768566132
train-epoch-step: 91-444 -- Loss: 0.1797979772090912
train-epoch-step: 91-445 -- Loss: 0.18004070222377777
train-epoch-step: 91-446 -- Loss: 0.15553241968154907
train-epoch-step: 91-447 -- Loss: 0.18822194635868073
train-epoch-step: 91-448 -- Loss: 0.21917137503623962
train-epoch-step: 91-449 -- Loss: 0.1907154768705368
train-epoch-step: 91-450 -- Loss: 0.18850867450237274
train-epoch-step: 91-451 -- Loss: 0.14555072784423828
train-epoch-step: 91-452 -- Loss: 0.12925685942173004
train-epoch-step: 91-453 -- Loss: 0.08827066421508789
train-epoch-step: 91-454 -- Loss: 0.22341111302375793
train-epoch-step: 91-455 -- Loss: 0.122137650847435
train-epoch-step: 91-456 -- Loss: 0.11334792524576187
train-epoch-step: 91-457 -- Loss: 0.20927640795707703
train-epoch-step: 91-458 -- Loss: 0.15710914134979248
train-epoch-step: 91-459 -- Loss: 0.21460029482841492
train-epoch-step: 91-460 -- Loss: 0.13226579129695892
train-epoch-step: 91-461 -- Loss: 0.135384202003479
train-epoch-step: 91-462 -- Loss: 0.1523238718509674
train-epoch-step: 91-463 -- Loss: 0.1491086184978485
train-epoch-step: 91-464 -- Loss: 0.15967020392417908
train-epoch-step: 91-465 -- Loss: 0.23312491178512573
train-epoch-step: 91-466 -- Loss: 0.20244693756103516
train-epoch-step: 91-467 -- Loss: 0.11552776396274567
train-epoch-step: 91-468 -- Loss: 0.16983431577682495
train-epoch-step: 91-469 -- Loss: 0.2053447663784027
train-epoch-step: 91-470 -- Loss: 0.16336026787757874
train-epoch-step: 91-471 -- Loss: 0.14830437302589417
train-epoch-step: 91-472 -- Loss: 0.15982508659362793
train-epoch-step: 91-473 -- Loss: 0.15813866257667542
train-epoch-step: 91-474 -- Loss: 0.12086646258831024
train-epoch-step: 91-475 -- Loss: 0.10845305025577545
train-epoch-step: 91-476 -- Loss: 0.19453099370002747
train-epoch-step: 91-477 -- Loss: 0.19060231745243073
train-epoch-step: 91-478 -- Loss: 0.21178218722343445
train-epoch-step: 91-479 -- Loss: 0.14721275866031647
train-epoch-step: 91-480 -- Loss: 0.18356460332870483
train-epoch-step: 91-481 -- Loss: 0.2747083306312561
train-epoch-step: 91-482 -- Loss: 0.2510768473148346
train-epoch-step: 91-483 -- Loss: 0.1765354722738266
train-epoch-step: 91-484 -- Loss: 0.20817291736602783
train-epoch-step: 91-485 -- Loss: 0.13163387775421143
train-epoch-step: 91-486 -- Loss: 0.22360868752002716
train-epoch-step: 91-487 -- Loss: 0.23022834956645966
train-epoch-step: 91-488 -- Loss: 0.1826954483985901
train-epoch-step: 91-489 -- Loss: 0.21240243315696716
train-epoch-step: 91-490 -- Loss: 0.13186728954315186
train-epoch-step: 91-491 -- Loss: 0.1331947296857834
train-epoch-step: 91-492 -- Loss: 0.12388989329338074
train-epoch-step: 91-493 -- Loss: 0.19284087419509888
train-epoch-step: 91-494 -- Loss: 0.19952936470508575
train-epoch-step: 91-495 -- Loss: 0.19883547723293304
train-epoch-step: 91-496 -- Loss: 0.1394406110048294
train-epoch-step: 91-497 -- Loss: 0.17816400527954102
train-epoch-step: 91-498 -- Loss: 0.14701764285564423
train-epoch-step: 91-499 -- Loss: 0.1649692952632904
train-epoch-step: 91-500 -- Loss: 0.1507304459810257
train-epoch-step: 91-501 -- Loss: 0.2030945122241974
train-epoch-step: 91-502 -- Loss: 0.1517181694507599
train-epoch-step: 91-503 -- Loss: 0.20840299129486084
train-epoch-step: 91-504 -- Loss: 0.12201695144176483
train-epoch-step: 91-505 -- Loss: 0.1689319610595703
train-epoch-step: 91-506 -- Loss: 0.11420139670372009
train-epoch-step: 91-507 -- Loss: 0.18036429584026337
train-epoch-step: 91-508 -- Loss: 0.17056512832641602
train-epoch-step: 91-509 -- Loss: 0.1624520868062973
train-epoch-step: 91-510 -- Loss: 0.1234097108244896
train-epoch-step: 91-511 -- Loss: 0.20847059786319733
train-epoch-step: 91-512 -- Loss: 0.1741037219762802
train-epoch-step: 91-513 -- Loss: 0.184041827917099
train-epoch-step: 91-514 -- Loss: 0.14416107535362244
train-epoch-step: 91-515 -- Loss: 0.1524628847837448
train-epoch-step: 91-516 -- Loss: 0.16897250711917877
train-epoch-step: 91-517 -- Loss: 0.17095425724983215
train-epoch-step: 91-518 -- Loss: 0.1334143429994583
train-epoch-step: 91-519 -- Loss: 0.13920186460018158
train-epoch-step: 91-520 -- Loss: 0.17900845408439636
train-epoch-step: 91-521 -- Loss: 0.223774254322052
train-epoch-step: 91-522 -- Loss: 0.17032042145729065
train-epoch-step: 91-523 -- Loss: 0.1540408879518509
train-epoch-step: 91-524 -- Loss: 0.16767579317092896
train-epoch-step: 91-525 -- Loss: 0.18798840045928955
train-epoch-step: 91-526 -- Loss: 0.12694717943668365
train-epoch-step: 91-527 -- Loss: 0.14613577723503113
train-epoch-step: 91-528 -- Loss: 0.14939232170581818
train-epoch-step: 91-529 -- Loss: 0.1536138355731964
train-epoch-step: 91-530 -- Loss: 0.16197887063026428
train-epoch-step: 91-531 -- Loss: 0.19280710816383362
train-epoch-step: 91-532 -- Loss: 0.1623235046863556
train-epoch-step: 91-533 -- Loss: 0.17138363420963287
train-epoch-step: 91-534 -- Loss: 0.12946172058582306
train-epoch-step: 91-535 -- Loss: 0.2452886998653412
train-epoch-step: 91-536 -- Loss: 0.14973288774490356
train-epoch-step: 91-537 -- Loss: 0.1462114155292511
train-epoch-step: 91-538 -- Loss: 0.10313744843006134
train-epoch-step: 91-539 -- Loss: 0.17403550446033478
train-epoch-step: 91-540 -- Loss: 0.1297338902950287
train-epoch-step: 91-541 -- Loss: 0.20393936336040497
train-epoch-step: 91-542 -- Loss: 0.22411099076271057
train-epoch-step: 91-543 -- Loss: 0.1675363928079605
train-epoch-step: 91-544 -- Loss: 0.2281934916973114
train-epoch-step: 91-545 -- Loss: 0.18428632616996765
train-epoch-step: 91-546 -- Loss: 0.20073166489601135
train-epoch-step: 91-547 -- Loss: 0.18439312279224396
train-epoch-step: 91-548 -- Loss: 0.08827568590641022
train-epoch-step: 91-549 -- Loss: 0.14284013211727142
train-epoch-step: 91-550 -- Loss: 0.19481170177459717
train-epoch-step: 91-551 -- Loss: 0.15448817610740662
train-epoch-step: 91-552 -- Loss: 0.1259857714176178
train-epoch-step: 91-553 -- Loss: 0.1842440813779831
train-epoch-step: 91-554 -- Loss: 0.18459953367710114
train-epoch-step: 91-555 -- Loss: 0.20440803468227386
train-epoch-step: 91-556 -- Loss: 0.13981491327285767
train-epoch-step: 91-557 -- Loss: 0.22494779527187347
train-epoch-step: 91-558 -- Loss: 0.21668322384357452
train-epoch-step: 91-559 -- Loss: 0.1338193565607071
train-epoch-step: 91-560 -- Loss: 0.20085647702217102
train-epoch-step: 91-561 -- Loss: 0.18283136188983917
train-epoch-step: 91-562 -- Loss: 0.15700721740722656
train-epoch-step: 91-563 -- Loss: 0.1815110146999359
train-epoch-step: 91-564 -- Loss: 0.09791429340839386
train-epoch-step: 91-565 -- Loss: 0.17504096031188965
train-epoch-step: 91-566 -- Loss: 0.1439780592918396
train-epoch-step: 91-567 -- Loss: 0.21394801139831543
train-epoch-step: 91-568 -- Loss: 0.15257909893989563
train-epoch-step: 91-569 -- Loss: 0.23667579889297485
train-epoch-step: 91-570 -- Loss: 0.1605607569217682
train-epoch-step: 91-571 -- Loss: 0.210256889462471
train-epoch-step: 91-572 -- Loss: 0.23499327898025513
train-epoch-step: 91-573 -- Loss: 0.19296935200691223
train-epoch-step: 91-574 -- Loss: 0.24190188944339752
train-epoch-step: 91-575 -- Loss: 0.2986510992050171
train-epoch-step: 91-576 -- Loss: 0.12590420246124268
train-epoch-step: 91-577 -- Loss: 0.16012178361415863
train-epoch-step: 91-578 -- Loss: 0.20779292285442352
train-epoch-step: 91-579 -- Loss: 0.1628321409225464
train-epoch-step: 91-580 -- Loss: 0.16417831182479858
train-epoch-step: 91-581 -- Loss: 0.1348312646150589
train-epoch-step: 91-582 -- Loss: 0.20194405317306519
train-epoch-step: 91-583 -- Loss: 0.21792002022266388
train-epoch-step: 91-584 -- Loss: 0.15398000180721283
train-epoch-step: 91-585 -- Loss: 0.18866722285747528
train-epoch-step: 91-586 -- Loss: 0.2510952651500702
train-epoch-step: 91-587 -- Loss: 0.15782253444194794
train-epoch-step: 91-588 -- Loss: 0.12401743233203888
val-epoch-step: 91-589 -- Loss: 0.2301175594329834
val-epoch-step: 91-590 -- Loss: 0.15214091539382935
val-epoch-step: 91-591 -- Loss: 0.23489642143249512
val-epoch-step: 91-592 -- Loss: 0.17012162506580353
val-epoch-step: 91-593 -- Loss: 0.17255465686321259
val-epoch-step: 91-594 -- Loss: 0.3422786295413971
val-epoch-step: 91-595 -- Loss: 0.18704110383987427
val-epoch-step: 91-596 -- Loss: 0.19222202897071838
val-epoch-step: 91-597 -- Loss: 0.16977918148040771
val-epoch-step: 91-598 -- Loss: 0.14674904942512512
val-epoch-step: 91-599 -- Loss: 0.17863230407238007
val-epoch-step: 91-600 -- Loss: 0.168232262134552
val-epoch-step: 91-601 -- Loss: 0.14962448179721832
val-epoch-step: 91-602 -- Loss: 0.14069174230098724
val-epoch-step: 91-603 -- Loss: 0.19483691453933716
val-epoch-step: 91-604 -- Loss: 0.14736203849315643
val-epoch-step: 91-605 -- Loss: 0.1502484828233719
val-epoch-step: 91-606 -- Loss: 0.2485484480857849
val-epoch-step: 91-607 -- Loss: 0.12736429274082184
val-epoch-step: 91-608 -- Loss: 0.24650658667087555
val-epoch-step: 91-609 -- Loss: 0.16028259694576263
val-epoch-step: 91-610 -- Loss: 0.18473771214485168
val-epoch-step: 91-611 -- Loss: 0.14487886428833008
val-epoch-step: 91-612 -- Loss: 0.3538908362388611
val-epoch-step: 91-613 -- Loss: 0.1741507649421692
val-epoch-step: 91-614 -- Loss: 0.17370286583900452
val-epoch-step: 91-615 -- Loss: 0.17022979259490967
val-epoch-step: 91-616 -- Loss: 0.14165903627872467
val-epoch-step: 91-617 -- Loss: 0.182264506816864
val-epoch-step: 91-618 -- Loss: 0.17777426540851593
val-epoch-step: 91-619 -- Loss: 0.20825424790382385
val-epoch-step: 91-620 -- Loss: 0.13339443504810333
val-epoch-step: 91-621 -- Loss: 0.12277873605489731
val-epoch-step: 91-622 -- Loss: 0.1415139138698578
val-epoch-step: 91-623 -- Loss: 0.1445254534482956
val-epoch-step: 91-624 -- Loss: 0.1372688114643097
val-epoch-step: 91-625 -- Loss: 0.15338091552257538
val-epoch-step: 91-626 -- Loss: 0.14540119469165802
val-epoch-step: 91-627 -- Loss: 0.18240118026733398
val-epoch-step: 91-628 -- Loss: 0.49654141068458557
val-epoch-step: 91-629 -- Loss: 0.19818755984306335
val-epoch-step: 91-630 -- Loss: 0.3490161597728729
val-epoch-step: 91-631 -- Loss: 0.1374947726726532
val-epoch-step: 91-632 -- Loss: 0.21804623305797577
val-epoch-step: 91-633 -- Loss: 0.15187177062034607
val-epoch-step: 91-634 -- Loss: 0.13656073808670044
val-epoch-step: 91-635 -- Loss: 0.11396770179271698
val-epoch-step: 91-636 -- Loss: 0.16757342219352722
val-epoch-step: 91-637 -- Loss: 0.1782914400100708
val-epoch-step: 91-638 -- Loss: 0.15647824108600616
val-epoch-step: 91-639 -- Loss: 0.26132631301879883
val-epoch-step: 91-640 -- Loss: 0.24584513902664185
val-epoch-step: 91-641 -- Loss: 0.12486878037452698
val-epoch-step: 91-642 -- Loss: 0.17718255519866943
val-epoch-step: 91-643 -- Loss: 0.2067863494157791
val-epoch-step: 91-644 -- Loss: 0.160609170794487
val-epoch-step: 91-645 -- Loss: 0.21395249664783478
val-epoch-step: 91-646 -- Loss: 0.13312257826328278
val-epoch-step: 91-647 -- Loss: 0.12715812027454376
val-epoch-step: 91-648 -- Loss: 0.1530139148235321
val-epoch-step: 91-649 -- Loss: 0.20513281226158142
val-epoch-step: 91-650 -- Loss: 0.24603042006492615
val-epoch-step: 91-651 -- Loss: 0.1467067152261734
val-epoch-step: 91-652 -- Loss: 0.15092968940734863
val-epoch-step: 91-653 -- Loss: 0.19700753688812256
val-epoch-step: 91-654 -- Loss: 0.12186805158853531
Epoch: 91 -- Train Loss: tensor(0.1398, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1411, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 92-0 -- Loss: 0.21637485921382904
train-epoch-step: 92-1 -- Loss: 0.13982543349266052
train-epoch-step: 92-2 -- Loss: 0.19826284050941467
train-epoch-step: 92-3 -- Loss: 0.143036887049675
train-epoch-step: 92-4 -- Loss: 0.1546405553817749
train-epoch-step: 92-5 -- Loss: 0.17335893213748932
train-epoch-step: 92-6 -- Loss: 0.21391187608242035
train-epoch-step: 92-7 -- Loss: 0.16530591249465942
train-epoch-step: 92-8 -- Loss: 0.17850740253925323
train-epoch-step: 92-9 -- Loss: 0.2293287217617035
train-epoch-step: 92-10 -- Loss: 0.18458130955696106
train-epoch-step: 92-11 -- Loss: 0.1648859828710556
train-epoch-step: 92-12 -- Loss: 0.14558228850364685
train-epoch-step: 92-13 -- Loss: 0.17206968367099762
train-epoch-step: 92-14 -- Loss: 0.16064594686031342
train-epoch-step: 92-15 -- Loss: 0.15433549880981445
train-epoch-step: 92-16 -- Loss: 0.15715129673480988
train-epoch-step: 92-17 -- Loss: 0.21545952558517456
train-epoch-step: 92-18 -- Loss: 0.1892019361257553
train-epoch-step: 92-19 -- Loss: 0.1328628659248352
train-epoch-step: 92-20 -- Loss: 0.206508606672287
train-epoch-step: 92-21 -- Loss: 0.2362462282180786
train-epoch-step: 92-22 -- Loss: 0.1423332840204239
train-epoch-step: 92-23 -- Loss: 0.1381855010986328
train-epoch-step: 92-24 -- Loss: 0.12005075812339783
train-epoch-step: 92-25 -- Loss: 0.21855071187019348
train-epoch-step: 92-26 -- Loss: 0.1872570812702179
train-epoch-step: 92-27 -- Loss: 0.22396248579025269
train-epoch-step: 92-28 -- Loss: 0.11978182941675186
train-epoch-step: 92-29 -- Loss: 0.23748300969600677
train-epoch-step: 92-30 -- Loss: 0.10520650446414948
train-epoch-step: 92-31 -- Loss: 0.13311465084552765
train-epoch-step: 92-32 -- Loss: 0.16867908835411072
train-epoch-step: 92-33 -- Loss: 0.26454636454582214
train-epoch-step: 92-34 -- Loss: 0.16512209177017212
train-epoch-step: 92-35 -- Loss: 0.23315483331680298
train-epoch-step: 92-36 -- Loss: 0.14478763937950134
train-epoch-step: 92-37 -- Loss: 0.1352267861366272
train-epoch-step: 92-38 -- Loss: 0.16943757236003876
train-epoch-step: 92-39 -- Loss: 0.2168934941291809
train-epoch-step: 92-40 -- Loss: 0.18354150652885437
train-epoch-step: 92-41 -- Loss: 0.21480980515480042
train-epoch-step: 92-42 -- Loss: 0.14211595058441162
train-epoch-step: 92-43 -- Loss: 0.2679656744003296
train-epoch-step: 92-44 -- Loss: 0.12062244862318039
train-epoch-step: 92-45 -- Loss: 0.1105915755033493
train-epoch-step: 92-46 -- Loss: 0.1610288769006729
train-epoch-step: 92-47 -- Loss: 0.20791813731193542
train-epoch-step: 92-48 -- Loss: 0.1530306190252304
train-epoch-step: 92-49 -- Loss: 0.22168856859207153
train-epoch-step: 92-50 -- Loss: 0.10528869926929474
train-epoch-step: 92-51 -- Loss: 0.17262281477451324
train-epoch-step: 92-52 -- Loss: 0.1560279130935669
train-epoch-step: 92-53 -- Loss: 0.20224139094352722
train-epoch-step: 92-54 -- Loss: 0.28523245453834534
train-epoch-step: 92-55 -- Loss: 0.19783471524715424
train-epoch-step: 92-56 -- Loss: 0.17021769285202026
train-epoch-step: 92-57 -- Loss: 0.23306968808174133
train-epoch-step: 92-58 -- Loss: 0.2965596616268158
train-epoch-step: 92-59 -- Loss: 0.24096517264842987
train-epoch-step: 92-60 -- Loss: 0.12379980087280273
train-epoch-step: 92-61 -- Loss: 0.19269564747810364
train-epoch-step: 92-62 -- Loss: 0.1763572245836258
train-epoch-step: 92-63 -- Loss: 0.1313011795282364
train-epoch-step: 92-64 -- Loss: 0.14726082980632782
train-epoch-step: 92-65 -- Loss: 0.19931165874004364
train-epoch-step: 92-66 -- Loss: 0.10479900240898132
train-epoch-step: 92-67 -- Loss: 0.12168820202350616
train-epoch-step: 92-68 -- Loss: 0.21167142689228058
train-epoch-step: 92-69 -- Loss: 0.12067919969558716
train-epoch-step: 92-70 -- Loss: 0.21778663992881775
train-epoch-step: 92-71 -- Loss: 0.2640690207481384
train-epoch-step: 92-72 -- Loss: 0.16873052716255188
train-epoch-step: 92-73 -- Loss: 0.20304885506629944
train-epoch-step: 92-74 -- Loss: 0.09169693291187286
train-epoch-step: 92-75 -- Loss: 0.12741047143936157
train-epoch-step: 92-76 -- Loss: 0.1460147500038147
train-epoch-step: 92-77 -- Loss: 0.2221171259880066
train-epoch-step: 92-78 -- Loss: 0.2563804090023041
train-epoch-step: 92-79 -- Loss: 0.18817172944545746
train-epoch-step: 92-80 -- Loss: 0.25337696075439453
train-epoch-step: 92-81 -- Loss: 0.12324942648410797
train-epoch-step: 92-82 -- Loss: 0.24260422587394714
train-epoch-step: 92-83 -- Loss: 0.18000183999538422
train-epoch-step: 92-84 -- Loss: 0.1823618859052658
train-epoch-step: 92-85 -- Loss: 0.17084144055843353
train-epoch-step: 92-86 -- Loss: 0.12179235368967056
train-epoch-step: 92-87 -- Loss: 0.20891311764717102
train-epoch-step: 92-88 -- Loss: 0.13702929019927979
train-epoch-step: 92-89 -- Loss: 0.18010163307189941
train-epoch-step: 92-90 -- Loss: 0.18816611170768738
train-epoch-step: 92-91 -- Loss: 0.24746090173721313
train-epoch-step: 92-92 -- Loss: 0.15008780360221863
train-epoch-step: 92-93 -- Loss: 0.21401682496070862
train-epoch-step: 92-94 -- Loss: 0.25281593203544617
train-epoch-step: 92-95 -- Loss: 0.17935021221637726
train-epoch-step: 92-96 -- Loss: 0.20580849051475525
train-epoch-step: 92-97 -- Loss: 0.17854556441307068
train-epoch-step: 92-98 -- Loss: 0.15527036786079407
train-epoch-step: 92-99 -- Loss: 0.18460369110107422
train-epoch-step: 92-100 -- Loss: 0.1832495480775833
train-epoch-step: 92-101 -- Loss: 0.26720130443573
train-epoch-step: 92-102 -- Loss: 0.22918984293937683
train-epoch-step: 92-103 -- Loss: 0.18456031382083893
train-epoch-step: 92-104 -- Loss: 0.14762245118618011
train-epoch-step: 92-105 -- Loss: 0.2713956832885742
train-epoch-step: 92-106 -- Loss: 0.20068782567977905
train-epoch-step: 92-107 -- Loss: 0.18397685885429382
train-epoch-step: 92-108 -- Loss: 0.18941853940486908
train-epoch-step: 92-109 -- Loss: 0.14499162137508392
train-epoch-step: 92-110 -- Loss: 0.1812528520822525
train-epoch-step: 92-111 -- Loss: 0.17773155868053436
train-epoch-step: 92-112 -- Loss: 0.16967318952083588
train-epoch-step: 92-113 -- Loss: 0.16590483486652374
train-epoch-step: 92-114 -- Loss: 0.1968829333782196
train-epoch-step: 92-115 -- Loss: 0.16143052279949188
train-epoch-step: 92-116 -- Loss: 0.14228567481040955
train-epoch-step: 92-117 -- Loss: 0.13031546771526337
train-epoch-step: 92-118 -- Loss: 0.19992688298225403
train-epoch-step: 92-119 -- Loss: 0.1516822725534439
train-epoch-step: 92-120 -- Loss: 0.24635827541351318
train-epoch-step: 92-121 -- Loss: 0.24036064743995667
train-epoch-step: 92-122 -- Loss: 0.21352452039718628
train-epoch-step: 92-123 -- Loss: 0.196690633893013
train-epoch-step: 92-124 -- Loss: 0.11983046680688858
train-epoch-step: 92-125 -- Loss: 0.1476191133260727
train-epoch-step: 92-126 -- Loss: 0.225491464138031
train-epoch-step: 92-127 -- Loss: 0.1672392189502716
train-epoch-step: 92-128 -- Loss: 0.1680966168642044
train-epoch-step: 92-129 -- Loss: 0.13504715263843536
train-epoch-step: 92-130 -- Loss: 0.1873396337032318
train-epoch-step: 92-131 -- Loss: 0.13396842777729034
train-epoch-step: 92-132 -- Loss: 0.18796606361865997
train-epoch-step: 92-133 -- Loss: 0.11595092713832855
train-epoch-step: 92-134 -- Loss: 0.193961501121521
train-epoch-step: 92-135 -- Loss: 0.13459445536136627
train-epoch-step: 92-136 -- Loss: 0.12632301449775696
train-epoch-step: 92-137 -- Loss: 0.2430795282125473
train-epoch-step: 92-138 -- Loss: 0.2518039345741272
train-epoch-step: 92-139 -- Loss: 0.12807130813598633
train-epoch-step: 92-140 -- Loss: 0.22033977508544922
train-epoch-step: 92-141 -- Loss: 0.23009449243545532
train-epoch-step: 92-142 -- Loss: 0.19741185009479523
train-epoch-step: 92-143 -- Loss: 0.17467202246189117
train-epoch-step: 92-144 -- Loss: 0.18348172307014465
train-epoch-step: 92-145 -- Loss: 0.1467011719942093
train-epoch-step: 92-146 -- Loss: 0.17801159620285034
train-epoch-step: 92-147 -- Loss: 0.17050877213478088
train-epoch-step: 92-148 -- Loss: 0.1628672331571579
train-epoch-step: 92-149 -- Loss: 0.11502385139465332
train-epoch-step: 92-150 -- Loss: 0.1800098717212677
train-epoch-step: 92-151 -- Loss: 0.18630020320415497
train-epoch-step: 92-152 -- Loss: 0.18723419308662415
train-epoch-step: 92-153 -- Loss: 0.2590861916542053
train-epoch-step: 92-154 -- Loss: 0.12874114513397217
train-epoch-step: 92-155 -- Loss: 0.13155841827392578
train-epoch-step: 92-156 -- Loss: 0.11536896973848343
train-epoch-step: 92-157 -- Loss: 0.17250551283359528
train-epoch-step: 92-158 -- Loss: 0.16042445600032806
train-epoch-step: 92-159 -- Loss: 0.18250061571598053
train-epoch-step: 92-160 -- Loss: 0.2103826403617859
train-epoch-step: 92-161 -- Loss: 0.20232835412025452
train-epoch-step: 92-162 -- Loss: 0.20371118187904358
train-epoch-step: 92-163 -- Loss: 0.18493707478046417
train-epoch-step: 92-164 -- Loss: 0.19779014587402344
train-epoch-step: 92-165 -- Loss: 0.1595449447631836
train-epoch-step: 92-166 -- Loss: 0.1212562546133995
train-epoch-step: 92-167 -- Loss: 0.1267583668231964
train-epoch-step: 92-168 -- Loss: 0.19561725854873657
train-epoch-step: 92-169 -- Loss: 0.13640500605106354
train-epoch-step: 92-170 -- Loss: 0.19332382082939148
train-epoch-step: 92-171 -- Loss: 0.1443072259426117
train-epoch-step: 92-172 -- Loss: 0.25732940435409546
train-epoch-step: 92-173 -- Loss: 0.1265076845884323
train-epoch-step: 92-174 -- Loss: 0.24356918036937714
train-epoch-step: 92-175 -- Loss: 0.18352994322776794
train-epoch-step: 92-176 -- Loss: 0.12638244032859802
train-epoch-step: 92-177 -- Loss: 0.17377790808677673
train-epoch-step: 92-178 -- Loss: 0.17640072107315063
train-epoch-step: 92-179 -- Loss: 0.14310893416404724
train-epoch-step: 92-180 -- Loss: 0.14712201058864594
train-epoch-step: 92-181 -- Loss: 0.16318443417549133
train-epoch-step: 92-182 -- Loss: 0.20852047204971313
train-epoch-step: 92-183 -- Loss: 0.27261024713516235
train-epoch-step: 92-184 -- Loss: 0.13319970667362213
train-epoch-step: 92-185 -- Loss: 0.13999836146831512
train-epoch-step: 92-186 -- Loss: 0.18312667310237885
train-epoch-step: 92-187 -- Loss: 0.20882000029087067
train-epoch-step: 92-188 -- Loss: 0.1652170568704605
train-epoch-step: 92-189 -- Loss: 0.10544915497303009
train-epoch-step: 92-190 -- Loss: 0.17962056398391724
train-epoch-step: 92-191 -- Loss: 0.1600874811410904
train-epoch-step: 92-192 -- Loss: 0.22434327006340027
train-epoch-step: 92-193 -- Loss: 0.2047126591205597
train-epoch-step: 92-194 -- Loss: 0.177548348903656
train-epoch-step: 92-195 -- Loss: 0.16488341987133026
train-epoch-step: 92-196 -- Loss: 0.1668592244386673
train-epoch-step: 92-197 -- Loss: 0.12948986887931824
train-epoch-step: 92-198 -- Loss: 0.128811314702034
train-epoch-step: 92-199 -- Loss: 0.1466420590877533
train-epoch-step: 92-200 -- Loss: 0.12477786093950272
train-epoch-step: 92-201 -- Loss: 0.18018116056919098
train-epoch-step: 92-202 -- Loss: 0.13164585828781128
train-epoch-step: 92-203 -- Loss: 0.18655359745025635
train-epoch-step: 92-204 -- Loss: 0.1290181577205658
train-epoch-step: 92-205 -- Loss: 0.18380118906497955
train-epoch-step: 92-206 -- Loss: 0.19980089366436005
train-epoch-step: 92-207 -- Loss: 0.13445033133029938
train-epoch-step: 92-208 -- Loss: 0.1740928292274475
train-epoch-step: 92-209 -- Loss: 0.14162716269493103
train-epoch-step: 92-210 -- Loss: 0.13031451404094696
train-epoch-step: 92-211 -- Loss: 0.20549079775810242
train-epoch-step: 92-212 -- Loss: 0.1975814551115036
train-epoch-step: 92-213 -- Loss: 0.12655875086784363
train-epoch-step: 92-214 -- Loss: 0.14550240337848663
train-epoch-step: 92-215 -- Loss: 0.123472660779953
train-epoch-step: 92-216 -- Loss: 0.19939474761486053
train-epoch-step: 92-217 -- Loss: 0.20623262226581573
train-epoch-step: 92-218 -- Loss: 0.14861077070236206
train-epoch-step: 92-219 -- Loss: 0.16716036200523376
train-epoch-step: 92-220 -- Loss: 0.12645140290260315
train-epoch-step: 92-221 -- Loss: 0.20211085677146912
train-epoch-step: 92-222 -- Loss: 0.11267615854740143
train-epoch-step: 92-223 -- Loss: 0.16760775446891785
train-epoch-step: 92-224 -- Loss: 0.19187495112419128
train-epoch-step: 92-225 -- Loss: 0.2585509419441223
train-epoch-step: 92-226 -- Loss: 0.2029678374528885
train-epoch-step: 92-227 -- Loss: 0.21464259922504425
train-epoch-step: 92-228 -- Loss: 0.16869889199733734
train-epoch-step: 92-229 -- Loss: 0.1776619851589203
train-epoch-step: 92-230 -- Loss: 0.15859714150428772
train-epoch-step: 92-231 -- Loss: 0.16513630747795105
train-epoch-step: 92-232 -- Loss: 0.18992501497268677
train-epoch-step: 92-233 -- Loss: 0.08072813600301743
train-epoch-step: 92-234 -- Loss: 0.17090710997581482
train-epoch-step: 92-235 -- Loss: 0.14497360587120056
train-epoch-step: 92-236 -- Loss: 0.17705875635147095
train-epoch-step: 92-237 -- Loss: 0.2288399338722229
train-epoch-step: 92-238 -- Loss: 0.1512162983417511
train-epoch-step: 92-239 -- Loss: 0.1220516562461853
train-epoch-step: 92-240 -- Loss: 0.2233213484287262
train-epoch-step: 92-241 -- Loss: 0.1488703042268753
train-epoch-step: 92-242 -- Loss: 0.21176227927207947
train-epoch-step: 92-243 -- Loss: 0.23184135556221008
train-epoch-step: 92-244 -- Loss: 0.1987127810716629
train-epoch-step: 92-245 -- Loss: 0.20267453789710999
train-epoch-step: 92-246 -- Loss: 0.21467101573944092
train-epoch-step: 92-247 -- Loss: 0.2060093879699707
train-epoch-step: 92-248 -- Loss: 0.18106138706207275
train-epoch-step: 92-249 -- Loss: 0.13951456546783447
train-epoch-step: 92-250 -- Loss: 0.19836565852165222
train-epoch-step: 92-251 -- Loss: 0.10326780378818512
train-epoch-step: 92-252 -- Loss: 0.1957327425479889
train-epoch-step: 92-253 -- Loss: 0.13345269858837128
train-epoch-step: 92-254 -- Loss: 0.2126573771238327
train-epoch-step: 92-255 -- Loss: 0.1392940878868103
train-epoch-step: 92-256 -- Loss: 0.1414760947227478
train-epoch-step: 92-257 -- Loss: 0.19311483204364777
train-epoch-step: 92-258 -- Loss: 0.13827167451381683
train-epoch-step: 92-259 -- Loss: 0.11236147582530975
train-epoch-step: 92-260 -- Loss: 0.19220870733261108
train-epoch-step: 92-261 -- Loss: 0.17010124027729034
train-epoch-step: 92-262 -- Loss: 0.29200777411460876
train-epoch-step: 92-263 -- Loss: 0.19608211517333984
train-epoch-step: 92-264 -- Loss: 0.17124702036380768
train-epoch-step: 92-265 -- Loss: 0.10765629261732101
train-epoch-step: 92-266 -- Loss: 0.14970248937606812
train-epoch-step: 92-267 -- Loss: 0.12404157221317291
train-epoch-step: 92-268 -- Loss: 0.11244852840900421
train-epoch-step: 92-269 -- Loss: 0.16541767120361328
train-epoch-step: 92-270 -- Loss: 0.10350236296653748
train-epoch-step: 92-271 -- Loss: 0.14583802223205566
train-epoch-step: 92-272 -- Loss: 0.11269143223762512
train-epoch-step: 92-273 -- Loss: 0.1223677396774292
train-epoch-step: 92-274 -- Loss: 0.17840823531150818
train-epoch-step: 92-275 -- Loss: 0.1927766650915146
train-epoch-step: 92-276 -- Loss: 0.15215104818344116
train-epoch-step: 92-277 -- Loss: 0.15526315569877625
train-epoch-step: 92-278 -- Loss: 0.13307541608810425
train-epoch-step: 92-279 -- Loss: 0.13188406825065613
train-epoch-step: 92-280 -- Loss: 0.2066119909286499
train-epoch-step: 92-281 -- Loss: 0.17557847499847412
train-epoch-step: 92-282 -- Loss: 0.13936898112297058
train-epoch-step: 92-283 -- Loss: 0.11169497668743134
train-epoch-step: 92-284 -- Loss: 0.13230301439762115
train-epoch-step: 92-285 -- Loss: 0.1847984790802002
train-epoch-step: 92-286 -- Loss: 0.1478833705186844
train-epoch-step: 92-287 -- Loss: 0.20306171476840973
train-epoch-step: 92-288 -- Loss: 0.09012702852487564
train-epoch-step: 92-289 -- Loss: 0.1269892007112503
train-epoch-step: 92-290 -- Loss: 0.17723581194877625
train-epoch-step: 92-291 -- Loss: 0.11559881269931793
train-epoch-step: 92-292 -- Loss: 0.15420934557914734
train-epoch-step: 92-293 -- Loss: 0.13296836614608765
train-epoch-step: 92-294 -- Loss: 0.15449602901935577
train-epoch-step: 92-295 -- Loss: 0.2626058757305145
train-epoch-step: 92-296 -- Loss: 0.15734805166721344
train-epoch-step: 92-297 -- Loss: 0.1674492210149765
train-epoch-step: 92-298 -- Loss: 0.21977800130844116
train-epoch-step: 92-299 -- Loss: 0.1390843391418457
train-epoch-step: 92-300 -- Loss: 0.1555633544921875
train-epoch-step: 92-301 -- Loss: 0.170315682888031
train-epoch-step: 92-302 -- Loss: 0.2135424017906189
train-epoch-step: 92-303 -- Loss: 0.1966509222984314
train-epoch-step: 92-304 -- Loss: 0.12923093140125275
train-epoch-step: 92-305 -- Loss: 0.1385970115661621
train-epoch-step: 92-306 -- Loss: 0.2056078463792801
train-epoch-step: 92-307 -- Loss: 0.16098910570144653
train-epoch-step: 92-308 -- Loss: 0.217122420668602
train-epoch-step: 92-309 -- Loss: 0.14899328351020813
train-epoch-step: 92-310 -- Loss: 0.15409554541110992
train-epoch-step: 92-311 -- Loss: 0.1579279899597168
train-epoch-step: 92-312 -- Loss: 0.19722777605056763
train-epoch-step: 92-313 -- Loss: 0.0930929109454155
train-epoch-step: 92-314 -- Loss: 0.1909836083650589
train-epoch-step: 92-315 -- Loss: 0.16163620352745056
train-epoch-step: 92-316 -- Loss: 0.14873677492141724
train-epoch-step: 92-317 -- Loss: 0.13440439105033875
train-epoch-step: 92-318 -- Loss: 0.15447278320789337
train-epoch-step: 92-319 -- Loss: 0.1646788865327835
train-epoch-step: 92-320 -- Loss: 0.1129118874669075
train-epoch-step: 92-321 -- Loss: 0.13351206481456757
train-epoch-step: 92-322 -- Loss: 0.20815080404281616
train-epoch-step: 92-323 -- Loss: 0.15412171185016632
train-epoch-step: 92-324 -- Loss: 0.24854011833667755
train-epoch-step: 92-325 -- Loss: 0.15084221959114075
train-epoch-step: 92-326 -- Loss: 0.16596326231956482
train-epoch-step: 92-327 -- Loss: 0.2021026462316513
train-epoch-step: 92-328 -- Loss: 0.18965090811252594
train-epoch-step: 92-329 -- Loss: 0.33045142889022827
train-epoch-step: 92-330 -- Loss: 0.3527824580669403
train-epoch-step: 92-331 -- Loss: 0.20544373989105225
train-epoch-step: 92-332 -- Loss: 0.09457838535308838
train-epoch-step: 92-333 -- Loss: 0.17470313608646393
train-epoch-step: 92-334 -- Loss: 0.14827601611614227
train-epoch-step: 92-335 -- Loss: 0.16738252341747284
train-epoch-step: 92-336 -- Loss: 0.1435731202363968
train-epoch-step: 92-337 -- Loss: 0.19866250455379486
train-epoch-step: 92-338 -- Loss: 0.1541772186756134
train-epoch-step: 92-339 -- Loss: 0.13867616653442383
train-epoch-step: 92-340 -- Loss: 0.19672074913978577
train-epoch-step: 92-341 -- Loss: 0.13512074947357178
train-epoch-step: 92-342 -- Loss: 0.15717382729053497
train-epoch-step: 92-343 -- Loss: 0.14531555771827698
train-epoch-step: 92-344 -- Loss: 0.1598949134349823
train-epoch-step: 92-345 -- Loss: 0.12717849016189575
train-epoch-step: 92-346 -- Loss: 0.21634222567081451
train-epoch-step: 92-347 -- Loss: 0.15145781636238098
train-epoch-step: 92-348 -- Loss: 0.19170133769512177
train-epoch-step: 92-349 -- Loss: 0.19649462401866913
train-epoch-step: 92-350 -- Loss: 0.2464863657951355
train-epoch-step: 92-351 -- Loss: 0.18960602581501007
train-epoch-step: 92-352 -- Loss: 0.12041577696800232
train-epoch-step: 92-353 -- Loss: 0.1887103021144867
train-epoch-step: 92-354 -- Loss: 0.27248165011405945
train-epoch-step: 92-355 -- Loss: 0.11604288220405579
train-epoch-step: 92-356 -- Loss: 0.113997682929039
train-epoch-step: 92-357 -- Loss: 0.18622291088104248
train-epoch-step: 92-358 -- Loss: 0.18120643496513367
train-epoch-step: 92-359 -- Loss: 0.13872429728507996
train-epoch-step: 92-360 -- Loss: 0.11834439635276794
train-epoch-step: 92-361 -- Loss: 0.22509130835533142
train-epoch-step: 92-362 -- Loss: 0.16429129242897034
train-epoch-step: 92-363 -- Loss: 0.105385921895504
train-epoch-step: 92-364 -- Loss: 0.17414654791355133
train-epoch-step: 92-365 -- Loss: 0.16670143604278564
train-epoch-step: 92-366 -- Loss: 0.20861071348190308
train-epoch-step: 92-367 -- Loss: 0.219395712018013
train-epoch-step: 92-368 -- Loss: 0.20354990661144257
train-epoch-step: 92-369 -- Loss: 0.26972976326942444
train-epoch-step: 92-370 -- Loss: 0.12152865529060364
train-epoch-step: 92-371 -- Loss: 0.11763782799243927
train-epoch-step: 92-372 -- Loss: 0.14445023238658905
train-epoch-step: 92-373 -- Loss: 0.19095256924629211
train-epoch-step: 92-374 -- Loss: 0.1488150954246521
train-epoch-step: 92-375 -- Loss: 0.2617057263851166
train-epoch-step: 92-376 -- Loss: 0.15891459584236145
train-epoch-step: 92-377 -- Loss: 0.22349609434604645
train-epoch-step: 92-378 -- Loss: 0.19046901166439056
train-epoch-step: 92-379 -- Loss: 0.11916311085224152
train-epoch-step: 92-380 -- Loss: 0.08948291838169098
train-epoch-step: 92-381 -- Loss: 0.24207940697669983
train-epoch-step: 92-382 -- Loss: 0.22469761967658997
train-epoch-step: 92-383 -- Loss: 0.17136168479919434
train-epoch-step: 92-384 -- Loss: 0.21153047680854797
train-epoch-step: 92-385 -- Loss: 0.1807646006345749
train-epoch-step: 92-386 -- Loss: 0.18419790267944336
train-epoch-step: 92-387 -- Loss: 0.20476233959197998
train-epoch-step: 92-388 -- Loss: 0.1939181387424469
train-epoch-step: 92-389 -- Loss: 0.16092446446418762
train-epoch-step: 92-390 -- Loss: 0.14091916382312775
train-epoch-step: 92-391 -- Loss: 0.14089274406433105
train-epoch-step: 92-392 -- Loss: 0.1817382574081421
train-epoch-step: 92-393 -- Loss: 0.15191839635372162
train-epoch-step: 92-394 -- Loss: 0.1911247968673706
train-epoch-step: 92-395 -- Loss: 0.15063929557800293
train-epoch-step: 92-396 -- Loss: 0.12184570729732513
train-epoch-step: 92-397 -- Loss: 0.11811387538909912
train-epoch-step: 92-398 -- Loss: 0.19507339596748352
train-epoch-step: 92-399 -- Loss: 0.16929936408996582
train-epoch-step: 92-400 -- Loss: 0.2665950059890747
train-epoch-step: 92-401 -- Loss: 0.11891214549541473
train-epoch-step: 92-402 -- Loss: 0.25718954205513
train-epoch-step: 92-403 -- Loss: 0.15070463716983795
train-epoch-step: 92-404 -- Loss: 0.1352721005678177
train-epoch-step: 92-405 -- Loss: 0.1378602385520935
train-epoch-step: 92-406 -- Loss: 0.15964213013648987
train-epoch-step: 92-407 -- Loss: 0.10946914553642273
train-epoch-step: 92-408 -- Loss: 0.16099052131175995
train-epoch-step: 92-409 -- Loss: 0.1638968586921692
train-epoch-step: 92-410 -- Loss: 0.16856274008750916
train-epoch-step: 92-411 -- Loss: 0.18595309555530548
train-epoch-step: 92-412 -- Loss: 0.12477587163448334
train-epoch-step: 92-413 -- Loss: 0.13984937965869904
train-epoch-step: 92-414 -- Loss: 0.12576249241828918
train-epoch-step: 92-415 -- Loss: 0.1309133619070053
train-epoch-step: 92-416 -- Loss: 0.2571518123149872
train-epoch-step: 92-417 -- Loss: 0.18347489833831787
train-epoch-step: 92-418 -- Loss: 0.2225402593612671
train-epoch-step: 92-419 -- Loss: 0.1624944508075714
train-epoch-step: 92-420 -- Loss: 0.14810703694820404
train-epoch-step: 92-421 -- Loss: 0.17765013873577118
train-epoch-step: 92-422 -- Loss: 0.14205501973628998
train-epoch-step: 92-423 -- Loss: 0.16963575780391693
train-epoch-step: 92-424 -- Loss: 0.1349361538887024
train-epoch-step: 92-425 -- Loss: 0.17595961689949036
train-epoch-step: 92-426 -- Loss: 0.1610555648803711
train-epoch-step: 92-427 -- Loss: 0.12417270243167877
train-epoch-step: 92-428 -- Loss: 0.20032276213169098
train-epoch-step: 92-429 -- Loss: 0.1734435111284256
train-epoch-step: 92-430 -- Loss: 0.13631078600883484
train-epoch-step: 92-431 -- Loss: 0.1533096432685852
train-epoch-step: 92-432 -- Loss: 0.22991587221622467
train-epoch-step: 92-433 -- Loss: 0.1356237530708313
train-epoch-step: 92-434 -- Loss: 0.12919776141643524
train-epoch-step: 92-435 -- Loss: 0.14950136840343475
train-epoch-step: 92-436 -- Loss: 0.1499570608139038
train-epoch-step: 92-437 -- Loss: 0.13011965155601501
train-epoch-step: 92-438 -- Loss: 0.16261276602745056
train-epoch-step: 92-439 -- Loss: 0.2524050772190094
train-epoch-step: 92-440 -- Loss: 0.12975506484508514
train-epoch-step: 92-441 -- Loss: 0.19408190250396729
train-epoch-step: 92-442 -- Loss: 0.17090845108032227
train-epoch-step: 92-443 -- Loss: 0.1496761441230774
train-epoch-step: 92-444 -- Loss: 0.16565100848674774
train-epoch-step: 92-445 -- Loss: 0.1709458827972412
train-epoch-step: 92-446 -- Loss: 0.14862097799777985
train-epoch-step: 92-447 -- Loss: 0.18601980805397034
train-epoch-step: 92-448 -- Loss: 0.21732847392559052
train-epoch-step: 92-449 -- Loss: 0.1852031797170639
train-epoch-step: 92-450 -- Loss: 0.1722346842288971
train-epoch-step: 92-451 -- Loss: 0.13836871087551117
train-epoch-step: 92-452 -- Loss: 0.12725964188575745
train-epoch-step: 92-453 -- Loss: 0.09061311930418015
train-epoch-step: 92-454 -- Loss: 0.22458508610725403
train-epoch-step: 92-455 -- Loss: 0.11670570075511932
train-epoch-step: 92-456 -- Loss: 0.11373912543058395
train-epoch-step: 92-457 -- Loss: 0.20673224329948425
train-epoch-step: 92-458 -- Loss: 0.14938044548034668
train-epoch-step: 92-459 -- Loss: 0.20494073629379272
train-epoch-step: 92-460 -- Loss: 0.12584277987480164
train-epoch-step: 92-461 -- Loss: 0.12933418154716492
train-epoch-step: 92-462 -- Loss: 0.15492595732212067
train-epoch-step: 92-463 -- Loss: 0.13129505515098572
train-epoch-step: 92-464 -- Loss: 0.15349678695201874
train-epoch-step: 92-465 -- Loss: 0.23251134157180786
train-epoch-step: 92-466 -- Loss: 0.19618180394172668
train-epoch-step: 92-467 -- Loss: 0.11148156225681305
train-epoch-step: 92-468 -- Loss: 0.16592945158481598
train-epoch-step: 92-469 -- Loss: 0.19766530394554138
train-epoch-step: 92-470 -- Loss: 0.17209967970848083
train-epoch-step: 92-471 -- Loss: 0.1468883752822876
train-epoch-step: 92-472 -- Loss: 0.1578635573387146
train-epoch-step: 92-473 -- Loss: 0.1529775708913803
train-epoch-step: 92-474 -- Loss: 0.11339809745550156
train-epoch-step: 92-475 -- Loss: 0.10496766120195389
train-epoch-step: 92-476 -- Loss: 0.19358116388320923
train-epoch-step: 92-477 -- Loss: 0.19754701852798462
train-epoch-step: 92-478 -- Loss: 0.18130049109458923
train-epoch-step: 92-479 -- Loss: 0.1376197338104248
train-epoch-step: 92-480 -- Loss: 0.18904316425323486
train-epoch-step: 92-481 -- Loss: 0.28173258900642395
train-epoch-step: 92-482 -- Loss: 0.24191465973854065
train-epoch-step: 92-483 -- Loss: 0.1726822853088379
train-epoch-step: 92-484 -- Loss: 0.21055817604064941
train-epoch-step: 92-485 -- Loss: 0.12122312188148499
train-epoch-step: 92-486 -- Loss: 0.22521716356277466
train-epoch-step: 92-487 -- Loss: 0.22560042142868042
train-epoch-step: 92-488 -- Loss: 0.19648052752017975
train-epoch-step: 92-489 -- Loss: 0.21417072415351868
train-epoch-step: 92-490 -- Loss: 0.12942306697368622
train-epoch-step: 92-491 -- Loss: 0.13401612639427185
train-epoch-step: 92-492 -- Loss: 0.12509329617023468
train-epoch-step: 92-493 -- Loss: 0.19556951522827148
train-epoch-step: 92-494 -- Loss: 0.2070474922657013
train-epoch-step: 92-495 -- Loss: 0.19918015599250793
train-epoch-step: 92-496 -- Loss: 0.13858769834041595
train-epoch-step: 92-497 -- Loss: 0.17593039572238922
train-epoch-step: 92-498 -- Loss: 0.14302286505699158
train-epoch-step: 92-499 -- Loss: 0.16414915025234222
train-epoch-step: 92-500 -- Loss: 0.14850500226020813
train-epoch-step: 92-501 -- Loss: 0.21509797871112823
train-epoch-step: 92-502 -- Loss: 0.161685511469841
train-epoch-step: 92-503 -- Loss: 0.2102571278810501
train-epoch-step: 92-504 -- Loss: 0.11576372385025024
train-epoch-step: 92-505 -- Loss: 0.16537146270275116
train-epoch-step: 92-506 -- Loss: 0.1134197786450386
train-epoch-step: 92-507 -- Loss: 0.17171895503997803
train-epoch-step: 92-508 -- Loss: 0.16778111457824707
train-epoch-step: 92-509 -- Loss: 0.1671791672706604
train-epoch-step: 92-510 -- Loss: 0.12542077898979187
train-epoch-step: 92-511 -- Loss: 0.21159307658672333
train-epoch-step: 92-512 -- Loss: 0.17319057881832123
train-epoch-step: 92-513 -- Loss: 0.18285724520683289
train-epoch-step: 92-514 -- Loss: 0.14313927292823792
train-epoch-step: 92-515 -- Loss: 0.1475735902786255
train-epoch-step: 92-516 -- Loss: 0.1660347431898117
train-epoch-step: 92-517 -- Loss: 0.16683439910411835
train-epoch-step: 92-518 -- Loss: 0.13664968311786652
train-epoch-step: 92-519 -- Loss: 0.13602423667907715
train-epoch-step: 92-520 -- Loss: 0.18172186613082886
train-epoch-step: 92-521 -- Loss: 0.22183319926261902
train-epoch-step: 92-522 -- Loss: 0.1650545299053192
train-epoch-step: 92-523 -- Loss: 0.1519102305173874
train-epoch-step: 92-524 -- Loss: 0.16381067037582397
train-epoch-step: 92-525 -- Loss: 0.18885517120361328
train-epoch-step: 92-526 -- Loss: 0.12344738095998764
train-epoch-step: 92-527 -- Loss: 0.14599256217479706
train-epoch-step: 92-528 -- Loss: 0.14962349832057953
train-epoch-step: 92-529 -- Loss: 0.15132246911525726
train-epoch-step: 92-530 -- Loss: 0.16280847787857056
train-epoch-step: 92-531 -- Loss: 0.1909835934638977
train-epoch-step: 92-532 -- Loss: 0.1644790917634964
train-epoch-step: 92-533 -- Loss: 0.172841414809227
train-epoch-step: 92-534 -- Loss: 0.12741470336914062
train-epoch-step: 92-535 -- Loss: 0.2491265833377838
train-epoch-step: 92-536 -- Loss: 0.1520010232925415
train-epoch-step: 92-537 -- Loss: 0.14920450747013092
train-epoch-step: 92-538 -- Loss: 0.10208360105752945
train-epoch-step: 92-539 -- Loss: 0.1755935251712799
train-epoch-step: 92-540 -- Loss: 0.12978097796440125
train-epoch-step: 92-541 -- Loss: 0.20307651162147522
train-epoch-step: 92-542 -- Loss: 0.23138682544231415
train-epoch-step: 92-543 -- Loss: 0.16495820879936218
train-epoch-step: 92-544 -- Loss: 0.22910545766353607
train-epoch-step: 92-545 -- Loss: 0.1876383274793625
train-epoch-step: 92-546 -- Loss: 0.20175433158874512
train-epoch-step: 92-547 -- Loss: 0.17989619076251984
train-epoch-step: 92-548 -- Loss: 0.08858269453048706
train-epoch-step: 92-549 -- Loss: 0.1479826271533966
train-epoch-step: 92-550 -- Loss: 0.19123417139053345
train-epoch-step: 92-551 -- Loss: 0.15319779515266418
train-epoch-step: 92-552 -- Loss: 0.12270011007785797
train-epoch-step: 92-553 -- Loss: 0.18219444155693054
train-epoch-step: 92-554 -- Loss: 0.18391379714012146
train-epoch-step: 92-555 -- Loss: 0.2101309448480606
train-epoch-step: 92-556 -- Loss: 0.15009713172912598
train-epoch-step: 92-557 -- Loss: 0.2463662028312683
train-epoch-step: 92-558 -- Loss: 0.2252492904663086
train-epoch-step: 92-559 -- Loss: 0.13044987618923187
train-epoch-step: 92-560 -- Loss: 0.20795592665672302
train-epoch-step: 92-561 -- Loss: 0.17615105211734772
train-epoch-step: 92-562 -- Loss: 0.1580909639596939
train-epoch-step: 92-563 -- Loss: 0.17927321791648865
train-epoch-step: 92-564 -- Loss: 0.09505078941583633
train-epoch-step: 92-565 -- Loss: 0.19244354963302612
train-epoch-step: 92-566 -- Loss: 0.1440943330526352
train-epoch-step: 92-567 -- Loss: 0.20485377311706543
train-epoch-step: 92-568 -- Loss: 0.1552588939666748
train-epoch-step: 92-569 -- Loss: 0.243040531873703
train-epoch-step: 92-570 -- Loss: 0.16615194082260132
train-epoch-step: 92-571 -- Loss: 0.20581203699111938
train-epoch-step: 92-572 -- Loss: 0.23045018315315247
train-epoch-step: 92-573 -- Loss: 0.19361931085586548
train-epoch-step: 92-574 -- Loss: 0.23712235689163208
train-epoch-step: 92-575 -- Loss: 0.2959088385105133
train-epoch-step: 92-576 -- Loss: 0.11761946231126785
train-epoch-step: 92-577 -- Loss: 0.16337057948112488
train-epoch-step: 92-578 -- Loss: 0.20724976062774658
train-epoch-step: 92-579 -- Loss: 0.15646956861019135
train-epoch-step: 92-580 -- Loss: 0.16905106604099274
train-epoch-step: 92-581 -- Loss: 0.13683584332466125
train-epoch-step: 92-582 -- Loss: 0.2037629634141922
train-epoch-step: 92-583 -- Loss: 0.2023790031671524
train-epoch-step: 92-584 -- Loss: 0.15845929086208344
train-epoch-step: 92-585 -- Loss: 0.192840576171875
train-epoch-step: 92-586 -- Loss: 0.24519795179367065
train-epoch-step: 92-587 -- Loss: 0.15065468847751617
train-epoch-step: 92-588 -- Loss: 0.12533190846443176
val-epoch-step: 92-589 -- Loss: 0.19522079825401306
val-epoch-step: 92-590 -- Loss: 0.15253126621246338
val-epoch-step: 92-591 -- Loss: 0.24302004277706146
val-epoch-step: 92-592 -- Loss: 0.16848784685134888
val-epoch-step: 92-593 -- Loss: 0.1466880887746811
val-epoch-step: 92-594 -- Loss: 0.34914666414260864
val-epoch-step: 92-595 -- Loss: 0.17062439024448395
val-epoch-step: 92-596 -- Loss: 0.20813557505607605
val-epoch-step: 92-597 -- Loss: 0.16883188486099243
val-epoch-step: 92-598 -- Loss: 0.15053169429302216
val-epoch-step: 92-599 -- Loss: 0.18145348131656647
val-epoch-step: 92-600 -- Loss: 0.20152141153812408
val-epoch-step: 92-601 -- Loss: 0.1552819460630417
val-epoch-step: 92-602 -- Loss: 0.1377873420715332
val-epoch-step: 92-603 -- Loss: 0.17978066205978394
val-epoch-step: 92-604 -- Loss: 0.1465456187725067
val-epoch-step: 92-605 -- Loss: 0.14164991676807404
val-epoch-step: 92-606 -- Loss: 0.2770911455154419
val-epoch-step: 92-607 -- Loss: 0.1271466612815857
val-epoch-step: 92-608 -- Loss: 0.24114444851875305
val-epoch-step: 92-609 -- Loss: 0.16092906892299652
val-epoch-step: 92-610 -- Loss: 0.17643055319786072
val-epoch-step: 92-611 -- Loss: 0.15263943374156952
val-epoch-step: 92-612 -- Loss: 0.42492133378982544
val-epoch-step: 92-613 -- Loss: 0.16816140711307526
val-epoch-step: 92-614 -- Loss: 0.17529605329036713
val-epoch-step: 92-615 -- Loss: 0.16866852343082428
val-epoch-step: 92-616 -- Loss: 0.1479053497314453
val-epoch-step: 92-617 -- Loss: 0.1804855465888977
val-epoch-step: 92-618 -- Loss: 0.21254971623420715
val-epoch-step: 92-619 -- Loss: 0.21073007583618164
val-epoch-step: 92-620 -- Loss: 0.1354122757911682
val-epoch-step: 92-621 -- Loss: 0.12393134832382202
val-epoch-step: 92-622 -- Loss: 0.14546822011470795
val-epoch-step: 92-623 -- Loss: 0.14488568902015686
val-epoch-step: 92-624 -- Loss: 0.1382766216993332
val-epoch-step: 92-625 -- Loss: 0.1516401171684265
val-epoch-step: 92-626 -- Loss: 0.14403343200683594
val-epoch-step: 92-627 -- Loss: 0.17817573249340057
val-epoch-step: 92-628 -- Loss: 0.5798943042755127
val-epoch-step: 92-629 -- Loss: 0.2058251053094864
val-epoch-step: 92-630 -- Loss: 0.3398410379886627
val-epoch-step: 92-631 -- Loss: 0.15337128937244415
val-epoch-step: 92-632 -- Loss: 0.19852480292320251
val-epoch-step: 92-633 -- Loss: 0.1503675878047943
val-epoch-step: 92-634 -- Loss: 0.1386185586452484
val-epoch-step: 92-635 -- Loss: 0.10786489397287369
val-epoch-step: 92-636 -- Loss: 0.1651114672422409
val-epoch-step: 92-637 -- Loss: 0.17588792741298676
val-epoch-step: 92-638 -- Loss: 0.14780227839946747
val-epoch-step: 92-639 -- Loss: 0.25527119636535645
val-epoch-step: 92-640 -- Loss: 0.24794304370880127
val-epoch-step: 92-641 -- Loss: 0.13597238063812256
val-epoch-step: 92-642 -- Loss: 0.18174318969249725
val-epoch-step: 92-643 -- Loss: 0.21077394485473633
val-epoch-step: 92-644 -- Loss: 0.16319312155246735
val-epoch-step: 92-645 -- Loss: 0.21802426874637604
val-epoch-step: 92-646 -- Loss: 0.126242995262146
val-epoch-step: 92-647 -- Loss: 0.12426933646202087
val-epoch-step: 92-648 -- Loss: 0.1514488309621811
val-epoch-step: 92-649 -- Loss: 0.20805364847183228
val-epoch-step: 92-650 -- Loss: 0.2412625402212143
val-epoch-step: 92-651 -- Loss: 0.15434622764587402
val-epoch-step: 92-652 -- Loss: 0.1499311923980713
val-epoch-step: 92-653 -- Loss: 0.20440039038658142
val-epoch-step: 92-654 -- Loss: 0.11836761236190796
Epoch: 92 -- Train Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 93-0 -- Loss: 0.2152157723903656
train-epoch-step: 93-1 -- Loss: 0.1408916711807251
train-epoch-step: 93-2 -- Loss: 0.19441305100917816
train-epoch-step: 93-3 -- Loss: 0.13957719504833221
train-epoch-step: 93-4 -- Loss: 0.1541614979505539
train-epoch-step: 93-5 -- Loss: 0.18460994958877563
train-epoch-step: 93-6 -- Loss: 0.22775709629058838
train-epoch-step: 93-7 -- Loss: 0.16454346477985382
train-epoch-step: 93-8 -- Loss: 0.17327237129211426
train-epoch-step: 93-9 -- Loss: 0.22511740028858185
train-epoch-step: 93-10 -- Loss: 0.18341201543807983
train-epoch-step: 93-11 -- Loss: 0.17288237810134888
train-epoch-step: 93-12 -- Loss: 0.14776459336280823
train-epoch-step: 93-13 -- Loss: 0.1727973222732544
train-epoch-step: 93-14 -- Loss: 0.16124847531318665
train-epoch-step: 93-15 -- Loss: 0.15948866307735443
train-epoch-step: 93-16 -- Loss: 0.16189701855182648
train-epoch-step: 93-17 -- Loss: 0.23378032445907593
train-epoch-step: 93-18 -- Loss: 0.18740719556808472
train-epoch-step: 93-19 -- Loss: 0.1255178600549698
train-epoch-step: 93-20 -- Loss: 0.21044835448265076
train-epoch-step: 93-21 -- Loss: 0.29850471019744873
train-epoch-step: 93-22 -- Loss: 0.13991574943065643
train-epoch-step: 93-23 -- Loss: 0.13854429125785828
train-epoch-step: 93-24 -- Loss: 0.12319821864366531
train-epoch-step: 93-25 -- Loss: 0.23756584525108337
train-epoch-step: 93-26 -- Loss: 0.18967293202877045
train-epoch-step: 93-27 -- Loss: 0.30240389704704285
train-epoch-step: 93-28 -- Loss: 0.12711355090141296
train-epoch-step: 93-29 -- Loss: 0.2613990902900696
train-epoch-step: 93-30 -- Loss: 0.11952701210975647
train-epoch-step: 93-31 -- Loss: 0.15567535161972046
train-epoch-step: 93-32 -- Loss: 0.17646366357803345
train-epoch-step: 93-33 -- Loss: 0.286828875541687
train-epoch-step: 93-34 -- Loss: 0.1868053525686264
train-epoch-step: 93-35 -- Loss: 0.2674385905265808
train-epoch-step: 93-36 -- Loss: 0.14785893261432648
train-epoch-step: 93-37 -- Loss: 0.14366403222084045
train-epoch-step: 93-38 -- Loss: 0.17179574072360992
train-epoch-step: 93-39 -- Loss: 0.2944216728210449
train-epoch-step: 93-40 -- Loss: 0.25506412982940674
train-epoch-step: 93-41 -- Loss: 0.21785500645637512
train-epoch-step: 93-42 -- Loss: 0.15951518714427948
train-epoch-step: 93-43 -- Loss: 0.2756955027580261
train-epoch-step: 93-44 -- Loss: 0.13678236305713654
train-epoch-step: 93-45 -- Loss: 0.12112870067358017
train-epoch-step: 93-46 -- Loss: 0.1825307011604309
train-epoch-step: 93-47 -- Loss: 0.21806153655052185
train-epoch-step: 93-48 -- Loss: 0.15991318225860596
train-epoch-step: 93-49 -- Loss: 0.2745022773742676
train-epoch-step: 93-50 -- Loss: 0.12466706335544586
train-epoch-step: 93-51 -- Loss: 0.20865191519260406
train-epoch-step: 93-52 -- Loss: 0.18267302215099335
train-epoch-step: 93-53 -- Loss: 0.21824324131011963
train-epoch-step: 93-54 -- Loss: 0.32955312728881836
train-epoch-step: 93-55 -- Loss: 0.22109828889369965
train-epoch-step: 93-56 -- Loss: 0.1783059537410736
train-epoch-step: 93-57 -- Loss: 0.2559472322463989
train-epoch-step: 93-58 -- Loss: 0.3114171624183655
train-epoch-step: 93-59 -- Loss: 0.277478963136673
train-epoch-step: 93-60 -- Loss: 0.14769941568374634
train-epoch-step: 93-61 -- Loss: 0.24436108767986298
train-epoch-step: 93-62 -- Loss: 0.19911730289459229
train-epoch-step: 93-63 -- Loss: 0.16688278317451477
train-epoch-step: 93-64 -- Loss: 0.16640013456344604
train-epoch-step: 93-65 -- Loss: 0.1991579830646515
train-epoch-step: 93-66 -- Loss: 0.1312144696712494
train-epoch-step: 93-67 -- Loss: 0.13403141498565674
train-epoch-step: 93-68 -- Loss: 0.25885891914367676
train-epoch-step: 93-69 -- Loss: 0.1542375087738037
train-epoch-step: 93-70 -- Loss: 0.24098286032676697
train-epoch-step: 93-71 -- Loss: 0.2679089307785034
train-epoch-step: 93-72 -- Loss: 0.1813419908285141
train-epoch-step: 93-73 -- Loss: 0.22158578038215637
train-epoch-step: 93-74 -- Loss: 0.10543619096279144
train-epoch-step: 93-75 -- Loss: 0.13292762637138367
train-epoch-step: 93-76 -- Loss: 0.15136849880218506
train-epoch-step: 93-77 -- Loss: 0.24155274033546448
train-epoch-step: 93-78 -- Loss: 0.3418000638484955
train-epoch-step: 93-79 -- Loss: 0.19606561958789825
train-epoch-step: 93-80 -- Loss: 0.2468242645263672
train-epoch-step: 93-81 -- Loss: 0.13279330730438232
train-epoch-step: 93-82 -- Loss: 0.25224336981773376
train-epoch-step: 93-83 -- Loss: 0.17696616053581238
train-epoch-step: 93-84 -- Loss: 0.1945846676826477
train-epoch-step: 93-85 -- Loss: 0.17792221903800964
train-epoch-step: 93-86 -- Loss: 0.12134207785129547
train-epoch-step: 93-87 -- Loss: 0.213238924741745
train-epoch-step: 93-88 -- Loss: 0.14071525633335114
train-epoch-step: 93-89 -- Loss: 0.187970831990242
train-epoch-step: 93-90 -- Loss: 0.19126659631729126
train-epoch-step: 93-91 -- Loss: 0.24854137003421783
train-epoch-step: 93-92 -- Loss: 0.1513334959745407
train-epoch-step: 93-93 -- Loss: 0.17644459009170532
train-epoch-step: 93-94 -- Loss: 0.23223641514778137
train-epoch-step: 93-95 -- Loss: 0.188683420419693
train-epoch-step: 93-96 -- Loss: 0.21392449736595154
train-epoch-step: 93-97 -- Loss: 0.17355503141880035
train-epoch-step: 93-98 -- Loss: 0.15188616514205933
train-epoch-step: 93-99 -- Loss: 0.1812666356563568
train-epoch-step: 93-100 -- Loss: 0.18497894704341888
train-epoch-step: 93-101 -- Loss: 0.27565842866897583
train-epoch-step: 93-102 -- Loss: 0.2444024384021759
train-epoch-step: 93-103 -- Loss: 0.18517234921455383
train-epoch-step: 93-104 -- Loss: 0.14840121567249298
train-epoch-step: 93-105 -- Loss: 0.2817454934120178
train-epoch-step: 93-106 -- Loss: 0.17990848422050476
train-epoch-step: 93-107 -- Loss: 0.18476159870624542
train-epoch-step: 93-108 -- Loss: 0.18894922733306885
train-epoch-step: 93-109 -- Loss: 0.14700882136821747
train-epoch-step: 93-110 -- Loss: 0.18713173270225525
train-epoch-step: 93-111 -- Loss: 0.1825539618730545
train-epoch-step: 93-112 -- Loss: 0.18074987828731537
train-epoch-step: 93-113 -- Loss: 0.16893531382083893
train-epoch-step: 93-114 -- Loss: 0.19321183860301971
train-epoch-step: 93-115 -- Loss: 0.16315847635269165
train-epoch-step: 93-116 -- Loss: 0.14258690178394318
train-epoch-step: 93-117 -- Loss: 0.12446048110723495
train-epoch-step: 93-118 -- Loss: 0.18840853869915009
train-epoch-step: 93-119 -- Loss: 0.14838629961013794
train-epoch-step: 93-120 -- Loss: 0.2418726086616516
train-epoch-step: 93-121 -- Loss: 0.24773181974887848
train-epoch-step: 93-122 -- Loss: 0.21629220247268677
train-epoch-step: 93-123 -- Loss: 0.20619550347328186
train-epoch-step: 93-124 -- Loss: 0.12032545357942581
train-epoch-step: 93-125 -- Loss: 0.1515606790781021
train-epoch-step: 93-126 -- Loss: 0.2304185926914215
train-epoch-step: 93-127 -- Loss: 0.17203004658222198
train-epoch-step: 93-128 -- Loss: 0.17168042063713074
train-epoch-step: 93-129 -- Loss: 0.1512008011341095
train-epoch-step: 93-130 -- Loss: 0.19935321807861328
train-epoch-step: 93-131 -- Loss: 0.13806326687335968
train-epoch-step: 93-132 -- Loss: 0.1820390224456787
train-epoch-step: 93-133 -- Loss: 0.11310675740242004
train-epoch-step: 93-134 -- Loss: 0.19041740894317627
train-epoch-step: 93-135 -- Loss: 0.13651162385940552
train-epoch-step: 93-136 -- Loss: 0.12616345286369324
train-epoch-step: 93-137 -- Loss: 0.24326734244823456
train-epoch-step: 93-138 -- Loss: 0.2670464515686035
train-epoch-step: 93-139 -- Loss: 0.1329909861087799
train-epoch-step: 93-140 -- Loss: 0.21443666517734528
train-epoch-step: 93-141 -- Loss: 0.22845035791397095
train-epoch-step: 93-142 -- Loss: 0.19873672723770142
train-epoch-step: 93-143 -- Loss: 0.17508122324943542
train-epoch-step: 93-144 -- Loss: 0.1818539798259735
train-epoch-step: 93-145 -- Loss: 0.1467610001564026
train-epoch-step: 93-146 -- Loss: 0.18366628885269165
train-epoch-step: 93-147 -- Loss: 0.17490926384925842
train-epoch-step: 93-148 -- Loss: 0.15848305821418762
train-epoch-step: 93-149 -- Loss: 0.12948620319366455
train-epoch-step: 93-150 -- Loss: 0.1835867315530777
train-epoch-step: 93-151 -- Loss: 0.19342140853405
train-epoch-step: 93-152 -- Loss: 0.18965621292591095
train-epoch-step: 93-153 -- Loss: 0.255810022354126
train-epoch-step: 93-154 -- Loss: 0.12937046587467194
train-epoch-step: 93-155 -- Loss: 0.13844364881515503
train-epoch-step: 93-156 -- Loss: 0.1128978431224823
train-epoch-step: 93-157 -- Loss: 0.15669399499893188
train-epoch-step: 93-158 -- Loss: 0.16630616784095764
train-epoch-step: 93-159 -- Loss: 0.17453351616859436
train-epoch-step: 93-160 -- Loss: 0.23412564396858215
train-epoch-step: 93-161 -- Loss: 0.19616630673408508
train-epoch-step: 93-162 -- Loss: 0.20788109302520752
train-epoch-step: 93-163 -- Loss: 0.18663756549358368
train-epoch-step: 93-164 -- Loss: 0.189255952835083
train-epoch-step: 93-165 -- Loss: 0.16073890030384064
train-epoch-step: 93-166 -- Loss: 0.12136049568653107
train-epoch-step: 93-167 -- Loss: 0.11844493448734283
train-epoch-step: 93-168 -- Loss: 0.19705545902252197
train-epoch-step: 93-169 -- Loss: 0.1369280368089676
train-epoch-step: 93-170 -- Loss: 0.20221781730651855
train-epoch-step: 93-171 -- Loss: 0.14275121688842773
train-epoch-step: 93-172 -- Loss: 0.2574915289878845
train-epoch-step: 93-173 -- Loss: 0.1287890374660492
train-epoch-step: 93-174 -- Loss: 0.24602022767066956
train-epoch-step: 93-175 -- Loss: 0.18169263005256653
train-epoch-step: 93-176 -- Loss: 0.12876908481121063
train-epoch-step: 93-177 -- Loss: 0.17233358323574066
train-epoch-step: 93-178 -- Loss: 0.19225938618183136
train-epoch-step: 93-179 -- Loss: 0.1520366370677948
train-epoch-step: 93-180 -- Loss: 0.14863155782222748
train-epoch-step: 93-181 -- Loss: 0.17503805458545685
train-epoch-step: 93-182 -- Loss: 0.1970137655735016
train-epoch-step: 93-183 -- Loss: 0.27697211503982544
train-epoch-step: 93-184 -- Loss: 0.13755640387535095
train-epoch-step: 93-185 -- Loss: 0.14065919816493988
train-epoch-step: 93-186 -- Loss: 0.20504069328308105
train-epoch-step: 93-187 -- Loss: 0.20365583896636963
train-epoch-step: 93-188 -- Loss: 0.16584019362926483
train-epoch-step: 93-189 -- Loss: 0.10507723689079285
train-epoch-step: 93-190 -- Loss: 0.1879246085882187
train-epoch-step: 93-191 -- Loss: 0.15538130700588226
train-epoch-step: 93-192 -- Loss: 0.2195831686258316
train-epoch-step: 93-193 -- Loss: 0.2074839472770691
train-epoch-step: 93-194 -- Loss: 0.17764422297477722
train-epoch-step: 93-195 -- Loss: 0.16580966114997864
train-epoch-step: 93-196 -- Loss: 0.1647450029850006
train-epoch-step: 93-197 -- Loss: 0.1196373850107193
train-epoch-step: 93-198 -- Loss: 0.12502679228782654
train-epoch-step: 93-199 -- Loss: 0.14352118968963623
train-epoch-step: 93-200 -- Loss: 0.12172730267047882
train-epoch-step: 93-201 -- Loss: 0.1826382428407669
train-epoch-step: 93-202 -- Loss: 0.13307735323905945
train-epoch-step: 93-203 -- Loss: 0.16802878677845
train-epoch-step: 93-204 -- Loss: 0.13521841168403625
train-epoch-step: 93-205 -- Loss: 0.1841815561056137
train-epoch-step: 93-206 -- Loss: 0.19756869971752167
train-epoch-step: 93-207 -- Loss: 0.12993793189525604
train-epoch-step: 93-208 -- Loss: 0.17613908648490906
train-epoch-step: 93-209 -- Loss: 0.14142556488513947
train-epoch-step: 93-210 -- Loss: 0.13127359747886658
train-epoch-step: 93-211 -- Loss: 0.2043653130531311
train-epoch-step: 93-212 -- Loss: 0.192999005317688
train-epoch-step: 93-213 -- Loss: 0.1256919801235199
train-epoch-step: 93-214 -- Loss: 0.1453433632850647
train-epoch-step: 93-215 -- Loss: 0.12409074604511261
train-epoch-step: 93-216 -- Loss: 0.19497255980968475
train-epoch-step: 93-217 -- Loss: 0.21369031071662903
train-epoch-step: 93-218 -- Loss: 0.13897641003131866
train-epoch-step: 93-219 -- Loss: 0.1666432023048401
train-epoch-step: 93-220 -- Loss: 0.126033216714859
train-epoch-step: 93-221 -- Loss: 0.19636231660842896
train-epoch-step: 93-222 -- Loss: 0.1146341934800148
train-epoch-step: 93-223 -- Loss: 0.17186103761196136
train-epoch-step: 93-224 -- Loss: 0.181229829788208
train-epoch-step: 93-225 -- Loss: 0.26054391264915466
train-epoch-step: 93-226 -- Loss: 0.19907893240451813
train-epoch-step: 93-227 -- Loss: 0.2135506570339203
train-epoch-step: 93-228 -- Loss: 0.17369259893894196
train-epoch-step: 93-229 -- Loss: 0.17228977382183075
train-epoch-step: 93-230 -- Loss: 0.15597499907016754
train-epoch-step: 93-231 -- Loss: 0.15138375759124756
train-epoch-step: 93-232 -- Loss: 0.18623965978622437
train-epoch-step: 93-233 -- Loss: 0.08257037401199341
train-epoch-step: 93-234 -- Loss: 0.16833333671092987
train-epoch-step: 93-235 -- Loss: 0.14297792315483093
train-epoch-step: 93-236 -- Loss: 0.1785314381122589
train-epoch-step: 93-237 -- Loss: 0.2269321233034134
train-epoch-step: 93-238 -- Loss: 0.14825327694416046
train-epoch-step: 93-239 -- Loss: 0.1241188645362854
train-epoch-step: 93-240 -- Loss: 0.22648608684539795
train-epoch-step: 93-241 -- Loss: 0.15367768704891205
train-epoch-step: 93-242 -- Loss: 0.21560025215148926
train-epoch-step: 93-243 -- Loss: 0.2349342554807663
train-epoch-step: 93-244 -- Loss: 0.20233681797981262
train-epoch-step: 93-245 -- Loss: 0.20803816616535187
train-epoch-step: 93-246 -- Loss: 0.21507281064987183
train-epoch-step: 93-247 -- Loss: 0.20661193132400513
train-epoch-step: 93-248 -- Loss: 0.186746746301651
train-epoch-step: 93-249 -- Loss: 0.13594257831573486
train-epoch-step: 93-250 -- Loss: 0.19478943943977356
train-epoch-step: 93-251 -- Loss: 0.10615092515945435
train-epoch-step: 93-252 -- Loss: 0.19908857345581055
train-epoch-step: 93-253 -- Loss: 0.13452154397964478
train-epoch-step: 93-254 -- Loss: 0.2083011269569397
train-epoch-step: 93-255 -- Loss: 0.14332757890224457
train-epoch-step: 93-256 -- Loss: 0.1420026570558548
train-epoch-step: 93-257 -- Loss: 0.1920139640569687
train-epoch-step: 93-258 -- Loss: 0.13890758156776428
train-epoch-step: 93-259 -- Loss: 0.1122051328420639
train-epoch-step: 93-260 -- Loss: 0.19483192265033722
train-epoch-step: 93-261 -- Loss: 0.17005851864814758
train-epoch-step: 93-262 -- Loss: 0.29001080989837646
train-epoch-step: 93-263 -- Loss: 0.1997719705104828
train-epoch-step: 93-264 -- Loss: 0.17792576551437378
train-epoch-step: 93-265 -- Loss: 0.11960271745920181
train-epoch-step: 93-266 -- Loss: 0.15023642778396606
train-epoch-step: 93-267 -- Loss: 0.13042032718658447
train-epoch-step: 93-268 -- Loss: 0.11592115461826324
train-epoch-step: 93-269 -- Loss: 0.17036563158035278
train-epoch-step: 93-270 -- Loss: 0.1051579937338829
train-epoch-step: 93-271 -- Loss: 0.15152360498905182
train-epoch-step: 93-272 -- Loss: 0.11141796410083771
train-epoch-step: 93-273 -- Loss: 0.12192299216985703
train-epoch-step: 93-274 -- Loss: 0.1782541573047638
train-epoch-step: 93-275 -- Loss: 0.1824527084827423
train-epoch-step: 93-276 -- Loss: 0.1500924527645111
train-epoch-step: 93-277 -- Loss: 0.15297619998455048
train-epoch-step: 93-278 -- Loss: 0.13705535233020782
train-epoch-step: 93-279 -- Loss: 0.1383628249168396
train-epoch-step: 93-280 -- Loss: 0.2159486711025238
train-epoch-step: 93-281 -- Loss: 0.17177578806877136
train-epoch-step: 93-282 -- Loss: 0.1388946771621704
train-epoch-step: 93-283 -- Loss: 0.11741670966148376
train-epoch-step: 93-284 -- Loss: 0.17511975765228271
train-epoch-step: 93-285 -- Loss: 0.18703220784664154
train-epoch-step: 93-286 -- Loss: 0.14855845272541046
train-epoch-step: 93-287 -- Loss: 0.19781553745269775
train-epoch-step: 93-288 -- Loss: 0.0927238017320633
train-epoch-step: 93-289 -- Loss: 0.11582359671592712
train-epoch-step: 93-290 -- Loss: 0.1786712110042572
train-epoch-step: 93-291 -- Loss: 0.11585667729377747
train-epoch-step: 93-292 -- Loss: 0.155075341463089
train-epoch-step: 93-293 -- Loss: 0.14129522442817688
train-epoch-step: 93-294 -- Loss: 0.16446998715400696
train-epoch-step: 93-295 -- Loss: 0.31968095898628235
train-epoch-step: 93-296 -- Loss: 0.17860639095306396
train-epoch-step: 93-297 -- Loss: 0.1679428219795227
train-epoch-step: 93-298 -- Loss: 0.2289522886276245
train-epoch-step: 93-299 -- Loss: 0.1571526676416397
train-epoch-step: 93-300 -- Loss: 0.16893890500068665
train-epoch-step: 93-301 -- Loss: 0.17201513051986694
train-epoch-step: 93-302 -- Loss: 0.22090023756027222
train-epoch-step: 93-303 -- Loss: 0.2186528742313385
train-epoch-step: 93-304 -- Loss: 0.14844095706939697
train-epoch-step: 93-305 -- Loss: 0.15123820304870605
train-epoch-step: 93-306 -- Loss: 0.22148066759109497
train-epoch-step: 93-307 -- Loss: 0.16529318690299988
train-epoch-step: 93-308 -- Loss: 0.22206059098243713
train-epoch-step: 93-309 -- Loss: 0.1544952690601349
train-epoch-step: 93-310 -- Loss: 0.16284312307834625
train-epoch-step: 93-311 -- Loss: 0.16058917343616486
train-epoch-step: 93-312 -- Loss: 0.207721546292305
train-epoch-step: 93-313 -- Loss: 0.10037589818239212
train-epoch-step: 93-314 -- Loss: 0.19137820601463318
train-epoch-step: 93-315 -- Loss: 0.16939330101013184
train-epoch-step: 93-316 -- Loss: 0.1481461077928543
train-epoch-step: 93-317 -- Loss: 0.14249522984027863
train-epoch-step: 93-318 -- Loss: 0.1641712188720703
train-epoch-step: 93-319 -- Loss: 0.18388435244560242
train-epoch-step: 93-320 -- Loss: 0.11608751118183136
train-epoch-step: 93-321 -- Loss: 0.1334688514471054
train-epoch-step: 93-322 -- Loss: 0.20694153010845184
train-epoch-step: 93-323 -- Loss: 0.16532078385353088
train-epoch-step: 93-324 -- Loss: 0.24587354063987732
train-epoch-step: 93-325 -- Loss: 0.15196184813976288
train-epoch-step: 93-326 -- Loss: 0.16904765367507935
train-epoch-step: 93-327 -- Loss: 0.19859331846237183
train-epoch-step: 93-328 -- Loss: 0.18894201517105103
train-epoch-step: 93-329 -- Loss: 0.3333597779273987
train-epoch-step: 93-330 -- Loss: 0.3540987968444824
train-epoch-step: 93-331 -- Loss: 0.2113807648420334
train-epoch-step: 93-332 -- Loss: 0.09605243057012558
train-epoch-step: 93-333 -- Loss: 0.17467352747917175
train-epoch-step: 93-334 -- Loss: 0.15170219540596008
train-epoch-step: 93-335 -- Loss: 0.17087729275226593
train-epoch-step: 93-336 -- Loss: 0.15172074735164642
train-epoch-step: 93-337 -- Loss: 0.20051264762878418
train-epoch-step: 93-338 -- Loss: 0.159479022026062
train-epoch-step: 93-339 -- Loss: 0.13838686048984528
train-epoch-step: 93-340 -- Loss: 0.21554571390151978
train-epoch-step: 93-341 -- Loss: 0.13885313272476196
train-epoch-step: 93-342 -- Loss: 0.16143332421779633
train-epoch-step: 93-343 -- Loss: 0.14790421724319458
train-epoch-step: 93-344 -- Loss: 0.16041827201843262
train-epoch-step: 93-345 -- Loss: 0.12423807382583618
train-epoch-step: 93-346 -- Loss: 0.20915496349334717
train-epoch-step: 93-347 -- Loss: 0.15167739987373352
train-epoch-step: 93-348 -- Loss: 0.2168489396572113
train-epoch-step: 93-349 -- Loss: 0.1999426782131195
train-epoch-step: 93-350 -- Loss: 0.24874776601791382
train-epoch-step: 93-351 -- Loss: 0.1897384077310562
train-epoch-step: 93-352 -- Loss: 0.12686201930046082
train-epoch-step: 93-353 -- Loss: 0.19117127358913422
train-epoch-step: 93-354 -- Loss: 0.27869388461112976
train-epoch-step: 93-355 -- Loss: 0.11736086755990982
train-epoch-step: 93-356 -- Loss: 0.11423050612211227
train-epoch-step: 93-357 -- Loss: 0.1834927648305893
train-epoch-step: 93-358 -- Loss: 0.18658266961574554
train-epoch-step: 93-359 -- Loss: 0.13881415128707886
train-epoch-step: 93-360 -- Loss: 0.12152893096208572
train-epoch-step: 93-361 -- Loss: 0.2326522320508957
train-epoch-step: 93-362 -- Loss: 0.16905638575553894
train-epoch-step: 93-363 -- Loss: 0.10748337209224701
train-epoch-step: 93-364 -- Loss: 0.18136417865753174
train-epoch-step: 93-365 -- Loss: 0.1663929522037506
train-epoch-step: 93-366 -- Loss: 0.19804604351520538
train-epoch-step: 93-367 -- Loss: 0.22532564401626587
train-epoch-step: 93-368 -- Loss: 0.199748232960701
train-epoch-step: 93-369 -- Loss: 0.2707657814025879
train-epoch-step: 93-370 -- Loss: 0.12187309563159943
train-epoch-step: 93-371 -- Loss: 0.11829153448343277
train-epoch-step: 93-372 -- Loss: 0.14185692369937897
train-epoch-step: 93-373 -- Loss: 0.18061226606369019
train-epoch-step: 93-374 -- Loss: 0.14979255199432373
train-epoch-step: 93-375 -- Loss: 0.2656327486038208
train-epoch-step: 93-376 -- Loss: 0.191657155752182
train-epoch-step: 93-377 -- Loss: 0.2170831710100174
train-epoch-step: 93-378 -- Loss: 0.19281449913978577
train-epoch-step: 93-379 -- Loss: 0.11953534185886383
train-epoch-step: 93-380 -- Loss: 0.08991528302431107
train-epoch-step: 93-381 -- Loss: 0.23252688348293304
train-epoch-step: 93-382 -- Loss: 0.23414625227451324
train-epoch-step: 93-383 -- Loss: 0.1750715970993042
train-epoch-step: 93-384 -- Loss: 0.21855954825878143
train-epoch-step: 93-385 -- Loss: 0.19152025878429413
train-epoch-step: 93-386 -- Loss: 0.18847538530826569
train-epoch-step: 93-387 -- Loss: 0.19973863661289215
train-epoch-step: 93-388 -- Loss: 0.17722736299037933
train-epoch-step: 93-389 -- Loss: 0.16711823642253876
train-epoch-step: 93-390 -- Loss: 0.14376020431518555
train-epoch-step: 93-391 -- Loss: 0.14726778864860535
train-epoch-step: 93-392 -- Loss: 0.18168586492538452
train-epoch-step: 93-393 -- Loss: 0.15173517167568207
train-epoch-step: 93-394 -- Loss: 0.18756437301635742
train-epoch-step: 93-395 -- Loss: 0.1488340049982071
train-epoch-step: 93-396 -- Loss: 0.12455727159976959
train-epoch-step: 93-397 -- Loss: 0.12411896884441376
train-epoch-step: 93-398 -- Loss: 0.20150086283683777
train-epoch-step: 93-399 -- Loss: 0.1725962609052658
train-epoch-step: 93-400 -- Loss: 0.27469998598098755
train-epoch-step: 93-401 -- Loss: 0.11989093571901321
train-epoch-step: 93-402 -- Loss: 0.24531467258930206
train-epoch-step: 93-403 -- Loss: 0.1566004902124405
train-epoch-step: 93-404 -- Loss: 0.1378709226846695
train-epoch-step: 93-405 -- Loss: 0.14072541892528534
train-epoch-step: 93-406 -- Loss: 0.16523656249046326
train-epoch-step: 93-407 -- Loss: 0.11122521758079529
train-epoch-step: 93-408 -- Loss: 0.1580885648727417
train-epoch-step: 93-409 -- Loss: 0.168538898229599
train-epoch-step: 93-410 -- Loss: 0.17474575340747833
train-epoch-step: 93-411 -- Loss: 0.18901073932647705
train-epoch-step: 93-412 -- Loss: 0.129690483212471
train-epoch-step: 93-413 -- Loss: 0.14518533647060394
train-epoch-step: 93-414 -- Loss: 0.1294410675764084
train-epoch-step: 93-415 -- Loss: 0.13146425783634186
train-epoch-step: 93-416 -- Loss: 0.259086012840271
train-epoch-step: 93-417 -- Loss: 0.18395233154296875
train-epoch-step: 93-418 -- Loss: 0.22062373161315918
train-epoch-step: 93-419 -- Loss: 0.17109310626983643
train-epoch-step: 93-420 -- Loss: 0.14700116217136383
train-epoch-step: 93-421 -- Loss: 0.18065474927425385
train-epoch-step: 93-422 -- Loss: 0.14730972051620483
train-epoch-step: 93-423 -- Loss: 0.1685245931148529
train-epoch-step: 93-424 -- Loss: 0.13224782049655914
train-epoch-step: 93-425 -- Loss: 0.17716845870018005
train-epoch-step: 93-426 -- Loss: 0.16195394098758698
train-epoch-step: 93-427 -- Loss: 0.1328614354133606
train-epoch-step: 93-428 -- Loss: 0.18252894282341003
train-epoch-step: 93-429 -- Loss: 0.17356465756893158
train-epoch-step: 93-430 -- Loss: 0.14834435284137726
train-epoch-step: 93-431 -- Loss: 0.1603192687034607
train-epoch-step: 93-432 -- Loss: 0.24044175446033478
train-epoch-step: 93-433 -- Loss: 0.14104482531547546
train-epoch-step: 93-434 -- Loss: 0.1399652659893036
train-epoch-step: 93-435 -- Loss: 0.15389403700828552
train-epoch-step: 93-436 -- Loss: 0.15606123208999634
train-epoch-step: 93-437 -- Loss: 0.14472608268260956
train-epoch-step: 93-438 -- Loss: 0.16535954177379608
train-epoch-step: 93-439 -- Loss: 0.2780373692512512
train-epoch-step: 93-440 -- Loss: 0.12666045129299164
train-epoch-step: 93-441 -- Loss: 0.20791545510292053
train-epoch-step: 93-442 -- Loss: 0.17267149686813354
train-epoch-step: 93-443 -- Loss: 0.15787751972675323
train-epoch-step: 93-444 -- Loss: 0.1771620512008667
train-epoch-step: 93-445 -- Loss: 0.1913599669933319
train-epoch-step: 93-446 -- Loss: 0.15077714622020721
train-epoch-step: 93-447 -- Loss: 0.19194373488426208
train-epoch-step: 93-448 -- Loss: 0.2274750918149948
train-epoch-step: 93-449 -- Loss: 0.19277633726596832
train-epoch-step: 93-450 -- Loss: 0.1878635734319687
train-epoch-step: 93-451 -- Loss: 0.14168725907802582
train-epoch-step: 93-452 -- Loss: 0.133305162191391
train-epoch-step: 93-453 -- Loss: 0.08844800293445587
train-epoch-step: 93-454 -- Loss: 0.2309105396270752
train-epoch-step: 93-455 -- Loss: 0.1266426146030426
train-epoch-step: 93-456 -- Loss: 0.1189756840467453
train-epoch-step: 93-457 -- Loss: 0.21484199166297913
train-epoch-step: 93-458 -- Loss: 0.15904328227043152
train-epoch-step: 93-459 -- Loss: 0.21721996366977692
train-epoch-step: 93-460 -- Loss: 0.12211356312036514
train-epoch-step: 93-461 -- Loss: 0.1357249617576599
train-epoch-step: 93-462 -- Loss: 0.15629222989082336
train-epoch-step: 93-463 -- Loss: 0.13161906599998474
train-epoch-step: 93-464 -- Loss: 0.158705934882164
train-epoch-step: 93-465 -- Loss: 0.23995622992515564
train-epoch-step: 93-466 -- Loss: 0.19886378943920135
train-epoch-step: 93-467 -- Loss: 0.11071109771728516
train-epoch-step: 93-468 -- Loss: 0.16086088120937347
train-epoch-step: 93-469 -- Loss: 0.2069740742444992
train-epoch-step: 93-470 -- Loss: 0.1708465814590454
train-epoch-step: 93-471 -- Loss: 0.1643362194299698
train-epoch-step: 93-472 -- Loss: 0.15700407326221466
train-epoch-step: 93-473 -- Loss: 0.14905887842178345
train-epoch-step: 93-474 -- Loss: 0.11753962934017181
train-epoch-step: 93-475 -- Loss: 0.1051626056432724
train-epoch-step: 93-476 -- Loss: 0.20152691006660461
train-epoch-step: 93-477 -- Loss: 0.18916305899620056
train-epoch-step: 93-478 -- Loss: 0.18888965249061584
train-epoch-step: 93-479 -- Loss: 0.13970151543617249
train-epoch-step: 93-480 -- Loss: 0.18326862156391144
train-epoch-step: 93-481 -- Loss: 0.2720317244529724
train-epoch-step: 93-482 -- Loss: 0.24988514184951782
train-epoch-step: 93-483 -- Loss: 0.18383459746837616
train-epoch-step: 93-484 -- Loss: 0.2088891714811325
train-epoch-step: 93-485 -- Loss: 0.12527291476726532
train-epoch-step: 93-486 -- Loss: 0.21696233749389648
train-epoch-step: 93-487 -- Loss: 0.22809533774852753
train-epoch-step: 93-488 -- Loss: 0.18498894572257996
train-epoch-step: 93-489 -- Loss: 0.21892276406288147
train-epoch-step: 93-490 -- Loss: 0.13452653586864471
train-epoch-step: 93-491 -- Loss: 0.13334792852401733
train-epoch-step: 93-492 -- Loss: 0.12218993902206421
train-epoch-step: 93-493 -- Loss: 0.20166802406311035
train-epoch-step: 93-494 -- Loss: 0.19859236478805542
train-epoch-step: 93-495 -- Loss: 0.19727802276611328
train-epoch-step: 93-496 -- Loss: 0.14181964099407196
train-epoch-step: 93-497 -- Loss: 0.17577853798866272
train-epoch-step: 93-498 -- Loss: 0.14369764924049377
train-epoch-step: 93-499 -- Loss: 0.16456323862075806
train-epoch-step: 93-500 -- Loss: 0.15012168884277344
train-epoch-step: 93-501 -- Loss: 0.20337136089801788
train-epoch-step: 93-502 -- Loss: 0.1560981273651123
train-epoch-step: 93-503 -- Loss: 0.21348565816879272
train-epoch-step: 93-504 -- Loss: 0.11861707270145416
train-epoch-step: 93-505 -- Loss: 0.17434188723564148
train-epoch-step: 93-506 -- Loss: 0.11606469005346298
train-epoch-step: 93-507 -- Loss: 0.17617085576057434
train-epoch-step: 93-508 -- Loss: 0.17784956097602844
train-epoch-step: 93-509 -- Loss: 0.16288092732429504
train-epoch-step: 93-510 -- Loss: 0.12568895518779755
train-epoch-step: 93-511 -- Loss: 0.2069399058818817
train-epoch-step: 93-512 -- Loss: 0.1735440045595169
train-epoch-step: 93-513 -- Loss: 0.18318066000938416
train-epoch-step: 93-514 -- Loss: 0.14572188258171082
train-epoch-step: 93-515 -- Loss: 0.14867055416107178
train-epoch-step: 93-516 -- Loss: 0.17062819004058838
train-epoch-step: 93-517 -- Loss: 0.1673370599746704
train-epoch-step: 93-518 -- Loss: 0.1362747997045517
train-epoch-step: 93-519 -- Loss: 0.13058428466320038
train-epoch-step: 93-520 -- Loss: 0.18117085099220276
train-epoch-step: 93-521 -- Loss: 0.21987441182136536
train-epoch-step: 93-522 -- Loss: 0.17576584219932556
train-epoch-step: 93-523 -- Loss: 0.15238036215305328
train-epoch-step: 93-524 -- Loss: 0.16281801462173462
train-epoch-step: 93-525 -- Loss: 0.18859153985977173
train-epoch-step: 93-526 -- Loss: 0.13714291155338287
train-epoch-step: 93-527 -- Loss: 0.1446530520915985
train-epoch-step: 93-528 -- Loss: 0.15217770636081696
train-epoch-step: 93-529 -- Loss: 0.1551327258348465
train-epoch-step: 93-530 -- Loss: 0.1643008589744568
train-epoch-step: 93-531 -- Loss: 0.1905130296945572
train-epoch-step: 93-532 -- Loss: 0.1625332236289978
train-epoch-step: 93-533 -- Loss: 0.1693732589483261
train-epoch-step: 93-534 -- Loss: 0.1241011843085289
train-epoch-step: 93-535 -- Loss: 0.23818105459213257
train-epoch-step: 93-536 -- Loss: 0.151783287525177
train-epoch-step: 93-537 -- Loss: 0.14110717177391052
train-epoch-step: 93-538 -- Loss: 0.1009068563580513
train-epoch-step: 93-539 -- Loss: 0.17686469852924347
train-epoch-step: 93-540 -- Loss: 0.132966548204422
train-epoch-step: 93-541 -- Loss: 0.20363888144493103
train-epoch-step: 93-542 -- Loss: 0.21261811256408691
train-epoch-step: 93-543 -- Loss: 0.16274359822273254
train-epoch-step: 93-544 -- Loss: 0.21908614039421082
train-epoch-step: 93-545 -- Loss: 0.18729953467845917
train-epoch-step: 93-546 -- Loss: 0.2044210433959961
train-epoch-step: 93-547 -- Loss: 0.17899830639362335
train-epoch-step: 93-548 -- Loss: 0.09142569452524185
train-epoch-step: 93-549 -- Loss: 0.14465627074241638
train-epoch-step: 93-550 -- Loss: 0.19120408594608307
train-epoch-step: 93-551 -- Loss: 0.14939819276332855
train-epoch-step: 93-552 -- Loss: 0.1201697289943695
train-epoch-step: 93-553 -- Loss: 0.1817513406276703
train-epoch-step: 93-554 -- Loss: 0.1813136637210846
train-epoch-step: 93-555 -- Loss: 0.20467162132263184
train-epoch-step: 93-556 -- Loss: 0.14359334111213684
train-epoch-step: 93-557 -- Loss: 0.23009170591831207
train-epoch-step: 93-558 -- Loss: 0.22028397023677826
train-epoch-step: 93-559 -- Loss: 0.13187751173973083
train-epoch-step: 93-560 -- Loss: 0.20014384388923645
train-epoch-step: 93-561 -- Loss: 0.1744225025177002
train-epoch-step: 93-562 -- Loss: 0.15796208381652832
train-epoch-step: 93-563 -- Loss: 0.17777979373931885
train-epoch-step: 93-564 -- Loss: 0.09665755927562714
train-epoch-step: 93-565 -- Loss: 0.1772083044052124
train-epoch-step: 93-566 -- Loss: 0.1438324898481369
train-epoch-step: 93-567 -- Loss: 0.19908592104911804
train-epoch-step: 93-568 -- Loss: 0.1522260308265686
train-epoch-step: 93-569 -- Loss: 0.23972374200820923
train-epoch-step: 93-570 -- Loss: 0.16240383684635162
train-epoch-step: 93-571 -- Loss: 0.20835711061954498
train-epoch-step: 93-572 -- Loss: 0.23892705142498016
train-epoch-step: 93-573 -- Loss: 0.19226032495498657
train-epoch-step: 93-574 -- Loss: 0.23946714401245117
train-epoch-step: 93-575 -- Loss: 0.29473796486854553
train-epoch-step: 93-576 -- Loss: 0.11470311135053635
train-epoch-step: 93-577 -- Loss: 0.1601671576499939
train-epoch-step: 93-578 -- Loss: 0.20607590675354004
train-epoch-step: 93-579 -- Loss: 0.163612499833107
train-epoch-step: 93-580 -- Loss: 0.16925504803657532
train-epoch-step: 93-581 -- Loss: 0.13798193633556366
train-epoch-step: 93-582 -- Loss: 0.20101869106292725
train-epoch-step: 93-583 -- Loss: 0.20568953454494476
train-epoch-step: 93-584 -- Loss: 0.17523711919784546
train-epoch-step: 93-585 -- Loss: 0.19066458940505981
train-epoch-step: 93-586 -- Loss: 0.24412444233894348
train-epoch-step: 93-587 -- Loss: 0.15854404866695404
train-epoch-step: 93-588 -- Loss: 0.12612032890319824
val-epoch-step: 93-589 -- Loss: 0.1978803277015686
val-epoch-step: 93-590 -- Loss: 0.15218879282474518
val-epoch-step: 93-591 -- Loss: 0.23196941614151
val-epoch-step: 93-592 -- Loss: 0.17167304456233978
val-epoch-step: 93-593 -- Loss: 0.15420468151569366
val-epoch-step: 93-594 -- Loss: 0.3420904874801636
val-epoch-step: 93-595 -- Loss: 0.17988112568855286
val-epoch-step: 93-596 -- Loss: 0.20917055010795593
val-epoch-step: 93-597 -- Loss: 0.1706385314464569
val-epoch-step: 93-598 -- Loss: 0.15159502625465393
val-epoch-step: 93-599 -- Loss: 0.178988978266716
val-epoch-step: 93-600 -- Loss: 0.16398710012435913
val-epoch-step: 93-601 -- Loss: 0.15806716680526733
val-epoch-step: 93-602 -- Loss: 0.1426571011543274
val-epoch-step: 93-603 -- Loss: 0.1918204128742218
val-epoch-step: 93-604 -- Loss: 0.14117451012134552
val-epoch-step: 93-605 -- Loss: 0.1496218740940094
val-epoch-step: 93-606 -- Loss: 0.3123653829097748
val-epoch-step: 93-607 -- Loss: 0.12673243880271912
val-epoch-step: 93-608 -- Loss: 0.24725691974163055
val-epoch-step: 93-609 -- Loss: 0.1608092188835144
val-epoch-step: 93-610 -- Loss: 0.17435222864151
val-epoch-step: 93-611 -- Loss: 0.18525433540344238
val-epoch-step: 93-612 -- Loss: 0.40088850259780884
val-epoch-step: 93-613 -- Loss: 0.16853392124176025
val-epoch-step: 93-614 -- Loss: 0.1773644983768463
val-epoch-step: 93-615 -- Loss: 0.1736513376235962
val-epoch-step: 93-616 -- Loss: 0.1407855898141861
val-epoch-step: 93-617 -- Loss: 0.1938028335571289
val-epoch-step: 93-618 -- Loss: 0.1808052957057953
val-epoch-step: 93-619 -- Loss: 0.19730646908283234
val-epoch-step: 93-620 -- Loss: 0.13186129927635193
val-epoch-step: 93-621 -- Loss: 0.12152138352394104
val-epoch-step: 93-622 -- Loss: 0.1405593752861023
val-epoch-step: 93-623 -- Loss: 0.14691907167434692
val-epoch-step: 93-624 -- Loss: 0.14183776080608368
val-epoch-step: 93-625 -- Loss: 0.15477018058300018
val-epoch-step: 93-626 -- Loss: 0.1462363600730896
val-epoch-step: 93-627 -- Loss: 0.18278220295906067
val-epoch-step: 93-628 -- Loss: 0.3691065013408661
val-epoch-step: 93-629 -- Loss: 0.22228726744651794
val-epoch-step: 93-630 -- Loss: 0.33022341132164
val-epoch-step: 93-631 -- Loss: 0.15790629386901855
val-epoch-step: 93-632 -- Loss: 0.19301095604896545
val-epoch-step: 93-633 -- Loss: 0.151153564453125
val-epoch-step: 93-634 -- Loss: 0.1582370400428772
val-epoch-step: 93-635 -- Loss: 0.10985828191041946
val-epoch-step: 93-636 -- Loss: 0.160335510969162
val-epoch-step: 93-637 -- Loss: 0.17643602192401886
val-epoch-step: 93-638 -- Loss: 0.15588532388210297
val-epoch-step: 93-639 -- Loss: 0.27902641892433167
val-epoch-step: 93-640 -- Loss: 0.24239404499530792
val-epoch-step: 93-641 -- Loss: 0.1218651533126831
val-epoch-step: 93-642 -- Loss: 0.17125670611858368
val-epoch-step: 93-643 -- Loss: 0.21225126087665558
val-epoch-step: 93-644 -- Loss: 0.16087472438812256
val-epoch-step: 93-645 -- Loss: 0.21005848050117493
val-epoch-step: 93-646 -- Loss: 0.13260690867900848
val-epoch-step: 93-647 -- Loss: 0.12279008328914642
val-epoch-step: 93-648 -- Loss: 0.14953157305717468
val-epoch-step: 93-649 -- Loss: 0.21112021803855896
val-epoch-step: 93-650 -- Loss: 0.24193833768367767
val-epoch-step: 93-651 -- Loss: 0.14247238636016846
val-epoch-step: 93-652 -- Loss: 0.14673803746700287
val-epoch-step: 93-653 -- Loss: 0.20210321247577667
val-epoch-step: 93-654 -- Loss: 0.11809863895177841
Epoch: 93 -- Train Loss: tensor(0.1401, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 94-0 -- Loss: 0.21298089623451233
train-epoch-step: 94-1 -- Loss: 0.14014941453933716
train-epoch-step: 94-2 -- Loss: 0.19788067042827606
train-epoch-step: 94-3 -- Loss: 0.14550267159938812
train-epoch-step: 94-4 -- Loss: 0.15667793154716492
train-epoch-step: 94-5 -- Loss: 0.1838390827178955
train-epoch-step: 94-6 -- Loss: 0.21201711893081665
train-epoch-step: 94-7 -- Loss: 0.16639430820941925
train-epoch-step: 94-8 -- Loss: 0.17169609665870667
train-epoch-step: 94-9 -- Loss: 0.24630653858184814
train-epoch-step: 94-10 -- Loss: 0.18987199664115906
train-epoch-step: 94-11 -- Loss: 0.17282754182815552
train-epoch-step: 94-12 -- Loss: 0.14428570866584778
train-epoch-step: 94-13 -- Loss: 0.18823933601379395
train-epoch-step: 94-14 -- Loss: 0.16284142434597015
train-epoch-step: 94-15 -- Loss: 0.17804394662380219
train-epoch-step: 94-16 -- Loss: 0.1628401130437851
train-epoch-step: 94-17 -- Loss: 0.21467676758766174
train-epoch-step: 94-18 -- Loss: 0.1848045140504837
train-epoch-step: 94-19 -- Loss: 0.12805423140525818
train-epoch-step: 94-20 -- Loss: 0.2073485106229782
train-epoch-step: 94-21 -- Loss: 0.24031049013137817
train-epoch-step: 94-22 -- Loss: 0.13542471826076508
train-epoch-step: 94-23 -- Loss: 0.13905318081378937
train-epoch-step: 94-24 -- Loss: 0.12179102003574371
train-epoch-step: 94-25 -- Loss: 0.2188558131456375
train-epoch-step: 94-26 -- Loss: 0.18402820825576782
train-epoch-step: 94-27 -- Loss: 0.2321794629096985
train-epoch-step: 94-28 -- Loss: 0.11947072297334671
train-epoch-step: 94-29 -- Loss: 0.24298334121704102
train-epoch-step: 94-30 -- Loss: 0.11016621440649033
train-epoch-step: 94-31 -- Loss: 0.13314586877822876
train-epoch-step: 94-32 -- Loss: 0.1665508896112442
train-epoch-step: 94-33 -- Loss: 0.27039361000061035
train-epoch-step: 94-34 -- Loss: 0.16838490962982178
train-epoch-step: 94-35 -- Loss: 0.23814748227596283
train-epoch-step: 94-36 -- Loss: 0.13394376635551453
train-epoch-step: 94-37 -- Loss: 0.1328495889902115
train-epoch-step: 94-38 -- Loss: 0.1768202930688858
train-epoch-step: 94-39 -- Loss: 0.20915663242340088
train-epoch-step: 94-40 -- Loss: 0.1927676796913147
train-epoch-step: 94-41 -- Loss: 0.2111162543296814
train-epoch-step: 94-42 -- Loss: 0.14210516214370728
train-epoch-step: 94-43 -- Loss: 0.2563851475715637
train-epoch-step: 94-44 -- Loss: 0.12473329901695251
train-epoch-step: 94-45 -- Loss: 0.11196976900100708
train-epoch-step: 94-46 -- Loss: 0.16678892076015472
train-epoch-step: 94-47 -- Loss: 0.19799351692199707
train-epoch-step: 94-48 -- Loss: 0.14934703707695007
train-epoch-step: 94-49 -- Loss: 0.22312290966510773
train-epoch-step: 94-50 -- Loss: 0.11315843462944031
train-epoch-step: 94-51 -- Loss: 0.17713689804077148
train-epoch-step: 94-52 -- Loss: 0.15279532968997955
train-epoch-step: 94-53 -- Loss: 0.20408260822296143
train-epoch-step: 94-54 -- Loss: 0.2799515724182129
train-epoch-step: 94-55 -- Loss: 0.16196084022521973
train-epoch-step: 94-56 -- Loss: 0.17559383809566498
train-epoch-step: 94-57 -- Loss: 0.22668202221393585
train-epoch-step: 94-58 -- Loss: 0.2761501669883728
train-epoch-step: 94-59 -- Loss: 0.23247665166854858
train-epoch-step: 94-60 -- Loss: 0.1302524358034134
train-epoch-step: 94-61 -- Loss: 0.1962544023990631
train-epoch-step: 94-62 -- Loss: 0.17499200999736786
train-epoch-step: 94-63 -- Loss: 0.12882821261882782
train-epoch-step: 94-64 -- Loss: 0.13798467814922333
train-epoch-step: 94-65 -- Loss: 0.17586998641490936
train-epoch-step: 94-66 -- Loss: 0.1054953932762146
train-epoch-step: 94-67 -- Loss: 0.11857162415981293
train-epoch-step: 94-68 -- Loss: 0.2091340869665146
train-epoch-step: 94-69 -- Loss: 0.11742912977933884
train-epoch-step: 94-70 -- Loss: 0.22029152512550354
train-epoch-step: 94-71 -- Loss: 0.258748859167099
train-epoch-step: 94-72 -- Loss: 0.1714288592338562
train-epoch-step: 94-73 -- Loss: 0.19748148322105408
train-epoch-step: 94-74 -- Loss: 0.09224581718444824
train-epoch-step: 94-75 -- Loss: 0.122992143034935
train-epoch-step: 94-76 -- Loss: 0.14330807328224182
train-epoch-step: 94-77 -- Loss: 0.22246785461902618
train-epoch-step: 94-78 -- Loss: 0.2513151466846466
train-epoch-step: 94-79 -- Loss: 0.1872442364692688
train-epoch-step: 94-80 -- Loss: 0.23866461217403412
train-epoch-step: 94-81 -- Loss: 0.12422598898410797
train-epoch-step: 94-82 -- Loss: 0.23762480914592743
train-epoch-step: 94-83 -- Loss: 0.1720162034034729
train-epoch-step: 94-84 -- Loss: 0.1821955144405365
train-epoch-step: 94-85 -- Loss: 0.16806094348430634
train-epoch-step: 94-86 -- Loss: 0.11817621439695358
train-epoch-step: 94-87 -- Loss: 0.20254161953926086
train-epoch-step: 94-88 -- Loss: 0.1356101632118225
train-epoch-step: 94-89 -- Loss: 0.18067875504493713
train-epoch-step: 94-90 -- Loss: 0.18486088514328003
train-epoch-step: 94-91 -- Loss: 0.23602432012557983
train-epoch-step: 94-92 -- Loss: 0.14831680059432983
train-epoch-step: 94-93 -- Loss: 0.16708019375801086
train-epoch-step: 94-94 -- Loss: 0.2281857132911682
train-epoch-step: 94-95 -- Loss: 0.1835983395576477
train-epoch-step: 94-96 -- Loss: 0.20890939235687256
train-epoch-step: 94-97 -- Loss: 0.16810697317123413
train-epoch-step: 94-98 -- Loss: 0.2057262361049652
train-epoch-step: 94-99 -- Loss: 0.17216645181179047
train-epoch-step: 94-100 -- Loss: 0.18296079337596893
train-epoch-step: 94-101 -- Loss: 0.2534550130367279
train-epoch-step: 94-102 -- Loss: 0.222056046128273
train-epoch-step: 94-103 -- Loss: 0.17721757292747498
train-epoch-step: 94-104 -- Loss: 0.14264878630638123
train-epoch-step: 94-105 -- Loss: 0.2663140892982483
train-epoch-step: 94-106 -- Loss: 0.17109739780426025
train-epoch-step: 94-107 -- Loss: 0.18234623968601227
train-epoch-step: 94-108 -- Loss: 0.18827304244041443
train-epoch-step: 94-109 -- Loss: 0.13771648705005646
train-epoch-step: 94-110 -- Loss: 0.1767275631427765
train-epoch-step: 94-111 -- Loss: 0.1747327595949173
train-epoch-step: 94-112 -- Loss: 0.16490790247917175
train-epoch-step: 94-113 -- Loss: 0.16795063018798828
train-epoch-step: 94-114 -- Loss: 0.18708281219005585
train-epoch-step: 94-115 -- Loss: 0.15744204819202423
train-epoch-step: 94-116 -- Loss: 0.13661740720272064
train-epoch-step: 94-117 -- Loss: 0.12205637991428375
train-epoch-step: 94-118 -- Loss: 0.18426652252674103
train-epoch-step: 94-119 -- Loss: 0.14604762196540833
train-epoch-step: 94-120 -- Loss: 0.24745143949985504
train-epoch-step: 94-121 -- Loss: 0.23163244128227234
train-epoch-step: 94-122 -- Loss: 0.20643015205860138
train-epoch-step: 94-123 -- Loss: 0.2003646343946457
train-epoch-step: 94-124 -- Loss: 0.11676473170518875
train-epoch-step: 94-125 -- Loss: 0.14825907349586487
train-epoch-step: 94-126 -- Loss: 0.2261115312576294
train-epoch-step: 94-127 -- Loss: 0.17721854150295258
train-epoch-step: 94-128 -- Loss: 0.16604796051979065
train-epoch-step: 94-129 -- Loss: 0.14103960990905762
train-epoch-step: 94-130 -- Loss: 0.1886676549911499
train-epoch-step: 94-131 -- Loss: 0.13117307424545288
train-epoch-step: 94-132 -- Loss: 0.18434418737888336
train-epoch-step: 94-133 -- Loss: 0.11491894721984863
train-epoch-step: 94-134 -- Loss: 0.21058818697929382
train-epoch-step: 94-135 -- Loss: 0.13031436502933502
train-epoch-step: 94-136 -- Loss: 0.127386674284935
train-epoch-step: 94-137 -- Loss: 0.23563231527805328
train-epoch-step: 94-138 -- Loss: 0.2509734332561493
train-epoch-step: 94-139 -- Loss: 0.12765465676784515
train-epoch-step: 94-140 -- Loss: 0.2122429758310318
train-epoch-step: 94-141 -- Loss: 0.23486292362213135
train-epoch-step: 94-142 -- Loss: 0.19416368007659912
train-epoch-step: 94-143 -- Loss: 0.17348244786262512
train-epoch-step: 94-144 -- Loss: 0.1721874475479126
train-epoch-step: 94-145 -- Loss: 0.13787072896957397
train-epoch-step: 94-146 -- Loss: 0.18150757253170013
train-epoch-step: 94-147 -- Loss: 0.1722726821899414
train-epoch-step: 94-148 -- Loss: 0.1608479917049408
train-epoch-step: 94-149 -- Loss: 0.11697281152009964
train-epoch-step: 94-150 -- Loss: 0.1803949475288391
train-epoch-step: 94-151 -- Loss: 0.19018766283988953
train-epoch-step: 94-152 -- Loss: 0.1887674778699875
train-epoch-step: 94-153 -- Loss: 0.256753146648407
train-epoch-step: 94-154 -- Loss: 0.1278400421142578
train-epoch-step: 94-155 -- Loss: 0.13156574964523315
train-epoch-step: 94-156 -- Loss: 0.11299494653940201
train-epoch-step: 94-157 -- Loss: 0.16254818439483643
train-epoch-step: 94-158 -- Loss: 0.15736736357212067
train-epoch-step: 94-159 -- Loss: 0.17476992309093475
train-epoch-step: 94-160 -- Loss: 0.21726956963539124
train-epoch-step: 94-161 -- Loss: 0.1975313276052475
train-epoch-step: 94-162 -- Loss: 0.206574946641922
train-epoch-step: 94-163 -- Loss: 0.18017521500587463
train-epoch-step: 94-164 -- Loss: 0.18995113670825958
train-epoch-step: 94-165 -- Loss: 0.15802259743213654
train-epoch-step: 94-166 -- Loss: 0.11683030426502228
train-epoch-step: 94-167 -- Loss: 0.11787664890289307
train-epoch-step: 94-168 -- Loss: 0.19987699389457703
train-epoch-step: 94-169 -- Loss: 0.1368403285741806
train-epoch-step: 94-170 -- Loss: 0.1944769322872162
train-epoch-step: 94-171 -- Loss: 0.14329278469085693
train-epoch-step: 94-172 -- Loss: 0.2552429437637329
train-epoch-step: 94-173 -- Loss: 0.12878960371017456
train-epoch-step: 94-174 -- Loss: 0.23888246715068817
train-epoch-step: 94-175 -- Loss: 0.1844501793384552
train-epoch-step: 94-176 -- Loss: 0.12850098311901093
train-epoch-step: 94-177 -- Loss: 0.17731444537639618
train-epoch-step: 94-178 -- Loss: 0.17502030730247498
train-epoch-step: 94-179 -- Loss: 0.1388854831457138
train-epoch-step: 94-180 -- Loss: 0.14917194843292236
train-epoch-step: 94-181 -- Loss: 0.16104525327682495
train-epoch-step: 94-182 -- Loss: 0.17427650094032288
train-epoch-step: 94-183 -- Loss: 0.2636392414569855
train-epoch-step: 94-184 -- Loss: 0.13403356075286865
train-epoch-step: 94-185 -- Loss: 0.13554540276527405
train-epoch-step: 94-186 -- Loss: 0.18809086084365845
train-epoch-step: 94-187 -- Loss: 0.2051454782485962
train-epoch-step: 94-188 -- Loss: 0.16282230615615845
train-epoch-step: 94-189 -- Loss: 0.10174404829740524
train-epoch-step: 94-190 -- Loss: 0.18236592411994934
train-epoch-step: 94-191 -- Loss: 0.15244607627391815
train-epoch-step: 94-192 -- Loss: 0.21790426969528198
train-epoch-step: 94-193 -- Loss: 0.20302340388298035
train-epoch-step: 94-194 -- Loss: 0.17929384112358093
train-epoch-step: 94-195 -- Loss: 0.163559690117836
train-epoch-step: 94-196 -- Loss: 0.1625739336013794
train-epoch-step: 94-197 -- Loss: 0.1213732659816742
train-epoch-step: 94-198 -- Loss: 0.1257813423871994
train-epoch-step: 94-199 -- Loss: 0.1381625533103943
train-epoch-step: 94-200 -- Loss: 0.12003809213638306
train-epoch-step: 94-201 -- Loss: 0.18184731900691986
train-epoch-step: 94-202 -- Loss: 0.1328345388174057
train-epoch-step: 94-203 -- Loss: 0.17554205656051636
train-epoch-step: 94-204 -- Loss: 0.13203811645507812
train-epoch-step: 94-205 -- Loss: 0.1787176877260208
train-epoch-step: 94-206 -- Loss: 0.1952151656150818
train-epoch-step: 94-207 -- Loss: 0.13239428400993347
train-epoch-step: 94-208 -- Loss: 0.17782673239707947
train-epoch-step: 94-209 -- Loss: 0.14020179212093353
train-epoch-step: 94-210 -- Loss: 0.13270622491836548
train-epoch-step: 94-211 -- Loss: 0.20468172430992126
train-epoch-step: 94-212 -- Loss: 0.19646668434143066
train-epoch-step: 94-213 -- Loss: 0.1260221153497696
train-epoch-step: 94-214 -- Loss: 0.14807860553264618
train-epoch-step: 94-215 -- Loss: 0.12697666883468628
train-epoch-step: 94-216 -- Loss: 0.1889413297176361
train-epoch-step: 94-217 -- Loss: 0.207088440656662
train-epoch-step: 94-218 -- Loss: 0.13906338810920715
train-epoch-step: 94-219 -- Loss: 0.16062003374099731
train-epoch-step: 94-220 -- Loss: 0.12578564882278442
train-epoch-step: 94-221 -- Loss: 0.20655477046966553
train-epoch-step: 94-222 -- Loss: 0.11366139352321625
train-epoch-step: 94-223 -- Loss: 0.16351264715194702
train-epoch-step: 94-224 -- Loss: 0.18751263618469238
train-epoch-step: 94-225 -- Loss: 0.25950926542282104
train-epoch-step: 94-226 -- Loss: 0.20450490713119507
train-epoch-step: 94-227 -- Loss: 0.21757656335830688
train-epoch-step: 94-228 -- Loss: 0.17181558907032013
train-epoch-step: 94-229 -- Loss: 0.16984544694423676
train-epoch-step: 94-230 -- Loss: 0.15643368661403656
train-epoch-step: 94-231 -- Loss: 0.15450900793075562
train-epoch-step: 94-232 -- Loss: 0.18032227456569672
train-epoch-step: 94-233 -- Loss: 0.08134160190820694
train-epoch-step: 94-234 -- Loss: 0.16701875627040863
train-epoch-step: 94-235 -- Loss: 0.14135268330574036
train-epoch-step: 94-236 -- Loss: 0.1711808443069458
train-epoch-step: 94-237 -- Loss: 0.22322812676429749
train-epoch-step: 94-238 -- Loss: 0.15020368993282318
train-epoch-step: 94-239 -- Loss: 0.12380200624465942
train-epoch-step: 94-240 -- Loss: 0.22249168157577515
train-epoch-step: 94-241 -- Loss: 0.14962975680828094
train-epoch-step: 94-242 -- Loss: 0.20962658524513245
train-epoch-step: 94-243 -- Loss: 0.2309589833021164
train-epoch-step: 94-244 -- Loss: 0.2057124376296997
train-epoch-step: 94-245 -- Loss: 0.20091600716114044
train-epoch-step: 94-246 -- Loss: 0.21555966138839722
train-epoch-step: 94-247 -- Loss: 0.20472246408462524
train-epoch-step: 94-248 -- Loss: 0.18068242073059082
train-epoch-step: 94-249 -- Loss: 0.13745808601379395
train-epoch-step: 94-250 -- Loss: 0.18954764306545258
train-epoch-step: 94-251 -- Loss: 0.10147573798894882
train-epoch-step: 94-252 -- Loss: 0.20294179022312164
train-epoch-step: 94-253 -- Loss: 0.13098673522472382
train-epoch-step: 94-254 -- Loss: 0.20825207233428955
train-epoch-step: 94-255 -- Loss: 0.1396186798810959
train-epoch-step: 94-256 -- Loss: 0.1419181376695633
train-epoch-step: 94-257 -- Loss: 0.182257741689682
train-epoch-step: 94-258 -- Loss: 0.1408529281616211
train-epoch-step: 94-259 -- Loss: 0.11028384417295456
train-epoch-step: 94-260 -- Loss: 0.19300591945648193
train-epoch-step: 94-261 -- Loss: 0.17050817608833313
train-epoch-step: 94-262 -- Loss: 0.2791878283023834
train-epoch-step: 94-263 -- Loss: 0.19863103330135345
train-epoch-step: 94-264 -- Loss: 0.16842389106750488
train-epoch-step: 94-265 -- Loss: 0.11633051931858063
train-epoch-step: 94-266 -- Loss: 0.14949922263622284
train-epoch-step: 94-267 -- Loss: 0.1244770735502243
train-epoch-step: 94-268 -- Loss: 0.11708033084869385
train-epoch-step: 94-269 -- Loss: 0.16723063588142395
train-epoch-step: 94-270 -- Loss: 0.10955442488193512
train-epoch-step: 94-271 -- Loss: 0.1456145942211151
train-epoch-step: 94-272 -- Loss: 0.1113116443157196
train-epoch-step: 94-273 -- Loss: 0.12279755622148514
train-epoch-step: 94-274 -- Loss: 0.17831724882125854
train-epoch-step: 94-275 -- Loss: 0.1877090036869049
train-epoch-step: 94-276 -- Loss: 0.14864791929721832
train-epoch-step: 94-277 -- Loss: 0.14747896790504456
train-epoch-step: 94-278 -- Loss: 0.1358111947774887
train-epoch-step: 94-279 -- Loss: 0.13709023594856262
train-epoch-step: 94-280 -- Loss: 0.20764562487602234
train-epoch-step: 94-281 -- Loss: 0.17296156287193298
train-epoch-step: 94-282 -- Loss: 0.13440625369548798
train-epoch-step: 94-283 -- Loss: 0.1120535284280777
train-epoch-step: 94-284 -- Loss: 0.1373990774154663
train-epoch-step: 94-285 -- Loss: 0.19918715953826904
train-epoch-step: 94-286 -- Loss: 0.15009325742721558
train-epoch-step: 94-287 -- Loss: 0.20061428844928741
train-epoch-step: 94-288 -- Loss: 0.09056763350963593
train-epoch-step: 94-289 -- Loss: 0.11260267347097397
train-epoch-step: 94-290 -- Loss: 0.17387302219867706
train-epoch-step: 94-291 -- Loss: 0.11558587849140167
train-epoch-step: 94-292 -- Loss: 0.15523433685302734
train-epoch-step: 94-293 -- Loss: 0.13195854425430298
train-epoch-step: 94-294 -- Loss: 0.15392149984836578
train-epoch-step: 94-295 -- Loss: 0.2545843720436096
train-epoch-step: 94-296 -- Loss: 0.1532493382692337
train-epoch-step: 94-297 -- Loss: 0.16528767347335815
train-epoch-step: 94-298 -- Loss: 0.22563666105270386
train-epoch-step: 94-299 -- Loss: 0.13839420676231384
train-epoch-step: 94-300 -- Loss: 0.15935246646404266
train-epoch-step: 94-301 -- Loss: 0.17519576847553253
train-epoch-step: 94-302 -- Loss: 0.21344953775405884
train-epoch-step: 94-303 -- Loss: 0.19958028197288513
train-epoch-step: 94-304 -- Loss: 0.12544068694114685
train-epoch-step: 94-305 -- Loss: 0.14119821786880493
train-epoch-step: 94-306 -- Loss: 0.21585234999656677
train-epoch-step: 94-307 -- Loss: 0.1604476124048233
train-epoch-step: 94-308 -- Loss: 0.21391119062900543
train-epoch-step: 94-309 -- Loss: 0.14880186319351196
train-epoch-step: 94-310 -- Loss: 0.16275052726268768
train-epoch-step: 94-311 -- Loss: 0.15502557158470154
train-epoch-step: 94-312 -- Loss: 0.19875997304916382
train-epoch-step: 94-313 -- Loss: 0.09487614035606384
train-epoch-step: 94-314 -- Loss: 0.18299728631973267
train-epoch-step: 94-315 -- Loss: 0.16488701105117798
train-epoch-step: 94-316 -- Loss: 0.1481017768383026
train-epoch-step: 94-317 -- Loss: 0.13288134336471558
train-epoch-step: 94-318 -- Loss: 0.15363557636737823
train-epoch-step: 94-319 -- Loss: 0.16272620856761932
train-epoch-step: 94-320 -- Loss: 0.11460793018341064
train-epoch-step: 94-321 -- Loss: 0.12712523341178894
train-epoch-step: 94-322 -- Loss: 0.20267686247825623
train-epoch-step: 94-323 -- Loss: 0.15810702741146088
train-epoch-step: 94-324 -- Loss: 0.24619637429714203
train-epoch-step: 94-325 -- Loss: 0.15687565505504608
train-epoch-step: 94-326 -- Loss: 0.1707352101802826
train-epoch-step: 94-327 -- Loss: 0.20829221606254578
train-epoch-step: 94-328 -- Loss: 0.18478204309940338
train-epoch-step: 94-329 -- Loss: 0.32808294892311096
train-epoch-step: 94-330 -- Loss: 0.37623095512390137
train-epoch-step: 94-331 -- Loss: 0.20063470304012299
train-epoch-step: 94-332 -- Loss: 0.10090254247188568
train-epoch-step: 94-333 -- Loss: 0.18563704192638397
train-epoch-step: 94-334 -- Loss: 0.14696231484413147
train-epoch-step: 94-335 -- Loss: 0.17670148611068726
train-epoch-step: 94-336 -- Loss: 0.14452354609966278
train-epoch-step: 94-337 -- Loss: 0.20071926712989807
train-epoch-step: 94-338 -- Loss: 0.15306079387664795
train-epoch-step: 94-339 -- Loss: 0.13678891956806183
train-epoch-step: 94-340 -- Loss: 0.18994928896427155
train-epoch-step: 94-341 -- Loss: 0.13659410178661346
train-epoch-step: 94-342 -- Loss: 0.16313251852989197
train-epoch-step: 94-343 -- Loss: 0.14645570516586304
train-epoch-step: 94-344 -- Loss: 0.1659880131483078
train-epoch-step: 94-345 -- Loss: 0.13933491706848145
train-epoch-step: 94-346 -- Loss: 0.20795363187789917
train-epoch-step: 94-347 -- Loss: 0.14859996736049652
train-epoch-step: 94-348 -- Loss: 0.19975900650024414
train-epoch-step: 94-349 -- Loss: 0.19790351390838623
train-epoch-step: 94-350 -- Loss: 0.2462019920349121
train-epoch-step: 94-351 -- Loss: 0.18722620606422424
train-epoch-step: 94-352 -- Loss: 0.12328467518091202
train-epoch-step: 94-353 -- Loss: 0.18763792514801025
train-epoch-step: 94-354 -- Loss: 0.27330708503723145
train-epoch-step: 94-355 -- Loss: 0.11921843886375427
train-epoch-step: 94-356 -- Loss: 0.12367105484008789
train-epoch-step: 94-357 -- Loss: 0.18711432814598083
train-epoch-step: 94-358 -- Loss: 0.1787519007921219
train-epoch-step: 94-359 -- Loss: 0.1367723047733307
train-epoch-step: 94-360 -- Loss: 0.11980482935905457
train-epoch-step: 94-361 -- Loss: 0.22886067628860474
train-epoch-step: 94-362 -- Loss: 0.1639760285615921
train-epoch-step: 94-363 -- Loss: 0.10743246227502823
train-epoch-step: 94-364 -- Loss: 0.17512503266334534
train-epoch-step: 94-365 -- Loss: 0.17142148315906525
train-epoch-step: 94-366 -- Loss: 0.1960967779159546
train-epoch-step: 94-367 -- Loss: 0.22555536031723022
train-epoch-step: 94-368 -- Loss: 0.21755263209342957
train-epoch-step: 94-369 -- Loss: 0.26864978671073914
train-epoch-step: 94-370 -- Loss: 0.12360140681266785
train-epoch-step: 94-371 -- Loss: 0.1185692772269249
train-epoch-step: 94-372 -- Loss: 0.14603778719902039
train-epoch-step: 94-373 -- Loss: 0.19496776163578033
train-epoch-step: 94-374 -- Loss: 0.147565096616745
train-epoch-step: 94-375 -- Loss: 0.2641640305519104
train-epoch-step: 94-376 -- Loss: 0.17733269929885864
train-epoch-step: 94-377 -- Loss: 0.2295163869857788
train-epoch-step: 94-378 -- Loss: 0.19286412000656128
train-epoch-step: 94-379 -- Loss: 0.11726407706737518
train-epoch-step: 94-380 -- Loss: 0.09539146721363068
train-epoch-step: 94-381 -- Loss: 0.24505987763404846
train-epoch-step: 94-382 -- Loss: 0.26494061946868896
train-epoch-step: 94-383 -- Loss: 0.17234647274017334
train-epoch-step: 94-384 -- Loss: 0.20499631762504578
train-epoch-step: 94-385 -- Loss: 0.1864144504070282
train-epoch-step: 94-386 -- Loss: 0.17902356386184692
train-epoch-step: 94-387 -- Loss: 0.19878825545310974
train-epoch-step: 94-388 -- Loss: 0.18121397495269775
train-epoch-step: 94-389 -- Loss: 0.16741853952407837
train-epoch-step: 94-390 -- Loss: 0.1422257423400879
train-epoch-step: 94-391 -- Loss: 0.14676649868488312
train-epoch-step: 94-392 -- Loss: 0.1842106431722641
train-epoch-step: 94-393 -- Loss: 0.15612101554870605
train-epoch-step: 94-394 -- Loss: 0.1970401108264923
train-epoch-step: 94-395 -- Loss: 0.1647484451532364
train-epoch-step: 94-396 -- Loss: 0.1256016194820404
train-epoch-step: 94-397 -- Loss: 0.1209099292755127
train-epoch-step: 94-398 -- Loss: 0.1969604194164276
train-epoch-step: 94-399 -- Loss: 0.17298099398612976
train-epoch-step: 94-400 -- Loss: 0.27280116081237793
train-epoch-step: 94-401 -- Loss: 0.11928300559520721
train-epoch-step: 94-402 -- Loss: 0.2564719617366791
train-epoch-step: 94-403 -- Loss: 0.15218326449394226
train-epoch-step: 94-404 -- Loss: 0.14448702335357666
train-epoch-step: 94-405 -- Loss: 0.14201994240283966
train-epoch-step: 94-406 -- Loss: 0.1607436239719391
train-epoch-step: 94-407 -- Loss: 0.1089579313993454
train-epoch-step: 94-408 -- Loss: 0.15788790583610535
train-epoch-step: 94-409 -- Loss: 0.1688341200351715
train-epoch-step: 94-410 -- Loss: 0.17712336778640747
train-epoch-step: 94-411 -- Loss: 0.193202406167984
train-epoch-step: 94-412 -- Loss: 0.12629421055316925
train-epoch-step: 94-413 -- Loss: 0.13938738405704498
train-epoch-step: 94-414 -- Loss: 0.13058139383792877
train-epoch-step: 94-415 -- Loss: 0.13283592462539673
train-epoch-step: 94-416 -- Loss: 0.27369794249534607
train-epoch-step: 94-417 -- Loss: 0.1900232583284378
train-epoch-step: 94-418 -- Loss: 0.21696646511554718
train-epoch-step: 94-419 -- Loss: 0.16486871242523193
train-epoch-step: 94-420 -- Loss: 0.14803114533424377
train-epoch-step: 94-421 -- Loss: 0.17258933186531067
train-epoch-step: 94-422 -- Loss: 0.14505332708358765
train-epoch-step: 94-423 -- Loss: 0.16561764478683472
train-epoch-step: 94-424 -- Loss: 0.1361912041902542
train-epoch-step: 94-425 -- Loss: 0.1815502941608429
train-epoch-step: 94-426 -- Loss: 0.15743517875671387
train-epoch-step: 94-427 -- Loss: 0.11852190643548965
train-epoch-step: 94-428 -- Loss: 0.20195239782333374
train-epoch-step: 94-429 -- Loss: 0.1722823530435562
train-epoch-step: 94-430 -- Loss: 0.13796350359916687
train-epoch-step: 94-431 -- Loss: 0.15955089032649994
train-epoch-step: 94-432 -- Loss: 0.24557924270629883
train-epoch-step: 94-433 -- Loss: 0.13263028860092163
train-epoch-step: 94-434 -- Loss: 0.12584546208381653
train-epoch-step: 94-435 -- Loss: 0.1606917530298233
train-epoch-step: 94-436 -- Loss: 0.15187950432300568
train-epoch-step: 94-437 -- Loss: 0.13196414709091187
train-epoch-step: 94-438 -- Loss: 0.1631569117307663
train-epoch-step: 94-439 -- Loss: 0.270432710647583
train-epoch-step: 94-440 -- Loss: 0.1256924718618393
train-epoch-step: 94-441 -- Loss: 0.19362995028495789
train-epoch-step: 94-442 -- Loss: 0.16981390118598938
train-epoch-step: 94-443 -- Loss: 0.16424933075904846
train-epoch-step: 94-444 -- Loss: 0.1685088574886322
train-epoch-step: 94-445 -- Loss: 0.17206928133964539
train-epoch-step: 94-446 -- Loss: 0.14712724089622498
train-epoch-step: 94-447 -- Loss: 0.18637552857398987
train-epoch-step: 94-448 -- Loss: 0.22215120494365692
train-epoch-step: 94-449 -- Loss: 0.18331661820411682
train-epoch-step: 94-450 -- Loss: 0.18145501613616943
train-epoch-step: 94-451 -- Loss: 0.13962247967720032
train-epoch-step: 94-452 -- Loss: 0.1288602352142334
train-epoch-step: 94-453 -- Loss: 0.09029887616634369
train-epoch-step: 94-454 -- Loss: 0.23175503313541412
train-epoch-step: 94-455 -- Loss: 0.12067554891109467
train-epoch-step: 94-456 -- Loss: 0.11816587299108505
train-epoch-step: 94-457 -- Loss: 0.2132353037595749
train-epoch-step: 94-458 -- Loss: 0.1447555422782898
train-epoch-step: 94-459 -- Loss: 0.20853087306022644
train-epoch-step: 94-460 -- Loss: 0.12785744667053223
train-epoch-step: 94-461 -- Loss: 0.13141638040542603
train-epoch-step: 94-462 -- Loss: 0.14986297488212585
train-epoch-step: 94-463 -- Loss: 0.13346454501152039
train-epoch-step: 94-464 -- Loss: 0.1610870659351349
train-epoch-step: 94-465 -- Loss: 0.24760806560516357
train-epoch-step: 94-466 -- Loss: 0.1981416642665863
train-epoch-step: 94-467 -- Loss: 0.1108996719121933
train-epoch-step: 94-468 -- Loss: 0.1609416902065277
train-epoch-step: 94-469 -- Loss: 0.20384737849235535
train-epoch-step: 94-470 -- Loss: 0.16671952605247498
train-epoch-step: 94-471 -- Loss: 0.15011566877365112
train-epoch-step: 94-472 -- Loss: 0.15303003787994385
train-epoch-step: 94-473 -- Loss: 0.14875410497188568
train-epoch-step: 94-474 -- Loss: 0.11650072783231735
train-epoch-step: 94-475 -- Loss: 0.11074917018413544
train-epoch-step: 94-476 -- Loss: 0.19579675793647766
train-epoch-step: 94-477 -- Loss: 0.19015930593013763
train-epoch-step: 94-478 -- Loss: 0.18274399638175964
train-epoch-step: 94-479 -- Loss: 0.13743463158607483
train-epoch-step: 94-480 -- Loss: 0.19315285980701447
train-epoch-step: 94-481 -- Loss: 0.2770213484764099
train-epoch-step: 94-482 -- Loss: 0.2632337212562561
train-epoch-step: 94-483 -- Loss: 0.18102797865867615
train-epoch-step: 94-484 -- Loss: 0.20452772080898285
train-epoch-step: 94-485 -- Loss: 0.12339276075363159
train-epoch-step: 94-486 -- Loss: 0.22416704893112183
train-epoch-step: 94-487 -- Loss: 0.22868576645851135
train-epoch-step: 94-488 -- Loss: 0.18009023368358612
train-epoch-step: 94-489 -- Loss: 0.21524585783481598
train-epoch-step: 94-490 -- Loss: 0.13591839373111725
train-epoch-step: 94-491 -- Loss: 0.1344786286354065
train-epoch-step: 94-492 -- Loss: 0.1271466314792633
train-epoch-step: 94-493 -- Loss: 0.19553327560424805
train-epoch-step: 94-494 -- Loss: 0.1929972618818283
train-epoch-step: 94-495 -- Loss: 0.19023564457893372
train-epoch-step: 94-496 -- Loss: 0.13703902065753937
train-epoch-step: 94-497 -- Loss: 0.17902769148349762
train-epoch-step: 94-498 -- Loss: 0.14209909737110138
train-epoch-step: 94-499 -- Loss: 0.16306810081005096
train-epoch-step: 94-500 -- Loss: 0.1506013721227646
train-epoch-step: 94-501 -- Loss: 0.20880255103111267
train-epoch-step: 94-502 -- Loss: 0.14974793791770935
train-epoch-step: 94-503 -- Loss: 0.21183939278125763
train-epoch-step: 94-504 -- Loss: 0.12057934701442719
train-epoch-step: 94-505 -- Loss: 0.16734085977077484
train-epoch-step: 94-506 -- Loss: 0.11323042213916779
train-epoch-step: 94-507 -- Loss: 0.18101242184638977
train-epoch-step: 94-508 -- Loss: 0.17153358459472656
train-epoch-step: 94-509 -- Loss: 0.16660478711128235
train-epoch-step: 94-510 -- Loss: 0.12523412704467773
train-epoch-step: 94-511 -- Loss: 0.21207760274410248
train-epoch-step: 94-512 -- Loss: 0.17380227148532867
train-epoch-step: 94-513 -- Loss: 0.18087610602378845
train-epoch-step: 94-514 -- Loss: 0.14013971388339996
train-epoch-step: 94-515 -- Loss: 0.1563989371061325
train-epoch-step: 94-516 -- Loss: 0.17072106897830963
train-epoch-step: 94-517 -- Loss: 0.16996920108795166
train-epoch-step: 94-518 -- Loss: 0.13847923278808594
train-epoch-step: 94-519 -- Loss: 0.13264358043670654
train-epoch-step: 94-520 -- Loss: 0.18281355500221252
train-epoch-step: 94-521 -- Loss: 0.2283756136894226
train-epoch-step: 94-522 -- Loss: 0.1787845492362976
train-epoch-step: 94-523 -- Loss: 0.15382973849773407
train-epoch-step: 94-524 -- Loss: 0.16280291974544525
train-epoch-step: 94-525 -- Loss: 0.18833406269550323
train-epoch-step: 94-526 -- Loss: 0.1363820731639862
train-epoch-step: 94-527 -- Loss: 0.14706969261169434
train-epoch-step: 94-528 -- Loss: 0.1510612964630127
train-epoch-step: 94-529 -- Loss: 0.1533682644367218
train-epoch-step: 94-530 -- Loss: 0.16312578320503235
train-epoch-step: 94-531 -- Loss: 0.19828613102436066
train-epoch-step: 94-532 -- Loss: 0.1615714728832245
train-epoch-step: 94-533 -- Loss: 0.17216476798057556
train-epoch-step: 94-534 -- Loss: 0.1260659545660019
train-epoch-step: 94-535 -- Loss: 0.2473360300064087
train-epoch-step: 94-536 -- Loss: 0.1534530371427536
train-epoch-step: 94-537 -- Loss: 0.1414298564195633
train-epoch-step: 94-538 -- Loss: 0.10751442611217499
train-epoch-step: 94-539 -- Loss: 0.17632488906383514
train-epoch-step: 94-540 -- Loss: 0.13382099568843842
train-epoch-step: 94-541 -- Loss: 0.20286548137664795
train-epoch-step: 94-542 -- Loss: 0.21664565801620483
train-epoch-step: 94-543 -- Loss: 0.16464564204216003
train-epoch-step: 94-544 -- Loss: 0.21494993567466736
train-epoch-step: 94-545 -- Loss: 0.18976473808288574
train-epoch-step: 94-546 -- Loss: 0.2014714479446411
train-epoch-step: 94-547 -- Loss: 0.17953930795192719
train-epoch-step: 94-548 -- Loss: 0.09125803411006927
train-epoch-step: 94-549 -- Loss: 0.14216077327728271
train-epoch-step: 94-550 -- Loss: 0.1948007196187973
train-epoch-step: 94-551 -- Loss: 0.1493513584136963
train-epoch-step: 94-552 -- Loss: 0.12058436870574951
train-epoch-step: 94-553 -- Loss: 0.1830810159444809
train-epoch-step: 94-554 -- Loss: 0.18664294481277466
train-epoch-step: 94-555 -- Loss: 0.206257164478302
train-epoch-step: 94-556 -- Loss: 0.14531464874744415
train-epoch-step: 94-557 -- Loss: 0.23336204886436462
train-epoch-step: 94-558 -- Loss: 0.2214936763048172
train-epoch-step: 94-559 -- Loss: 0.13039711117744446
train-epoch-step: 94-560 -- Loss: 0.1990179419517517
train-epoch-step: 94-561 -- Loss: 0.18372049927711487
train-epoch-step: 94-562 -- Loss: 0.1562303751707077
train-epoch-step: 94-563 -- Loss: 0.18477186560630798
train-epoch-step: 94-564 -- Loss: 0.09941112250089645
train-epoch-step: 94-565 -- Loss: 0.17247675359249115
train-epoch-step: 94-566 -- Loss: 0.150325745344162
train-epoch-step: 94-567 -- Loss: 0.2034243941307068
train-epoch-step: 94-568 -- Loss: 0.1625288724899292
train-epoch-step: 94-569 -- Loss: 0.2517588436603546
train-epoch-step: 94-570 -- Loss: 0.15999045968055725
train-epoch-step: 94-571 -- Loss: 0.20911166071891785
train-epoch-step: 94-572 -- Loss: 0.23186272382736206
train-epoch-step: 94-573 -- Loss: 0.19936725497245789
train-epoch-step: 94-574 -- Loss: 0.23504337668418884
train-epoch-step: 94-575 -- Loss: 0.2884817123413086
train-epoch-step: 94-576 -- Loss: 0.11298468708992004
train-epoch-step: 94-577 -- Loss: 0.1613619476556778
train-epoch-step: 94-578 -- Loss: 0.21377511322498322
train-epoch-step: 94-579 -- Loss: 0.16075143218040466
train-epoch-step: 94-580 -- Loss: 0.17039677500724792
train-epoch-step: 94-581 -- Loss: 0.13861319422721863
train-epoch-step: 94-582 -- Loss: 0.20038840174674988
train-epoch-step: 94-583 -- Loss: 0.2133936882019043
train-epoch-step: 94-584 -- Loss: 0.15096306800842285
train-epoch-step: 94-585 -- Loss: 0.191123828291893
train-epoch-step: 94-586 -- Loss: 0.24987050890922546
train-epoch-step: 94-587 -- Loss: 0.15961232781410217
train-epoch-step: 94-588 -- Loss: 0.1251656413078308
val-epoch-step: 94-589 -- Loss: 0.20334942638874054
val-epoch-step: 94-590 -- Loss: 0.15150684118270874
val-epoch-step: 94-591 -- Loss: 0.22692111134529114
val-epoch-step: 94-592 -- Loss: 0.17084749042987823
val-epoch-step: 94-593 -- Loss: 0.15840700268745422
val-epoch-step: 94-594 -- Loss: 0.38020747900009155
val-epoch-step: 94-595 -- Loss: 0.17807279527187347
val-epoch-step: 94-596 -- Loss: 0.2168111801147461
val-epoch-step: 94-597 -- Loss: 0.17381994426250458
val-epoch-step: 94-598 -- Loss: 0.1572946161031723
val-epoch-step: 94-599 -- Loss: 0.1823986917734146
val-epoch-step: 94-600 -- Loss: 0.21160364151000977
val-epoch-step: 94-601 -- Loss: 0.1545281857252121
val-epoch-step: 94-602 -- Loss: 0.13176123797893524
val-epoch-step: 94-603 -- Loss: 0.19566714763641357
val-epoch-step: 94-604 -- Loss: 0.14113754034042358
val-epoch-step: 94-605 -- Loss: 0.14763064682483673
val-epoch-step: 94-606 -- Loss: 0.2507753074169159
val-epoch-step: 94-607 -- Loss: 0.13405701518058777
val-epoch-step: 94-608 -- Loss: 0.24223342537879944
val-epoch-step: 94-609 -- Loss: 0.1651402711868286
val-epoch-step: 94-610 -- Loss: 0.17849105596542358
val-epoch-step: 94-611 -- Loss: 0.15457803010940552
val-epoch-step: 94-612 -- Loss: 0.37050485610961914
val-epoch-step: 94-613 -- Loss: 0.1662716418504715
val-epoch-step: 94-614 -- Loss: 0.16854260861873627
val-epoch-step: 94-615 -- Loss: 0.16846850514411926
val-epoch-step: 94-616 -- Loss: 0.1456976979970932
val-epoch-step: 94-617 -- Loss: 0.1983082890510559
val-epoch-step: 94-618 -- Loss: 0.17866310477256775
val-epoch-step: 94-619 -- Loss: 0.21615102887153625
val-epoch-step: 94-620 -- Loss: 0.13894949853420258
val-epoch-step: 94-621 -- Loss: 0.12356269359588623
val-epoch-step: 94-622 -- Loss: 0.14222142100334167
val-epoch-step: 94-623 -- Loss: 0.14216908812522888
val-epoch-step: 94-624 -- Loss: 0.1366267204284668
val-epoch-step: 94-625 -- Loss: 0.15656228363513947
val-epoch-step: 94-626 -- Loss: 0.14314135909080505
val-epoch-step: 94-627 -- Loss: 0.17517021298408508
val-epoch-step: 94-628 -- Loss: 0.3881905674934387
val-epoch-step: 94-629 -- Loss: 0.20572176575660706
val-epoch-step: 94-630 -- Loss: 0.34358543157577515
val-epoch-step: 94-631 -- Loss: 0.14340469241142273
val-epoch-step: 94-632 -- Loss: 0.19238175451755524
val-epoch-step: 94-633 -- Loss: 0.15112973749637604
val-epoch-step: 94-634 -- Loss: 0.13099926710128784
val-epoch-step: 94-635 -- Loss: 0.10923875868320465
val-epoch-step: 94-636 -- Loss: 0.15942957997322083
val-epoch-step: 94-637 -- Loss: 0.17760805785655975
val-epoch-step: 94-638 -- Loss: 0.151679128408432
val-epoch-step: 94-639 -- Loss: 0.2657385766506195
val-epoch-step: 94-640 -- Loss: 0.2423318326473236
val-epoch-step: 94-641 -- Loss: 0.1264408826828003
val-epoch-step: 94-642 -- Loss: 0.20108535885810852
val-epoch-step: 94-643 -- Loss: 0.21274203062057495
val-epoch-step: 94-644 -- Loss: 0.16239139437675476
val-epoch-step: 94-645 -- Loss: 0.21803079545497894
val-epoch-step: 94-646 -- Loss: 0.1279137283563614
val-epoch-step: 94-647 -- Loss: 0.12368767708539963
val-epoch-step: 94-648 -- Loss: 0.150511234998703
val-epoch-step: 94-649 -- Loss: 0.1962617039680481
val-epoch-step: 94-650 -- Loss: 0.24398641288280487
val-epoch-step: 94-651 -- Loss: 0.13886408507823944
val-epoch-step: 94-652 -- Loss: 0.15105710923671722
val-epoch-step: 94-653 -- Loss: 0.20912714302539825
val-epoch-step: 94-654 -- Loss: 0.10773724317550659
Epoch: 94 -- Train Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 95-0 -- Loss: 0.2147981971502304
train-epoch-step: 95-1 -- Loss: 0.13675229251384735
train-epoch-step: 95-2 -- Loss: 0.1930575668811798
train-epoch-step: 95-3 -- Loss: 0.13923043012619019
train-epoch-step: 95-4 -- Loss: 0.15799777209758759
train-epoch-step: 95-5 -- Loss: 0.1804073452949524
train-epoch-step: 95-6 -- Loss: 0.23380491137504578
train-epoch-step: 95-7 -- Loss: 0.1638200730085373
train-epoch-step: 95-8 -- Loss: 0.17293532192707062
train-epoch-step: 95-9 -- Loss: 0.2239265739917755
train-epoch-step: 95-10 -- Loss: 0.18337969481945038
train-epoch-step: 95-11 -- Loss: 0.17148856818675995
train-epoch-step: 95-12 -- Loss: 0.14754298329353333
train-epoch-step: 95-13 -- Loss: 0.17457576096057892
train-epoch-step: 95-14 -- Loss: 0.1586368978023529
train-epoch-step: 95-15 -- Loss: 0.1551990956068039
train-epoch-step: 95-16 -- Loss: 0.16683579981327057
train-epoch-step: 95-17 -- Loss: 0.21677035093307495
train-epoch-step: 95-18 -- Loss: 0.18608908355236053
train-epoch-step: 95-19 -- Loss: 0.12717022001743317
train-epoch-step: 95-20 -- Loss: 0.20952889323234558
train-epoch-step: 95-21 -- Loss: 0.23531559109687805
train-epoch-step: 95-22 -- Loss: 0.13837620615959167
train-epoch-step: 95-23 -- Loss: 0.1378793865442276
train-epoch-step: 95-24 -- Loss: 0.122113436460495
train-epoch-step: 95-25 -- Loss: 0.22087298333644867
train-epoch-step: 95-26 -- Loss: 0.18725740909576416
train-epoch-step: 95-27 -- Loss: 0.22016695141792297
train-epoch-step: 95-28 -- Loss: 0.11936940997838974
train-epoch-step: 95-29 -- Loss: 0.2378060668706894
train-epoch-step: 95-30 -- Loss: 0.10740809887647629
train-epoch-step: 95-31 -- Loss: 0.12850219011306763
train-epoch-step: 95-32 -- Loss: 0.16965702176094055
train-epoch-step: 95-33 -- Loss: 0.26030588150024414
train-epoch-step: 95-34 -- Loss: 0.16742348670959473
train-epoch-step: 95-35 -- Loss: 0.23610751330852509
train-epoch-step: 95-36 -- Loss: 0.13845983147621155
train-epoch-step: 95-37 -- Loss: 0.1348726451396942
train-epoch-step: 95-38 -- Loss: 0.16951054334640503
train-epoch-step: 95-39 -- Loss: 0.21369031071662903
train-epoch-step: 95-40 -- Loss: 0.1963418424129486
train-epoch-step: 95-41 -- Loss: 0.21606215834617615
train-epoch-step: 95-42 -- Loss: 0.1407904326915741
train-epoch-step: 95-43 -- Loss: 0.24725818634033203
train-epoch-step: 95-44 -- Loss: 0.12025108933448792
train-epoch-step: 95-45 -- Loss: 0.11718294024467468
train-epoch-step: 95-46 -- Loss: 0.16559365391731262
train-epoch-step: 95-47 -- Loss: 0.19010743498802185
train-epoch-step: 95-48 -- Loss: 0.14824016392230988
train-epoch-step: 95-49 -- Loss: 0.21414804458618164
train-epoch-step: 95-50 -- Loss: 0.10923627018928528
train-epoch-step: 95-51 -- Loss: 0.1707834154367447
train-epoch-step: 95-52 -- Loss: 0.1514674872159958
train-epoch-step: 95-53 -- Loss: 0.204858660697937
train-epoch-step: 95-54 -- Loss: 0.27685725688934326
train-epoch-step: 95-55 -- Loss: 0.16025301814079285
train-epoch-step: 95-56 -- Loss: 0.17183326184749603
train-epoch-step: 95-57 -- Loss: 0.2326558530330658
train-epoch-step: 95-58 -- Loss: 0.28324198722839355
train-epoch-step: 95-59 -- Loss: 0.23572559654712677
train-epoch-step: 95-60 -- Loss: 0.1302226185798645
train-epoch-step: 95-61 -- Loss: 0.19346152245998383
train-epoch-step: 95-62 -- Loss: 0.1833079755306244
train-epoch-step: 95-63 -- Loss: 0.12682083249092102
train-epoch-step: 95-64 -- Loss: 0.14505158364772797
train-epoch-step: 95-65 -- Loss: 0.17407770454883575
train-epoch-step: 95-66 -- Loss: 0.10566218197345734
train-epoch-step: 95-67 -- Loss: 0.11928467452526093
train-epoch-step: 95-68 -- Loss: 0.21277377009391785
train-epoch-step: 95-69 -- Loss: 0.12233790010213852
train-epoch-step: 95-70 -- Loss: 0.22493401169776917
train-epoch-step: 95-71 -- Loss: 0.25400787591934204
train-epoch-step: 95-72 -- Loss: 0.16556201875209808
train-epoch-step: 95-73 -- Loss: 0.20171380043029785
train-epoch-step: 95-74 -- Loss: 0.09217378497123718
train-epoch-step: 95-75 -- Loss: 0.13587604463100433
train-epoch-step: 95-76 -- Loss: 0.14015530049800873
train-epoch-step: 95-77 -- Loss: 0.22794055938720703
train-epoch-step: 95-78 -- Loss: 0.25091874599456787
train-epoch-step: 95-79 -- Loss: 0.1855291873216629
train-epoch-step: 95-80 -- Loss: 0.25080037117004395
train-epoch-step: 95-81 -- Loss: 0.12427309900522232
train-epoch-step: 95-82 -- Loss: 0.24613314867019653
train-epoch-step: 95-83 -- Loss: 0.16752305626869202
train-epoch-step: 95-84 -- Loss: 0.17886239290237427
train-epoch-step: 95-85 -- Loss: 0.16476230323314667
train-epoch-step: 95-86 -- Loss: 0.1162385568022728
train-epoch-step: 95-87 -- Loss: 0.20584307610988617
train-epoch-step: 95-88 -- Loss: 0.1389610469341278
train-epoch-step: 95-89 -- Loss: 0.18469351530075073
train-epoch-step: 95-90 -- Loss: 0.18586692214012146
train-epoch-step: 95-91 -- Loss: 0.23920346796512604
train-epoch-step: 95-92 -- Loss: 0.15125136077404022
train-epoch-step: 95-93 -- Loss: 0.1746334731578827
train-epoch-step: 95-94 -- Loss: 0.21692588925361633
train-epoch-step: 95-95 -- Loss: 0.1822032630443573
train-epoch-step: 95-96 -- Loss: 0.20668387413024902
train-epoch-step: 95-97 -- Loss: 0.17105045914649963
train-epoch-step: 95-98 -- Loss: 0.15266939997673035
train-epoch-step: 95-99 -- Loss: 0.1758251190185547
train-epoch-step: 95-100 -- Loss: 0.18389953672885895
train-epoch-step: 95-101 -- Loss: 0.25683295726776123
train-epoch-step: 95-102 -- Loss: 0.2387368381023407
train-epoch-step: 95-103 -- Loss: 0.17672404646873474
train-epoch-step: 95-104 -- Loss: 0.14236107468605042
train-epoch-step: 95-105 -- Loss: 0.25686609745025635
train-epoch-step: 95-106 -- Loss: 0.178056538105011
train-epoch-step: 95-107 -- Loss: 0.18661341071128845
train-epoch-step: 95-108 -- Loss: 0.18820466101169586
train-epoch-step: 95-109 -- Loss: 0.14222939312458038
train-epoch-step: 95-110 -- Loss: 0.17993375658988953
train-epoch-step: 95-111 -- Loss: 0.1801159679889679
train-epoch-step: 95-112 -- Loss: 0.16614031791687012
train-epoch-step: 95-113 -- Loss: 0.16654270887374878
train-epoch-step: 95-114 -- Loss: 0.18823017179965973
train-epoch-step: 95-115 -- Loss: 0.15935415029525757
train-epoch-step: 95-116 -- Loss: 0.13693855702877045
train-epoch-step: 95-117 -- Loss: 0.12472781538963318
train-epoch-step: 95-118 -- Loss: 0.18365779519081116
train-epoch-step: 95-119 -- Loss: 0.14636248350143433
train-epoch-step: 95-120 -- Loss: 0.23824834823608398
train-epoch-step: 95-121 -- Loss: 0.232434943318367
train-epoch-step: 95-122 -- Loss: 0.21692004799842834
train-epoch-step: 95-123 -- Loss: 0.2010296732187271
train-epoch-step: 95-124 -- Loss: 0.11850100010633469
train-epoch-step: 95-125 -- Loss: 0.15016770362854004
train-epoch-step: 95-126 -- Loss: 0.22309282422065735
train-epoch-step: 95-127 -- Loss: 0.18887954950332642
train-epoch-step: 95-128 -- Loss: 0.1682174950838089
train-epoch-step: 95-129 -- Loss: 0.1368555724620819
train-epoch-step: 95-130 -- Loss: 0.18311627209186554
train-epoch-step: 95-131 -- Loss: 0.13173092901706696
train-epoch-step: 95-132 -- Loss: 0.18646278977394104
train-epoch-step: 95-133 -- Loss: 0.12557601928710938
train-epoch-step: 95-134 -- Loss: 0.1840185970067978
train-epoch-step: 95-135 -- Loss: 0.12751075625419617
train-epoch-step: 95-136 -- Loss: 0.12741008400917053
train-epoch-step: 95-137 -- Loss: 0.24270111322402954
train-epoch-step: 95-138 -- Loss: 0.25729915499687195
train-epoch-step: 95-139 -- Loss: 0.12597835063934326
train-epoch-step: 95-140 -- Loss: 0.19893895089626312
train-epoch-step: 95-141 -- Loss: 0.23246422410011292
train-epoch-step: 95-142 -- Loss: 0.1978854089975357
train-epoch-step: 95-143 -- Loss: 0.17137542366981506
train-epoch-step: 95-144 -- Loss: 0.17646127939224243
train-epoch-step: 95-145 -- Loss: 0.14095599949359894
train-epoch-step: 95-146 -- Loss: 0.17405229806900024
train-epoch-step: 95-147 -- Loss: 0.1644027680158615
train-epoch-step: 95-148 -- Loss: 0.15522916615009308
train-epoch-step: 95-149 -- Loss: 0.11695133149623871
train-epoch-step: 95-150 -- Loss: 0.17679977416992188
train-epoch-step: 95-151 -- Loss: 0.21709510684013367
train-epoch-step: 95-152 -- Loss: 0.18528473377227783
train-epoch-step: 95-153 -- Loss: 0.25968194007873535
train-epoch-step: 95-154 -- Loss: 0.13345840573310852
train-epoch-step: 95-155 -- Loss: 0.13192620873451233
train-epoch-step: 95-156 -- Loss: 0.11364978551864624
train-epoch-step: 95-157 -- Loss: 0.1589645892381668
train-epoch-step: 95-158 -- Loss: 0.15879862010478973
train-epoch-step: 95-159 -- Loss: 0.17941848933696747
train-epoch-step: 95-160 -- Loss: 0.2102828323841095
train-epoch-step: 95-161 -- Loss: 0.197363942861557
train-epoch-step: 95-162 -- Loss: 0.2046159952878952
train-epoch-step: 95-163 -- Loss: 0.1974921077489853
train-epoch-step: 95-164 -- Loss: 0.18996207416057587
train-epoch-step: 95-165 -- Loss: 0.17575225234031677
train-epoch-step: 95-166 -- Loss: 0.12076431512832642
train-epoch-step: 95-167 -- Loss: 0.1273290514945984
train-epoch-step: 95-168 -- Loss: 0.19761309027671814
train-epoch-step: 95-169 -- Loss: 0.1361140012741089
train-epoch-step: 95-170 -- Loss: 0.19245359301567078
train-epoch-step: 95-171 -- Loss: 0.13748887181282043
train-epoch-step: 95-172 -- Loss: 0.26236727833747864
train-epoch-step: 95-173 -- Loss: 0.14590135216712952
train-epoch-step: 95-174 -- Loss: 0.24589034914970398
train-epoch-step: 95-175 -- Loss: 0.1849709153175354
train-epoch-step: 95-176 -- Loss: 0.13163982331752777
train-epoch-step: 95-177 -- Loss: 0.18346503376960754
train-epoch-step: 95-178 -- Loss: 0.17670264840126038
train-epoch-step: 95-179 -- Loss: 0.1471395492553711
train-epoch-step: 95-180 -- Loss: 0.1517380177974701
train-epoch-step: 95-181 -- Loss: 0.1643657088279724
train-epoch-step: 95-182 -- Loss: 0.18242968618869781
train-epoch-step: 95-183 -- Loss: 0.26460179686546326
train-epoch-step: 95-184 -- Loss: 0.13538016378879547
train-epoch-step: 95-185 -- Loss: 0.13845206797122955
train-epoch-step: 95-186 -- Loss: 0.19252300262451172
train-epoch-step: 95-187 -- Loss: 0.2029363065958023
train-epoch-step: 95-188 -- Loss: 0.17110252380371094
train-epoch-step: 95-189 -- Loss: 0.10485120862722397
train-epoch-step: 95-190 -- Loss: 0.18402141332626343
train-epoch-step: 95-191 -- Loss: 0.15577754378318787
train-epoch-step: 95-192 -- Loss: 0.22602112591266632
train-epoch-step: 95-193 -- Loss: 0.20933331549167633
train-epoch-step: 95-194 -- Loss: 0.17948581278324127
train-epoch-step: 95-195 -- Loss: 0.1600063592195511
train-epoch-step: 95-196 -- Loss: 0.17158657312393188
train-epoch-step: 95-197 -- Loss: 0.13478967547416687
train-epoch-step: 95-198 -- Loss: 0.12675994634628296
train-epoch-step: 95-199 -- Loss: 0.14405682682991028
train-epoch-step: 95-200 -- Loss: 0.12134794890880585
train-epoch-step: 95-201 -- Loss: 0.19879595935344696
train-epoch-step: 95-202 -- Loss: 0.13328486680984497
train-epoch-step: 95-203 -- Loss: 0.17645391821861267
train-epoch-step: 95-204 -- Loss: 0.13175202906131744
train-epoch-step: 95-205 -- Loss: 0.17720654606819153
train-epoch-step: 95-206 -- Loss: 0.19842393696308136
train-epoch-step: 95-207 -- Loss: 0.13378754258155823
train-epoch-step: 95-208 -- Loss: 0.17390233278274536
train-epoch-step: 95-209 -- Loss: 0.1478763222694397
train-epoch-step: 95-210 -- Loss: 0.1329532414674759
train-epoch-step: 95-211 -- Loss: 0.21126757562160492
train-epoch-step: 95-212 -- Loss: 0.19981779158115387
train-epoch-step: 95-213 -- Loss: 0.12659603357315063
train-epoch-step: 95-214 -- Loss: 0.14801721274852753
train-epoch-step: 95-215 -- Loss: 0.12837094068527222
train-epoch-step: 95-216 -- Loss: 0.19462831318378448
train-epoch-step: 95-217 -- Loss: 0.22996819019317627
train-epoch-step: 95-218 -- Loss: 0.1503714770078659
train-epoch-step: 95-219 -- Loss: 0.17280051112174988
train-epoch-step: 95-220 -- Loss: 0.1282271444797516
train-epoch-step: 95-221 -- Loss: 0.2090899497270584
train-epoch-step: 95-222 -- Loss: 0.11431287974119186
train-epoch-step: 95-223 -- Loss: 0.17448368668556213
train-epoch-step: 95-224 -- Loss: 0.19187700748443604
train-epoch-step: 95-225 -- Loss: 0.2579793632030487
train-epoch-step: 95-226 -- Loss: 0.1997814178466797
train-epoch-step: 95-227 -- Loss: 0.21432888507843018
train-epoch-step: 95-228 -- Loss: 0.17033103108406067
train-epoch-step: 95-229 -- Loss: 0.17214713990688324
train-epoch-step: 95-230 -- Loss: 0.164406880736351
train-epoch-step: 95-231 -- Loss: 0.15223237872123718
train-epoch-step: 95-232 -- Loss: 0.18167036771774292
train-epoch-step: 95-233 -- Loss: 0.08410266041755676
train-epoch-step: 95-234 -- Loss: 0.16923491656780243
train-epoch-step: 95-235 -- Loss: 0.14080286026000977
train-epoch-step: 95-236 -- Loss: 0.1758575439453125
train-epoch-step: 95-237 -- Loss: 0.23111651837825775
train-epoch-step: 95-238 -- Loss: 0.15811501443386078
train-epoch-step: 95-239 -- Loss: 0.12850742042064667
train-epoch-step: 95-240 -- Loss: 0.22621357440948486
train-epoch-step: 95-241 -- Loss: 0.14984586834907532
train-epoch-step: 95-242 -- Loss: 0.21356937289237976
train-epoch-step: 95-243 -- Loss: 0.22784988582134247
train-epoch-step: 95-244 -- Loss: 0.20233556628227234
train-epoch-step: 95-245 -- Loss: 0.20312826335430145
train-epoch-step: 95-246 -- Loss: 0.2168225795030594
train-epoch-step: 95-247 -- Loss: 0.19907087087631226
train-epoch-step: 95-248 -- Loss: 0.18105612695217133
train-epoch-step: 95-249 -- Loss: 0.13455142080783844
train-epoch-step: 95-250 -- Loss: 0.1908550262451172
train-epoch-step: 95-251 -- Loss: 0.10541553795337677
train-epoch-step: 95-252 -- Loss: 0.19091977179050446
train-epoch-step: 95-253 -- Loss: 0.13239483535289764
train-epoch-step: 95-254 -- Loss: 0.21600842475891113
train-epoch-step: 95-255 -- Loss: 0.1408945769071579
train-epoch-step: 95-256 -- Loss: 0.14124643802642822
train-epoch-step: 95-257 -- Loss: 0.1847648322582245
train-epoch-step: 95-258 -- Loss: 0.13681524991989136
train-epoch-step: 95-259 -- Loss: 0.13166113197803497
train-epoch-step: 95-260 -- Loss: 0.19429291784763336
train-epoch-step: 95-261 -- Loss: 0.1702098697423935
train-epoch-step: 95-262 -- Loss: 0.28743672370910645
train-epoch-step: 95-263 -- Loss: 0.19191201031208038
train-epoch-step: 95-264 -- Loss: 0.1699623018503189
train-epoch-step: 95-265 -- Loss: 0.11608219146728516
train-epoch-step: 95-266 -- Loss: 0.15302389860153198
train-epoch-step: 95-267 -- Loss: 0.13370947539806366
train-epoch-step: 95-268 -- Loss: 0.12285073101520538
train-epoch-step: 95-269 -- Loss: 0.1722828894853592
train-epoch-step: 95-270 -- Loss: 0.1068119928240776
train-epoch-step: 95-271 -- Loss: 0.144283264875412
train-epoch-step: 95-272 -- Loss: 0.11480610072612762
train-epoch-step: 95-273 -- Loss: 0.12360158562660217
train-epoch-step: 95-274 -- Loss: 0.1771608144044876
train-epoch-step: 95-275 -- Loss: 0.19915397465229034
train-epoch-step: 95-276 -- Loss: 0.15440331399440765
train-epoch-step: 95-277 -- Loss: 0.15215034782886505
train-epoch-step: 95-278 -- Loss: 0.14619991183280945
train-epoch-step: 95-279 -- Loss: 0.1375233381986618
train-epoch-step: 95-280 -- Loss: 0.21281704306602478
train-epoch-step: 95-281 -- Loss: 0.1736820638179779
train-epoch-step: 95-282 -- Loss: 0.13915769755840302
train-epoch-step: 95-283 -- Loss: 0.11444886028766632
train-epoch-step: 95-284 -- Loss: 0.13161702454090118
train-epoch-step: 95-285 -- Loss: 0.18972516059875488
train-epoch-step: 95-286 -- Loss: 0.1499662697315216
train-epoch-step: 95-287 -- Loss: 0.20795559883117676
train-epoch-step: 95-288 -- Loss: 0.09272333979606628
train-epoch-step: 95-289 -- Loss: 0.11610859632492065
train-epoch-step: 95-290 -- Loss: 0.17481161653995514
train-epoch-step: 95-291 -- Loss: 0.11964597553014755
train-epoch-step: 95-292 -- Loss: 0.15545576810836792
train-epoch-step: 95-293 -- Loss: 0.13804033398628235
train-epoch-step: 95-294 -- Loss: 0.15868553519248962
train-epoch-step: 95-295 -- Loss: 0.29776352643966675
train-epoch-step: 95-296 -- Loss: 0.15811386704444885
train-epoch-step: 95-297 -- Loss: 0.16817818582057953
train-epoch-step: 95-298 -- Loss: 0.223690003156662
train-epoch-step: 95-299 -- Loss: 0.1417742371559143
train-epoch-step: 95-300 -- Loss: 0.16062141954898834
train-epoch-step: 95-301 -- Loss: 0.17180204391479492
train-epoch-step: 95-302 -- Loss: 0.21298779547214508
train-epoch-step: 95-303 -- Loss: 0.19650660455226898
train-epoch-step: 95-304 -- Loss: 0.13872559368610382
train-epoch-step: 95-305 -- Loss: 0.1374586671590805
train-epoch-step: 95-306 -- Loss: 0.21358820796012878
train-epoch-step: 95-307 -- Loss: 0.16370010375976562
train-epoch-step: 95-308 -- Loss: 0.21307864785194397
train-epoch-step: 95-309 -- Loss: 0.14914089441299438
train-epoch-step: 95-310 -- Loss: 0.1625712364912033
train-epoch-step: 95-311 -- Loss: 0.15727229416370392
train-epoch-step: 95-312 -- Loss: 0.2005315124988556
train-epoch-step: 95-313 -- Loss: 0.09574097394943237
train-epoch-step: 95-314 -- Loss: 0.1908813863992691
train-epoch-step: 95-315 -- Loss: 0.16325588524341583
train-epoch-step: 95-316 -- Loss: 0.14493286609649658
train-epoch-step: 95-317 -- Loss: 0.14847266674041748
train-epoch-step: 95-318 -- Loss: 0.17093826830387115
train-epoch-step: 95-319 -- Loss: 0.16217003762722015
train-epoch-step: 95-320 -- Loss: 0.1253775656223297
train-epoch-step: 95-321 -- Loss: 0.1339351236820221
train-epoch-step: 95-322 -- Loss: 0.20829398930072784
train-epoch-step: 95-323 -- Loss: 0.15771760046482086
train-epoch-step: 95-324 -- Loss: 0.25004592537879944
train-epoch-step: 95-325 -- Loss: 0.15567751228809357
train-epoch-step: 95-326 -- Loss: 0.1712484359741211
train-epoch-step: 95-327 -- Loss: 0.20242589712142944
train-epoch-step: 95-328 -- Loss: 0.19365262985229492
train-epoch-step: 95-329 -- Loss: 0.3459431231021881
train-epoch-step: 95-330 -- Loss: 0.3554139733314514
train-epoch-step: 95-331 -- Loss: 0.20334938168525696
train-epoch-step: 95-332 -- Loss: 0.09710150212049484
train-epoch-step: 95-333 -- Loss: 0.18232950568199158
train-epoch-step: 95-334 -- Loss: 0.16146443784236908
train-epoch-step: 95-335 -- Loss: 0.16781550645828247
train-epoch-step: 95-336 -- Loss: 0.14767427742481232
train-epoch-step: 95-337 -- Loss: 0.19905218482017517
train-epoch-step: 95-338 -- Loss: 0.15853768587112427
train-epoch-step: 95-339 -- Loss: 0.14011748135089874
train-epoch-step: 95-340 -- Loss: 0.19682163000106812
train-epoch-step: 95-341 -- Loss: 0.13642431795597076
train-epoch-step: 95-342 -- Loss: 0.161347895860672
train-epoch-step: 95-343 -- Loss: 0.15254202485084534
train-epoch-step: 95-344 -- Loss: 0.1628444790840149
train-epoch-step: 95-345 -- Loss: 0.1337546408176422
train-epoch-step: 95-346 -- Loss: 0.19884923100471497
train-epoch-step: 95-347 -- Loss: 0.1495712399482727
train-epoch-step: 95-348 -- Loss: 0.19858811795711517
train-epoch-step: 95-349 -- Loss: 0.1981297731399536
train-epoch-step: 95-350 -- Loss: 0.2633502781391144
train-epoch-step: 95-351 -- Loss: 0.18737557530403137
train-epoch-step: 95-352 -- Loss: 0.12401074171066284
train-epoch-step: 95-353 -- Loss: 0.19044999778270721
train-epoch-step: 95-354 -- Loss: 0.28009575605392456
train-epoch-step: 95-355 -- Loss: 0.11675848066806793
train-epoch-step: 95-356 -- Loss: 0.11473752558231354
train-epoch-step: 95-357 -- Loss: 0.19684427976608276
train-epoch-step: 95-358 -- Loss: 0.1823377013206482
train-epoch-step: 95-359 -- Loss: 0.1366465538740158
train-epoch-step: 95-360 -- Loss: 0.12025132030248642
train-epoch-step: 95-361 -- Loss: 0.2330358624458313
train-epoch-step: 95-362 -- Loss: 0.16324572265148163
train-epoch-step: 95-363 -- Loss: 0.10970251262187958
train-epoch-step: 95-364 -- Loss: 0.17454631626605988
train-epoch-step: 95-365 -- Loss: 0.1802307814359665
train-epoch-step: 95-366 -- Loss: 0.20090988278388977
train-epoch-step: 95-367 -- Loss: 0.2262999713420868
train-epoch-step: 95-368 -- Loss: 0.19945114850997925
train-epoch-step: 95-369 -- Loss: 0.267625629901886
train-epoch-step: 95-370 -- Loss: 0.12095277011394501
train-epoch-step: 95-371 -- Loss: 0.1256626844406128
train-epoch-step: 95-372 -- Loss: 0.154667466878891
train-epoch-step: 95-373 -- Loss: 0.20444053411483765
train-epoch-step: 95-374 -- Loss: 0.1504320651292801
train-epoch-step: 95-375 -- Loss: 0.26218968629837036
train-epoch-step: 95-376 -- Loss: 0.1606186032295227
train-epoch-step: 95-377 -- Loss: 0.24432651698589325
train-epoch-step: 95-378 -- Loss: 0.19796213507652283
train-epoch-step: 95-379 -- Loss: 0.11950090527534485
train-epoch-step: 95-380 -- Loss: 0.08838488906621933
train-epoch-step: 95-381 -- Loss: 0.2346070110797882
train-epoch-step: 95-382 -- Loss: 0.24597066640853882
train-epoch-step: 95-383 -- Loss: 0.17618800699710846
train-epoch-step: 95-384 -- Loss: 0.20832112431526184
train-epoch-step: 95-385 -- Loss: 0.18190136551856995
train-epoch-step: 95-386 -- Loss: 0.17713318765163422
train-epoch-step: 95-387 -- Loss: 0.20782896876335144
train-epoch-step: 95-388 -- Loss: 0.1977795958518982
train-epoch-step: 95-389 -- Loss: 0.16068877279758453
train-epoch-step: 95-390 -- Loss: 0.13934148848056793
train-epoch-step: 95-391 -- Loss: 0.14000505208969116
train-epoch-step: 95-392 -- Loss: 0.17873919010162354
train-epoch-step: 95-393 -- Loss: 0.15628699958324432
train-epoch-step: 95-394 -- Loss: 0.19629362225532532
train-epoch-step: 95-395 -- Loss: 0.14965569972991943
train-epoch-step: 95-396 -- Loss: 0.12574845552444458
train-epoch-step: 95-397 -- Loss: 0.12131159007549286
train-epoch-step: 95-398 -- Loss: 0.19978168606758118
train-epoch-step: 95-399 -- Loss: 0.1701628416776657
train-epoch-step: 95-400 -- Loss: 0.2697402238845825
train-epoch-step: 95-401 -- Loss: 0.11795730888843536
train-epoch-step: 95-402 -- Loss: 0.2529654800891876
train-epoch-step: 95-403 -- Loss: 0.1498989462852478
train-epoch-step: 95-404 -- Loss: 0.1342950314283371
train-epoch-step: 95-405 -- Loss: 0.1425483524799347
train-epoch-step: 95-406 -- Loss: 0.1667959839105606
train-epoch-step: 95-407 -- Loss: 0.11259099841117859
train-epoch-step: 95-408 -- Loss: 0.1585848033428192
train-epoch-step: 95-409 -- Loss: 0.16964131593704224
train-epoch-step: 95-410 -- Loss: 0.1736019253730774
train-epoch-step: 95-411 -- Loss: 0.1932603120803833
train-epoch-step: 95-412 -- Loss: 0.12758740782737732
train-epoch-step: 95-413 -- Loss: 0.14271841943264008
train-epoch-step: 95-414 -- Loss: 0.12932947278022766
train-epoch-step: 95-415 -- Loss: 0.13282865285873413
train-epoch-step: 95-416 -- Loss: 0.25705239176750183
train-epoch-step: 95-417 -- Loss: 0.19196517765522003
train-epoch-step: 95-418 -- Loss: 0.22462043166160583
train-epoch-step: 95-419 -- Loss: 0.16268359124660492
train-epoch-step: 95-420 -- Loss: 0.14391623437404633
train-epoch-step: 95-421 -- Loss: 0.18110710382461548
train-epoch-step: 95-422 -- Loss: 0.14095227420330048
train-epoch-step: 95-423 -- Loss: 0.17543593049049377
train-epoch-step: 95-424 -- Loss: 0.13651815056800842
train-epoch-step: 95-425 -- Loss: 0.17943750321865082
train-epoch-step: 95-426 -- Loss: 0.15988902747631073
train-epoch-step: 95-427 -- Loss: 0.12047295272350311
train-epoch-step: 95-428 -- Loss: 0.1980472207069397
train-epoch-step: 95-429 -- Loss: 0.1715960055589676
train-epoch-step: 95-430 -- Loss: 0.13845428824424744
train-epoch-step: 95-431 -- Loss: 0.158018097281456
train-epoch-step: 95-432 -- Loss: 0.23571288585662842
train-epoch-step: 95-433 -- Loss: 0.13715860247612
train-epoch-step: 95-434 -- Loss: 0.12434432655572891
train-epoch-step: 95-435 -- Loss: 0.15591245889663696
train-epoch-step: 95-436 -- Loss: 0.15125295519828796
train-epoch-step: 95-437 -- Loss: 0.1273304522037506
train-epoch-step: 95-438 -- Loss: 0.1641935259103775
train-epoch-step: 95-439 -- Loss: 0.25672298669815063
train-epoch-step: 95-440 -- Loss: 0.129018172621727
train-epoch-step: 95-441 -- Loss: 0.19120946526527405
train-epoch-step: 95-442 -- Loss: 0.17017291486263275
train-epoch-step: 95-443 -- Loss: 0.15422549843788147
train-epoch-step: 95-444 -- Loss: 0.17043964564800262
train-epoch-step: 95-445 -- Loss: 0.1743498593568802
train-epoch-step: 95-446 -- Loss: 0.15062347054481506
train-epoch-step: 95-447 -- Loss: 0.18664999306201935
train-epoch-step: 95-448 -- Loss: 0.2267593890428543
train-epoch-step: 95-449 -- Loss: 0.18474093079566956
train-epoch-step: 95-450 -- Loss: 0.1747351884841919
train-epoch-step: 95-451 -- Loss: 0.14178600907325745
train-epoch-step: 95-452 -- Loss: 0.13078947365283966
train-epoch-step: 95-453 -- Loss: 0.09012416750192642
train-epoch-step: 95-454 -- Loss: 0.22554826736450195
train-epoch-step: 95-455 -- Loss: 0.11831674724817276
train-epoch-step: 95-456 -- Loss: 0.11724385619163513
train-epoch-step: 95-457 -- Loss: 0.21707120537757874
train-epoch-step: 95-458 -- Loss: 0.1416778266429901
train-epoch-step: 95-459 -- Loss: 0.2079794704914093
train-epoch-step: 95-460 -- Loss: 0.11837480962276459
train-epoch-step: 95-461 -- Loss: 0.1331944763660431
train-epoch-step: 95-462 -- Loss: 0.1512880027294159
train-epoch-step: 95-463 -- Loss: 0.13233400881290436
train-epoch-step: 95-464 -- Loss: 0.17329543828964233
train-epoch-step: 95-465 -- Loss: 0.2383560836315155
train-epoch-step: 95-466 -- Loss: 0.20194607973098755
train-epoch-step: 95-467 -- Loss: 0.11153717339038849
train-epoch-step: 95-468 -- Loss: 0.1580250859260559
train-epoch-step: 95-469 -- Loss: 0.19855260848999023
train-epoch-step: 95-470 -- Loss: 0.16755715012550354
train-epoch-step: 95-471 -- Loss: 0.16113056242465973
train-epoch-step: 95-472 -- Loss: 0.15516257286071777
train-epoch-step: 95-473 -- Loss: 0.15402589738368988
train-epoch-step: 95-474 -- Loss: 0.12273314595222473
train-epoch-step: 95-475 -- Loss: 0.10703635215759277
train-epoch-step: 95-476 -- Loss: 0.19688843190670013
train-epoch-step: 95-477 -- Loss: 0.19448824226856232
train-epoch-step: 95-478 -- Loss: 0.19001221656799316
train-epoch-step: 95-479 -- Loss: 0.1407654583454132
train-epoch-step: 95-480 -- Loss: 0.1890966296195984
train-epoch-step: 95-481 -- Loss: 0.274911493062973
train-epoch-step: 95-482 -- Loss: 0.25164657831192017
train-epoch-step: 95-483 -- Loss: 0.17093920707702637
train-epoch-step: 95-484 -- Loss: 0.20763041079044342
train-epoch-step: 95-485 -- Loss: 0.12052130699157715
train-epoch-step: 95-486 -- Loss: 0.2185257077217102
train-epoch-step: 95-487 -- Loss: 0.2300330400466919
train-epoch-step: 95-488 -- Loss: 0.1868739128112793
train-epoch-step: 95-489 -- Loss: 0.21065770089626312
train-epoch-step: 95-490 -- Loss: 0.14212970435619354
train-epoch-step: 95-491 -- Loss: 0.1318553239107132
train-epoch-step: 95-492 -- Loss: 0.12539182603359222
train-epoch-step: 95-493 -- Loss: 0.19333282113075256
train-epoch-step: 95-494 -- Loss: 0.1959834098815918
train-epoch-step: 95-495 -- Loss: 0.19141598045825958
train-epoch-step: 95-496 -- Loss: 0.13682511448860168
train-epoch-step: 95-497 -- Loss: 0.17828944325447083
train-epoch-step: 95-498 -- Loss: 0.14370347559452057
train-epoch-step: 95-499 -- Loss: 0.1651749461889267
train-epoch-step: 95-500 -- Loss: 0.15425941348075867
train-epoch-step: 95-501 -- Loss: 0.20955902338027954
train-epoch-step: 95-502 -- Loss: 0.15272724628448486
train-epoch-step: 95-503 -- Loss: 0.21320314705371857
train-epoch-step: 95-504 -- Loss: 0.11857539415359497
train-epoch-step: 95-505 -- Loss: 0.16926224529743195
train-epoch-step: 95-506 -- Loss: 0.1149880588054657
train-epoch-step: 95-507 -- Loss: 0.18213246762752533
train-epoch-step: 95-508 -- Loss: 0.17509450018405914
train-epoch-step: 95-509 -- Loss: 0.16594144701957703
train-epoch-step: 95-510 -- Loss: 0.1289849728345871
train-epoch-step: 95-511 -- Loss: 0.2178797870874405
train-epoch-step: 95-512 -- Loss: 0.1721230000257492
train-epoch-step: 95-513 -- Loss: 0.18200665712356567
train-epoch-step: 95-514 -- Loss: 0.1447092592716217
train-epoch-step: 95-515 -- Loss: 0.14970746636390686
train-epoch-step: 95-516 -- Loss: 0.16980090737342834
train-epoch-step: 95-517 -- Loss: 0.17532570660114288
train-epoch-step: 95-518 -- Loss: 0.1314094364643097
train-epoch-step: 95-519 -- Loss: 0.13180065155029297
train-epoch-step: 95-520 -- Loss: 0.18160851299762726
train-epoch-step: 95-521 -- Loss: 0.22793453931808472
train-epoch-step: 95-522 -- Loss: 0.17087100446224213
train-epoch-step: 95-523 -- Loss: 0.15545238554477692
train-epoch-step: 95-524 -- Loss: 0.15935258567333221
train-epoch-step: 95-525 -- Loss: 0.18816906213760376
train-epoch-step: 95-526 -- Loss: 0.1290959119796753
train-epoch-step: 95-527 -- Loss: 0.14418521523475647
train-epoch-step: 95-528 -- Loss: 0.15138009190559387
train-epoch-step: 95-529 -- Loss: 0.14988911151885986
train-epoch-step: 95-530 -- Loss: 0.16240988671779633
train-epoch-step: 95-531 -- Loss: 0.1900835484266281
train-epoch-step: 95-532 -- Loss: 0.16379843652248383
train-epoch-step: 95-533 -- Loss: 0.16941601037979126
train-epoch-step: 95-534 -- Loss: 0.12489917874336243
train-epoch-step: 95-535 -- Loss: 0.24743466079235077
train-epoch-step: 95-536 -- Loss: 0.15123769640922546
train-epoch-step: 95-537 -- Loss: 0.14239169657230377
train-epoch-step: 95-538 -- Loss: 0.10050969570875168
train-epoch-step: 95-539 -- Loss: 0.17426231503486633
train-epoch-step: 95-540 -- Loss: 0.13188405334949493
train-epoch-step: 95-541 -- Loss: 0.20549282431602478
train-epoch-step: 95-542 -- Loss: 0.2145725041627884
train-epoch-step: 95-543 -- Loss: 0.16322626173496246
train-epoch-step: 95-544 -- Loss: 0.21797122061252594
train-epoch-step: 95-545 -- Loss: 0.18763114511966705
train-epoch-step: 95-546 -- Loss: 0.20737871527671814
train-epoch-step: 95-547 -- Loss: 0.17624816298484802
train-epoch-step: 95-548 -- Loss: 0.09003230184316635
train-epoch-step: 95-549 -- Loss: 0.14014406502246857
train-epoch-step: 95-550 -- Loss: 0.19240784645080566
train-epoch-step: 95-551 -- Loss: 0.1512705683708191
train-epoch-step: 95-552 -- Loss: 0.12117087841033936
train-epoch-step: 95-553 -- Loss: 0.18255853652954102
train-epoch-step: 95-554 -- Loss: 0.17879903316497803
train-epoch-step: 95-555 -- Loss: 0.19696471095085144
train-epoch-step: 95-556 -- Loss: 0.15148043632507324
train-epoch-step: 95-557 -- Loss: 0.2229960560798645
train-epoch-step: 95-558 -- Loss: 0.22009742259979248
train-epoch-step: 95-559 -- Loss: 0.1365204155445099
train-epoch-step: 95-560 -- Loss: 0.19876880943775177
train-epoch-step: 95-561 -- Loss: 0.17527930438518524
train-epoch-step: 95-562 -- Loss: 0.16056735813617706
train-epoch-step: 95-563 -- Loss: 0.18234747648239136
train-epoch-step: 95-564 -- Loss: 0.09837977588176727
train-epoch-step: 95-565 -- Loss: 0.17654751241207123
train-epoch-step: 95-566 -- Loss: 0.14661096036434174
train-epoch-step: 95-567 -- Loss: 0.20354968309402466
train-epoch-step: 95-568 -- Loss: 0.15237291157245636
train-epoch-step: 95-569 -- Loss: 0.24050070345401764
train-epoch-step: 95-570 -- Loss: 0.1638118475675583
train-epoch-step: 95-571 -- Loss: 0.199162095785141
train-epoch-step: 95-572 -- Loss: 0.23443648219108582
train-epoch-step: 95-573 -- Loss: 0.19215093553066254
train-epoch-step: 95-574 -- Loss: 0.23620793223381042
train-epoch-step: 95-575 -- Loss: 0.2819105386734009
train-epoch-step: 95-576 -- Loss: 0.11283235996961594
train-epoch-step: 95-577 -- Loss: 0.16245748102664948
train-epoch-step: 95-578 -- Loss: 0.21243302524089813
train-epoch-step: 95-579 -- Loss: 0.16137221455574036
train-epoch-step: 95-580 -- Loss: 0.16686800122261047
train-epoch-step: 95-581 -- Loss: 0.14367227256298065
train-epoch-step: 95-582 -- Loss: 0.19773772358894348
train-epoch-step: 95-583 -- Loss: 0.21248918771743774
train-epoch-step: 95-584 -- Loss: 0.15556015074253082
train-epoch-step: 95-585 -- Loss: 0.18835845589637756
train-epoch-step: 95-586 -- Loss: 0.24190160632133484
train-epoch-step: 95-587 -- Loss: 0.15231652557849884
train-epoch-step: 95-588 -- Loss: 0.1257726103067398
val-epoch-step: 95-589 -- Loss: 0.20841874182224274
val-epoch-step: 95-590 -- Loss: 0.15223029255867004
val-epoch-step: 95-591 -- Loss: 0.2425035685300827
val-epoch-step: 95-592 -- Loss: 0.17051002383232117
val-epoch-step: 95-593 -- Loss: 0.17140275239944458
val-epoch-step: 95-594 -- Loss: 0.32602590322494507
val-epoch-step: 95-595 -- Loss: 0.17812740802764893
val-epoch-step: 95-596 -- Loss: 0.18870997428894043
val-epoch-step: 95-597 -- Loss: 0.16572493314743042
val-epoch-step: 95-598 -- Loss: 0.14478492736816406
val-epoch-step: 95-599 -- Loss: 0.17729762196540833
val-epoch-step: 95-600 -- Loss: 0.1802993267774582
val-epoch-step: 95-601 -- Loss: 0.15242093801498413
val-epoch-step: 95-602 -- Loss: 0.1371135711669922
val-epoch-step: 95-603 -- Loss: 0.19540536403656006
val-epoch-step: 95-604 -- Loss: 0.15077880024909973
val-epoch-step: 95-605 -- Loss: 0.14372803270816803
val-epoch-step: 95-606 -- Loss: 0.27552351355552673
val-epoch-step: 95-607 -- Loss: 0.12136424332857132
val-epoch-step: 95-608 -- Loss: 0.24651038646697998
val-epoch-step: 95-609 -- Loss: 0.18553119897842407
val-epoch-step: 95-610 -- Loss: 0.17515629529953003
val-epoch-step: 95-611 -- Loss: 0.15529285371303558
val-epoch-step: 95-612 -- Loss: 0.343292772769928
val-epoch-step: 95-613 -- Loss: 0.16987961530685425
val-epoch-step: 95-614 -- Loss: 0.16301661729812622
val-epoch-step: 95-615 -- Loss: 0.16837909817695618
val-epoch-step: 95-616 -- Loss: 0.14376500248908997
val-epoch-step: 95-617 -- Loss: 0.1946675181388855
val-epoch-step: 95-618 -- Loss: 0.16863369941711426
val-epoch-step: 95-619 -- Loss: 0.19646306335926056
val-epoch-step: 95-620 -- Loss: 0.13333624601364136
val-epoch-step: 95-621 -- Loss: 0.12130869925022125
val-epoch-step: 95-622 -- Loss: 0.14283296465873718
val-epoch-step: 95-623 -- Loss: 0.14760887622833252
val-epoch-step: 95-624 -- Loss: 0.13771271705627441
val-epoch-step: 95-625 -- Loss: 0.15304240584373474
val-epoch-step: 95-626 -- Loss: 0.14268313348293304
val-epoch-step: 95-627 -- Loss: 0.17709793150424957
val-epoch-step: 95-628 -- Loss: 0.40635818243026733
val-epoch-step: 95-629 -- Loss: 0.18228518962860107
val-epoch-step: 95-630 -- Loss: 0.3446149528026581
val-epoch-step: 95-631 -- Loss: 0.1367785930633545
val-epoch-step: 95-632 -- Loss: 0.19626958668231964
val-epoch-step: 95-633 -- Loss: 0.14615964889526367
val-epoch-step: 95-634 -- Loss: 0.13728228211402893
val-epoch-step: 95-635 -- Loss: 0.10952073335647583
val-epoch-step: 95-636 -- Loss: 0.15872572362422943
val-epoch-step: 95-637 -- Loss: 0.186711385846138
val-epoch-step: 95-638 -- Loss: 0.14542870223522186
val-epoch-step: 95-639 -- Loss: 0.2529424726963043
val-epoch-step: 95-640 -- Loss: 0.2510417103767395
val-epoch-step: 95-641 -- Loss: 0.1307651251554489
val-epoch-step: 95-642 -- Loss: 0.1748637557029724
val-epoch-step: 95-643 -- Loss: 0.20468521118164062
val-epoch-step: 95-644 -- Loss: 0.16155095398426056
val-epoch-step: 95-645 -- Loss: 0.210826575756073
val-epoch-step: 95-646 -- Loss: 0.12583479285240173
val-epoch-step: 95-647 -- Loss: 0.12478241324424744
val-epoch-step: 95-648 -- Loss: 0.14914816617965698
val-epoch-step: 95-649 -- Loss: 0.20429742336273193
val-epoch-step: 95-650 -- Loss: 0.2460150569677353
val-epoch-step: 95-651 -- Loss: 0.16752201318740845
val-epoch-step: 95-652 -- Loss: 0.15491074323654175
val-epoch-step: 95-653 -- Loss: 0.25186583399772644
val-epoch-step: 95-654 -- Loss: 0.10907097905874252
Epoch: 95 -- Train Loss: tensor(0.1392, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1410, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 96-0 -- Loss: 0.21931526064872742
train-epoch-step: 96-1 -- Loss: 0.13910791277885437
train-epoch-step: 96-2 -- Loss: 0.18925799429416656
train-epoch-step: 96-3 -- Loss: 0.1429569572210312
train-epoch-step: 96-4 -- Loss: 0.15357324481010437
train-epoch-step: 96-5 -- Loss: 0.17603135108947754
train-epoch-step: 96-6 -- Loss: 0.22539152204990387
train-epoch-step: 96-7 -- Loss: 0.1576930582523346
train-epoch-step: 96-8 -- Loss: 0.17777512967586517
train-epoch-step: 96-9 -- Loss: 0.21268919110298157
train-epoch-step: 96-10 -- Loss: 0.18608003854751587
train-epoch-step: 96-11 -- Loss: 0.1776399165391922
train-epoch-step: 96-12 -- Loss: 0.14330251514911652
train-epoch-step: 96-13 -- Loss: 0.1762063205242157
train-epoch-step: 96-14 -- Loss: 0.15944600105285645
train-epoch-step: 96-15 -- Loss: 0.15173472464084625
train-epoch-step: 96-16 -- Loss: 0.1600704938173294
train-epoch-step: 96-17 -- Loss: 0.21827542781829834
train-epoch-step: 96-18 -- Loss: 0.18273137509822845
train-epoch-step: 96-19 -- Loss: 0.12398014217615128
train-epoch-step: 96-20 -- Loss: 0.21041668951511383
train-epoch-step: 96-21 -- Loss: 0.23977605998516083
train-epoch-step: 96-22 -- Loss: 0.13654226064682007
train-epoch-step: 96-23 -- Loss: 0.13505171239376068
train-epoch-step: 96-24 -- Loss: 0.11899730563163757
train-epoch-step: 96-25 -- Loss: 0.22105862200260162
train-epoch-step: 96-26 -- Loss: 0.18439629673957825
train-epoch-step: 96-27 -- Loss: 0.21777920424938202
train-epoch-step: 96-28 -- Loss: 0.12175333499908447
train-epoch-step: 96-29 -- Loss: 0.23497362434864044
train-epoch-step: 96-30 -- Loss: 0.10577181726694107
train-epoch-step: 96-31 -- Loss: 0.13052010536193848
train-epoch-step: 96-32 -- Loss: 0.16875433921813965
train-epoch-step: 96-33 -- Loss: 0.2611430287361145
train-epoch-step: 96-34 -- Loss: 0.1682872176170349
train-epoch-step: 96-35 -- Loss: 0.24141347408294678
train-epoch-step: 96-36 -- Loss: 0.13413991034030914
train-epoch-step: 96-37 -- Loss: 0.1311299055814743
train-epoch-step: 96-38 -- Loss: 0.16877509653568268
train-epoch-step: 96-39 -- Loss: 0.2066037952899933
train-epoch-step: 96-40 -- Loss: 0.18966864049434662
train-epoch-step: 96-41 -- Loss: 0.2079131007194519
train-epoch-step: 96-42 -- Loss: 0.1414097249507904
train-epoch-step: 96-43 -- Loss: 0.2525021731853485
train-epoch-step: 96-44 -- Loss: 0.11879365146160126
train-epoch-step: 96-45 -- Loss: 0.11266015470027924
train-epoch-step: 96-46 -- Loss: 0.17051316797733307
train-epoch-step: 96-47 -- Loss: 0.182710200548172
train-epoch-step: 96-48 -- Loss: 0.15068329870700836
train-epoch-step: 96-49 -- Loss: 0.21746167540550232
train-epoch-step: 96-50 -- Loss: 0.11004208773374557
train-epoch-step: 96-51 -- Loss: 0.17077672481536865
train-epoch-step: 96-52 -- Loss: 0.15138095617294312
train-epoch-step: 96-53 -- Loss: 0.203622505068779
train-epoch-step: 96-54 -- Loss: 0.2811867296695709
train-epoch-step: 96-55 -- Loss: 0.16309663653373718
train-epoch-step: 96-56 -- Loss: 0.17042383551597595
train-epoch-step: 96-57 -- Loss: 0.23760759830474854
train-epoch-step: 96-58 -- Loss: 0.2724686563014984
train-epoch-step: 96-59 -- Loss: 0.22614051401615143
train-epoch-step: 96-60 -- Loss: 0.12763294577598572
train-epoch-step: 96-61 -- Loss: 0.1970146894454956
train-epoch-step: 96-62 -- Loss: 0.17727334797382355
train-epoch-step: 96-63 -- Loss: 0.1306263953447342
train-epoch-step: 96-64 -- Loss: 0.142124742269516
train-epoch-step: 96-65 -- Loss: 0.18040330708026886
train-epoch-step: 96-66 -- Loss: 0.10858787596225739
train-epoch-step: 96-67 -- Loss: 0.125688835978508
train-epoch-step: 96-68 -- Loss: 0.20188239216804504
train-epoch-step: 96-69 -- Loss: 0.1188153326511383
train-epoch-step: 96-70 -- Loss: 0.22255036234855652
train-epoch-step: 96-71 -- Loss: 0.2516155540943146
train-epoch-step: 96-72 -- Loss: 0.16677334904670715
train-epoch-step: 96-73 -- Loss: 0.19824624061584473
train-epoch-step: 96-74 -- Loss: 0.09352361410856247
train-epoch-step: 96-75 -- Loss: 0.12671726942062378
train-epoch-step: 96-76 -- Loss: 0.14640524983406067
train-epoch-step: 96-77 -- Loss: 0.2236863225698471
train-epoch-step: 96-78 -- Loss: 0.24541306495666504
train-epoch-step: 96-79 -- Loss: 0.18275490403175354
train-epoch-step: 96-80 -- Loss: 0.23792624473571777
train-epoch-step: 96-81 -- Loss: 0.11816728860139847
train-epoch-step: 96-82 -- Loss: 0.24149787425994873
train-epoch-step: 96-83 -- Loss: 0.17425835132598877
train-epoch-step: 96-84 -- Loss: 0.18056844174861908
train-epoch-step: 96-85 -- Loss: 0.16691772639751434
train-epoch-step: 96-86 -- Loss: 0.11568273603916168
train-epoch-step: 96-87 -- Loss: 0.20529313385486603
train-epoch-step: 96-88 -- Loss: 0.13493257761001587
train-epoch-step: 96-89 -- Loss: 0.18024621903896332
train-epoch-step: 96-90 -- Loss: 0.18510828912258148
train-epoch-step: 96-91 -- Loss: 0.25035834312438965
train-epoch-step: 96-92 -- Loss: 0.15289780497550964
train-epoch-step: 96-93 -- Loss: 0.17675837874412537
train-epoch-step: 96-94 -- Loss: 0.21517185866832733
train-epoch-step: 96-95 -- Loss: 0.18172089755535126
train-epoch-step: 96-96 -- Loss: 0.20713204145431519
train-epoch-step: 96-97 -- Loss: 0.16862651705741882
train-epoch-step: 96-98 -- Loss: 0.16695818305015564
train-epoch-step: 96-99 -- Loss: 0.1792815625667572
train-epoch-step: 96-100 -- Loss: 0.17951469123363495
train-epoch-step: 96-101 -- Loss: 0.26836276054382324
train-epoch-step: 96-102 -- Loss: 0.22552630305290222
train-epoch-step: 96-103 -- Loss: 0.18937979638576508
train-epoch-step: 96-104 -- Loss: 0.14436239004135132
train-epoch-step: 96-105 -- Loss: 0.26784297823905945
train-epoch-step: 96-106 -- Loss: 0.17397449910640717
train-epoch-step: 96-107 -- Loss: 0.18619020283222198
train-epoch-step: 96-108 -- Loss: 0.22120824456214905
train-epoch-step: 96-109 -- Loss: 0.14874489605426788
train-epoch-step: 96-110 -- Loss: 0.179751917719841
train-epoch-step: 96-111 -- Loss: 0.17691287398338318
train-epoch-step: 96-112 -- Loss: 0.16783960163593292
train-epoch-step: 96-113 -- Loss: 0.16392900049686432
train-epoch-step: 96-114 -- Loss: 0.19450286030769348
train-epoch-step: 96-115 -- Loss: 0.1604813188314438
train-epoch-step: 96-116 -- Loss: 0.13425573706626892
train-epoch-step: 96-117 -- Loss: 0.12693534791469574
train-epoch-step: 96-118 -- Loss: 0.19788934290409088
train-epoch-step: 96-119 -- Loss: 0.15054187178611755
train-epoch-step: 96-120 -- Loss: 0.27072757482528687
train-epoch-step: 96-121 -- Loss: 0.23909088969230652
train-epoch-step: 96-122 -- Loss: 0.20698949694633484
train-epoch-step: 96-123 -- Loss: 0.19570094347000122
train-epoch-step: 96-124 -- Loss: 0.12678255140781403
train-epoch-step: 96-125 -- Loss: 0.15232110023498535
train-epoch-step: 96-126 -- Loss: 0.22775202989578247
train-epoch-step: 96-127 -- Loss: 0.1671370267868042
train-epoch-step: 96-128 -- Loss: 0.16960464417934418
train-epoch-step: 96-129 -- Loss: 0.14880633354187012
train-epoch-step: 96-130 -- Loss: 0.19314688444137573
train-epoch-step: 96-131 -- Loss: 0.13677608966827393
train-epoch-step: 96-132 -- Loss: 0.18293344974517822
train-epoch-step: 96-133 -- Loss: 0.12116594612598419
train-epoch-step: 96-134 -- Loss: 0.19104887545108795
train-epoch-step: 96-135 -- Loss: 0.13318078219890594
train-epoch-step: 96-136 -- Loss: 0.1328057199716568
train-epoch-step: 96-137 -- Loss: 0.24086594581604004
train-epoch-step: 96-138 -- Loss: 0.25257980823516846
train-epoch-step: 96-139 -- Loss: 0.1279001533985138
train-epoch-step: 96-140 -- Loss: 0.20332106947898865
train-epoch-step: 96-141 -- Loss: 0.22970956563949585
train-epoch-step: 96-142 -- Loss: 0.19810932874679565
train-epoch-step: 96-143 -- Loss: 0.17038768529891968
train-epoch-step: 96-144 -- Loss: 0.17937467992305756
train-epoch-step: 96-145 -- Loss: 0.13804426789283752
train-epoch-step: 96-146 -- Loss: 0.1712627410888672
train-epoch-step: 96-147 -- Loss: 0.16337862610816956
train-epoch-step: 96-148 -- Loss: 0.1606237292289734
train-epoch-step: 96-149 -- Loss: 0.11906358599662781
train-epoch-step: 96-150 -- Loss: 0.18170037865638733
train-epoch-step: 96-151 -- Loss: 0.18272508680820465
train-epoch-step: 96-152 -- Loss: 0.19208607077598572
train-epoch-step: 96-153 -- Loss: 0.2611057162284851
train-epoch-step: 96-154 -- Loss: 0.1270131766796112
train-epoch-step: 96-155 -- Loss: 0.13344183564186096
train-epoch-step: 96-156 -- Loss: 0.1206861138343811
train-epoch-step: 96-157 -- Loss: 0.1592160314321518
train-epoch-step: 96-158 -- Loss: 0.16280235350131989
train-epoch-step: 96-159 -- Loss: 0.17568248510360718
train-epoch-step: 96-160 -- Loss: 0.20647449791431427
train-epoch-step: 96-161 -- Loss: 0.19652172923088074
train-epoch-step: 96-162 -- Loss: 0.2052399218082428
train-epoch-step: 96-163 -- Loss: 0.1788696050643921
train-epoch-step: 96-164 -- Loss: 0.1916491538286209
train-epoch-step: 96-165 -- Loss: 0.15763138234615326
train-epoch-step: 96-166 -- Loss: 0.11656124889850616
train-epoch-step: 96-167 -- Loss: 0.11925873905420303
train-epoch-step: 96-168 -- Loss: 0.19820019602775574
train-epoch-step: 96-169 -- Loss: 0.13551080226898193
train-epoch-step: 96-170 -- Loss: 0.1958688497543335
train-epoch-step: 96-171 -- Loss: 0.14005756378173828
train-epoch-step: 96-172 -- Loss: 0.26042449474334717
train-epoch-step: 96-173 -- Loss: 0.13203522562980652
train-epoch-step: 96-174 -- Loss: 0.24565963447093964
train-epoch-step: 96-175 -- Loss: 0.18946579098701477
train-epoch-step: 96-176 -- Loss: 0.13028760254383087
train-epoch-step: 96-177 -- Loss: 0.17511574923992157
train-epoch-step: 96-178 -- Loss: 0.17447444796562195
train-epoch-step: 96-179 -- Loss: 0.14046597480773926
train-epoch-step: 96-180 -- Loss: 0.14907525479793549
train-epoch-step: 96-181 -- Loss: 0.16648328304290771
train-epoch-step: 96-182 -- Loss: 0.18305113911628723
train-epoch-step: 96-183 -- Loss: 0.26782575249671936
train-epoch-step: 96-184 -- Loss: 0.13400644063949585
train-epoch-step: 96-185 -- Loss: 0.14527122676372528
train-epoch-step: 96-186 -- Loss: 0.17858445644378662
train-epoch-step: 96-187 -- Loss: 0.2033127248287201
train-epoch-step: 96-188 -- Loss: 0.1679162234067917
train-epoch-step: 96-189 -- Loss: 0.10478202998638153
train-epoch-step: 96-190 -- Loss: 0.19077596068382263
train-epoch-step: 96-191 -- Loss: 0.15107539296150208
train-epoch-step: 96-192 -- Loss: 0.22068530321121216
train-epoch-step: 96-193 -- Loss: 0.20401707291603088
train-epoch-step: 96-194 -- Loss: 0.17560860514640808
train-epoch-step: 96-195 -- Loss: 0.1617841124534607
train-epoch-step: 96-196 -- Loss: 0.1659517139196396
train-epoch-step: 96-197 -- Loss: 0.1290249228477478
train-epoch-step: 96-198 -- Loss: 0.12421444058418274
train-epoch-step: 96-199 -- Loss: 0.14269673824310303
train-epoch-step: 96-200 -- Loss: 0.12168077379465103
train-epoch-step: 96-201 -- Loss: 0.18605585396289825
train-epoch-step: 96-202 -- Loss: 0.13257844746112823
train-epoch-step: 96-203 -- Loss: 0.17451898753643036
train-epoch-step: 96-204 -- Loss: 0.13125289976596832
train-epoch-step: 96-205 -- Loss: 0.1798277497291565
train-epoch-step: 96-206 -- Loss: 0.19139304757118225
train-epoch-step: 96-207 -- Loss: 0.13704423606395721
train-epoch-step: 96-208 -- Loss: 0.17382250726222992
train-epoch-step: 96-209 -- Loss: 0.13927610218524933
train-epoch-step: 96-210 -- Loss: 0.12634198367595673
train-epoch-step: 96-211 -- Loss: 0.1996886134147644
train-epoch-step: 96-212 -- Loss: 0.1935388296842575
train-epoch-step: 96-213 -- Loss: 0.12686997652053833
train-epoch-step: 96-214 -- Loss: 0.14367210865020752
train-epoch-step: 96-215 -- Loss: 0.12102659791707993
train-epoch-step: 96-216 -- Loss: 0.1964748054742813
train-epoch-step: 96-217 -- Loss: 0.20072898268699646
train-epoch-step: 96-218 -- Loss: 0.14432024955749512
train-epoch-step: 96-219 -- Loss: 0.16845008730888367
train-epoch-step: 96-220 -- Loss: 0.12992101907730103
train-epoch-step: 96-221 -- Loss: 0.19560185074806213
train-epoch-step: 96-222 -- Loss: 0.11558817327022552
train-epoch-step: 96-223 -- Loss: 0.16498461365699768
train-epoch-step: 96-224 -- Loss: 0.1825033724308014
train-epoch-step: 96-225 -- Loss: 0.26198551058769226
train-epoch-step: 96-226 -- Loss: 0.20235946774482727
train-epoch-step: 96-227 -- Loss: 0.21567615866661072
train-epoch-step: 96-228 -- Loss: 0.17075394093990326
train-epoch-step: 96-229 -- Loss: 0.17110532522201538
train-epoch-step: 96-230 -- Loss: 0.1597217172384262
train-epoch-step: 96-231 -- Loss: 0.14802931249141693
train-epoch-step: 96-232 -- Loss: 0.1822982281446457
train-epoch-step: 96-233 -- Loss: 0.08206330984830856
train-epoch-step: 96-234 -- Loss: 0.16736462712287903
train-epoch-step: 96-235 -- Loss: 0.14051708579063416
train-epoch-step: 96-236 -- Loss: 0.17306016385555267
train-epoch-step: 96-237 -- Loss: 0.22798429429531097
train-epoch-step: 96-238 -- Loss: 0.16027334332466125
train-epoch-step: 96-239 -- Loss: 0.1242314875125885
train-epoch-step: 96-240 -- Loss: 0.21791647374629974
train-epoch-step: 96-241 -- Loss: 0.15027520060539246
train-epoch-step: 96-242 -- Loss: 0.21441304683685303
train-epoch-step: 96-243 -- Loss: 0.23928320407867432
train-epoch-step: 96-244 -- Loss: 0.19675908982753754
train-epoch-step: 96-245 -- Loss: 0.2055341899394989
train-epoch-step: 96-246 -- Loss: 0.21257692575454712
train-epoch-step: 96-247 -- Loss: 0.2072046399116516
train-epoch-step: 96-248 -- Loss: 0.17935681343078613
train-epoch-step: 96-249 -- Loss: 0.15384717285633087
train-epoch-step: 96-250 -- Loss: 0.19340822100639343
train-epoch-step: 96-251 -- Loss: 0.101668581366539
train-epoch-step: 96-252 -- Loss: 0.20529913902282715
train-epoch-step: 96-253 -- Loss: 0.13531512022018433
train-epoch-step: 96-254 -- Loss: 0.20806920528411865
train-epoch-step: 96-255 -- Loss: 0.14029331505298615
train-epoch-step: 96-256 -- Loss: 0.16824305057525635
train-epoch-step: 96-257 -- Loss: 0.187893807888031
train-epoch-step: 96-258 -- Loss: 0.14003941416740417
train-epoch-step: 96-259 -- Loss: 0.11518596112728119
train-epoch-step: 96-260 -- Loss: 0.1991879940032959
train-epoch-step: 96-261 -- Loss: 0.16990545392036438
train-epoch-step: 96-262 -- Loss: 0.28664085268974304
train-epoch-step: 96-263 -- Loss: 0.19964101910591125
train-epoch-step: 96-264 -- Loss: 0.17527784407138824
train-epoch-step: 96-265 -- Loss: 0.11250477284193039
train-epoch-step: 96-266 -- Loss: 0.15089109539985657
train-epoch-step: 96-267 -- Loss: 0.12788045406341553
train-epoch-step: 96-268 -- Loss: 0.11560625582933426
train-epoch-step: 96-269 -- Loss: 0.1671907752752304
train-epoch-step: 96-270 -- Loss: 0.10340920835733414
train-epoch-step: 96-271 -- Loss: 0.14653748273849487
train-epoch-step: 96-272 -- Loss: 0.1113368421792984
train-epoch-step: 96-273 -- Loss: 0.12458473443984985
train-epoch-step: 96-274 -- Loss: 0.17980104684829712
train-epoch-step: 96-275 -- Loss: 0.19007346034049988
train-epoch-step: 96-276 -- Loss: 0.15538784861564636
train-epoch-step: 96-277 -- Loss: 0.15170468389987946
train-epoch-step: 96-278 -- Loss: 0.13671062886714935
train-epoch-step: 96-279 -- Loss: 0.13621430099010468
train-epoch-step: 96-280 -- Loss: 0.20976901054382324
train-epoch-step: 96-281 -- Loss: 0.17224343121051788
train-epoch-step: 96-282 -- Loss: 0.14215202629566193
train-epoch-step: 96-283 -- Loss: 0.11114092171192169
train-epoch-step: 96-284 -- Loss: 0.1370132565498352
train-epoch-step: 96-285 -- Loss: 0.18355602025985718
train-epoch-step: 96-286 -- Loss: 0.15187641978263855
train-epoch-step: 96-287 -- Loss: 0.20423486828804016
train-epoch-step: 96-288 -- Loss: 0.09113278239965439
train-epoch-step: 96-289 -- Loss: 0.11690278351306915
train-epoch-step: 96-290 -- Loss: 0.1742585003376007
train-epoch-step: 96-291 -- Loss: 0.11445845663547516
train-epoch-step: 96-292 -- Loss: 0.15143141150474548
train-epoch-step: 96-293 -- Loss: 0.1326439529657364
train-epoch-step: 96-294 -- Loss: 0.15498709678649902
train-epoch-step: 96-295 -- Loss: 0.2602747976779938
train-epoch-step: 96-296 -- Loss: 0.16026858985424042
train-epoch-step: 96-297 -- Loss: 0.16613824665546417
train-epoch-step: 96-298 -- Loss: 0.22081047296524048
train-epoch-step: 96-299 -- Loss: 0.13658669590950012
train-epoch-step: 96-300 -- Loss: 0.16780593991279602
train-epoch-step: 96-301 -- Loss: 0.17614531517028809
train-epoch-step: 96-302 -- Loss: 0.21357491612434387
train-epoch-step: 96-303 -- Loss: 0.19572244584560394
train-epoch-step: 96-304 -- Loss: 0.12092594802379608
train-epoch-step: 96-305 -- Loss: 0.1415693610906601
train-epoch-step: 96-306 -- Loss: 0.20686101913452148
train-epoch-step: 96-307 -- Loss: 0.15922637283802032
train-epoch-step: 96-308 -- Loss: 0.20857232809066772
train-epoch-step: 96-309 -- Loss: 0.15039384365081787
train-epoch-step: 96-310 -- Loss: 0.15746551752090454
train-epoch-step: 96-311 -- Loss: 0.16048972308635712
train-epoch-step: 96-312 -- Loss: 0.19760729372501373
train-epoch-step: 96-313 -- Loss: 0.09247547388076782
train-epoch-step: 96-314 -- Loss: 0.18684601783752441
train-epoch-step: 96-315 -- Loss: 0.16307002305984497
train-epoch-step: 96-316 -- Loss: 0.14724445343017578
train-epoch-step: 96-317 -- Loss: 0.13448353111743927
train-epoch-step: 96-318 -- Loss: 0.15459877252578735
train-epoch-step: 96-319 -- Loss: 0.16317468881607056
train-epoch-step: 96-320 -- Loss: 0.11328935623168945
train-epoch-step: 96-321 -- Loss: 0.12791605293750763
train-epoch-step: 96-322 -- Loss: 0.20876087248325348
train-epoch-step: 96-323 -- Loss: 0.15425054728984833
train-epoch-step: 96-324 -- Loss: 0.24734725058078766
train-epoch-step: 96-325 -- Loss: 0.15091724693775177
train-epoch-step: 96-326 -- Loss: 0.1623699963092804
train-epoch-step: 96-327 -- Loss: 0.19896435737609863
train-epoch-step: 96-328 -- Loss: 0.18686705827713013
train-epoch-step: 96-329 -- Loss: 0.3316801190376282
train-epoch-step: 96-330 -- Loss: 0.3480088710784912
train-epoch-step: 96-331 -- Loss: 0.2059118151664734
train-epoch-step: 96-332 -- Loss: 0.09692921489477158
train-epoch-step: 96-333 -- Loss: 0.1775386929512024
train-epoch-step: 96-334 -- Loss: 0.1490480899810791
train-epoch-step: 96-335 -- Loss: 0.16471166908740997
train-epoch-step: 96-336 -- Loss: 0.14962886273860931
train-epoch-step: 96-337 -- Loss: 0.19758975505828857
train-epoch-step: 96-338 -- Loss: 0.15550395846366882
train-epoch-step: 96-339 -- Loss: 0.13896718621253967
train-epoch-step: 96-340 -- Loss: 0.19186890125274658
train-epoch-step: 96-341 -- Loss: 0.13563229143619537
train-epoch-step: 96-342 -- Loss: 0.1554606854915619
train-epoch-step: 96-343 -- Loss: 0.14742834866046906
train-epoch-step: 96-344 -- Loss: 0.1679561734199524
train-epoch-step: 96-345 -- Loss: 0.1217159628868103
train-epoch-step: 96-346 -- Loss: 0.19675122201442719
train-epoch-step: 96-347 -- Loss: 0.14671708643436432
train-epoch-step: 96-348 -- Loss: 0.19183793663978577
train-epoch-step: 96-349 -- Loss: 0.19700987637043
train-epoch-step: 96-350 -- Loss: 0.24310946464538574
train-epoch-step: 96-351 -- Loss: 0.18782006204128265
train-epoch-step: 96-352 -- Loss: 0.12503963708877563
train-epoch-step: 96-353 -- Loss: 0.18546780943870544
train-epoch-step: 96-354 -- Loss: 0.2726689875125885
train-epoch-step: 96-355 -- Loss: 0.11493399739265442
train-epoch-step: 96-356 -- Loss: 0.11345371603965759
train-epoch-step: 96-357 -- Loss: 0.17989808320999146
train-epoch-step: 96-358 -- Loss: 0.1840340793132782
train-epoch-step: 96-359 -- Loss: 0.1361120492219925
train-epoch-step: 96-360 -- Loss: 0.12100516259670258
train-epoch-step: 96-361 -- Loss: 0.22835786640644073
train-epoch-step: 96-362 -- Loss: 0.16627176105976105
train-epoch-step: 96-363 -- Loss: 0.10539043694734573
train-epoch-step: 96-364 -- Loss: 0.17263132333755493
train-epoch-step: 96-365 -- Loss: 0.1715235561132431
train-epoch-step: 96-366 -- Loss: 0.19414180517196655
train-epoch-step: 96-367 -- Loss: 0.22491870820522308
train-epoch-step: 96-368 -- Loss: 0.19000184535980225
train-epoch-step: 96-369 -- Loss: 0.2698570191860199
train-epoch-step: 96-370 -- Loss: 0.12305036932229996
train-epoch-step: 96-371 -- Loss: 0.11986513435840607
train-epoch-step: 96-372 -- Loss: 0.14613860845565796
train-epoch-step: 96-373 -- Loss: 0.18694746494293213
train-epoch-step: 96-374 -- Loss: 0.1517927199602127
train-epoch-step: 96-375 -- Loss: 0.2635737657546997
train-epoch-step: 96-376 -- Loss: 0.15874841809272766
train-epoch-step: 96-377 -- Loss: 0.21816317737102509
train-epoch-step: 96-378 -- Loss: 0.19327007234096527
train-epoch-step: 96-379 -- Loss: 0.11727628111839294
train-epoch-step: 96-380 -- Loss: 0.09073623269796371
train-epoch-step: 96-381 -- Loss: 0.24261274933815002
train-epoch-step: 96-382 -- Loss: 0.22564749419689178
train-epoch-step: 96-383 -- Loss: 0.17066532373428345
train-epoch-step: 96-384 -- Loss: 0.20854654908180237
train-epoch-step: 96-385 -- Loss: 0.18056367337703705
train-epoch-step: 96-386 -- Loss: 0.1810150295495987
train-epoch-step: 96-387 -- Loss: 0.19528792798519135
train-epoch-step: 96-388 -- Loss: 0.17562183737754822
train-epoch-step: 96-389 -- Loss: 0.16412325203418732
train-epoch-step: 96-390 -- Loss: 0.14195506274700165
train-epoch-step: 96-391 -- Loss: 0.14422687888145447
train-epoch-step: 96-392 -- Loss: 0.17692911624908447
train-epoch-step: 96-393 -- Loss: 0.14972738921642303
train-epoch-step: 96-394 -- Loss: 0.19459575414657593
train-epoch-step: 96-395 -- Loss: 0.15736377239227295
train-epoch-step: 96-396 -- Loss: 0.1204456016421318
train-epoch-step: 96-397 -- Loss: 0.1208108514547348
train-epoch-step: 96-398 -- Loss: 0.20031669735908508
train-epoch-step: 96-399 -- Loss: 0.1723587065935135
train-epoch-step: 96-400 -- Loss: 0.2757360339164734
train-epoch-step: 96-401 -- Loss: 0.11603173613548279
train-epoch-step: 96-402 -- Loss: 0.2455560863018036
train-epoch-step: 96-403 -- Loss: 0.15655499696731567
train-epoch-step: 96-404 -- Loss: 0.13771194219589233
train-epoch-step: 96-405 -- Loss: 0.13978537917137146
train-epoch-step: 96-406 -- Loss: 0.15998996794223785
train-epoch-step: 96-407 -- Loss: 0.1077289879322052
train-epoch-step: 96-408 -- Loss: 0.1571878343820572
train-epoch-step: 96-409 -- Loss: 0.16196104884147644
train-epoch-step: 96-410 -- Loss: 0.166703462600708
train-epoch-step: 96-411 -- Loss: 0.18988505005836487
train-epoch-step: 96-412 -- Loss: 0.12443946301937103
train-epoch-step: 96-413 -- Loss: 0.13922899961471558
train-epoch-step: 96-414 -- Loss: 0.12822458148002625
train-epoch-step: 96-415 -- Loss: 0.14897994697093964
train-epoch-step: 96-416 -- Loss: 0.2541597783565521
train-epoch-step: 96-417 -- Loss: 0.18570783734321594
train-epoch-step: 96-418 -- Loss: 0.21908460557460785
train-epoch-step: 96-419 -- Loss: 0.16261620819568634
train-epoch-step: 96-420 -- Loss: 0.14864003658294678
train-epoch-step: 96-421 -- Loss: 0.17254464328289032
train-epoch-step: 96-422 -- Loss: 0.14279991388320923
train-epoch-step: 96-423 -- Loss: 0.16242581605911255
train-epoch-step: 96-424 -- Loss: 0.14130538702011108
train-epoch-step: 96-425 -- Loss: 0.1744881272315979
train-epoch-step: 96-426 -- Loss: 0.15789683163166046
train-epoch-step: 96-427 -- Loss: 0.11758922040462494
train-epoch-step: 96-428 -- Loss: 0.18206669390201569
train-epoch-step: 96-429 -- Loss: 0.17075912654399872
train-epoch-step: 96-430 -- Loss: 0.13622301816940308
train-epoch-step: 96-431 -- Loss: 0.16002507507801056
train-epoch-step: 96-432 -- Loss: 0.24396544694900513
train-epoch-step: 96-433 -- Loss: 0.13309745490550995
train-epoch-step: 96-434 -- Loss: 0.12239257991313934
train-epoch-step: 96-435 -- Loss: 0.15435457229614258
train-epoch-step: 96-436 -- Loss: 0.15337757766246796
train-epoch-step: 96-437 -- Loss: 0.1286313682794571
train-epoch-step: 96-438 -- Loss: 0.15896931290626526
train-epoch-step: 96-439 -- Loss: 0.25927960872650146
train-epoch-step: 96-440 -- Loss: 0.12381835281848907
train-epoch-step: 96-441 -- Loss: 0.1904764473438263
train-epoch-step: 96-442 -- Loss: 0.16779860854148865
train-epoch-step: 96-443 -- Loss: 0.15081828832626343
train-epoch-step: 96-444 -- Loss: 0.16677254438400269
train-epoch-step: 96-445 -- Loss: 0.172533318400383
train-epoch-step: 96-446 -- Loss: 0.14808832108974457
train-epoch-step: 96-447 -- Loss: 0.1840795874595642
train-epoch-step: 96-448 -- Loss: 0.21600985527038574
train-epoch-step: 96-449 -- Loss: 0.18468666076660156
train-epoch-step: 96-450 -- Loss: 0.17517998814582825
train-epoch-step: 96-451 -- Loss: 0.14244316518306732
train-epoch-step: 96-452 -- Loss: 0.12464867532253265
train-epoch-step: 96-453 -- Loss: 0.0865805596113205
train-epoch-step: 96-454 -- Loss: 0.22257059812545776
train-epoch-step: 96-455 -- Loss: 0.12091986835002899
train-epoch-step: 96-456 -- Loss: 0.11269460618495941
train-epoch-step: 96-457 -- Loss: 0.20467427372932434
train-epoch-step: 96-458 -- Loss: 0.14097541570663452
train-epoch-step: 96-459 -- Loss: 0.20679950714111328
train-epoch-step: 96-460 -- Loss: 0.12216916680335999
train-epoch-step: 96-461 -- Loss: 0.1334790289402008
train-epoch-step: 96-462 -- Loss: 0.14783722162246704
train-epoch-step: 96-463 -- Loss: 0.1290723830461502
train-epoch-step: 96-464 -- Loss: 0.15554536879062653
train-epoch-step: 96-465 -- Loss: 0.2280459702014923
train-epoch-step: 96-466 -- Loss: 0.1970023810863495
train-epoch-step: 96-467 -- Loss: 0.10886818170547485
train-epoch-step: 96-468 -- Loss: 0.16277211904525757
train-epoch-step: 96-469 -- Loss: 0.20387431979179382
train-epoch-step: 96-470 -- Loss: 0.1744951605796814
train-epoch-step: 96-471 -- Loss: 0.15435409545898438
train-epoch-step: 96-472 -- Loss: 0.15493163466453552
train-epoch-step: 96-473 -- Loss: 0.14501823484897614
train-epoch-step: 96-474 -- Loss: 0.12427503615617752
train-epoch-step: 96-475 -- Loss: 0.11024779826402664
train-epoch-step: 96-476 -- Loss: 0.19994200766086578
train-epoch-step: 96-477 -- Loss: 0.21481743454933167
train-epoch-step: 96-478 -- Loss: 0.1796090453863144
train-epoch-step: 96-479 -- Loss: 0.13328641653060913
train-epoch-step: 96-480 -- Loss: 0.17922760546207428
train-epoch-step: 96-481 -- Loss: 0.3046380281448364
train-epoch-step: 96-482 -- Loss: 0.2530844211578369
train-epoch-step: 96-483 -- Loss: 0.17595285177230835
train-epoch-step: 96-484 -- Loss: 0.21126358211040497
train-epoch-step: 96-485 -- Loss: 0.1295357197523117
train-epoch-step: 96-486 -- Loss: 0.21810530126094818
train-epoch-step: 96-487 -- Loss: 0.22637102007865906
train-epoch-step: 96-488 -- Loss: 0.194380983710289
train-epoch-step: 96-489 -- Loss: 0.21837152540683746
train-epoch-step: 96-490 -- Loss: 0.13654418289661407
train-epoch-step: 96-491 -- Loss: 0.1360127180814743
train-epoch-step: 96-492 -- Loss: 0.12586157023906708
train-epoch-step: 96-493 -- Loss: 0.20319698750972748
train-epoch-step: 96-494 -- Loss: 0.19441719353199005
train-epoch-step: 96-495 -- Loss: 0.19760532677173615
train-epoch-step: 96-496 -- Loss: 0.1382303386926651
train-epoch-step: 96-497 -- Loss: 0.18101656436920166
train-epoch-step: 96-498 -- Loss: 0.14674033224582672
train-epoch-step: 96-499 -- Loss: 0.1755623072385788
train-epoch-step: 96-500 -- Loss: 0.15493911504745483
train-epoch-step: 96-501 -- Loss: 0.21446222066879272
train-epoch-step: 96-502 -- Loss: 0.1566082090139389
train-epoch-step: 96-503 -- Loss: 0.21284940838813782
train-epoch-step: 96-504 -- Loss: 0.11898207664489746
train-epoch-step: 96-505 -- Loss: 0.16707298159599304
train-epoch-step: 96-506 -- Loss: 0.11203740537166595
train-epoch-step: 96-507 -- Loss: 0.17681998014450073
train-epoch-step: 96-508 -- Loss: 0.17267131805419922
train-epoch-step: 96-509 -- Loss: 0.16252879798412323
train-epoch-step: 96-510 -- Loss: 0.12297125160694122
train-epoch-step: 96-511 -- Loss: 0.21488022804260254
train-epoch-step: 96-512 -- Loss: 0.1780402511358261
train-epoch-step: 96-513 -- Loss: 0.18115738034248352
train-epoch-step: 96-514 -- Loss: 0.15402522683143616
train-epoch-step: 96-515 -- Loss: 0.1547977477312088
train-epoch-step: 96-516 -- Loss: 0.17336861789226532
train-epoch-step: 96-517 -- Loss: 0.16952216625213623
train-epoch-step: 96-518 -- Loss: 0.13526661694049835
train-epoch-step: 96-519 -- Loss: 0.13503706455230713
train-epoch-step: 96-520 -- Loss: 0.1800437718629837
train-epoch-step: 96-521 -- Loss: 0.21960538625717163
train-epoch-step: 96-522 -- Loss: 0.16462159156799316
train-epoch-step: 96-523 -- Loss: 0.15280404686927795
train-epoch-step: 96-524 -- Loss: 0.1638593077659607
train-epoch-step: 96-525 -- Loss: 0.1861347258090973
train-epoch-step: 96-526 -- Loss: 0.13161885738372803
train-epoch-step: 96-527 -- Loss: 0.14842987060546875
train-epoch-step: 96-528 -- Loss: 0.15409958362579346
train-epoch-step: 96-529 -- Loss: 0.15190617740154266
train-epoch-step: 96-530 -- Loss: 0.1646900326013565
train-epoch-step: 96-531 -- Loss: 0.19272953271865845
train-epoch-step: 96-532 -- Loss: 0.16526949405670166
train-epoch-step: 96-533 -- Loss: 0.1705622673034668
train-epoch-step: 96-534 -- Loss: 0.1269906908273697
train-epoch-step: 96-535 -- Loss: 0.23978379368782043
train-epoch-step: 96-536 -- Loss: 0.15100784599781036
train-epoch-step: 96-537 -- Loss: 0.14870736002922058
train-epoch-step: 96-538 -- Loss: 0.10201316326856613
train-epoch-step: 96-539 -- Loss: 0.17306247353553772
train-epoch-step: 96-540 -- Loss: 0.1345197558403015
train-epoch-step: 96-541 -- Loss: 0.20576977729797363
train-epoch-step: 96-542 -- Loss: 0.2111154943704605
train-epoch-step: 96-543 -- Loss: 0.16217972338199615
train-epoch-step: 96-544 -- Loss: 0.2170586884021759
train-epoch-step: 96-545 -- Loss: 0.19274196028709412
train-epoch-step: 96-546 -- Loss: 0.20222848653793335
train-epoch-step: 96-547 -- Loss: 0.17831963300704956
train-epoch-step: 96-548 -- Loss: 0.09113534539937973
train-epoch-step: 96-549 -- Loss: 0.14530785381793976
train-epoch-step: 96-550 -- Loss: 0.19178980588912964
train-epoch-step: 96-551 -- Loss: 0.14915701746940613
train-epoch-step: 96-552 -- Loss: 0.12404391169548035
train-epoch-step: 96-553 -- Loss: 0.18786297738552094
train-epoch-step: 96-554 -- Loss: 0.1852835714817047
train-epoch-step: 96-555 -- Loss: 0.20335403084754944
train-epoch-step: 96-556 -- Loss: 0.13978484272956848
train-epoch-step: 96-557 -- Loss: 0.23626896739006042
train-epoch-step: 96-558 -- Loss: 0.21521803736686707
train-epoch-step: 96-559 -- Loss: 0.13954660296440125
train-epoch-step: 96-560 -- Loss: 0.1983412206172943
train-epoch-step: 96-561 -- Loss: 0.17353439331054688
train-epoch-step: 96-562 -- Loss: 0.15475283563137054
train-epoch-step: 96-563 -- Loss: 0.1789941042661667
train-epoch-step: 96-564 -- Loss: 0.0995350033044815
train-epoch-step: 96-565 -- Loss: 0.18031182885169983
train-epoch-step: 96-566 -- Loss: 0.146147683262825
train-epoch-step: 96-567 -- Loss: 0.21540477871894836
train-epoch-step: 96-568 -- Loss: 0.15554216504096985
train-epoch-step: 96-569 -- Loss: 0.24385856091976166
train-epoch-step: 96-570 -- Loss: 0.16372738778591156
train-epoch-step: 96-571 -- Loss: 0.2139371633529663
train-epoch-step: 96-572 -- Loss: 0.23669978976249695
train-epoch-step: 96-573 -- Loss: 0.18855604529380798
train-epoch-step: 96-574 -- Loss: 0.24625706672668457
train-epoch-step: 96-575 -- Loss: 0.28331780433654785
train-epoch-step: 96-576 -- Loss: 0.11522728204727173
train-epoch-step: 96-577 -- Loss: 0.1621917188167572
train-epoch-step: 96-578 -- Loss: 0.21234342455863953
train-epoch-step: 96-579 -- Loss: 0.15694692730903625
train-epoch-step: 96-580 -- Loss: 0.16856050491333008
train-epoch-step: 96-581 -- Loss: 0.13676169514656067
train-epoch-step: 96-582 -- Loss: 0.20160727202892303
train-epoch-step: 96-583 -- Loss: 0.22333770990371704
train-epoch-step: 96-584 -- Loss: 0.15785779058933258
train-epoch-step: 96-585 -- Loss: 0.1904076784849167
train-epoch-step: 96-586 -- Loss: 0.2534153163433075
train-epoch-step: 96-587 -- Loss: 0.15899276733398438
train-epoch-step: 96-588 -- Loss: 0.12843650579452515
val-epoch-step: 96-589 -- Loss: 0.20905709266662598
val-epoch-step: 96-590 -- Loss: 0.1559579074382782
val-epoch-step: 96-591 -- Loss: 0.22777698934078217
val-epoch-step: 96-592 -- Loss: 0.17390641570091248
val-epoch-step: 96-593 -- Loss: 0.1539362370967865
val-epoch-step: 96-594 -- Loss: 0.48427313566207886
val-epoch-step: 96-595 -- Loss: 0.17250020802021027
val-epoch-step: 96-596 -- Loss: 0.26370948553085327
val-epoch-step: 96-597 -- Loss: 0.17210818827152252
val-epoch-step: 96-598 -- Loss: 0.1468041092157364
val-epoch-step: 96-599 -- Loss: 0.1813616007566452
val-epoch-step: 96-600 -- Loss: 0.24054065346717834
val-epoch-step: 96-601 -- Loss: 0.1573961079120636
val-epoch-step: 96-602 -- Loss: 0.14377331733703613
val-epoch-step: 96-603 -- Loss: 0.1946694254875183
val-epoch-step: 96-604 -- Loss: 0.16218885779380798
val-epoch-step: 96-605 -- Loss: 0.14745688438415527
val-epoch-step: 96-606 -- Loss: 0.24486899375915527
val-epoch-step: 96-607 -- Loss: 0.15044371783733368
val-epoch-step: 96-608 -- Loss: 0.2568546533584595
val-epoch-step: 96-609 -- Loss: 0.17029625177383423
val-epoch-step: 96-610 -- Loss: 0.1910638064146042
val-epoch-step: 96-611 -- Loss: 0.1500791311264038
val-epoch-step: 96-612 -- Loss: 0.5018243789672852
val-epoch-step: 96-613 -- Loss: 0.168550044298172
val-epoch-step: 96-614 -- Loss: 0.18128322064876556
val-epoch-step: 96-615 -- Loss: 0.170974463224411
val-epoch-step: 96-616 -- Loss: 0.16056406497955322
val-epoch-step: 96-617 -- Loss: 0.19498106837272644
val-epoch-step: 96-618 -- Loss: 0.2298593372106552
val-epoch-step: 96-619 -- Loss: 0.20621901750564575
val-epoch-step: 96-620 -- Loss: 0.14802199602127075
val-epoch-step: 96-621 -- Loss: 0.13143587112426758
val-epoch-step: 96-622 -- Loss: 0.1551947146654129
val-epoch-step: 96-623 -- Loss: 0.1459227353334427
val-epoch-step: 96-624 -- Loss: 0.14122140407562256
val-epoch-step: 96-625 -- Loss: 0.15518026053905487
val-epoch-step: 96-626 -- Loss: 0.14643728733062744
val-epoch-step: 96-627 -- Loss: 0.18257851898670197
val-epoch-step: 96-628 -- Loss: 0.634811282157898
val-epoch-step: 96-629 -- Loss: 0.26048049330711365
val-epoch-step: 96-630 -- Loss: 0.3493533432483673
val-epoch-step: 96-631 -- Loss: 0.1451629102230072
val-epoch-step: 96-632 -- Loss: 0.21221575140953064
val-epoch-step: 96-633 -- Loss: 0.1521821916103363
val-epoch-step: 96-634 -- Loss: 0.1505049765110016
val-epoch-step: 96-635 -- Loss: 0.11515883356332779
val-epoch-step: 96-636 -- Loss: 0.17342700064182281
val-epoch-step: 96-637 -- Loss: 0.17816737294197083
val-epoch-step: 96-638 -- Loss: 0.14810943603515625
val-epoch-step: 96-639 -- Loss: 0.2596365511417389
val-epoch-step: 96-640 -- Loss: 0.25318774580955505
val-epoch-step: 96-641 -- Loss: 0.13070598244667053
val-epoch-step: 96-642 -- Loss: 0.1837647259235382
val-epoch-step: 96-643 -- Loss: 0.20923550426959991
val-epoch-step: 96-644 -- Loss: 0.15969640016555786
val-epoch-step: 96-645 -- Loss: 0.22065171599388123
val-epoch-step: 96-646 -- Loss: 0.127271369099617
val-epoch-step: 96-647 -- Loss: 0.1290603131055832
val-epoch-step: 96-648 -- Loss: 0.15380120277404785
val-epoch-step: 96-649 -- Loss: 0.20817652344703674
val-epoch-step: 96-650 -- Loss: 0.2507195770740509
val-epoch-step: 96-651 -- Loss: 0.14758096635341644
val-epoch-step: 96-652 -- Loss: 0.160785973072052
val-epoch-step: 96-653 -- Loss: 0.1928403675556183
val-epoch-step: 96-654 -- Loss: 0.11403820663690567
Epoch: 96 -- Train Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 97-0 -- Loss: 0.21748919785022736
train-epoch-step: 97-1 -- Loss: 0.15015017986297607
train-epoch-step: 97-2 -- Loss: 0.19292353093624115
train-epoch-step: 97-3 -- Loss: 0.13866110146045685
train-epoch-step: 97-4 -- Loss: 0.15647006034851074
train-epoch-step: 97-5 -- Loss: 0.18590973317623138
train-epoch-step: 97-6 -- Loss: 0.22896406054496765
train-epoch-step: 97-7 -- Loss: 0.16177158057689667
train-epoch-step: 97-8 -- Loss: 0.1808108687400818
train-epoch-step: 97-9 -- Loss: 0.224863201379776
train-epoch-step: 97-10 -- Loss: 0.2067977488040924
train-epoch-step: 97-11 -- Loss: 0.1680203080177307
train-epoch-step: 97-12 -- Loss: 0.14636622369289398
train-epoch-step: 97-13 -- Loss: 0.17679239809513092
train-epoch-step: 97-14 -- Loss: 0.15879692137241364
train-epoch-step: 97-15 -- Loss: 0.1554376631975174
train-epoch-step: 97-16 -- Loss: 0.16939868032932281
train-epoch-step: 97-17 -- Loss: 0.2327006608247757
train-epoch-step: 97-18 -- Loss: 0.18463188409805298
train-epoch-step: 97-19 -- Loss: 0.12499338388442993
train-epoch-step: 97-20 -- Loss: 0.21196559071540833
train-epoch-step: 97-21 -- Loss: 0.3108237683773041
train-epoch-step: 97-22 -- Loss: 0.14131827652454376
train-epoch-step: 97-23 -- Loss: 0.13856589794158936
train-epoch-step: 97-24 -- Loss: 0.12558595836162567
train-epoch-step: 97-25 -- Loss: 0.23433275520801544
train-epoch-step: 97-26 -- Loss: 0.23217669129371643
train-epoch-step: 97-27 -- Loss: 0.25606831908226013
train-epoch-step: 97-28 -- Loss: 0.13078543543815613
train-epoch-step: 97-29 -- Loss: 0.25328293442726135
train-epoch-step: 97-30 -- Loss: 0.11646007001399994
train-epoch-step: 97-31 -- Loss: 0.1376522332429886
train-epoch-step: 97-32 -- Loss: 0.17530988156795502
train-epoch-step: 97-33 -- Loss: 0.2800447642803192
train-epoch-step: 97-34 -- Loss: 0.18087440729141235
train-epoch-step: 97-35 -- Loss: 0.2540082037448883
train-epoch-step: 97-36 -- Loss: 0.14422471821308136
train-epoch-step: 97-37 -- Loss: 0.15534694492816925
train-epoch-step: 97-38 -- Loss: 0.18368349969387054
train-epoch-step: 97-39 -- Loss: 0.22500671446323395
train-epoch-step: 97-40 -- Loss: 0.19545991718769073
train-epoch-step: 97-41 -- Loss: 0.22209197282791138
train-epoch-step: 97-42 -- Loss: 0.15341061353683472
train-epoch-step: 97-43 -- Loss: 0.27191659808158875
train-epoch-step: 97-44 -- Loss: 0.12998875975608826
train-epoch-step: 97-45 -- Loss: 0.13331949710845947
train-epoch-step: 97-46 -- Loss: 0.17701292037963867
train-epoch-step: 97-47 -- Loss: 0.197638601064682
train-epoch-step: 97-48 -- Loss: 0.16432572901248932
train-epoch-step: 97-49 -- Loss: 0.23557204008102417
train-epoch-step: 97-50 -- Loss: 0.1143808513879776
train-epoch-step: 97-51 -- Loss: 0.19951078295707703
train-epoch-step: 97-52 -- Loss: 0.19080427289009094
train-epoch-step: 97-53 -- Loss: 0.20929855108261108
train-epoch-step: 97-54 -- Loss: 0.2969587445259094
train-epoch-step: 97-55 -- Loss: 0.16765709221363068
train-epoch-step: 97-56 -- Loss: 0.2248690128326416
train-epoch-step: 97-57 -- Loss: 0.23927506804466248
train-epoch-step: 97-58 -- Loss: 0.2802621126174927
train-epoch-step: 97-59 -- Loss: 0.27852457761764526
train-epoch-step: 97-60 -- Loss: 0.13170567154884338
train-epoch-step: 97-61 -- Loss: 0.20835435390472412
train-epoch-step: 97-62 -- Loss: 0.18724147975444794
train-epoch-step: 97-63 -- Loss: 0.13645939528942108
train-epoch-step: 97-64 -- Loss: 0.14803466200828552
train-epoch-step: 97-65 -- Loss: 0.17507372796535492
train-epoch-step: 97-66 -- Loss: 0.10767942667007446
train-epoch-step: 97-67 -- Loss: 0.12534388899803162
train-epoch-step: 97-68 -- Loss: 0.21661294996738434
train-epoch-step: 97-69 -- Loss: 0.123597651720047
train-epoch-step: 97-70 -- Loss: 0.21558082103729248
train-epoch-step: 97-71 -- Loss: 0.25594326853752136
train-epoch-step: 97-72 -- Loss: 0.17438575625419617
train-epoch-step: 97-73 -- Loss: 0.20525628328323364
train-epoch-step: 97-74 -- Loss: 0.09352263063192368
train-epoch-step: 97-75 -- Loss: 0.12657499313354492
train-epoch-step: 97-76 -- Loss: 0.14243172109127045
train-epoch-step: 97-77 -- Loss: 0.2240975797176361
train-epoch-step: 97-78 -- Loss: 0.2686375081539154
train-epoch-step: 97-79 -- Loss: 0.19123029708862305
train-epoch-step: 97-80 -- Loss: 0.24529442191123962
train-epoch-step: 97-81 -- Loss: 0.12761905789375305
train-epoch-step: 97-82 -- Loss: 0.25165829062461853
train-epoch-step: 97-83 -- Loss: 0.1716826856136322
train-epoch-step: 97-84 -- Loss: 0.18478688597679138
train-epoch-step: 97-85 -- Loss: 0.18246951699256897
train-epoch-step: 97-86 -- Loss: 0.12105270475149155
train-epoch-step: 97-87 -- Loss: 0.21614542603492737
train-epoch-step: 97-88 -- Loss: 0.1425086110830307
train-epoch-step: 97-89 -- Loss: 0.19070108234882355
train-epoch-step: 97-90 -- Loss: 0.1874282956123352
train-epoch-step: 97-91 -- Loss: 0.24046017229557037
train-epoch-step: 97-92 -- Loss: 0.14758841693401337
train-epoch-step: 97-93 -- Loss: 0.17761269211769104
train-epoch-step: 97-94 -- Loss: 0.21734152734279633
train-epoch-step: 97-95 -- Loss: 0.18420863151550293
train-epoch-step: 97-96 -- Loss: 0.21008536219596863
train-epoch-step: 97-97 -- Loss: 0.17237424850463867
train-epoch-step: 97-98 -- Loss: 0.15217965841293335
train-epoch-step: 97-99 -- Loss: 0.18204575777053833
train-epoch-step: 97-100 -- Loss: 0.1833360195159912
train-epoch-step: 97-101 -- Loss: 0.2606702446937561
train-epoch-step: 97-102 -- Loss: 0.21202468872070312
train-epoch-step: 97-103 -- Loss: 0.18150831758975983
train-epoch-step: 97-104 -- Loss: 0.14473891258239746
train-epoch-step: 97-105 -- Loss: 0.26164206862449646
train-epoch-step: 97-106 -- Loss: 0.17812588810920715
train-epoch-step: 97-107 -- Loss: 0.18291480839252472
train-epoch-step: 97-108 -- Loss: 0.18925750255584717
train-epoch-step: 97-109 -- Loss: 0.1438606232404709
train-epoch-step: 97-110 -- Loss: 0.17597702145576477
train-epoch-step: 97-111 -- Loss: 0.17490029335021973
train-epoch-step: 97-112 -- Loss: 0.16487213969230652
train-epoch-step: 97-113 -- Loss: 0.16579757630825043
train-epoch-step: 97-114 -- Loss: 0.19005197286605835
train-epoch-step: 97-115 -- Loss: 0.15608492493629456
train-epoch-step: 97-116 -- Loss: 0.1342325359582901
train-epoch-step: 97-117 -- Loss: 0.12399619817733765
train-epoch-step: 97-118 -- Loss: 0.19112065434455872
train-epoch-step: 97-119 -- Loss: 0.15180964767932892
train-epoch-step: 97-120 -- Loss: 0.24356868863105774
train-epoch-step: 97-121 -- Loss: 0.23171496391296387
train-epoch-step: 97-122 -- Loss: 0.20948593318462372
train-epoch-step: 97-123 -- Loss: 0.20528548955917358
train-epoch-step: 97-124 -- Loss: 0.11773514747619629
train-epoch-step: 97-125 -- Loss: 0.1514636129140854
train-epoch-step: 97-126 -- Loss: 0.22830431163311005
train-epoch-step: 97-127 -- Loss: 0.1758396029472351
train-epoch-step: 97-128 -- Loss: 0.1679055392742157
train-epoch-step: 97-129 -- Loss: 0.1363764852285385
train-epoch-step: 97-130 -- Loss: 0.18624530732631683
train-epoch-step: 97-131 -- Loss: 0.12952326238155365
train-epoch-step: 97-132 -- Loss: 0.18320465087890625
train-epoch-step: 97-133 -- Loss: 0.11348742991685867
train-epoch-step: 97-134 -- Loss: 0.18985408544540405
train-epoch-step: 97-135 -- Loss: 0.13581931591033936
train-epoch-step: 97-136 -- Loss: 0.12859244644641876
train-epoch-step: 97-137 -- Loss: 0.23766155540943146
train-epoch-step: 97-138 -- Loss: 0.2590848207473755
train-epoch-step: 97-139 -- Loss: 0.12734660506248474
train-epoch-step: 97-140 -- Loss: 0.20474664866924286
train-epoch-step: 97-141 -- Loss: 0.2314491868019104
train-epoch-step: 97-142 -- Loss: 0.1971990019083023
train-epoch-step: 97-143 -- Loss: 0.16494473814964294
train-epoch-step: 97-144 -- Loss: 0.1828623265028
train-epoch-step: 97-145 -- Loss: 0.1395353227853775
train-epoch-step: 97-146 -- Loss: 0.17273646593093872
train-epoch-step: 97-147 -- Loss: 0.16479156911373138
train-epoch-step: 97-148 -- Loss: 0.1548866182565689
train-epoch-step: 97-149 -- Loss: 0.11791730672121048
train-epoch-step: 97-150 -- Loss: 0.18285508453845978
train-epoch-step: 97-151 -- Loss: 0.18849876523017883
train-epoch-step: 97-152 -- Loss: 0.19089430570602417
train-epoch-step: 97-153 -- Loss: 0.27873116731643677
train-epoch-step: 97-154 -- Loss: 0.12993945181369781
train-epoch-step: 97-155 -- Loss: 0.13147859275341034
train-epoch-step: 97-156 -- Loss: 0.11434132605791092
train-epoch-step: 97-157 -- Loss: 0.15913048386573792
train-epoch-step: 97-158 -- Loss: 0.15993385016918182
train-epoch-step: 97-159 -- Loss: 0.17835327982902527
train-epoch-step: 97-160 -- Loss: 0.2032073736190796
train-epoch-step: 97-161 -- Loss: 0.1961633712053299
train-epoch-step: 97-162 -- Loss: 0.20359987020492554
train-epoch-step: 97-163 -- Loss: 0.19415128231048584
train-epoch-step: 97-164 -- Loss: 0.1919384002685547
train-epoch-step: 97-165 -- Loss: 0.15974870324134827
train-epoch-step: 97-166 -- Loss: 0.11722661554813385
train-epoch-step: 97-167 -- Loss: 0.12164858728647232
train-epoch-step: 97-168 -- Loss: 0.1969044804573059
train-epoch-step: 97-169 -- Loss: 0.13647225499153137
train-epoch-step: 97-170 -- Loss: 0.19419604539871216
train-epoch-step: 97-171 -- Loss: 0.14487779140472412
train-epoch-step: 97-172 -- Loss: 0.2547791600227356
train-epoch-step: 97-173 -- Loss: 0.12976309657096863
train-epoch-step: 97-174 -- Loss: 0.24038265645503998
train-epoch-step: 97-175 -- Loss: 0.18585211038589478
train-epoch-step: 97-176 -- Loss: 0.12584394216537476
train-epoch-step: 97-177 -- Loss: 0.16889163851737976
train-epoch-step: 97-178 -- Loss: 0.17017149925231934
train-epoch-step: 97-179 -- Loss: 0.14661365747451782
train-epoch-step: 97-180 -- Loss: 0.1498877853155136
train-epoch-step: 97-181 -- Loss: 0.16526024043560028
train-epoch-step: 97-182 -- Loss: 0.1807270348072052
train-epoch-step: 97-183 -- Loss: 0.27521517872810364
train-epoch-step: 97-184 -- Loss: 0.13698488473892212
train-epoch-step: 97-185 -- Loss: 0.1399611085653305
train-epoch-step: 97-186 -- Loss: 0.1776077002286911
train-epoch-step: 97-187 -- Loss: 0.20486968755722046
train-epoch-step: 97-188 -- Loss: 0.16824248433113098
train-epoch-step: 97-189 -- Loss: 0.10177434235811234
train-epoch-step: 97-190 -- Loss: 0.18039172887802124
train-epoch-step: 97-191 -- Loss: 0.1580299586057663
train-epoch-step: 97-192 -- Loss: 0.2248685359954834
train-epoch-step: 97-193 -- Loss: 0.20434561371803284
train-epoch-step: 97-194 -- Loss: 0.17737329006195068
train-epoch-step: 97-195 -- Loss: 0.1640813946723938
train-epoch-step: 97-196 -- Loss: 0.16309978067874908
train-epoch-step: 97-197 -- Loss: 0.12256042659282684
train-epoch-step: 97-198 -- Loss: 0.12685593962669373
train-epoch-step: 97-199 -- Loss: 0.14630602300167084
train-epoch-step: 97-200 -- Loss: 0.12072481960058212
train-epoch-step: 97-201 -- Loss: 0.1817389726638794
train-epoch-step: 97-202 -- Loss: 0.1330997347831726
train-epoch-step: 97-203 -- Loss: 0.17644557356834412
train-epoch-step: 97-204 -- Loss: 0.13257087767124176
train-epoch-step: 97-205 -- Loss: 0.1801893711090088
train-epoch-step: 97-206 -- Loss: 0.19531425833702087
train-epoch-step: 97-207 -- Loss: 0.1321290284395218
train-epoch-step: 97-208 -- Loss: 0.17979863286018372
train-epoch-step: 97-209 -- Loss: 0.13887488842010498
train-epoch-step: 97-210 -- Loss: 0.12762081623077393
train-epoch-step: 97-211 -- Loss: 0.20623555779457092
train-epoch-step: 97-212 -- Loss: 0.19605213403701782
train-epoch-step: 97-213 -- Loss: 0.12641766667366028
train-epoch-step: 97-214 -- Loss: 0.1416173279285431
train-epoch-step: 97-215 -- Loss: 0.12324371188879013
train-epoch-step: 97-216 -- Loss: 0.19700030982494354
train-epoch-step: 97-217 -- Loss: 0.203847274184227
train-epoch-step: 97-218 -- Loss: 0.14294959604740143
train-epoch-step: 97-219 -- Loss: 0.16699762642383575
train-epoch-step: 97-220 -- Loss: 0.12306983768939972
train-epoch-step: 97-221 -- Loss: 0.19950711727142334
train-epoch-step: 97-222 -- Loss: 0.11393091082572937
train-epoch-step: 97-223 -- Loss: 0.16858923435211182
train-epoch-step: 97-224 -- Loss: 0.1815457046031952
train-epoch-step: 97-225 -- Loss: 0.26463162899017334
train-epoch-step: 97-226 -- Loss: 0.20549891889095306
train-epoch-step: 97-227 -- Loss: 0.2126922309398651
train-epoch-step: 97-228 -- Loss: 0.16980764269828796
train-epoch-step: 97-229 -- Loss: 0.1678507775068283
train-epoch-step: 97-230 -- Loss: 0.15773004293441772
train-epoch-step: 97-231 -- Loss: 0.14996075630187988
train-epoch-step: 97-232 -- Loss: 0.18667364120483398
train-epoch-step: 97-233 -- Loss: 0.08231960237026215
train-epoch-step: 97-234 -- Loss: 0.16620318591594696
train-epoch-step: 97-235 -- Loss: 0.14231890439987183
train-epoch-step: 97-236 -- Loss: 0.1768263578414917
train-epoch-step: 97-237 -- Loss: 0.22465434670448303
train-epoch-step: 97-238 -- Loss: 0.15025019645690918
train-epoch-step: 97-239 -- Loss: 0.12138812988996506
train-epoch-step: 97-240 -- Loss: 0.22363805770874023
train-epoch-step: 97-241 -- Loss: 0.14987969398498535
train-epoch-step: 97-242 -- Loss: 0.2072945386171341
train-epoch-step: 97-243 -- Loss: 0.23337939381599426
train-epoch-step: 97-244 -- Loss: 0.2056819647550583
train-epoch-step: 97-245 -- Loss: 0.20240359008312225
train-epoch-step: 97-246 -- Loss: 0.20810367166996002
train-epoch-step: 97-247 -- Loss: 0.202591210603714
train-epoch-step: 97-248 -- Loss: 0.182511106133461
train-epoch-step: 97-249 -- Loss: 0.13395705819129944
train-epoch-step: 97-250 -- Loss: 0.19297194480895996
train-epoch-step: 97-251 -- Loss: 0.10226928442716599
train-epoch-step: 97-252 -- Loss: 0.19256745278835297
train-epoch-step: 97-253 -- Loss: 0.13838361203670502
train-epoch-step: 97-254 -- Loss: 0.20681925117969513
train-epoch-step: 97-255 -- Loss: 0.13919416069984436
train-epoch-step: 97-256 -- Loss: 0.147635817527771
train-epoch-step: 97-257 -- Loss: 0.18281792104244232
train-epoch-step: 97-258 -- Loss: 0.1405252069234848
train-epoch-step: 97-259 -- Loss: 0.10924367606639862
train-epoch-step: 97-260 -- Loss: 0.1957571804523468
train-epoch-step: 97-261 -- Loss: 0.16663283109664917
train-epoch-step: 97-262 -- Loss: 0.2834746837615967
train-epoch-step: 97-263 -- Loss: 0.19845212996006012
train-epoch-step: 97-264 -- Loss: 0.1720450520515442
train-epoch-step: 97-265 -- Loss: 0.11091836541891098
train-epoch-step: 97-266 -- Loss: 0.14842014014720917
train-epoch-step: 97-267 -- Loss: 0.12875942885875702
train-epoch-step: 97-268 -- Loss: 0.11453118175268173
train-epoch-step: 97-269 -- Loss: 0.1659773886203766
train-epoch-step: 97-270 -- Loss: 0.11317767202854156
train-epoch-step: 97-271 -- Loss: 0.14460420608520508
train-epoch-step: 97-272 -- Loss: 0.11666148900985718
train-epoch-step: 97-273 -- Loss: 0.12516474723815918
train-epoch-step: 97-274 -- Loss: 0.17700886726379395
train-epoch-step: 97-275 -- Loss: 0.18433575332164764
train-epoch-step: 97-276 -- Loss: 0.150127112865448
train-epoch-step: 97-277 -- Loss: 0.1471979022026062
train-epoch-step: 97-278 -- Loss: 0.1382254958152771
train-epoch-step: 97-279 -- Loss: 0.13428427278995514
train-epoch-step: 97-280 -- Loss: 0.2120099514722824
train-epoch-step: 97-281 -- Loss: 0.17406073212623596
train-epoch-step: 97-282 -- Loss: 0.13763032853603363
train-epoch-step: 97-283 -- Loss: 0.11070365458726883
train-epoch-step: 97-284 -- Loss: 0.12819673120975494
train-epoch-step: 97-285 -- Loss: 0.1861700713634491
train-epoch-step: 97-286 -- Loss: 0.14693893492221832
train-epoch-step: 97-287 -- Loss: 0.20397907495498657
train-epoch-step: 97-288 -- Loss: 0.09114673733711243
train-epoch-step: 97-289 -- Loss: 0.11524089425802231
train-epoch-step: 97-290 -- Loss: 0.18241579830646515
train-epoch-step: 97-291 -- Loss: 0.12116139382123947
train-epoch-step: 97-292 -- Loss: 0.1490170806646347
train-epoch-step: 97-293 -- Loss: 0.131509467959404
train-epoch-step: 97-294 -- Loss: 0.1547441929578781
train-epoch-step: 97-295 -- Loss: 0.2650642991065979
train-epoch-step: 97-296 -- Loss: 0.15021555125713348
train-epoch-step: 97-297 -- Loss: 0.16588783264160156
train-epoch-step: 97-298 -- Loss: 0.22534972429275513
train-epoch-step: 97-299 -- Loss: 0.14269812405109406
train-epoch-step: 97-300 -- Loss: 0.1556342989206314
train-epoch-step: 97-301 -- Loss: 0.1685672551393509
train-epoch-step: 97-302 -- Loss: 0.21057747304439545
train-epoch-step: 97-303 -- Loss: 0.20223398506641388
train-epoch-step: 97-304 -- Loss: 0.13629040122032166
train-epoch-step: 97-305 -- Loss: 0.13754916191101074
train-epoch-step: 97-306 -- Loss: 0.20515042543411255
train-epoch-step: 97-307 -- Loss: 0.16243906319141388
train-epoch-step: 97-308 -- Loss: 0.22095948457717896
train-epoch-step: 97-309 -- Loss: 0.1556471586227417
train-epoch-step: 97-310 -- Loss: 0.15700305998325348
train-epoch-step: 97-311 -- Loss: 0.15351638197898865
train-epoch-step: 97-312 -- Loss: 0.1966850459575653
train-epoch-step: 97-313 -- Loss: 0.09407560527324677
train-epoch-step: 97-314 -- Loss: 0.18958166241645813
train-epoch-step: 97-315 -- Loss: 0.16224607825279236
train-epoch-step: 97-316 -- Loss: 0.14727215468883514
train-epoch-step: 97-317 -- Loss: 0.13759398460388184
train-epoch-step: 97-318 -- Loss: 0.15301388502120972
train-epoch-step: 97-319 -- Loss: 0.1623764932155609
train-epoch-step: 97-320 -- Loss: 0.11887665092945099
train-epoch-step: 97-321 -- Loss: 0.1333707571029663
train-epoch-step: 97-322 -- Loss: 0.20729532837867737
train-epoch-step: 97-323 -- Loss: 0.15649905800819397
train-epoch-step: 97-324 -- Loss: 0.24440616369247437
train-epoch-step: 97-325 -- Loss: 0.15010429918766022
train-epoch-step: 97-326 -- Loss: 0.16370302438735962
train-epoch-step: 97-327 -- Loss: 0.19719548523426056
train-epoch-step: 97-328 -- Loss: 0.1849553883075714
train-epoch-step: 97-329 -- Loss: 0.3315277397632599
train-epoch-step: 97-330 -- Loss: 0.34869641065597534
train-epoch-step: 97-331 -- Loss: 0.20169676840305328
train-epoch-step: 97-332 -- Loss: 0.09811589121818542
train-epoch-step: 97-333 -- Loss: 0.1791990101337433
train-epoch-step: 97-334 -- Loss: 0.1495129019021988
train-epoch-step: 97-335 -- Loss: 0.1704324334859848
train-epoch-step: 97-336 -- Loss: 0.14256736636161804
train-epoch-step: 97-337 -- Loss: 0.2016477882862091
train-epoch-step: 97-338 -- Loss: 0.15432576835155487
train-epoch-step: 97-339 -- Loss: 0.1377893090248108
train-epoch-step: 97-340 -- Loss: 0.20006951689720154
train-epoch-step: 97-341 -- Loss: 0.1417849063873291
train-epoch-step: 97-342 -- Loss: 0.1598605066537857
train-epoch-step: 97-343 -- Loss: 0.15328797698020935
train-epoch-step: 97-344 -- Loss: 0.16239432990550995
train-epoch-step: 97-345 -- Loss: 0.12446197122335434
train-epoch-step: 97-346 -- Loss: 0.20997029542922974
train-epoch-step: 97-347 -- Loss: 0.14748695492744446
train-epoch-step: 97-348 -- Loss: 0.20324301719665527
train-epoch-step: 97-349 -- Loss: 0.1995314061641693
train-epoch-step: 97-350 -- Loss: 0.24539873003959656
train-epoch-step: 97-351 -- Loss: 0.19086618721485138
train-epoch-step: 97-352 -- Loss: 0.12761187553405762
train-epoch-step: 97-353 -- Loss: 0.1857713758945465
train-epoch-step: 97-354 -- Loss: 0.2721824645996094
train-epoch-step: 97-355 -- Loss: 0.11324427276849747
train-epoch-step: 97-356 -- Loss: 0.11461557447910309
train-epoch-step: 97-357 -- Loss: 0.19588878750801086
train-epoch-step: 97-358 -- Loss: 0.18097463250160217
train-epoch-step: 97-359 -- Loss: 0.15139414370059967
train-epoch-step: 97-360 -- Loss: 0.11945360153913498
train-epoch-step: 97-361 -- Loss: 0.23285174369812012
train-epoch-step: 97-362 -- Loss: 0.1665477752685547
train-epoch-step: 97-363 -- Loss: 0.1092294305562973
train-epoch-step: 97-364 -- Loss: 0.17803730070590973
train-epoch-step: 97-365 -- Loss: 0.16660639643669128
train-epoch-step: 97-366 -- Loss: 0.19317486882209778
train-epoch-step: 97-367 -- Loss: 0.23679736256599426
train-epoch-step: 97-368 -- Loss: 0.19880186021327972
train-epoch-step: 97-369 -- Loss: 0.2801250219345093
train-epoch-step: 97-370 -- Loss: 0.1209174394607544
train-epoch-step: 97-371 -- Loss: 0.12370860576629639
train-epoch-step: 97-372 -- Loss: 0.1428016722202301
train-epoch-step: 97-373 -- Loss: 0.19276303052902222
train-epoch-step: 97-374 -- Loss: 0.15110693871974945
train-epoch-step: 97-375 -- Loss: 0.25934961438179016
train-epoch-step: 97-376 -- Loss: 0.1558169424533844
train-epoch-step: 97-377 -- Loss: 0.22460046410560608
train-epoch-step: 97-378 -- Loss: 0.19935885071754456
train-epoch-step: 97-379 -- Loss: 0.12071835249662399
train-epoch-step: 97-380 -- Loss: 0.08794034272432327
train-epoch-step: 97-381 -- Loss: 0.2413603961467743
train-epoch-step: 97-382 -- Loss: 0.24364332854747772
train-epoch-step: 97-383 -- Loss: 0.1706448793411255
train-epoch-step: 97-384 -- Loss: 0.2047313004732132
train-epoch-step: 97-385 -- Loss: 0.18245209753513336
train-epoch-step: 97-386 -- Loss: 0.1802782565355301
train-epoch-step: 97-387 -- Loss: 0.20114287734031677
train-epoch-step: 97-388 -- Loss: 0.17934508621692657
train-epoch-step: 97-389 -- Loss: 0.18152090907096863
train-epoch-step: 97-390 -- Loss: 0.14355048537254333
train-epoch-step: 97-391 -- Loss: 0.141401469707489
train-epoch-step: 97-392 -- Loss: 0.18606171011924744
train-epoch-step: 97-393 -- Loss: 0.152767151594162
train-epoch-step: 97-394 -- Loss: 0.21079666912555695
train-epoch-step: 97-395 -- Loss: 0.15084220468997955
train-epoch-step: 97-396 -- Loss: 0.12300905585289001
train-epoch-step: 97-397 -- Loss: 0.1267353892326355
train-epoch-step: 97-398 -- Loss: 0.20340868830680847
train-epoch-step: 97-399 -- Loss: 0.1748713105916977
train-epoch-step: 97-400 -- Loss: 0.2714504599571228
train-epoch-step: 97-401 -- Loss: 0.11846248805522919
train-epoch-step: 97-402 -- Loss: 0.24615535140037537
train-epoch-step: 97-403 -- Loss: 0.15262585878372192
train-epoch-step: 97-404 -- Loss: 0.1343541145324707
train-epoch-step: 97-405 -- Loss: 0.13751475512981415
train-epoch-step: 97-406 -- Loss: 0.17430806159973145
train-epoch-step: 97-407 -- Loss: 0.11095961928367615
train-epoch-step: 97-408 -- Loss: 0.1582859456539154
train-epoch-step: 97-409 -- Loss: 0.1706182062625885
train-epoch-step: 97-410 -- Loss: 0.17242833971977234
train-epoch-step: 97-411 -- Loss: 0.19080233573913574
train-epoch-step: 97-412 -- Loss: 0.12673267722129822
train-epoch-step: 97-413 -- Loss: 0.1381891369819641
train-epoch-step: 97-414 -- Loss: 0.12922123074531555
train-epoch-step: 97-415 -- Loss: 0.12759721279144287
train-epoch-step: 97-416 -- Loss: 0.254791796207428
train-epoch-step: 97-417 -- Loss: 0.18992768228054047
train-epoch-step: 97-418 -- Loss: 0.23241621255874634
train-epoch-step: 97-419 -- Loss: 0.1621265411376953
train-epoch-step: 97-420 -- Loss: 0.15244543552398682
train-epoch-step: 97-421 -- Loss: 0.17581698298454285
train-epoch-step: 97-422 -- Loss: 0.14474275708198547
train-epoch-step: 97-423 -- Loss: 0.16914333403110504
train-epoch-step: 97-424 -- Loss: 0.13614259660243988
train-epoch-step: 97-425 -- Loss: 0.17745257914066315
train-epoch-step: 97-426 -- Loss: 0.16867728531360626
train-epoch-step: 97-427 -- Loss: 0.11895625293254852
train-epoch-step: 97-428 -- Loss: 0.18682554364204407
train-epoch-step: 97-429 -- Loss: 0.17087122797966003
train-epoch-step: 97-430 -- Loss: 0.13647818565368652
train-epoch-step: 97-431 -- Loss: 0.1618354171514511
train-epoch-step: 97-432 -- Loss: 0.23302242159843445
train-epoch-step: 97-433 -- Loss: 0.13290081918239594
train-epoch-step: 97-434 -- Loss: 0.1256270706653595
train-epoch-step: 97-435 -- Loss: 0.15188980102539062
train-epoch-step: 97-436 -- Loss: 0.1540878266096115
train-epoch-step: 97-437 -- Loss: 0.1266496777534485
train-epoch-step: 97-438 -- Loss: 0.1590864658355713
train-epoch-step: 97-439 -- Loss: 0.2531982958316803
train-epoch-step: 97-440 -- Loss: 0.12405265867710114
train-epoch-step: 97-441 -- Loss: 0.19184638559818268
train-epoch-step: 97-442 -- Loss: 0.17130327224731445
train-epoch-step: 97-443 -- Loss: 0.15241876244544983
train-epoch-step: 97-444 -- Loss: 0.16859623789787292
train-epoch-step: 97-445 -- Loss: 0.17277918756008148
train-epoch-step: 97-446 -- Loss: 0.1484016329050064
train-epoch-step: 97-447 -- Loss: 0.18868213891983032
train-epoch-step: 97-448 -- Loss: 0.21834613382816315
train-epoch-step: 97-449 -- Loss: 0.18416942656040192
train-epoch-step: 97-450 -- Loss: 0.17332018911838531
train-epoch-step: 97-451 -- Loss: 0.1451895833015442
train-epoch-step: 97-452 -- Loss: 0.1251366287469864
train-epoch-step: 97-453 -- Loss: 0.08837604522705078
train-epoch-step: 97-454 -- Loss: 0.22485056519508362
train-epoch-step: 97-455 -- Loss: 0.11979565769433975
train-epoch-step: 97-456 -- Loss: 0.11341795325279236
train-epoch-step: 97-457 -- Loss: 0.21337032318115234
train-epoch-step: 97-458 -- Loss: 0.14244231581687927
train-epoch-step: 97-459 -- Loss: 0.20730528235435486
train-epoch-step: 97-460 -- Loss: 0.12096483260393143
train-epoch-step: 97-461 -- Loss: 0.1305030733346939
train-epoch-step: 97-462 -- Loss: 0.1490374654531479
train-epoch-step: 97-463 -- Loss: 0.13133984804153442
train-epoch-step: 97-464 -- Loss: 0.153512105345726
train-epoch-step: 97-465 -- Loss: 0.23293837904930115
train-epoch-step: 97-466 -- Loss: 0.19899550080299377
train-epoch-step: 97-467 -- Loss: 0.110219806432724
train-epoch-step: 97-468 -- Loss: 0.16480876505374908
train-epoch-step: 97-469 -- Loss: 0.20377103984355927
train-epoch-step: 97-470 -- Loss: 0.16442906856536865
train-epoch-step: 97-471 -- Loss: 0.14975722134113312
train-epoch-step: 97-472 -- Loss: 0.15585936605930328
train-epoch-step: 97-473 -- Loss: 0.14989544451236725
train-epoch-step: 97-474 -- Loss: 0.11283349245786667
train-epoch-step: 97-475 -- Loss: 0.10503360629081726
train-epoch-step: 97-476 -- Loss: 0.19895261526107788
train-epoch-step: 97-477 -- Loss: 0.19912636280059814
train-epoch-step: 97-478 -- Loss: 0.17769132554531097
train-epoch-step: 97-479 -- Loss: 0.1318046897649765
train-epoch-step: 97-480 -- Loss: 0.17383147776126862
train-epoch-step: 97-481 -- Loss: 0.2773951590061188
train-epoch-step: 97-482 -- Loss: 0.2377195805311203
train-epoch-step: 97-483 -- Loss: 0.17449326813220978
train-epoch-step: 97-484 -- Loss: 0.20586705207824707
train-epoch-step: 97-485 -- Loss: 0.1269633173942566
train-epoch-step: 97-486 -- Loss: 0.21778073906898499
train-epoch-step: 97-487 -- Loss: 0.22543683648109436
train-epoch-step: 97-488 -- Loss: 0.17941579222679138
train-epoch-step: 97-489 -- Loss: 0.21627449989318848
train-epoch-step: 97-490 -- Loss: 0.1337721347808838
train-epoch-step: 97-491 -- Loss: 0.13079124689102173
train-epoch-step: 97-492 -- Loss: 0.1331987977027893
train-epoch-step: 97-493 -- Loss: 0.20585480332374573
train-epoch-step: 97-494 -- Loss: 0.20091615617275238
train-epoch-step: 97-495 -- Loss: 0.19085589051246643
train-epoch-step: 97-496 -- Loss: 0.1399884819984436
train-epoch-step: 97-497 -- Loss: 0.1775660365819931
train-epoch-step: 97-498 -- Loss: 0.14083147048950195
train-epoch-step: 97-499 -- Loss: 0.16318590939044952
train-epoch-step: 97-500 -- Loss: 0.1491873562335968
train-epoch-step: 97-501 -- Loss: 0.2042430192232132
train-epoch-step: 97-502 -- Loss: 0.1507553905248642
train-epoch-step: 97-503 -- Loss: 0.20520275831222534
train-epoch-step: 97-504 -- Loss: 0.12257350981235504
train-epoch-step: 97-505 -- Loss: 0.16773194074630737
train-epoch-step: 97-506 -- Loss: 0.11176174134016037
train-epoch-step: 97-507 -- Loss: 0.17971712350845337
train-epoch-step: 97-508 -- Loss: 0.1692262589931488
train-epoch-step: 97-509 -- Loss: 0.16268688440322876
train-epoch-step: 97-510 -- Loss: 0.12657427787780762
train-epoch-step: 97-511 -- Loss: 0.21435317397117615
train-epoch-step: 97-512 -- Loss: 0.1742604523897171
train-epoch-step: 97-513 -- Loss: 0.17832094430923462
train-epoch-step: 97-514 -- Loss: 0.14290191233158112
train-epoch-step: 97-515 -- Loss: 0.15042085945606232
train-epoch-step: 97-516 -- Loss: 0.1696072667837143
train-epoch-step: 97-517 -- Loss: 0.16841287910938263
train-epoch-step: 97-518 -- Loss: 0.1339770257472992
train-epoch-step: 97-519 -- Loss: 0.1326134353876114
train-epoch-step: 97-520 -- Loss: 0.177832692861557
train-epoch-step: 97-521 -- Loss: 0.2202669382095337
train-epoch-step: 97-522 -- Loss: 0.17213329672813416
train-epoch-step: 97-523 -- Loss: 0.15438194572925568
train-epoch-step: 97-524 -- Loss: 0.16169680655002594
train-epoch-step: 97-525 -- Loss: 0.1865808665752411
train-epoch-step: 97-526 -- Loss: 0.12643960118293762
train-epoch-step: 97-527 -- Loss: 0.1458231508731842
train-epoch-step: 97-528 -- Loss: 0.15491242706775665
train-epoch-step: 97-529 -- Loss: 0.14967352151870728
train-epoch-step: 97-530 -- Loss: 0.16230176389217377
train-epoch-step: 97-531 -- Loss: 0.18743467330932617
train-epoch-step: 97-532 -- Loss: 0.16354462504386902
train-epoch-step: 97-533 -- Loss: 0.1709892451763153
train-epoch-step: 97-534 -- Loss: 0.12488135695457458
train-epoch-step: 97-535 -- Loss: 0.24488702416419983
train-epoch-step: 97-536 -- Loss: 0.15100392699241638
train-epoch-step: 97-537 -- Loss: 0.15682552754878998
train-epoch-step: 97-538 -- Loss: 0.10017222911119461
train-epoch-step: 97-539 -- Loss: 0.17329998314380646
train-epoch-step: 97-540 -- Loss: 0.13199517130851746
train-epoch-step: 97-541 -- Loss: 0.2019016146659851
train-epoch-step: 97-542 -- Loss: 0.2190832793712616
train-epoch-step: 97-543 -- Loss: 0.16192050278186798
train-epoch-step: 97-544 -- Loss: 0.22556518018245697
train-epoch-step: 97-545 -- Loss: 0.1884242445230484
train-epoch-step: 97-546 -- Loss: 0.20180699229240417
train-epoch-step: 97-547 -- Loss: 0.17456847429275513
train-epoch-step: 97-548 -- Loss: 0.08931367099285126
train-epoch-step: 97-549 -- Loss: 0.1465083360671997
train-epoch-step: 97-550 -- Loss: 0.19469058513641357
train-epoch-step: 97-551 -- Loss: 0.1514139175415039
train-epoch-step: 97-552 -- Loss: 0.11930644512176514
train-epoch-step: 97-553 -- Loss: 0.18552672863006592
train-epoch-step: 97-554 -- Loss: 0.1803354024887085
train-epoch-step: 97-555 -- Loss: 0.2050676941871643
train-epoch-step: 97-556 -- Loss: 0.13893239200115204
train-epoch-step: 97-557 -- Loss: 0.22105056047439575
train-epoch-step: 97-558 -- Loss: 0.2201637178659439
train-epoch-step: 97-559 -- Loss: 0.1369476616382599
train-epoch-step: 97-560 -- Loss: 0.1975269913673401
train-epoch-step: 97-561 -- Loss: 0.18000978231430054
train-epoch-step: 97-562 -- Loss: 0.15263791382312775
train-epoch-step: 97-563 -- Loss: 0.17856630682945251
train-epoch-step: 97-564 -- Loss: 0.09537501633167267
train-epoch-step: 97-565 -- Loss: 0.1753605604171753
train-epoch-step: 97-566 -- Loss: 0.14761073887348175
train-epoch-step: 97-567 -- Loss: 0.21366280317306519
train-epoch-step: 97-568 -- Loss: 0.15482044219970703
train-epoch-step: 97-569 -- Loss: 0.23610761761665344
train-epoch-step: 97-570 -- Loss: 0.1608101725578308
train-epoch-step: 97-571 -- Loss: 0.2089136838912964
train-epoch-step: 97-572 -- Loss: 0.2251664400100708
train-epoch-step: 97-573 -- Loss: 0.18960939347743988
train-epoch-step: 97-574 -- Loss: 0.23170554637908936
train-epoch-step: 97-575 -- Loss: 0.2959536015987396
train-epoch-step: 97-576 -- Loss: 0.1139717772603035
train-epoch-step: 97-577 -- Loss: 0.1615201234817505
train-epoch-step: 97-578 -- Loss: 0.2124004065990448
train-epoch-step: 97-579 -- Loss: 0.16067352890968323
train-epoch-step: 97-580 -- Loss: 0.1728629171848297
train-epoch-step: 97-581 -- Loss: 0.1367119699716568
train-epoch-step: 97-582 -- Loss: 0.20001070201396942
train-epoch-step: 97-583 -- Loss: 0.20840272307395935
train-epoch-step: 97-584 -- Loss: 0.15583054721355438
train-epoch-step: 97-585 -- Loss: 0.18632011115550995
train-epoch-step: 97-586 -- Loss: 0.2444973587989807
train-epoch-step: 97-587 -- Loss: 0.15375974774360657
train-epoch-step: 97-588 -- Loss: 0.12485174834728241
val-epoch-step: 97-589 -- Loss: 0.2179761379957199
val-epoch-step: 97-590 -- Loss: 0.14976026117801666
val-epoch-step: 97-591 -- Loss: 0.24913252890110016
val-epoch-step: 97-592 -- Loss: 0.17435768246650696
val-epoch-step: 97-593 -- Loss: 0.15028923749923706
val-epoch-step: 97-594 -- Loss: 0.39981943368911743
val-epoch-step: 97-595 -- Loss: 0.17548683285713196
val-epoch-step: 97-596 -- Loss: 0.1934037208557129
val-epoch-step: 97-597 -- Loss: 0.16887810826301575
val-epoch-step: 97-598 -- Loss: 0.1454841047525406
val-epoch-step: 97-599 -- Loss: 0.17868900299072266
val-epoch-step: 97-600 -- Loss: 0.1683546006679535
val-epoch-step: 97-601 -- Loss: 0.15073677897453308
val-epoch-step: 97-602 -- Loss: 0.13435524702072144
val-epoch-step: 97-603 -- Loss: 0.18298308551311493
val-epoch-step: 97-604 -- Loss: 0.1475013941526413
val-epoch-step: 97-605 -- Loss: 0.14542391896247864
val-epoch-step: 97-606 -- Loss: 0.2581367492675781
val-epoch-step: 97-607 -- Loss: 0.13060244917869568
val-epoch-step: 97-608 -- Loss: 0.2523983120918274
val-epoch-step: 97-609 -- Loss: 0.16599994897842407
val-epoch-step: 97-610 -- Loss: 0.17706453800201416
val-epoch-step: 97-611 -- Loss: 0.15353423357009888
val-epoch-step: 97-612 -- Loss: 0.3452249765396118
val-epoch-step: 97-613 -- Loss: 0.16962319612503052
val-epoch-step: 97-614 -- Loss: 0.16211950778961182
val-epoch-step: 97-615 -- Loss: 0.16995076835155487
val-epoch-step: 97-616 -- Loss: 0.15581578016281128
val-epoch-step: 97-617 -- Loss: 0.19022049009799957
val-epoch-step: 97-618 -- Loss: 0.18805328011512756
val-epoch-step: 97-619 -- Loss: 0.20557710528373718
val-epoch-step: 97-620 -- Loss: 0.1357460767030716
val-epoch-step: 97-621 -- Loss: 0.11867250502109528
val-epoch-step: 97-622 -- Loss: 0.14484518766403198
val-epoch-step: 97-623 -- Loss: 0.1492672562599182
val-epoch-step: 97-624 -- Loss: 0.13430234789848328
val-epoch-step: 97-625 -- Loss: 0.15140660107135773
val-epoch-step: 97-626 -- Loss: 0.14176353812217712
val-epoch-step: 97-627 -- Loss: 0.19038225710391998
val-epoch-step: 97-628 -- Loss: 0.41361764073371887
val-epoch-step: 97-629 -- Loss: 0.21936047077178955
val-epoch-step: 97-630 -- Loss: 0.34645581245422363
val-epoch-step: 97-631 -- Loss: 0.13576696813106537
val-epoch-step: 97-632 -- Loss: 0.20243744552135468
val-epoch-step: 97-633 -- Loss: 0.15979258716106415
val-epoch-step: 97-634 -- Loss: 0.14579790830612183
val-epoch-step: 97-635 -- Loss: 0.11069337278604507
val-epoch-step: 97-636 -- Loss: 0.1690603792667389
val-epoch-step: 97-637 -- Loss: 0.1785874366760254
val-epoch-step: 97-638 -- Loss: 0.16174201667308807
val-epoch-step: 97-639 -- Loss: 0.2507321834564209
val-epoch-step: 97-640 -- Loss: 0.24784716963768005
val-epoch-step: 97-641 -- Loss: 0.13711149990558624
val-epoch-step: 97-642 -- Loss: 0.1889154016971588
val-epoch-step: 97-643 -- Loss: 0.2067650556564331
val-epoch-step: 97-644 -- Loss: 0.1594691127538681
val-epoch-step: 97-645 -- Loss: 0.21595081686973572
val-epoch-step: 97-646 -- Loss: 0.13085061311721802
val-epoch-step: 97-647 -- Loss: 0.12824887037277222
val-epoch-step: 97-648 -- Loss: 0.16280381381511688
val-epoch-step: 97-649 -- Loss: 0.20742398500442505
val-epoch-step: 97-650 -- Loss: 0.2445567399263382
val-epoch-step: 97-651 -- Loss: 0.1415424346923828
val-epoch-step: 97-652 -- Loss: 0.14557884633541107
val-epoch-step: 97-653 -- Loss: 0.1933150738477707
val-epoch-step: 97-654 -- Loss: 0.11237252503633499
Epoch: 97 -- Train Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 98-0 -- Loss: 0.2177809327840805
train-epoch-step: 98-1 -- Loss: 0.13761073350906372
train-epoch-step: 98-2 -- Loss: 0.19095094501972198
train-epoch-step: 98-3 -- Loss: 0.13589556515216827
train-epoch-step: 98-4 -- Loss: 0.15156231820583344
train-epoch-step: 98-5 -- Loss: 0.1844494342803955
train-epoch-step: 98-6 -- Loss: 0.21625618636608124
train-epoch-step: 98-7 -- Loss: 0.1614413559436798
train-epoch-step: 98-8 -- Loss: 0.17686758935451508
train-epoch-step: 98-9 -- Loss: 0.2624503970146179
train-epoch-step: 98-10 -- Loss: 0.18364325165748596
train-epoch-step: 98-11 -- Loss: 0.16875673830509186
train-epoch-step: 98-12 -- Loss: 0.1425294578075409
train-epoch-step: 98-13 -- Loss: 0.1718250960111618
train-epoch-step: 98-14 -- Loss: 0.16351726651191711
train-epoch-step: 98-15 -- Loss: 0.15324857831001282
train-epoch-step: 98-16 -- Loss: 0.16447952389717102
train-epoch-step: 98-17 -- Loss: 0.2231076955795288
train-epoch-step: 98-18 -- Loss: 0.1840774267911911
train-epoch-step: 98-19 -- Loss: 0.1306312531232834
train-epoch-step: 98-20 -- Loss: 0.21020007133483887
train-epoch-step: 98-21 -- Loss: 0.23958012461662292
train-epoch-step: 98-22 -- Loss: 0.13914188742637634
train-epoch-step: 98-23 -- Loss: 0.1377536654472351
train-epoch-step: 98-24 -- Loss: 0.12037792056798935
train-epoch-step: 98-25 -- Loss: 0.2182483971118927
train-epoch-step: 98-26 -- Loss: 0.183210551738739
train-epoch-step: 98-27 -- Loss: 0.23293788731098175
train-epoch-step: 98-28 -- Loss: 0.12108451128005981
train-epoch-step: 98-29 -- Loss: 0.24041685461997986
train-epoch-step: 98-30 -- Loss: 0.10324003547430038
train-epoch-step: 98-31 -- Loss: 0.13348932564258575
train-epoch-step: 98-32 -- Loss: 0.1666058450937271
train-epoch-step: 98-33 -- Loss: 0.27398669719696045
train-epoch-step: 98-34 -- Loss: 0.16247308254241943
train-epoch-step: 98-35 -- Loss: 0.23730048537254333
train-epoch-step: 98-36 -- Loss: 0.13750723004341125
train-epoch-step: 98-37 -- Loss: 0.13289763033390045
train-epoch-step: 98-38 -- Loss: 0.16709208488464355
train-epoch-step: 98-39 -- Loss: 0.21152901649475098
train-epoch-step: 98-40 -- Loss: 0.1903708279132843
train-epoch-step: 98-41 -- Loss: 0.21239033341407776
train-epoch-step: 98-42 -- Loss: 0.13917182385921478
train-epoch-step: 98-43 -- Loss: 0.24815401434898376
train-epoch-step: 98-44 -- Loss: 0.11858275532722473
train-epoch-step: 98-45 -- Loss: 0.11324699223041534
train-epoch-step: 98-46 -- Loss: 0.1784619688987732
train-epoch-step: 98-47 -- Loss: 0.18877901136875153
train-epoch-step: 98-48 -- Loss: 0.156001478433609
train-epoch-step: 98-49 -- Loss: 0.22465503215789795
train-epoch-step: 98-50 -- Loss: 0.10750008374452591
train-epoch-step: 98-51 -- Loss: 0.17289286851882935
train-epoch-step: 98-52 -- Loss: 0.1531486064195633
train-epoch-step: 98-53 -- Loss: 0.20557720959186554
train-epoch-step: 98-54 -- Loss: 0.2851376533508301
train-epoch-step: 98-55 -- Loss: 0.1589590460062027
train-epoch-step: 98-56 -- Loss: 0.17034919559955597
train-epoch-step: 98-57 -- Loss: 0.22962212562561035
train-epoch-step: 98-58 -- Loss: 0.2745526432991028
train-epoch-step: 98-59 -- Loss: 0.2326616793870926
train-epoch-step: 98-60 -- Loss: 0.12387281656265259
train-epoch-step: 98-61 -- Loss: 0.1937178522348404
train-epoch-step: 98-62 -- Loss: 0.17636898159980774
train-epoch-step: 98-63 -- Loss: 0.12921090424060822
train-epoch-step: 98-64 -- Loss: 0.14227500557899475
train-epoch-step: 98-65 -- Loss: 0.17678238451480865
train-epoch-step: 98-66 -- Loss: 0.10817151516675949
train-epoch-step: 98-67 -- Loss: 0.12129553407430649
train-epoch-step: 98-68 -- Loss: 0.20431023836135864
train-epoch-step: 98-69 -- Loss: 0.11807366460561752
train-epoch-step: 98-70 -- Loss: 0.22253066301345825
train-epoch-step: 98-71 -- Loss: 0.25224530696868896
train-epoch-step: 98-72 -- Loss: 0.16995006799697876
train-epoch-step: 98-73 -- Loss: 0.20187059044837952
train-epoch-step: 98-74 -- Loss: 0.09076608717441559
train-epoch-step: 98-75 -- Loss: 0.12174712866544724
train-epoch-step: 98-76 -- Loss: 0.1411685049533844
train-epoch-step: 98-77 -- Loss: 0.2250286489725113
train-epoch-step: 98-78 -- Loss: 0.24972756206989288
train-epoch-step: 98-79 -- Loss: 0.18209995329380035
train-epoch-step: 98-80 -- Loss: 0.2457868456840515
train-epoch-step: 98-81 -- Loss: 0.11950364708900452
train-epoch-step: 98-82 -- Loss: 0.2428741157054901
train-epoch-step: 98-83 -- Loss: 0.17072077095508575
train-epoch-step: 98-84 -- Loss: 0.1800176501274109
train-epoch-step: 98-85 -- Loss: 0.16800183057785034
train-epoch-step: 98-86 -- Loss: 0.11783595383167267
train-epoch-step: 98-87 -- Loss: 0.209322988986969
train-epoch-step: 98-88 -- Loss: 0.1338692307472229
train-epoch-step: 98-89 -- Loss: 0.18109290301799774
train-epoch-step: 98-90 -- Loss: 0.18579712510108948
train-epoch-step: 98-91 -- Loss: 0.23261041939258575
train-epoch-step: 98-92 -- Loss: 0.14773042500019073
train-epoch-step: 98-93 -- Loss: 0.1720326840877533
train-epoch-step: 98-94 -- Loss: 0.21863479912281036
train-epoch-step: 98-95 -- Loss: 0.18822118639945984
train-epoch-step: 98-96 -- Loss: 0.2079179435968399
train-epoch-step: 98-97 -- Loss: 0.16751216351985931
train-epoch-step: 98-98 -- Loss: 0.15491428971290588
train-epoch-step: 98-99 -- Loss: 0.18702346086502075
train-epoch-step: 98-100 -- Loss: 0.18149416148662567
train-epoch-step: 98-101 -- Loss: 0.24821051955223083
train-epoch-step: 98-102 -- Loss: 0.2128477841615677
train-epoch-step: 98-103 -- Loss: 0.1769239604473114
train-epoch-step: 98-104 -- Loss: 0.14286980032920837
train-epoch-step: 98-105 -- Loss: 0.2621258795261383
train-epoch-step: 98-106 -- Loss: 0.17334142327308655
train-epoch-step: 98-107 -- Loss: 0.1811305582523346
train-epoch-step: 98-108 -- Loss: 0.18515019118785858
train-epoch-step: 98-109 -- Loss: 0.1406254917383194
train-epoch-step: 98-110 -- Loss: 0.17901936173439026
train-epoch-step: 98-111 -- Loss: 0.1861921101808548
train-epoch-step: 98-112 -- Loss: 0.16681620478630066
train-epoch-step: 98-113 -- Loss: 0.16180482506752014
train-epoch-step: 98-114 -- Loss: 0.1916586458683014
train-epoch-step: 98-115 -- Loss: 0.15636548399925232
train-epoch-step: 98-116 -- Loss: 0.13515743613243103
train-epoch-step: 98-117 -- Loss: 0.12472041696310043
train-epoch-step: 98-118 -- Loss: 0.18870234489440918
train-epoch-step: 98-119 -- Loss: 0.14838907122612
train-epoch-step: 98-120 -- Loss: 0.24058231711387634
train-epoch-step: 98-121 -- Loss: 0.23108863830566406
train-epoch-step: 98-122 -- Loss: 0.22120878100395203
train-epoch-step: 98-123 -- Loss: 0.1909170299768448
train-epoch-step: 98-124 -- Loss: 0.11735370755195618
train-epoch-step: 98-125 -- Loss: 0.15123027563095093
train-epoch-step: 98-126 -- Loss: 0.22268329560756683
train-epoch-step: 98-127 -- Loss: 0.1700688600540161
train-epoch-step: 98-128 -- Loss: 0.163554385304451
train-epoch-step: 98-129 -- Loss: 0.1402006894350052
train-epoch-step: 98-130 -- Loss: 0.19082996249198914
train-epoch-step: 98-131 -- Loss: 0.13746178150177002
train-epoch-step: 98-132 -- Loss: 0.18120048940181732
train-epoch-step: 98-133 -- Loss: 0.12787917256355286
train-epoch-step: 98-134 -- Loss: 0.19501735270023346
train-epoch-step: 98-135 -- Loss: 0.13015884160995483
train-epoch-step: 98-136 -- Loss: 0.12419140338897705
train-epoch-step: 98-137 -- Loss: 0.23826096951961517
train-epoch-step: 98-138 -- Loss: 0.24898208677768707
train-epoch-step: 98-139 -- Loss: 0.13630226254463196
train-epoch-step: 98-140 -- Loss: 0.20267155766487122
train-epoch-step: 98-141 -- Loss: 0.23342451453208923
train-epoch-step: 98-142 -- Loss: 0.20316104590892792
train-epoch-step: 98-143 -- Loss: 0.17232291400432587
train-epoch-step: 98-144 -- Loss: 0.17274509370326996
train-epoch-step: 98-145 -- Loss: 0.1421426683664322
train-epoch-step: 98-146 -- Loss: 0.17170405387878418
train-epoch-step: 98-147 -- Loss: 0.16939674317836761
train-epoch-step: 98-148 -- Loss: 0.15935155749320984
train-epoch-step: 98-149 -- Loss: 0.12194668501615524
train-epoch-step: 98-150 -- Loss: 0.18150950968265533
train-epoch-step: 98-151 -- Loss: 0.18638081848621368
train-epoch-step: 98-152 -- Loss: 0.2286016047000885
train-epoch-step: 98-153 -- Loss: 0.25394654273986816
train-epoch-step: 98-154 -- Loss: 0.12495451420545578
train-epoch-step: 98-155 -- Loss: 0.1297297477722168
train-epoch-step: 98-156 -- Loss: 0.11498755216598511
train-epoch-step: 98-157 -- Loss: 0.1632087081670761
train-epoch-step: 98-158 -- Loss: 0.16641195118427277
train-epoch-step: 98-159 -- Loss: 0.20975330471992493
train-epoch-step: 98-160 -- Loss: 0.2016286849975586
train-epoch-step: 98-161 -- Loss: 0.1938941329717636
train-epoch-step: 98-162 -- Loss: 0.210389643907547
train-epoch-step: 98-163 -- Loss: 0.18963754177093506
train-epoch-step: 98-164 -- Loss: 0.18635009229183197
train-epoch-step: 98-165 -- Loss: 0.16519302129745483
train-epoch-step: 98-166 -- Loss: 0.1140812486410141
train-epoch-step: 98-167 -- Loss: 0.11980463564395905
train-epoch-step: 98-168 -- Loss: 0.19562393426895142
train-epoch-step: 98-169 -- Loss: 0.13831762969493866
train-epoch-step: 98-170 -- Loss: 0.19839262962341309
train-epoch-step: 98-171 -- Loss: 0.13823537528514862
train-epoch-step: 98-172 -- Loss: 0.25654810667037964
train-epoch-step: 98-173 -- Loss: 0.13610009849071503
train-epoch-step: 98-174 -- Loss: 0.2427547127008438
train-epoch-step: 98-175 -- Loss: 0.18752050399780273
train-epoch-step: 98-176 -- Loss: 0.13684800267219543
train-epoch-step: 98-177 -- Loss: 0.17687980830669403
train-epoch-step: 98-178 -- Loss: 0.18169912695884705
train-epoch-step: 98-179 -- Loss: 0.15369752049446106
train-epoch-step: 98-180 -- Loss: 0.152018740773201
train-epoch-step: 98-181 -- Loss: 0.1660587638616562
train-epoch-step: 98-182 -- Loss: 0.1862695813179016
train-epoch-step: 98-183 -- Loss: 0.2665751576423645
train-epoch-step: 98-184 -- Loss: 0.13481195271015167
train-epoch-step: 98-185 -- Loss: 0.13643495738506317
train-epoch-step: 98-186 -- Loss: 0.19616982340812683
train-epoch-step: 98-187 -- Loss: 0.2073712944984436
train-epoch-step: 98-188 -- Loss: 0.17644207179546356
train-epoch-step: 98-189 -- Loss: 0.10313674807548523
train-epoch-step: 98-190 -- Loss: 0.19403067231178284
train-epoch-step: 98-191 -- Loss: 0.155051589012146
train-epoch-step: 98-192 -- Loss: 0.22738346457481384
train-epoch-step: 98-193 -- Loss: 0.21940067410469055
train-epoch-step: 98-194 -- Loss: 0.1730448603630066
train-epoch-step: 98-195 -- Loss: 0.16825686395168304
train-epoch-step: 98-196 -- Loss: 0.20305317640304565
train-epoch-step: 98-197 -- Loss: 0.1253947615623474
train-epoch-step: 98-198 -- Loss: 0.12880392372608185
train-epoch-step: 98-199 -- Loss: 0.14303280413150787
train-epoch-step: 98-200 -- Loss: 0.12229380011558533
train-epoch-step: 98-201 -- Loss: 0.19020162522792816
train-epoch-step: 98-202 -- Loss: 0.1365130990743637
train-epoch-step: 98-203 -- Loss: 0.17682936787605286
train-epoch-step: 98-204 -- Loss: 0.1312883049249649
train-epoch-step: 98-205 -- Loss: 0.18308806419372559
train-epoch-step: 98-206 -- Loss: 0.19835126399993896
train-epoch-step: 98-207 -- Loss: 0.12898117303848267
train-epoch-step: 98-208 -- Loss: 0.1847221553325653
train-epoch-step: 98-209 -- Loss: 0.14281725883483887
train-epoch-step: 98-210 -- Loss: 0.13593466579914093
train-epoch-step: 98-211 -- Loss: 0.19913235306739807
train-epoch-step: 98-212 -- Loss: 0.19235698878765106
train-epoch-step: 98-213 -- Loss: 0.1267818808555603
train-epoch-step: 98-214 -- Loss: 0.1434776782989502
train-epoch-step: 98-215 -- Loss: 0.12456537038087845
train-epoch-step: 98-216 -- Loss: 0.19108913838863373
train-epoch-step: 98-217 -- Loss: 0.21304625272750854
train-epoch-step: 98-218 -- Loss: 0.14879615604877472
train-epoch-step: 98-219 -- Loss: 0.16389679908752441
train-epoch-step: 98-220 -- Loss: 0.12602631747722626
train-epoch-step: 98-221 -- Loss: 0.19694150984287262
train-epoch-step: 98-222 -- Loss: 0.11994306743144989
train-epoch-step: 98-223 -- Loss: 0.17476893961429596
train-epoch-step: 98-224 -- Loss: 0.18604955077171326
train-epoch-step: 98-225 -- Loss: 0.2625386416912079
train-epoch-step: 98-226 -- Loss: 0.19823932647705078
train-epoch-step: 98-227 -- Loss: 0.22133594751358032
train-epoch-step: 98-228 -- Loss: 0.17306341230869293
train-epoch-step: 98-229 -- Loss: 0.17204537987709045
train-epoch-step: 98-230 -- Loss: 0.15948012471199036
train-epoch-step: 98-231 -- Loss: 0.150358185172081
train-epoch-step: 98-232 -- Loss: 0.1867092400789261
train-epoch-step: 98-233 -- Loss: 0.08491635322570801
train-epoch-step: 98-234 -- Loss: 0.16705507040023804
train-epoch-step: 98-235 -- Loss: 0.1467495560646057
train-epoch-step: 98-236 -- Loss: 0.1738857626914978
train-epoch-step: 98-237 -- Loss: 0.24827931821346283
train-epoch-step: 98-238 -- Loss: 0.15660929679870605
train-epoch-step: 98-239 -- Loss: 0.12133213877677917
train-epoch-step: 98-240 -- Loss: 0.22433780133724213
train-epoch-step: 98-241 -- Loss: 0.15588410198688507
train-epoch-step: 98-242 -- Loss: 0.21412797272205353
train-epoch-step: 98-243 -- Loss: 0.2312910109758377
train-epoch-step: 98-244 -- Loss: 0.2009611874818802
train-epoch-step: 98-245 -- Loss: 0.20076778531074524
train-epoch-step: 98-246 -- Loss: 0.21936696767807007
train-epoch-step: 98-247 -- Loss: 0.20302104949951172
train-epoch-step: 98-248 -- Loss: 0.18019026517868042
train-epoch-step: 98-249 -- Loss: 0.13447517156600952
train-epoch-step: 98-250 -- Loss: 0.19100631773471832
train-epoch-step: 98-251 -- Loss: 0.10401225835084915
train-epoch-step: 98-252 -- Loss: 0.19545623660087585
train-epoch-step: 98-253 -- Loss: 0.1627805382013321
train-epoch-step: 98-254 -- Loss: 0.20645058155059814
train-epoch-step: 98-255 -- Loss: 0.13995331525802612
train-epoch-step: 98-256 -- Loss: 0.15659099817276
train-epoch-step: 98-257 -- Loss: 0.1915682852268219
train-epoch-step: 98-258 -- Loss: 0.13933102786540985
train-epoch-step: 98-259 -- Loss: 0.11553484201431274
train-epoch-step: 98-260 -- Loss: 0.19704732298851013
train-epoch-step: 98-261 -- Loss: 0.16869691014289856
train-epoch-step: 98-262 -- Loss: 0.29290902614593506
train-epoch-step: 98-263 -- Loss: 0.19659718871116638
train-epoch-step: 98-264 -- Loss: 0.1713799685239792
train-epoch-step: 98-265 -- Loss: 0.10556138306856155
train-epoch-step: 98-266 -- Loss: 0.1481892168521881
train-epoch-step: 98-267 -- Loss: 0.12242317944765091
train-epoch-step: 98-268 -- Loss: 0.11409616470336914
train-epoch-step: 98-269 -- Loss: 0.16744235157966614
train-epoch-step: 98-270 -- Loss: 0.10690067708492279
train-epoch-step: 98-271 -- Loss: 0.14418597519397736
train-epoch-step: 98-272 -- Loss: 0.11257284134626389
train-epoch-step: 98-273 -- Loss: 0.12346155941486359
train-epoch-step: 98-274 -- Loss: 0.17652177810668945
train-epoch-step: 98-275 -- Loss: 0.18762655556201935
train-epoch-step: 98-276 -- Loss: 0.14946973323822021
train-epoch-step: 98-277 -- Loss: 0.14713291823863983
train-epoch-step: 98-278 -- Loss: 0.13148851692676544
train-epoch-step: 98-279 -- Loss: 0.13370460271835327
train-epoch-step: 98-280 -- Loss: 0.2129349261522293
train-epoch-step: 98-281 -- Loss: 0.17242741584777832
train-epoch-step: 98-282 -- Loss: 0.13870151340961456
train-epoch-step: 98-283 -- Loss: 0.11447553336620331
train-epoch-step: 98-284 -- Loss: 0.1372607946395874
train-epoch-step: 98-285 -- Loss: 0.18363113701343536
train-epoch-step: 98-286 -- Loss: 0.14640751481056213
train-epoch-step: 98-287 -- Loss: 0.19742423295974731
train-epoch-step: 98-288 -- Loss: 0.09007474780082703
train-epoch-step: 98-289 -- Loss: 0.11606355011463165
train-epoch-step: 98-290 -- Loss: 0.17751900851726532
train-epoch-step: 98-291 -- Loss: 0.1149728000164032
train-epoch-step: 98-292 -- Loss: 0.14948968589305878
train-epoch-step: 98-293 -- Loss: 0.1338684856891632
train-epoch-step: 98-294 -- Loss: 0.15772050619125366
train-epoch-step: 98-295 -- Loss: 0.26217368245124817
train-epoch-step: 98-296 -- Loss: 0.15468716621398926
train-epoch-step: 98-297 -- Loss: 0.16609588265419006
train-epoch-step: 98-298 -- Loss: 0.22554507851600647
train-epoch-step: 98-299 -- Loss: 0.14026415348052979
train-epoch-step: 98-300 -- Loss: 0.15869149565696716
train-epoch-step: 98-301 -- Loss: 0.17171774804592133
train-epoch-step: 98-302 -- Loss: 0.2073928266763687
train-epoch-step: 98-303 -- Loss: 0.20277586579322815
train-epoch-step: 98-304 -- Loss: 0.1201409325003624
train-epoch-step: 98-305 -- Loss: 0.14008761942386627
train-epoch-step: 98-306 -- Loss: 0.21630477905273438
train-epoch-step: 98-307 -- Loss: 0.15849293768405914
train-epoch-step: 98-308 -- Loss: 0.2234196662902832
train-epoch-step: 98-309 -- Loss: 0.14923834800720215
train-epoch-step: 98-310 -- Loss: 0.15727825462818146
train-epoch-step: 98-311 -- Loss: 0.1536562144756317
train-epoch-step: 98-312 -- Loss: 0.20172414183616638
train-epoch-step: 98-313 -- Loss: 0.09363318979740143
train-epoch-step: 98-314 -- Loss: 0.18615520000457764
train-epoch-step: 98-315 -- Loss: 0.16371528804302216
train-epoch-step: 98-316 -- Loss: 0.14923998713493347
train-epoch-step: 98-317 -- Loss: 0.13372443616390228
train-epoch-step: 98-318 -- Loss: 0.15089468657970428
train-epoch-step: 98-319 -- Loss: 0.17607912421226501
train-epoch-step: 98-320 -- Loss: 0.11365487426519394
train-epoch-step: 98-321 -- Loss: 0.1268886923789978
train-epoch-step: 98-322 -- Loss: 0.21021124720573425
train-epoch-step: 98-323 -- Loss: 0.1543625146150589
train-epoch-step: 98-324 -- Loss: 0.24864454567432404
train-epoch-step: 98-325 -- Loss: 0.151605024933815
train-epoch-step: 98-326 -- Loss: 0.16662520170211792
train-epoch-step: 98-327 -- Loss: 0.19837017357349396
train-epoch-step: 98-328 -- Loss: 0.19041971862316132
train-epoch-step: 98-329 -- Loss: 0.33746418356895447
train-epoch-step: 98-330 -- Loss: 0.3476957082748413
train-epoch-step: 98-331 -- Loss: 0.2029038965702057
train-epoch-step: 98-332 -- Loss: 0.09886498004198074
train-epoch-step: 98-333 -- Loss: 0.18124522268772125
train-epoch-step: 98-334 -- Loss: 0.15163350105285645
train-epoch-step: 98-335 -- Loss: 0.16738608479499817
train-epoch-step: 98-336 -- Loss: 0.1464294195175171
train-epoch-step: 98-337 -- Loss: 0.20195704698562622
train-epoch-step: 98-338 -- Loss: 0.15385401248931885
train-epoch-step: 98-339 -- Loss: 0.13607832789421082
train-epoch-step: 98-340 -- Loss: 0.19278393685817719
train-epoch-step: 98-341 -- Loss: 0.13872848451137543
train-epoch-step: 98-342 -- Loss: 0.15826217830181122
train-epoch-step: 98-343 -- Loss: 0.14962708950042725
train-epoch-step: 98-344 -- Loss: 0.16329334676265717
train-epoch-step: 98-345 -- Loss: 0.12127580493688583
train-epoch-step: 98-346 -- Loss: 0.20967306196689606
train-epoch-step: 98-347 -- Loss: 0.14796298742294312
train-epoch-step: 98-348 -- Loss: 0.20328038930892944
train-epoch-step: 98-349 -- Loss: 0.19710113108158112
train-epoch-step: 98-350 -- Loss: 0.2466500699520111
train-epoch-step: 98-351 -- Loss: 0.18705160915851593
train-epoch-step: 98-352 -- Loss: 0.11784462630748749
train-epoch-step: 98-353 -- Loss: 0.1869012862443924
train-epoch-step: 98-354 -- Loss: 0.2686774432659149
train-epoch-step: 98-355 -- Loss: 0.11566148698329926
train-epoch-step: 98-356 -- Loss: 0.11282670497894287
train-epoch-step: 98-357 -- Loss: 0.18116618692874908
train-epoch-step: 98-358 -- Loss: 0.18835528194904327
train-epoch-step: 98-359 -- Loss: 0.1317499577999115
train-epoch-step: 98-360 -- Loss: 0.12002377957105637
train-epoch-step: 98-361 -- Loss: 0.23534075915813446
train-epoch-step: 98-362 -- Loss: 0.16366079449653625
train-epoch-step: 98-363 -- Loss: 0.1048077791929245
train-epoch-step: 98-364 -- Loss: 0.18575690686702728
train-epoch-step: 98-365 -- Loss: 0.1718425750732422
train-epoch-step: 98-366 -- Loss: 0.19622470438480377
train-epoch-step: 98-367 -- Loss: 0.23298484086990356
train-epoch-step: 98-368 -- Loss: 0.19524864852428436
train-epoch-step: 98-369 -- Loss: 0.27082550525665283
train-epoch-step: 98-370 -- Loss: 0.12041706591844559
train-epoch-step: 98-371 -- Loss: 0.11776864528656006
train-epoch-step: 98-372 -- Loss: 0.14257335662841797
train-epoch-step: 98-373 -- Loss: 0.18208597600460052
train-epoch-step: 98-374 -- Loss: 0.15438628196716309
train-epoch-step: 98-375 -- Loss: 0.2634061574935913
train-epoch-step: 98-376 -- Loss: 0.14870581030845642
train-epoch-step: 98-377 -- Loss: 0.21494658291339874
train-epoch-step: 98-378 -- Loss: 0.19308021664619446
train-epoch-step: 98-379 -- Loss: 0.1195930540561676
train-epoch-step: 98-380 -- Loss: 0.08831508457660675
train-epoch-step: 98-381 -- Loss: 0.2368750274181366
train-epoch-step: 98-382 -- Loss: 0.2313803732395172
train-epoch-step: 98-383 -- Loss: 0.1727341115474701
train-epoch-step: 98-384 -- Loss: 0.2165287882089615
train-epoch-step: 98-385 -- Loss: 0.18606698513031006
train-epoch-step: 98-386 -- Loss: 0.18121059238910675
train-epoch-step: 98-387 -- Loss: 0.19589310884475708
train-epoch-step: 98-388 -- Loss: 0.17700807750225067
train-epoch-step: 98-389 -- Loss: 0.1643538922071457
train-epoch-step: 98-390 -- Loss: 0.14037321507930756
train-epoch-step: 98-391 -- Loss: 0.14034202694892883
train-epoch-step: 98-392 -- Loss: 0.17956368625164032
train-epoch-step: 98-393 -- Loss: 0.15162517130374908
train-epoch-step: 98-394 -- Loss: 0.2028656303882599
train-epoch-step: 98-395 -- Loss: 0.15114668011665344
train-epoch-step: 98-396 -- Loss: 0.12058913707733154
train-epoch-step: 98-397 -- Loss: 0.12122999131679535
train-epoch-step: 98-398 -- Loss: 0.193487748503685
train-epoch-step: 98-399 -- Loss: 0.16679608821868896
train-epoch-step: 98-400 -- Loss: 0.26902544498443604
train-epoch-step: 98-401 -- Loss: 0.11551372706890106
train-epoch-step: 98-402 -- Loss: 0.25085583329200745
train-epoch-step: 98-403 -- Loss: 0.15059269964694977
train-epoch-step: 98-404 -- Loss: 0.13587991893291473
train-epoch-step: 98-405 -- Loss: 0.13744059205055237
train-epoch-step: 98-406 -- Loss: 0.16556218266487122
train-epoch-step: 98-407 -- Loss: 0.10794233530759811
train-epoch-step: 98-408 -- Loss: 0.1579553782939911
train-epoch-step: 98-409 -- Loss: 0.16147707402706146
train-epoch-step: 98-410 -- Loss: 0.16701865196228027
train-epoch-step: 98-411 -- Loss: 0.185237318277359
train-epoch-step: 98-412 -- Loss: 0.12977251410484314
train-epoch-step: 98-413 -- Loss: 0.14065144956111908
train-epoch-step: 98-414 -- Loss: 0.12998947501182556
train-epoch-step: 98-415 -- Loss: 0.13060379028320312
train-epoch-step: 98-416 -- Loss: 0.25716152787208557
train-epoch-step: 98-417 -- Loss: 0.18657174706459045
train-epoch-step: 98-418 -- Loss: 0.21531039476394653
train-epoch-step: 98-419 -- Loss: 0.16128337383270264
train-epoch-step: 98-420 -- Loss: 0.14642105996608734
train-epoch-step: 98-421 -- Loss: 0.17143118381500244
train-epoch-step: 98-422 -- Loss: 0.14321844279766083
train-epoch-step: 98-423 -- Loss: 0.16067945957183838
train-epoch-step: 98-424 -- Loss: 0.1348598301410675
train-epoch-step: 98-425 -- Loss: 0.17756794393062592
train-epoch-step: 98-426 -- Loss: 0.16161412000656128
train-epoch-step: 98-427 -- Loss: 0.11734391748905182
train-epoch-step: 98-428 -- Loss: 0.18972332775592804
train-epoch-step: 98-429 -- Loss: 0.1713370829820633
train-epoch-step: 98-430 -- Loss: 0.14234082400798798
train-epoch-step: 98-431 -- Loss: 0.1553315818309784
train-epoch-step: 98-432 -- Loss: 0.23089824616909027
train-epoch-step: 98-433 -- Loss: 0.13507014513015747
train-epoch-step: 98-434 -- Loss: 0.12237557768821716
train-epoch-step: 98-435 -- Loss: 0.15011534094810486
train-epoch-step: 98-436 -- Loss: 0.14756077527999878
train-epoch-step: 98-437 -- Loss: 0.12515519559383392
train-epoch-step: 98-438 -- Loss: 0.16074639558792114
train-epoch-step: 98-439 -- Loss: 0.2497096061706543
train-epoch-step: 98-440 -- Loss: 0.12374389916658401
train-epoch-step: 98-441 -- Loss: 0.1960378736257553
train-epoch-step: 98-442 -- Loss: 0.17066527903079987
train-epoch-step: 98-443 -- Loss: 0.15187577903270721
train-epoch-step: 98-444 -- Loss: 0.1712181568145752
train-epoch-step: 98-445 -- Loss: 0.17816351354122162
train-epoch-step: 98-446 -- Loss: 0.1478228121995926
train-epoch-step: 98-447 -- Loss: 0.18592268228530884
train-epoch-step: 98-448 -- Loss: 0.21597279608249664
train-epoch-step: 98-449 -- Loss: 0.18529996275901794
train-epoch-step: 98-450 -- Loss: 0.17578855156898499
train-epoch-step: 98-451 -- Loss: 0.1369207799434662
train-epoch-step: 98-452 -- Loss: 0.12273593991994858
train-epoch-step: 98-453 -- Loss: 0.08636964112520218
train-epoch-step: 98-454 -- Loss: 0.21943463385105133
train-epoch-step: 98-455 -- Loss: 0.11750972270965576
train-epoch-step: 98-456 -- Loss: 0.11829724907875061
train-epoch-step: 98-457 -- Loss: 0.20756252110004425
train-epoch-step: 98-458 -- Loss: 0.16715113818645477
train-epoch-step: 98-459 -- Loss: 0.20336905121803284
train-epoch-step: 98-460 -- Loss: 0.12395867705345154
train-epoch-step: 98-461 -- Loss: 0.13054409623146057
train-epoch-step: 98-462 -- Loss: 0.1453048288822174
train-epoch-step: 98-463 -- Loss: 0.13081103563308716
train-epoch-step: 98-464 -- Loss: 0.15398940443992615
train-epoch-step: 98-465 -- Loss: 0.2347361445426941
train-epoch-step: 98-466 -- Loss: 0.19958829879760742
train-epoch-step: 98-467 -- Loss: 0.11022830009460449
train-epoch-step: 98-468 -- Loss: 0.1725252866744995
train-epoch-step: 98-469 -- Loss: 0.22297820448875427
train-epoch-step: 98-470 -- Loss: 0.16447921097278595
train-epoch-step: 98-471 -- Loss: 0.15551012754440308
train-epoch-step: 98-472 -- Loss: 0.15294845402240753
train-epoch-step: 98-473 -- Loss: 0.1536569893360138
train-epoch-step: 98-474 -- Loss: 0.11654520779848099
train-epoch-step: 98-475 -- Loss: 0.11435040831565857
train-epoch-step: 98-476 -- Loss: 0.1955728530883789
train-epoch-step: 98-477 -- Loss: 0.20122680068016052
train-epoch-step: 98-478 -- Loss: 0.18836404383182526
train-epoch-step: 98-479 -- Loss: 0.13619551062583923
train-epoch-step: 98-480 -- Loss: 0.18098628520965576
train-epoch-step: 98-481 -- Loss: 0.2747136950492859
train-epoch-step: 98-482 -- Loss: 0.25562480092048645
train-epoch-step: 98-483 -- Loss: 0.17565315961837769
train-epoch-step: 98-484 -- Loss: 0.20917537808418274
train-epoch-step: 98-485 -- Loss: 0.12597179412841797
train-epoch-step: 98-486 -- Loss: 0.23058417439460754
train-epoch-step: 98-487 -- Loss: 0.22463849186897278
train-epoch-step: 98-488 -- Loss: 0.1900658905506134
train-epoch-step: 98-489 -- Loss: 0.2146492302417755
train-epoch-step: 98-490 -- Loss: 0.1316765993833542
train-epoch-step: 98-491 -- Loss: 0.13528528809547424
train-epoch-step: 98-492 -- Loss: 0.12863634526729584
train-epoch-step: 98-493 -- Loss: 0.20078369975090027
train-epoch-step: 98-494 -- Loss: 0.19853509962558746
train-epoch-step: 98-495 -- Loss: 0.19708752632141113
train-epoch-step: 98-496 -- Loss: 0.1431562304496765
train-epoch-step: 98-497 -- Loss: 0.1762290894985199
train-epoch-step: 98-498 -- Loss: 0.1442018449306488
train-epoch-step: 98-499 -- Loss: 0.17204649746418
train-epoch-step: 98-500 -- Loss: 0.1534639298915863
train-epoch-step: 98-501 -- Loss: 0.2069767713546753
train-epoch-step: 98-502 -- Loss: 0.1485082060098648
train-epoch-step: 98-503 -- Loss: 0.21967358887195587
train-epoch-step: 98-504 -- Loss: 0.11435779929161072
train-epoch-step: 98-505 -- Loss: 0.16853894293308258
train-epoch-step: 98-506 -- Loss: 0.11574263870716095
train-epoch-step: 98-507 -- Loss: 0.1779194325208664
train-epoch-step: 98-508 -- Loss: 0.17762912809848785
train-epoch-step: 98-509 -- Loss: 0.1752316802740097
train-epoch-step: 98-510 -- Loss: 0.12443093210458755
train-epoch-step: 98-511 -- Loss: 0.21071559190750122
train-epoch-step: 98-512 -- Loss: 0.16947798430919647
train-epoch-step: 98-513 -- Loss: 0.1752457320690155
train-epoch-step: 98-514 -- Loss: 0.1433008909225464
train-epoch-step: 98-515 -- Loss: 0.1505862921476364
train-epoch-step: 98-516 -- Loss: 0.16716015338897705
train-epoch-step: 98-517 -- Loss: 0.1705179363489151
train-epoch-step: 98-518 -- Loss: 0.13655032217502594
train-epoch-step: 98-519 -- Loss: 0.13337832689285278
train-epoch-step: 98-520 -- Loss: 0.17958243191242218
train-epoch-step: 98-521 -- Loss: 0.2290683090686798
train-epoch-step: 98-522 -- Loss: 0.18505559861660004
train-epoch-step: 98-523 -- Loss: 0.1521042436361313
train-epoch-step: 98-524 -- Loss: 0.16434557735919952
train-epoch-step: 98-525 -- Loss: 0.18706263601779938
train-epoch-step: 98-526 -- Loss: 0.13028666377067566
train-epoch-step: 98-527 -- Loss: 0.1461331844329834
train-epoch-step: 98-528 -- Loss: 0.15253117680549622
train-epoch-step: 98-529 -- Loss: 0.1485913097858429
train-epoch-step: 98-530 -- Loss: 0.1644650101661682
train-epoch-step: 98-531 -- Loss: 0.19701184332370758
train-epoch-step: 98-532 -- Loss: 0.17009314894676208
train-epoch-step: 98-533 -- Loss: 0.17449262738227844
train-epoch-step: 98-534 -- Loss: 0.1277705729007721
train-epoch-step: 98-535 -- Loss: 0.2406691610813141
train-epoch-step: 98-536 -- Loss: 0.15497353672981262
train-epoch-step: 98-537 -- Loss: 0.13835828006267548
train-epoch-step: 98-538 -- Loss: 0.10168390721082687
train-epoch-step: 98-539 -- Loss: 0.20844766497612
train-epoch-step: 98-540 -- Loss: 0.13169294595718384
train-epoch-step: 98-541 -- Loss: 0.2060171216726303
train-epoch-step: 98-542 -- Loss: 0.21488423645496368
train-epoch-step: 98-543 -- Loss: 0.16091014444828033
train-epoch-step: 98-544 -- Loss: 0.22815246880054474
train-epoch-step: 98-545 -- Loss: 0.18568700551986694
train-epoch-step: 98-546 -- Loss: 0.21685683727264404
train-epoch-step: 98-547 -- Loss: 0.17823326587677002
train-epoch-step: 98-548 -- Loss: 0.08887812495231628
train-epoch-step: 98-549 -- Loss: 0.14438629150390625
train-epoch-step: 98-550 -- Loss: 0.1973767876625061
train-epoch-step: 98-551 -- Loss: 0.14697496592998505
train-epoch-step: 98-552 -- Loss: 0.11897239089012146
train-epoch-step: 98-553 -- Loss: 0.18049299716949463
train-epoch-step: 98-554 -- Loss: 0.18181900680065155
train-epoch-step: 98-555 -- Loss: 0.20330308377742767
train-epoch-step: 98-556 -- Loss: 0.13960571587085724
train-epoch-step: 98-557 -- Loss: 0.2281285524368286
train-epoch-step: 98-558 -- Loss: 0.22148942947387695
train-epoch-step: 98-559 -- Loss: 0.13211879134178162
train-epoch-step: 98-560 -- Loss: 0.21094763278961182
train-epoch-step: 98-561 -- Loss: 0.17704910039901733
train-epoch-step: 98-562 -- Loss: 0.15738485753536224
train-epoch-step: 98-563 -- Loss: 0.17671237885951996
train-epoch-step: 98-564 -- Loss: 0.09733308851718903
train-epoch-step: 98-565 -- Loss: 0.1745782196521759
train-epoch-step: 98-566 -- Loss: 0.14426906406879425
train-epoch-step: 98-567 -- Loss: 0.20670334994792938
train-epoch-step: 98-568 -- Loss: 0.15363681316375732
train-epoch-step: 98-569 -- Loss: 0.23679494857788086
train-epoch-step: 98-570 -- Loss: 0.19040565192699432
train-epoch-step: 98-571 -- Loss: 0.2055872082710266
train-epoch-step: 98-572 -- Loss: 0.23497524857521057
train-epoch-step: 98-573 -- Loss: 0.19355344772338867
train-epoch-step: 98-574 -- Loss: 0.24869336187839508
train-epoch-step: 98-575 -- Loss: 0.2849447727203369
train-epoch-step: 98-576 -- Loss: 0.11349819600582123
train-epoch-step: 98-577 -- Loss: 0.16990694403648376
train-epoch-step: 98-578 -- Loss: 0.21981124579906464
train-epoch-step: 98-579 -- Loss: 0.16549158096313477
train-epoch-step: 98-580 -- Loss: 0.16581127047538757
train-epoch-step: 98-581 -- Loss: 0.14387309551239014
train-epoch-step: 98-582 -- Loss: 0.2008201777935028
train-epoch-step: 98-583 -- Loss: 0.22687222063541412
train-epoch-step: 98-584 -- Loss: 0.16877201199531555
train-epoch-step: 98-585 -- Loss: 0.18799032270908356
train-epoch-step: 98-586 -- Loss: 0.24776069819927216
train-epoch-step: 98-587 -- Loss: 0.15710240602493286
train-epoch-step: 98-588 -- Loss: 0.1256963461637497
val-epoch-step: 98-589 -- Loss: 0.20190900564193726
val-epoch-step: 98-590 -- Loss: 0.15201318264007568
val-epoch-step: 98-591 -- Loss: 0.2337503731250763
val-epoch-step: 98-592 -- Loss: 0.17171160876750946
val-epoch-step: 98-593 -- Loss: 0.16707101464271545
val-epoch-step: 98-594 -- Loss: 0.42449501156806946
val-epoch-step: 98-595 -- Loss: 0.18190962076187134
val-epoch-step: 98-596 -- Loss: 0.20928898453712463
val-epoch-step: 98-597 -- Loss: 0.1668652892112732
val-epoch-step: 98-598 -- Loss: 0.147219717502594
val-epoch-step: 98-599 -- Loss: 0.18318814039230347
val-epoch-step: 98-600 -- Loss: 0.16428592801094055
val-epoch-step: 98-601 -- Loss: 0.14890234172344208
val-epoch-step: 98-602 -- Loss: 0.13622833788394928
val-epoch-step: 98-603 -- Loss: 0.19047892093658447
val-epoch-step: 98-604 -- Loss: 0.1525736153125763
val-epoch-step: 98-605 -- Loss: 0.14148880541324615
val-epoch-step: 98-606 -- Loss: 0.24681498110294342
val-epoch-step: 98-607 -- Loss: 0.12401586771011353
val-epoch-step: 98-608 -- Loss: 0.2463063895702362
val-epoch-step: 98-609 -- Loss: 0.16158360242843628
val-epoch-step: 98-610 -- Loss: 0.17793676257133484
val-epoch-step: 98-611 -- Loss: 0.16548751294612885
val-epoch-step: 98-612 -- Loss: 0.4766266942024231
val-epoch-step: 98-613 -- Loss: 0.17528289556503296
val-epoch-step: 98-614 -- Loss: 0.17904768884181976
val-epoch-step: 98-615 -- Loss: 0.16889312863349915
val-epoch-step: 98-616 -- Loss: 0.15392135083675385
val-epoch-step: 98-617 -- Loss: 0.18854986131191254
val-epoch-step: 98-618 -- Loss: 0.17094004154205322
val-epoch-step: 98-619 -- Loss: 0.2148292362689972
val-epoch-step: 98-620 -- Loss: 0.13685457408428192
val-epoch-step: 98-621 -- Loss: 0.12543971836566925
val-epoch-step: 98-622 -- Loss: 0.1427958607673645
val-epoch-step: 98-623 -- Loss: 0.14661772549152374
val-epoch-step: 98-624 -- Loss: 0.14128565788269043
val-epoch-step: 98-625 -- Loss: 0.1584423929452896
val-epoch-step: 98-626 -- Loss: 0.1432916671037674
val-epoch-step: 98-627 -- Loss: 0.1830088049173355
val-epoch-step: 98-628 -- Loss: 0.5875111818313599
val-epoch-step: 98-629 -- Loss: 0.19920876622200012
val-epoch-step: 98-630 -- Loss: 0.33758261799812317
val-epoch-step: 98-631 -- Loss: 0.15614531934261322
val-epoch-step: 98-632 -- Loss: 0.19410236179828644
val-epoch-step: 98-633 -- Loss: 0.14917758107185364
val-epoch-step: 98-634 -- Loss: 0.13224099576473236
val-epoch-step: 98-635 -- Loss: 0.1118517518043518
val-epoch-step: 98-636 -- Loss: 0.16765958070755005
val-epoch-step: 98-637 -- Loss: 0.17845849692821503
val-epoch-step: 98-638 -- Loss: 0.1590113341808319
val-epoch-step: 98-639 -- Loss: 0.2563975751399994
val-epoch-step: 98-640 -- Loss: 0.2590771019458771
val-epoch-step: 98-641 -- Loss: 0.12435691058635712
val-epoch-step: 98-642 -- Loss: 0.187996506690979
val-epoch-step: 98-643 -- Loss: 0.2040884792804718
val-epoch-step: 98-644 -- Loss: 0.16178163886070251
val-epoch-step: 98-645 -- Loss: 0.21844756603240967
val-epoch-step: 98-646 -- Loss: 0.13683408498764038
val-epoch-step: 98-647 -- Loss: 0.1255413442850113
val-epoch-step: 98-648 -- Loss: 0.1498389095067978
val-epoch-step: 98-649 -- Loss: 0.20492978394031525
val-epoch-step: 98-650 -- Loss: 0.24718812108039856
val-epoch-step: 98-651 -- Loss: 0.14176113903522491
val-epoch-step: 98-652 -- Loss: 0.15777820348739624
val-epoch-step: 98-653 -- Loss: 0.19776651263237
val-epoch-step: 98-654 -- Loss: 0.11784207075834274
Epoch: 98 -- Train Loss: tensor(0.1389, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 99-0 -- Loss: 0.22050730884075165
train-epoch-step: 99-1 -- Loss: 0.14001362025737762
train-epoch-step: 99-2 -- Loss: 0.19503596425056458
train-epoch-step: 99-3 -- Loss: 0.1430683135986328
train-epoch-step: 99-4 -- Loss: 0.15163114666938782
train-epoch-step: 99-5 -- Loss: 0.17897246778011322
train-epoch-step: 99-6 -- Loss: 0.2167663276195526
train-epoch-step: 99-7 -- Loss: 0.16639301180839539
train-epoch-step: 99-8 -- Loss: 0.16945505142211914
train-epoch-step: 99-9 -- Loss: 0.2266833335161209
train-epoch-step: 99-10 -- Loss: 0.18831242620944977
train-epoch-step: 99-11 -- Loss: 0.1713574230670929
train-epoch-step: 99-12 -- Loss: 0.14761726558208466
train-epoch-step: 99-13 -- Loss: 0.1703471839427948
train-epoch-step: 99-14 -- Loss: 0.1610129326581955
train-epoch-step: 99-15 -- Loss: 0.17402343451976776
train-epoch-step: 99-16 -- Loss: 0.1653335690498352
train-epoch-step: 99-17 -- Loss: 0.2157713919878006
train-epoch-step: 99-18 -- Loss: 0.1830894649028778
train-epoch-step: 99-19 -- Loss: 0.1253991276025772
train-epoch-step: 99-20 -- Loss: 0.20655778050422668
train-epoch-step: 99-21 -- Loss: 0.24650530517101288
train-epoch-step: 99-22 -- Loss: 0.13802260160446167
train-epoch-step: 99-23 -- Loss: 0.1374555230140686
train-epoch-step: 99-24 -- Loss: 0.12371556460857391
train-epoch-step: 99-25 -- Loss: 0.22053158283233643
train-epoch-step: 99-26 -- Loss: 0.183883935213089
train-epoch-step: 99-27 -- Loss: 0.2304663062095642
train-epoch-step: 99-28 -- Loss: 0.11891818791627884
train-epoch-step: 99-29 -- Loss: 0.237759530544281
train-epoch-step: 99-30 -- Loss: 0.10602640360593796
train-epoch-step: 99-31 -- Loss: 0.128886878490448
train-epoch-step: 99-32 -- Loss: 0.1682247668504715
train-epoch-step: 99-33 -- Loss: 0.26634323596954346
train-epoch-step: 99-34 -- Loss: 0.16428934037685394
train-epoch-step: 99-35 -- Loss: 0.2380775660276413
train-epoch-step: 99-36 -- Loss: 0.1364118754863739
train-epoch-step: 99-37 -- Loss: 0.13153581321239471
train-epoch-step: 99-38 -- Loss: 0.16449740529060364
train-epoch-step: 99-39 -- Loss: 0.21045279502868652
train-epoch-step: 99-40 -- Loss: 0.18601077795028687
train-epoch-step: 99-41 -- Loss: 0.2114211767911911
train-epoch-step: 99-42 -- Loss: 0.14424428343772888
train-epoch-step: 99-43 -- Loss: 0.25938254594802856
train-epoch-step: 99-44 -- Loss: 0.13180986046791077
train-epoch-step: 99-45 -- Loss: 0.11399209499359131
train-epoch-step: 99-46 -- Loss: 0.1694963276386261
train-epoch-step: 99-47 -- Loss: 0.19047246873378754
train-epoch-step: 99-48 -- Loss: 0.15095418691635132
train-epoch-step: 99-49 -- Loss: 0.22300225496292114
train-epoch-step: 99-50 -- Loss: 0.10773037374019623
train-epoch-step: 99-51 -- Loss: 0.17244137823581696
train-epoch-step: 99-52 -- Loss: 0.15543846786022186
train-epoch-step: 99-53 -- Loss: 0.2070458084344864
train-epoch-step: 99-54 -- Loss: 0.2779296338558197
train-epoch-step: 99-55 -- Loss: 0.1597636342048645
train-epoch-step: 99-56 -- Loss: 0.17031116783618927
train-epoch-step: 99-57 -- Loss: 0.23389668762683868
train-epoch-step: 99-58 -- Loss: 0.27362629771232605
train-epoch-step: 99-59 -- Loss: 0.23039579391479492
train-epoch-step: 99-60 -- Loss: 0.1280101239681244
train-epoch-step: 99-61 -- Loss: 0.21413548290729523
train-epoch-step: 99-62 -- Loss: 0.1777520775794983
train-epoch-step: 99-63 -- Loss: 0.13586381077766418
train-epoch-step: 99-64 -- Loss: 0.14308622479438782
train-epoch-step: 99-65 -- Loss: 0.1760805994272232
train-epoch-step: 99-66 -- Loss: 0.1048746183514595
train-epoch-step: 99-67 -- Loss: 0.12129028886556625
train-epoch-step: 99-68 -- Loss: 0.20195502042770386
train-epoch-step: 99-69 -- Loss: 0.11782246828079224
train-epoch-step: 99-70 -- Loss: 0.21056899428367615
train-epoch-step: 99-71 -- Loss: 0.2553017735481262
train-epoch-step: 99-72 -- Loss: 0.16242173314094543
train-epoch-step: 99-73 -- Loss: 0.20373502373695374
train-epoch-step: 99-74 -- Loss: 0.09170092642307281
train-epoch-step: 99-75 -- Loss: 0.12232967466115952
train-epoch-step: 99-76 -- Loss: 0.1465446501970291
train-epoch-step: 99-77 -- Loss: 0.22516323626041412
train-epoch-step: 99-78 -- Loss: 0.26369744539260864
train-epoch-step: 99-79 -- Loss: 0.1844257116317749
train-epoch-step: 99-80 -- Loss: 0.2372765839099884
train-epoch-step: 99-81 -- Loss: 0.11978593468666077
train-epoch-step: 99-82 -- Loss: 0.23916436731815338
train-epoch-step: 99-83 -- Loss: 0.16949987411499023
train-epoch-step: 99-84 -- Loss: 0.18624182045459747
train-epoch-step: 99-85 -- Loss: 0.16829368472099304
train-epoch-step: 99-86 -- Loss: 0.11448519676923752
train-epoch-step: 99-87 -- Loss: 0.2062353789806366
train-epoch-step: 99-88 -- Loss: 0.13387276232242584
train-epoch-step: 99-89 -- Loss: 0.18108370900154114
train-epoch-step: 99-90 -- Loss: 0.18481461703777313
train-epoch-step: 99-91 -- Loss: 0.23176953196525574
train-epoch-step: 99-92 -- Loss: 0.14855527877807617
train-epoch-step: 99-93 -- Loss: 0.1679239571094513
train-epoch-step: 99-94 -- Loss: 0.2213076949119568
train-epoch-step: 99-95 -- Loss: 0.17940010130405426
train-epoch-step: 99-96 -- Loss: 0.2023467868566513
train-epoch-step: 99-97 -- Loss: 0.1727793663740158
train-epoch-step: 99-98 -- Loss: 0.1495690941810608
train-epoch-step: 99-99 -- Loss: 0.16991545259952545
train-epoch-step: 99-100 -- Loss: 0.18097221851348877
train-epoch-step: 99-101 -- Loss: 0.2526867687702179
train-epoch-step: 99-102 -- Loss: 0.21823358535766602
train-epoch-step: 99-103 -- Loss: 0.17837169766426086
train-epoch-step: 99-104 -- Loss: 0.14315512776374817
train-epoch-step: 99-105 -- Loss: 0.26073089241981506
train-epoch-step: 99-106 -- Loss: 0.16811160743236542
train-epoch-step: 99-107 -- Loss: 0.1840285360813141
train-epoch-step: 99-108 -- Loss: 0.18259267508983612
train-epoch-step: 99-109 -- Loss: 0.1401621550321579
train-epoch-step: 99-110 -- Loss: 0.1754186898469925
train-epoch-step: 99-111 -- Loss: 0.17380540072917938
train-epoch-step: 99-112 -- Loss: 0.1637648046016693
train-epoch-step: 99-113 -- Loss: 0.15847356617450714
train-epoch-step: 99-114 -- Loss: 0.19465000927448273
train-epoch-step: 99-115 -- Loss: 0.1541423797607422
train-epoch-step: 99-116 -- Loss: 0.13072653114795685
train-epoch-step: 99-117 -- Loss: 0.12408091127872467
train-epoch-step: 99-118 -- Loss: 0.18470735847949982
train-epoch-step: 99-119 -- Loss: 0.14341898262500763
train-epoch-step: 99-120 -- Loss: 0.24160043895244598
train-epoch-step: 99-121 -- Loss: 0.22722771763801575
train-epoch-step: 99-122 -- Loss: 0.20543161034584045
train-epoch-step: 99-123 -- Loss: 0.19694790244102478
train-epoch-step: 99-124 -- Loss: 0.11644472926855087
train-epoch-step: 99-125 -- Loss: 0.1478865146636963
train-epoch-step: 99-126 -- Loss: 0.22479502856731415
train-epoch-step: 99-127 -- Loss: 0.1683417558670044
train-epoch-step: 99-128 -- Loss: 0.1660756766796112
train-epoch-step: 99-129 -- Loss: 0.13349558413028717
train-epoch-step: 99-130 -- Loss: 0.18286025524139404
train-epoch-step: 99-131 -- Loss: 0.1312321126461029
train-epoch-step: 99-132 -- Loss: 0.18331828713417053
train-epoch-step: 99-133 -- Loss: 0.10952906310558319
train-epoch-step: 99-134 -- Loss: 0.18860125541687012
train-epoch-step: 99-135 -- Loss: 0.13015665113925934
train-epoch-step: 99-136 -- Loss: 0.12010042369365692
train-epoch-step: 99-137 -- Loss: 0.2321624457836151
train-epoch-step: 99-138 -- Loss: 0.2506601810455322
train-epoch-step: 99-139 -- Loss: 0.12486091256141663
train-epoch-step: 99-140 -- Loss: 0.20486041903495789
train-epoch-step: 99-141 -- Loss: 0.2272646725177765
train-epoch-step: 99-142 -- Loss: 0.1987362653017044
train-epoch-step: 99-143 -- Loss: 0.16395124793052673
train-epoch-step: 99-144 -- Loss: 0.17777501046657562
train-epoch-step: 99-145 -- Loss: 0.14067909121513367
train-epoch-step: 99-146 -- Loss: 0.16911067068576813
train-epoch-step: 99-147 -- Loss: 0.17398470640182495
train-epoch-step: 99-148 -- Loss: 0.15599489212036133
train-epoch-step: 99-149 -- Loss: 0.11587657779455185
train-epoch-step: 99-150 -- Loss: 0.17938360571861267
train-epoch-step: 99-151 -- Loss: 0.1897018700838089
train-epoch-step: 99-152 -- Loss: 0.1868649572134018
train-epoch-step: 99-153 -- Loss: 0.2561994194984436
train-epoch-step: 99-154 -- Loss: 0.13121022284030914
train-epoch-step: 99-155 -- Loss: 0.12859132885932922
train-epoch-step: 99-156 -- Loss: 0.11434689909219742
train-epoch-step: 99-157 -- Loss: 0.16382217407226562
train-epoch-step: 99-158 -- Loss: 0.16316896677017212
train-epoch-step: 99-159 -- Loss: 0.17915676534175873
train-epoch-step: 99-160 -- Loss: 0.19829046726226807
train-epoch-step: 99-161 -- Loss: 0.19180884957313538
train-epoch-step: 99-162 -- Loss: 0.2084752917289734
train-epoch-step: 99-163 -- Loss: 0.17851442098617554
train-epoch-step: 99-164 -- Loss: 0.19081857800483704
train-epoch-step: 99-165 -- Loss: 0.15736402571201324
train-epoch-step: 99-166 -- Loss: 0.11755289882421494
train-epoch-step: 99-167 -- Loss: 0.11685718595981598
train-epoch-step: 99-168 -- Loss: 0.19862407445907593
train-epoch-step: 99-169 -- Loss: 0.13313370943069458
train-epoch-step: 99-170 -- Loss: 0.19169282913208008
train-epoch-step: 99-171 -- Loss: 0.14131835103034973
train-epoch-step: 99-172 -- Loss: 0.2543584108352661
train-epoch-step: 99-173 -- Loss: 0.12885388731956482
train-epoch-step: 99-174 -- Loss: 0.23846474289894104
train-epoch-step: 99-175 -- Loss: 0.181507870554924
train-epoch-step: 99-176 -- Loss: 0.12964840233325958
train-epoch-step: 99-177 -- Loss: 0.17551876604557037
train-epoch-step: 99-178 -- Loss: 0.17306995391845703
train-epoch-step: 99-179 -- Loss: 0.15632684528827667
train-epoch-step: 99-180 -- Loss: 0.15145228803157806
train-epoch-step: 99-181 -- Loss: 0.15917232632637024
train-epoch-step: 99-182 -- Loss: 0.17317010462284088
train-epoch-step: 99-183 -- Loss: 0.26585060358047485
train-epoch-step: 99-184 -- Loss: 0.13217060267925262
train-epoch-step: 99-185 -- Loss: 0.1368076354265213
train-epoch-step: 99-186 -- Loss: 0.1864893138408661
train-epoch-step: 99-187 -- Loss: 0.20128601789474487
train-epoch-step: 99-188 -- Loss: 0.1639992743730545
train-epoch-step: 99-189 -- Loss: 0.10169004648923874
train-epoch-step: 99-190 -- Loss: 0.1829942911863327
train-epoch-step: 99-191 -- Loss: 0.16389477252960205
train-epoch-step: 99-192 -- Loss: 0.22010783851146698
train-epoch-step: 99-193 -- Loss: 0.19989421963691711
train-epoch-step: 99-194 -- Loss: 0.1775258183479309
train-epoch-step: 99-195 -- Loss: 0.1658410280942917
train-epoch-step: 99-196 -- Loss: 0.1618209034204483
train-epoch-step: 99-197 -- Loss: 0.12240760028362274
train-epoch-step: 99-198 -- Loss: 0.12177954614162445
train-epoch-step: 99-199 -- Loss: 0.14129294455051422
train-epoch-step: 99-200 -- Loss: 0.12099483609199524
train-epoch-step: 99-201 -- Loss: 0.18569383025169373
train-epoch-step: 99-202 -- Loss: 0.13271449506282806
train-epoch-step: 99-203 -- Loss: 0.16911813616752625
train-epoch-step: 99-204 -- Loss: 0.13194982707500458
train-epoch-step: 99-205 -- Loss: 0.18261563777923584
train-epoch-step: 99-206 -- Loss: 0.19694381952285767
train-epoch-step: 99-207 -- Loss: 0.131021648645401
train-epoch-step: 99-208 -- Loss: 0.17562633752822876
train-epoch-step: 99-209 -- Loss: 0.13643166422843933
train-epoch-step: 99-210 -- Loss: 0.12852373719215393
train-epoch-step: 99-211 -- Loss: 0.19914433360099792
train-epoch-step: 99-212 -- Loss: 0.18973302841186523
train-epoch-step: 99-213 -- Loss: 0.1323268562555313
train-epoch-step: 99-214 -- Loss: 0.14095081388950348
train-epoch-step: 99-215 -- Loss: 0.12103360891342163
train-epoch-step: 99-216 -- Loss: 0.1945904791355133
train-epoch-step: 99-217 -- Loss: 0.2058774083852768
train-epoch-step: 99-218 -- Loss: 0.1397024542093277
train-epoch-step: 99-219 -- Loss: 0.16103576123714447
train-epoch-step: 99-220 -- Loss: 0.1249321773648262
train-epoch-step: 99-221 -- Loss: 0.19833651185035706
train-epoch-step: 99-222 -- Loss: 0.11277713626623154
train-epoch-step: 99-223 -- Loss: 0.16505581140518188
train-epoch-step: 99-224 -- Loss: 0.1832887977361679
train-epoch-step: 99-225 -- Loss: 0.26763200759887695
train-epoch-step: 99-226 -- Loss: 0.19938866794109344
train-epoch-step: 99-227 -- Loss: 0.2161787897348404
train-epoch-step: 99-228 -- Loss: 0.16988365352153778
train-epoch-step: 99-229 -- Loss: 0.1728006899356842
train-epoch-step: 99-230 -- Loss: 0.15946215391159058
train-epoch-step: 99-231 -- Loss: 0.1482149064540863
train-epoch-step: 99-232 -- Loss: 0.1788344383239746
train-epoch-step: 99-233 -- Loss: 0.0813167616724968
train-epoch-step: 99-234 -- Loss: 0.16958948969841003
train-epoch-step: 99-235 -- Loss: 0.1365932673215866
train-epoch-step: 99-236 -- Loss: 0.17538180947303772
train-epoch-step: 99-237 -- Loss: 0.23523782193660736
train-epoch-step: 99-238 -- Loss: 0.15305499732494354
train-epoch-step: 99-239 -- Loss: 0.12286315858364105
train-epoch-step: 99-240 -- Loss: 0.22316987812519073
train-epoch-step: 99-241 -- Loss: 0.14992867410182953
train-epoch-step: 99-242 -- Loss: 0.2123088538646698
train-epoch-step: 99-243 -- Loss: 0.22875922918319702
train-epoch-step: 99-244 -- Loss: 0.199299156665802
train-epoch-step: 99-245 -- Loss: 0.201381653547287
train-epoch-step: 99-246 -- Loss: 0.20936404168605804
train-epoch-step: 99-247 -- Loss: 0.2030038833618164
train-epoch-step: 99-248 -- Loss: 0.18282538652420044
train-epoch-step: 99-249 -- Loss: 0.13365644216537476
train-epoch-step: 99-250 -- Loss: 0.1881825476884842
train-epoch-step: 99-251 -- Loss: 0.10267111659049988
train-epoch-step: 99-252 -- Loss: 0.182940274477005
train-epoch-step: 99-253 -- Loss: 0.13156847655773163
train-epoch-step: 99-254 -- Loss: 0.20572130382061005
train-epoch-step: 99-255 -- Loss: 0.14031976461410522
train-epoch-step: 99-256 -- Loss: 0.182352215051651
train-epoch-step: 99-257 -- Loss: 0.18647365272045135
train-epoch-step: 99-258 -- Loss: 0.13857151567935944
train-epoch-step: 99-259 -- Loss: 0.11105971038341522
train-epoch-step: 99-260 -- Loss: 0.19152849912643433
train-epoch-step: 99-261 -- Loss: 0.16735416650772095
train-epoch-step: 99-262 -- Loss: 0.28838467597961426
train-epoch-step: 99-263 -- Loss: 0.19776248931884766
train-epoch-step: 99-264 -- Loss: 0.16958291828632355
train-epoch-step: 99-265 -- Loss: 0.10388637334108353
train-epoch-step: 99-266 -- Loss: 0.14849647879600525
train-epoch-step: 99-267 -- Loss: 0.12586750090122223
train-epoch-step: 99-268 -- Loss: 0.11429131776094437
train-epoch-step: 99-269 -- Loss: 0.16710689663887024
train-epoch-step: 99-270 -- Loss: 0.1169615387916565
train-epoch-step: 99-271 -- Loss: 0.14091210067272186
train-epoch-step: 99-272 -- Loss: 0.11260285973548889
train-epoch-step: 99-273 -- Loss: 0.12598520517349243
train-epoch-step: 99-274 -- Loss: 0.17852604389190674
train-epoch-step: 99-275 -- Loss: 0.18649937212467194
train-epoch-step: 99-276 -- Loss: 0.15640641748905182
train-epoch-step: 99-277 -- Loss: 0.1476665437221527
train-epoch-step: 99-278 -- Loss: 0.13246208429336548
train-epoch-step: 99-279 -- Loss: 0.1323639452457428
train-epoch-step: 99-280 -- Loss: 0.20677730441093445
train-epoch-step: 99-281 -- Loss: 0.17247939109802246
train-epoch-step: 99-282 -- Loss: 0.13363024592399597
train-epoch-step: 99-283 -- Loss: 0.11075077950954437
train-epoch-step: 99-284 -- Loss: 0.1451077163219452
train-epoch-step: 99-285 -- Loss: 0.18805377185344696
train-epoch-step: 99-286 -- Loss: 0.15038339793682098
train-epoch-step: 99-287 -- Loss: 0.19124695658683777
train-epoch-step: 99-288 -- Loss: 0.09574268758296967
train-epoch-step: 99-289 -- Loss: 0.11624907702207565
train-epoch-step: 99-290 -- Loss: 0.17767049372196198
train-epoch-step: 99-291 -- Loss: 0.1180061548948288
train-epoch-step: 99-292 -- Loss: 0.15706530213356018
train-epoch-step: 99-293 -- Loss: 0.13721095025539398
train-epoch-step: 99-294 -- Loss: 0.1591915786266327
train-epoch-step: 99-295 -- Loss: 0.3842507004737854
train-epoch-step: 99-296 -- Loss: 0.16953136026859283
train-epoch-step: 99-297 -- Loss: 0.17129716277122498
train-epoch-step: 99-298 -- Loss: 0.24009689688682556
train-epoch-step: 99-299 -- Loss: 0.21385467052459717
train-epoch-step: 99-300 -- Loss: 0.17496871948242188
train-epoch-step: 99-301 -- Loss: 0.16898833215236664
train-epoch-step: 99-302 -- Loss: 0.2334606945514679
train-epoch-step: 99-303 -- Loss: 0.1980554610490799
train-epoch-step: 99-304 -- Loss: 0.16444990038871765
train-epoch-step: 99-305 -- Loss: 0.13977114856243134
train-epoch-step: 99-306 -- Loss: 0.2310584932565689
train-epoch-step: 99-307 -- Loss: 0.16497942805290222
train-epoch-step: 99-308 -- Loss: 0.23359240591526031
train-epoch-step: 99-309 -- Loss: 0.15703192353248596
train-epoch-step: 99-310 -- Loss: 0.16628733277320862
train-epoch-step: 99-311 -- Loss: 0.16162553429603577
train-epoch-step: 99-312 -- Loss: 0.22228389978408813
train-epoch-step: 99-313 -- Loss: 0.10431652516126633
train-epoch-step: 99-314 -- Loss: 0.19020390510559082
train-epoch-step: 99-315 -- Loss: 0.1742083877325058
train-epoch-step: 99-316 -- Loss: 0.1518443524837494
train-epoch-step: 99-317 -- Loss: 0.14381302893161774
train-epoch-step: 99-318 -- Loss: 0.16341999173164368
train-epoch-step: 99-319 -- Loss: 0.17455416917800903
train-epoch-step: 99-320 -- Loss: 0.11726216226816177
train-epoch-step: 99-321 -- Loss: 0.13451151549816132
train-epoch-step: 99-322 -- Loss: 0.22730378806591034
train-epoch-step: 99-323 -- Loss: 0.15921849012374878
train-epoch-step: 99-324 -- Loss: 0.2482326775789261
train-epoch-step: 99-325 -- Loss: 0.1558227241039276
train-epoch-step: 99-326 -- Loss: 0.1765960305929184
train-epoch-step: 99-327 -- Loss: 0.20918071269989014
train-epoch-step: 99-328 -- Loss: 0.19249802827835083
train-epoch-step: 99-329 -- Loss: 0.34026843309402466
train-epoch-step: 99-330 -- Loss: 0.3542167544364929
train-epoch-step: 99-331 -- Loss: 0.20477917790412903
train-epoch-step: 99-332 -- Loss: 0.09625500440597534
train-epoch-step: 99-333 -- Loss: 0.1831735074520111
train-epoch-step: 99-334 -- Loss: 0.15084342658519745
train-epoch-step: 99-335 -- Loss: 0.17057420313358307
train-epoch-step: 99-336 -- Loss: 0.1533934623003006
train-epoch-step: 99-337 -- Loss: 0.1984005570411682
train-epoch-step: 99-338 -- Loss: 0.15949924290180206
train-epoch-step: 99-339 -- Loss: 0.14212806522846222
train-epoch-step: 99-340 -- Loss: 0.19432982802391052
train-epoch-step: 99-341 -- Loss: 0.14096930623054504
train-epoch-step: 99-342 -- Loss: 0.16212156414985657
train-epoch-step: 99-343 -- Loss: 0.14903120696544647
train-epoch-step: 99-344 -- Loss: 0.17035210132598877
train-epoch-step: 99-345 -- Loss: 0.13063980638980865
train-epoch-step: 99-346 -- Loss: 0.20808759331703186
train-epoch-step: 99-347 -- Loss: 0.14895525574684143
train-epoch-step: 99-348 -- Loss: 0.19980299472808838
train-epoch-step: 99-349 -- Loss: 0.19883857667446136
train-epoch-step: 99-350 -- Loss: 0.2875784635543823
train-epoch-step: 99-351 -- Loss: 0.19413842260837555
train-epoch-step: 99-352 -- Loss: 0.12713807821273804
train-epoch-step: 99-353 -- Loss: 0.18871809542179108
train-epoch-step: 99-354 -- Loss: 0.286904513835907
train-epoch-step: 99-355 -- Loss: 0.11627242714166641
train-epoch-step: 99-356 -- Loss: 0.11919329315423965
train-epoch-step: 99-357 -- Loss: 0.1901337206363678
train-epoch-step: 99-358 -- Loss: 0.18761324882507324
train-epoch-step: 99-359 -- Loss: 0.1409825086593628
train-epoch-step: 99-360 -- Loss: 0.12067350745201111
train-epoch-step: 99-361 -- Loss: 0.2305026352405548
train-epoch-step: 99-362 -- Loss: 0.16677165031433105
train-epoch-step: 99-363 -- Loss: 0.1070423275232315
train-epoch-step: 99-364 -- Loss: 0.17780792713165283
train-epoch-step: 99-365 -- Loss: 0.16440297663211823
train-epoch-step: 99-366 -- Loss: 0.196510449051857
train-epoch-step: 99-367 -- Loss: 0.22993236780166626
train-epoch-step: 99-368 -- Loss: 0.20015022158622742
train-epoch-step: 99-369 -- Loss: 0.2740771174430847
train-epoch-step: 99-370 -- Loss: 0.11980230361223221
train-epoch-step: 99-371 -- Loss: 0.11826889216899872
train-epoch-step: 99-372 -- Loss: 0.1426948755979538
train-epoch-step: 99-373 -- Loss: 0.1907249093055725
train-epoch-step: 99-374 -- Loss: 0.15148864686489105
train-epoch-step: 99-375 -- Loss: 0.25804537534713745
train-epoch-step: 99-376 -- Loss: 0.1669842004776001
train-epoch-step: 99-377 -- Loss: 0.22623950242996216
train-epoch-step: 99-378 -- Loss: 0.20097440481185913
train-epoch-step: 99-379 -- Loss: 0.11517150700092316
train-epoch-step: 99-380 -- Loss: 0.09117338061332703
train-epoch-step: 99-381 -- Loss: 0.23616796731948853
train-epoch-step: 99-382 -- Loss: 0.2194431871175766
train-epoch-step: 99-383 -- Loss: 0.17885108292102814
train-epoch-step: 99-384 -- Loss: 0.2064622938632965
train-epoch-step: 99-385 -- Loss: 0.18545100092887878
train-epoch-step: 99-386 -- Loss: 0.20081540942192078
train-epoch-step: 99-387 -- Loss: 0.20307305455207825
train-epoch-step: 99-388 -- Loss: 0.19372713565826416
train-epoch-step: 99-389 -- Loss: 0.16474680602550507
train-epoch-step: 99-390 -- Loss: 0.14763623476028442
train-epoch-step: 99-391 -- Loss: 0.15462467074394226
train-epoch-step: 99-392 -- Loss: 0.18112027645111084
train-epoch-step: 99-393 -- Loss: 0.152618870139122
train-epoch-step: 99-394 -- Loss: 0.19698330760002136
train-epoch-step: 99-395 -- Loss: 0.15899032354354858
train-epoch-step: 99-396 -- Loss: 0.12395737320184708
train-epoch-step: 99-397 -- Loss: 0.12457824498414993
train-epoch-step: 99-398 -- Loss: 0.19677437841892242
train-epoch-step: 99-399 -- Loss: 0.1711125373840332
train-epoch-step: 99-400 -- Loss: 0.2834509015083313
train-epoch-step: 99-401 -- Loss: 0.11908522993326187
train-epoch-step: 99-402 -- Loss: 0.25092393159866333
train-epoch-step: 99-403 -- Loss: 0.15235646069049835
train-epoch-step: 99-404 -- Loss: 0.1391277313232422
train-epoch-step: 99-405 -- Loss: 0.13859888911247253
train-epoch-step: 99-406 -- Loss: 0.16710536181926727
train-epoch-step: 99-407 -- Loss: 0.10983250290155411
train-epoch-step: 99-408 -- Loss: 0.1635504812002182
train-epoch-step: 99-409 -- Loss: 0.17716707289218903
train-epoch-step: 99-410 -- Loss: 0.17057450115680695
train-epoch-step: 99-411 -- Loss: 0.18845486640930176
train-epoch-step: 99-412 -- Loss: 0.12515142560005188
train-epoch-step: 99-413 -- Loss: 0.1437714695930481
train-epoch-step: 99-414 -- Loss: 0.12921665608882904
train-epoch-step: 99-415 -- Loss: 0.13413654267787933
train-epoch-step: 99-416 -- Loss: 0.2629550099372864
train-epoch-step: 99-417 -- Loss: 0.1950012445449829
train-epoch-step: 99-418 -- Loss: 0.22033259272575378
train-epoch-step: 99-419 -- Loss: 0.1650797426700592
train-epoch-step: 99-420 -- Loss: 0.1511700451374054
train-epoch-step: 99-421 -- Loss: 0.17971906065940857
train-epoch-step: 99-422 -- Loss: 0.14254522323608398
train-epoch-step: 99-423 -- Loss: 0.16460512578487396
train-epoch-step: 99-424 -- Loss: 0.13648931682109833
train-epoch-step: 99-425 -- Loss: 0.18032635748386383
train-epoch-step: 99-426 -- Loss: 0.1634180098772049
train-epoch-step: 99-427 -- Loss: 0.11737194657325745
train-epoch-step: 99-428 -- Loss: 0.18416930735111237
train-epoch-step: 99-429 -- Loss: 0.17195194959640503
train-epoch-step: 99-430 -- Loss: 0.14512094855308533
train-epoch-step: 99-431 -- Loss: 0.15726175904273987
train-epoch-step: 99-432 -- Loss: 0.23627951741218567
train-epoch-step: 99-433 -- Loss: 0.13523569703102112
train-epoch-step: 99-434 -- Loss: 0.12454075366258621
train-epoch-step: 99-435 -- Loss: 0.15437652170658112
train-epoch-step: 99-436 -- Loss: 0.15329134464263916
train-epoch-step: 99-437 -- Loss: 0.1265452355146408
train-epoch-step: 99-438 -- Loss: 0.1608191579580307
train-epoch-step: 99-439 -- Loss: 0.25674062967300415
train-epoch-step: 99-440 -- Loss: 0.12791778147220612
train-epoch-step: 99-441 -- Loss: 0.19583724439144135
train-epoch-step: 99-442 -- Loss: 0.17290633916854858
train-epoch-step: 99-443 -- Loss: 0.15865744650363922
train-epoch-step: 99-444 -- Loss: 0.1672157347202301
train-epoch-step: 99-445 -- Loss: 0.17394091188907623
train-epoch-step: 99-446 -- Loss: 0.14510849118232727
train-epoch-step: 99-447 -- Loss: 0.18710003793239594
train-epoch-step: 99-448 -- Loss: 0.2193179726600647
train-epoch-step: 99-449 -- Loss: 0.1848091334104538
train-epoch-step: 99-450 -- Loss: 0.17423759400844574
train-epoch-step: 99-451 -- Loss: 0.13726122677326202
train-epoch-step: 99-452 -- Loss: 0.12436439096927643
train-epoch-step: 99-453 -- Loss: 0.09259197860956192
train-epoch-step: 99-454 -- Loss: 0.220271497964859
train-epoch-step: 99-455 -- Loss: 0.12288577854633331
train-epoch-step: 99-456 -- Loss: 0.1131126880645752
train-epoch-step: 99-457 -- Loss: 0.20579469203948975
train-epoch-step: 99-458 -- Loss: 0.14704132080078125
train-epoch-step: 99-459 -- Loss: 0.20596498250961304
train-epoch-step: 99-460 -- Loss: 0.12088344991207123
train-epoch-step: 99-461 -- Loss: 0.12912651896476746
train-epoch-step: 99-462 -- Loss: 0.15452030301094055
train-epoch-step: 99-463 -- Loss: 0.1340678483247757
train-epoch-step: 99-464 -- Loss: 0.15586444735527039
train-epoch-step: 99-465 -- Loss: 0.23026907444000244
train-epoch-step: 99-466 -- Loss: 0.2002096027135849
train-epoch-step: 99-467 -- Loss: 0.11258821189403534
train-epoch-step: 99-468 -- Loss: 0.1570996791124344
train-epoch-step: 99-469 -- Loss: 0.20216946303844452
train-epoch-step: 99-470 -- Loss: 0.1625135838985443
train-epoch-step: 99-471 -- Loss: 0.15096674859523773
train-epoch-step: 99-472 -- Loss: 0.15589386224746704
train-epoch-step: 99-473 -- Loss: 0.1540963500738144
train-epoch-step: 99-474 -- Loss: 0.11225676536560059
train-epoch-step: 99-475 -- Loss: 0.1081867665052414
train-epoch-step: 99-476 -- Loss: 0.1918666660785675
train-epoch-step: 99-477 -- Loss: 0.19245468080043793
train-epoch-step: 99-478 -- Loss: 0.18234947323799133
train-epoch-step: 99-479 -- Loss: 0.1342601478099823
train-epoch-step: 99-480 -- Loss: 0.18997733294963837
train-epoch-step: 99-481 -- Loss: 0.27435553073883057
train-epoch-step: 99-482 -- Loss: 0.2455567717552185
train-epoch-step: 99-483 -- Loss: 0.17596450448036194
train-epoch-step: 99-484 -- Loss: 0.20680296421051025
train-epoch-step: 99-485 -- Loss: 0.12314830720424652
train-epoch-step: 99-486 -- Loss: 0.22193171083927155
train-epoch-step: 99-487 -- Loss: 0.2290978878736496
train-epoch-step: 99-488 -- Loss: 0.18059727549552917
train-epoch-step: 99-489 -- Loss: 0.21383923292160034
train-epoch-step: 99-490 -- Loss: 0.12856531143188477
train-epoch-step: 99-491 -- Loss: 0.13261951506137848
train-epoch-step: 99-492 -- Loss: 0.1257786601781845
train-epoch-step: 99-493 -- Loss: 0.1887473464012146
train-epoch-step: 99-494 -- Loss: 0.20326969027519226
train-epoch-step: 99-495 -- Loss: 0.19491945207118988
train-epoch-step: 99-496 -- Loss: 0.1417333334684372
train-epoch-step: 99-497 -- Loss: 0.1871221661567688
train-epoch-step: 99-498 -- Loss: 0.1443329006433487
train-epoch-step: 99-499 -- Loss: 0.16082696616649628
train-epoch-step: 99-500 -- Loss: 0.14767487347126007
train-epoch-step: 99-501 -- Loss: 0.21995532512664795
train-epoch-step: 99-502 -- Loss: 0.14681997895240784
train-epoch-step: 99-503 -- Loss: 0.20764927566051483
train-epoch-step: 99-504 -- Loss: 0.11992084980010986
train-epoch-step: 99-505 -- Loss: 0.16688206791877747
train-epoch-step: 99-506 -- Loss: 0.11249759048223495
train-epoch-step: 99-507 -- Loss: 0.1716523915529251
train-epoch-step: 99-508 -- Loss: 0.1659967601299286
train-epoch-step: 99-509 -- Loss: 0.16154682636260986
train-epoch-step: 99-510 -- Loss: 0.12585896253585815
train-epoch-step: 99-511 -- Loss: 0.20785990357398987
train-epoch-step: 99-512 -- Loss: 0.17408816516399384
train-epoch-step: 99-513 -- Loss: 0.17345508933067322
train-epoch-step: 99-514 -- Loss: 0.13884755969047546
train-epoch-step: 99-515 -- Loss: 0.15196946263313293
train-epoch-step: 99-516 -- Loss: 0.1713925302028656
train-epoch-step: 99-517 -- Loss: 0.17055994272232056
train-epoch-step: 99-518 -- Loss: 0.13626667857170105
train-epoch-step: 99-519 -- Loss: 0.13051298260688782
train-epoch-step: 99-520 -- Loss: 0.17942920327186584
train-epoch-step: 99-521 -- Loss: 0.22242864966392517
train-epoch-step: 99-522 -- Loss: 0.16257551312446594
train-epoch-step: 99-523 -- Loss: 0.15814384818077087
train-epoch-step: 99-524 -- Loss: 0.15977221727371216
train-epoch-step: 99-525 -- Loss: 0.18318849802017212
train-epoch-step: 99-526 -- Loss: 0.12463198602199554
train-epoch-step: 99-527 -- Loss: 0.1472395807504654
train-epoch-step: 99-528 -- Loss: 0.15029561519622803
train-epoch-step: 99-529 -- Loss: 0.15388965606689453
train-epoch-step: 99-530 -- Loss: 0.17602011561393738
train-epoch-step: 99-531 -- Loss: 0.19071224331855774
train-epoch-step: 99-532 -- Loss: 0.16426274180412292
train-epoch-step: 99-533 -- Loss: 0.17247259616851807
train-epoch-step: 99-534 -- Loss: 0.1252058446407318
train-epoch-step: 99-535 -- Loss: 0.24432708323001862
train-epoch-step: 99-536 -- Loss: 0.1525162160396576
train-epoch-step: 99-537 -- Loss: 0.1384914517402649
train-epoch-step: 99-538 -- Loss: 0.09842432290315628
train-epoch-step: 99-539 -- Loss: 0.1770799160003662
train-epoch-step: 99-540 -- Loss: 0.1292608082294464
train-epoch-step: 99-541 -- Loss: 0.19840049743652344
train-epoch-step: 99-542 -- Loss: 0.22647616267204285
train-epoch-step: 99-543 -- Loss: 0.1601397693157196
train-epoch-step: 99-544 -- Loss: 0.2197980284690857
train-epoch-step: 99-545 -- Loss: 0.19499298930168152
train-epoch-step: 99-546 -- Loss: 0.2072179615497589
train-epoch-step: 99-547 -- Loss: 0.1862463355064392
train-epoch-step: 99-548 -- Loss: 0.08791793882846832
train-epoch-step: 99-549 -- Loss: 0.14207077026367188
train-epoch-step: 99-550 -- Loss: 0.19833536446094513
train-epoch-step: 99-551 -- Loss: 0.148365780711174
train-epoch-step: 99-552 -- Loss: 0.12707504630088806
train-epoch-step: 99-553 -- Loss: 0.17932091653347015
train-epoch-step: 99-554 -- Loss: 0.17768563330173492
train-epoch-step: 99-555 -- Loss: 0.20822924375534058
train-epoch-step: 99-556 -- Loss: 0.14784212410449982
train-epoch-step: 99-557 -- Loss: 0.22063209116458893
train-epoch-step: 99-558 -- Loss: 0.22199958562850952
train-epoch-step: 99-559 -- Loss: 0.13387537002563477
train-epoch-step: 99-560 -- Loss: 0.19408442080020905
train-epoch-step: 99-561 -- Loss: 0.18447990715503693
train-epoch-step: 99-562 -- Loss: 0.15823879837989807
train-epoch-step: 99-563 -- Loss: 0.17512597143650055
train-epoch-step: 99-564 -- Loss: 0.09576685726642609
train-epoch-step: 99-565 -- Loss: 0.17167973518371582
train-epoch-step: 99-566 -- Loss: 0.14632682502269745
train-epoch-step: 99-567 -- Loss: 0.20497117936611176
train-epoch-step: 99-568 -- Loss: 0.151239812374115
train-epoch-step: 99-569 -- Loss: 0.23555810749530792
train-epoch-step: 99-570 -- Loss: 0.16465741395950317
train-epoch-step: 99-571 -- Loss: 0.20200897753238678
train-epoch-step: 99-572 -- Loss: 0.23014496266841888
train-epoch-step: 99-573 -- Loss: 0.19631457328796387
train-epoch-step: 99-574 -- Loss: 0.22827407717704773
train-epoch-step: 99-575 -- Loss: 0.283056378364563
train-epoch-step: 99-576 -- Loss: 0.11279348284006119
train-epoch-step: 99-577 -- Loss: 0.16481778025627136
train-epoch-step: 99-578 -- Loss: 0.21030199527740479
train-epoch-step: 99-579 -- Loss: 0.15797016024589539
train-epoch-step: 99-580 -- Loss: 0.1654144674539566
train-epoch-step: 99-581 -- Loss: 0.1416756510734558
train-epoch-step: 99-582 -- Loss: 0.20294824242591858
train-epoch-step: 99-583 -- Loss: 0.2068791538476944
train-epoch-step: 99-584 -- Loss: 0.15444259345531464
train-epoch-step: 99-585 -- Loss: 0.18805915117263794
train-epoch-step: 99-586 -- Loss: 0.2476256638765335
train-epoch-step: 99-587 -- Loss: 0.15433387458324432
train-epoch-step: 99-588 -- Loss: 0.12264199554920197
val-epoch-step: 99-589 -- Loss: 0.21291489899158478
val-epoch-step: 99-590 -- Loss: 0.14882074296474457
val-epoch-step: 99-591 -- Loss: 0.237654447555542
val-epoch-step: 99-592 -- Loss: 0.16753710806369781
val-epoch-step: 99-593 -- Loss: 0.17751967906951904
val-epoch-step: 99-594 -- Loss: 0.3437651991844177
val-epoch-step: 99-595 -- Loss: 0.18349239230155945
val-epoch-step: 99-596 -- Loss: 0.18660296499729156
val-epoch-step: 99-597 -- Loss: 0.1658991426229477
val-epoch-step: 99-598 -- Loss: 0.1455772966146469
val-epoch-step: 99-599 -- Loss: 0.17606863379478455
val-epoch-step: 99-600 -- Loss: 0.16570600867271423
val-epoch-step: 99-601 -- Loss: 0.15031327307224274
val-epoch-step: 99-602 -- Loss: 0.13433991372585297
val-epoch-step: 99-603 -- Loss: 0.1950453817844391
val-epoch-step: 99-604 -- Loss: 0.143695667386055
val-epoch-step: 99-605 -- Loss: 0.14671778678894043
val-epoch-step: 99-606 -- Loss: 0.26492029428482056
val-epoch-step: 99-607 -- Loss: 0.11982603371143341
val-epoch-step: 99-608 -- Loss: 0.2439582347869873
val-epoch-step: 99-609 -- Loss: 0.17342180013656616
val-epoch-step: 99-610 -- Loss: 0.17537946999073029
val-epoch-step: 99-611 -- Loss: 0.1516445428133011
val-epoch-step: 99-612 -- Loss: 0.38534781336784363
val-epoch-step: 99-613 -- Loss: 0.17059040069580078
val-epoch-step: 99-614 -- Loss: 0.16417498886585236
val-epoch-step: 99-615 -- Loss: 0.16968367993831635
val-epoch-step: 99-616 -- Loss: 0.13983458280563354
val-epoch-step: 99-617 -- Loss: 0.2001173198223114
val-epoch-step: 99-618 -- Loss: 0.1732826828956604
val-epoch-step: 99-619 -- Loss: 0.20904450118541718
val-epoch-step: 99-620 -- Loss: 0.13068191707134247
val-epoch-step: 99-621 -- Loss: 0.12528271973133087
val-epoch-step: 99-622 -- Loss: 0.14261755347251892
val-epoch-step: 99-623 -- Loss: 0.14859573543071747
val-epoch-step: 99-624 -- Loss: 0.1400621384382248
val-epoch-step: 99-625 -- Loss: 0.1516653150320053
val-epoch-step: 99-626 -- Loss: 0.14521868526935577
val-epoch-step: 99-627 -- Loss: 0.17982272803783417
val-epoch-step: 99-628 -- Loss: 0.4698171317577362
val-epoch-step: 99-629 -- Loss: 0.18813872337341309
val-epoch-step: 99-630 -- Loss: 0.340029239654541
val-epoch-step: 99-631 -- Loss: 0.1543073058128357
val-epoch-step: 99-632 -- Loss: 0.18949973583221436
val-epoch-step: 99-633 -- Loss: 0.14919474720954895
val-epoch-step: 99-634 -- Loss: 0.14006094634532928
val-epoch-step: 99-635 -- Loss: 0.10817709565162659
val-epoch-step: 99-636 -- Loss: 0.15797209739685059
val-epoch-step: 99-637 -- Loss: 0.17680643498897552
val-epoch-step: 99-638 -- Loss: 0.144279345870018
val-epoch-step: 99-639 -- Loss: 0.25528982281684875
val-epoch-step: 99-640 -- Loss: 0.2427632063627243
val-epoch-step: 99-641 -- Loss: 0.1281411051750183
val-epoch-step: 99-642 -- Loss: 0.17036807537078857
val-epoch-step: 99-643 -- Loss: 0.2011769860982895
val-epoch-step: 99-644 -- Loss: 0.1600360870361328
val-epoch-step: 99-645 -- Loss: 0.21827460825443268
val-epoch-step: 99-646 -- Loss: 0.1245771199464798
val-epoch-step: 99-647 -- Loss: 0.12548023462295532
val-epoch-step: 99-648 -- Loss: 0.1478017270565033
val-epoch-step: 99-649 -- Loss: 0.20061302185058594
val-epoch-step: 99-650 -- Loss: 0.2483803629875183
val-epoch-step: 99-651 -- Loss: 0.13526064157485962
val-epoch-step: 99-652 -- Loss: 0.1489400863647461
val-epoch-step: 99-653 -- Loss: 0.18996593356132507
val-epoch-step: 99-654 -- Loss: 0.11245817691087723
Epoch: 99 -- Train Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1405, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 100-0 -- Loss: 0.21823135018348694
train-epoch-step: 100-1 -- Loss: 0.13701573014259338
train-epoch-step: 100-2 -- Loss: 0.18959204852581024
train-epoch-step: 100-3 -- Loss: 0.13592512905597687
train-epoch-step: 100-4 -- Loss: 0.15371045470237732
train-epoch-step: 100-5 -- Loss: 0.17561182379722595
train-epoch-step: 100-6 -- Loss: 0.20394441485404968
train-epoch-step: 100-7 -- Loss: 0.16031718254089355
train-epoch-step: 100-8 -- Loss: 0.1668480932712555
train-epoch-step: 100-9 -- Loss: 0.21759089827537537
train-epoch-step: 100-10 -- Loss: 0.1913682520389557
train-epoch-step: 100-11 -- Loss: 0.16763660311698914
train-epoch-step: 100-12 -- Loss: 0.14109070599079132
train-epoch-step: 100-13 -- Loss: 0.169717475771904
train-epoch-step: 100-14 -- Loss: 0.15628483891487122
train-epoch-step: 100-15 -- Loss: 0.15302491188049316
train-epoch-step: 100-16 -- Loss: 0.16375473141670227
train-epoch-step: 100-17 -- Loss: 0.2241840362548828
train-epoch-step: 100-18 -- Loss: 0.18989908695220947
train-epoch-step: 100-19 -- Loss: 0.12594589591026306
train-epoch-step: 100-20 -- Loss: 0.20555302500724792
train-epoch-step: 100-21 -- Loss: 0.24830351769924164
train-epoch-step: 100-22 -- Loss: 0.13535799086093903
train-epoch-step: 100-23 -- Loss: 0.13958600163459778
train-epoch-step: 100-24 -- Loss: 0.1206691712141037
train-epoch-step: 100-25 -- Loss: 0.216887965798378
train-epoch-step: 100-26 -- Loss: 0.18621210753917694
train-epoch-step: 100-27 -- Loss: 0.22762522101402283
train-epoch-step: 100-28 -- Loss: 0.12478569149971008
train-epoch-step: 100-29 -- Loss: 0.25423404574394226
train-epoch-step: 100-30 -- Loss: 0.10852131992578506
train-epoch-step: 100-31 -- Loss: 0.1270824521780014
train-epoch-step: 100-32 -- Loss: 0.16789981722831726
train-epoch-step: 100-33 -- Loss: 0.26570025086402893
train-epoch-step: 100-34 -- Loss: 0.17810454964637756
train-epoch-step: 100-35 -- Loss: 0.23543491959571838
train-epoch-step: 100-36 -- Loss: 0.13108371198177338
train-epoch-step: 100-37 -- Loss: 0.13661056756973267
train-epoch-step: 100-38 -- Loss: 0.17167462408542633
train-epoch-step: 100-39 -- Loss: 0.20961329340934753
train-epoch-step: 100-40 -- Loss: 0.18919461965560913
train-epoch-step: 100-41 -- Loss: 0.21421608328819275
train-epoch-step: 100-42 -- Loss: 0.1479850858449936
train-epoch-step: 100-43 -- Loss: 0.24901239573955536
train-epoch-step: 100-44 -- Loss: 0.12344750016927719
train-epoch-step: 100-45 -- Loss: 0.11045630276203156
train-epoch-step: 100-46 -- Loss: 0.17106905579566956
train-epoch-step: 100-47 -- Loss: 0.2163570672273636
train-epoch-step: 100-48 -- Loss: 0.14975418150424957
train-epoch-step: 100-49 -- Loss: 0.22595448791980743
train-epoch-step: 100-50 -- Loss: 0.10550845414400101
train-epoch-step: 100-51 -- Loss: 0.16950565576553345
train-epoch-step: 100-52 -- Loss: 0.15129096806049347
train-epoch-step: 100-53 -- Loss: 0.2012718915939331
train-epoch-step: 100-54 -- Loss: 0.2788260579109192
train-epoch-step: 100-55 -- Loss: 0.1652466207742691
train-epoch-step: 100-56 -- Loss: 0.16914163529872894
train-epoch-step: 100-57 -- Loss: 0.2295895516872406
train-epoch-step: 100-58 -- Loss: 0.2747129499912262
train-epoch-step: 100-59 -- Loss: 0.2338009774684906
train-epoch-step: 100-60 -- Loss: 0.12516745924949646
train-epoch-step: 100-61 -- Loss: 0.1956382542848587
train-epoch-step: 100-62 -- Loss: 0.1789994239807129
train-epoch-step: 100-63 -- Loss: 0.1282580941915512
train-epoch-step: 100-64 -- Loss: 0.14576253294944763
train-epoch-step: 100-65 -- Loss: 0.17681272327899933
train-epoch-step: 100-66 -- Loss: 0.11045930534601212
train-epoch-step: 100-67 -- Loss: 0.12229686975479126
train-epoch-step: 100-68 -- Loss: 0.2087365984916687
train-epoch-step: 100-69 -- Loss: 0.11849125474691391
train-epoch-step: 100-70 -- Loss: 0.21586506068706512
train-epoch-step: 100-71 -- Loss: 0.24984614551067352
train-epoch-step: 100-72 -- Loss: 0.16638681292533875
train-epoch-step: 100-73 -- Loss: 0.20269104838371277
train-epoch-step: 100-74 -- Loss: 0.0924355536699295
train-epoch-step: 100-75 -- Loss: 0.1259566843509674
train-epoch-step: 100-76 -- Loss: 0.14103630185127258
train-epoch-step: 100-77 -- Loss: 0.22390753030776978
train-epoch-step: 100-78 -- Loss: 0.2521201968193054
train-epoch-step: 100-79 -- Loss: 0.18229743838310242
train-epoch-step: 100-80 -- Loss: 0.24374361336231232
train-epoch-step: 100-81 -- Loss: 0.11790779232978821
train-epoch-step: 100-82 -- Loss: 0.24925854802131653
train-epoch-step: 100-83 -- Loss: 0.1685795783996582
train-epoch-step: 100-84 -- Loss: 0.17833329737186432
train-epoch-step: 100-85 -- Loss: 0.1720852255821228
train-epoch-step: 100-86 -- Loss: 0.11575774848461151
train-epoch-step: 100-87 -- Loss: 0.20200522243976593
train-epoch-step: 100-88 -- Loss: 0.13432593643665314
train-epoch-step: 100-89 -- Loss: 0.1848537176847458
train-epoch-step: 100-90 -- Loss: 0.18806089460849762
train-epoch-step: 100-91 -- Loss: 0.2346031665802002
train-epoch-step: 100-92 -- Loss: 0.15192769467830658
train-epoch-step: 100-93 -- Loss: 0.1681751310825348
train-epoch-step: 100-94 -- Loss: 0.21648651361465454
train-epoch-step: 100-95 -- Loss: 0.18335582315921783
train-epoch-step: 100-96 -- Loss: 0.21415504813194275
train-epoch-step: 100-97 -- Loss: 0.17655356228351593
train-epoch-step: 100-98 -- Loss: 0.15307176113128662
train-epoch-step: 100-99 -- Loss: 0.17499396204948425
train-epoch-step: 100-100 -- Loss: 0.18327391147613525
train-epoch-step: 100-101 -- Loss: 0.260580450296402
train-epoch-step: 100-102 -- Loss: 0.21582962572574615
train-epoch-step: 100-103 -- Loss: 0.176336407661438
train-epoch-step: 100-104 -- Loss: 0.14146259427070618
train-epoch-step: 100-105 -- Loss: 0.2510916590690613
train-epoch-step: 100-106 -- Loss: 0.17125897109508514
train-epoch-step: 100-107 -- Loss: 0.1847902089357376
train-epoch-step: 100-108 -- Loss: 0.18342936038970947
train-epoch-step: 100-109 -- Loss: 0.14022724330425262
train-epoch-step: 100-110 -- Loss: 0.18003080785274506
train-epoch-step: 100-111 -- Loss: 0.17831996083259583
train-epoch-step: 100-112 -- Loss: 0.16413278877735138
train-epoch-step: 100-113 -- Loss: 0.15945212543010712
train-epoch-step: 100-114 -- Loss: 0.1902761608362198
train-epoch-step: 100-115 -- Loss: 0.15496525168418884
train-epoch-step: 100-116 -- Loss: 0.13714611530303955
train-epoch-step: 100-117 -- Loss: 0.12558944523334503
train-epoch-step: 100-118 -- Loss: 0.18914952874183655
train-epoch-step: 100-119 -- Loss: 0.14707453548908234
train-epoch-step: 100-120 -- Loss: 0.24026045203208923
train-epoch-step: 100-121 -- Loss: 0.22289830446243286
train-epoch-step: 100-122 -- Loss: 0.20809420943260193
train-epoch-step: 100-123 -- Loss: 0.1962391883134842
train-epoch-step: 100-124 -- Loss: 0.11811084300279617
train-epoch-step: 100-125 -- Loss: 0.1488015353679657
train-epoch-step: 100-126 -- Loss: 0.22058077156543732
train-epoch-step: 100-127 -- Loss: 0.16697683930397034
train-epoch-step: 100-128 -- Loss: 0.165037602186203
train-epoch-step: 100-129 -- Loss: 0.14078235626220703
train-epoch-step: 100-130 -- Loss: 0.18660861253738403
train-epoch-step: 100-131 -- Loss: 0.13101139664649963
train-epoch-step: 100-132 -- Loss: 0.18180643022060394
train-epoch-step: 100-133 -- Loss: 0.11527086049318314
train-epoch-step: 100-134 -- Loss: 0.18653267621994019
train-epoch-step: 100-135 -- Loss: 0.1303648054599762
train-epoch-step: 100-136 -- Loss: 0.1385282278060913
train-epoch-step: 100-137 -- Loss: 0.23701085150241852
train-epoch-step: 100-138 -- Loss: 0.25049281120300293
train-epoch-step: 100-139 -- Loss: 0.12857115268707275
train-epoch-step: 100-140 -- Loss: 0.1985713690519333
train-epoch-step: 100-141 -- Loss: 0.2249828428030014
train-epoch-step: 100-142 -- Loss: 0.19658279418945312
train-epoch-step: 100-143 -- Loss: 0.16823792457580566
train-epoch-step: 100-144 -- Loss: 0.17380940914154053
train-epoch-step: 100-145 -- Loss: 0.13920144736766815
train-epoch-step: 100-146 -- Loss: 0.1695639044046402
train-epoch-step: 100-147 -- Loss: 0.16514773666858673
train-epoch-step: 100-148 -- Loss: 0.15254263579845428
train-epoch-step: 100-149 -- Loss: 0.1144775003194809
train-epoch-step: 100-150 -- Loss: 0.18118876218795776
train-epoch-step: 100-151 -- Loss: 0.1811681091785431
train-epoch-step: 100-152 -- Loss: 0.1859976351261139
train-epoch-step: 100-153 -- Loss: 0.2573031783103943
train-epoch-step: 100-154 -- Loss: 0.12576119601726532
train-epoch-step: 100-155 -- Loss: 0.13280285894870758
train-epoch-step: 100-156 -- Loss: 0.112891785800457
train-epoch-step: 100-157 -- Loss: 0.15909968316555023
train-epoch-step: 100-158 -- Loss: 0.15880271792411804
train-epoch-step: 100-159 -- Loss: 0.17247521877288818
train-epoch-step: 100-160 -- Loss: 0.20441129803657532
train-epoch-step: 100-161 -- Loss: 0.19235368072986603
train-epoch-step: 100-162 -- Loss: 0.20163872838020325
train-epoch-step: 100-163 -- Loss: 0.18491819500923157
train-epoch-step: 100-164 -- Loss: 0.1895153820514679
train-epoch-step: 100-165 -- Loss: 0.15720921754837036
train-epoch-step: 100-166 -- Loss: 0.11389017105102539
train-epoch-step: 100-167 -- Loss: 0.12773580849170685
train-epoch-step: 100-168 -- Loss: 0.19537752866744995
train-epoch-step: 100-169 -- Loss: 0.1420155167579651
train-epoch-step: 100-170 -- Loss: 0.1973678171634674
train-epoch-step: 100-171 -- Loss: 0.13909311592578888
train-epoch-step: 100-172 -- Loss: 0.25138935446739197
train-epoch-step: 100-173 -- Loss: 0.13544806838035583
train-epoch-step: 100-174 -- Loss: 0.24037638306617737
train-epoch-step: 100-175 -- Loss: 0.20406687259674072
train-epoch-step: 100-176 -- Loss: 0.1286228448152542
train-epoch-step: 100-177 -- Loss: 0.172499418258667
train-epoch-step: 100-178 -- Loss: 0.17562370002269745
train-epoch-step: 100-179 -- Loss: 0.14145012199878693
train-epoch-step: 100-180 -- Loss: 0.1473337858915329
train-epoch-step: 100-181 -- Loss: 0.16649411618709564
train-epoch-step: 100-182 -- Loss: 0.1804456263780594
train-epoch-step: 100-183 -- Loss: 0.26580697298049927
train-epoch-step: 100-184 -- Loss: 0.134384885430336
train-epoch-step: 100-185 -- Loss: 0.1351681500673294
train-epoch-step: 100-186 -- Loss: 0.194574236869812
train-epoch-step: 100-187 -- Loss: 0.20629167556762695
train-epoch-step: 100-188 -- Loss: 0.16727221012115479
train-epoch-step: 100-189 -- Loss: 0.10409179329872131
train-epoch-step: 100-190 -- Loss: 0.17754045128822327
train-epoch-step: 100-191 -- Loss: 0.15243901312351227
train-epoch-step: 100-192 -- Loss: 0.22699041664600372
train-epoch-step: 100-193 -- Loss: 0.20169690251350403
train-epoch-step: 100-194 -- Loss: 0.17944546043872833
train-epoch-step: 100-195 -- Loss: 0.16036391258239746
train-epoch-step: 100-196 -- Loss: 0.16037605702877045
train-epoch-step: 100-197 -- Loss: 0.11858248710632324
train-epoch-step: 100-198 -- Loss: 0.12313465774059296
train-epoch-step: 100-199 -- Loss: 0.1432165652513504
train-epoch-step: 100-200 -- Loss: 0.12917473912239075
train-epoch-step: 100-201 -- Loss: 0.1811269372701645
train-epoch-step: 100-202 -- Loss: 0.13443970680236816
train-epoch-step: 100-203 -- Loss: 0.1729900985956192
train-epoch-step: 100-204 -- Loss: 0.1362258791923523
train-epoch-step: 100-205 -- Loss: 0.19081512093544006
train-epoch-step: 100-206 -- Loss: 0.19546648859977722
train-epoch-step: 100-207 -- Loss: 0.13186372816562653
train-epoch-step: 100-208 -- Loss: 0.16983643174171448
train-epoch-step: 100-209 -- Loss: 0.13817435503005981
train-epoch-step: 100-210 -- Loss: 0.12797410786151886
train-epoch-step: 100-211 -- Loss: 0.2099493145942688
train-epoch-step: 100-212 -- Loss: 0.1923326849937439
train-epoch-step: 100-213 -- Loss: 0.12616567313671112
train-epoch-step: 100-214 -- Loss: 0.14383593201637268
train-epoch-step: 100-215 -- Loss: 0.12384066730737686
train-epoch-step: 100-216 -- Loss: 0.1887969672679901
train-epoch-step: 100-217 -- Loss: 0.20361483097076416
train-epoch-step: 100-218 -- Loss: 0.14746026694774628
train-epoch-step: 100-219 -- Loss: 0.1648133248090744
train-epoch-step: 100-220 -- Loss: 0.1216459721326828
train-epoch-step: 100-221 -- Loss: 0.20530031621456146
train-epoch-step: 100-222 -- Loss: 0.11310162395238876
train-epoch-step: 100-223 -- Loss: 0.16467627882957458
train-epoch-step: 100-224 -- Loss: 0.1846511960029602
train-epoch-step: 100-225 -- Loss: 0.26606470346450806
train-epoch-step: 100-226 -- Loss: 0.2001785933971405
train-epoch-step: 100-227 -- Loss: 0.2124343067407608
train-epoch-step: 100-228 -- Loss: 0.17132531106472015
train-epoch-step: 100-229 -- Loss: 0.171818345785141
train-epoch-step: 100-230 -- Loss: 0.16206791996955872
train-epoch-step: 100-231 -- Loss: 0.1489691436290741
train-epoch-step: 100-232 -- Loss: 0.17918814718723297
train-epoch-step: 100-233 -- Loss: 0.07988078892230988
train-epoch-step: 100-234 -- Loss: 0.1660165637731552
train-epoch-step: 100-235 -- Loss: 0.13715426623821259
train-epoch-step: 100-236 -- Loss: 0.17594745755195618
train-epoch-step: 100-237 -- Loss: 0.2249576598405838
train-epoch-step: 100-238 -- Loss: 0.15313038229942322
train-epoch-step: 100-239 -- Loss: 0.12230870127677917
train-epoch-step: 100-240 -- Loss: 0.22119659185409546
train-epoch-step: 100-241 -- Loss: 0.14802750945091248
train-epoch-step: 100-242 -- Loss: 0.2132573425769806
train-epoch-step: 100-243 -- Loss: 0.23026634752750397
train-epoch-step: 100-244 -- Loss: 0.19651196897029877
train-epoch-step: 100-245 -- Loss: 0.19735407829284668
train-epoch-step: 100-246 -- Loss: 0.21615485846996307
train-epoch-step: 100-247 -- Loss: 0.20129482448101044
train-epoch-step: 100-248 -- Loss: 0.1790955811738968
train-epoch-step: 100-249 -- Loss: 0.13507568836212158
train-epoch-step: 100-250 -- Loss: 0.19315165281295776
train-epoch-step: 100-251 -- Loss: 0.1022106409072876
train-epoch-step: 100-252 -- Loss: 0.19229064881801605
train-epoch-step: 100-253 -- Loss: 0.13146521151065826
train-epoch-step: 100-254 -- Loss: 0.20408576726913452
train-epoch-step: 100-255 -- Loss: 0.14189788699150085
train-epoch-step: 100-256 -- Loss: 0.1437264084815979
train-epoch-step: 100-257 -- Loss: 0.18225106596946716
train-epoch-step: 100-258 -- Loss: 0.14249876141548157
train-epoch-step: 100-259 -- Loss: 0.11256678402423859
train-epoch-step: 100-260 -- Loss: 0.1956501603126526
train-epoch-step: 100-261 -- Loss: 0.17262142896652222
train-epoch-step: 100-262 -- Loss: 0.2757550776004791
train-epoch-step: 100-263 -- Loss: 0.19396400451660156
train-epoch-step: 100-264 -- Loss: 0.17090491950511932
train-epoch-step: 100-265 -- Loss: 0.11559019237756729
train-epoch-step: 100-266 -- Loss: 0.14994312822818756
train-epoch-step: 100-267 -- Loss: 0.12327834963798523
train-epoch-step: 100-268 -- Loss: 0.11357469856739044
train-epoch-step: 100-269 -- Loss: 0.16810749471187592
train-epoch-step: 100-270 -- Loss: 0.11266836524009705
train-epoch-step: 100-271 -- Loss: 0.14249004423618317
train-epoch-step: 100-272 -- Loss: 0.11855199187994003
train-epoch-step: 100-273 -- Loss: 0.12175538390874863
train-epoch-step: 100-274 -- Loss: 0.17638173699378967
train-epoch-step: 100-275 -- Loss: 0.18664437532424927
train-epoch-step: 100-276 -- Loss: 0.1484195590019226
train-epoch-step: 100-277 -- Loss: 0.14947333931922913
train-epoch-step: 100-278 -- Loss: 0.13347679376602173
train-epoch-step: 100-279 -- Loss: 0.13532134890556335
train-epoch-step: 100-280 -- Loss: 0.22715124487876892
train-epoch-step: 100-281 -- Loss: 0.1677187979221344
train-epoch-step: 100-282 -- Loss: 0.13752782344818115
train-epoch-step: 100-283 -- Loss: 0.109566330909729
train-epoch-step: 100-284 -- Loss: 0.12926916778087616
train-epoch-step: 100-285 -- Loss: 0.18271717429161072
train-epoch-step: 100-286 -- Loss: 0.14753131568431854
train-epoch-step: 100-287 -- Loss: 0.1969718188047409
train-epoch-step: 100-288 -- Loss: 0.09308972954750061
train-epoch-step: 100-289 -- Loss: 0.11480593681335449
train-epoch-step: 100-290 -- Loss: 0.18624530732631683
train-epoch-step: 100-291 -- Loss: 0.11369912326335907
train-epoch-step: 100-292 -- Loss: 0.15070149302482605
train-epoch-step: 100-293 -- Loss: 0.13449586927890778
train-epoch-step: 100-294 -- Loss: 0.15362006425857544
train-epoch-step: 100-295 -- Loss: 0.25042492151260376
train-epoch-step: 100-296 -- Loss: 0.15480154752731323
train-epoch-step: 100-297 -- Loss: 0.1689026951789856
train-epoch-step: 100-298 -- Loss: 0.22553259134292603
train-epoch-step: 100-299 -- Loss: 0.14940649271011353
train-epoch-step: 100-300 -- Loss: 0.20299574732780457
train-epoch-step: 100-301 -- Loss: 0.17587804794311523
train-epoch-step: 100-302 -- Loss: 0.2071591019630432
train-epoch-step: 100-303 -- Loss: 0.19784700870513916
train-epoch-step: 100-304 -- Loss: 0.11745383590459824
train-epoch-step: 100-305 -- Loss: 0.14323754608631134
train-epoch-step: 100-306 -- Loss: 0.2132914662361145
train-epoch-step: 100-307 -- Loss: 0.15837930142879486
train-epoch-step: 100-308 -- Loss: 0.2077523022890091
train-epoch-step: 100-309 -- Loss: 0.14880438148975372
train-epoch-step: 100-310 -- Loss: 0.15730413794517517
train-epoch-step: 100-311 -- Loss: 0.15369568765163422
train-epoch-step: 100-312 -- Loss: 0.1982014775276184
train-epoch-step: 100-313 -- Loss: 0.09431960433721542
train-epoch-step: 100-314 -- Loss: 0.1861182600259781
train-epoch-step: 100-315 -- Loss: 0.16320273280143738
train-epoch-step: 100-316 -- Loss: 0.14927123486995697
train-epoch-step: 100-317 -- Loss: 0.1398693025112152
train-epoch-step: 100-318 -- Loss: 0.15814298391342163
train-epoch-step: 100-319 -- Loss: 0.16539354622364044
train-epoch-step: 100-320 -- Loss: 0.11246155202388763
train-epoch-step: 100-321 -- Loss: 0.12965533137321472
train-epoch-step: 100-322 -- Loss: 0.20387500524520874
train-epoch-step: 100-323 -- Loss: 0.15468943119049072
train-epoch-step: 100-324 -- Loss: 0.24574895203113556
train-epoch-step: 100-325 -- Loss: 0.1538848578929901
train-epoch-step: 100-326 -- Loss: 0.17433562874794006
train-epoch-step: 100-327 -- Loss: 0.1978430449962616
train-epoch-step: 100-328 -- Loss: 0.18658268451690674
train-epoch-step: 100-329 -- Loss: 0.3354566693305969
train-epoch-step: 100-330 -- Loss: 0.34877893328666687
train-epoch-step: 100-331 -- Loss: 0.20497888326644897
train-epoch-step: 100-332 -- Loss: 0.09897717833518982
train-epoch-step: 100-333 -- Loss: 0.17397861182689667
train-epoch-step: 100-334 -- Loss: 0.14871083199977875
train-epoch-step: 100-335 -- Loss: 0.17849914729595184
train-epoch-step: 100-336 -- Loss: 0.14183957874774933
train-epoch-step: 100-337 -- Loss: 0.2015257477760315
train-epoch-step: 100-338 -- Loss: 0.15699724853038788
train-epoch-step: 100-339 -- Loss: 0.14222189784049988
train-epoch-step: 100-340 -- Loss: 0.19493772089481354
train-epoch-step: 100-341 -- Loss: 0.13809701800346375
train-epoch-step: 100-342 -- Loss: 0.16152995824813843
train-epoch-step: 100-343 -- Loss: 0.15209156274795532
train-epoch-step: 100-344 -- Loss: 0.1607065051794052
train-epoch-step: 100-345 -- Loss: 0.1286548227071762
train-epoch-step: 100-346 -- Loss: 0.2048090100288391
train-epoch-step: 100-347 -- Loss: 0.15129874646663666
train-epoch-step: 100-348 -- Loss: 0.19862887263298035
train-epoch-step: 100-349 -- Loss: 0.19475716352462769
train-epoch-step: 100-350 -- Loss: 0.24517084658145905
train-epoch-step: 100-351 -- Loss: 0.18673358857631683
train-epoch-step: 100-352 -- Loss: 0.1223779022693634
train-epoch-step: 100-353 -- Loss: 0.18969759345054626
train-epoch-step: 100-354 -- Loss: 0.27382001280784607
train-epoch-step: 100-355 -- Loss: 0.11407870799303055
train-epoch-step: 100-356 -- Loss: 0.11196056753396988
train-epoch-step: 100-357 -- Loss: 0.18439757823944092
train-epoch-step: 100-358 -- Loss: 0.18048416078090668
train-epoch-step: 100-359 -- Loss: 0.13715113699436188
train-epoch-step: 100-360 -- Loss: 0.11941561102867126
train-epoch-step: 100-361 -- Loss: 0.2267177402973175
train-epoch-step: 100-362 -- Loss: 0.1644257754087448
train-epoch-step: 100-363 -- Loss: 0.10558939725160599
train-epoch-step: 100-364 -- Loss: 0.17622588574886322
train-epoch-step: 100-365 -- Loss: 0.16106803715229034
train-epoch-step: 100-366 -- Loss: 0.20402902364730835
train-epoch-step: 100-367 -- Loss: 0.22528234124183655
train-epoch-step: 100-368 -- Loss: 0.195806086063385
train-epoch-step: 100-369 -- Loss: 0.2736493945121765
train-epoch-step: 100-370 -- Loss: 0.12387511134147644
train-epoch-step: 100-371 -- Loss: 0.11898645758628845
train-epoch-step: 100-372 -- Loss: 0.15665344893932343
train-epoch-step: 100-373 -- Loss: 0.18383966386318207
train-epoch-step: 100-374 -- Loss: 0.15268056094646454
train-epoch-step: 100-375 -- Loss: 0.25795432925224304
train-epoch-step: 100-376 -- Loss: 0.15703916549682617
train-epoch-step: 100-377 -- Loss: 0.22258466482162476
train-epoch-step: 100-378 -- Loss: 0.1977655291557312
train-epoch-step: 100-379 -- Loss: 0.11802753061056137
train-epoch-step: 100-380 -- Loss: 0.09555736184120178
train-epoch-step: 100-381 -- Loss: 0.23997172713279724
train-epoch-step: 100-382 -- Loss: 0.23886677622795105
train-epoch-step: 100-383 -- Loss: 0.17285701632499695
train-epoch-step: 100-384 -- Loss: 0.2088150829076767
train-epoch-step: 100-385 -- Loss: 0.18694813549518585
train-epoch-step: 100-386 -- Loss: 0.19065232574939728
train-epoch-step: 100-387 -- Loss: 0.20715776085853577
train-epoch-step: 100-388 -- Loss: 0.18573707342147827
train-epoch-step: 100-389 -- Loss: 0.1640448421239853
train-epoch-step: 100-390 -- Loss: 0.13898682594299316
train-epoch-step: 100-391 -- Loss: 0.15536296367645264
train-epoch-step: 100-392 -- Loss: 0.18283449113368988
train-epoch-step: 100-393 -- Loss: 0.1534651815891266
train-epoch-step: 100-394 -- Loss: 0.20768457651138306
train-epoch-step: 100-395 -- Loss: 0.1725265085697174
train-epoch-step: 100-396 -- Loss: 0.12532630562782288
train-epoch-step: 100-397 -- Loss: 0.1324395388364792
train-epoch-step: 100-398 -- Loss: 0.200893372297287
train-epoch-step: 100-399 -- Loss: 0.17196553945541382
train-epoch-step: 100-400 -- Loss: 0.27552229166030884
train-epoch-step: 100-401 -- Loss: 0.1270095854997635
train-epoch-step: 100-402 -- Loss: 0.25801926851272583
train-epoch-step: 100-403 -- Loss: 0.15953636169433594
train-epoch-step: 100-404 -- Loss: 0.1371004730463028
train-epoch-step: 100-405 -- Loss: 0.14006857573986053
train-epoch-step: 100-406 -- Loss: 0.16860218346118927
train-epoch-step: 100-407 -- Loss: 0.11203588545322418
train-epoch-step: 100-408 -- Loss: 0.1598128229379654
train-epoch-step: 100-409 -- Loss: 0.1701928675174713
train-epoch-step: 100-410 -- Loss: 0.16849064826965332
train-epoch-step: 100-411 -- Loss: 0.18723180890083313
train-epoch-step: 100-412 -- Loss: 0.12587444484233856
train-epoch-step: 100-413 -- Loss: 0.141627237200737
train-epoch-step: 100-414 -- Loss: 0.12773928046226501
train-epoch-step: 100-415 -- Loss: 0.13310325145721436
train-epoch-step: 100-416 -- Loss: 0.27298569679260254
train-epoch-step: 100-417 -- Loss: 0.18945690989494324
train-epoch-step: 100-418 -- Loss: 0.216342031955719
train-epoch-step: 100-419 -- Loss: 0.16604119539260864
train-epoch-step: 100-420 -- Loss: 0.14848046004772186
train-epoch-step: 100-421 -- Loss: 0.18382753431797028
train-epoch-step: 100-422 -- Loss: 0.14469414949417114
train-epoch-step: 100-423 -- Loss: 0.17037057876586914
train-epoch-step: 100-424 -- Loss: 0.13541027903556824
train-epoch-step: 100-425 -- Loss: 0.18118558824062347
train-epoch-step: 100-426 -- Loss: 0.16141514480113983
train-epoch-step: 100-427 -- Loss: 0.12100254744291306
train-epoch-step: 100-428 -- Loss: 0.1894673854112625
train-epoch-step: 100-429 -- Loss: 0.1763724386692047
train-epoch-step: 100-430 -- Loss: 0.13787755370140076
train-epoch-step: 100-431 -- Loss: 0.15607646107673645
train-epoch-step: 100-432 -- Loss: 0.22961807250976562
train-epoch-step: 100-433 -- Loss: 0.13620537519454956
train-epoch-step: 100-434 -- Loss: 0.12399713695049286
train-epoch-step: 100-435 -- Loss: 0.15650343894958496
train-epoch-step: 100-436 -- Loss: 0.15321755409240723
train-epoch-step: 100-437 -- Loss: 0.1270567774772644
train-epoch-step: 100-438 -- Loss: 0.16385023295879364
train-epoch-step: 100-439 -- Loss: 0.25555655360221863
train-epoch-step: 100-440 -- Loss: 0.12741954624652863
train-epoch-step: 100-441 -- Loss: 0.20131243765354156
train-epoch-step: 100-442 -- Loss: 0.16780303418636322
train-epoch-step: 100-443 -- Loss: 0.1552492082118988
train-epoch-step: 100-444 -- Loss: 0.17729836702346802
train-epoch-step: 100-445 -- Loss: 0.17652317881584167
train-epoch-step: 100-446 -- Loss: 0.15004347264766693
train-epoch-step: 100-447 -- Loss: 0.18812569975852966
train-epoch-step: 100-448 -- Loss: 0.2362171858549118
train-epoch-step: 100-449 -- Loss: 0.19839595258235931
train-epoch-step: 100-450 -- Loss: 0.18275146186351776
train-epoch-step: 100-451 -- Loss: 0.14334094524383545
train-epoch-step: 100-452 -- Loss: 0.13659963011741638
train-epoch-step: 100-453 -- Loss: 0.09194618463516235
train-epoch-step: 100-454 -- Loss: 0.22538645565509796
train-epoch-step: 100-455 -- Loss: 0.11925368010997772
train-epoch-step: 100-456 -- Loss: 0.11719374358654022
train-epoch-step: 100-457 -- Loss: 0.21703076362609863
train-epoch-step: 100-458 -- Loss: 0.1498599350452423
train-epoch-step: 100-459 -- Loss: 0.23188704252243042
train-epoch-step: 100-460 -- Loss: 0.13582167029380798
train-epoch-step: 100-461 -- Loss: 0.13270390033721924
train-epoch-step: 100-462 -- Loss: 0.16043397784233093
train-epoch-step: 100-463 -- Loss: 0.1396905779838562
train-epoch-step: 100-464 -- Loss: 0.16810232400894165
train-epoch-step: 100-465 -- Loss: 0.2558916211128235
train-epoch-step: 100-466 -- Loss: 0.20902442932128906
train-epoch-step: 100-467 -- Loss: 0.11225143074989319
train-epoch-step: 100-468 -- Loss: 0.16536712646484375
train-epoch-step: 100-469 -- Loss: 0.25125426054000854
train-epoch-step: 100-470 -- Loss: 0.1711994707584381
train-epoch-step: 100-471 -- Loss: 0.15286244451999664
train-epoch-step: 100-472 -- Loss: 0.16415950655937195
train-epoch-step: 100-473 -- Loss: 0.15651029348373413
train-epoch-step: 100-474 -- Loss: 0.11739493161439896
train-epoch-step: 100-475 -- Loss: 0.10571952164173126
train-epoch-step: 100-476 -- Loss: 0.2014208287000656
train-epoch-step: 100-477 -- Loss: 0.22713840007781982
train-epoch-step: 100-478 -- Loss: 0.22761479020118713
train-epoch-step: 100-479 -- Loss: 0.16352179646492004
train-epoch-step: 100-480 -- Loss: 0.20486341416835785
train-epoch-step: 100-481 -- Loss: 0.2859589457511902
train-epoch-step: 100-482 -- Loss: 0.2591107487678528
train-epoch-step: 100-483 -- Loss: 0.18594703078269958
train-epoch-step: 100-484 -- Loss: 0.21717706322669983
train-epoch-step: 100-485 -- Loss: 0.13931713998317719
train-epoch-step: 100-486 -- Loss: 0.25027063488960266
train-epoch-step: 100-487 -- Loss: 0.2327173501253128
train-epoch-step: 100-488 -- Loss: 0.19875769317150116
train-epoch-step: 100-489 -- Loss: 0.22435498237609863
train-epoch-step: 100-490 -- Loss: 0.13899965584278107
train-epoch-step: 100-491 -- Loss: 0.13737058639526367
train-epoch-step: 100-492 -- Loss: 0.12434789538383484
train-epoch-step: 100-493 -- Loss: 0.19726282358169556
train-epoch-step: 100-494 -- Loss: 0.20239681005477905
train-epoch-step: 100-495 -- Loss: 0.20443984866142273
train-epoch-step: 100-496 -- Loss: 0.14924700558185577
train-epoch-step: 100-497 -- Loss: 0.18684887886047363
train-epoch-step: 100-498 -- Loss: 0.15097759664058685
train-epoch-step: 100-499 -- Loss: 0.18560336530208588
train-epoch-step: 100-500 -- Loss: 0.16042016446590424
train-epoch-step: 100-501 -- Loss: 0.2252243012189865
train-epoch-step: 100-502 -- Loss: 0.1593666970729828
train-epoch-step: 100-503 -- Loss: 0.23665682971477509
train-epoch-step: 100-504 -- Loss: 0.12352002412080765
train-epoch-step: 100-505 -- Loss: 0.16915731132030487
train-epoch-step: 100-506 -- Loss: 0.1198110431432724
train-epoch-step: 100-507 -- Loss: 0.18557029962539673
train-epoch-step: 100-508 -- Loss: 0.17621825635433197
train-epoch-step: 100-509 -- Loss: 0.16912920773029327
train-epoch-step: 100-510 -- Loss: 0.12530581653118134
train-epoch-step: 100-511 -- Loss: 0.21749982237815857
train-epoch-step: 100-512 -- Loss: 0.18022498488426208
train-epoch-step: 100-513 -- Loss: 0.18548186123371124
train-epoch-step: 100-514 -- Loss: 0.14115186035633087
train-epoch-step: 100-515 -- Loss: 0.15170782804489136
train-epoch-step: 100-516 -- Loss: 0.17265287041664124
train-epoch-step: 100-517 -- Loss: 0.17384669184684753
train-epoch-step: 100-518 -- Loss: 0.1417006403207779
train-epoch-step: 100-519 -- Loss: 0.13439466059207916
train-epoch-step: 100-520 -- Loss: 0.17982298135757446
train-epoch-step: 100-521 -- Loss: 0.22565925121307373
train-epoch-step: 100-522 -- Loss: 0.1698111891746521
train-epoch-step: 100-523 -- Loss: 0.14916379749774933
train-epoch-step: 100-524 -- Loss: 0.16717274487018585
train-epoch-step: 100-525 -- Loss: 0.1860230565071106
train-epoch-step: 100-526 -- Loss: 0.1247231662273407
train-epoch-step: 100-527 -- Loss: 0.14203408360481262
train-epoch-step: 100-528 -- Loss: 0.14899852871894836
train-epoch-step: 100-529 -- Loss: 0.1503164917230606
train-epoch-step: 100-530 -- Loss: 0.16827909648418427
train-epoch-step: 100-531 -- Loss: 0.18929246068000793
train-epoch-step: 100-532 -- Loss: 0.1651660054922104
train-epoch-step: 100-533 -- Loss: 0.16678929328918457
train-epoch-step: 100-534 -- Loss: 0.12555941939353943
train-epoch-step: 100-535 -- Loss: 0.24935781955718994
train-epoch-step: 100-536 -- Loss: 0.1483469009399414
train-epoch-step: 100-537 -- Loss: 0.14401684701442719
train-epoch-step: 100-538 -- Loss: 0.1047205924987793
train-epoch-step: 100-539 -- Loss: 0.2235237956047058
train-epoch-step: 100-540 -- Loss: 0.13395237922668457
train-epoch-step: 100-541 -- Loss: 0.20276011526584625
train-epoch-step: 100-542 -- Loss: 0.22177693247795105
train-epoch-step: 100-543 -- Loss: 0.16933122277259827
train-epoch-step: 100-544 -- Loss: 0.22302430868148804
train-epoch-step: 100-545 -- Loss: 0.1951504945755005
train-epoch-step: 100-546 -- Loss: 0.20312151312828064
train-epoch-step: 100-547 -- Loss: 0.1795668751001358
train-epoch-step: 100-548 -- Loss: 0.08906784653663635
train-epoch-step: 100-549 -- Loss: 0.1434401571750641
train-epoch-step: 100-550 -- Loss: 0.19445224106311798
train-epoch-step: 100-551 -- Loss: 0.1518193930387497
train-epoch-step: 100-552 -- Loss: 0.12237338721752167
train-epoch-step: 100-553 -- Loss: 0.18802471458911896
train-epoch-step: 100-554 -- Loss: 0.17790836095809937
train-epoch-step: 100-555 -- Loss: 0.20496788620948792
train-epoch-step: 100-556 -- Loss: 0.14352582395076752
train-epoch-step: 100-557 -- Loss: 0.2331937551498413
train-epoch-step: 100-558 -- Loss: 0.22072434425354004
train-epoch-step: 100-559 -- Loss: 0.13644810020923615
train-epoch-step: 100-560 -- Loss: 0.20510274171829224
train-epoch-step: 100-561 -- Loss: 0.17874744534492493
train-epoch-step: 100-562 -- Loss: 0.16069766879081726
train-epoch-step: 100-563 -- Loss: 0.18445059657096863
train-epoch-step: 100-564 -- Loss: 0.09746042639017105
train-epoch-step: 100-565 -- Loss: 0.17612433433532715
train-epoch-step: 100-566 -- Loss: 0.14361852407455444
train-epoch-step: 100-567 -- Loss: 0.20561271905899048
train-epoch-step: 100-568 -- Loss: 0.15323443710803986
train-epoch-step: 100-569 -- Loss: 0.23578466475009918
train-epoch-step: 100-570 -- Loss: 0.16540969908237457
train-epoch-step: 100-571 -- Loss: 0.2123372107744217
train-epoch-step: 100-572 -- Loss: 0.236336350440979
train-epoch-step: 100-573 -- Loss: 0.1968424767255783
train-epoch-step: 100-574 -- Loss: 0.2366059273481369
train-epoch-step: 100-575 -- Loss: 0.29389670491218567
train-epoch-step: 100-576 -- Loss: 0.12249647825956345
train-epoch-step: 100-577 -- Loss: 0.1638251394033432
train-epoch-step: 100-578 -- Loss: 0.210384801030159
train-epoch-step: 100-579 -- Loss: 0.1578313559293747
train-epoch-step: 100-580 -- Loss: 0.16490688920021057
train-epoch-step: 100-581 -- Loss: 0.15008345246315002
train-epoch-step: 100-582 -- Loss: 0.1976761519908905
train-epoch-step: 100-583 -- Loss: 0.22599975764751434
train-epoch-step: 100-584 -- Loss: 0.1641397476196289
train-epoch-step: 100-585 -- Loss: 0.19904032349586487
train-epoch-step: 100-586 -- Loss: 0.25065702199935913
train-epoch-step: 100-587 -- Loss: 0.18922948837280273
train-epoch-step: 100-588 -- Loss: 0.1244407594203949
val-epoch-step: 100-589 -- Loss: 0.2098742425441742
val-epoch-step: 100-590 -- Loss: 0.1501922756433487
val-epoch-step: 100-591 -- Loss: 0.22234442830085754
val-epoch-step: 100-592 -- Loss: 0.1692979335784912
val-epoch-step: 100-593 -- Loss: 0.15285706520080566
val-epoch-step: 100-594 -- Loss: 0.368396520614624
val-epoch-step: 100-595 -- Loss: 0.18968012928962708
val-epoch-step: 100-596 -- Loss: 0.2293376922607422
val-epoch-step: 100-597 -- Loss: 0.17772594094276428
val-epoch-step: 100-598 -- Loss: 0.16600832343101501
val-epoch-step: 100-599 -- Loss: 0.18253570795059204
val-epoch-step: 100-600 -- Loss: 0.16625858843326569
val-epoch-step: 100-601 -- Loss: 0.15551793575286865
val-epoch-step: 100-602 -- Loss: 0.14974287152290344
val-epoch-step: 100-603 -- Loss: 0.19116079807281494
val-epoch-step: 100-604 -- Loss: 0.14604192972183228
val-epoch-step: 100-605 -- Loss: 0.14546307921409607
val-epoch-step: 100-606 -- Loss: 0.25861087441444397
val-epoch-step: 100-607 -- Loss: 0.1301143318414688
val-epoch-step: 100-608 -- Loss: 0.2553270757198334
val-epoch-step: 100-609 -- Loss: 0.16561773419380188
val-epoch-step: 100-610 -- Loss: 0.18535204231739044
val-epoch-step: 100-611 -- Loss: 0.1604958474636078
val-epoch-step: 100-612 -- Loss: 0.4625510573387146
val-epoch-step: 100-613 -- Loss: 0.16808871924877167
val-epoch-step: 100-614 -- Loss: 0.1661396622657776
val-epoch-step: 100-615 -- Loss: 0.17088720202445984
val-epoch-step: 100-616 -- Loss: 0.14957745373249054
val-epoch-step: 100-617 -- Loss: 0.1896955966949463
val-epoch-step: 100-618 -- Loss: 0.2323610484600067
val-epoch-step: 100-619 -- Loss: 0.2131766527891159
val-epoch-step: 100-620 -- Loss: 0.14008904993534088
val-epoch-step: 100-621 -- Loss: 0.12481556832790375
val-epoch-step: 100-622 -- Loss: 0.14088398218154907
val-epoch-step: 100-623 -- Loss: 0.1512172818183899
val-epoch-step: 100-624 -- Loss: 0.13692834973335266
val-epoch-step: 100-625 -- Loss: 0.16122257709503174
val-epoch-step: 100-626 -- Loss: 0.15056423842906952
val-epoch-step: 100-627 -- Loss: 0.17881464958190918
val-epoch-step: 100-628 -- Loss: 0.4644092619419098
val-epoch-step: 100-629 -- Loss: 0.2481507956981659
val-epoch-step: 100-630 -- Loss: 0.3451034724712372
val-epoch-step: 100-631 -- Loss: 0.14793869853019714
val-epoch-step: 100-632 -- Loss: 0.2025378793478012
val-epoch-step: 100-633 -- Loss: 0.1502121388912201
val-epoch-step: 100-634 -- Loss: 0.1531147062778473
val-epoch-step: 100-635 -- Loss: 0.11579227447509766
val-epoch-step: 100-636 -- Loss: 0.1633690893650055
val-epoch-step: 100-637 -- Loss: 0.17880508303642273
val-epoch-step: 100-638 -- Loss: 0.16335108876228333
val-epoch-step: 100-639 -- Loss: 0.25535184144973755
val-epoch-step: 100-640 -- Loss: 0.2622324228286743
val-epoch-step: 100-641 -- Loss: 0.12326714396476746
val-epoch-step: 100-642 -- Loss: 0.17690524458885193
val-epoch-step: 100-643 -- Loss: 0.21122044324874878
val-epoch-step: 100-644 -- Loss: 0.16244852542877197
val-epoch-step: 100-645 -- Loss: 0.21549007296562195
val-epoch-step: 100-646 -- Loss: 0.12466065585613251
val-epoch-step: 100-647 -- Loss: 0.13191530108451843
val-epoch-step: 100-648 -- Loss: 0.14957359433174133
val-epoch-step: 100-649 -- Loss: 0.20714980363845825
val-epoch-step: 100-650 -- Loss: 0.24654820561408997
val-epoch-step: 100-651 -- Loss: 0.14618365466594696
val-epoch-step: 100-652 -- Loss: 0.149659663438797
val-epoch-step: 100-653 -- Loss: 0.21845488250255585
val-epoch-step: 100-654 -- Loss: 0.11777225881814957
Epoch: 100 -- Train Loss: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 71.79 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 71.79
                         Test Loss: 0.0 -- Test Acc: 71.79
train-epoch-step: 101-0 -- Loss: 0.21624326705932617
train-epoch-step: 101-1 -- Loss: 0.14329224824905396
train-epoch-step: 101-2 -- Loss: 0.19460396468639374
train-epoch-step: 101-3 -- Loss: 0.1527670919895172
train-epoch-step: 101-4 -- Loss: 0.15442198514938354
train-epoch-step: 101-5 -- Loss: 0.19665054976940155
train-epoch-step: 101-6 -- Loss: 0.21254883706569672
train-epoch-step: 101-7 -- Loss: 0.16468802094459534
train-epoch-step: 101-8 -- Loss: 0.1975783109664917
train-epoch-step: 101-9 -- Loss: 0.2220221906900406
train-epoch-step: 101-10 -- Loss: 0.18817251920700073
train-epoch-step: 101-11 -- Loss: 0.1747698187828064
train-epoch-step: 101-12 -- Loss: 0.14956159889698029
train-epoch-step: 101-13 -- Loss: 0.17485983669757843
train-epoch-step: 101-14 -- Loss: 0.1599137932062149
train-epoch-step: 101-15 -- Loss: 0.15879939496517181
train-epoch-step: 101-16 -- Loss: 0.17771463096141815
train-epoch-step: 101-17 -- Loss: 0.23252521455287933
train-epoch-step: 101-18 -- Loss: 0.2072215974330902
train-epoch-step: 101-19 -- Loss: 0.13176299631595612
train-epoch-step: 101-20 -- Loss: 0.21291270852088928
train-epoch-step: 101-21 -- Loss: 0.24341823160648346
train-epoch-step: 101-22 -- Loss: 0.14631305634975433
train-epoch-step: 101-23 -- Loss: 0.14564207196235657
train-epoch-step: 101-24 -- Loss: 0.1216457411646843
train-epoch-step: 101-25 -- Loss: 0.2264227271080017
train-epoch-step: 101-26 -- Loss: 0.18859480321407318
train-epoch-step: 101-27 -- Loss: 0.2285861074924469
train-epoch-step: 101-28 -- Loss: 0.12476098537445068
train-epoch-step: 101-29 -- Loss: 0.23526053130626678
train-epoch-step: 101-30 -- Loss: 0.11557996273040771
train-epoch-step: 101-31 -- Loss: 0.14515358209609985
train-epoch-step: 101-32 -- Loss: 0.17519056797027588
train-epoch-step: 101-33 -- Loss: 0.26636528968811035
train-epoch-step: 101-34 -- Loss: 0.17070765793323517
train-epoch-step: 101-35 -- Loss: 0.23708026111125946
train-epoch-step: 101-36 -- Loss: 0.13670237362384796
train-epoch-step: 101-37 -- Loss: 0.13613012433052063
train-epoch-step: 101-38 -- Loss: 0.16915276646614075
train-epoch-step: 101-39 -- Loss: 0.21868957579135895
train-epoch-step: 101-40 -- Loss: 0.19382016360759735
train-epoch-step: 101-41 -- Loss: 0.21330644190311432
train-epoch-step: 101-42 -- Loss: 0.18149498105049133
train-epoch-step: 101-43 -- Loss: 0.25012218952178955
train-epoch-step: 101-44 -- Loss: 0.12092160433530807
train-epoch-step: 101-45 -- Loss: 0.11365041136741638
train-epoch-step: 101-46 -- Loss: 0.17387419939041138
train-epoch-step: 101-47 -- Loss: 0.19354617595672607
train-epoch-step: 101-48 -- Loss: 0.15205097198486328
train-epoch-step: 101-49 -- Loss: 0.228659987449646
train-epoch-step: 101-50 -- Loss: 0.10956603288650513
train-epoch-step: 101-51 -- Loss: 0.17883549630641937
train-epoch-step: 101-52 -- Loss: 0.1657465249300003
train-epoch-step: 101-53 -- Loss: 0.24541358649730682
train-epoch-step: 101-54 -- Loss: 0.28455808758735657
train-epoch-step: 101-55 -- Loss: 0.1630985289812088
train-epoch-step: 101-56 -- Loss: 0.1743924468755722
train-epoch-step: 101-57 -- Loss: 0.23233696818351746
train-epoch-step: 101-58 -- Loss: 0.28633761405944824
train-epoch-step: 101-59 -- Loss: 0.25598567724227905
train-epoch-step: 101-60 -- Loss: 0.12899363040924072
train-epoch-step: 101-61 -- Loss: 0.2074594795703888
train-epoch-step: 101-62 -- Loss: 0.18774329125881195
train-epoch-step: 101-63 -- Loss: 0.13513943552970886
train-epoch-step: 101-64 -- Loss: 0.1449718475341797
train-epoch-step: 101-65 -- Loss: 0.17205917835235596
train-epoch-step: 101-66 -- Loss: 0.10357460379600525
train-epoch-step: 101-67 -- Loss: 0.12473359704017639
train-epoch-step: 101-68 -- Loss: 0.2008855640888214
train-epoch-step: 101-69 -- Loss: 0.12088757008314133
train-epoch-step: 101-70 -- Loss: 0.23391780257225037
train-epoch-step: 101-71 -- Loss: 0.2798859477043152
train-epoch-step: 101-72 -- Loss: 0.1708969920873642
train-epoch-step: 101-73 -- Loss: 0.20297320187091827
train-epoch-step: 101-74 -- Loss: 0.09642050415277481
train-epoch-step: 101-75 -- Loss: 0.12285050749778748
train-epoch-step: 101-76 -- Loss: 0.14195311069488525
train-epoch-step: 101-77 -- Loss: 0.21641236543655396
train-epoch-step: 101-78 -- Loss: 0.25236180424690247
train-epoch-step: 101-79 -- Loss: 0.1857829988002777
train-epoch-step: 101-80 -- Loss: 0.259625643491745
train-epoch-step: 101-81 -- Loss: 0.12407441437244415
train-epoch-step: 101-82 -- Loss: 0.247852623462677
train-epoch-step: 101-83 -- Loss: 0.17136695981025696
train-epoch-step: 101-84 -- Loss: 0.18723534047603607
train-epoch-step: 101-85 -- Loss: 0.16791269183158875
train-epoch-step: 101-86 -- Loss: 0.11827822029590607
train-epoch-step: 101-87 -- Loss: 0.22249539196491241
train-epoch-step: 101-88 -- Loss: 0.13616585731506348
train-epoch-step: 101-89 -- Loss: 0.18422377109527588
train-epoch-step: 101-90 -- Loss: 0.18558543920516968
train-epoch-step: 101-91 -- Loss: 0.23765015602111816
train-epoch-step: 101-92 -- Loss: 0.1532149761915207
train-epoch-step: 101-93 -- Loss: 0.17032700777053833
train-epoch-step: 101-94 -- Loss: 0.2197653204202652
train-epoch-step: 101-95 -- Loss: 0.18365709483623505
train-epoch-step: 101-96 -- Loss: 0.20941776037216187
train-epoch-step: 101-97 -- Loss: 0.1689682900905609
train-epoch-step: 101-98 -- Loss: 0.15159209072589874
train-epoch-step: 101-99 -- Loss: 0.18371258676052094
train-epoch-step: 101-100 -- Loss: 0.1782151609659195
train-epoch-step: 101-101 -- Loss: 0.26246997714042664
train-epoch-step: 101-102 -- Loss: 0.20874936878681183
train-epoch-step: 101-103 -- Loss: 0.18082194030284882
train-epoch-step: 101-104 -- Loss: 0.15004600584506989
train-epoch-step: 101-105 -- Loss: 0.26591041684150696
train-epoch-step: 101-106 -- Loss: 0.17106939852237701
train-epoch-step: 101-107 -- Loss: 0.1842212826013565
train-epoch-step: 101-108 -- Loss: 0.19374851882457733
train-epoch-step: 101-109 -- Loss: 0.14066801965236664
train-epoch-step: 101-110 -- Loss: 0.17733553051948547
train-epoch-step: 101-111 -- Loss: 0.1819513440132141
train-epoch-step: 101-112 -- Loss: 0.16685059666633606
train-epoch-step: 101-113 -- Loss: 0.16269296407699585
train-epoch-step: 101-114 -- Loss: 0.18967995047569275
train-epoch-step: 101-115 -- Loss: 0.1543739289045334
train-epoch-step: 101-116 -- Loss: 0.1320042461156845
train-epoch-step: 101-117 -- Loss: 0.12412867695093155
train-epoch-step: 101-118 -- Loss: 0.18761730194091797
train-epoch-step: 101-119 -- Loss: 0.1470109522342682
train-epoch-step: 101-120 -- Loss: 0.24099580943584442
train-epoch-step: 101-121 -- Loss: 0.2428053468465805
train-epoch-step: 101-122 -- Loss: 0.21004725992679596
train-epoch-step: 101-123 -- Loss: 0.21419107913970947
train-epoch-step: 101-124 -- Loss: 0.11896703392267227
train-epoch-step: 101-125 -- Loss: 0.147080659866333
train-epoch-step: 101-126 -- Loss: 0.2220487892627716
train-epoch-step: 101-127 -- Loss: 0.17465266585350037
train-epoch-step: 101-128 -- Loss: 0.169973224401474
train-epoch-step: 101-129 -- Loss: 0.1466093361377716
train-epoch-step: 101-130 -- Loss: 0.1935114860534668
train-epoch-step: 101-131 -- Loss: 0.1347862035036087
train-epoch-step: 101-132 -- Loss: 0.18513277173042297
train-epoch-step: 101-133 -- Loss: 0.1224839836359024
train-epoch-step: 101-134 -- Loss: 0.18794703483581543
train-epoch-step: 101-135 -- Loss: 0.13823014497756958
train-epoch-step: 101-136 -- Loss: 0.13682325184345245
train-epoch-step: 101-137 -- Loss: 0.23489373922348022
train-epoch-step: 101-138 -- Loss: 0.27375924587249756
train-epoch-step: 101-139 -- Loss: 0.13740292191505432
train-epoch-step: 101-140 -- Loss: 0.20940633118152618
train-epoch-step: 101-141 -- Loss: 0.23442807793617249
train-epoch-step: 101-142 -- Loss: 0.20391342043876648
train-epoch-step: 101-143 -- Loss: 0.16843342781066895
train-epoch-step: 101-144 -- Loss: 0.19138085842132568
train-epoch-step: 101-145 -- Loss: 0.14448601007461548
train-epoch-step: 101-146 -- Loss: 0.1852850615978241
train-epoch-step: 101-147 -- Loss: 0.1694241315126419
train-epoch-step: 101-148 -- Loss: 0.16406488418579102
train-epoch-step: 101-149 -- Loss: 0.11663416028022766
train-epoch-step: 101-150 -- Loss: 0.1791733205318451
train-epoch-step: 101-151 -- Loss: 0.18227308988571167
train-epoch-step: 101-152 -- Loss: 0.18393070995807648
train-epoch-step: 101-153 -- Loss: 0.2566990852355957
train-epoch-step: 101-154 -- Loss: 0.12865838408470154
train-epoch-step: 101-155 -- Loss: 0.13891413807868958
train-epoch-step: 101-156 -- Loss: 0.11798501014709473
train-epoch-step: 101-157 -- Loss: 0.15659117698669434
train-epoch-step: 101-158 -- Loss: 0.162928506731987
train-epoch-step: 101-159 -- Loss: 0.17646366357803345
train-epoch-step: 101-160 -- Loss: 0.20904865860939026
train-epoch-step: 101-161 -- Loss: 0.20014013350009918
train-epoch-step: 101-162 -- Loss: 0.20401743054389954
train-epoch-step: 101-163 -- Loss: 0.1777210533618927
train-epoch-step: 101-164 -- Loss: 0.19160224497318268
train-epoch-step: 101-165 -- Loss: 0.1586824655532837
train-epoch-step: 101-166 -- Loss: 0.11740406602621078
train-epoch-step: 101-167 -- Loss: 0.11722758412361145
train-epoch-step: 101-168 -- Loss: 0.19672031700611115
train-epoch-step: 101-169 -- Loss: 0.1380903273820877
train-epoch-step: 101-170 -- Loss: 0.1952957808971405
train-epoch-step: 101-171 -- Loss: 0.13945098221302032
train-epoch-step: 101-172 -- Loss: 0.25128990411758423
train-epoch-step: 101-173 -- Loss: 0.12980450689792633
train-epoch-step: 101-174 -- Loss: 0.24192644655704498
train-epoch-step: 101-175 -- Loss: 0.18236473202705383
train-epoch-step: 101-176 -- Loss: 0.13143379986286163
train-epoch-step: 101-177 -- Loss: 0.18427643179893494
train-epoch-step: 101-178 -- Loss: 0.1706802248954773
train-epoch-step: 101-179 -- Loss: 0.13680574297904968
train-epoch-step: 101-180 -- Loss: 0.14794591069221497
train-epoch-step: 101-181 -- Loss: 0.1678532510995865
train-epoch-step: 101-182 -- Loss: 0.17901478707790375
train-epoch-step: 101-183 -- Loss: 0.27045345306396484
train-epoch-step: 101-184 -- Loss: 0.13549643754959106
train-epoch-step: 101-185 -- Loss: 0.13810166716575623
train-epoch-step: 101-186 -- Loss: 0.1784549355506897
train-epoch-step: 101-187 -- Loss: 0.20432963967323303
train-epoch-step: 101-188 -- Loss: 0.16673420369625092
train-epoch-step: 101-189 -- Loss: 0.10401926189661026
train-epoch-step: 101-190 -- Loss: 0.18611037731170654
train-epoch-step: 101-191 -- Loss: 0.15489251911640167
train-epoch-step: 101-192 -- Loss: 0.22162273526191711
train-epoch-step: 101-193 -- Loss: 0.1995323896408081
train-epoch-step: 101-194 -- Loss: 0.17874696850776672
train-epoch-step: 101-195 -- Loss: 0.16110000014305115
train-epoch-step: 101-196 -- Loss: 0.16621233522891998
train-epoch-step: 101-197 -- Loss: 0.12243588268756866
train-epoch-step: 101-198 -- Loss: 0.12927931547164917
train-epoch-step: 101-199 -- Loss: 0.14083629846572876
train-epoch-step: 101-200 -- Loss: 0.12058805674314499
train-epoch-step: 101-201 -- Loss: 0.18445143103599548
train-epoch-step: 101-202 -- Loss: 0.13252289593219757
train-epoch-step: 101-203 -- Loss: 0.17740297317504883
train-epoch-step: 101-204 -- Loss: 0.13560304045677185
train-epoch-step: 101-205 -- Loss: 0.17921121418476105
train-epoch-step: 101-206 -- Loss: 0.1925288736820221
train-epoch-step: 101-207 -- Loss: 0.13539712131023407
train-epoch-step: 101-208 -- Loss: 0.17180678248405457
train-epoch-step: 101-209 -- Loss: 0.14144574105739594
train-epoch-step: 101-210 -- Loss: 0.1271003931760788
train-epoch-step: 101-211 -- Loss: 0.19939249753952026
train-epoch-step: 101-212 -- Loss: 0.19326162338256836
train-epoch-step: 101-213 -- Loss: 0.12382030487060547
train-epoch-step: 101-214 -- Loss: 0.14129668474197388
train-epoch-step: 101-215 -- Loss: 0.12740714848041534
train-epoch-step: 101-216 -- Loss: 0.19705398380756378
train-epoch-step: 101-217 -- Loss: 0.22127509117126465
train-epoch-step: 101-218 -- Loss: 0.14374452829360962
train-epoch-step: 101-219 -- Loss: 0.16433024406433105
train-epoch-step: 101-220 -- Loss: 0.12550853192806244
train-epoch-step: 101-221 -- Loss: 0.19722303748130798
train-epoch-step: 101-222 -- Loss: 0.11425165832042694
train-epoch-step: 101-223 -- Loss: 0.16512233018875122
train-epoch-step: 101-224 -- Loss: 0.1906796544790268
train-epoch-step: 101-225 -- Loss: 0.26450076699256897
train-epoch-step: 101-226 -- Loss: 0.20422586798667908
train-epoch-step: 101-227 -- Loss: 0.21862173080444336
train-epoch-step: 101-228 -- Loss: 0.16972239315509796
train-epoch-step: 101-229 -- Loss: 0.16489146649837494
train-epoch-step: 101-230 -- Loss: 0.15681201219558716
train-epoch-step: 101-231 -- Loss: 0.1505889594554901
train-epoch-step: 101-232 -- Loss: 0.18458017706871033
train-epoch-step: 101-233 -- Loss: 0.08168381452560425
train-epoch-step: 101-234 -- Loss: 0.16780222952365875
train-epoch-step: 101-235 -- Loss: 0.14283360540866852
train-epoch-step: 101-236 -- Loss: 0.17321279644966125
train-epoch-step: 101-237 -- Loss: 0.22315266728401184
train-epoch-step: 101-238 -- Loss: 0.15463273227214813
train-epoch-step: 101-239 -- Loss: 0.1217910498380661
train-epoch-step: 101-240 -- Loss: 0.21767553687095642
train-epoch-step: 101-241 -- Loss: 0.1631021797657013
train-epoch-step: 101-242 -- Loss: 0.21290189027786255
train-epoch-step: 101-243 -- Loss: 0.2296997606754303
train-epoch-step: 101-244 -- Loss: 0.20947304368019104
train-epoch-step: 101-245 -- Loss: 0.19962243735790253
train-epoch-step: 101-246 -- Loss: 0.21053443849086761
train-epoch-step: 101-247 -- Loss: 0.20247961580753326
train-epoch-step: 101-248 -- Loss: 0.18218424916267395
train-epoch-step: 101-249 -- Loss: 0.13349087536334991
train-epoch-step: 101-250 -- Loss: 0.19565726816654205
train-epoch-step: 101-251 -- Loss: 0.10093874484300613
train-epoch-step: 101-252 -- Loss: 0.20535509288311005
train-epoch-step: 101-253 -- Loss: 0.1341712325811386
train-epoch-step: 101-254 -- Loss: 0.2106526643037796
train-epoch-step: 101-255 -- Loss: 0.13979823887348175
train-epoch-step: 101-256 -- Loss: 0.14331746101379395
train-epoch-step: 101-257 -- Loss: 0.1813073307275772
train-epoch-step: 101-258 -- Loss: 0.13775968551635742
train-epoch-step: 101-259 -- Loss: 0.10829006880521774
train-epoch-step: 101-260 -- Loss: 0.1921757459640503
train-epoch-step: 101-261 -- Loss: 0.16837367415428162
train-epoch-step: 101-262 -- Loss: 0.27403607964515686
train-epoch-step: 101-263 -- Loss: 0.19003237783908844
train-epoch-step: 101-264 -- Loss: 0.16807976365089417
train-epoch-step: 101-265 -- Loss: 0.10668192058801651
train-epoch-step: 101-266 -- Loss: 0.15060579776763916
train-epoch-step: 101-267 -- Loss: 0.12544755637645721
train-epoch-step: 101-268 -- Loss: 0.11757722496986389
train-epoch-step: 101-269 -- Loss: 0.16901539266109467
train-epoch-step: 101-270 -- Loss: 0.10408413410186768
train-epoch-step: 101-271 -- Loss: 0.14272336661815643
train-epoch-step: 101-272 -- Loss: 0.11247967928647995
train-epoch-step: 101-273 -- Loss: 0.12417125701904297
train-epoch-step: 101-274 -- Loss: 0.19138695299625397
train-epoch-step: 101-275 -- Loss: 0.1945643126964569
train-epoch-step: 101-276 -- Loss: 0.15378418564796448
train-epoch-step: 101-277 -- Loss: 0.1493915170431137
train-epoch-step: 101-278 -- Loss: 0.13334085047245026
train-epoch-step: 101-279 -- Loss: 0.13023723661899567
train-epoch-step: 101-280 -- Loss: 0.20428061485290527
train-epoch-step: 101-281 -- Loss: 0.17420175671577454
train-epoch-step: 101-282 -- Loss: 0.1365668624639511
train-epoch-step: 101-283 -- Loss: 0.11044426262378693
train-epoch-step: 101-284 -- Loss: 0.1333070993423462
train-epoch-step: 101-285 -- Loss: 0.18509244918823242
train-epoch-step: 101-286 -- Loss: 0.14916513860225677
train-epoch-step: 101-287 -- Loss: 0.19575896859169006
train-epoch-step: 101-288 -- Loss: 0.09325055778026581
train-epoch-step: 101-289 -- Loss: 0.11539123952388763
train-epoch-step: 101-290 -- Loss: 0.1747528463602066
train-epoch-step: 101-291 -- Loss: 0.1189214289188385
train-epoch-step: 101-292 -- Loss: 0.1506345123052597
train-epoch-step: 101-293 -- Loss: 0.1332738846540451
train-epoch-step: 101-294 -- Loss: 0.16795888543128967
train-epoch-step: 101-295 -- Loss: 0.2526189982891083
train-epoch-step: 101-296 -- Loss: 0.1549975872039795
train-epoch-step: 101-297 -- Loss: 0.16407302021980286
train-epoch-step: 101-298 -- Loss: 0.22301852703094482
train-epoch-step: 101-299 -- Loss: 0.170704647898674
train-epoch-step: 101-300 -- Loss: 0.1566389799118042
train-epoch-step: 101-301 -- Loss: 0.17808009684085846
train-epoch-step: 101-302 -- Loss: 0.20894737541675568
train-epoch-step: 101-303 -- Loss: 0.23924914002418518
train-epoch-step: 101-304 -- Loss: 0.13181190192699432
train-epoch-step: 101-305 -- Loss: 0.15305665135383606
train-epoch-step: 101-306 -- Loss: 0.23483702540397644
train-epoch-step: 101-307 -- Loss: 0.16426733136177063
train-epoch-step: 101-308 -- Loss: 0.22609010338783264
train-epoch-step: 101-309 -- Loss: 0.15953442454338074
train-epoch-step: 101-310 -- Loss: 0.16287639737129211
train-epoch-step: 101-311 -- Loss: 0.15681469440460205
train-epoch-step: 101-312 -- Loss: 0.236951544880867
train-epoch-step: 101-313 -- Loss: 0.0966942235827446
train-epoch-step: 101-314 -- Loss: 0.19381166994571686
train-epoch-step: 101-315 -- Loss: 0.1663082093000412
train-epoch-step: 101-316 -- Loss: 0.15759694576263428
train-epoch-step: 101-317 -- Loss: 0.13662096858024597
train-epoch-step: 101-318 -- Loss: 0.15807059407234192
train-epoch-step: 101-319 -- Loss: 0.16840018332004547
train-epoch-step: 101-320 -- Loss: 0.11624543368816376
train-epoch-step: 101-321 -- Loss: 0.12636354565620422
train-epoch-step: 101-322 -- Loss: 0.22743818163871765
train-epoch-step: 101-323 -- Loss: 0.1588369905948639
train-epoch-step: 101-324 -- Loss: 0.2579800486564636
train-epoch-step: 101-325 -- Loss: 0.15624278783798218
train-epoch-step: 101-326 -- Loss: 0.1627207100391388
train-epoch-step: 101-327 -- Loss: 0.20049530267715454
train-epoch-step: 101-328 -- Loss: 0.1912163943052292
train-epoch-step: 101-329 -- Loss: 0.3285868167877197
train-epoch-step: 101-330 -- Loss: 0.35963666439056396
train-epoch-step: 101-331 -- Loss: 0.20726457238197327
train-epoch-step: 101-332 -- Loss: 0.10034476220607758
train-epoch-step: 101-333 -- Loss: 0.18760570883750916
train-epoch-step: 101-334 -- Loss: 0.14945779740810394
train-epoch-step: 101-335 -- Loss: 0.1709917187690735
train-epoch-step: 101-336 -- Loss: 0.1505943238735199
train-epoch-step: 101-337 -- Loss: 0.1978386491537094
train-epoch-step: 101-338 -- Loss: 0.1562148779630661
train-epoch-step: 101-339 -- Loss: 0.1558590680360794
train-epoch-step: 101-340 -- Loss: 0.19164052605628967
train-epoch-step: 101-341 -- Loss: 0.13781437277793884
train-epoch-step: 101-342 -- Loss: 0.1567656248807907
train-epoch-step: 101-343 -- Loss: 0.15433061122894287
train-epoch-step: 101-344 -- Loss: 0.15955491364002228
train-epoch-step: 101-345 -- Loss: 0.12205321341753006
train-epoch-step: 101-346 -- Loss: 0.2064424753189087
train-epoch-step: 101-347 -- Loss: 0.14874601364135742
train-epoch-step: 101-348 -- Loss: 0.1970992237329483
train-epoch-step: 101-349 -- Loss: 0.19438716769218445
train-epoch-step: 101-350 -- Loss: 0.26013845205307007
train-epoch-step: 101-351 -- Loss: 0.19101285934448242
train-epoch-step: 101-352 -- Loss: 0.12098442763090134
train-epoch-step: 101-353 -- Loss: 0.19210413098335266
train-epoch-step: 101-354 -- Loss: 0.27195918560028076
train-epoch-step: 101-355 -- Loss: 0.11402294784784317
train-epoch-step: 101-356 -- Loss: 0.11589682102203369
train-epoch-step: 101-357 -- Loss: 0.1819705218076706
train-epoch-step: 101-358 -- Loss: 0.1817171275615692
train-epoch-step: 101-359 -- Loss: 0.13675206899642944
train-epoch-step: 101-360 -- Loss: 0.11931414157152176
train-epoch-step: 101-361 -- Loss: 0.2506745457649231
train-epoch-step: 101-362 -- Loss: 0.17796918749809265
train-epoch-step: 101-363 -- Loss: 0.10916948318481445
train-epoch-step: 101-364 -- Loss: 0.1773015856742859
train-epoch-step: 101-365 -- Loss: 0.1676686853170395
train-epoch-step: 101-366 -- Loss: 0.19100725650787354
train-epoch-step: 101-367 -- Loss: 0.23107224702835083
train-epoch-step: 101-368 -- Loss: 0.19219300150871277
train-epoch-step: 101-369 -- Loss: 0.27056488394737244
train-epoch-step: 101-370 -- Loss: 0.12190801650285721
train-epoch-step: 101-371 -- Loss: 0.12281328439712524
train-epoch-step: 101-372 -- Loss: 0.14452339708805084
train-epoch-step: 101-373 -- Loss: 0.19397607445716858
train-epoch-step: 101-374 -- Loss: 0.15070761740207672
train-epoch-step: 101-375 -- Loss: 0.2558719515800476
train-epoch-step: 101-376 -- Loss: 0.16270673274993896
train-epoch-step: 101-377 -- Loss: 0.2202225923538208
train-epoch-step: 101-378 -- Loss: 0.19205357134342194
train-epoch-step: 101-379 -- Loss: 0.11551080644130707
train-epoch-step: 101-380 -- Loss: 0.08772396296262741
train-epoch-step: 101-381 -- Loss: 0.2395731508731842
train-epoch-step: 101-382 -- Loss: 0.2328159511089325
train-epoch-step: 101-383 -- Loss: 0.17601178586483002
train-epoch-step: 101-384 -- Loss: 0.21070517599582672
train-epoch-step: 101-385 -- Loss: 0.18380838632583618
train-epoch-step: 101-386 -- Loss: 0.18241773545742035
train-epoch-step: 101-387 -- Loss: 0.195397287607193
train-epoch-step: 101-388 -- Loss: 0.17169049382209778
train-epoch-step: 101-389 -- Loss: 0.16200867295265198
train-epoch-step: 101-390 -- Loss: 0.13905322551727295
train-epoch-step: 101-391 -- Loss: 0.14071162045001984
train-epoch-step: 101-392 -- Loss: 0.18186838924884796
train-epoch-step: 101-393 -- Loss: 0.14908932149410248
train-epoch-step: 101-394 -- Loss: 0.19448208808898926
train-epoch-step: 101-395 -- Loss: 0.14972396194934845
train-epoch-step: 101-396 -- Loss: 0.124166339635849
train-epoch-step: 101-397 -- Loss: 0.12072640657424927
train-epoch-step: 101-398 -- Loss: 0.1910891979932785
train-epoch-step: 101-399 -- Loss: 0.17113323509693146
train-epoch-step: 101-400 -- Loss: 0.2673957645893097
train-epoch-step: 101-401 -- Loss: 0.11522141844034195
train-epoch-step: 101-402 -- Loss: 0.25596994161605835
train-epoch-step: 101-403 -- Loss: 0.15329614281654358
train-epoch-step: 101-404 -- Loss: 0.13700449466705322
train-epoch-step: 101-405 -- Loss: 0.1369500458240509
train-epoch-step: 101-406 -- Loss: 0.16136862337589264
train-epoch-step: 101-407 -- Loss: 0.10834822058677673
train-epoch-step: 101-408 -- Loss: 0.15914055705070496
train-epoch-step: 101-409 -- Loss: 0.16333073377609253
train-epoch-step: 101-410 -- Loss: 0.17084407806396484
train-epoch-step: 101-411 -- Loss: 0.19588066637516022
train-epoch-step: 101-412 -- Loss: 0.1231735497713089
train-epoch-step: 101-413 -- Loss: 0.1423950046300888
train-epoch-step: 101-414 -- Loss: 0.12691694498062134
train-epoch-step: 101-415 -- Loss: 0.13037973642349243
train-epoch-step: 101-416 -- Loss: 0.2583073377609253
train-epoch-step: 101-417 -- Loss: 0.18724991381168365
train-epoch-step: 101-418 -- Loss: 0.2570312023162842
train-epoch-step: 101-419 -- Loss: 0.1653287708759308
train-epoch-step: 101-420 -- Loss: 0.15292465686798096
train-epoch-step: 101-421 -- Loss: 0.17499470710754395
train-epoch-step: 101-422 -- Loss: 0.14359024167060852
train-epoch-step: 101-423 -- Loss: 0.17080442607402802
train-epoch-step: 101-424 -- Loss: 0.13625067472457886
train-epoch-step: 101-425 -- Loss: 0.176848366856575
train-epoch-step: 101-426 -- Loss: 0.17012785375118256
train-epoch-step: 101-427 -- Loss: 0.1269453465938568
train-epoch-step: 101-428 -- Loss: 0.207633376121521
train-epoch-step: 101-429 -- Loss: 0.1722496747970581
train-epoch-step: 101-430 -- Loss: 0.13700753450393677
train-epoch-step: 101-431 -- Loss: 0.15769091248512268
train-epoch-step: 101-432 -- Loss: 0.23394504189491272
train-epoch-step: 101-433 -- Loss: 0.13361087441444397
train-epoch-step: 101-434 -- Loss: 0.12250231951475143
train-epoch-step: 101-435 -- Loss: 0.1541336327791214
train-epoch-step: 101-436 -- Loss: 0.1587742269039154
train-epoch-step: 101-437 -- Loss: 0.128945454955101
train-epoch-step: 101-438 -- Loss: 0.162869393825531
train-epoch-step: 101-439 -- Loss: 0.25639742612838745
train-epoch-step: 101-440 -- Loss: 0.12830935418605804
train-epoch-step: 101-441 -- Loss: 0.1940668523311615
train-epoch-step: 101-442 -- Loss: 0.17096878588199615
train-epoch-step: 101-443 -- Loss: 0.15604189038276672
train-epoch-step: 101-444 -- Loss: 0.17658868432044983
train-epoch-step: 101-445 -- Loss: 0.1739480197429657
train-epoch-step: 101-446 -- Loss: 0.14558012783527374
train-epoch-step: 101-447 -- Loss: 0.1816927194595337
train-epoch-step: 101-448 -- Loss: 0.24143126606941223
train-epoch-step: 101-449 -- Loss: 0.18309617042541504
train-epoch-step: 101-450 -- Loss: 0.17385472357273102
train-epoch-step: 101-451 -- Loss: 0.14157985150814056
train-epoch-step: 101-452 -- Loss: 0.1387917548418045
train-epoch-step: 101-453 -- Loss: 0.08753330260515213
train-epoch-step: 101-454 -- Loss: 0.22447414696216583
train-epoch-step: 101-455 -- Loss: 0.12143054604530334
train-epoch-step: 101-456 -- Loss: 0.11500568687915802
train-epoch-step: 101-457 -- Loss: 0.20690320432186127
train-epoch-step: 101-458 -- Loss: 0.1482168436050415
train-epoch-step: 101-459 -- Loss: 0.21442072093486786
train-epoch-step: 101-460 -- Loss: 0.12444110214710236
train-epoch-step: 101-461 -- Loss: 0.13010092079639435
train-epoch-step: 101-462 -- Loss: 0.15177001059055328
train-epoch-step: 101-463 -- Loss: 0.13020935654640198
train-epoch-step: 101-464 -- Loss: 0.15518106520175934
train-epoch-step: 101-465 -- Loss: 0.22883948683738708
train-epoch-step: 101-466 -- Loss: 0.19406470656394958
train-epoch-step: 101-467 -- Loss: 0.10956130921840668
train-epoch-step: 101-468 -- Loss: 0.16299758851528168
train-epoch-step: 101-469 -- Loss: 0.20214706659317017
train-epoch-step: 101-470 -- Loss: 0.1793752759695053
train-epoch-step: 101-471 -- Loss: 0.15210293233394623
train-epoch-step: 101-472 -- Loss: 0.15261802077293396
train-epoch-step: 101-473 -- Loss: 0.15191802382469177
train-epoch-step: 101-474 -- Loss: 0.11932382732629776
train-epoch-step: 101-475 -- Loss: 0.10632976144552231
train-epoch-step: 101-476 -- Loss: 0.19367994368076324
train-epoch-step: 101-477 -- Loss: 0.18972241878509521
train-epoch-step: 101-478 -- Loss: 0.17957203090190887
train-epoch-step: 101-479 -- Loss: 0.13365896046161652
train-epoch-step: 101-480 -- Loss: 0.18776611983776093
train-epoch-step: 101-481 -- Loss: 0.28406500816345215
train-epoch-step: 101-482 -- Loss: 0.2477145493030548
train-epoch-step: 101-483 -- Loss: 0.17430120706558228
train-epoch-step: 101-484 -- Loss: 0.20603184401988983
train-epoch-step: 101-485 -- Loss: 0.12562628090381622
train-epoch-step: 101-486 -- Loss: 0.22148731350898743
train-epoch-step: 101-487 -- Loss: 0.22725042700767517
train-epoch-step: 101-488 -- Loss: 0.17930281162261963
train-epoch-step: 101-489 -- Loss: 0.21240131556987762
train-epoch-step: 101-490 -- Loss: 0.1318012773990631
train-epoch-step: 101-491 -- Loss: 0.13083027303218842
train-epoch-step: 101-492 -- Loss: 0.12246380001306534
train-epoch-step: 101-493 -- Loss: 0.19341807067394257
train-epoch-step: 101-494 -- Loss: 0.1979452669620514
train-epoch-step: 101-495 -- Loss: 0.19488422572612762
train-epoch-step: 101-496 -- Loss: 0.13904881477355957
train-epoch-step: 101-497 -- Loss: 0.17504611611366272
train-epoch-step: 101-498 -- Loss: 0.1453976333141327
train-epoch-step: 101-499 -- Loss: 0.16090205311775208
train-epoch-step: 101-500 -- Loss: 0.14842067658901215
train-epoch-step: 101-501 -- Loss: 0.20798921585083008
train-epoch-step: 101-502 -- Loss: 0.15387830138206482
train-epoch-step: 101-503 -- Loss: 0.20875880122184753
train-epoch-step: 101-504 -- Loss: 0.11749301850795746
train-epoch-step: 101-505 -- Loss: 0.1648988425731659
train-epoch-step: 101-506 -- Loss: 0.11142142117023468
train-epoch-step: 101-507 -- Loss: 0.17665639519691467
train-epoch-step: 101-508 -- Loss: 0.1716976761817932
train-epoch-step: 101-509 -- Loss: 0.16518184542655945
train-epoch-step: 101-510 -- Loss: 0.12782858312129974
train-epoch-step: 101-511 -- Loss: 0.20761947333812714
train-epoch-step: 101-512 -- Loss: 0.1748366802930832
train-epoch-step: 101-513 -- Loss: 0.18587304651737213
train-epoch-step: 101-514 -- Loss: 0.1415065973997116
train-epoch-step: 101-515 -- Loss: 0.14750607311725616
train-epoch-step: 101-516 -- Loss: 0.17543743550777435
train-epoch-step: 101-517 -- Loss: 0.16963036358356476
train-epoch-step: 101-518 -- Loss: 0.13616788387298584
train-epoch-step: 101-519 -- Loss: 0.1308654099702835
train-epoch-step: 101-520 -- Loss: 0.1782650202512741
train-epoch-step: 101-521 -- Loss: 0.22068974375724792
train-epoch-step: 101-522 -- Loss: 0.1768278032541275
train-epoch-step: 101-523 -- Loss: 0.15884163975715637
train-epoch-step: 101-524 -- Loss: 0.1588953733444214
train-epoch-step: 101-525 -- Loss: 0.18590441346168518
train-epoch-step: 101-526 -- Loss: 0.12659254670143127
train-epoch-step: 101-527 -- Loss: 0.14578789472579956
train-epoch-step: 101-528 -- Loss: 0.1504303365945816
train-epoch-step: 101-529 -- Loss: 0.14605100452899933
train-epoch-step: 101-530 -- Loss: 0.16364893317222595
train-epoch-step: 101-531 -- Loss: 0.1950942575931549
train-epoch-step: 101-532 -- Loss: 0.16612109541893005
train-epoch-step: 101-533 -- Loss: 0.16977384686470032
train-epoch-step: 101-534 -- Loss: 0.12584634125232697
train-epoch-step: 101-535 -- Loss: 0.24066300690174103
train-epoch-step: 101-536 -- Loss: 0.1518237441778183
train-epoch-step: 101-537 -- Loss: 0.14145603775978088
train-epoch-step: 101-538 -- Loss: 0.09811475872993469
train-epoch-step: 101-539 -- Loss: 0.1822108030319214
train-epoch-step: 101-540 -- Loss: 0.13406668603420258
train-epoch-step: 101-541 -- Loss: 0.20081022381782532
train-epoch-step: 101-542 -- Loss: 0.21679167449474335
train-epoch-step: 101-543 -- Loss: 0.163789764046669
train-epoch-step: 101-544 -- Loss: 0.21785691380500793
train-epoch-step: 101-545 -- Loss: 0.1881110668182373
train-epoch-step: 101-546 -- Loss: 0.19882267713546753
train-epoch-step: 101-547 -- Loss: 0.1769007444381714
train-epoch-step: 101-548 -- Loss: 0.08798041939735413
train-epoch-step: 101-549 -- Loss: 0.14263896644115448
train-epoch-step: 101-550 -- Loss: 0.19709628820419312
train-epoch-step: 101-551 -- Loss: 0.14834560453891754
train-epoch-step: 101-552 -- Loss: 0.12206810712814331
train-epoch-step: 101-553 -- Loss: 0.18196697533130646
train-epoch-step: 101-554 -- Loss: 0.1784513294696808
train-epoch-step: 101-555 -- Loss: 0.2000054568052292
train-epoch-step: 101-556 -- Loss: 0.13824060559272766
train-epoch-step: 101-557 -- Loss: 0.23129475116729736
train-epoch-step: 101-558 -- Loss: 0.21972337365150452
train-epoch-step: 101-559 -- Loss: 0.1350862681865692
train-epoch-step: 101-560 -- Loss: 0.19760648906230927
train-epoch-step: 101-561 -- Loss: 0.17706944048404694
train-epoch-step: 101-562 -- Loss: 0.15930908918380737
train-epoch-step: 101-563 -- Loss: 0.17630258202552795
train-epoch-step: 101-564 -- Loss: 0.09745226055383682
train-epoch-step: 101-565 -- Loss: 0.17863143980503082
train-epoch-step: 101-566 -- Loss: 0.14473988115787506
train-epoch-step: 101-567 -- Loss: 0.19775675237178802
train-epoch-step: 101-568 -- Loss: 0.1553846150636673
train-epoch-step: 101-569 -- Loss: 0.23749102652072906
train-epoch-step: 101-570 -- Loss: 0.16099929809570312
train-epoch-step: 101-571 -- Loss: 0.20303423702716827
train-epoch-step: 101-572 -- Loss: 0.23096801340579987
train-epoch-step: 101-573 -- Loss: 0.18919111788272858
train-epoch-step: 101-574 -- Loss: 0.23288531601428986
train-epoch-step: 101-575 -- Loss: 0.2799423038959503
train-epoch-step: 101-576 -- Loss: 0.11072304099798203
train-epoch-step: 101-577 -- Loss: 0.15818212926387787
train-epoch-step: 101-578 -- Loss: 0.20627334713935852
train-epoch-step: 101-579 -- Loss: 0.15963703393936157
train-epoch-step: 101-580 -- Loss: 0.16356413066387177
train-epoch-step: 101-581 -- Loss: 0.13206714391708374
train-epoch-step: 101-582 -- Loss: 0.19649536907672882
train-epoch-step: 101-583 -- Loss: 0.2038699984550476
train-epoch-step: 101-584 -- Loss: 0.16835430264472961
train-epoch-step: 101-585 -- Loss: 0.18583840131759644
train-epoch-step: 101-586 -- Loss: 0.24080967903137207
train-epoch-step: 101-587 -- Loss: 0.15503214299678802
train-epoch-step: 101-588 -- Loss: 0.12466660141944885
val-epoch-step: 101-589 -- Loss: 0.2081713080406189
val-epoch-step: 101-590 -- Loss: 0.14834322035312653
val-epoch-step: 101-591 -- Loss: 0.23440435528755188
val-epoch-step: 101-592 -- Loss: 0.16926106810569763
val-epoch-step: 101-593 -- Loss: 0.15921100974082947
val-epoch-step: 101-594 -- Loss: 0.35077038407325745
val-epoch-step: 101-595 -- Loss: 0.174363374710083
val-epoch-step: 101-596 -- Loss: 0.20689430832862854
val-epoch-step: 101-597 -- Loss: 0.1677682250738144
val-epoch-step: 101-598 -- Loss: 0.14814914762973785
val-epoch-step: 101-599 -- Loss: 0.17936140298843384
val-epoch-step: 101-600 -- Loss: 0.1720658838748932
val-epoch-step: 101-601 -- Loss: 0.1499841958284378
val-epoch-step: 101-602 -- Loss: 0.1370251327753067
val-epoch-step: 101-603 -- Loss: 0.20536890625953674
val-epoch-step: 101-604 -- Loss: 0.14527305960655212
val-epoch-step: 101-605 -- Loss: 0.14461123943328857
val-epoch-step: 101-606 -- Loss: 0.35842621326446533
val-epoch-step: 101-607 -- Loss: 0.12270719558000565
val-epoch-step: 101-608 -- Loss: 0.24483583867549896
val-epoch-step: 101-609 -- Loss: 0.16063326597213745
val-epoch-step: 101-610 -- Loss: 0.17395493388175964
val-epoch-step: 101-611 -- Loss: 0.1586536318063736
val-epoch-step: 101-612 -- Loss: 0.4693129062652588
val-epoch-step: 101-613 -- Loss: 0.17011921107769012
val-epoch-step: 101-614 -- Loss: 0.1647086888551712
val-epoch-step: 101-615 -- Loss: 0.1706046164035797
val-epoch-step: 101-616 -- Loss: 0.14645721018314362
val-epoch-step: 101-617 -- Loss: 0.1923292577266693
val-epoch-step: 101-618 -- Loss: 0.1738337278366089
val-epoch-step: 101-619 -- Loss: 0.20249402523040771
val-epoch-step: 101-620 -- Loss: 0.13032889366149902
val-epoch-step: 101-621 -- Loss: 0.1263347864151001
val-epoch-step: 101-622 -- Loss: 0.14207404851913452
val-epoch-step: 101-623 -- Loss: 0.14597634971141815
val-epoch-step: 101-624 -- Loss: 0.13968080282211304
val-epoch-step: 101-625 -- Loss: 0.15451985597610474
val-epoch-step: 101-626 -- Loss: 0.1448032706975937
val-epoch-step: 101-627 -- Loss: 0.18233396112918854
val-epoch-step: 101-628 -- Loss: 0.4348156452178955
val-epoch-step: 101-629 -- Loss: 0.22270634770393372
val-epoch-step: 101-630 -- Loss: 0.3416122794151306
val-epoch-step: 101-631 -- Loss: 0.14751195907592773
val-epoch-step: 101-632 -- Loss: 0.19112180173397064
val-epoch-step: 101-633 -- Loss: 0.15504437685012817
val-epoch-step: 101-634 -- Loss: 0.1501433253288269
val-epoch-step: 101-635 -- Loss: 0.11144241690635681
val-epoch-step: 101-636 -- Loss: 0.16310547292232513
val-epoch-step: 101-637 -- Loss: 0.17649316787719727
val-epoch-step: 101-638 -- Loss: 0.1524735987186432
val-epoch-step: 101-639 -- Loss: 0.2571507692337036
val-epoch-step: 101-640 -- Loss: 0.25314539670944214
val-epoch-step: 101-641 -- Loss: 0.1249159425497055
val-epoch-step: 101-642 -- Loss: 0.1753428876399994
val-epoch-step: 101-643 -- Loss: 0.19967228174209595
val-epoch-step: 101-644 -- Loss: 0.16582946479320526
val-epoch-step: 101-645 -- Loss: 0.2161611020565033
val-epoch-step: 101-646 -- Loss: 0.13062305748462677
val-epoch-step: 101-647 -- Loss: 0.12368656694889069
val-epoch-step: 101-648 -- Loss: 0.14791589975357056
val-epoch-step: 101-649 -- Loss: 0.20611515641212463
val-epoch-step: 101-650 -- Loss: 0.2508352994918823
val-epoch-step: 101-651 -- Loss: 0.14315280318260193
val-epoch-step: 101-652 -- Loss: 0.15071016550064087
val-epoch-step: 101-653 -- Loss: 0.1976926624774933
val-epoch-step: 101-654 -- Loss: 0.10938341915607452
Epoch: 101 -- Train Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 102-0 -- Loss: 0.21484428644180298
train-epoch-step: 102-1 -- Loss: 0.14080838859081268
train-epoch-step: 102-2 -- Loss: 0.1915387660264969
train-epoch-step: 102-3 -- Loss: 0.13589322566986084
train-epoch-step: 102-4 -- Loss: 0.15452316403388977
train-epoch-step: 102-5 -- Loss: 0.17318256199359894
train-epoch-step: 102-6 -- Loss: 0.20464691519737244
train-epoch-step: 102-7 -- Loss: 0.16022257506847382
train-epoch-step: 102-8 -- Loss: 0.16873912513256073
train-epoch-step: 102-9 -- Loss: 0.2199588268995285
train-epoch-step: 102-10 -- Loss: 0.17902600765228271
train-epoch-step: 102-11 -- Loss: 0.17417171597480774
train-epoch-step: 102-12 -- Loss: 0.14322347939014435
train-epoch-step: 102-13 -- Loss: 0.16957105696201324
train-epoch-step: 102-14 -- Loss: 0.15646055340766907
train-epoch-step: 102-15 -- Loss: 0.15562954545021057
train-epoch-step: 102-16 -- Loss: 0.16094642877578735
train-epoch-step: 102-17 -- Loss: 0.22631891071796417
train-epoch-step: 102-18 -- Loss: 0.18302714824676514
train-epoch-step: 102-19 -- Loss: 0.1276031732559204
train-epoch-step: 102-20 -- Loss: 0.2044660747051239
train-epoch-step: 102-21 -- Loss: 0.23511621356010437
train-epoch-step: 102-22 -- Loss: 0.13383233547210693
train-epoch-step: 102-23 -- Loss: 0.13698838651180267
train-epoch-step: 102-24 -- Loss: 0.12076989561319351
train-epoch-step: 102-25 -- Loss: 0.21663308143615723
train-epoch-step: 102-26 -- Loss: 0.18560181558132172
train-epoch-step: 102-27 -- Loss: 0.21813298761844635
train-epoch-step: 102-28 -- Loss: 0.11950287967920303
train-epoch-step: 102-29 -- Loss: 0.2341519296169281
train-epoch-step: 102-30 -- Loss: 0.1055879220366478
train-epoch-step: 102-31 -- Loss: 0.12881451845169067
train-epoch-step: 102-32 -- Loss: 0.1689026653766632
train-epoch-step: 102-33 -- Loss: 0.2697407007217407
train-epoch-step: 102-34 -- Loss: 0.16363133490085602
train-epoch-step: 102-35 -- Loss: 0.23739546537399292
train-epoch-step: 102-36 -- Loss: 0.1342582106590271
train-epoch-step: 102-37 -- Loss: 0.13090215623378754
train-epoch-step: 102-38 -- Loss: 0.1713722050189972
train-epoch-step: 102-39 -- Loss: 0.21558831632137299
train-epoch-step: 102-40 -- Loss: 0.187301367521286
train-epoch-step: 102-41 -- Loss: 0.2099209427833557
train-epoch-step: 102-42 -- Loss: 0.14195363223552704
train-epoch-step: 102-43 -- Loss: 0.24868243932724
train-epoch-step: 102-44 -- Loss: 0.1212034597992897
train-epoch-step: 102-45 -- Loss: 0.10924872756004333
train-epoch-step: 102-46 -- Loss: 0.16404174268245697
train-epoch-step: 102-47 -- Loss: 0.1891252100467682
train-epoch-step: 102-48 -- Loss: 0.14714552462100983
train-epoch-step: 102-49 -- Loss: 0.21566851437091827
train-epoch-step: 102-50 -- Loss: 0.10688978433609009
train-epoch-step: 102-51 -- Loss: 0.17523497343063354
train-epoch-step: 102-52 -- Loss: 0.15287920832633972
train-epoch-step: 102-53 -- Loss: 0.20098239183425903
train-epoch-step: 102-54 -- Loss: 0.2765887975692749
train-epoch-step: 102-55 -- Loss: 0.15714333951473236
train-epoch-step: 102-56 -- Loss: 0.17151597142219543
train-epoch-step: 102-57 -- Loss: 0.22949659824371338
train-epoch-step: 102-58 -- Loss: 0.27985382080078125
train-epoch-step: 102-59 -- Loss: 0.22818224132061005
train-epoch-step: 102-60 -- Loss: 0.12459118664264679
train-epoch-step: 102-61 -- Loss: 0.19744765758514404
train-epoch-step: 102-62 -- Loss: 0.17741142213344574
train-epoch-step: 102-63 -- Loss: 0.13111194968223572
train-epoch-step: 102-64 -- Loss: 0.13915227353572845
train-epoch-step: 102-65 -- Loss: 0.1703481674194336
train-epoch-step: 102-66 -- Loss: 0.10823839902877808
train-epoch-step: 102-67 -- Loss: 0.11880351603031158
train-epoch-step: 102-68 -- Loss: 0.2052127867937088
train-epoch-step: 102-69 -- Loss: 0.11684519797563553
train-epoch-step: 102-70 -- Loss: 0.23576730489730835
train-epoch-step: 102-71 -- Loss: 0.2503047287464142
train-epoch-step: 102-72 -- Loss: 0.16579656302928925
train-epoch-step: 102-73 -- Loss: 0.19807104766368866
train-epoch-step: 102-74 -- Loss: 0.09227778017520905
train-epoch-step: 102-75 -- Loss: 0.12534554302692413
train-epoch-step: 102-76 -- Loss: 0.1418931931257248
train-epoch-step: 102-77 -- Loss: 0.22488202154636383
train-epoch-step: 102-78 -- Loss: 0.26321592926979065
train-epoch-step: 102-79 -- Loss: 0.1887287050485611
train-epoch-step: 102-80 -- Loss: 0.31149259209632874
train-epoch-step: 102-81 -- Loss: 0.12324173748493195
train-epoch-step: 102-82 -- Loss: 0.2441384196281433
train-epoch-step: 102-83 -- Loss: 0.17489886283874512
train-epoch-step: 102-84 -- Loss: 0.19713199138641357
train-epoch-step: 102-85 -- Loss: 0.1747608482837677
train-epoch-step: 102-86 -- Loss: 0.12927787005901337
train-epoch-step: 102-87 -- Loss: 0.22492049634456635
train-epoch-step: 102-88 -- Loss: 0.13705331087112427
train-epoch-step: 102-89 -- Loss: 0.20312365889549255
train-epoch-step: 102-90 -- Loss: 0.1918652057647705
train-epoch-step: 102-91 -- Loss: 0.26407405734062195
train-epoch-step: 102-92 -- Loss: 0.15060675144195557
train-epoch-step: 102-93 -- Loss: 0.26163917779922485
train-epoch-step: 102-94 -- Loss: 0.2394774854183197
train-epoch-step: 102-95 -- Loss: 0.20226448774337769
train-epoch-step: 102-96 -- Loss: 0.22168828547000885
train-epoch-step: 102-97 -- Loss: 0.17768946290016174
train-epoch-step: 102-98 -- Loss: 0.15813396871089935
train-epoch-step: 102-99 -- Loss: 0.20012369751930237
train-epoch-step: 102-100 -- Loss: 0.23216891288757324
train-epoch-step: 102-101 -- Loss: 0.27063751220703125
train-epoch-step: 102-102 -- Loss: 0.2388359159231186
train-epoch-step: 102-103 -- Loss: 0.20213550329208374
train-epoch-step: 102-104 -- Loss: 0.15223485231399536
train-epoch-step: 102-105 -- Loss: 0.2808580994606018
train-epoch-step: 102-106 -- Loss: 0.1755853295326233
train-epoch-step: 102-107 -- Loss: 0.1887476146221161
train-epoch-step: 102-108 -- Loss: 0.21415361762046814
train-epoch-step: 102-109 -- Loss: 0.14288072288036346
train-epoch-step: 102-110 -- Loss: 0.1791847050189972
train-epoch-step: 102-111 -- Loss: 0.1879076361656189
train-epoch-step: 102-112 -- Loss: 0.16748282313346863
train-epoch-step: 102-113 -- Loss: 0.17741931974887848
train-epoch-step: 102-114 -- Loss: 0.1917424499988556
train-epoch-step: 102-115 -- Loss: 0.1623496413230896
train-epoch-step: 102-116 -- Loss: 0.1415473222732544
train-epoch-step: 102-117 -- Loss: 0.12495795637369156
train-epoch-step: 102-118 -- Loss: 0.1954532414674759
train-epoch-step: 102-119 -- Loss: 0.15207472443580627
train-epoch-step: 102-120 -- Loss: 0.248340904712677
train-epoch-step: 102-121 -- Loss: 0.23680853843688965
train-epoch-step: 102-122 -- Loss: 0.21626079082489014
train-epoch-step: 102-123 -- Loss: 0.19916824996471405
train-epoch-step: 102-124 -- Loss: 0.12386129796504974
train-epoch-step: 102-125 -- Loss: 0.1522614061832428
train-epoch-step: 102-126 -- Loss: 0.23312973976135254
train-epoch-step: 102-127 -- Loss: 0.17758354544639587
train-epoch-step: 102-128 -- Loss: 0.1670059859752655
train-epoch-step: 102-129 -- Loss: 0.1465529054403305
train-epoch-step: 102-130 -- Loss: 0.19555920362472534
train-epoch-step: 102-131 -- Loss: 0.1396389603614807
train-epoch-step: 102-132 -- Loss: 0.1838042438030243
train-epoch-step: 102-133 -- Loss: 0.11306598037481308
train-epoch-step: 102-134 -- Loss: 0.20398391783237457
train-epoch-step: 102-135 -- Loss: 0.13764899969100952
train-epoch-step: 102-136 -- Loss: 0.13358542323112488
train-epoch-step: 102-137 -- Loss: 0.239772230386734
train-epoch-step: 102-138 -- Loss: 0.254357248544693
train-epoch-step: 102-139 -- Loss: 0.1293378472328186
train-epoch-step: 102-140 -- Loss: 0.2252301126718521
train-epoch-step: 102-141 -- Loss: 0.2415052056312561
train-epoch-step: 102-142 -- Loss: 0.20010554790496826
train-epoch-step: 102-143 -- Loss: 0.17160062491893768
train-epoch-step: 102-144 -- Loss: 0.1800796538591385
train-epoch-step: 102-145 -- Loss: 0.13960164785385132
train-epoch-step: 102-146 -- Loss: 0.1716407686471939
train-epoch-step: 102-147 -- Loss: 0.16435301303863525
train-epoch-step: 102-148 -- Loss: 0.16006293892860413
train-epoch-step: 102-149 -- Loss: 0.12030278146266937
train-epoch-step: 102-150 -- Loss: 0.18647423386573792
train-epoch-step: 102-151 -- Loss: 0.18586444854736328
train-epoch-step: 102-152 -- Loss: 0.18843360245227814
train-epoch-step: 102-153 -- Loss: 0.26966872811317444
train-epoch-step: 102-154 -- Loss: 0.13321076333522797
train-epoch-step: 102-155 -- Loss: 0.13351526856422424
train-epoch-step: 102-156 -- Loss: 0.11728306114673615
train-epoch-step: 102-157 -- Loss: 0.16854284703731537
train-epoch-step: 102-158 -- Loss: 0.16361582279205322
train-epoch-step: 102-159 -- Loss: 0.17680777609348297
train-epoch-step: 102-160 -- Loss: 0.22635531425476074
train-epoch-step: 102-161 -- Loss: 0.19873963296413422
train-epoch-step: 102-162 -- Loss: 0.20469331741333008
train-epoch-step: 102-163 -- Loss: 0.18154433369636536
train-epoch-step: 102-164 -- Loss: 0.1919289380311966
train-epoch-step: 102-165 -- Loss: 0.16009974479675293
train-epoch-step: 102-166 -- Loss: 0.11731354892253876
train-epoch-step: 102-167 -- Loss: 0.11880654096603394
train-epoch-step: 102-168 -- Loss: 0.19700035452842712
train-epoch-step: 102-169 -- Loss: 0.13742901384830475
train-epoch-step: 102-170 -- Loss: 0.19434016942977905
train-epoch-step: 102-171 -- Loss: 0.14069342613220215
train-epoch-step: 102-172 -- Loss: 0.25282108783721924
train-epoch-step: 102-173 -- Loss: 0.1293724924325943
train-epoch-step: 102-174 -- Loss: 0.23943299055099487
train-epoch-step: 102-175 -- Loss: 0.18444031476974487
train-epoch-step: 102-176 -- Loss: 0.13186293840408325
train-epoch-step: 102-177 -- Loss: 0.17475803196430206
train-epoch-step: 102-178 -- Loss: 0.1715203821659088
train-epoch-step: 102-179 -- Loss: 0.13738217949867249
train-epoch-step: 102-180 -- Loss: 0.15057477355003357
train-epoch-step: 102-181 -- Loss: 0.1748127043247223
train-epoch-step: 102-182 -- Loss: 0.19159279763698578
train-epoch-step: 102-183 -- Loss: 0.2603757977485657
train-epoch-step: 102-184 -- Loss: 0.13783025741577148
train-epoch-step: 102-185 -- Loss: 0.1415613293647766
train-epoch-step: 102-186 -- Loss: 0.191826730966568
train-epoch-step: 102-187 -- Loss: 0.20892488956451416
train-epoch-step: 102-188 -- Loss: 0.171669602394104
train-epoch-step: 102-189 -- Loss: 0.1026366725564003
train-epoch-step: 102-190 -- Loss: 0.17905499041080475
train-epoch-step: 102-191 -- Loss: 0.16484886407852173
train-epoch-step: 102-192 -- Loss: 0.22784514725208282
train-epoch-step: 102-193 -- Loss: 0.2085322141647339
train-epoch-step: 102-194 -- Loss: 0.1836751103401184
train-epoch-step: 102-195 -- Loss: 0.17203153669834137
train-epoch-step: 102-196 -- Loss: 0.1700952649116516
train-epoch-step: 102-197 -- Loss: 0.1445821225643158
train-epoch-step: 102-198 -- Loss: 0.1264997273683548
train-epoch-step: 102-199 -- Loss: 0.14684611558914185
train-epoch-step: 102-200 -- Loss: 0.11933379620313644
train-epoch-step: 102-201 -- Loss: 0.18645213544368744
train-epoch-step: 102-202 -- Loss: 0.13286778330802917
train-epoch-step: 102-203 -- Loss: 0.1734275072813034
train-epoch-step: 102-204 -- Loss: 0.1328141689300537
train-epoch-step: 102-205 -- Loss: 0.19232991337776184
train-epoch-step: 102-206 -- Loss: 0.19682198762893677
train-epoch-step: 102-207 -- Loss: 0.131588414311409
train-epoch-step: 102-208 -- Loss: 0.1755203902721405
train-epoch-step: 102-209 -- Loss: 0.1423189640045166
train-epoch-step: 102-210 -- Loss: 0.1288713663816452
train-epoch-step: 102-211 -- Loss: 0.2150241732597351
train-epoch-step: 102-212 -- Loss: 0.2005259096622467
train-epoch-step: 102-213 -- Loss: 0.12517303228378296
train-epoch-step: 102-214 -- Loss: 0.1437608301639557
train-epoch-step: 102-215 -- Loss: 0.12406714260578156
train-epoch-step: 102-216 -- Loss: 0.1948605626821518
train-epoch-step: 102-217 -- Loss: 0.20584139227867126
train-epoch-step: 102-218 -- Loss: 0.14932169020175934
train-epoch-step: 102-219 -- Loss: 0.1628251075744629
train-epoch-step: 102-220 -- Loss: 0.12464601546525955
train-epoch-step: 102-221 -- Loss: 0.20677702128887177
train-epoch-step: 102-222 -- Loss: 0.11697237193584442
train-epoch-step: 102-223 -- Loss: 0.16585810482501984
train-epoch-step: 102-224 -- Loss: 0.18609505891799927
train-epoch-step: 102-225 -- Loss: 0.25695493817329407
train-epoch-step: 102-226 -- Loss: 0.2032330334186554
train-epoch-step: 102-227 -- Loss: 0.2174283266067505
train-epoch-step: 102-228 -- Loss: 0.17287996411323547
train-epoch-step: 102-229 -- Loss: 0.16624346375465393
train-epoch-step: 102-230 -- Loss: 0.16001930832862854
train-epoch-step: 102-231 -- Loss: 0.15150152146816254
train-epoch-step: 102-232 -- Loss: 0.17910724878311157
train-epoch-step: 102-233 -- Loss: 0.08238019049167633
train-epoch-step: 102-234 -- Loss: 0.1653788983821869
train-epoch-step: 102-235 -- Loss: 0.142621248960495
train-epoch-step: 102-236 -- Loss: 0.1765100508928299
train-epoch-step: 102-237 -- Loss: 0.22259247303009033
train-epoch-step: 102-238 -- Loss: 0.16059330105781555
train-epoch-step: 102-239 -- Loss: 0.12776929140090942
train-epoch-step: 102-240 -- Loss: 0.22200164198875427
train-epoch-step: 102-241 -- Loss: 0.1516001671552658
train-epoch-step: 102-242 -- Loss: 0.21354898810386658
train-epoch-step: 102-243 -- Loss: 0.2261589765548706
train-epoch-step: 102-244 -- Loss: 0.19962960481643677
train-epoch-step: 102-245 -- Loss: 0.19987516105175018
train-epoch-step: 102-246 -- Loss: 0.21074900031089783
train-epoch-step: 102-247 -- Loss: 0.20229795575141907
train-epoch-step: 102-248 -- Loss: 0.18552902340888977
train-epoch-step: 102-249 -- Loss: 0.13621404767036438
train-epoch-step: 102-250 -- Loss: 0.22620002925395966
train-epoch-step: 102-251 -- Loss: 0.10195428133010864
train-epoch-step: 102-252 -- Loss: 0.19157174229621887
train-epoch-step: 102-253 -- Loss: 0.1342974603176117
train-epoch-step: 102-254 -- Loss: 0.21035322546958923
train-epoch-step: 102-255 -- Loss: 0.1408732682466507
train-epoch-step: 102-256 -- Loss: 0.15042394399642944
train-epoch-step: 102-257 -- Loss: 0.19119466841220856
train-epoch-step: 102-258 -- Loss: 0.14351235330104828
train-epoch-step: 102-259 -- Loss: 0.11380766332149506
train-epoch-step: 102-260 -- Loss: 0.193573996424675
train-epoch-step: 102-261 -- Loss: 0.17208537459373474
train-epoch-step: 102-262 -- Loss: 0.28981369733810425
train-epoch-step: 102-263 -- Loss: 0.1964571177959442
train-epoch-step: 102-264 -- Loss: 0.17531956732273102
train-epoch-step: 102-265 -- Loss: 0.11808010190725327
train-epoch-step: 102-266 -- Loss: 0.14980000257492065
train-epoch-step: 102-267 -- Loss: 0.12809394299983978
train-epoch-step: 102-268 -- Loss: 0.11341012269258499
train-epoch-step: 102-269 -- Loss: 0.1682235598564148
train-epoch-step: 102-270 -- Loss: 0.10772047936916351
train-epoch-step: 102-271 -- Loss: 0.14248482882976532
train-epoch-step: 102-272 -- Loss: 0.12272123247385025
train-epoch-step: 102-273 -- Loss: 0.12276360392570496
train-epoch-step: 102-274 -- Loss: 0.17943067848682404
train-epoch-step: 102-275 -- Loss: 0.19521071016788483
train-epoch-step: 102-276 -- Loss: 0.15069738030433655
train-epoch-step: 102-277 -- Loss: 0.15316471457481384
train-epoch-step: 102-278 -- Loss: 0.13398009538650513
train-epoch-step: 102-279 -- Loss: 0.13460443913936615
train-epoch-step: 102-280 -- Loss: 0.22384721040725708
train-epoch-step: 102-281 -- Loss: 0.17214149236679077
train-epoch-step: 102-282 -- Loss: 0.13643288612365723
train-epoch-step: 102-283 -- Loss: 0.11633245646953583
train-epoch-step: 102-284 -- Loss: 0.15677648782730103
train-epoch-step: 102-285 -- Loss: 0.19371460378170013
train-epoch-step: 102-286 -- Loss: 0.14846162497997284
train-epoch-step: 102-287 -- Loss: 0.20342229306697845
train-epoch-step: 102-288 -- Loss: 0.09260761737823486
train-epoch-step: 102-289 -- Loss: 0.11546047031879425
train-epoch-step: 102-290 -- Loss: 0.18705956637859344
train-epoch-step: 102-291 -- Loss: 0.11580604314804077
train-epoch-step: 102-292 -- Loss: 0.15594714879989624
train-epoch-step: 102-293 -- Loss: 0.13294488191604614
train-epoch-step: 102-294 -- Loss: 0.15593695640563965
train-epoch-step: 102-295 -- Loss: 0.2620302438735962
train-epoch-step: 102-296 -- Loss: 0.15406714379787445
train-epoch-step: 102-297 -- Loss: 0.16709734499454498
train-epoch-step: 102-298 -- Loss: 0.22515304386615753
train-epoch-step: 102-299 -- Loss: 0.14137619733810425
train-epoch-step: 102-300 -- Loss: 0.16115957498550415
train-epoch-step: 102-301 -- Loss: 0.17932844161987305
train-epoch-step: 102-302 -- Loss: 0.2129921019077301
train-epoch-step: 102-303 -- Loss: 0.1947474181652069
train-epoch-step: 102-304 -- Loss: 0.12915806472301483
train-epoch-step: 102-305 -- Loss: 0.1424085944890976
train-epoch-step: 102-306 -- Loss: 0.20963169634342194
train-epoch-step: 102-307 -- Loss: 0.16335614025592804
train-epoch-step: 102-308 -- Loss: 0.2123171091079712
train-epoch-step: 102-309 -- Loss: 0.15016146004199982
train-epoch-step: 102-310 -- Loss: 0.1655167192220688
train-epoch-step: 102-311 -- Loss: 0.1587875485420227
train-epoch-step: 102-312 -- Loss: 0.1972825527191162
train-epoch-step: 102-313 -- Loss: 0.0962742492556572
train-epoch-step: 102-314 -- Loss: 0.18349476158618927
train-epoch-step: 102-315 -- Loss: 0.1677159070968628
train-epoch-step: 102-316 -- Loss: 0.15303826332092285
train-epoch-step: 102-317 -- Loss: 0.13586631417274475
train-epoch-step: 102-318 -- Loss: 0.1546756476163864
train-epoch-step: 102-319 -- Loss: 0.1647070199251175
train-epoch-step: 102-320 -- Loss: 0.11221157014369965
train-epoch-step: 102-321 -- Loss: 0.13093127310276031
train-epoch-step: 102-322 -- Loss: 0.21069090068340302
train-epoch-step: 102-323 -- Loss: 0.1766107827425003
train-epoch-step: 102-324 -- Loss: 0.2519408166408539
train-epoch-step: 102-325 -- Loss: 0.15266160666942596
train-epoch-step: 102-326 -- Loss: 0.1686399281024933
train-epoch-step: 102-327 -- Loss: 0.1996099054813385
train-epoch-step: 102-328 -- Loss: 0.18264631927013397
train-epoch-step: 102-329 -- Loss: 0.3266235589981079
train-epoch-step: 102-330 -- Loss: 0.3473004996776581
train-epoch-step: 102-331 -- Loss: 0.19775713980197906
train-epoch-step: 102-332 -- Loss: 0.09473100304603577
train-epoch-step: 102-333 -- Loss: 0.18368841707706451
train-epoch-step: 102-334 -- Loss: 0.1493636518716812
train-epoch-step: 102-335 -- Loss: 0.1750921905040741
train-epoch-step: 102-336 -- Loss: 0.1441282033920288
train-epoch-step: 102-337 -- Loss: 0.19871270656585693
train-epoch-step: 102-338 -- Loss: 0.15650762617588043
train-epoch-step: 102-339 -- Loss: 0.14617320895195007
train-epoch-step: 102-340 -- Loss: 0.1917571872472763
train-epoch-step: 102-341 -- Loss: 0.13695546984672546
train-epoch-step: 102-342 -- Loss: 0.1581069827079773
train-epoch-step: 102-343 -- Loss: 0.14871945977210999
train-epoch-step: 102-344 -- Loss: 0.16731205582618713
train-epoch-step: 102-345 -- Loss: 0.1485634446144104
train-epoch-step: 102-346 -- Loss: 0.204462930560112
train-epoch-step: 102-347 -- Loss: 0.14893211424350739
train-epoch-step: 102-348 -- Loss: 0.19757667183876038
train-epoch-step: 102-349 -- Loss: 0.20114466547966003
train-epoch-step: 102-350 -- Loss: 0.2732004225254059
train-epoch-step: 102-351 -- Loss: 0.1862822324037552
train-epoch-step: 102-352 -- Loss: 0.11847279965877533
train-epoch-step: 102-353 -- Loss: 0.1881064474582672
train-epoch-step: 102-354 -- Loss: 0.2734043002128601
train-epoch-step: 102-355 -- Loss: 0.11635306477546692
train-epoch-step: 102-356 -- Loss: 0.11721155047416687
train-epoch-step: 102-357 -- Loss: 0.19029945135116577
train-epoch-step: 102-358 -- Loss: 0.18103286623954773
train-epoch-step: 102-359 -- Loss: 0.13809949159622192
train-epoch-step: 102-360 -- Loss: 0.12493250519037247
train-epoch-step: 102-361 -- Loss: 0.23480695486068726
train-epoch-step: 102-362 -- Loss: 0.1645708829164505
train-epoch-step: 102-363 -- Loss: 0.1061072126030922
train-epoch-step: 102-364 -- Loss: 0.171830952167511
train-epoch-step: 102-365 -- Loss: 0.16694001853466034
train-epoch-step: 102-366 -- Loss: 0.19720782339572906
train-epoch-step: 102-367 -- Loss: 0.22562646865844727
train-epoch-step: 102-368 -- Loss: 0.19199486076831818
train-epoch-step: 102-369 -- Loss: 0.2748120427131653
train-epoch-step: 102-370 -- Loss: 0.12067294120788574
train-epoch-step: 102-371 -- Loss: 0.11593962460756302
train-epoch-step: 102-372 -- Loss: 0.1407507061958313
train-epoch-step: 102-373 -- Loss: 0.18622982501983643
train-epoch-step: 102-374 -- Loss: 0.14737474918365479
train-epoch-step: 102-375 -- Loss: 0.26096081733703613
train-epoch-step: 102-376 -- Loss: 0.16038601100444794
train-epoch-step: 102-377 -- Loss: 0.22290784120559692
train-epoch-step: 102-378 -- Loss: 0.19260664284229279
train-epoch-step: 102-379 -- Loss: 0.11799054592847824
train-epoch-step: 102-380 -- Loss: 0.0895659476518631
train-epoch-step: 102-381 -- Loss: 0.23953017592430115
train-epoch-step: 102-382 -- Loss: 0.23316450417041779
train-epoch-step: 102-383 -- Loss: 0.17548277974128723
train-epoch-step: 102-384 -- Loss: 0.21222802996635437
train-epoch-step: 102-385 -- Loss: 0.18392314016819
train-epoch-step: 102-386 -- Loss: 0.1839815378189087
train-epoch-step: 102-387 -- Loss: 0.19576185941696167
train-epoch-step: 102-388 -- Loss: 0.18364986777305603
train-epoch-step: 102-389 -- Loss: 0.16158469021320343
train-epoch-step: 102-390 -- Loss: 0.14360839128494263
train-epoch-step: 102-391 -- Loss: 0.14251726865768433
train-epoch-step: 102-392 -- Loss: 0.17878283560276031
train-epoch-step: 102-393 -- Loss: 0.15143129229545593
train-epoch-step: 102-394 -- Loss: 0.18706771731376648
train-epoch-step: 102-395 -- Loss: 0.1488618552684784
train-epoch-step: 102-396 -- Loss: 0.12162043899297714
train-epoch-step: 102-397 -- Loss: 0.12100426852703094
train-epoch-step: 102-398 -- Loss: 0.1917579472064972
train-epoch-step: 102-399 -- Loss: 0.1669534295797348
train-epoch-step: 102-400 -- Loss: 0.28045251965522766
train-epoch-step: 102-401 -- Loss: 0.11821183562278748
train-epoch-step: 102-402 -- Loss: 0.2550363838672638
train-epoch-step: 102-403 -- Loss: 0.15130895376205444
train-epoch-step: 102-404 -- Loss: 0.13539573550224304
train-epoch-step: 102-405 -- Loss: 0.13850665092468262
train-epoch-step: 102-406 -- Loss: 0.15964630246162415
train-epoch-step: 102-407 -- Loss: 0.1102309301495552
train-epoch-step: 102-408 -- Loss: 0.15934479236602783
train-epoch-step: 102-409 -- Loss: 0.16682308912277222
train-epoch-step: 102-410 -- Loss: 0.16990044713020325
train-epoch-step: 102-411 -- Loss: 0.18983036279678345
train-epoch-step: 102-412 -- Loss: 0.1261206567287445
train-epoch-step: 102-413 -- Loss: 0.1417928785085678
train-epoch-step: 102-414 -- Loss: 0.1278330534696579
train-epoch-step: 102-415 -- Loss: 0.1303294450044632
train-epoch-step: 102-416 -- Loss: 0.2573164105415344
train-epoch-step: 102-417 -- Loss: 0.18374735116958618
train-epoch-step: 102-418 -- Loss: 0.22038206458091736
train-epoch-step: 102-419 -- Loss: 0.16016167402267456
train-epoch-step: 102-420 -- Loss: 0.15281035006046295
train-epoch-step: 102-421 -- Loss: 0.175596684217453
train-epoch-step: 102-422 -- Loss: 0.1451534479856491
train-epoch-step: 102-423 -- Loss: 0.1658031940460205
train-epoch-step: 102-424 -- Loss: 0.1334868222475052
train-epoch-step: 102-425 -- Loss: 0.17628586292266846
train-epoch-step: 102-426 -- Loss: 0.16181041300296783
train-epoch-step: 102-427 -- Loss: 0.11683446168899536
train-epoch-step: 102-428 -- Loss: 0.19285911321640015
train-epoch-step: 102-429 -- Loss: 0.16649115085601807
train-epoch-step: 102-430 -- Loss: 0.13563859462738037
train-epoch-step: 102-431 -- Loss: 0.15821337699890137
train-epoch-step: 102-432 -- Loss: 0.23043891787528992
train-epoch-step: 102-433 -- Loss: 0.13317817449569702
train-epoch-step: 102-434 -- Loss: 0.12586964666843414
train-epoch-step: 102-435 -- Loss: 0.15418492257595062
train-epoch-step: 102-436 -- Loss: 0.15058785676956177
train-epoch-step: 102-437 -- Loss: 0.1270720660686493
train-epoch-step: 102-438 -- Loss: 0.1624944508075714
train-epoch-step: 102-439 -- Loss: 0.2645754814147949
train-epoch-step: 102-440 -- Loss: 0.12588922679424286
train-epoch-step: 102-441 -- Loss: 0.19622841477394104
train-epoch-step: 102-442 -- Loss: 0.16975712776184082
train-epoch-step: 102-443 -- Loss: 0.14751002192497253
train-epoch-step: 102-444 -- Loss: 0.17286406457424164
train-epoch-step: 102-445 -- Loss: 0.17098566889762878
train-epoch-step: 102-446 -- Loss: 0.1439608335494995
train-epoch-step: 102-447 -- Loss: 0.1851990520954132
train-epoch-step: 102-448 -- Loss: 0.21526336669921875
train-epoch-step: 102-449 -- Loss: 0.18630237877368927
train-epoch-step: 102-450 -- Loss: 0.1727728396654129
train-epoch-step: 102-451 -- Loss: 0.1411202847957611
train-epoch-step: 102-452 -- Loss: 0.1273687779903412
train-epoch-step: 102-453 -- Loss: 0.08822189271450043
train-epoch-step: 102-454 -- Loss: 0.22014924883842468
train-epoch-step: 102-455 -- Loss: 0.12091359496116638
train-epoch-step: 102-456 -- Loss: 0.11381359398365021
train-epoch-step: 102-457 -- Loss: 0.2074497938156128
train-epoch-step: 102-458 -- Loss: 0.14532482624053955
train-epoch-step: 102-459 -- Loss: 0.21054275333881378
train-epoch-step: 102-460 -- Loss: 0.11828812956809998
train-epoch-step: 102-461 -- Loss: 0.12951013445854187
train-epoch-step: 102-462 -- Loss: 0.15338177978992462
train-epoch-step: 102-463 -- Loss: 0.12924699485301971
train-epoch-step: 102-464 -- Loss: 0.15646542608737946
train-epoch-step: 102-465 -- Loss: 0.23106802999973297
train-epoch-step: 102-466 -- Loss: 0.19128116965293884
train-epoch-step: 102-467 -- Loss: 0.10850405693054199
train-epoch-step: 102-468 -- Loss: 0.16170868277549744
train-epoch-step: 102-469 -- Loss: 0.20410849153995514
train-epoch-step: 102-470 -- Loss: 0.16117168962955475
train-epoch-step: 102-471 -- Loss: 0.15757742524147034
train-epoch-step: 102-472 -- Loss: 0.1533483862876892
train-epoch-step: 102-473 -- Loss: 0.14739064872264862
train-epoch-step: 102-474 -- Loss: 0.114398293197155
train-epoch-step: 102-475 -- Loss: 0.10527030378580093
train-epoch-step: 102-476 -- Loss: 0.1953880488872528
train-epoch-step: 102-477 -- Loss: 0.20571649074554443
train-epoch-step: 102-478 -- Loss: 0.18686543405056
train-epoch-step: 102-479 -- Loss: 0.1385052502155304
train-epoch-step: 102-480 -- Loss: 0.18838056921958923
train-epoch-step: 102-481 -- Loss: 0.2699306011199951
train-epoch-step: 102-482 -- Loss: 0.24465614557266235
train-epoch-step: 102-483 -- Loss: 0.17462754249572754
train-epoch-step: 102-484 -- Loss: 0.20893655717372894
train-epoch-step: 102-485 -- Loss: 0.12234446406364441
train-epoch-step: 102-486 -- Loss: 0.21957425773143768
train-epoch-step: 102-487 -- Loss: 0.22614145278930664
train-epoch-step: 102-488 -- Loss: 0.18158580362796783
train-epoch-step: 102-489 -- Loss: 0.21347497403621674
train-epoch-step: 102-490 -- Loss: 0.13312029838562012
train-epoch-step: 102-491 -- Loss: 0.13062526285648346
train-epoch-step: 102-492 -- Loss: 0.12424024939537048
train-epoch-step: 102-493 -- Loss: 0.193424254655838
train-epoch-step: 102-494 -- Loss: 0.19872254133224487
train-epoch-step: 102-495 -- Loss: 0.1962359994649887
train-epoch-step: 102-496 -- Loss: 0.1480284035205841
train-epoch-step: 102-497 -- Loss: 0.18573538959026337
train-epoch-step: 102-498 -- Loss: 0.14002834260463715
train-epoch-step: 102-499 -- Loss: 0.16249549388885498
train-epoch-step: 102-500 -- Loss: 0.15409459173679352
train-epoch-step: 102-501 -- Loss: 0.22507737576961517
train-epoch-step: 102-502 -- Loss: 0.15336376428604126
train-epoch-step: 102-503 -- Loss: 0.2097766101360321
train-epoch-step: 102-504 -- Loss: 0.12870369851589203
train-epoch-step: 102-505 -- Loss: 0.182485431432724
train-epoch-step: 102-506 -- Loss: 0.11394194513559341
train-epoch-step: 102-507 -- Loss: 0.18116213381290436
train-epoch-step: 102-508 -- Loss: 0.16895897686481476
train-epoch-step: 102-509 -- Loss: 0.16693317890167236
train-epoch-step: 102-510 -- Loss: 0.12483672052621841
train-epoch-step: 102-511 -- Loss: 0.2111070454120636
train-epoch-step: 102-512 -- Loss: 0.1772131621837616
train-epoch-step: 102-513 -- Loss: 0.18113407492637634
train-epoch-step: 102-514 -- Loss: 0.14038053154945374
train-epoch-step: 102-515 -- Loss: 0.15125301480293274
train-epoch-step: 102-516 -- Loss: 0.17066529393196106
train-epoch-step: 102-517 -- Loss: 0.1708184778690338
train-epoch-step: 102-518 -- Loss: 0.13694274425506592
train-epoch-step: 102-519 -- Loss: 0.1322595179080963
train-epoch-step: 102-520 -- Loss: 0.1817183494567871
train-epoch-step: 102-521 -- Loss: 0.22865325212478638
train-epoch-step: 102-522 -- Loss: 0.17454597353935242
train-epoch-step: 102-523 -- Loss: 0.16056139767169952
train-epoch-step: 102-524 -- Loss: 0.161204531788826
train-epoch-step: 102-525 -- Loss: 0.1921686828136444
train-epoch-step: 102-526 -- Loss: 0.1282893717288971
train-epoch-step: 102-527 -- Loss: 0.14344078302383423
train-epoch-step: 102-528 -- Loss: 0.14942532777786255
train-epoch-step: 102-529 -- Loss: 0.15220287442207336
train-epoch-step: 102-530 -- Loss: 0.16386261582374573
train-epoch-step: 102-531 -- Loss: 0.19116856157779694
train-epoch-step: 102-532 -- Loss: 0.16629000008106232
train-epoch-step: 102-533 -- Loss: 0.17078526318073273
train-epoch-step: 102-534 -- Loss: 0.12292838096618652
train-epoch-step: 102-535 -- Loss: 0.2499845027923584
train-epoch-step: 102-536 -- Loss: 0.15252958238124847
train-epoch-step: 102-537 -- Loss: 0.14515231549739838
train-epoch-step: 102-538 -- Loss: 0.10304237902164459
train-epoch-step: 102-539 -- Loss: 0.182779461145401
train-epoch-step: 102-540 -- Loss: 0.13150495290756226
train-epoch-step: 102-541 -- Loss: 0.21039029955863953
train-epoch-step: 102-542 -- Loss: 0.2147568166255951
train-epoch-step: 102-543 -- Loss: 0.16721689701080322
train-epoch-step: 102-544 -- Loss: 0.2159080058336258
train-epoch-step: 102-545 -- Loss: 0.18975482881069183
train-epoch-step: 102-546 -- Loss: 0.19325284659862518
train-epoch-step: 102-547 -- Loss: 0.17335984110832214
train-epoch-step: 102-548 -- Loss: 0.08950625360012054
train-epoch-step: 102-549 -- Loss: 0.14094744622707367
train-epoch-step: 102-550 -- Loss: 0.19280582666397095
train-epoch-step: 102-551 -- Loss: 0.1482556313276291
train-epoch-step: 102-552 -- Loss: 0.12094492465257645
train-epoch-step: 102-553 -- Loss: 0.18052035570144653
train-epoch-step: 102-554 -- Loss: 0.18455728888511658
train-epoch-step: 102-555 -- Loss: 0.19904589653015137
train-epoch-step: 102-556 -- Loss: 0.13917100429534912
train-epoch-step: 102-557 -- Loss: 0.22486776113510132
train-epoch-step: 102-558 -- Loss: 0.23311874270439148
train-epoch-step: 102-559 -- Loss: 0.14228826761245728
train-epoch-step: 102-560 -- Loss: 0.1963910460472107
train-epoch-step: 102-561 -- Loss: 0.17496570944786072
train-epoch-step: 102-562 -- Loss: 0.15706892311573029
train-epoch-step: 102-563 -- Loss: 0.17998015880584717
train-epoch-step: 102-564 -- Loss: 0.09432268142700195
train-epoch-step: 102-565 -- Loss: 0.1759796142578125
train-epoch-step: 102-566 -- Loss: 0.14320509135723114
train-epoch-step: 102-567 -- Loss: 0.2040901482105255
train-epoch-step: 102-568 -- Loss: 0.15116845071315765
train-epoch-step: 102-569 -- Loss: 0.2356933355331421
train-epoch-step: 102-570 -- Loss: 0.16066519916057587
train-epoch-step: 102-571 -- Loss: 0.20395013689994812
train-epoch-step: 102-572 -- Loss: 0.23557846248149872
train-epoch-step: 102-573 -- Loss: 0.19616717100143433
train-epoch-step: 102-574 -- Loss: 0.23734241724014282
train-epoch-step: 102-575 -- Loss: 0.28931429982185364
train-epoch-step: 102-576 -- Loss: 0.11148398369550705
train-epoch-step: 102-577 -- Loss: 0.16074295341968536
train-epoch-step: 102-578 -- Loss: 0.20765374600887299
train-epoch-step: 102-579 -- Loss: 0.16083967685699463
train-epoch-step: 102-580 -- Loss: 0.16598200798034668
train-epoch-step: 102-581 -- Loss: 0.13649210333824158
train-epoch-step: 102-582 -- Loss: 0.2024223506450653
train-epoch-step: 102-583 -- Loss: 0.20899878442287445
train-epoch-step: 102-584 -- Loss: 0.15453894436359406
train-epoch-step: 102-585 -- Loss: 0.18834561109542847
train-epoch-step: 102-586 -- Loss: 0.2469593733549118
train-epoch-step: 102-587 -- Loss: 0.15465745329856873
train-epoch-step: 102-588 -- Loss: 0.12464551627635956
val-epoch-step: 102-589 -- Loss: 0.1903408020734787
val-epoch-step: 102-590 -- Loss: 0.1558082103729248
val-epoch-step: 102-591 -- Loss: 0.24245545268058777
val-epoch-step: 102-592 -- Loss: 0.16915234923362732
val-epoch-step: 102-593 -- Loss: 0.18238544464111328
val-epoch-step: 102-594 -- Loss: 0.3617366552352905
val-epoch-step: 102-595 -- Loss: 0.1795458197593689
val-epoch-step: 102-596 -- Loss: 0.19617655873298645
val-epoch-step: 102-597 -- Loss: 0.17107319831848145
val-epoch-step: 102-598 -- Loss: 0.15434274077415466
val-epoch-step: 102-599 -- Loss: 0.17485114932060242
val-epoch-step: 102-600 -- Loss: 0.17522621154785156
val-epoch-step: 102-601 -- Loss: 0.15360166132450104
val-epoch-step: 102-602 -- Loss: 0.13766826689243317
val-epoch-step: 102-603 -- Loss: 0.1874276101589203
val-epoch-step: 102-604 -- Loss: 0.14542388916015625
val-epoch-step: 102-605 -- Loss: 0.14508166909217834
val-epoch-step: 102-606 -- Loss: 0.26160910725593567
val-epoch-step: 102-607 -- Loss: 0.1178559884428978
val-epoch-step: 102-608 -- Loss: 0.2395225465297699
val-epoch-step: 102-609 -- Loss: 0.16476546227931976
val-epoch-step: 102-610 -- Loss: 0.17591509222984314
val-epoch-step: 102-611 -- Loss: 0.1491028517484665
val-epoch-step: 102-612 -- Loss: 0.32903704047203064
val-epoch-step: 102-613 -- Loss: 0.16780546307563782
val-epoch-step: 102-614 -- Loss: 0.1677606850862503
val-epoch-step: 102-615 -- Loss: 0.1691005825996399
val-epoch-step: 102-616 -- Loss: 0.15386025607585907
val-epoch-step: 102-617 -- Loss: 0.1933119297027588
val-epoch-step: 102-618 -- Loss: 0.17816489934921265
val-epoch-step: 102-619 -- Loss: 0.20021775364875793
val-epoch-step: 102-620 -- Loss: 0.13938327133655548
val-epoch-step: 102-621 -- Loss: 0.1217484250664711
val-epoch-step: 102-622 -- Loss: 0.13992758095264435
val-epoch-step: 102-623 -- Loss: 0.1490589827299118
val-epoch-step: 102-624 -- Loss: 0.13930533826351166
val-epoch-step: 102-625 -- Loss: 0.1507570743560791
val-epoch-step: 102-626 -- Loss: 0.14438678324222565
val-epoch-step: 102-627 -- Loss: 0.1805724799633026
val-epoch-step: 102-628 -- Loss: 0.5051918625831604
val-epoch-step: 102-629 -- Loss: 0.18425729870796204
val-epoch-step: 102-630 -- Loss: 0.3436940610408783
val-epoch-step: 102-631 -- Loss: 0.13669253885746002
val-epoch-step: 102-632 -- Loss: 0.22461043298244476
val-epoch-step: 102-633 -- Loss: 0.153558149933815
val-epoch-step: 102-634 -- Loss: 0.14808489382266998
val-epoch-step: 102-635 -- Loss: 0.11171936988830566
val-epoch-step: 102-636 -- Loss: 0.17371025681495667
val-epoch-step: 102-637 -- Loss: 0.18014837801456451
val-epoch-step: 102-638 -- Loss: 0.14142240583896637
val-epoch-step: 102-639 -- Loss: 0.26486068964004517
val-epoch-step: 102-640 -- Loss: 0.24753129482269287
val-epoch-step: 102-641 -- Loss: 0.12057772278785706
val-epoch-step: 102-642 -- Loss: 0.17609907686710358
val-epoch-step: 102-643 -- Loss: 0.2122122347354889
val-epoch-step: 102-644 -- Loss: 0.15893378853797913
val-epoch-step: 102-645 -- Loss: 0.21495798230171204
val-epoch-step: 102-646 -- Loss: 0.12710562348365784
val-epoch-step: 102-647 -- Loss: 0.13135166466236115
val-epoch-step: 102-648 -- Loss: 0.1486930400133133
val-epoch-step: 102-649 -- Loss: 0.20272748172283173
val-epoch-step: 102-650 -- Loss: 0.24973392486572266
val-epoch-step: 102-651 -- Loss: 0.1397959589958191
val-epoch-step: 102-652 -- Loss: 0.14902666211128235
val-epoch-step: 102-653 -- Loss: 0.21723702549934387
val-epoch-step: 102-654 -- Loss: 0.11279068142175674
Epoch: 102 -- Train Loss: tensor(0.1391, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 103-0 -- Loss: 0.21382677555084229
train-epoch-step: 103-1 -- Loss: 0.13895146548748016
train-epoch-step: 103-2 -- Loss: 0.19186662137508392
train-epoch-step: 103-3 -- Loss: 0.1377110630273819
train-epoch-step: 103-4 -- Loss: 0.1497909128665924
train-epoch-step: 103-5 -- Loss: 0.17651039361953735
train-epoch-step: 103-6 -- Loss: 0.20707115530967712
train-epoch-step: 103-7 -- Loss: 0.16168269515037537
train-epoch-step: 103-8 -- Loss: 0.17613177001476288
train-epoch-step: 103-9 -- Loss: 0.2188890427350998
train-epoch-step: 103-10 -- Loss: 0.18230408430099487
train-epoch-step: 103-11 -- Loss: 0.16776758432388306
train-epoch-step: 103-12 -- Loss: 0.14292889833450317
train-epoch-step: 103-13 -- Loss: 0.17221592366695404
train-epoch-step: 103-14 -- Loss: 0.16021989285945892
train-epoch-step: 103-15 -- Loss: 0.15295642614364624
train-epoch-step: 103-16 -- Loss: 0.15794651210308075
train-epoch-step: 103-17 -- Loss: 0.21582046151161194
train-epoch-step: 103-18 -- Loss: 0.19178682565689087
train-epoch-step: 103-19 -- Loss: 0.12739291787147522
train-epoch-step: 103-20 -- Loss: 0.2070707082748413
train-epoch-step: 103-21 -- Loss: 0.24203047156333923
train-epoch-step: 103-22 -- Loss: 0.13252700865268707
train-epoch-step: 103-23 -- Loss: 0.14087024331092834
train-epoch-step: 103-24 -- Loss: 0.11911749839782715
train-epoch-step: 103-25 -- Loss: 0.21206337213516235
train-epoch-step: 103-26 -- Loss: 0.18420743942260742
train-epoch-step: 103-27 -- Loss: 0.21961566805839539
train-epoch-step: 103-28 -- Loss: 0.11968975514173508
train-epoch-step: 103-29 -- Loss: 0.23585954308509827
train-epoch-step: 103-30 -- Loss: 0.10496059060096741
train-epoch-step: 103-31 -- Loss: 0.12855444848537445
train-epoch-step: 103-32 -- Loss: 0.16530197858810425
train-epoch-step: 103-33 -- Loss: 0.2642090916633606
train-epoch-step: 103-34 -- Loss: 0.16664570569992065
train-epoch-step: 103-35 -- Loss: 0.23109489679336548
train-epoch-step: 103-36 -- Loss: 0.13122476637363434
train-epoch-step: 103-37 -- Loss: 0.13539162278175354
train-epoch-step: 103-38 -- Loss: 0.16808153688907623
train-epoch-step: 103-39 -- Loss: 0.2085687816143036
train-epoch-step: 103-40 -- Loss: 0.19040095806121826
train-epoch-step: 103-41 -- Loss: 0.21046817302703857
train-epoch-step: 103-42 -- Loss: 0.1493348926305771
train-epoch-step: 103-43 -- Loss: 0.2532193660736084
train-epoch-step: 103-44 -- Loss: 0.12565533816814423
train-epoch-step: 103-45 -- Loss: 0.11167311668395996
train-epoch-step: 103-46 -- Loss: 0.1676422655582428
train-epoch-step: 103-47 -- Loss: 0.18608787655830383
train-epoch-step: 103-48 -- Loss: 0.1484035849571228
train-epoch-step: 103-49 -- Loss: 0.22507134079933167
train-epoch-step: 103-50 -- Loss: 0.1080414205789566
train-epoch-step: 103-51 -- Loss: 0.17022305727005005
train-epoch-step: 103-52 -- Loss: 0.15447546541690826
train-epoch-step: 103-53 -- Loss: 0.19988900423049927
train-epoch-step: 103-54 -- Loss: 0.27443110942840576
train-epoch-step: 103-55 -- Loss: 0.15705306828022003
train-epoch-step: 103-56 -- Loss: 0.16724662482738495
train-epoch-step: 103-57 -- Loss: 0.22808316349983215
train-epoch-step: 103-58 -- Loss: 0.2783069610595703
train-epoch-step: 103-59 -- Loss: 0.2340918928384781
train-epoch-step: 103-60 -- Loss: 0.12324555218219757
train-epoch-step: 103-61 -- Loss: 0.20142865180969238
train-epoch-step: 103-62 -- Loss: 0.18032431602478027
train-epoch-step: 103-63 -- Loss: 0.12708868086338043
train-epoch-step: 103-64 -- Loss: 0.1387752741575241
train-epoch-step: 103-65 -- Loss: 0.1705930382013321
train-epoch-step: 103-66 -- Loss: 0.10392362624406815
train-epoch-step: 103-67 -- Loss: 0.11778927594423294
train-epoch-step: 103-68 -- Loss: 0.20268581807613373
train-epoch-step: 103-69 -- Loss: 0.11638050526380539
train-epoch-step: 103-70 -- Loss: 0.2175029069185257
train-epoch-step: 103-71 -- Loss: 0.24788735806941986
train-epoch-step: 103-72 -- Loss: 0.16556070744991302
train-epoch-step: 103-73 -- Loss: 0.19839486479759216
train-epoch-step: 103-74 -- Loss: 0.09091717004776001
train-epoch-step: 103-75 -- Loss: 0.12549272179603577
train-epoch-step: 103-76 -- Loss: 0.13915079832077026
train-epoch-step: 103-77 -- Loss: 0.22033557295799255
train-epoch-step: 103-78 -- Loss: 0.24599315226078033
train-epoch-step: 103-79 -- Loss: 0.1851322054862976
train-epoch-step: 103-80 -- Loss: 0.2374279499053955
train-epoch-step: 103-81 -- Loss: 0.11882152408361435
train-epoch-step: 103-82 -- Loss: 0.24073141813278198
train-epoch-step: 103-83 -- Loss: 0.17460405826568604
train-epoch-step: 103-84 -- Loss: 0.17943976819515228
train-epoch-step: 103-85 -- Loss: 0.16948935389518738
train-epoch-step: 103-86 -- Loss: 0.1181107833981514
train-epoch-step: 103-87 -- Loss: 0.21080225706100464
train-epoch-step: 103-88 -- Loss: 0.13582436740398407
train-epoch-step: 103-89 -- Loss: 0.18105486035346985
train-epoch-step: 103-90 -- Loss: 0.18086425960063934
train-epoch-step: 103-91 -- Loss: 0.23619788885116577
train-epoch-step: 103-92 -- Loss: 0.146615132689476
train-epoch-step: 103-93 -- Loss: 0.16645681858062744
train-epoch-step: 103-94 -- Loss: 0.220371812582016
train-epoch-step: 103-95 -- Loss: 0.17941907048225403
train-epoch-step: 103-96 -- Loss: 0.2032758593559265
train-epoch-step: 103-97 -- Loss: 0.17030508816242218
train-epoch-step: 103-98 -- Loss: 0.15295399725437164
train-epoch-step: 103-99 -- Loss: 0.17690372467041016
train-epoch-step: 103-100 -- Loss: 0.17974068224430084
train-epoch-step: 103-101 -- Loss: 0.25974857807159424
train-epoch-step: 103-102 -- Loss: 0.2116962969303131
train-epoch-step: 103-103 -- Loss: 0.1815197467803955
train-epoch-step: 103-104 -- Loss: 0.14197835326194763
train-epoch-step: 103-105 -- Loss: 0.24594175815582275
train-epoch-step: 103-106 -- Loss: 0.17444029450416565
train-epoch-step: 103-107 -- Loss: 0.184078648686409
train-epoch-step: 103-108 -- Loss: 0.18669800460338593
train-epoch-step: 103-109 -- Loss: 0.13668973743915558
train-epoch-step: 103-110 -- Loss: 0.17701518535614014
train-epoch-step: 103-111 -- Loss: 0.17495524883270264
train-epoch-step: 103-112 -- Loss: 0.164569690823555
train-epoch-step: 103-113 -- Loss: 0.16135920584201813
train-epoch-step: 103-114 -- Loss: 0.18721112608909607
train-epoch-step: 103-115 -- Loss: 0.15351828932762146
train-epoch-step: 103-116 -- Loss: 0.13323989510536194
train-epoch-step: 103-117 -- Loss: 0.12107865512371063
train-epoch-step: 103-118 -- Loss: 0.1875445693731308
train-epoch-step: 103-119 -- Loss: 0.15168584883213043
train-epoch-step: 103-120 -- Loss: 0.23697738349437714
train-epoch-step: 103-121 -- Loss: 0.22394149005413055
train-epoch-step: 103-122 -- Loss: 0.20915040373802185
train-epoch-step: 103-123 -- Loss: 0.19675493240356445
train-epoch-step: 103-124 -- Loss: 0.11812969297170639
train-epoch-step: 103-125 -- Loss: 0.14734819531440735
train-epoch-step: 103-126 -- Loss: 0.22278493642807007
train-epoch-step: 103-127 -- Loss: 0.16702070832252502
train-epoch-step: 103-128 -- Loss: 0.16573239862918854
train-epoch-step: 103-129 -- Loss: 0.1479484736919403
train-epoch-step: 103-130 -- Loss: 0.1944904625415802
train-epoch-step: 103-131 -- Loss: 0.13446925580501556
train-epoch-step: 103-132 -- Loss: 0.18163318932056427
train-epoch-step: 103-133 -- Loss: 0.11099110543727875
train-epoch-step: 103-134 -- Loss: 0.1836264431476593
train-epoch-step: 103-135 -- Loss: 0.12847492098808289
train-epoch-step: 103-136 -- Loss: 0.122430220246315
train-epoch-step: 103-137 -- Loss: 0.23796817660331726
train-epoch-step: 103-138 -- Loss: 0.2535776197910309
train-epoch-step: 103-139 -- Loss: 0.12895408272743225
train-epoch-step: 103-140 -- Loss: 0.20455414056777954
train-epoch-step: 103-141 -- Loss: 0.22061267495155334
train-epoch-step: 103-142 -- Loss: 0.19722820818424225
train-epoch-step: 103-143 -- Loss: 0.16108419001102448
train-epoch-step: 103-144 -- Loss: 0.17187011241912842
train-epoch-step: 103-145 -- Loss: 0.13791704177856445
train-epoch-step: 103-146 -- Loss: 0.16922242939472198
train-epoch-step: 103-147 -- Loss: 0.1619824767112732
train-epoch-step: 103-148 -- Loss: 0.15782636404037476
train-epoch-step: 103-149 -- Loss: 0.11643731594085693
train-epoch-step: 103-150 -- Loss: 0.17635715007781982
train-epoch-step: 103-151 -- Loss: 0.1870226413011551
train-epoch-step: 103-152 -- Loss: 0.18343503773212433
train-epoch-step: 103-153 -- Loss: 0.26361680030822754
train-epoch-step: 103-154 -- Loss: 0.1290292590856552
train-epoch-step: 103-155 -- Loss: 0.1307096928358078
train-epoch-step: 103-156 -- Loss: 0.11158174276351929
train-epoch-step: 103-157 -- Loss: 0.16165323555469513
train-epoch-step: 103-158 -- Loss: 0.16186252236366272
train-epoch-step: 103-159 -- Loss: 0.17975196242332458
train-epoch-step: 103-160 -- Loss: 0.21736417710781097
train-epoch-step: 103-161 -- Loss: 0.19475743174552917
train-epoch-step: 103-162 -- Loss: 0.2035313844680786
train-epoch-step: 103-163 -- Loss: 0.17898410558700562
train-epoch-step: 103-164 -- Loss: 0.1903640329837799
train-epoch-step: 103-165 -- Loss: 0.16788235306739807
train-epoch-step: 103-166 -- Loss: 0.11378352344036102
train-epoch-step: 103-167 -- Loss: 0.1186390221118927
train-epoch-step: 103-168 -- Loss: 0.19751890003681183
train-epoch-step: 103-169 -- Loss: 0.1356838196516037
train-epoch-step: 103-170 -- Loss: 0.1937953382730484
train-epoch-step: 103-171 -- Loss: 0.13970839977264404
train-epoch-step: 103-172 -- Loss: 0.25316116213798523
train-epoch-step: 103-173 -- Loss: 0.1297033727169037
train-epoch-step: 103-174 -- Loss: 0.23985059559345245
train-epoch-step: 103-175 -- Loss: 0.18113596737384796
train-epoch-step: 103-176 -- Loss: 0.12970229983329773
train-epoch-step: 103-177 -- Loss: 0.17399390041828156
train-epoch-step: 103-178 -- Loss: 0.169226735830307
train-epoch-step: 103-179 -- Loss: 0.15502803027629852
train-epoch-step: 103-180 -- Loss: 0.14580857753753662
train-epoch-step: 103-181 -- Loss: 0.1672588437795639
train-epoch-step: 103-182 -- Loss: 0.17940782010555267
train-epoch-step: 103-183 -- Loss: 0.2631298303604126
train-epoch-step: 103-184 -- Loss: 0.13429534435272217
train-epoch-step: 103-185 -- Loss: 0.13922175765037537
train-epoch-step: 103-186 -- Loss: 0.18391697108745575
train-epoch-step: 103-187 -- Loss: 0.20101703703403473
train-epoch-step: 103-188 -- Loss: 0.1628904789686203
train-epoch-step: 103-189 -- Loss: 0.10222272574901581
train-epoch-step: 103-190 -- Loss: 0.17966896295547485
train-epoch-step: 103-191 -- Loss: 0.14866788685321808
train-epoch-step: 103-192 -- Loss: 0.21873971819877625
train-epoch-step: 103-193 -- Loss: 0.19962090253829956
train-epoch-step: 103-194 -- Loss: 0.17478933930397034
train-epoch-step: 103-195 -- Loss: 0.16751904785633087
train-epoch-step: 103-196 -- Loss: 0.16665178537368774
train-epoch-step: 103-197 -- Loss: 0.12362205982208252
train-epoch-step: 103-198 -- Loss: 0.12089762836694717
train-epoch-step: 103-199 -- Loss: 0.13880985975265503
train-epoch-step: 103-200 -- Loss: 0.12108512222766876
train-epoch-step: 103-201 -- Loss: 0.18780289590358734
train-epoch-step: 103-202 -- Loss: 0.1324131339788437
train-epoch-step: 103-203 -- Loss: 0.17382153868675232
train-epoch-step: 103-204 -- Loss: 0.13179796934127808
train-epoch-step: 103-205 -- Loss: 0.18902257084846497
train-epoch-step: 103-206 -- Loss: 0.1933073103427887
train-epoch-step: 103-207 -- Loss: 0.13175398111343384
train-epoch-step: 103-208 -- Loss: 0.17749156057834625
train-epoch-step: 103-209 -- Loss: 0.14327643811702728
train-epoch-step: 103-210 -- Loss: 0.13134720921516418
train-epoch-step: 103-211 -- Loss: 0.2109893560409546
train-epoch-step: 103-212 -- Loss: 0.19423487782478333
train-epoch-step: 103-213 -- Loss: 0.12431196868419647
train-epoch-step: 103-214 -- Loss: 0.14766258001327515
train-epoch-step: 103-215 -- Loss: 0.12344437837600708
train-epoch-step: 103-216 -- Loss: 0.19076070189476013
train-epoch-step: 103-217 -- Loss: 0.20656229555606842
train-epoch-step: 103-218 -- Loss: 0.13815030455589294
train-epoch-step: 103-219 -- Loss: 0.16340069472789764
train-epoch-step: 103-220 -- Loss: 0.12548570334911346
train-epoch-step: 103-221 -- Loss: 0.2035645842552185
train-epoch-step: 103-222 -- Loss: 0.1123197078704834
train-epoch-step: 103-223 -- Loss: 0.16869573295116425
train-epoch-step: 103-224 -- Loss: 0.18339119851589203
train-epoch-step: 103-225 -- Loss: 0.2633661925792694
train-epoch-step: 103-226 -- Loss: 0.19893240928649902
train-epoch-step: 103-227 -- Loss: 0.21334810554981232
train-epoch-step: 103-228 -- Loss: 0.1679934561252594
train-epoch-step: 103-229 -- Loss: 0.17805328965187073
train-epoch-step: 103-230 -- Loss: 0.1597835123538971
train-epoch-step: 103-231 -- Loss: 0.1507032960653305
train-epoch-step: 103-232 -- Loss: 0.18534348905086517
train-epoch-step: 103-233 -- Loss: 0.08218247443437576
train-epoch-step: 103-234 -- Loss: 0.1705731302499771
train-epoch-step: 103-235 -- Loss: 0.1389138400554657
train-epoch-step: 103-236 -- Loss: 0.17338088154792786
train-epoch-step: 103-237 -- Loss: 0.2280057668685913
train-epoch-step: 103-238 -- Loss: 0.15204809606075287
train-epoch-step: 103-239 -- Loss: 0.12368166446685791
train-epoch-step: 103-240 -- Loss: 0.22327826917171478
train-epoch-step: 103-241 -- Loss: 0.14732375741004944
train-epoch-step: 103-242 -- Loss: 0.2150609791278839
train-epoch-step: 103-243 -- Loss: 0.2294735312461853
train-epoch-step: 103-244 -- Loss: 0.20801573991775513
train-epoch-step: 103-245 -- Loss: 0.20105640590190887
train-epoch-step: 103-246 -- Loss: 0.21127456426620483
train-epoch-step: 103-247 -- Loss: 0.2171897143125534
train-epoch-step: 103-248 -- Loss: 0.18277664482593536
train-epoch-step: 103-249 -- Loss: 0.1324530392885208
train-epoch-step: 103-250 -- Loss: 0.1897408366203308
train-epoch-step: 103-251 -- Loss: 0.1075851246714592
train-epoch-step: 103-252 -- Loss: 0.19172810018062592
train-epoch-step: 103-253 -- Loss: 0.13425254821777344
train-epoch-step: 103-254 -- Loss: 0.20534873008728027
train-epoch-step: 103-255 -- Loss: 0.13982009887695312
train-epoch-step: 103-256 -- Loss: 0.14380721747875214
train-epoch-step: 103-257 -- Loss: 0.18354377150535583
train-epoch-step: 103-258 -- Loss: 0.13735562562942505
train-epoch-step: 103-259 -- Loss: 0.1069260686635971
train-epoch-step: 103-260 -- Loss: 0.18985582888126373
train-epoch-step: 103-261 -- Loss: 0.1654261201620102
train-epoch-step: 103-262 -- Loss: 0.2651498019695282
train-epoch-step: 103-263 -- Loss: 0.19810745120048523
train-epoch-step: 103-264 -- Loss: 0.1726711094379425
train-epoch-step: 103-265 -- Loss: 0.10346311330795288
train-epoch-step: 103-266 -- Loss: 0.1491750180721283
train-epoch-step: 103-267 -- Loss: 0.12480125576257706
train-epoch-step: 103-268 -- Loss: 0.11484566330909729
train-epoch-step: 103-269 -- Loss: 0.16579505801200867
train-epoch-step: 103-270 -- Loss: 0.10489553958177567
train-epoch-step: 103-271 -- Loss: 0.14010055363178253
train-epoch-step: 103-272 -- Loss: 0.11309723556041718
train-epoch-step: 103-273 -- Loss: 0.12285464257001877
train-epoch-step: 103-274 -- Loss: 0.175370454788208
train-epoch-step: 103-275 -- Loss: 0.18089160323143005
train-epoch-step: 103-276 -- Loss: 0.14773885905742645
train-epoch-step: 103-277 -- Loss: 0.15046828985214233
train-epoch-step: 103-278 -- Loss: 0.14279893040657043
train-epoch-step: 103-279 -- Loss: 0.13221237063407898
train-epoch-step: 103-280 -- Loss: 0.2077348232269287
train-epoch-step: 103-281 -- Loss: 0.16825103759765625
train-epoch-step: 103-282 -- Loss: 0.13913634419441223
train-epoch-step: 103-283 -- Loss: 0.11238499730825424
train-epoch-step: 103-284 -- Loss: 0.12868273258209229
train-epoch-step: 103-285 -- Loss: 0.18146023154258728
train-epoch-step: 103-286 -- Loss: 0.14691337943077087
train-epoch-step: 103-287 -- Loss: 0.19326242804527283
train-epoch-step: 103-288 -- Loss: 0.0904502272605896
train-epoch-step: 103-289 -- Loss: 0.11361053586006165
train-epoch-step: 103-290 -- Loss: 0.17407706379890442
train-epoch-step: 103-291 -- Loss: 0.11427313089370728
train-epoch-step: 103-292 -- Loss: 0.15091806650161743
train-epoch-step: 103-293 -- Loss: 0.1346088945865631
train-epoch-step: 103-294 -- Loss: 0.15226298570632935
train-epoch-step: 103-295 -- Loss: 0.251003235578537
train-epoch-step: 103-296 -- Loss: 0.15175944566726685
train-epoch-step: 103-297 -- Loss: 0.1629534214735031
train-epoch-step: 103-298 -- Loss: 0.22202564775943756
train-epoch-step: 103-299 -- Loss: 0.14882780611515045
train-epoch-step: 103-300 -- Loss: 0.15519143640995026
train-epoch-step: 103-301 -- Loss: 0.17112033069133759
train-epoch-step: 103-302 -- Loss: 0.20498645305633545
train-epoch-step: 103-303 -- Loss: 0.19438190758228302
train-epoch-step: 103-304 -- Loss: 0.13114018738269806
train-epoch-step: 103-305 -- Loss: 0.13648223876953125
train-epoch-step: 103-306 -- Loss: 0.19997578859329224
train-epoch-step: 103-307 -- Loss: 0.16058973968029022
train-epoch-step: 103-308 -- Loss: 0.21086473762989044
train-epoch-step: 103-309 -- Loss: 0.14761947095394135
train-epoch-step: 103-310 -- Loss: 0.15660449862480164
train-epoch-step: 103-311 -- Loss: 0.15306389331817627
train-epoch-step: 103-312 -- Loss: 0.19683100283145905
train-epoch-step: 103-313 -- Loss: 0.0944560244679451
train-epoch-step: 103-314 -- Loss: 0.18493162095546722
train-epoch-step: 103-315 -- Loss: 0.16139408946037292
train-epoch-step: 103-316 -- Loss: 0.14845271408557892
train-epoch-step: 103-317 -- Loss: 0.13982951641082764
train-epoch-step: 103-318 -- Loss: 0.15067730844020844
train-epoch-step: 103-319 -- Loss: 0.1617916077375412
train-epoch-step: 103-320 -- Loss: 0.11118341982364655
train-epoch-step: 103-321 -- Loss: 0.12839634716510773
train-epoch-step: 103-322 -- Loss: 0.2067999392747879
train-epoch-step: 103-323 -- Loss: 0.17456844449043274
train-epoch-step: 103-324 -- Loss: 0.24366214871406555
train-epoch-step: 103-325 -- Loss: 0.15076380968093872
train-epoch-step: 103-326 -- Loss: 0.16459450125694275
train-epoch-step: 103-327 -- Loss: 0.19898928701877594
train-epoch-step: 103-328 -- Loss: 0.18621990084648132
train-epoch-step: 103-329 -- Loss: 0.3259439468383789
train-epoch-step: 103-330 -- Loss: 0.34122923016548157
train-epoch-step: 103-331 -- Loss: 0.2007797360420227
train-epoch-step: 103-332 -- Loss: 0.09747150540351868
train-epoch-step: 103-333 -- Loss: 0.17960456013679504
train-epoch-step: 103-334 -- Loss: 0.1533408910036087
train-epoch-step: 103-335 -- Loss: 0.1694682538509369
train-epoch-step: 103-336 -- Loss: 0.1455073058605194
train-epoch-step: 103-337 -- Loss: 0.19382615387439728
train-epoch-step: 103-338 -- Loss: 0.15501998364925385
train-epoch-step: 103-339 -- Loss: 0.13608045876026154
train-epoch-step: 103-340 -- Loss: 0.19398349523544312
train-epoch-step: 103-341 -- Loss: 0.13592644035816193
train-epoch-step: 103-342 -- Loss: 0.16057655215263367
train-epoch-step: 103-343 -- Loss: 0.14795859158039093
train-epoch-step: 103-344 -- Loss: 0.15980583429336548
train-epoch-step: 103-345 -- Loss: 0.12149079144001007
train-epoch-step: 103-346 -- Loss: 0.1994636356830597
train-epoch-step: 103-347 -- Loss: 0.1480330526828766
train-epoch-step: 103-348 -- Loss: 0.19772076606750488
train-epoch-step: 103-349 -- Loss: 0.20062455534934998
train-epoch-step: 103-350 -- Loss: 0.2484925240278244
train-epoch-step: 103-351 -- Loss: 0.18994170427322388
train-epoch-step: 103-352 -- Loss: 0.1210959404706955
train-epoch-step: 103-353 -- Loss: 0.18654365837574005
train-epoch-step: 103-354 -- Loss: 0.27559229731559753
train-epoch-step: 103-355 -- Loss: 0.11090157181024551
train-epoch-step: 103-356 -- Loss: 0.11212491989135742
train-epoch-step: 103-357 -- Loss: 0.18319590389728546
train-epoch-step: 103-358 -- Loss: 0.18160220980644226
train-epoch-step: 103-359 -- Loss: 0.14498868584632874
train-epoch-step: 103-360 -- Loss: 0.1175374910235405
train-epoch-step: 103-361 -- Loss: 0.22660000622272491
train-epoch-step: 103-362 -- Loss: 0.16682246327400208
train-epoch-step: 103-363 -- Loss: 0.10721184313297272
train-epoch-step: 103-364 -- Loss: 0.1738022118806839
train-epoch-step: 103-365 -- Loss: 0.1642695963382721
train-epoch-step: 103-366 -- Loss: 0.189949169754982
train-epoch-step: 103-367 -- Loss: 0.2174231857061386
train-epoch-step: 103-368 -- Loss: 0.18806010484695435
train-epoch-step: 103-369 -- Loss: 0.27013206481933594
train-epoch-step: 103-370 -- Loss: 0.12004972994327545
train-epoch-step: 103-371 -- Loss: 0.11903417110443115
train-epoch-step: 103-372 -- Loss: 0.1414726972579956
train-epoch-step: 103-373 -- Loss: 0.18765008449554443
train-epoch-step: 103-374 -- Loss: 0.15175791084766388
train-epoch-step: 103-375 -- Loss: 0.2595190405845642
train-epoch-step: 103-376 -- Loss: 0.1544821560382843
train-epoch-step: 103-377 -- Loss: 0.21271777153015137
train-epoch-step: 103-378 -- Loss: 0.19513937830924988
train-epoch-step: 103-379 -- Loss: 0.11847706884145737
train-epoch-step: 103-380 -- Loss: 0.08743659406900406
train-epoch-step: 103-381 -- Loss: 0.24099989235401154
train-epoch-step: 103-382 -- Loss: 0.2245231568813324
train-epoch-step: 103-383 -- Loss: 0.16481390595436096
train-epoch-step: 103-384 -- Loss: 0.21559488773345947
train-epoch-step: 103-385 -- Loss: 0.1842532753944397
train-epoch-step: 103-386 -- Loss: 0.17638565599918365
train-epoch-step: 103-387 -- Loss: 0.19909539818763733
train-epoch-step: 103-388 -- Loss: 0.18249985575675964
train-epoch-step: 103-389 -- Loss: 0.15915873646736145
train-epoch-step: 103-390 -- Loss: 0.13899099826812744
train-epoch-step: 103-391 -- Loss: 0.13932256400585175
train-epoch-step: 103-392 -- Loss: 0.17577677965164185
train-epoch-step: 103-393 -- Loss: 0.15131250023841858
train-epoch-step: 103-394 -- Loss: 0.21115100383758545
train-epoch-step: 103-395 -- Loss: 0.14333444833755493
train-epoch-step: 103-396 -- Loss: 0.1209060549736023
train-epoch-step: 103-397 -- Loss: 0.1186622753739357
train-epoch-step: 103-398 -- Loss: 0.19275806844234467
train-epoch-step: 103-399 -- Loss: 0.16763681173324585
train-epoch-step: 103-400 -- Loss: 0.26409026980400085
train-epoch-step: 103-401 -- Loss: 0.1153881847858429
train-epoch-step: 103-402 -- Loss: 0.25518330931663513
train-epoch-step: 103-403 -- Loss: 0.15358011424541473
train-epoch-step: 103-404 -- Loss: 0.13166899979114532
train-epoch-step: 103-405 -- Loss: 0.13744620978832245
train-epoch-step: 103-406 -- Loss: 0.15969938039779663
train-epoch-step: 103-407 -- Loss: 0.10872047394514084
train-epoch-step: 103-408 -- Loss: 0.15640951693058014
train-epoch-step: 103-409 -- Loss: 0.16579842567443848
train-epoch-step: 103-410 -- Loss: 0.1665206104516983
train-epoch-step: 103-411 -- Loss: 0.18754510581493378
train-epoch-step: 103-412 -- Loss: 0.12425507605075836
train-epoch-step: 103-413 -- Loss: 0.1420360505580902
train-epoch-step: 103-414 -- Loss: 0.12608081102371216
train-epoch-step: 103-415 -- Loss: 0.12861201167106628
train-epoch-step: 103-416 -- Loss: 0.2566506266593933
train-epoch-step: 103-417 -- Loss: 0.18337933719158173
train-epoch-step: 103-418 -- Loss: 0.22087210416793823
train-epoch-step: 103-419 -- Loss: 0.158662348985672
train-epoch-step: 103-420 -- Loss: 0.14872057735919952
train-epoch-step: 103-421 -- Loss: 0.16921421885490417
train-epoch-step: 103-422 -- Loss: 0.1477012038230896
train-epoch-step: 103-423 -- Loss: 0.1642102599143982
train-epoch-step: 103-424 -- Loss: 0.1317119598388672
train-epoch-step: 103-425 -- Loss: 0.17284782230854034
train-epoch-step: 103-426 -- Loss: 0.1593630611896515
train-epoch-step: 103-427 -- Loss: 0.11714039742946625
train-epoch-step: 103-428 -- Loss: 0.18285858631134033
train-epoch-step: 103-429 -- Loss: 0.1680416464805603
train-epoch-step: 103-430 -- Loss: 0.13651032745838165
train-epoch-step: 103-431 -- Loss: 0.16020996868610382
train-epoch-step: 103-432 -- Loss: 0.23412850499153137
train-epoch-step: 103-433 -- Loss: 0.1301746815443039
train-epoch-step: 103-434 -- Loss: 0.12146907299757004
train-epoch-step: 103-435 -- Loss: 0.152377188205719
train-epoch-step: 103-436 -- Loss: 0.14757920801639557
train-epoch-step: 103-437 -- Loss: 0.127157524228096
train-epoch-step: 103-438 -- Loss: 0.15963411331176758
train-epoch-step: 103-439 -- Loss: 0.24809986352920532
train-epoch-step: 103-440 -- Loss: 0.1259572058916092
train-epoch-step: 103-441 -- Loss: 0.20323362946510315
train-epoch-step: 103-442 -- Loss: 0.16868847608566284
train-epoch-step: 103-443 -- Loss: 0.1503225713968277
train-epoch-step: 103-444 -- Loss: 0.16542670130729675
train-epoch-step: 103-445 -- Loss: 0.17065250873565674
train-epoch-step: 103-446 -- Loss: 0.14842122793197632
train-epoch-step: 103-447 -- Loss: 0.18610714375972748
train-epoch-step: 103-448 -- Loss: 0.21863815188407898
train-epoch-step: 103-449 -- Loss: 0.1873374581336975
train-epoch-step: 103-450 -- Loss: 0.17324534058570862
train-epoch-step: 103-451 -- Loss: 0.13966940343379974
train-epoch-step: 103-452 -- Loss: 0.1308460831642151
train-epoch-step: 103-453 -- Loss: 0.08710197359323502
train-epoch-step: 103-454 -- Loss: 0.21754279732704163
train-epoch-step: 103-455 -- Loss: 0.12036268413066864
train-epoch-step: 103-456 -- Loss: 0.11227582395076752
train-epoch-step: 103-457 -- Loss: 0.2122197449207306
train-epoch-step: 103-458 -- Loss: 0.14179833233356476
train-epoch-step: 103-459 -- Loss: 0.2018294632434845
train-epoch-step: 103-460 -- Loss: 0.11916328221559525
train-epoch-step: 103-461 -- Loss: 0.13876183331012726
train-epoch-step: 103-462 -- Loss: 0.14902904629707336
train-epoch-step: 103-463 -- Loss: 0.13304154574871063
train-epoch-step: 103-464 -- Loss: 0.15282531082630157
train-epoch-step: 103-465 -- Loss: 0.22624756395816803
train-epoch-step: 103-466 -- Loss: 0.19165150821208954
train-epoch-step: 103-467 -- Loss: 0.11224548518657684
train-epoch-step: 103-468 -- Loss: 0.16187617182731628
train-epoch-step: 103-469 -- Loss: 0.19636842608451843
train-epoch-step: 103-470 -- Loss: 0.16919751465320587
train-epoch-step: 103-471 -- Loss: 0.1533733457326889
train-epoch-step: 103-472 -- Loss: 0.15764504671096802
train-epoch-step: 103-473 -- Loss: 0.14553362131118774
train-epoch-step: 103-474 -- Loss: 0.11599120497703552
train-epoch-step: 103-475 -- Loss: 0.10632287710905075
train-epoch-step: 103-476 -- Loss: 0.19645945727825165
train-epoch-step: 103-477 -- Loss: 0.19106486439704895
train-epoch-step: 103-478 -- Loss: 0.18952614068984985
train-epoch-step: 103-479 -- Loss: 0.13866758346557617
train-epoch-step: 103-480 -- Loss: 0.18139559030532837
train-epoch-step: 103-481 -- Loss: 0.2753909230232239
train-epoch-step: 103-482 -- Loss: 0.23904144763946533
train-epoch-step: 103-483 -- Loss: 0.17570576071739197
train-epoch-step: 103-484 -- Loss: 0.21099865436553955
train-epoch-step: 103-485 -- Loss: 0.13300931453704834
train-epoch-step: 103-486 -- Loss: 0.21660378575325012
train-epoch-step: 103-487 -- Loss: 0.2248467355966568
train-epoch-step: 103-488 -- Loss: 0.18509356677532196
train-epoch-step: 103-489 -- Loss: 0.21671757102012634
train-epoch-step: 103-490 -- Loss: 0.1343308538198471
train-epoch-step: 103-491 -- Loss: 0.13367466628551483
train-epoch-step: 103-492 -- Loss: 0.1228908970952034
train-epoch-step: 103-493 -- Loss: 0.19241875410079956
train-epoch-step: 103-494 -- Loss: 0.19436557590961456
train-epoch-step: 103-495 -- Loss: 0.19032125174999237
train-epoch-step: 103-496 -- Loss: 0.13503801822662354
train-epoch-step: 103-497 -- Loss: 0.17516262829303741
train-epoch-step: 103-498 -- Loss: 0.1398969441652298
train-epoch-step: 103-499 -- Loss: 0.1621968299150467
train-epoch-step: 103-500 -- Loss: 0.14740219712257385
train-epoch-step: 103-501 -- Loss: 0.21138149499893188
train-epoch-step: 103-502 -- Loss: 0.15110279619693756
train-epoch-step: 103-503 -- Loss: 0.20634765923023224
train-epoch-step: 103-504 -- Loss: 0.11912926286458969
train-epoch-step: 103-505 -- Loss: 0.1695311963558197
train-epoch-step: 103-506 -- Loss: 0.11564245074987411
train-epoch-step: 103-507 -- Loss: 0.17463037371635437
train-epoch-step: 103-508 -- Loss: 0.18277499079704285
train-epoch-step: 103-509 -- Loss: 0.1608089655637741
train-epoch-step: 103-510 -- Loss: 0.12285425513982773
train-epoch-step: 103-511 -- Loss: 0.21260212361812592
train-epoch-step: 103-512 -- Loss: 0.17131474614143372
train-epoch-step: 103-513 -- Loss: 0.1874362826347351
train-epoch-step: 103-514 -- Loss: 0.15757212042808533
train-epoch-step: 103-515 -- Loss: 0.15264254808425903
train-epoch-step: 103-516 -- Loss: 0.16779732704162598
train-epoch-step: 103-517 -- Loss: 0.16788338124752045
train-epoch-step: 103-518 -- Loss: 0.13178877532482147
train-epoch-step: 103-519 -- Loss: 0.1298285275697708
train-epoch-step: 103-520 -- Loss: 0.1772376298904419
train-epoch-step: 103-521 -- Loss: 0.2276383638381958
train-epoch-step: 103-522 -- Loss: 0.16079646348953247
train-epoch-step: 103-523 -- Loss: 0.15538574755191803
train-epoch-step: 103-524 -- Loss: 0.16044554114341736
train-epoch-step: 103-525 -- Loss: 0.19106683135032654
train-epoch-step: 103-526 -- Loss: 0.12856200337409973
train-epoch-step: 103-527 -- Loss: 0.1422404944896698
train-epoch-step: 103-528 -- Loss: 0.15067137777805328
train-epoch-step: 103-529 -- Loss: 0.14717045426368713
train-epoch-step: 103-530 -- Loss: 0.17035971581935883
train-epoch-step: 103-531 -- Loss: 0.18571554124355316
train-epoch-step: 103-532 -- Loss: 0.1680711954832077
train-epoch-step: 103-533 -- Loss: 0.1704959273338318
train-epoch-step: 103-534 -- Loss: 0.1278562992811203
train-epoch-step: 103-535 -- Loss: 0.25055286288261414
train-epoch-step: 103-536 -- Loss: 0.1507347822189331
train-epoch-step: 103-537 -- Loss: 0.1477142870426178
train-epoch-step: 103-538 -- Loss: 0.10219016671180725
train-epoch-step: 103-539 -- Loss: 0.1766083538532257
train-epoch-step: 103-540 -- Loss: 0.12889103591442108
train-epoch-step: 103-541 -- Loss: 0.20125064253807068
train-epoch-step: 103-542 -- Loss: 0.21430934965610504
train-epoch-step: 103-543 -- Loss: 0.16286718845367432
train-epoch-step: 103-544 -- Loss: 0.2349890172481537
train-epoch-step: 103-545 -- Loss: 0.19489307701587677
train-epoch-step: 103-546 -- Loss: 0.19954583048820496
train-epoch-step: 103-547 -- Loss: 0.2050359845161438
train-epoch-step: 103-548 -- Loss: 0.0876605436205864
train-epoch-step: 103-549 -- Loss: 0.1433662474155426
train-epoch-step: 103-550 -- Loss: 0.19378770887851715
train-epoch-step: 103-551 -- Loss: 0.14842991530895233
train-epoch-step: 103-552 -- Loss: 0.12038959562778473
train-epoch-step: 103-553 -- Loss: 0.17966198921203613
train-epoch-step: 103-554 -- Loss: 0.1812307983636856
train-epoch-step: 103-555 -- Loss: 0.2053772509098053
train-epoch-step: 103-556 -- Loss: 0.14136825501918793
train-epoch-step: 103-557 -- Loss: 0.2331080138683319
train-epoch-step: 103-558 -- Loss: 0.22167477011680603
train-epoch-step: 103-559 -- Loss: 0.12927323579788208
train-epoch-step: 103-560 -- Loss: 0.20486289262771606
train-epoch-step: 103-561 -- Loss: 0.1825411021709442
train-epoch-step: 103-562 -- Loss: 0.1507425606250763
train-epoch-step: 103-563 -- Loss: 0.1775875687599182
train-epoch-step: 103-564 -- Loss: 0.09961484372615814
train-epoch-step: 103-565 -- Loss: 0.25875288248062134
train-epoch-step: 103-566 -- Loss: 0.14589214324951172
train-epoch-step: 103-567 -- Loss: 0.22175000607967377
train-epoch-step: 103-568 -- Loss: 0.16023796796798706
train-epoch-step: 103-569 -- Loss: 0.24271118640899658
train-epoch-step: 103-570 -- Loss: 0.17153777182102203
train-epoch-step: 103-571 -- Loss: 0.21624620258808136
train-epoch-step: 103-572 -- Loss: 0.25167155265808105
train-epoch-step: 103-573 -- Loss: 0.20703978836536407
train-epoch-step: 103-574 -- Loss: 0.27615195512771606
train-epoch-step: 103-575 -- Loss: 0.329576700925827
train-epoch-step: 103-576 -- Loss: 0.13031689822673798
train-epoch-step: 103-577 -- Loss: 0.1744535267353058
train-epoch-step: 103-578 -- Loss: 0.21958279609680176
train-epoch-step: 103-579 -- Loss: 0.1652236431837082
train-epoch-step: 103-580 -- Loss: 0.1860222965478897
train-epoch-step: 103-581 -- Loss: 0.16149866580963135
train-epoch-step: 103-582 -- Loss: 0.21938180923461914
train-epoch-step: 103-583 -- Loss: 0.2968774139881134
train-epoch-step: 103-584 -- Loss: 0.17602990567684174
train-epoch-step: 103-585 -- Loss: 0.20715847611427307
train-epoch-step: 103-586 -- Loss: 0.26630282402038574
train-epoch-step: 103-587 -- Loss: 0.1704462468624115
train-epoch-step: 103-588 -- Loss: 0.14571678638458252
val-epoch-step: 103-589 -- Loss: 0.24536098539829254
val-epoch-step: 103-590 -- Loss: 0.16281037032604218
val-epoch-step: 103-591 -- Loss: 0.2571905255317688
val-epoch-step: 103-592 -- Loss: 0.18120791018009186
val-epoch-step: 103-593 -- Loss: 0.16545122861862183
val-epoch-step: 103-594 -- Loss: 0.42078012228012085
val-epoch-step: 103-595 -- Loss: 0.18319284915924072
val-epoch-step: 103-596 -- Loss: 0.26835083961486816
val-epoch-step: 103-597 -- Loss: 0.18831926584243774
val-epoch-step: 103-598 -- Loss: 0.1628475785255432
val-epoch-step: 103-599 -- Loss: 0.18847233057022095
val-epoch-step: 103-600 -- Loss: 0.18767210841178894
val-epoch-step: 103-601 -- Loss: 0.18747903406620026
val-epoch-step: 103-602 -- Loss: 0.15698206424713135
val-epoch-step: 103-603 -- Loss: 0.2082735300064087
val-epoch-step: 103-604 -- Loss: 0.17548955976963043
val-epoch-step: 103-605 -- Loss: 0.15908728539943695
val-epoch-step: 103-606 -- Loss: 0.2767462730407715
val-epoch-step: 103-607 -- Loss: 0.16851156949996948
val-epoch-step: 103-608 -- Loss: 0.27473822236061096
val-epoch-step: 103-609 -- Loss: 0.1814720332622528
val-epoch-step: 103-610 -- Loss: 0.19006803631782532
val-epoch-step: 103-611 -- Loss: 0.16301174461841583
val-epoch-step: 103-612 -- Loss: 0.4329855144023895
val-epoch-step: 103-613 -- Loss: 0.17924413084983826
val-epoch-step: 103-614 -- Loss: 0.19373399019241333
val-epoch-step: 103-615 -- Loss: 0.18053242564201355
val-epoch-step: 103-616 -- Loss: 0.15777891874313354
val-epoch-step: 103-617 -- Loss: 0.21343225240707397
val-epoch-step: 103-618 -- Loss: 0.26333242654800415
val-epoch-step: 103-619 -- Loss: 0.22507040202617645
val-epoch-step: 103-620 -- Loss: 0.14765629172325134
val-epoch-step: 103-621 -- Loss: 0.13596297800540924
val-epoch-step: 103-622 -- Loss: 0.17167358100414276
val-epoch-step: 103-623 -- Loss: 0.15425817668437958
val-epoch-step: 103-624 -- Loss: 0.14154815673828125
val-epoch-step: 103-625 -- Loss: 0.17234855890274048
val-epoch-step: 103-626 -- Loss: 0.16153056919574738
val-epoch-step: 103-627 -- Loss: 0.200079545378685
val-epoch-step: 103-628 -- Loss: 0.4833340048789978
val-epoch-step: 103-629 -- Loss: 0.273826003074646
val-epoch-step: 103-630 -- Loss: 0.36006948351860046
val-epoch-step: 103-631 -- Loss: 0.1662454605102539
val-epoch-step: 103-632 -- Loss: 0.23138287663459778
val-epoch-step: 103-633 -- Loss: 0.16932496428489685
val-epoch-step: 103-634 -- Loss: 0.14853963255882263
val-epoch-step: 103-635 -- Loss: 0.11932048201560974
val-epoch-step: 103-636 -- Loss: 0.17962895333766937
val-epoch-step: 103-637 -- Loss: 0.18814438581466675
val-epoch-step: 103-638 -- Loss: 0.1862252652645111
val-epoch-step: 103-639 -- Loss: 0.2582709789276123
val-epoch-step: 103-640 -- Loss: 0.2717197835445404
val-epoch-step: 103-641 -- Loss: 0.174125537276268
val-epoch-step: 103-642 -- Loss: 0.21068307757377625
val-epoch-step: 103-643 -- Loss: 0.2085903435945511
val-epoch-step: 103-644 -- Loss: 0.18992650508880615
val-epoch-step: 103-645 -- Loss: 0.23085102438926697
val-epoch-step: 103-646 -- Loss: 0.15228402614593506
val-epoch-step: 103-647 -- Loss: 0.1343562752008438
val-epoch-step: 103-648 -- Loss: 0.17518198490142822
val-epoch-step: 103-649 -- Loss: 0.37762266397476196
val-epoch-step: 103-650 -- Loss: 0.25819364190101624
val-epoch-step: 103-651 -- Loss: 0.14757508039474487
val-epoch-step: 103-652 -- Loss: 0.1687934398651123
val-epoch-step: 103-653 -- Loss: 0.23095127940177917
val-epoch-step: 103-654 -- Loss: 0.12861281633377075
Epoch: 103 -- Train Loss: tensor(0.1387, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 104-0 -- Loss: 0.23227019608020782
train-epoch-step: 104-1 -- Loss: 0.1509026288986206
train-epoch-step: 104-2 -- Loss: 0.2114185243844986
train-epoch-step: 104-3 -- Loss: 0.1538577824831009
train-epoch-step: 104-4 -- Loss: 0.16259890794754028
train-epoch-step: 104-5 -- Loss: 0.21277908980846405
train-epoch-step: 104-6 -- Loss: 0.2782720923423767
train-epoch-step: 104-7 -- Loss: 0.1690857708454132
train-epoch-step: 104-8 -- Loss: 0.25731050968170166
train-epoch-step: 104-9 -- Loss: 0.24306899309158325
train-epoch-step: 104-10 -- Loss: 0.19112877547740936
train-epoch-step: 104-11 -- Loss: 0.188075989484787
train-epoch-step: 104-12 -- Loss: 0.1611059457063675
train-epoch-step: 104-13 -- Loss: 0.1883484125137329
train-epoch-step: 104-14 -- Loss: 0.1744452565908432
train-epoch-step: 104-15 -- Loss: 0.18795958161354065
train-epoch-step: 104-16 -- Loss: 0.17594917118549347
train-epoch-step: 104-17 -- Loss: 0.2746541500091553
train-epoch-step: 104-18 -- Loss: 0.21654097735881805
train-epoch-step: 104-19 -- Loss: 0.1416511833667755
train-epoch-step: 104-20 -- Loss: 0.3142601251602173
train-epoch-step: 104-21 -- Loss: 0.2617613673210144
train-epoch-step: 104-22 -- Loss: 0.14384309947490692
train-epoch-step: 104-23 -- Loss: 0.15946143865585327
train-epoch-step: 104-24 -- Loss: 0.13003000617027283
train-epoch-step: 104-25 -- Loss: 0.22295337915420532
train-epoch-step: 104-26 -- Loss: 0.22282148897647858
train-epoch-step: 104-27 -- Loss: 0.29645949602127075
train-epoch-step: 104-28 -- Loss: 0.12735338509082794
train-epoch-step: 104-29 -- Loss: 0.28097400069236755
train-epoch-step: 104-30 -- Loss: 0.11661823093891144
train-epoch-step: 104-31 -- Loss: 0.17561867833137512
train-epoch-step: 104-32 -- Loss: 0.17397698760032654
train-epoch-step: 104-33 -- Loss: 0.3090316951274872
train-epoch-step: 104-34 -- Loss: 0.19322341680526733
train-epoch-step: 104-35 -- Loss: 0.24504093825817108
train-epoch-step: 104-36 -- Loss: 0.14506080746650696
train-epoch-step: 104-37 -- Loss: 0.15200425684452057
train-epoch-step: 104-38 -- Loss: 0.2591100335121155
train-epoch-step: 104-39 -- Loss: 0.31990405917167664
train-epoch-step: 104-40 -- Loss: 0.23174530267715454
train-epoch-step: 104-41 -- Loss: 0.2301763892173767
train-epoch-step: 104-42 -- Loss: 0.16185423731803894
train-epoch-step: 104-43 -- Loss: 0.28421270847320557
train-epoch-step: 104-44 -- Loss: 0.1306687742471695
train-epoch-step: 104-45 -- Loss: 0.13288457691669464
train-epoch-step: 104-46 -- Loss: 0.18118591606616974
train-epoch-step: 104-47 -- Loss: 0.23948977887630463
train-epoch-step: 104-48 -- Loss: 0.17334944009780884
train-epoch-step: 104-49 -- Loss: 0.24891915917396545
train-epoch-step: 104-50 -- Loss: 0.12072902917861938
train-epoch-step: 104-51 -- Loss: 0.21604713797569275
train-epoch-step: 104-52 -- Loss: 0.169705331325531
train-epoch-step: 104-53 -- Loss: 0.2389923334121704
train-epoch-step: 104-54 -- Loss: 0.3321400582790375
train-epoch-step: 104-55 -- Loss: 0.2060244083404541
train-epoch-step: 104-56 -- Loss: 0.19310718774795532
train-epoch-step: 104-57 -- Loss: 0.24944090843200684
train-epoch-step: 104-58 -- Loss: 0.30910977721214294
train-epoch-step: 104-59 -- Loss: 0.24708062410354614
train-epoch-step: 104-60 -- Loss: 0.13395144045352936
train-epoch-step: 104-61 -- Loss: 0.20564720034599304
train-epoch-step: 104-62 -- Loss: 0.19125285744667053
train-epoch-step: 104-63 -- Loss: 0.14222463965415955
train-epoch-step: 104-64 -- Loss: 0.14989006519317627
train-epoch-step: 104-65 -- Loss: 0.19040848314762115
train-epoch-step: 104-66 -- Loss: 0.11309520900249481
train-epoch-step: 104-67 -- Loss: 0.12351946532726288
train-epoch-step: 104-68 -- Loss: 0.2107994109392166
train-epoch-step: 104-69 -- Loss: 0.12204963713884354
train-epoch-step: 104-70 -- Loss: 0.25931110978126526
train-epoch-step: 104-71 -- Loss: 0.2681824564933777
train-epoch-step: 104-72 -- Loss: 0.17234539985656738
train-epoch-step: 104-73 -- Loss: 0.2267632782459259
train-epoch-step: 104-74 -- Loss: 0.10159271955490112
train-epoch-step: 104-75 -- Loss: 0.12846218049526215
train-epoch-step: 104-76 -- Loss: 0.15216776728630066
train-epoch-step: 104-77 -- Loss: 0.2306346893310547
train-epoch-step: 104-78 -- Loss: 0.3369274437427521
train-epoch-step: 104-79 -- Loss: 0.19573402404785156
train-epoch-step: 104-80 -- Loss: 0.25538527965545654
train-epoch-step: 104-81 -- Loss: 0.13761869072914124
train-epoch-step: 104-82 -- Loss: 0.2559657394886017
train-epoch-step: 104-83 -- Loss: 0.18709012866020203
train-epoch-step: 104-84 -- Loss: 0.19833460450172424
train-epoch-step: 104-85 -- Loss: 0.17470383644104004
train-epoch-step: 104-86 -- Loss: 0.12242133915424347
train-epoch-step: 104-87 -- Loss: 0.24147871136665344
train-epoch-step: 104-88 -- Loss: 0.14324766397476196
train-epoch-step: 104-89 -- Loss: 0.21636763215065002
train-epoch-step: 104-90 -- Loss: 0.1916009783744812
train-epoch-step: 104-91 -- Loss: 0.25489410758018494
train-epoch-step: 104-92 -- Loss: 0.15394477546215057
train-epoch-step: 104-93 -- Loss: 0.2096945345401764
train-epoch-step: 104-94 -- Loss: 0.33910560607910156
train-epoch-step: 104-95 -- Loss: 0.1902635395526886
train-epoch-step: 104-96 -- Loss: 0.21749329566955566
train-epoch-step: 104-97 -- Loss: 0.17571629583835602
train-epoch-step: 104-98 -- Loss: 0.1528676450252533
train-epoch-step: 104-99 -- Loss: 0.19162778556346893
train-epoch-step: 104-100 -- Loss: 0.18841713666915894
train-epoch-step: 104-101 -- Loss: 0.2731875479221344
train-epoch-step: 104-102 -- Loss: 0.2594898045063019
train-epoch-step: 104-103 -- Loss: 0.18860045075416565
train-epoch-step: 104-104 -- Loss: 0.15081046521663666
train-epoch-step: 104-105 -- Loss: 0.28116849064826965
train-epoch-step: 104-106 -- Loss: 0.18269360065460205
train-epoch-step: 104-107 -- Loss: 0.20438143610954285
train-epoch-step: 104-108 -- Loss: 0.2815872132778168
train-epoch-step: 104-109 -- Loss: 0.15516352653503418
train-epoch-step: 104-110 -- Loss: 0.19395208358764648
train-epoch-step: 104-111 -- Loss: 0.18821339309215546
train-epoch-step: 104-112 -- Loss: 0.1662416309118271
train-epoch-step: 104-113 -- Loss: 0.18637554347515106
train-epoch-step: 104-114 -- Loss: 0.19753989577293396
train-epoch-step: 104-115 -- Loss: 0.16561359167099
train-epoch-step: 104-116 -- Loss: 0.1439930498600006
train-epoch-step: 104-117 -- Loss: 0.13325555622577667
train-epoch-step: 104-118 -- Loss: 0.1980338841676712
train-epoch-step: 104-119 -- Loss: 0.16672158241271973
train-epoch-step: 104-120 -- Loss: 0.24878090620040894
train-epoch-step: 104-121 -- Loss: 0.2561657428741455
train-epoch-step: 104-122 -- Loss: 0.27875077724456787
train-epoch-step: 104-123 -- Loss: 0.22081349790096283
train-epoch-step: 104-124 -- Loss: 0.13475632667541504
train-epoch-step: 104-125 -- Loss: 0.15829993784427643
train-epoch-step: 104-126 -- Loss: 0.24225075542926788
train-epoch-step: 104-127 -- Loss: 0.19912539422512054
train-epoch-step: 104-128 -- Loss: 0.19131526350975037
train-epoch-step: 104-129 -- Loss: 0.1606672704219818
train-epoch-step: 104-130 -- Loss: 0.2165776938199997
train-epoch-step: 104-131 -- Loss: 0.14140525460243225
train-epoch-step: 104-132 -- Loss: 0.20162172615528107
train-epoch-step: 104-133 -- Loss: 0.12804631888866425
train-epoch-step: 104-134 -- Loss: 0.2218095362186432
train-epoch-step: 104-135 -- Loss: 0.13713453710079193
train-epoch-step: 104-136 -- Loss: 0.12986938655376434
train-epoch-step: 104-137 -- Loss: 0.26890048384666443
train-epoch-step: 104-138 -- Loss: 0.2703802287578583
train-epoch-step: 104-139 -- Loss: 0.1375543624162674
train-epoch-step: 104-140 -- Loss: 0.2597440481185913
train-epoch-step: 104-141 -- Loss: 0.2439490258693695
train-epoch-step: 104-142 -- Loss: 0.21053627133369446
train-epoch-step: 104-143 -- Loss: 0.18296536803245544
train-epoch-step: 104-144 -- Loss: 0.18810725212097168
train-epoch-step: 104-145 -- Loss: 0.15562450885772705
train-epoch-step: 104-146 -- Loss: 0.1777336299419403
train-epoch-step: 104-147 -- Loss: 0.1697704792022705
train-epoch-step: 104-148 -- Loss: 0.16609394550323486
train-epoch-step: 104-149 -- Loss: 0.12186871469020844
train-epoch-step: 104-150 -- Loss: 0.18863257765769958
train-epoch-step: 104-151 -- Loss: 0.20580515265464783
train-epoch-step: 104-152 -- Loss: 0.1921629160642624
train-epoch-step: 104-153 -- Loss: 0.28454118967056274
train-epoch-step: 104-154 -- Loss: 0.13492318987846375
train-epoch-step: 104-155 -- Loss: 0.14254963397979736
train-epoch-step: 104-156 -- Loss: 0.11993329972028732
train-epoch-step: 104-157 -- Loss: 0.1633593589067459
train-epoch-step: 104-158 -- Loss: 0.17510643601417542
train-epoch-step: 104-159 -- Loss: 0.18265566229820251
train-epoch-step: 104-160 -- Loss: 0.22542932629585266
train-epoch-step: 104-161 -- Loss: 0.21064093708992004
train-epoch-step: 104-162 -- Loss: 0.20538398623466492
train-epoch-step: 104-163 -- Loss: 0.18713203072547913
train-epoch-step: 104-164 -- Loss: 0.19560575485229492
train-epoch-step: 104-165 -- Loss: 0.1607467383146286
train-epoch-step: 104-166 -- Loss: 0.1181754618883133
train-epoch-step: 104-167 -- Loss: 0.1321365088224411
train-epoch-step: 104-168 -- Loss: 0.203605055809021
train-epoch-step: 104-169 -- Loss: 0.1424122154712677
train-epoch-step: 104-170 -- Loss: 0.1944005936384201
train-epoch-step: 104-171 -- Loss: 0.14075380563735962
train-epoch-step: 104-172 -- Loss: 0.2561878263950348
train-epoch-step: 104-173 -- Loss: 0.13483481109142303
train-epoch-step: 104-174 -- Loss: 0.2406587451696396
train-epoch-step: 104-175 -- Loss: 0.1831284463405609
train-epoch-step: 104-176 -- Loss: 0.13702699542045593
train-epoch-step: 104-177 -- Loss: 0.17614105343818665
train-epoch-step: 104-178 -- Loss: 0.17612455785274506
train-epoch-step: 104-179 -- Loss: 0.14591623842716217
train-epoch-step: 104-180 -- Loss: 0.14941316843032837
train-epoch-step: 104-181 -- Loss: 0.16482724249362946
train-epoch-step: 104-182 -- Loss: 0.1830098181962967
train-epoch-step: 104-183 -- Loss: 0.2731814384460449
train-epoch-step: 104-184 -- Loss: 0.1381041407585144
train-epoch-step: 104-185 -- Loss: 0.14021533727645874
train-epoch-step: 104-186 -- Loss: 0.18303510546684265
train-epoch-step: 104-187 -- Loss: 0.2058098018169403
train-epoch-step: 104-188 -- Loss: 0.17294754087924957
train-epoch-step: 104-189 -- Loss: 0.10325363278388977
train-epoch-step: 104-190 -- Loss: 0.18716377019882202
train-epoch-step: 104-191 -- Loss: 0.15967419743537903
train-epoch-step: 104-192 -- Loss: 0.23298178613185883
train-epoch-step: 104-193 -- Loss: 0.19741621613502502
train-epoch-step: 104-194 -- Loss: 0.17776477336883545
train-epoch-step: 104-195 -- Loss: 0.16251568496227264
train-epoch-step: 104-196 -- Loss: 0.17444825172424316
train-epoch-step: 104-197 -- Loss: 0.13213732838630676
train-epoch-step: 104-198 -- Loss: 0.12450836598873138
train-epoch-step: 104-199 -- Loss: 0.15661121904850006
train-epoch-step: 104-200 -- Loss: 0.12393774092197418
train-epoch-step: 104-201 -- Loss: 0.18152578175067902
train-epoch-step: 104-202 -- Loss: 0.1339414417743683
train-epoch-step: 104-203 -- Loss: 0.18611617386341095
train-epoch-step: 104-204 -- Loss: 0.13677366077899933
train-epoch-step: 104-205 -- Loss: 0.20126035809516907
train-epoch-step: 104-206 -- Loss: 0.19725239276885986
train-epoch-step: 104-207 -- Loss: 0.12864738702774048
train-epoch-step: 104-208 -- Loss: 0.1755807101726532
train-epoch-step: 104-209 -- Loss: 0.14488236606121063
train-epoch-step: 104-210 -- Loss: 0.13260264694690704
train-epoch-step: 104-211 -- Loss: 0.2095617651939392
train-epoch-step: 104-212 -- Loss: 0.20045074820518494
train-epoch-step: 104-213 -- Loss: 0.12630128860473633
train-epoch-step: 104-214 -- Loss: 0.14384515583515167
train-epoch-step: 104-215 -- Loss: 0.12274251878261566
train-epoch-step: 104-216 -- Loss: 0.19523461163043976
train-epoch-step: 104-217 -- Loss: 0.21431991457939148
train-epoch-step: 104-218 -- Loss: 0.14395590126514435
train-epoch-step: 104-219 -- Loss: 0.16618749499320984
train-epoch-step: 104-220 -- Loss: 0.12863387167453766
train-epoch-step: 104-221 -- Loss: 0.2008497416973114
train-epoch-step: 104-222 -- Loss: 0.11500892788171768
train-epoch-step: 104-223 -- Loss: 0.1674806922674179
train-epoch-step: 104-224 -- Loss: 0.1915544867515564
train-epoch-step: 104-225 -- Loss: 0.264792263507843
train-epoch-step: 104-226 -- Loss: 0.20436862111091614
train-epoch-step: 104-227 -- Loss: 0.21672819554805756
train-epoch-step: 104-228 -- Loss: 0.1776549220085144
train-epoch-step: 104-229 -- Loss: 0.169038787484169
train-epoch-step: 104-230 -- Loss: 0.16013239324092865
train-epoch-step: 104-231 -- Loss: 0.1525023728609085
train-epoch-step: 104-232 -- Loss: 0.17986246943473816
train-epoch-step: 104-233 -- Loss: 0.0860682874917984
train-epoch-step: 104-234 -- Loss: 0.1692848801612854
train-epoch-step: 104-235 -- Loss: 0.14278782904148102
train-epoch-step: 104-236 -- Loss: 0.17463210225105286
train-epoch-step: 104-237 -- Loss: 0.22828374803066254
train-epoch-step: 104-238 -- Loss: 0.16045121848583221
train-epoch-step: 104-239 -- Loss: 0.1238594800233841
train-epoch-step: 104-240 -- Loss: 0.2254904955625534
train-epoch-step: 104-241 -- Loss: 0.1583637148141861
train-epoch-step: 104-242 -- Loss: 0.21498331427574158
train-epoch-step: 104-243 -- Loss: 0.22798168659210205
train-epoch-step: 104-244 -- Loss: 0.2058745175600052
train-epoch-step: 104-245 -- Loss: 0.20937994122505188
train-epoch-step: 104-246 -- Loss: 0.21724900603294373
train-epoch-step: 104-247 -- Loss: 0.203170508146286
train-epoch-step: 104-248 -- Loss: 0.18193070590496063
train-epoch-step: 104-249 -- Loss: 0.1369006484746933
train-epoch-step: 104-250 -- Loss: 0.20188771188259125
train-epoch-step: 104-251 -- Loss: 0.10299858450889587
train-epoch-step: 104-252 -- Loss: 0.19762709736824036
train-epoch-step: 104-253 -- Loss: 0.1354283094406128
train-epoch-step: 104-254 -- Loss: 0.20870046317577362
train-epoch-step: 104-255 -- Loss: 0.14042024314403534
train-epoch-step: 104-256 -- Loss: 0.14972692728042603
train-epoch-step: 104-257 -- Loss: 0.19116489589214325
train-epoch-step: 104-258 -- Loss: 0.14262007176876068
train-epoch-step: 104-259 -- Loss: 0.11170533299446106
train-epoch-step: 104-260 -- Loss: 0.19674648344516754
train-epoch-step: 104-261 -- Loss: 0.16861435770988464
train-epoch-step: 104-262 -- Loss: 0.2864476442337036
train-epoch-step: 104-263 -- Loss: 0.1985348016023636
train-epoch-step: 104-264 -- Loss: 0.16782605648040771
train-epoch-step: 104-265 -- Loss: 0.10761649161577225
train-epoch-step: 104-266 -- Loss: 0.14819297194480896
train-epoch-step: 104-267 -- Loss: 0.12711180746555328
train-epoch-step: 104-268 -- Loss: 0.11246662586927414
train-epoch-step: 104-269 -- Loss: 0.16937567293643951
train-epoch-step: 104-270 -- Loss: 0.1055619865655899
train-epoch-step: 104-271 -- Loss: 0.14390623569488525
train-epoch-step: 104-272 -- Loss: 0.11919108033180237
train-epoch-step: 104-273 -- Loss: 0.12622448801994324
train-epoch-step: 104-274 -- Loss: 0.17671456933021545
train-epoch-step: 104-275 -- Loss: 0.19801533222198486
train-epoch-step: 104-276 -- Loss: 0.16068696975708008
train-epoch-step: 104-277 -- Loss: 0.148581862449646
train-epoch-step: 104-278 -- Loss: 0.1484055519104004
train-epoch-step: 104-279 -- Loss: 0.14200814068317413
train-epoch-step: 104-280 -- Loss: 0.21106214821338654
train-epoch-step: 104-281 -- Loss: 0.1777082085609436
train-epoch-step: 104-282 -- Loss: 0.1402117758989334
train-epoch-step: 104-283 -- Loss: 0.11163138598203659
train-epoch-step: 104-284 -- Loss: 0.12995749711990356
train-epoch-step: 104-285 -- Loss: 0.190928652882576
train-epoch-step: 104-286 -- Loss: 0.15108321607112885
train-epoch-step: 104-287 -- Loss: 0.1971745640039444
train-epoch-step: 104-288 -- Loss: 0.09274876862764359
train-epoch-step: 104-289 -- Loss: 0.11680946499109268
train-epoch-step: 104-290 -- Loss: 0.17452749609947205
train-epoch-step: 104-291 -- Loss: 0.11361035704612732
train-epoch-step: 104-292 -- Loss: 0.152112677693367
train-epoch-step: 104-293 -- Loss: 0.1358719766139984
train-epoch-step: 104-294 -- Loss: 0.1548883616924286
train-epoch-step: 104-295 -- Loss: 0.2519923746585846
train-epoch-step: 104-296 -- Loss: 0.1545257419347763
train-epoch-step: 104-297 -- Loss: 0.1668255627155304
train-epoch-step: 104-298 -- Loss: 0.22450341284275055
train-epoch-step: 104-299 -- Loss: 0.14221447706222534
train-epoch-step: 104-300 -- Loss: 0.1593882441520691
train-epoch-step: 104-301 -- Loss: 0.1737237274646759
train-epoch-step: 104-302 -- Loss: 0.21305721998214722
train-epoch-step: 104-303 -- Loss: 0.20548921823501587
train-epoch-step: 104-304 -- Loss: 0.12189289182424545
train-epoch-step: 104-305 -- Loss: 0.1386772096157074
train-epoch-step: 104-306 -- Loss: 0.22709918022155762
train-epoch-step: 104-307 -- Loss: 0.15892450511455536
train-epoch-step: 104-308 -- Loss: 0.2211250364780426
train-epoch-step: 104-309 -- Loss: 0.15622273087501526
train-epoch-step: 104-310 -- Loss: 0.15967020392417908
train-epoch-step: 104-311 -- Loss: 0.1539405733346939
train-epoch-step: 104-312 -- Loss: 0.19542081654071808
train-epoch-step: 104-313 -- Loss: 0.09348659217357635
train-epoch-step: 104-314 -- Loss: 0.18404069542884827
train-epoch-step: 104-315 -- Loss: 0.1653985232114792
train-epoch-step: 104-316 -- Loss: 0.15641510486602783
train-epoch-step: 104-317 -- Loss: 0.140128031373024
train-epoch-step: 104-318 -- Loss: 0.1573982536792755
train-epoch-step: 104-319 -- Loss: 0.1626695990562439
train-epoch-step: 104-320 -- Loss: 0.11731657385826111
train-epoch-step: 104-321 -- Loss: 0.1276293843984604
train-epoch-step: 104-322 -- Loss: 0.20819146931171417
train-epoch-step: 104-323 -- Loss: 0.157739520072937
train-epoch-step: 104-324 -- Loss: 0.2611844837665558
train-epoch-step: 104-325 -- Loss: 0.1522032469511032
train-epoch-step: 104-326 -- Loss: 0.17123061418533325
train-epoch-step: 104-327 -- Loss: 0.20549717545509338
train-epoch-step: 104-328 -- Loss: 0.19198936223983765
train-epoch-step: 104-329 -- Loss: 0.33482277393341064
train-epoch-step: 104-330 -- Loss: 0.34795838594436646
train-epoch-step: 104-331 -- Loss: 0.2066018283367157
train-epoch-step: 104-332 -- Loss: 0.09946468472480774
train-epoch-step: 104-333 -- Loss: 0.18108676373958588
train-epoch-step: 104-334 -- Loss: 0.15518724918365479
train-epoch-step: 104-335 -- Loss: 0.16760507225990295
train-epoch-step: 104-336 -- Loss: 0.14411716163158417
train-epoch-step: 104-337 -- Loss: 0.19943220913410187
train-epoch-step: 104-338 -- Loss: 0.15767475962638855
train-epoch-step: 104-339 -- Loss: 0.14143669605255127
train-epoch-step: 104-340 -- Loss: 0.19157154858112335
train-epoch-step: 104-341 -- Loss: 0.15413540601730347
train-epoch-step: 104-342 -- Loss: 0.16278855502605438
train-epoch-step: 104-343 -- Loss: 0.15097692608833313
train-epoch-step: 104-344 -- Loss: 0.161050945520401
train-epoch-step: 104-345 -- Loss: 0.13536031544208527
train-epoch-step: 104-346 -- Loss: 0.2077198028564453
train-epoch-step: 104-347 -- Loss: 0.14713597297668457
train-epoch-step: 104-348 -- Loss: 0.1961575448513031
train-epoch-step: 104-349 -- Loss: 0.20142506062984467
train-epoch-step: 104-350 -- Loss: 0.2518272399902344
train-epoch-step: 104-351 -- Loss: 0.18693989515304565
train-epoch-step: 104-352 -- Loss: 0.12098577618598938
train-epoch-step: 104-353 -- Loss: 0.19423457980155945
train-epoch-step: 104-354 -- Loss: 0.2801004946231842
train-epoch-step: 104-355 -- Loss: 0.11541211605072021
train-epoch-step: 104-356 -- Loss: 0.11588987708091736
train-epoch-step: 104-357 -- Loss: 0.18473458290100098
train-epoch-step: 104-358 -- Loss: 0.18235111236572266
train-epoch-step: 104-359 -- Loss: 0.13638168573379517
train-epoch-step: 104-360 -- Loss: 0.11871114373207092
train-epoch-step: 104-361 -- Loss: 0.23161128163337708
train-epoch-step: 104-362 -- Loss: 0.17162200808525085
train-epoch-step: 104-363 -- Loss: 0.10650710016489029
train-epoch-step: 104-364 -- Loss: 0.1752503216266632
train-epoch-step: 104-365 -- Loss: 0.17251215875148773
train-epoch-step: 104-366 -- Loss: 0.19851794838905334
train-epoch-step: 104-367 -- Loss: 0.22606085240840912
train-epoch-step: 104-368 -- Loss: 0.19334286451339722
train-epoch-step: 104-369 -- Loss: 0.27208641171455383
train-epoch-step: 104-370 -- Loss: 0.12175896763801575
train-epoch-step: 104-371 -- Loss: 0.12013948708772659
train-epoch-step: 104-372 -- Loss: 0.14436674118041992
train-epoch-step: 104-373 -- Loss: 0.1812984049320221
train-epoch-step: 104-374 -- Loss: 0.15248459577560425
train-epoch-step: 104-375 -- Loss: 0.2593866288661957
train-epoch-step: 104-376 -- Loss: 0.16014854609966278
train-epoch-step: 104-377 -- Loss: 0.2182496339082718
train-epoch-step: 104-378 -- Loss: 0.19763284921646118
train-epoch-step: 104-379 -- Loss: 0.11434531956911087
train-epoch-step: 104-380 -- Loss: 0.09031809866428375
train-epoch-step: 104-381 -- Loss: 0.2349396049976349
train-epoch-step: 104-382 -- Loss: 0.22918978333473206
train-epoch-step: 104-383 -- Loss: 0.17533722519874573
train-epoch-step: 104-384 -- Loss: 0.2121080756187439
train-epoch-step: 104-385 -- Loss: 0.18879058957099915
train-epoch-step: 104-386 -- Loss: 0.17988677322864532
train-epoch-step: 104-387 -- Loss: 0.1998102366924286
train-epoch-step: 104-388 -- Loss: 0.1834232658147812
train-epoch-step: 104-389 -- Loss: 0.1610790491104126
train-epoch-step: 104-390 -- Loss: 0.13716815412044525
train-epoch-step: 104-391 -- Loss: 0.1447174847126007
train-epoch-step: 104-392 -- Loss: 0.17644280195236206
train-epoch-step: 104-393 -- Loss: 0.15097233653068542
train-epoch-step: 104-394 -- Loss: 0.19154638051986694
train-epoch-step: 104-395 -- Loss: 0.1469898670911789
train-epoch-step: 104-396 -- Loss: 0.1228552833199501
train-epoch-step: 104-397 -- Loss: 0.12100100517272949
train-epoch-step: 104-398 -- Loss: 0.1939598023891449
train-epoch-step: 104-399 -- Loss: 0.1754639744758606
train-epoch-step: 104-400 -- Loss: 0.26778745651245117
train-epoch-step: 104-401 -- Loss: 0.11756633222103119
train-epoch-step: 104-402 -- Loss: 0.24281863868236542
train-epoch-step: 104-403 -- Loss: 0.16326873004436493
train-epoch-step: 104-404 -- Loss: 0.1348474770784378
train-epoch-step: 104-405 -- Loss: 0.14403386414051056
train-epoch-step: 104-406 -- Loss: 0.16032305359840393
train-epoch-step: 104-407 -- Loss: 0.1086074635386467
train-epoch-step: 104-408 -- Loss: 0.1575040966272354
train-epoch-step: 104-409 -- Loss: 0.17209330201148987
train-epoch-step: 104-410 -- Loss: 0.1730538010597229
train-epoch-step: 104-411 -- Loss: 0.19596640765666962
train-epoch-step: 104-412 -- Loss: 0.12800170481204987
train-epoch-step: 104-413 -- Loss: 0.1439332515001297
train-epoch-step: 104-414 -- Loss: 0.13337814807891846
train-epoch-step: 104-415 -- Loss: 0.13377544283866882
train-epoch-step: 104-416 -- Loss: 0.26104819774627686
train-epoch-step: 104-417 -- Loss: 0.18477745354175568
train-epoch-step: 104-418 -- Loss: 0.22805486619472504
train-epoch-step: 104-419 -- Loss: 0.1611325740814209
train-epoch-step: 104-420 -- Loss: 0.14722847938537598
train-epoch-step: 104-421 -- Loss: 0.1722887009382248
train-epoch-step: 104-422 -- Loss: 0.14341601729393005
train-epoch-step: 104-423 -- Loss: 0.19623920321464539
train-epoch-step: 104-424 -- Loss: 0.13215592503547668
train-epoch-step: 104-425 -- Loss: 0.17404471337795258
train-epoch-step: 104-426 -- Loss: 0.16599300503730774
train-epoch-step: 104-427 -- Loss: 0.11607912927865982
train-epoch-step: 104-428 -- Loss: 0.1798376441001892
train-epoch-step: 104-429 -- Loss: 0.17509564757347107
train-epoch-step: 104-430 -- Loss: 0.13640442490577698
train-epoch-step: 104-431 -- Loss: 0.1688988208770752
train-epoch-step: 104-432 -- Loss: 0.23223090171813965
train-epoch-step: 104-433 -- Loss: 0.13235433399677277
train-epoch-step: 104-434 -- Loss: 0.1228398010134697
train-epoch-step: 104-435 -- Loss: 0.15316614508628845
train-epoch-step: 104-436 -- Loss: 0.14782628417015076
train-epoch-step: 104-437 -- Loss: 0.12982754409313202
train-epoch-step: 104-438 -- Loss: 0.161225363612175
train-epoch-step: 104-439 -- Loss: 0.2605557143688202
train-epoch-step: 104-440 -- Loss: 0.12799528241157532
train-epoch-step: 104-441 -- Loss: 0.19491395354270935
train-epoch-step: 104-442 -- Loss: 0.17367705702781677
train-epoch-step: 104-443 -- Loss: 0.14918163418769836
train-epoch-step: 104-444 -- Loss: 0.17109185457229614
train-epoch-step: 104-445 -- Loss: 0.17499838769435883
train-epoch-step: 104-446 -- Loss: 0.14598619937896729
train-epoch-step: 104-447 -- Loss: 0.1844620704650879
train-epoch-step: 104-448 -- Loss: 0.2179843783378601
train-epoch-step: 104-449 -- Loss: 0.1814766526222229
train-epoch-step: 104-450 -- Loss: 0.17394763231277466
train-epoch-step: 104-451 -- Loss: 0.14258694648742676
train-epoch-step: 104-452 -- Loss: 0.12739689648151398
train-epoch-step: 104-453 -- Loss: 0.09132902324199677
train-epoch-step: 104-454 -- Loss: 0.21905040740966797
train-epoch-step: 104-455 -- Loss: 0.12615136802196503
train-epoch-step: 104-456 -- Loss: 0.11614386737346649
train-epoch-step: 104-457 -- Loss: 0.20921164751052856
train-epoch-step: 104-458 -- Loss: 0.14346763491630554
train-epoch-step: 104-459 -- Loss: 0.20626351237297058
train-epoch-step: 104-460 -- Loss: 0.1208956241607666
train-epoch-step: 104-461 -- Loss: 0.1302826702594757
train-epoch-step: 104-462 -- Loss: 0.1510305255651474
train-epoch-step: 104-463 -- Loss: 0.13065636157989502
train-epoch-step: 104-464 -- Loss: 0.1520928144454956
train-epoch-step: 104-465 -- Loss: 0.232325941324234
train-epoch-step: 104-466 -- Loss: 0.1993316411972046
train-epoch-step: 104-467 -- Loss: 0.1075332835316658
train-epoch-step: 104-468 -- Loss: 0.15963667631149292
train-epoch-step: 104-469 -- Loss: 0.19974973797798157
train-epoch-step: 104-470 -- Loss: 0.1696658581495285
train-epoch-step: 104-471 -- Loss: 0.15577039122581482
train-epoch-step: 104-472 -- Loss: 0.15290693938732147
train-epoch-step: 104-473 -- Loss: 0.14982016384601593
train-epoch-step: 104-474 -- Loss: 0.11246411502361298
train-epoch-step: 104-475 -- Loss: 0.108245849609375
train-epoch-step: 104-476 -- Loss: 0.1934419870376587
train-epoch-step: 104-477 -- Loss: 0.19146832823753357
train-epoch-step: 104-478 -- Loss: 0.18281614780426025
train-epoch-step: 104-479 -- Loss: 0.13269922137260437
train-epoch-step: 104-480 -- Loss: 0.18918782472610474
train-epoch-step: 104-481 -- Loss: 0.26992499828338623
train-epoch-step: 104-482 -- Loss: 0.2780493199825287
train-epoch-step: 104-483 -- Loss: 0.1777855008840561
train-epoch-step: 104-484 -- Loss: 0.20843112468719482
train-epoch-step: 104-485 -- Loss: 0.1228567361831665
train-epoch-step: 104-486 -- Loss: 0.2251381278038025
train-epoch-step: 104-487 -- Loss: 0.2308477759361267
train-epoch-step: 104-488 -- Loss: 0.17497438192367554
train-epoch-step: 104-489 -- Loss: 0.21170613169670105
train-epoch-step: 104-490 -- Loss: 0.13490070402622223
train-epoch-step: 104-491 -- Loss: 0.132869690656662
train-epoch-step: 104-492 -- Loss: 0.1245729923248291
train-epoch-step: 104-493 -- Loss: 0.19390980899333954
train-epoch-step: 104-494 -- Loss: 0.19490019977092743
train-epoch-step: 104-495 -- Loss: 0.1951141357421875
train-epoch-step: 104-496 -- Loss: 0.14122873544692993
train-epoch-step: 104-497 -- Loss: 0.18046343326568604
train-epoch-step: 104-498 -- Loss: 0.14090383052825928
train-epoch-step: 104-499 -- Loss: 0.16743288934230804
train-epoch-step: 104-500 -- Loss: 0.14732524752616882
train-epoch-step: 104-501 -- Loss: 0.20256711542606354
train-epoch-step: 104-502 -- Loss: 0.16257146000862122
train-epoch-step: 104-503 -- Loss: 0.21015192568302155
train-epoch-step: 104-504 -- Loss: 0.12577006220817566
train-epoch-step: 104-505 -- Loss: 0.17204293608665466
train-epoch-step: 104-506 -- Loss: 0.11102184653282166
train-epoch-step: 104-507 -- Loss: 0.17247173190116882
train-epoch-step: 104-508 -- Loss: 0.17265090346336365
train-epoch-step: 104-509 -- Loss: 0.1686183661222458
train-epoch-step: 104-510 -- Loss: 0.12454454600811005
train-epoch-step: 104-511 -- Loss: 0.21685121953487396
train-epoch-step: 104-512 -- Loss: 0.17493489384651184
train-epoch-step: 104-513 -- Loss: 0.18197119235992432
train-epoch-step: 104-514 -- Loss: 0.14082039892673492
train-epoch-step: 104-515 -- Loss: 0.14894616603851318
train-epoch-step: 104-516 -- Loss: 0.1668878048658371
train-epoch-step: 104-517 -- Loss: 0.1704537272453308
train-epoch-step: 104-518 -- Loss: 0.1385771483182907
train-epoch-step: 104-519 -- Loss: 0.13202466070652008
train-epoch-step: 104-520 -- Loss: 0.17792776226997375
train-epoch-step: 104-521 -- Loss: 0.2218169867992401
train-epoch-step: 104-522 -- Loss: 0.16743338108062744
train-epoch-step: 104-523 -- Loss: 0.15389277040958405
train-epoch-step: 104-524 -- Loss: 0.16035574674606323
train-epoch-step: 104-525 -- Loss: 0.18497192859649658
train-epoch-step: 104-526 -- Loss: 0.12414433062076569
train-epoch-step: 104-527 -- Loss: 0.14466592669487
train-epoch-step: 104-528 -- Loss: 0.15054266154766083
train-epoch-step: 104-529 -- Loss: 0.14975757896900177
train-epoch-step: 104-530 -- Loss: 0.16095493733882904
train-epoch-step: 104-531 -- Loss: 0.18852443993091583
train-epoch-step: 104-532 -- Loss: 0.16703249514102936
train-epoch-step: 104-533 -- Loss: 0.17358919978141785
train-epoch-step: 104-534 -- Loss: 0.12412228435277939
train-epoch-step: 104-535 -- Loss: 0.27159571647644043
train-epoch-step: 104-536 -- Loss: 0.15155452489852905
train-epoch-step: 104-537 -- Loss: 0.14169153571128845
train-epoch-step: 104-538 -- Loss: 0.10462834686040878
train-epoch-step: 104-539 -- Loss: 0.17934772372245789
train-epoch-step: 104-540 -- Loss: 0.1307111382484436
train-epoch-step: 104-541 -- Loss: 0.20313790440559387
train-epoch-step: 104-542 -- Loss: 0.21368874609470367
train-epoch-step: 104-543 -- Loss: 0.16041862964630127
train-epoch-step: 104-544 -- Loss: 0.22450506687164307
train-epoch-step: 104-545 -- Loss: 0.18786336481571198
train-epoch-step: 104-546 -- Loss: 0.19799761474132538
train-epoch-step: 104-547 -- Loss: 0.17760731279850006
train-epoch-step: 104-548 -- Loss: 0.08856688439846039
train-epoch-step: 104-549 -- Loss: 0.14238321781158447
train-epoch-step: 104-550 -- Loss: 0.1918705850839615
train-epoch-step: 104-551 -- Loss: 0.14851516485214233
train-epoch-step: 104-552 -- Loss: 0.11997343599796295
train-epoch-step: 104-553 -- Loss: 0.18045222759246826
train-epoch-step: 104-554 -- Loss: 0.18345098197460175
train-epoch-step: 104-555 -- Loss: 0.2086092233657837
train-epoch-step: 104-556 -- Loss: 0.1420615017414093
train-epoch-step: 104-557 -- Loss: 0.23104608058929443
train-epoch-step: 104-558 -- Loss: 0.22300568222999573
train-epoch-step: 104-559 -- Loss: 0.13240334391593933
train-epoch-step: 104-560 -- Loss: 0.20138125121593475
train-epoch-step: 104-561 -- Loss: 0.17616742849349976
train-epoch-step: 104-562 -- Loss: 0.1573978066444397
train-epoch-step: 104-563 -- Loss: 0.17703549563884735
train-epoch-step: 104-564 -- Loss: 0.09762059152126312
train-epoch-step: 104-565 -- Loss: 0.1787341982126236
train-epoch-step: 104-566 -- Loss: 0.14126282930374146
train-epoch-step: 104-567 -- Loss: 0.20311158895492554
train-epoch-step: 104-568 -- Loss: 0.15529173612594604
train-epoch-step: 104-569 -- Loss: 0.23923316597938538
train-epoch-step: 104-570 -- Loss: 0.15825513005256653
train-epoch-step: 104-571 -- Loss: 0.20859834551811218
train-epoch-step: 104-572 -- Loss: 0.23167777061462402
train-epoch-step: 104-573 -- Loss: 0.19657468795776367
train-epoch-step: 104-574 -- Loss: 0.23936156928539276
train-epoch-step: 104-575 -- Loss: 0.2865521013736725
train-epoch-step: 104-576 -- Loss: 0.11232589930295944
train-epoch-step: 104-577 -- Loss: 0.16426411271095276
train-epoch-step: 104-578 -- Loss: 0.20545899868011475
train-epoch-step: 104-579 -- Loss: 0.16182313859462738
train-epoch-step: 104-580 -- Loss: 0.168407142162323
train-epoch-step: 104-581 -- Loss: 0.13292014598846436
train-epoch-step: 104-582 -- Loss: 0.19801782071590424
train-epoch-step: 104-583 -- Loss: 0.2098420113325119
train-epoch-step: 104-584 -- Loss: 0.15597286820411682
train-epoch-step: 104-585 -- Loss: 0.18900419771671295
train-epoch-step: 104-586 -- Loss: 0.24430537223815918
train-epoch-step: 104-587 -- Loss: 0.15775956213474274
train-epoch-step: 104-588 -- Loss: 0.12244883179664612
val-epoch-step: 104-589 -- Loss: 0.2039887011051178
val-epoch-step: 104-590 -- Loss: 0.14921855926513672
val-epoch-step: 104-591 -- Loss: 0.2321627140045166
val-epoch-step: 104-592 -- Loss: 0.16664855182170868
val-epoch-step: 104-593 -- Loss: 0.1710118055343628
val-epoch-step: 104-594 -- Loss: 0.36641359329223633
val-epoch-step: 104-595 -- Loss: 0.16835756599903107
val-epoch-step: 104-596 -- Loss: 0.20242395997047424
val-epoch-step: 104-597 -- Loss: 0.16362972557544708
val-epoch-step: 104-598 -- Loss: 0.14569303393363953
val-epoch-step: 104-599 -- Loss: 0.17771923542022705
val-epoch-step: 104-600 -- Loss: 0.17256486415863037
val-epoch-step: 104-601 -- Loss: 0.15438076853752136
val-epoch-step: 104-602 -- Loss: 0.133358895778656
val-epoch-step: 104-603 -- Loss: 0.20103538036346436
val-epoch-step: 104-604 -- Loss: 0.14517822861671448
val-epoch-step: 104-605 -- Loss: 0.14181487262248993
val-epoch-step: 104-606 -- Loss: 0.2509135901927948
val-epoch-step: 104-607 -- Loss: 0.13807356357574463
val-epoch-step: 104-608 -- Loss: 0.256144642829895
val-epoch-step: 104-609 -- Loss: 0.16436094045639038
val-epoch-step: 104-610 -- Loss: 0.17159047722816467
val-epoch-step: 104-611 -- Loss: 0.1732563078403473
val-epoch-step: 104-612 -- Loss: 0.35786640644073486
val-epoch-step: 104-613 -- Loss: 0.16571280360221863
val-epoch-step: 104-614 -- Loss: 0.17888326942920685
val-epoch-step: 104-615 -- Loss: 0.16743730008602142
val-epoch-step: 104-616 -- Loss: 0.14071939885616302
val-epoch-step: 104-617 -- Loss: 0.18882881104946136
val-epoch-step: 104-618 -- Loss: 0.17662671208381653
val-epoch-step: 104-619 -- Loss: 0.19535064697265625
val-epoch-step: 104-620 -- Loss: 0.13150592148303986
val-epoch-step: 104-621 -- Loss: 0.12964588403701782
val-epoch-step: 104-622 -- Loss: 0.14400812983512878
val-epoch-step: 104-623 -- Loss: 0.1497969627380371
val-epoch-step: 104-624 -- Loss: 0.1400604546070099
val-epoch-step: 104-625 -- Loss: 0.15278969705104828
val-epoch-step: 104-626 -- Loss: 0.14516021311283112
val-epoch-step: 104-627 -- Loss: 0.1788986474275589
val-epoch-step: 104-628 -- Loss: 0.4644227921962738
val-epoch-step: 104-629 -- Loss: 0.1914401799440384
val-epoch-step: 104-630 -- Loss: 0.33825963735580444
val-epoch-step: 104-631 -- Loss: 0.13525693118572235
val-epoch-step: 104-632 -- Loss: 0.1909913718700409
val-epoch-step: 104-633 -- Loss: 0.1546841859817505
val-epoch-step: 104-634 -- Loss: 0.14943963289260864
val-epoch-step: 104-635 -- Loss: 0.1090233325958252
val-epoch-step: 104-636 -- Loss: 0.15609371662139893
val-epoch-step: 104-637 -- Loss: 0.17705677449703217
val-epoch-step: 104-638 -- Loss: 0.1545586884021759
val-epoch-step: 104-639 -- Loss: 0.25295794010162354
val-epoch-step: 104-640 -- Loss: 0.2406972348690033
val-epoch-step: 104-641 -- Loss: 0.13009721040725708
val-epoch-step: 104-642 -- Loss: 0.18052858114242554
val-epoch-step: 104-643 -- Loss: 0.2025289088487625
val-epoch-step: 104-644 -- Loss: 0.15970192849636078
val-epoch-step: 104-645 -- Loss: 0.21319739520549774
val-epoch-step: 104-646 -- Loss: 0.12371145933866501
val-epoch-step: 104-647 -- Loss: 0.12358758598566055
val-epoch-step: 104-648 -- Loss: 0.1486937254667282
val-epoch-step: 104-649 -- Loss: 0.20575395226478577
val-epoch-step: 104-650 -- Loss: 0.24631968140602112
val-epoch-step: 104-651 -- Loss: 0.14565572142601013
val-epoch-step: 104-652 -- Loss: 0.1501585990190506
val-epoch-step: 104-653 -- Loss: 0.19156917929649353
val-epoch-step: 104-654 -- Loss: 0.10825394093990326
Epoch: 104 -- Train Loss: tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1412, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 105-0 -- Loss: 0.22156262397766113
train-epoch-step: 105-1 -- Loss: 0.13636614382266998
train-epoch-step: 105-2 -- Loss: 0.18734392523765564
train-epoch-step: 105-3 -- Loss: 0.14184732735157013
train-epoch-step: 105-4 -- Loss: 0.15215393900871277
train-epoch-step: 105-5 -- Loss: 0.17721980810165405
train-epoch-step: 105-6 -- Loss: 0.22120842337608337
train-epoch-step: 105-7 -- Loss: 0.16404490172863007
train-epoch-step: 105-8 -- Loss: 0.17570920288562775
train-epoch-step: 105-9 -- Loss: 0.22142314910888672
train-epoch-step: 105-10 -- Loss: 0.1865435540676117
train-epoch-step: 105-11 -- Loss: 0.16918084025382996
train-epoch-step: 105-12 -- Loss: 0.14359350502490997
train-epoch-step: 105-13 -- Loss: 0.16941887140274048
train-epoch-step: 105-14 -- Loss: 0.1560876965522766
train-epoch-step: 105-15 -- Loss: 0.15067517757415771
train-epoch-step: 105-16 -- Loss: 0.15772570669651031
train-epoch-step: 105-17 -- Loss: 0.2118750810623169
train-epoch-step: 105-18 -- Loss: 0.1863989531993866
train-epoch-step: 105-19 -- Loss: 0.12665830552577972
train-epoch-step: 105-20 -- Loss: 0.20714502036571503
train-epoch-step: 105-21 -- Loss: 0.23453274369239807
train-epoch-step: 105-22 -- Loss: 0.1318822056055069
train-epoch-step: 105-23 -- Loss: 0.13487938046455383
train-epoch-step: 105-24 -- Loss: 0.11883389949798584
train-epoch-step: 105-25 -- Loss: 0.21058784425258636
train-epoch-step: 105-26 -- Loss: 0.18430761992931366
train-epoch-step: 105-27 -- Loss: 0.21413500607013702
train-epoch-step: 105-28 -- Loss: 0.11884208768606186
train-epoch-step: 105-29 -- Loss: 0.23665739595890045
train-epoch-step: 105-30 -- Loss: 0.10324457287788391
train-epoch-step: 105-31 -- Loss: 0.130195751786232
train-epoch-step: 105-32 -- Loss: 0.16349154710769653
train-epoch-step: 105-33 -- Loss: 0.2615143656730652
train-epoch-step: 105-34 -- Loss: 0.16714468598365784
train-epoch-step: 105-35 -- Loss: 0.2387995570898056
train-epoch-step: 105-36 -- Loss: 0.13593921065330505
train-epoch-step: 105-37 -- Loss: 0.13333725929260254
train-epoch-step: 105-38 -- Loss: 0.166756734251976
train-epoch-step: 105-39 -- Loss: 0.2073417752981186
train-epoch-step: 105-40 -- Loss: 0.18815073370933533
train-epoch-step: 105-41 -- Loss: 0.20938128232955933
train-epoch-step: 105-42 -- Loss: 0.15179935097694397
train-epoch-step: 105-43 -- Loss: 0.24912720918655396
train-epoch-step: 105-44 -- Loss: 0.12308309972286224
train-epoch-step: 105-45 -- Loss: 0.1199943795800209
train-epoch-step: 105-46 -- Loss: 0.1676543653011322
train-epoch-step: 105-47 -- Loss: 0.18863093852996826
train-epoch-step: 105-48 -- Loss: 0.15337565541267395
train-epoch-step: 105-49 -- Loss: 0.2197163999080658
train-epoch-step: 105-50 -- Loss: 0.11102146655321121
train-epoch-step: 105-51 -- Loss: 0.17389076948165894
train-epoch-step: 105-52 -- Loss: 0.1515609323978424
train-epoch-step: 105-53 -- Loss: 0.20325282216072083
train-epoch-step: 105-54 -- Loss: 0.27692121267318726
train-epoch-step: 105-55 -- Loss: 0.1581180989742279
train-epoch-step: 105-56 -- Loss: 0.1656123846769333
train-epoch-step: 105-57 -- Loss: 0.2268548160791397
train-epoch-step: 105-58 -- Loss: 0.2772091031074524
train-epoch-step: 105-59 -- Loss: 0.2381831854581833
train-epoch-step: 105-60 -- Loss: 0.12482179701328278
train-epoch-step: 105-61 -- Loss: 0.19601860642433167
train-epoch-step: 105-62 -- Loss: 0.1764080971479416
train-epoch-step: 105-63 -- Loss: 0.13195788860321045
train-epoch-step: 105-64 -- Loss: 0.1514245569705963
train-epoch-step: 105-65 -- Loss: 0.1794109046459198
train-epoch-step: 105-66 -- Loss: 0.10929816961288452
train-epoch-step: 105-67 -- Loss: 0.12535211443901062
train-epoch-step: 105-68 -- Loss: 0.21338556706905365
train-epoch-step: 105-69 -- Loss: 0.12100782990455627
train-epoch-step: 105-70 -- Loss: 0.21926599740982056
train-epoch-step: 105-71 -- Loss: 0.24978448450565338
train-epoch-step: 105-72 -- Loss: 0.16829662024974823
train-epoch-step: 105-73 -- Loss: 0.2009422779083252
train-epoch-step: 105-74 -- Loss: 0.09201359003782272
train-epoch-step: 105-75 -- Loss: 0.12507443130016327
train-epoch-step: 105-76 -- Loss: 0.13821564614772797
train-epoch-step: 105-77 -- Loss: 0.22419828176498413
train-epoch-step: 105-78 -- Loss: 0.25258955359458923
train-epoch-step: 105-79 -- Loss: 0.18880406022071838
train-epoch-step: 105-80 -- Loss: 0.253768652677536
train-epoch-step: 105-81 -- Loss: 0.1212921291589737
train-epoch-step: 105-82 -- Loss: 0.25084787607192993
train-epoch-step: 105-83 -- Loss: 0.1753963679075241
train-epoch-step: 105-84 -- Loss: 0.1848522126674652
train-epoch-step: 105-85 -- Loss: 0.16641581058502197
train-epoch-step: 105-86 -- Loss: 0.11628405749797821
train-epoch-step: 105-87 -- Loss: 0.207869753241539
train-epoch-step: 105-88 -- Loss: 0.13841953873634338
train-epoch-step: 105-89 -- Loss: 0.1796998381614685
train-epoch-step: 105-90 -- Loss: 0.18680673837661743
train-epoch-step: 105-91 -- Loss: 0.2326677292585373
train-epoch-step: 105-92 -- Loss: 0.14986953139305115
train-epoch-step: 105-93 -- Loss: 0.16915223002433777
train-epoch-step: 105-94 -- Loss: 0.21975314617156982
train-epoch-step: 105-95 -- Loss: 0.18377575278282166
train-epoch-step: 105-96 -- Loss: 0.20717251300811768
train-epoch-step: 105-97 -- Loss: 0.1720466911792755
train-epoch-step: 105-98 -- Loss: 0.15213514864444733
train-epoch-step: 105-99 -- Loss: 0.17272162437438965
train-epoch-step: 105-100 -- Loss: 0.18194082379341125
train-epoch-step: 105-101 -- Loss: 0.2495168000459671
train-epoch-step: 105-102 -- Loss: 0.2244463413953781
train-epoch-step: 105-103 -- Loss: 0.17710351943969727
train-epoch-step: 105-104 -- Loss: 0.14386749267578125
train-epoch-step: 105-105 -- Loss: 0.26128894090652466
train-epoch-step: 105-106 -- Loss: 0.1713162362575531
train-epoch-step: 105-107 -- Loss: 0.1823616474866867
train-epoch-step: 105-108 -- Loss: 0.18351513147354126
train-epoch-step: 105-109 -- Loss: 0.14024648070335388
train-epoch-step: 105-110 -- Loss: 0.17417004704475403
train-epoch-step: 105-111 -- Loss: 0.1748925894498825
train-epoch-step: 105-112 -- Loss: 0.16529183089733124
train-epoch-step: 105-113 -- Loss: 0.15696683526039124
train-epoch-step: 105-114 -- Loss: 0.19338670372962952
train-epoch-step: 105-115 -- Loss: 0.15520194172859192
train-epoch-step: 105-116 -- Loss: 0.1295841932296753
train-epoch-step: 105-117 -- Loss: 0.12072903662919998
train-epoch-step: 105-118 -- Loss: 0.18248942494392395
train-epoch-step: 105-119 -- Loss: 0.14920663833618164
train-epoch-step: 105-120 -- Loss: 0.23987463116645813
train-epoch-step: 105-121 -- Loss: 0.2235272228717804
train-epoch-step: 105-122 -- Loss: 0.21057766675949097
train-epoch-step: 105-123 -- Loss: 0.1981648951768875
train-epoch-step: 105-124 -- Loss: 0.12111686170101166
train-epoch-step: 105-125 -- Loss: 0.1474386304616928
train-epoch-step: 105-126 -- Loss: 0.2229824662208557
train-epoch-step: 105-127 -- Loss: 0.16999678313732147
train-epoch-step: 105-128 -- Loss: 0.16336771845817566
train-epoch-step: 105-129 -- Loss: 0.1365518867969513
train-epoch-step: 105-130 -- Loss: 0.18699373304843903
train-epoch-step: 105-131 -- Loss: 0.13319078087806702
train-epoch-step: 105-132 -- Loss: 0.18077963590621948
train-epoch-step: 105-133 -- Loss: 0.11774571239948273
train-epoch-step: 105-134 -- Loss: 0.18290282785892487
train-epoch-step: 105-135 -- Loss: 0.14317353069782257
train-epoch-step: 105-136 -- Loss: 0.12051840126514435
train-epoch-step: 105-137 -- Loss: 0.23100164532661438
train-epoch-step: 105-138 -- Loss: 0.2480241060256958
train-epoch-step: 105-139 -- Loss: 0.12452962249517441
train-epoch-step: 105-140 -- Loss: 0.2047603577375412
train-epoch-step: 105-141 -- Loss: 0.2255854606628418
train-epoch-step: 105-142 -- Loss: 0.19877339899539948
train-epoch-step: 105-143 -- Loss: 0.1628677397966385
train-epoch-step: 105-144 -- Loss: 0.17392165958881378
train-epoch-step: 105-145 -- Loss: 0.13729244470596313
train-epoch-step: 105-146 -- Loss: 0.1718226820230484
train-epoch-step: 105-147 -- Loss: 0.1643960028886795
train-epoch-step: 105-148 -- Loss: 0.15723997354507446
train-epoch-step: 105-149 -- Loss: 0.11396698653697968
train-epoch-step: 105-150 -- Loss: 0.17765754461288452
train-epoch-step: 105-151 -- Loss: 0.184568390250206
train-epoch-step: 105-152 -- Loss: 0.21657446026802063
train-epoch-step: 105-153 -- Loss: 0.25733622908592224
train-epoch-step: 105-154 -- Loss: 0.12838850915431976
train-epoch-step: 105-155 -- Loss: 0.13035376369953156
train-epoch-step: 105-156 -- Loss: 0.11959294974803925
train-epoch-step: 105-157 -- Loss: 0.1614830493927002
train-epoch-step: 105-158 -- Loss: 0.15915313363075256
train-epoch-step: 105-159 -- Loss: 0.17561139166355133
train-epoch-step: 105-160 -- Loss: 0.2230030596256256
train-epoch-step: 105-161 -- Loss: 0.20036005973815918
train-epoch-step: 105-162 -- Loss: 0.20369090139865875
train-epoch-step: 105-163 -- Loss: 0.18089433014392853
train-epoch-step: 105-164 -- Loss: 0.1906844973564148
train-epoch-step: 105-165 -- Loss: 0.15831980109214783
train-epoch-step: 105-166 -- Loss: 0.11553465574979782
train-epoch-step: 105-167 -- Loss: 0.11739791184663773
train-epoch-step: 105-168 -- Loss: 0.19074277579784393
train-epoch-step: 105-169 -- Loss: 0.1348964422941208
train-epoch-step: 105-170 -- Loss: 0.19462795555591583
train-epoch-step: 105-171 -- Loss: 0.14098350703716278
train-epoch-step: 105-172 -- Loss: 0.2540673613548279
train-epoch-step: 105-173 -- Loss: 0.13130734860897064
train-epoch-step: 105-174 -- Loss: 0.24116277694702148
train-epoch-step: 105-175 -- Loss: 0.18680340051651
train-epoch-step: 105-176 -- Loss: 0.12498614192008972
train-epoch-step: 105-177 -- Loss: 0.17376035451889038
train-epoch-step: 105-178 -- Loss: 0.17505769431591034
train-epoch-step: 105-179 -- Loss: 0.15089097619056702
train-epoch-step: 105-180 -- Loss: 0.14760802686214447
train-epoch-step: 105-181 -- Loss: 0.16529683768749237
train-epoch-step: 105-182 -- Loss: 0.17619100213050842
train-epoch-step: 105-183 -- Loss: 0.27464497089385986
train-epoch-step: 105-184 -- Loss: 0.13386142253875732
train-epoch-step: 105-185 -- Loss: 0.13845059275627136
train-epoch-step: 105-186 -- Loss: 0.1844218671321869
train-epoch-step: 105-187 -- Loss: 0.204071044921875
train-epoch-step: 105-188 -- Loss: 0.167301744222641
train-epoch-step: 105-189 -- Loss: 0.1057455912232399
train-epoch-step: 105-190 -- Loss: 0.17678746581077576
train-epoch-step: 105-191 -- Loss: 0.1573023498058319
train-epoch-step: 105-192 -- Loss: 0.22207124531269073
train-epoch-step: 105-193 -- Loss: 0.19917403161525726
train-epoch-step: 105-194 -- Loss: 0.17429979145526886
train-epoch-step: 105-195 -- Loss: 0.16104468703269958
train-epoch-step: 105-196 -- Loss: 0.16062840819358826
train-epoch-step: 105-197 -- Loss: 0.13004978001117706
train-epoch-step: 105-198 -- Loss: 0.12642931938171387
train-epoch-step: 105-199 -- Loss: 0.14354875683784485
train-epoch-step: 105-200 -- Loss: 0.11829990148544312
train-epoch-step: 105-201 -- Loss: 0.18376919627189636
train-epoch-step: 105-202 -- Loss: 0.1336480677127838
train-epoch-step: 105-203 -- Loss: 0.16962847113609314
train-epoch-step: 105-204 -- Loss: 0.12920139729976654
train-epoch-step: 105-205 -- Loss: 0.18254989385604858
train-epoch-step: 105-206 -- Loss: 0.19466906785964966
train-epoch-step: 105-207 -- Loss: 0.1297050565481186
train-epoch-step: 105-208 -- Loss: 0.17401649057865143
train-epoch-step: 105-209 -- Loss: 0.14293089509010315
train-epoch-step: 105-210 -- Loss: 0.13393822312355042
train-epoch-step: 105-211 -- Loss: 0.20367220044136047
train-epoch-step: 105-212 -- Loss: 0.19117148220539093
train-epoch-step: 105-213 -- Loss: 0.12533321976661682
train-epoch-step: 105-214 -- Loss: 0.14503170549869537
train-epoch-step: 105-215 -- Loss: 0.12345590442419052
train-epoch-step: 105-216 -- Loss: 0.19518393278121948
train-epoch-step: 105-217 -- Loss: 0.2101825773715973
train-epoch-step: 105-218 -- Loss: 0.1386357992887497
train-epoch-step: 105-219 -- Loss: 0.16394123435020447
train-epoch-step: 105-220 -- Loss: 0.12495419383049011
train-epoch-step: 105-221 -- Loss: 0.19907397031784058
train-epoch-step: 105-222 -- Loss: 0.11524493247270584
train-epoch-step: 105-223 -- Loss: 0.16473734378814697
train-epoch-step: 105-224 -- Loss: 0.18162454664707184
train-epoch-step: 105-225 -- Loss: 0.2586545944213867
train-epoch-step: 105-226 -- Loss: 0.20027725398540497
train-epoch-step: 105-227 -- Loss: 0.21132312715053558
train-epoch-step: 105-228 -- Loss: 0.1754012405872345
train-epoch-step: 105-229 -- Loss: 0.16674311459064484
train-epoch-step: 105-230 -- Loss: 0.16161854565143585
train-epoch-step: 105-231 -- Loss: 0.16240116953849792
train-epoch-step: 105-232 -- Loss: 0.18051597476005554
train-epoch-step: 105-233 -- Loss: 0.08065657317638397
train-epoch-step: 105-234 -- Loss: 0.16775357723236084
train-epoch-step: 105-235 -- Loss: 0.14091837406158447
train-epoch-step: 105-236 -- Loss: 0.17661184072494507
train-epoch-step: 105-237 -- Loss: 0.22649787366390228
train-epoch-step: 105-238 -- Loss: 0.15068365633487701
train-epoch-step: 105-239 -- Loss: 0.12181595712900162
train-epoch-step: 105-240 -- Loss: 0.21912872791290283
train-epoch-step: 105-241 -- Loss: 0.1492455154657364
train-epoch-step: 105-242 -- Loss: 0.21349522471427917
train-epoch-step: 105-243 -- Loss: 0.23181286454200745
train-epoch-step: 105-244 -- Loss: 0.2018848955631256
train-epoch-step: 105-245 -- Loss: 0.20109760761260986
train-epoch-step: 105-246 -- Loss: 0.21581363677978516
train-epoch-step: 105-247 -- Loss: 0.19831301271915436
train-epoch-step: 105-248 -- Loss: 0.17832502722740173
train-epoch-step: 105-249 -- Loss: 0.135122150182724
train-epoch-step: 105-250 -- Loss: 0.1919759213924408
train-epoch-step: 105-251 -- Loss: 0.10324051976203918
train-epoch-step: 105-252 -- Loss: 0.19115111231803894
train-epoch-step: 105-253 -- Loss: 0.1306297779083252
train-epoch-step: 105-254 -- Loss: 0.20964175462722778
train-epoch-step: 105-255 -- Loss: 0.1428220123052597
train-epoch-step: 105-256 -- Loss: 0.14978955686092377
train-epoch-step: 105-257 -- Loss: 0.1812627613544464
train-epoch-step: 105-258 -- Loss: 0.1387661099433899
train-epoch-step: 105-259 -- Loss: 0.14175410568714142
train-epoch-step: 105-260 -- Loss: 0.20209085941314697
train-epoch-step: 105-261 -- Loss: 0.1647738218307495
train-epoch-step: 105-262 -- Loss: 0.29523393511772156
train-epoch-step: 105-263 -- Loss: 0.1951625943183899
train-epoch-step: 105-264 -- Loss: 0.17073319852352142
train-epoch-step: 105-265 -- Loss: 0.11150666326284409
train-epoch-step: 105-266 -- Loss: 0.14969398081302643
train-epoch-step: 105-267 -- Loss: 0.12617798149585724
train-epoch-step: 105-268 -- Loss: 0.11532776057720184
train-epoch-step: 105-269 -- Loss: 0.19860783219337463
train-epoch-step: 105-270 -- Loss: 0.10903723537921906
train-epoch-step: 105-271 -- Loss: 0.14270375669002533
train-epoch-step: 105-272 -- Loss: 0.11120034009218216
train-epoch-step: 105-273 -- Loss: 0.12255751341581345
train-epoch-step: 105-274 -- Loss: 0.21976548433303833
train-epoch-step: 105-275 -- Loss: 0.18679429590702057
train-epoch-step: 105-276 -- Loss: 0.1663873791694641
train-epoch-step: 105-277 -- Loss: 0.14928145706653595
train-epoch-step: 105-278 -- Loss: 0.1336432695388794
train-epoch-step: 105-279 -- Loss: 0.1306445151567459
train-epoch-step: 105-280 -- Loss: 0.20410659909248352
train-epoch-step: 105-281 -- Loss: 0.17213550209999084
train-epoch-step: 105-282 -- Loss: 0.13490158319473267
train-epoch-step: 105-283 -- Loss: 0.11347144097089767
train-epoch-step: 105-284 -- Loss: 0.13543856143951416
train-epoch-step: 105-285 -- Loss: 0.18296892940998077
train-epoch-step: 105-286 -- Loss: 0.1577613800764084
train-epoch-step: 105-287 -- Loss: 0.1987922489643097
train-epoch-step: 105-288 -- Loss: 0.09274352341890335
train-epoch-step: 105-289 -- Loss: 0.11513541638851166
train-epoch-step: 105-290 -- Loss: 0.17873017489910126
train-epoch-step: 105-291 -- Loss: 0.11306849122047424
train-epoch-step: 105-292 -- Loss: 0.1577494740486145
train-epoch-step: 105-293 -- Loss: 0.13243243098258972
train-epoch-step: 105-294 -- Loss: 0.16236470639705658
train-epoch-step: 105-295 -- Loss: 0.2538827657699585
train-epoch-step: 105-296 -- Loss: 0.1628003567457199
train-epoch-step: 105-297 -- Loss: 0.16838480532169342
train-epoch-step: 105-298 -- Loss: 0.22357866168022156
train-epoch-step: 105-299 -- Loss: 0.13933753967285156
train-epoch-step: 105-300 -- Loss: 0.16348829865455627
train-epoch-step: 105-301 -- Loss: 0.1814451366662979
train-epoch-step: 105-302 -- Loss: 0.20826217532157898
train-epoch-step: 105-303 -- Loss: 0.1956588327884674
train-epoch-step: 105-304 -- Loss: 0.12213362753391266
train-epoch-step: 105-305 -- Loss: 0.14429634809494019
train-epoch-step: 105-306 -- Loss: 0.20278099179267883
train-epoch-step: 105-307 -- Loss: 0.1678575873374939
train-epoch-step: 105-308 -- Loss: 0.210158571600914
train-epoch-step: 105-309 -- Loss: 0.15217378735542297
train-epoch-step: 105-310 -- Loss: 0.15979093313217163
train-epoch-step: 105-311 -- Loss: 0.15638388693332672
train-epoch-step: 105-312 -- Loss: 0.2012854814529419
train-epoch-step: 105-313 -- Loss: 0.09234344959259033
train-epoch-step: 105-314 -- Loss: 0.18603907525539398
train-epoch-step: 105-315 -- Loss: 0.16444148123264313
train-epoch-step: 105-316 -- Loss: 0.145548015832901
train-epoch-step: 105-317 -- Loss: 0.133351132273674
train-epoch-step: 105-318 -- Loss: 0.14851114153862
train-epoch-step: 105-319 -- Loss: 0.1657484620809555
train-epoch-step: 105-320 -- Loss: 0.11111010611057281
train-epoch-step: 105-321 -- Loss: 0.12837250530719757
train-epoch-step: 105-322 -- Loss: 0.20424607396125793
train-epoch-step: 105-323 -- Loss: 0.15253645181655884
train-epoch-step: 105-324 -- Loss: 0.2449222058057785
train-epoch-step: 105-325 -- Loss: 0.1528589129447937
train-epoch-step: 105-326 -- Loss: 0.16848856210708618
train-epoch-step: 105-327 -- Loss: 0.20100577175617218
train-epoch-step: 105-328 -- Loss: 0.19121143221855164
train-epoch-step: 105-329 -- Loss: 0.3297695517539978
train-epoch-step: 105-330 -- Loss: 0.3517065644264221
train-epoch-step: 105-331 -- Loss: 0.21294425427913666
train-epoch-step: 105-332 -- Loss: 0.09545399248600006
train-epoch-step: 105-333 -- Loss: 0.17833268642425537
train-epoch-step: 105-334 -- Loss: 0.1500461846590042
train-epoch-step: 105-335 -- Loss: 0.17013153433799744
train-epoch-step: 105-336 -- Loss: 0.1422247439622879
train-epoch-step: 105-337 -- Loss: 0.2012360543012619
train-epoch-step: 105-338 -- Loss: 0.1592436283826828
train-epoch-step: 105-339 -- Loss: 0.1357954442501068
train-epoch-step: 105-340 -- Loss: 0.19475743174552917
train-epoch-step: 105-341 -- Loss: 0.1339910924434662
train-epoch-step: 105-342 -- Loss: 0.15733057260513306
train-epoch-step: 105-343 -- Loss: 0.1477171778678894
train-epoch-step: 105-344 -- Loss: 0.16410328447818756
train-epoch-step: 105-345 -- Loss: 0.12250994890928268
train-epoch-step: 105-346 -- Loss: 0.21384260058403015
train-epoch-step: 105-347 -- Loss: 0.1477571725845337
train-epoch-step: 105-348 -- Loss: 0.19777840375900269
train-epoch-step: 105-349 -- Loss: 0.19721511006355286
train-epoch-step: 105-350 -- Loss: 0.24735233187675476
train-epoch-step: 105-351 -- Loss: 0.18701952695846558
train-epoch-step: 105-352 -- Loss: 0.12555618584156036
train-epoch-step: 105-353 -- Loss: 0.1903083771467209
train-epoch-step: 105-354 -- Loss: 0.2739064395427704
train-epoch-step: 105-355 -- Loss: 0.11451362073421478
train-epoch-step: 105-356 -- Loss: 0.11357253789901733
train-epoch-step: 105-357 -- Loss: 0.18273194134235382
train-epoch-step: 105-358 -- Loss: 0.17759136855602264
train-epoch-step: 105-359 -- Loss: 0.13331499695777893
train-epoch-step: 105-360 -- Loss: 0.11944343894720078
train-epoch-step: 105-361 -- Loss: 0.2387603223323822
train-epoch-step: 105-362 -- Loss: 0.1643373668193817
train-epoch-step: 105-363 -- Loss: 0.10856695473194122
train-epoch-step: 105-364 -- Loss: 0.17287984490394592
train-epoch-step: 105-365 -- Loss: 0.16509783267974854
train-epoch-step: 105-366 -- Loss: 0.20095407962799072
train-epoch-step: 105-367 -- Loss: 0.218386709690094
train-epoch-step: 105-368 -- Loss: 0.2008422613143921
train-epoch-step: 105-369 -- Loss: 0.2764943242073059
train-epoch-step: 105-370 -- Loss: 0.12111975252628326
train-epoch-step: 105-371 -- Loss: 0.11666969209909439
train-epoch-step: 105-372 -- Loss: 0.14220641553401947
train-epoch-step: 105-373 -- Loss: 0.18171687424182892
train-epoch-step: 105-374 -- Loss: 0.14829984307289124
train-epoch-step: 105-375 -- Loss: 0.2617490887641907
train-epoch-step: 105-376 -- Loss: 0.16504408419132233
train-epoch-step: 105-377 -- Loss: 0.21879392862319946
train-epoch-step: 105-378 -- Loss: 0.1910068690776825
train-epoch-step: 105-379 -- Loss: 0.11523915082216263
train-epoch-step: 105-380 -- Loss: 0.08905406296253204
train-epoch-step: 105-381 -- Loss: 0.24272024631500244
train-epoch-step: 105-382 -- Loss: 0.22686462104320526
train-epoch-step: 105-383 -- Loss: 0.16874060034751892
train-epoch-step: 105-384 -- Loss: 0.2118581235408783
train-epoch-step: 105-385 -- Loss: 0.17995020747184753
train-epoch-step: 105-386 -- Loss: 0.17937757074832916
train-epoch-step: 105-387 -- Loss: 0.1983189433813095
train-epoch-step: 105-388 -- Loss: 0.18491359055042267
train-epoch-step: 105-389 -- Loss: 0.16203466057777405
train-epoch-step: 105-390 -- Loss: 0.13993225991725922
train-epoch-step: 105-391 -- Loss: 0.1392548531293869
train-epoch-step: 105-392 -- Loss: 0.17788736522197723
train-epoch-step: 105-393 -- Loss: 0.15205024182796478
train-epoch-step: 105-394 -- Loss: 0.1880662441253662
train-epoch-step: 105-395 -- Loss: 0.15470421314239502
train-epoch-step: 105-396 -- Loss: 0.12067031860351562
train-epoch-step: 105-397 -- Loss: 0.11866498738527298
train-epoch-step: 105-398 -- Loss: 0.1902824491262436
train-epoch-step: 105-399 -- Loss: 0.17041698098182678
train-epoch-step: 105-400 -- Loss: 0.26790088415145874
train-epoch-step: 105-401 -- Loss: 0.11630791425704956
train-epoch-step: 105-402 -- Loss: 0.24861083924770355
train-epoch-step: 105-403 -- Loss: 0.1505393534898758
train-epoch-step: 105-404 -- Loss: 0.13345839083194733
train-epoch-step: 105-405 -- Loss: 0.15554611384868622
train-epoch-step: 105-406 -- Loss: 0.1595449149608612
train-epoch-step: 105-407 -- Loss: 0.10798970609903336
train-epoch-step: 105-408 -- Loss: 0.1564858853816986
train-epoch-step: 105-409 -- Loss: 0.1626378893852234
train-epoch-step: 105-410 -- Loss: 0.17128048837184906
train-epoch-step: 105-411 -- Loss: 0.1870848685503006
train-epoch-step: 105-412 -- Loss: 0.12420202791690826
train-epoch-step: 105-413 -- Loss: 0.14101608097553253
train-epoch-step: 105-414 -- Loss: 0.12743261456489563
train-epoch-step: 105-415 -- Loss: 0.13046911358833313
train-epoch-step: 105-416 -- Loss: 0.2639981210231781
train-epoch-step: 105-417 -- Loss: 0.18383106589317322
train-epoch-step: 105-418 -- Loss: 0.2165006697177887
train-epoch-step: 105-419 -- Loss: 0.16763438284397125
train-epoch-step: 105-420 -- Loss: 0.14638695120811462
train-epoch-step: 105-421 -- Loss: 0.17697882652282715
train-epoch-step: 105-422 -- Loss: 0.1427193433046341
train-epoch-step: 105-423 -- Loss: 0.16502028703689575
train-epoch-step: 105-424 -- Loss: 0.1352466195821762
train-epoch-step: 105-425 -- Loss: 0.17421835660934448
train-epoch-step: 105-426 -- Loss: 0.16154323518276215
train-epoch-step: 105-427 -- Loss: 0.11656391620635986
train-epoch-step: 105-428 -- Loss: 0.18641828000545502
train-epoch-step: 105-429 -- Loss: 0.16908468306064606
train-epoch-step: 105-430 -- Loss: 0.13494399189949036
train-epoch-step: 105-431 -- Loss: 0.15549081563949585
train-epoch-step: 105-432 -- Loss: 0.2308354675769806
train-epoch-step: 105-433 -- Loss: 0.13303375244140625
train-epoch-step: 105-434 -- Loss: 0.11974247545003891
train-epoch-step: 105-435 -- Loss: 0.14985662698745728
train-epoch-step: 105-436 -- Loss: 0.14829972386360168
train-epoch-step: 105-437 -- Loss: 0.12850850820541382
train-epoch-step: 105-438 -- Loss: 0.16116738319396973
train-epoch-step: 105-439 -- Loss: 0.2534414529800415
train-epoch-step: 105-440 -- Loss: 0.12353653460741043
train-epoch-step: 105-441 -- Loss: 0.1888117790222168
train-epoch-step: 105-442 -- Loss: 0.1753774881362915
train-epoch-step: 105-443 -- Loss: 0.14739638566970825
train-epoch-step: 105-444 -- Loss: 0.16870906949043274
train-epoch-step: 105-445 -- Loss: 0.17849816381931305
train-epoch-step: 105-446 -- Loss: 0.14679692685604095
train-epoch-step: 105-447 -- Loss: 0.1848965883255005
train-epoch-step: 105-448 -- Loss: 0.21397630870342255
train-epoch-step: 105-449 -- Loss: 0.18300440907478333
train-epoch-step: 105-450 -- Loss: 0.17631390690803528
train-epoch-step: 105-451 -- Loss: 0.13675448298454285
train-epoch-step: 105-452 -- Loss: 0.12522415816783905
train-epoch-step: 105-453 -- Loss: 0.08676130324602127
train-epoch-step: 105-454 -- Loss: 0.22253845632076263
train-epoch-step: 105-455 -- Loss: 0.11725673079490662
train-epoch-step: 105-456 -- Loss: 0.1133871003985405
train-epoch-step: 105-457 -- Loss: 0.20553740859031677
train-epoch-step: 105-458 -- Loss: 0.1364881992340088
train-epoch-step: 105-459 -- Loss: 0.20434819161891937
train-epoch-step: 105-460 -- Loss: 0.1214917004108429
train-epoch-step: 105-461 -- Loss: 0.13126905262470245
train-epoch-step: 105-462 -- Loss: 0.1468237191438675
train-epoch-step: 105-463 -- Loss: 0.12702755630016327
train-epoch-step: 105-464 -- Loss: 0.16048510372638702
train-epoch-step: 105-465 -- Loss: 0.22444334626197815
train-epoch-step: 105-466 -- Loss: 0.19257688522338867
train-epoch-step: 105-467 -- Loss: 0.11215047538280487
train-epoch-step: 105-468 -- Loss: 0.1592024266719818
train-epoch-step: 105-469 -- Loss: 0.19685888290405273
train-epoch-step: 105-470 -- Loss: 0.16629557311534882
train-epoch-step: 105-471 -- Loss: 0.15344126522541046
train-epoch-step: 105-472 -- Loss: 0.15513712167739868
train-epoch-step: 105-473 -- Loss: 0.14840354025363922
train-epoch-step: 105-474 -- Loss: 0.11556390672922134
train-epoch-step: 105-475 -- Loss: 0.10439560562372208
train-epoch-step: 105-476 -- Loss: 0.19378279149532318
train-epoch-step: 105-477 -- Loss: 0.1878458708524704
train-epoch-step: 105-478 -- Loss: 0.18647843599319458
train-epoch-step: 105-479 -- Loss: 0.1325346827507019
train-epoch-step: 105-480 -- Loss: 0.19352656602859497
train-epoch-step: 105-481 -- Loss: 0.2709997892379761
train-epoch-step: 105-482 -- Loss: 0.23640277981758118
train-epoch-step: 105-483 -- Loss: 0.17327137291431427
train-epoch-step: 105-484 -- Loss: 0.2068527340888977
train-epoch-step: 105-485 -- Loss: 0.12259911000728607
train-epoch-step: 105-486 -- Loss: 0.22466400265693665
train-epoch-step: 105-487 -- Loss: 0.23279725015163422
train-epoch-step: 105-488 -- Loss: 0.17163795232772827
train-epoch-step: 105-489 -- Loss: 0.21202132105827332
train-epoch-step: 105-490 -- Loss: 0.13081195950508118
train-epoch-step: 105-491 -- Loss: 0.13158385455608368
train-epoch-step: 105-492 -- Loss: 0.12257610261440277
train-epoch-step: 105-493 -- Loss: 0.18977969884872437
train-epoch-step: 105-494 -- Loss: 0.19375082850456238
train-epoch-step: 105-495 -- Loss: 0.19148851931095123
train-epoch-step: 105-496 -- Loss: 0.13980229198932648
train-epoch-step: 105-497 -- Loss: 0.18135672807693481
train-epoch-step: 105-498 -- Loss: 0.1422114372253418
train-epoch-step: 105-499 -- Loss: 0.16596072912216187
train-epoch-step: 105-500 -- Loss: 0.1477314680814743
train-epoch-step: 105-501 -- Loss: 0.20944350957870483
train-epoch-step: 105-502 -- Loss: 0.14990012347698212
train-epoch-step: 105-503 -- Loss: 0.2128864824771881
train-epoch-step: 105-504 -- Loss: 0.1182040423154831
train-epoch-step: 105-505 -- Loss: 0.16645994782447815
train-epoch-step: 105-506 -- Loss: 0.11316008865833282
train-epoch-step: 105-507 -- Loss: 0.17587487399578094
train-epoch-step: 105-508 -- Loss: 0.16515028476715088
train-epoch-step: 105-509 -- Loss: 0.16572734713554382
train-epoch-step: 105-510 -- Loss: 0.1228523924946785
train-epoch-step: 105-511 -- Loss: 0.20530536770820618
train-epoch-step: 105-512 -- Loss: 0.1743137240409851
train-epoch-step: 105-513 -- Loss: 0.1937347799539566
train-epoch-step: 105-514 -- Loss: 0.14383229613304138
train-epoch-step: 105-515 -- Loss: 0.1469653993844986
train-epoch-step: 105-516 -- Loss: 0.17301996052265167
train-epoch-step: 105-517 -- Loss: 0.16486263275146484
train-epoch-step: 105-518 -- Loss: 0.13298429548740387
train-epoch-step: 105-519 -- Loss: 0.1308155655860901
train-epoch-step: 105-520 -- Loss: 0.17754462361335754
train-epoch-step: 105-521 -- Loss: 0.2244461178779602
train-epoch-step: 105-522 -- Loss: 0.16568629443645477
train-epoch-step: 105-523 -- Loss: 0.15227456390857697
train-epoch-step: 105-524 -- Loss: 0.16053587198257446
train-epoch-step: 105-525 -- Loss: 0.18245941400527954
train-epoch-step: 105-526 -- Loss: 0.12784627079963684
train-epoch-step: 105-527 -- Loss: 0.14122924208641052
train-epoch-step: 105-528 -- Loss: 0.15129710733890533
train-epoch-step: 105-529 -- Loss: 0.14892743527889252
train-epoch-step: 105-530 -- Loss: 0.1615273654460907
train-epoch-step: 105-531 -- Loss: 0.1889682561159134
train-epoch-step: 105-532 -- Loss: 0.1632647067308426
train-epoch-step: 105-533 -- Loss: 0.17234192788600922
train-epoch-step: 105-534 -- Loss: 0.1251257359981537
train-epoch-step: 105-535 -- Loss: 0.25675123929977417
train-epoch-step: 105-536 -- Loss: 0.14833080768585205
train-epoch-step: 105-537 -- Loss: 0.13890980184078217
train-epoch-step: 105-538 -- Loss: 0.10428020358085632
train-epoch-step: 105-539 -- Loss: 0.17125993967056274
train-epoch-step: 105-540 -- Loss: 0.13037747144699097
train-epoch-step: 105-541 -- Loss: 0.19750772416591644
train-epoch-step: 105-542 -- Loss: 0.21201317012310028
train-epoch-step: 105-543 -- Loss: 0.16707506775856018
train-epoch-step: 105-544 -- Loss: 0.21886982023715973
train-epoch-step: 105-545 -- Loss: 0.18546150624752045
train-epoch-step: 105-546 -- Loss: 0.1969595104455948
train-epoch-step: 105-547 -- Loss: 0.17306619882583618
train-epoch-step: 105-548 -- Loss: 0.08759228140115738
train-epoch-step: 105-549 -- Loss: 0.14193923771381378
train-epoch-step: 105-550 -- Loss: 0.19379538297653198
train-epoch-step: 105-551 -- Loss: 0.14426851272583008
train-epoch-step: 105-552 -- Loss: 0.12427521497011185
train-epoch-step: 105-553 -- Loss: 0.18038427829742432
train-epoch-step: 105-554 -- Loss: 0.18175587058067322
train-epoch-step: 105-555 -- Loss: 0.19699402153491974
train-epoch-step: 105-556 -- Loss: 0.14868198335170746
train-epoch-step: 105-557 -- Loss: 0.2217065691947937
train-epoch-step: 105-558 -- Loss: 0.2198619842529297
train-epoch-step: 105-559 -- Loss: 0.13914014399051666
train-epoch-step: 105-560 -- Loss: 0.20020157098770142
train-epoch-step: 105-561 -- Loss: 0.1696007251739502
train-epoch-step: 105-562 -- Loss: 0.16100995242595673
train-epoch-step: 105-563 -- Loss: 0.1781408190727234
train-epoch-step: 105-564 -- Loss: 0.09704122692346573
train-epoch-step: 105-565 -- Loss: 0.17915765941143036
train-epoch-step: 105-566 -- Loss: 0.14205363392829895
train-epoch-step: 105-567 -- Loss: 0.20640885829925537
train-epoch-step: 105-568 -- Loss: 0.15321075916290283
train-epoch-step: 105-569 -- Loss: 0.23463696241378784
train-epoch-step: 105-570 -- Loss: 0.160538449883461
train-epoch-step: 105-571 -- Loss: 0.2066521942615509
train-epoch-step: 105-572 -- Loss: 0.232487291097641
train-epoch-step: 105-573 -- Loss: 0.1869504451751709
train-epoch-step: 105-574 -- Loss: 0.23198477923870087
train-epoch-step: 105-575 -- Loss: 0.29440200328826904
train-epoch-step: 105-576 -- Loss: 0.11614060401916504
train-epoch-step: 105-577 -- Loss: 0.16109693050384521
train-epoch-step: 105-578 -- Loss: 0.21253584325313568
train-epoch-step: 105-579 -- Loss: 0.15865206718444824
train-epoch-step: 105-580 -- Loss: 0.1666073501110077
train-epoch-step: 105-581 -- Loss: 0.1311928778886795
train-epoch-step: 105-582 -- Loss: 0.20139116048812866
train-epoch-step: 105-583 -- Loss: 0.2217824012041092
train-epoch-step: 105-584 -- Loss: 0.15582038462162018
train-epoch-step: 105-585 -- Loss: 0.18914182484149933
train-epoch-step: 105-586 -- Loss: 0.24479460716247559
train-epoch-step: 105-587 -- Loss: 0.15510068833827972
train-epoch-step: 105-588 -- Loss: 0.12453728914260864
val-epoch-step: 105-589 -- Loss: 0.2209683358669281
val-epoch-step: 105-590 -- Loss: 0.15062452852725983
val-epoch-step: 105-591 -- Loss: 0.24856451153755188
val-epoch-step: 105-592 -- Loss: 0.16780072450637817
val-epoch-step: 105-593 -- Loss: 0.1555212438106537
val-epoch-step: 105-594 -- Loss: 0.35310304164886475
val-epoch-step: 105-595 -- Loss: 0.17595285177230835
val-epoch-step: 105-596 -- Loss: 0.23884230852127075
val-epoch-step: 105-597 -- Loss: 0.16980044543743134
val-epoch-step: 105-598 -- Loss: 0.1450195610523224
val-epoch-step: 105-599 -- Loss: 0.17687655985355377
val-epoch-step: 105-600 -- Loss: 0.1650353968143463
val-epoch-step: 105-601 -- Loss: 0.14776423573493958
val-epoch-step: 105-602 -- Loss: 0.13210901618003845
val-epoch-step: 105-603 -- Loss: 0.19580285251140594
val-epoch-step: 105-604 -- Loss: 0.16223323345184326
val-epoch-step: 105-605 -- Loss: 0.15087631344795227
val-epoch-step: 105-606 -- Loss: 0.26621612906455994
val-epoch-step: 105-607 -- Loss: 0.12193120270967484
val-epoch-step: 105-608 -- Loss: 0.2475498914718628
val-epoch-step: 105-609 -- Loss: 0.16504588723182678
val-epoch-step: 105-610 -- Loss: 0.17682580649852753
val-epoch-step: 105-611 -- Loss: 0.15081368386745453
val-epoch-step: 105-612 -- Loss: 0.38980481028556824
val-epoch-step: 105-613 -- Loss: 0.16835163533687592
val-epoch-step: 105-614 -- Loss: 0.17116360366344452
val-epoch-step: 105-615 -- Loss: 0.1719352900981903
val-epoch-step: 105-616 -- Loss: 0.14535707235336304
val-epoch-step: 105-617 -- Loss: 0.19213774800300598
val-epoch-step: 105-618 -- Loss: 0.1754654347896576
val-epoch-step: 105-619 -- Loss: 0.19948457181453705
val-epoch-step: 105-620 -- Loss: 0.1322496384382248
val-epoch-step: 105-621 -- Loss: 0.12459953129291534
val-epoch-step: 105-622 -- Loss: 0.14155247807502747
val-epoch-step: 105-623 -- Loss: 0.14455248415470123
val-epoch-step: 105-624 -- Loss: 0.13841906189918518
val-epoch-step: 105-625 -- Loss: 0.16379483044147491
val-epoch-step: 105-626 -- Loss: 0.14953544735908508
val-epoch-step: 105-627 -- Loss: 0.17906694114208221
val-epoch-step: 105-628 -- Loss: 0.4792344570159912
val-epoch-step: 105-629 -- Loss: 0.20753327012062073
val-epoch-step: 105-630 -- Loss: 0.34786808490753174
val-epoch-step: 105-631 -- Loss: 0.1455773264169693
val-epoch-step: 105-632 -- Loss: 0.1993820071220398
val-epoch-step: 105-633 -- Loss: 0.14871324598789215
val-epoch-step: 105-634 -- Loss: 0.14843681454658508
val-epoch-step: 105-635 -- Loss: 0.11014936864376068
val-epoch-step: 105-636 -- Loss: 0.16178587079048157
val-epoch-step: 105-637 -- Loss: 0.1813814491033554
val-epoch-step: 105-638 -- Loss: 0.1500057876110077
val-epoch-step: 105-639 -- Loss: 0.2926084101200104
val-epoch-step: 105-640 -- Loss: 0.24281981587409973
val-epoch-step: 105-641 -- Loss: 0.12527912855148315
val-epoch-step: 105-642 -- Loss: 0.1919962614774704
val-epoch-step: 105-643 -- Loss: 0.21012765169143677
val-epoch-step: 105-644 -- Loss: 0.1604076623916626
val-epoch-step: 105-645 -- Loss: 0.2171240746974945
val-epoch-step: 105-646 -- Loss: 0.13075654208660126
val-epoch-step: 105-647 -- Loss: 0.12050230801105499
val-epoch-step: 105-648 -- Loss: 0.14958402514457703
val-epoch-step: 105-649 -- Loss: 0.20230713486671448
val-epoch-step: 105-650 -- Loss: 0.24195533990859985
val-epoch-step: 105-651 -- Loss: 0.1363360732793808
val-epoch-step: 105-652 -- Loss: 0.14970602095127106
val-epoch-step: 105-653 -- Loss: 0.19374296069145203
val-epoch-step: 105-654 -- Loss: 0.10891107469797134
Epoch: 105 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 106-0 -- Loss: 0.21347030997276306
train-epoch-step: 106-1 -- Loss: 0.13507194817066193
train-epoch-step: 106-2 -- Loss: 0.20480214059352875
train-epoch-step: 106-3 -- Loss: 0.1387505978345871
train-epoch-step: 106-4 -- Loss: 0.15004873275756836
train-epoch-step: 106-5 -- Loss: 0.1747128665447235
train-epoch-step: 106-6 -- Loss: 0.2022627294063568
train-epoch-step: 106-7 -- Loss: 0.16383720934391022
train-epoch-step: 106-8 -- Loss: 0.17664776742458344
train-epoch-step: 106-9 -- Loss: 0.21015754342079163
train-epoch-step: 106-10 -- Loss: 0.1803170144557953
train-epoch-step: 106-11 -- Loss: 0.16678549349308014
train-epoch-step: 106-12 -- Loss: 0.143174946308136
train-epoch-step: 106-13 -- Loss: 0.17097225785255432
train-epoch-step: 106-14 -- Loss: 0.15599042177200317
train-epoch-step: 106-15 -- Loss: 0.15042974054813385
train-epoch-step: 106-16 -- Loss: 0.16353455185890198
train-epoch-step: 106-17 -- Loss: 0.21471980214118958
train-epoch-step: 106-18 -- Loss: 0.18639487028121948
train-epoch-step: 106-19 -- Loss: 0.1308867186307907
train-epoch-step: 106-20 -- Loss: 0.20963740348815918
train-epoch-step: 106-21 -- Loss: 0.23532822728157043
train-epoch-step: 106-22 -- Loss: 0.13618694245815277
train-epoch-step: 106-23 -- Loss: 0.14003953337669373
train-epoch-step: 106-24 -- Loss: 0.12160728871822357
train-epoch-step: 106-25 -- Loss: 0.21803221106529236
train-epoch-step: 106-26 -- Loss: 0.18441691994667053
train-epoch-step: 106-27 -- Loss: 0.23240265250205994
train-epoch-step: 106-28 -- Loss: 0.1199701726436615
train-epoch-step: 106-29 -- Loss: 0.2298763543367386
train-epoch-step: 106-30 -- Loss: 0.10555513203144073
train-epoch-step: 106-31 -- Loss: 0.12769442796707153
train-epoch-step: 106-32 -- Loss: 0.1664733588695526
train-epoch-step: 106-33 -- Loss: 0.26899293065071106
train-epoch-step: 106-34 -- Loss: 0.1666729599237442
train-epoch-step: 106-35 -- Loss: 0.2330055683851242
train-epoch-step: 106-36 -- Loss: 0.13727837800979614
train-epoch-step: 106-37 -- Loss: 0.13113147020339966
train-epoch-step: 106-38 -- Loss: 0.1689785122871399
train-epoch-step: 106-39 -- Loss: 0.21529673039913177
train-epoch-step: 106-40 -- Loss: 0.19071348011493683
train-epoch-step: 106-41 -- Loss: 0.2149910032749176
train-epoch-step: 106-42 -- Loss: 0.14300458133220673
train-epoch-step: 106-43 -- Loss: 0.2524164021015167
train-epoch-step: 106-44 -- Loss: 0.12418662756681442
train-epoch-step: 106-45 -- Loss: 0.11631622910499573
train-epoch-step: 106-46 -- Loss: 0.16846217215061188
train-epoch-step: 106-47 -- Loss: 0.18700478971004486
train-epoch-step: 106-48 -- Loss: 0.15278731286525726
train-epoch-step: 106-49 -- Loss: 0.22884899377822876
train-epoch-step: 106-50 -- Loss: 0.10687211155891418
train-epoch-step: 106-51 -- Loss: 0.17082293331623077
train-epoch-step: 106-52 -- Loss: 0.15121030807495117
train-epoch-step: 106-53 -- Loss: 0.20260584354400635
train-epoch-step: 106-54 -- Loss: 0.27127715945243835
train-epoch-step: 106-55 -- Loss: 0.1600213199853897
train-epoch-step: 106-56 -- Loss: 0.16837681829929352
train-epoch-step: 106-57 -- Loss: 0.23163531720638275
train-epoch-step: 106-58 -- Loss: 0.27530190348625183
train-epoch-step: 106-59 -- Loss: 0.23118293285369873
train-epoch-step: 106-60 -- Loss: 0.12653028964996338
train-epoch-step: 106-61 -- Loss: 0.19315125048160553
train-epoch-step: 106-62 -- Loss: 0.18291042745113373
train-epoch-step: 106-63 -- Loss: 0.12783442437648773
train-epoch-step: 106-64 -- Loss: 0.1396932750940323
train-epoch-step: 106-65 -- Loss: 0.17476962506771088
train-epoch-step: 106-66 -- Loss: 0.10289114713668823
train-epoch-step: 106-67 -- Loss: 0.12466934323310852
train-epoch-step: 106-68 -- Loss: 0.20519213378429413
train-epoch-step: 106-69 -- Loss: 0.11933420598506927
train-epoch-step: 106-70 -- Loss: 0.21569660305976868
train-epoch-step: 106-71 -- Loss: 0.24411895871162415
train-epoch-step: 106-72 -- Loss: 0.16919085383415222
train-epoch-step: 106-73 -- Loss: 0.19964350759983063
train-epoch-step: 106-74 -- Loss: 0.09203974157571793
train-epoch-step: 106-75 -- Loss: 0.12417875975370407
train-epoch-step: 106-76 -- Loss: 0.14134138822555542
train-epoch-step: 106-77 -- Loss: 0.21459318697452545
train-epoch-step: 106-78 -- Loss: 0.2498987466096878
train-epoch-step: 106-79 -- Loss: 0.1810222715139389
train-epoch-step: 106-80 -- Loss: 0.23852786421775818
train-epoch-step: 106-81 -- Loss: 0.11753242462873459
train-epoch-step: 106-82 -- Loss: 0.23941616714000702
train-epoch-step: 106-83 -- Loss: 0.16944670677185059
train-epoch-step: 106-84 -- Loss: 0.17794102430343628
train-epoch-step: 106-85 -- Loss: 0.16673347353935242
train-epoch-step: 106-86 -- Loss: 0.11726517975330353
train-epoch-step: 106-87 -- Loss: 0.20068444311618805
train-epoch-step: 106-88 -- Loss: 0.13555333018302917
train-epoch-step: 106-89 -- Loss: 0.18170008063316345
train-epoch-step: 106-90 -- Loss: 0.19009709358215332
train-epoch-step: 106-91 -- Loss: 0.23959501087665558
train-epoch-step: 106-92 -- Loss: 0.1482953131198883
train-epoch-step: 106-93 -- Loss: 0.16463196277618408
train-epoch-step: 106-94 -- Loss: 0.21392178535461426
train-epoch-step: 106-95 -- Loss: 0.17972338199615479
train-epoch-step: 106-96 -- Loss: 0.20649954676628113
train-epoch-step: 106-97 -- Loss: 0.1665804237127304
train-epoch-step: 106-98 -- Loss: 0.15175190567970276
train-epoch-step: 106-99 -- Loss: 0.17459046840667725
train-epoch-step: 106-100 -- Loss: 0.1770995706319809
train-epoch-step: 106-101 -- Loss: 0.2512952983379364
train-epoch-step: 106-102 -- Loss: 0.21289314329624176
train-epoch-step: 106-103 -- Loss: 0.17986543476581573
train-epoch-step: 106-104 -- Loss: 0.14259928464889526
train-epoch-step: 106-105 -- Loss: 0.2559964954853058
train-epoch-step: 106-106 -- Loss: 0.1743108481168747
train-epoch-step: 106-107 -- Loss: 0.1835658848285675
train-epoch-step: 106-108 -- Loss: 0.18647147715091705
train-epoch-step: 106-109 -- Loss: 0.14001597464084625
train-epoch-step: 106-110 -- Loss: 0.1754276156425476
train-epoch-step: 106-111 -- Loss: 0.17441457509994507
train-epoch-step: 106-112 -- Loss: 0.16161231696605682
train-epoch-step: 106-113 -- Loss: 0.15368279814720154
train-epoch-step: 106-114 -- Loss: 0.18794819712638855
train-epoch-step: 106-115 -- Loss: 0.15695345401763916
train-epoch-step: 106-116 -- Loss: 0.13334831595420837
train-epoch-step: 106-117 -- Loss: 0.12310562282800674
train-epoch-step: 106-118 -- Loss: 0.18800917267799377
train-epoch-step: 106-119 -- Loss: 0.1428893804550171
train-epoch-step: 106-120 -- Loss: 0.23372343182563782
train-epoch-step: 106-121 -- Loss: 0.22808004915714264
train-epoch-step: 106-122 -- Loss: 0.21234963834285736
train-epoch-step: 106-123 -- Loss: 0.1916867047548294
train-epoch-step: 106-124 -- Loss: 0.12183065712451935
train-epoch-step: 106-125 -- Loss: 0.1499146819114685
train-epoch-step: 106-126 -- Loss: 0.22358450293540955
train-epoch-step: 106-127 -- Loss: 0.1737084537744522
train-epoch-step: 106-128 -- Loss: 0.16449472308158875
train-epoch-step: 106-129 -- Loss: 0.1301620900630951
train-epoch-step: 106-130 -- Loss: 0.18497826159000397
train-epoch-step: 106-131 -- Loss: 0.13285836577415466
train-epoch-step: 106-132 -- Loss: 0.18283671140670776
train-epoch-step: 106-133 -- Loss: 0.11042305827140808
train-epoch-step: 106-134 -- Loss: 0.1857052892446518
train-epoch-step: 106-135 -- Loss: 0.13281044363975525
train-epoch-step: 106-136 -- Loss: 0.12488599866628647
train-epoch-step: 106-137 -- Loss: 0.23269245028495789
train-epoch-step: 106-138 -- Loss: 0.24781712889671326
train-epoch-step: 106-139 -- Loss: 0.12548115849494934
train-epoch-step: 106-140 -- Loss: 0.2054668515920639
train-epoch-step: 106-141 -- Loss: 0.22215263545513153
train-epoch-step: 106-142 -- Loss: 0.1955781877040863
train-epoch-step: 106-143 -- Loss: 0.1619834154844284
train-epoch-step: 106-144 -- Loss: 0.17570197582244873
train-epoch-step: 106-145 -- Loss: 0.138517826795578
train-epoch-step: 106-146 -- Loss: 0.1706375628709793
train-epoch-step: 106-147 -- Loss: 0.1636669635772705
train-epoch-step: 106-148 -- Loss: 0.15546981990337372
train-epoch-step: 106-149 -- Loss: 0.11721091717481613
train-epoch-step: 106-150 -- Loss: 0.17877846956253052
train-epoch-step: 106-151 -- Loss: 0.18628950417041779
train-epoch-step: 106-152 -- Loss: 0.1837901473045349
train-epoch-step: 106-153 -- Loss: 0.2604581117630005
train-epoch-step: 106-154 -- Loss: 0.12565603852272034
train-epoch-step: 106-155 -- Loss: 0.13045746088027954
train-epoch-step: 106-156 -- Loss: 0.1140543594956398
train-epoch-step: 106-157 -- Loss: 0.16001135110855103
train-epoch-step: 106-158 -- Loss: 0.1573369801044464
train-epoch-step: 106-159 -- Loss: 0.1760576069355011
train-epoch-step: 106-160 -- Loss: 0.19618284702301025
train-epoch-step: 106-161 -- Loss: 0.20045457780361176
train-epoch-step: 106-162 -- Loss: 0.20254790782928467
train-epoch-step: 106-163 -- Loss: 0.1803555190563202
train-epoch-step: 106-164 -- Loss: 0.18356779217720032
train-epoch-step: 106-165 -- Loss: 0.1551714837551117
train-epoch-step: 106-166 -- Loss: 0.11652813106775284
train-epoch-step: 106-167 -- Loss: 0.11789698153734207
train-epoch-step: 106-168 -- Loss: 0.1937905251979828
train-epoch-step: 106-169 -- Loss: 0.13646838068962097
train-epoch-step: 106-170 -- Loss: 0.19119396805763245
train-epoch-step: 106-171 -- Loss: 0.1409720927476883
train-epoch-step: 106-172 -- Loss: 0.24739386141300201
train-epoch-step: 106-173 -- Loss: 0.13719862699508667
train-epoch-step: 106-174 -- Loss: 0.23972447216510773
train-epoch-step: 106-175 -- Loss: 0.18237543106079102
train-epoch-step: 106-176 -- Loss: 0.14055411517620087
train-epoch-step: 106-177 -- Loss: 0.17424538731575012
train-epoch-step: 106-178 -- Loss: 0.17404673993587494
train-epoch-step: 106-179 -- Loss: 0.14430490136146545
train-epoch-step: 106-180 -- Loss: 0.14497162401676178
train-epoch-step: 106-181 -- Loss: 0.16294527053833008
train-epoch-step: 106-182 -- Loss: 0.1835688054561615
train-epoch-step: 106-183 -- Loss: 0.2666798532009125
train-epoch-step: 106-184 -- Loss: 0.13287010788917542
train-epoch-step: 106-185 -- Loss: 0.14097939431667328
train-epoch-step: 106-186 -- Loss: 0.18319769203662872
train-epoch-step: 106-187 -- Loss: 0.20109379291534424
train-epoch-step: 106-188 -- Loss: 0.1622495800256729
train-epoch-step: 106-189 -- Loss: 0.10001757740974426
train-epoch-step: 106-190 -- Loss: 0.18453049659729004
train-epoch-step: 106-191 -- Loss: 0.1542341709136963
train-epoch-step: 106-192 -- Loss: 0.22059963643550873
train-epoch-step: 106-193 -- Loss: 0.19769085943698883
train-epoch-step: 106-194 -- Loss: 0.17933745682239532
train-epoch-step: 106-195 -- Loss: 0.16072644293308258
train-epoch-step: 106-196 -- Loss: 0.16483019292354584
train-epoch-step: 106-197 -- Loss: 0.12166951596736908
train-epoch-step: 106-198 -- Loss: 0.1271943598985672
train-epoch-step: 106-199 -- Loss: 0.14303289353847504
train-epoch-step: 106-200 -- Loss: 0.12263674288988113
train-epoch-step: 106-201 -- Loss: 0.1806105673313141
train-epoch-step: 106-202 -- Loss: 0.1296619027853012
train-epoch-step: 106-203 -- Loss: 0.17141437530517578
train-epoch-step: 106-204 -- Loss: 0.12975752353668213
train-epoch-step: 106-205 -- Loss: 0.1822519600391388
train-epoch-step: 106-206 -- Loss: 0.19532646238803864
train-epoch-step: 106-207 -- Loss: 0.12740705907344818
train-epoch-step: 106-208 -- Loss: 0.17660753428936005
train-epoch-step: 106-209 -- Loss: 0.14658737182617188
train-epoch-step: 106-210 -- Loss: 0.12881888449192047
train-epoch-step: 106-211 -- Loss: 0.1969749629497528
train-epoch-step: 106-212 -- Loss: 0.1952829211950302
train-epoch-step: 106-213 -- Loss: 0.12308892607688904
train-epoch-step: 106-214 -- Loss: 0.14531154930591583
train-epoch-step: 106-215 -- Loss: 0.12312999367713928
train-epoch-step: 106-216 -- Loss: 0.19338999688625336
train-epoch-step: 106-217 -- Loss: 0.20379246771335602
train-epoch-step: 106-218 -- Loss: 0.14591512084007263
train-epoch-step: 106-219 -- Loss: 0.16254732012748718
train-epoch-step: 106-220 -- Loss: 0.12290070950984955
train-epoch-step: 106-221 -- Loss: 0.1978631615638733
train-epoch-step: 106-222 -- Loss: 0.111972376704216
train-epoch-step: 106-223 -- Loss: 0.1650059074163437
train-epoch-step: 106-224 -- Loss: 0.180915966629982
train-epoch-step: 106-225 -- Loss: 0.2545204758644104
train-epoch-step: 106-226 -- Loss: 0.19904707372188568
train-epoch-step: 106-227 -- Loss: 0.2137843817472458
train-epoch-step: 106-228 -- Loss: 0.17224688827991486
train-epoch-step: 106-229 -- Loss: 0.16993354260921478
train-epoch-step: 106-230 -- Loss: 0.15857954323291779
train-epoch-step: 106-231 -- Loss: 0.1514231413602829
train-epoch-step: 106-232 -- Loss: 0.17803506553173065
train-epoch-step: 106-233 -- Loss: 0.08055230230093002
train-epoch-step: 106-234 -- Loss: 0.16575375199317932
train-epoch-step: 106-235 -- Loss: 0.14235758781433105
train-epoch-step: 106-236 -- Loss: 0.17031864821910858
train-epoch-step: 106-237 -- Loss: 0.22946882247924805
train-epoch-step: 106-238 -- Loss: 0.15340851247310638
train-epoch-step: 106-239 -- Loss: 0.11832940578460693
train-epoch-step: 106-240 -- Loss: 0.21672379970550537
train-epoch-step: 106-241 -- Loss: 0.1478872001171112
train-epoch-step: 106-242 -- Loss: 0.21105273067951202
train-epoch-step: 106-243 -- Loss: 0.22659747302532196
train-epoch-step: 106-244 -- Loss: 0.19959627091884613
train-epoch-step: 106-245 -- Loss: 0.19708861410617828
train-epoch-step: 106-246 -- Loss: 0.20487840473651886
train-epoch-step: 106-247 -- Loss: 0.20666368305683136
train-epoch-step: 106-248 -- Loss: 0.18025782704353333
train-epoch-step: 106-249 -- Loss: 0.1301167756319046
train-epoch-step: 106-250 -- Loss: 0.19046784937381744
train-epoch-step: 106-251 -- Loss: 0.10182306915521622
train-epoch-step: 106-252 -- Loss: 0.19859620928764343
train-epoch-step: 106-253 -- Loss: 0.1303597092628479
train-epoch-step: 106-254 -- Loss: 0.2037770003080368
train-epoch-step: 106-255 -- Loss: 0.1392521858215332
train-epoch-step: 106-256 -- Loss: 0.14668351411819458
train-epoch-step: 106-257 -- Loss: 0.1914670169353485
train-epoch-step: 106-258 -- Loss: 0.13936671614646912
train-epoch-step: 106-259 -- Loss: 0.1109318733215332
train-epoch-step: 106-260 -- Loss: 0.19144576787948608
train-epoch-step: 106-261 -- Loss: 0.1726369708776474
train-epoch-step: 106-262 -- Loss: 0.2864677906036377
train-epoch-step: 106-263 -- Loss: 0.19234570860862732
train-epoch-step: 106-264 -- Loss: 0.1668432205915451
train-epoch-step: 106-265 -- Loss: 0.10201592743396759
train-epoch-step: 106-266 -- Loss: 0.14924754202365875
train-epoch-step: 106-267 -- Loss: 0.12990905344486237
train-epoch-step: 106-268 -- Loss: 0.11275991052389145
train-epoch-step: 106-269 -- Loss: 0.16521362960338593
train-epoch-step: 106-270 -- Loss: 0.10332336276769638
train-epoch-step: 106-271 -- Loss: 0.14339356124401093
train-epoch-step: 106-272 -- Loss: 0.10949475318193436
train-epoch-step: 106-273 -- Loss: 0.1210363432765007
train-epoch-step: 106-274 -- Loss: 0.17518357932567596
train-epoch-step: 106-275 -- Loss: 0.18122050166130066
train-epoch-step: 106-276 -- Loss: 0.1518900841474533
train-epoch-step: 106-277 -- Loss: 0.15730518102645874
train-epoch-step: 106-278 -- Loss: 0.13201244175434113
train-epoch-step: 106-279 -- Loss: 0.13244879245758057
train-epoch-step: 106-280 -- Loss: 0.20239953696727753
train-epoch-step: 106-281 -- Loss: 0.16891352832317352
train-epoch-step: 106-282 -- Loss: 0.134851336479187
train-epoch-step: 106-283 -- Loss: 0.11108967661857605
train-epoch-step: 106-284 -- Loss: 0.127772256731987
train-epoch-step: 106-285 -- Loss: 0.18339712917804718
train-epoch-step: 106-286 -- Loss: 0.14692898094654083
train-epoch-step: 106-287 -- Loss: 0.19442741572856903
train-epoch-step: 106-288 -- Loss: 0.08990415185689926
train-epoch-step: 106-289 -- Loss: 0.11077923327684402
train-epoch-step: 106-290 -- Loss: 0.1731657236814499
train-epoch-step: 106-291 -- Loss: 0.11402744799852371
train-epoch-step: 106-292 -- Loss: 0.14898066222667694
train-epoch-step: 106-293 -- Loss: 0.13297945261001587
train-epoch-step: 106-294 -- Loss: 0.16882307827472687
train-epoch-step: 106-295 -- Loss: 0.2474767416715622
train-epoch-step: 106-296 -- Loss: 0.15391279757022858
train-epoch-step: 106-297 -- Loss: 0.16504724323749542
train-epoch-step: 106-298 -- Loss: 0.2216259092092514
train-epoch-step: 106-299 -- Loss: 0.164103165268898
train-epoch-step: 106-300 -- Loss: 0.15788915753364563
train-epoch-step: 106-301 -- Loss: 0.17037929594516754
train-epoch-step: 106-302 -- Loss: 0.21196869015693665
train-epoch-step: 106-303 -- Loss: 0.19857506453990936
train-epoch-step: 106-304 -- Loss: 0.12350381165742874
train-epoch-step: 106-305 -- Loss: 0.13797929883003235
train-epoch-step: 106-306 -- Loss: 0.212715744972229
train-epoch-step: 106-307 -- Loss: 0.16037288308143616
train-epoch-step: 106-308 -- Loss: 0.2120968997478485
train-epoch-step: 106-309 -- Loss: 0.15163303911685944
train-epoch-step: 106-310 -- Loss: 0.1514613777399063
train-epoch-step: 106-311 -- Loss: 0.15289685130119324
train-epoch-step: 106-312 -- Loss: 0.20013755559921265
train-epoch-step: 106-313 -- Loss: 0.0931263118982315
train-epoch-step: 106-314 -- Loss: 0.18674074113368988
train-epoch-step: 106-315 -- Loss: 0.16272103786468506
train-epoch-step: 106-316 -- Loss: 0.14939218759536743
train-epoch-step: 106-317 -- Loss: 0.13562767207622528
train-epoch-step: 106-318 -- Loss: 0.15631318092346191
train-epoch-step: 106-319 -- Loss: 0.16409271955490112
train-epoch-step: 106-320 -- Loss: 0.11319370567798615
train-epoch-step: 106-321 -- Loss: 0.12671813368797302
train-epoch-step: 106-322 -- Loss: 0.20380938053131104
train-epoch-step: 106-323 -- Loss: 0.15419967472553253
train-epoch-step: 106-324 -- Loss: 0.24523574113845825
train-epoch-step: 106-325 -- Loss: 0.1512402594089508
train-epoch-step: 106-326 -- Loss: 0.16434277594089508
train-epoch-step: 106-327 -- Loss: 0.19510430097579956
train-epoch-step: 106-328 -- Loss: 0.18742237985134125
train-epoch-step: 106-329 -- Loss: 0.32607302069664
train-epoch-step: 106-330 -- Loss: 0.34328389167785645
train-epoch-step: 106-331 -- Loss: 0.19933627545833588
train-epoch-step: 106-332 -- Loss: 0.0942554920911789
train-epoch-step: 106-333 -- Loss: 0.1755335032939911
train-epoch-step: 106-334 -- Loss: 0.14803001284599304
train-epoch-step: 106-335 -- Loss: 0.1669008731842041
train-epoch-step: 106-336 -- Loss: 0.1401178240776062
train-epoch-step: 106-337 -- Loss: 0.19460955262184143
train-epoch-step: 106-338 -- Loss: 0.15468433499336243
train-epoch-step: 106-339 -- Loss: 0.1371263712644577
train-epoch-step: 106-340 -- Loss: 0.18548312783241272
train-epoch-step: 106-341 -- Loss: 0.13514623045921326
train-epoch-step: 106-342 -- Loss: 0.15522639453411102
train-epoch-step: 106-343 -- Loss: 0.15026214718818665
train-epoch-step: 106-344 -- Loss: 0.16055412590503693
train-epoch-step: 106-345 -- Loss: 0.123345747590065
train-epoch-step: 106-346 -- Loss: 0.22170214354991913
train-epoch-step: 106-347 -- Loss: 0.14566196501255035
train-epoch-step: 106-348 -- Loss: 0.19316130876541138
train-epoch-step: 106-349 -- Loss: 0.1995088756084442
train-epoch-step: 106-350 -- Loss: 0.2465972900390625
train-epoch-step: 106-351 -- Loss: 0.1871550977230072
train-epoch-step: 106-352 -- Loss: 0.12070390582084656
train-epoch-step: 106-353 -- Loss: 0.18881499767303467
train-epoch-step: 106-354 -- Loss: 0.26704055070877075
train-epoch-step: 106-355 -- Loss: 0.11575916409492493
train-epoch-step: 106-356 -- Loss: 0.1130889281630516
train-epoch-step: 106-357 -- Loss: 0.1811474710702896
train-epoch-step: 106-358 -- Loss: 0.17876213788986206
train-epoch-step: 106-359 -- Loss: 0.1321023404598236
train-epoch-step: 106-360 -- Loss: 0.12065831571817398
train-epoch-step: 106-361 -- Loss: 0.22819405794143677
train-epoch-step: 106-362 -- Loss: 0.16177961230278015
train-epoch-step: 106-363 -- Loss: 0.1055152639746666
train-epoch-step: 106-364 -- Loss: 0.17576828598976135
train-epoch-step: 106-365 -- Loss: 0.16767805814743042
train-epoch-step: 106-366 -- Loss: 0.195756733417511
train-epoch-step: 106-367 -- Loss: 0.2198028862476349
train-epoch-step: 106-368 -- Loss: 0.18758350610733032
train-epoch-step: 106-369 -- Loss: 0.279007226228714
train-epoch-step: 106-370 -- Loss: 0.11949487775564194
train-epoch-step: 106-371 -- Loss: 0.11994428932666779
train-epoch-step: 106-372 -- Loss: 0.14531433582305908
train-epoch-step: 106-373 -- Loss: 0.1803985834121704
train-epoch-step: 106-374 -- Loss: 0.14793534576892853
train-epoch-step: 106-375 -- Loss: 0.25593507289886475
train-epoch-step: 106-376 -- Loss: 0.1511438488960266
train-epoch-step: 106-377 -- Loss: 0.21451866626739502
train-epoch-step: 106-378 -- Loss: 0.1904030740261078
train-epoch-step: 106-379 -- Loss: 0.11408029496669769
train-epoch-step: 106-380 -- Loss: 0.08728006482124329
train-epoch-step: 106-381 -- Loss: 0.23220673203468323
train-epoch-step: 106-382 -- Loss: 0.2283570021390915
train-epoch-step: 106-383 -- Loss: 0.1708044558763504
train-epoch-step: 106-384 -- Loss: 0.20871339738368988
train-epoch-step: 106-385 -- Loss: 0.18552958965301514
train-epoch-step: 106-386 -- Loss: 0.1807207465171814
train-epoch-step: 106-387 -- Loss: 0.19616250693798065
train-epoch-step: 106-388 -- Loss: 0.174042746424675
train-epoch-step: 106-389 -- Loss: 0.16248005628585815
train-epoch-step: 106-390 -- Loss: 0.13825155794620514
train-epoch-step: 106-391 -- Loss: 0.1390204131603241
train-epoch-step: 106-392 -- Loss: 0.1768728345632553
train-epoch-step: 106-393 -- Loss: 0.1481674164533615
train-epoch-step: 106-394 -- Loss: 0.190096914768219
train-epoch-step: 106-395 -- Loss: 0.14749158918857574
train-epoch-step: 106-396 -- Loss: 0.12140053510665894
train-epoch-step: 106-397 -- Loss: 0.11972499638795853
train-epoch-step: 106-398 -- Loss: 0.1960849165916443
train-epoch-step: 106-399 -- Loss: 0.16792626678943634
train-epoch-step: 106-400 -- Loss: 0.2665051817893982
train-epoch-step: 106-401 -- Loss: 0.11456996202468872
train-epoch-step: 106-402 -- Loss: 0.24824151396751404
train-epoch-step: 106-403 -- Loss: 0.1485905945301056
train-epoch-step: 106-404 -- Loss: 0.13407790660858154
train-epoch-step: 106-405 -- Loss: 0.14396792650222778
train-epoch-step: 106-406 -- Loss: 0.15863032639026642
train-epoch-step: 106-407 -- Loss: 0.10667389631271362
train-epoch-step: 106-408 -- Loss: 0.15443289279937744
train-epoch-step: 106-409 -- Loss: 0.16718760132789612
train-epoch-step: 106-410 -- Loss: 0.16698838770389557
train-epoch-step: 106-411 -- Loss: 0.18552814424037933
train-epoch-step: 106-412 -- Loss: 0.125026136636734
train-epoch-step: 106-413 -- Loss: 0.14135590195655823
train-epoch-step: 106-414 -- Loss: 0.12777668237686157
train-epoch-step: 106-415 -- Loss: 0.12785442173480988
train-epoch-step: 106-416 -- Loss: 0.25114935636520386
train-epoch-step: 106-417 -- Loss: 0.18739184737205505
train-epoch-step: 106-418 -- Loss: 0.22146907448768616
train-epoch-step: 106-419 -- Loss: 0.16224241256713867
train-epoch-step: 106-420 -- Loss: 0.14879024028778076
train-epoch-step: 106-421 -- Loss: 0.16769123077392578
train-epoch-step: 106-422 -- Loss: 0.14591793715953827
train-epoch-step: 106-423 -- Loss: 0.16436441242694855
train-epoch-step: 106-424 -- Loss: 0.1323930025100708
train-epoch-step: 106-425 -- Loss: 0.17363043129444122
train-epoch-step: 106-426 -- Loss: 0.1577366292476654
train-epoch-step: 106-427 -- Loss: 0.1168283224105835
train-epoch-step: 106-428 -- Loss: 0.1828194260597229
train-epoch-step: 106-429 -- Loss: 0.16764935851097107
train-epoch-step: 106-430 -- Loss: 0.13787442445755005
train-epoch-step: 106-431 -- Loss: 0.15791651606559753
train-epoch-step: 106-432 -- Loss: 0.232693612575531
train-epoch-step: 106-433 -- Loss: 0.1344825178384781
train-epoch-step: 106-434 -- Loss: 0.12402619421482086
train-epoch-step: 106-435 -- Loss: 0.14816999435424805
train-epoch-step: 106-436 -- Loss: 0.14693540334701538
train-epoch-step: 106-437 -- Loss: 0.12563492357730865
train-epoch-step: 106-438 -- Loss: 0.16218405961990356
train-epoch-step: 106-439 -- Loss: 0.2556975483894348
train-epoch-step: 106-440 -- Loss: 0.12324617803096771
train-epoch-step: 106-441 -- Loss: 0.188432514667511
train-epoch-step: 106-442 -- Loss: 0.16632485389709473
train-epoch-step: 106-443 -- Loss: 0.15607446432113647
train-epoch-step: 106-444 -- Loss: 0.16486746072769165
train-epoch-step: 106-445 -- Loss: 0.17883682250976562
train-epoch-step: 106-446 -- Loss: 0.14903421700000763
train-epoch-step: 106-447 -- Loss: 0.18069876730442047
train-epoch-step: 106-448 -- Loss: 0.2147272527217865
train-epoch-step: 106-449 -- Loss: 0.18472711741924286
train-epoch-step: 106-450 -- Loss: 0.17492446303367615
train-epoch-step: 106-451 -- Loss: 0.1432507187128067
train-epoch-step: 106-452 -- Loss: 0.13078054785728455
train-epoch-step: 106-453 -- Loss: 0.08930285274982452
train-epoch-step: 106-454 -- Loss: 0.22445259988307953
train-epoch-step: 106-455 -- Loss: 0.12295392900705338
train-epoch-step: 106-456 -- Loss: 0.11340812593698502
train-epoch-step: 106-457 -- Loss: 0.20360039174556732
train-epoch-step: 106-458 -- Loss: 0.14283505082130432
train-epoch-step: 106-459 -- Loss: 0.20390179753303528
train-epoch-step: 106-460 -- Loss: 0.1238064169883728
train-epoch-step: 106-461 -- Loss: 0.12958966195583344
train-epoch-step: 106-462 -- Loss: 0.15273120999336243
train-epoch-step: 106-463 -- Loss: 0.1312578022480011
train-epoch-step: 106-464 -- Loss: 0.15324759483337402
train-epoch-step: 106-465 -- Loss: 0.224847674369812
train-epoch-step: 106-466 -- Loss: 0.20085933804512024
train-epoch-step: 106-467 -- Loss: 0.11336471885442734
train-epoch-step: 106-468 -- Loss: 0.1560426652431488
train-epoch-step: 106-469 -- Loss: 0.1997908502817154
train-epoch-step: 106-470 -- Loss: 0.16255712509155273
train-epoch-step: 106-471 -- Loss: 0.14650586247444153
train-epoch-step: 106-472 -- Loss: 0.15304584801197052
train-epoch-step: 106-473 -- Loss: 0.1483031064271927
train-epoch-step: 106-474 -- Loss: 0.11658239364624023
train-epoch-step: 106-475 -- Loss: 0.10646095871925354
train-epoch-step: 106-476 -- Loss: 0.1979585736989975
train-epoch-step: 106-477 -- Loss: 0.19153954088687897
train-epoch-step: 106-478 -- Loss: 0.18761789798736572
train-epoch-step: 106-479 -- Loss: 0.13228406012058258
train-epoch-step: 106-480 -- Loss: 0.18555301427841187
train-epoch-step: 106-481 -- Loss: 0.2697821259498596
train-epoch-step: 106-482 -- Loss: 0.26476916670799255
train-epoch-step: 106-483 -- Loss: 0.17242419719696045
train-epoch-step: 106-484 -- Loss: 0.20505119860172272
train-epoch-step: 106-485 -- Loss: 0.13835443556308746
train-epoch-step: 106-486 -- Loss: 0.2236863374710083
train-epoch-step: 106-487 -- Loss: 0.22650989890098572
train-epoch-step: 106-488 -- Loss: 0.18440648913383484
train-epoch-step: 106-489 -- Loss: 0.21395361423492432
train-epoch-step: 106-490 -- Loss: 0.13111068308353424
train-epoch-step: 106-491 -- Loss: 0.1353807896375656
train-epoch-step: 106-492 -- Loss: 0.12491894513368607
train-epoch-step: 106-493 -- Loss: 0.21051651239395142
train-epoch-step: 106-494 -- Loss: 0.1944962739944458
train-epoch-step: 106-495 -- Loss: 0.190925732254982
train-epoch-step: 106-496 -- Loss: 0.13779790699481964
train-epoch-step: 106-497 -- Loss: 0.17731788754463196
train-epoch-step: 106-498 -- Loss: 0.14570707082748413
train-epoch-step: 106-499 -- Loss: 0.1667625904083252
train-epoch-step: 106-500 -- Loss: 0.14977452158927917
train-epoch-step: 106-501 -- Loss: 0.20773693919181824
train-epoch-step: 106-502 -- Loss: 0.16417017579078674
train-epoch-step: 106-503 -- Loss: 0.21579374372959137
train-epoch-step: 106-504 -- Loss: 0.11876705288887024
train-epoch-step: 106-505 -- Loss: 0.17224477231502533
train-epoch-step: 106-506 -- Loss: 0.13229285180568695
train-epoch-step: 106-507 -- Loss: 0.18480250239372253
train-epoch-step: 106-508 -- Loss: 0.17594324052333832
train-epoch-step: 106-509 -- Loss: 0.16908130049705505
train-epoch-step: 106-510 -- Loss: 0.1286495476961136
train-epoch-step: 106-511 -- Loss: 0.2097804844379425
train-epoch-step: 106-512 -- Loss: 0.17390288412570953
train-epoch-step: 106-513 -- Loss: 0.18675678968429565
train-epoch-step: 106-514 -- Loss: 0.14705023169517517
train-epoch-step: 106-515 -- Loss: 0.14895765483379364
train-epoch-step: 106-516 -- Loss: 0.18710972368717194
train-epoch-step: 106-517 -- Loss: 0.1737549901008606
train-epoch-step: 106-518 -- Loss: 0.13769440352916718
train-epoch-step: 106-519 -- Loss: 0.13468189537525177
train-epoch-step: 106-520 -- Loss: 0.18764272332191467
train-epoch-step: 106-521 -- Loss: 0.2211228311061859
train-epoch-step: 106-522 -- Loss: 0.17873890697956085
train-epoch-step: 106-523 -- Loss: 0.15711946785449982
train-epoch-step: 106-524 -- Loss: 0.16346406936645508
train-epoch-step: 106-525 -- Loss: 0.1916794776916504
train-epoch-step: 106-526 -- Loss: 0.1284620761871338
train-epoch-step: 106-527 -- Loss: 0.16556841135025024
train-epoch-step: 106-528 -- Loss: 0.14928099513053894
train-epoch-step: 106-529 -- Loss: 0.1555117666721344
train-epoch-step: 106-530 -- Loss: 0.16526632010936737
train-epoch-step: 106-531 -- Loss: 0.1927720159292221
train-epoch-step: 106-532 -- Loss: 0.16329869627952576
train-epoch-step: 106-533 -- Loss: 0.1739112138748169
train-epoch-step: 106-534 -- Loss: 0.1390814185142517
train-epoch-step: 106-535 -- Loss: 0.26131367683410645
train-epoch-step: 106-536 -- Loss: 0.17393934726715088
train-epoch-step: 106-537 -- Loss: 0.16244934499263763
train-epoch-step: 106-538 -- Loss: 0.10938878357410431
train-epoch-step: 106-539 -- Loss: 0.18156224489212036
train-epoch-step: 106-540 -- Loss: 0.13304589688777924
train-epoch-step: 106-541 -- Loss: 0.2076030969619751
train-epoch-step: 106-542 -- Loss: 0.21729245781898499
train-epoch-step: 106-543 -- Loss: 0.16264067590236664
train-epoch-step: 106-544 -- Loss: 0.21935994923114777
train-epoch-step: 106-545 -- Loss: 0.18626216053962708
train-epoch-step: 106-546 -- Loss: 0.209455206990242
train-epoch-step: 106-547 -- Loss: 0.18988826870918274
train-epoch-step: 106-548 -- Loss: 0.09434207528829575
train-epoch-step: 106-549 -- Loss: 0.14455179870128632
train-epoch-step: 106-550 -- Loss: 0.19522389769554138
train-epoch-step: 106-551 -- Loss: 0.14862237870693207
train-epoch-step: 106-552 -- Loss: 0.12019491195678711
train-epoch-step: 106-553 -- Loss: 0.17932742834091187
train-epoch-step: 106-554 -- Loss: 0.19218650460243225
train-epoch-step: 106-555 -- Loss: 0.20655223727226257
train-epoch-step: 106-556 -- Loss: 0.14337117969989777
train-epoch-step: 106-557 -- Loss: 0.22383619844913483
train-epoch-step: 106-558 -- Loss: 0.2244400680065155
train-epoch-step: 106-559 -- Loss: 0.13155490159988403
train-epoch-step: 106-560 -- Loss: 0.19535553455352783
train-epoch-step: 106-561 -- Loss: 0.17385298013687134
train-epoch-step: 106-562 -- Loss: 0.15848977863788605
train-epoch-step: 106-563 -- Loss: 0.17618608474731445
train-epoch-step: 106-564 -- Loss: 0.09766983240842819
train-epoch-step: 106-565 -- Loss: 0.17985954880714417
train-epoch-step: 106-566 -- Loss: 0.14241155982017517
train-epoch-step: 106-567 -- Loss: 0.20428428053855896
train-epoch-step: 106-568 -- Loss: 0.15399999916553497
train-epoch-step: 106-569 -- Loss: 0.23454368114471436
train-epoch-step: 106-570 -- Loss: 0.16264662146568298
train-epoch-step: 106-571 -- Loss: 0.20965984463691711
train-epoch-step: 106-572 -- Loss: 0.23043575882911682
train-epoch-step: 106-573 -- Loss: 0.19168195128440857
train-epoch-step: 106-574 -- Loss: 0.23490659892559052
train-epoch-step: 106-575 -- Loss: 0.28500112891197205
train-epoch-step: 106-576 -- Loss: 0.11522815376520157
train-epoch-step: 106-577 -- Loss: 0.16129720211029053
train-epoch-step: 106-578 -- Loss: 0.20986467599868774
train-epoch-step: 106-579 -- Loss: 0.17843234539031982
train-epoch-step: 106-580 -- Loss: 0.16573089361190796
train-epoch-step: 106-581 -- Loss: 0.13875114917755127
train-epoch-step: 106-582 -- Loss: 0.1992677003145218
train-epoch-step: 106-583 -- Loss: 0.23011568188667297
train-epoch-step: 106-584 -- Loss: 0.15593968331813812
train-epoch-step: 106-585 -- Loss: 0.18904438614845276
train-epoch-step: 106-586 -- Loss: 0.2455134391784668
train-epoch-step: 106-587 -- Loss: 0.152959942817688
train-epoch-step: 106-588 -- Loss: 0.12824711203575134
val-epoch-step: 106-589 -- Loss: 0.20358794927597046
val-epoch-step: 106-590 -- Loss: 0.15139634907245636
val-epoch-step: 106-591 -- Loss: 0.24671593308448792
val-epoch-step: 106-592 -- Loss: 0.16837078332901
val-epoch-step: 106-593 -- Loss: 0.16212619841098785
val-epoch-step: 106-594 -- Loss: 0.39823663234710693
val-epoch-step: 106-595 -- Loss: 0.1764647364616394
val-epoch-step: 106-596 -- Loss: 0.22009751200675964
val-epoch-step: 106-597 -- Loss: 0.16974210739135742
val-epoch-step: 106-598 -- Loss: 0.1445813924074173
val-epoch-step: 106-599 -- Loss: 0.17844069004058838
val-epoch-step: 106-600 -- Loss: 0.16387152671813965
val-epoch-step: 106-601 -- Loss: 0.16397805511951447
val-epoch-step: 106-602 -- Loss: 0.13810551166534424
val-epoch-step: 106-603 -- Loss: 0.18621551990509033
val-epoch-step: 106-604 -- Loss: 0.14532355964183807
val-epoch-step: 106-605 -- Loss: 0.14191225171089172
val-epoch-step: 106-606 -- Loss: 0.26946765184402466
val-epoch-step: 106-607 -- Loss: 0.12867695093154907
val-epoch-step: 106-608 -- Loss: 0.2549164295196533
val-epoch-step: 106-609 -- Loss: 0.16857309639453888
val-epoch-step: 106-610 -- Loss: 0.17041844129562378
val-epoch-step: 106-611 -- Loss: 0.15566101670265198
val-epoch-step: 106-612 -- Loss: 0.3506395220756531
val-epoch-step: 106-613 -- Loss: 0.18821129202842712
val-epoch-step: 106-614 -- Loss: 0.17024201154708862
val-epoch-step: 106-615 -- Loss: 0.1739450991153717
val-epoch-step: 106-616 -- Loss: 0.15511594712734222
val-epoch-step: 106-617 -- Loss: 0.19284844398498535
val-epoch-step: 106-618 -- Loss: 0.2333904504776001
val-epoch-step: 106-619 -- Loss: 0.20033986866474152
val-epoch-step: 106-620 -- Loss: 0.15929272770881653
val-epoch-step: 106-621 -- Loss: 0.12442321330308914
val-epoch-step: 106-622 -- Loss: 0.14764170348644257
val-epoch-step: 106-623 -- Loss: 0.1588631570339203
val-epoch-step: 106-624 -- Loss: 0.13982656598091125
val-epoch-step: 106-625 -- Loss: 0.15250752866268158
val-epoch-step: 106-626 -- Loss: 0.1468043327331543
val-epoch-step: 106-627 -- Loss: 0.1810379922389984
val-epoch-step: 106-628 -- Loss: 0.4942827820777893
val-epoch-step: 106-629 -- Loss: 0.22731834650039673
val-epoch-step: 106-630 -- Loss: 0.3467048704624176
val-epoch-step: 106-631 -- Loss: 0.14021103084087372
val-epoch-step: 106-632 -- Loss: 0.19498328864574432
val-epoch-step: 106-633 -- Loss: 0.15116427838802338
val-epoch-step: 106-634 -- Loss: 0.14621584117412567
val-epoch-step: 106-635 -- Loss: 0.11086532473564148
val-epoch-step: 106-636 -- Loss: 0.1637224555015564
val-epoch-step: 106-637 -- Loss: 0.18340927362442017
val-epoch-step: 106-638 -- Loss: 0.15057285130023956
val-epoch-step: 106-639 -- Loss: 0.24833275377750397
val-epoch-step: 106-640 -- Loss: 0.24274855852127075
val-epoch-step: 106-641 -- Loss: 0.1340813785791397
val-epoch-step: 106-642 -- Loss: 0.17531995475292206
val-epoch-step: 106-643 -- Loss: 0.2177950143814087
val-epoch-step: 106-644 -- Loss: 0.1607123464345932
val-epoch-step: 106-645 -- Loss: 0.2114465981721878
val-epoch-step: 106-646 -- Loss: 0.12475281208753586
val-epoch-step: 106-647 -- Loss: 0.13163258135318756
val-epoch-step: 106-648 -- Loss: 0.1549755185842514
val-epoch-step: 106-649 -- Loss: 0.20640188455581665
val-epoch-step: 106-650 -- Loss: 0.24628759920597076
val-epoch-step: 106-651 -- Loss: 0.1431197077035904
val-epoch-step: 106-652 -- Loss: 0.1496916562318802
val-epoch-step: 106-653 -- Loss: 0.1951034963130951
val-epoch-step: 106-654 -- Loss: 0.10851862281560898
Epoch: 106 -- Train Loss: tensor(0.1385, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 107-0 -- Loss: 0.22442562878131866
train-epoch-step: 107-1 -- Loss: 0.14004650712013245
train-epoch-step: 107-2 -- Loss: 0.18924613296985626
train-epoch-step: 107-3 -- Loss: 0.1353519707918167
train-epoch-step: 107-4 -- Loss: 0.1548926830291748
train-epoch-step: 107-5 -- Loss: 0.19538800418376923
train-epoch-step: 107-6 -- Loss: 0.22339606285095215
train-epoch-step: 107-7 -- Loss: 0.16338194906711578
train-epoch-step: 107-8 -- Loss: 0.19246278703212738
train-epoch-step: 107-9 -- Loss: 0.22604116797447205
train-epoch-step: 107-10 -- Loss: 0.18879514932632446
train-epoch-step: 107-11 -- Loss: 0.17119744420051575
train-epoch-step: 107-12 -- Loss: 0.1419346034526825
train-epoch-step: 107-13 -- Loss: 0.1731412261724472
train-epoch-step: 107-14 -- Loss: 0.16001266241073608
train-epoch-step: 107-15 -- Loss: 0.15292207896709442
train-epoch-step: 107-16 -- Loss: 0.1698734313249588
train-epoch-step: 107-17 -- Loss: 0.23675037920475006
train-epoch-step: 107-18 -- Loss: 0.190002903342247
train-epoch-step: 107-19 -- Loss: 0.12751665711402893
train-epoch-step: 107-20 -- Loss: 0.21223212778568268
train-epoch-step: 107-21 -- Loss: 0.26606541872024536
train-epoch-step: 107-22 -- Loss: 0.1370939165353775
train-epoch-step: 107-23 -- Loss: 0.13641703128814697
train-epoch-step: 107-24 -- Loss: 0.12301934510469437
train-epoch-step: 107-25 -- Loss: 0.24308982491493225
train-epoch-step: 107-26 -- Loss: 0.1958429515361786
train-epoch-step: 107-27 -- Loss: 0.22183671593666077
train-epoch-step: 107-28 -- Loss: 0.12681441009044647
train-epoch-step: 107-29 -- Loss: 0.24468070268630981
train-epoch-step: 107-30 -- Loss: 0.11044381558895111
train-epoch-step: 107-31 -- Loss: 0.13365395367145538
train-epoch-step: 107-32 -- Loss: 0.17886267602443695
train-epoch-step: 107-33 -- Loss: 0.2705317437648773
train-epoch-step: 107-34 -- Loss: 0.17186494171619415
train-epoch-step: 107-35 -- Loss: 0.24046435952186584
train-epoch-step: 107-36 -- Loss: 0.13958732783794403
train-epoch-step: 107-37 -- Loss: 0.13256700336933136
train-epoch-step: 107-38 -- Loss: 0.16852954030036926
train-epoch-step: 107-39 -- Loss: 0.21875032782554626
train-epoch-step: 107-40 -- Loss: 0.19225332140922546
train-epoch-step: 107-41 -- Loss: 0.2143584042787552
train-epoch-step: 107-42 -- Loss: 0.14272576570510864
train-epoch-step: 107-43 -- Loss: 0.25315895676612854
train-epoch-step: 107-44 -- Loss: 0.12411614507436752
train-epoch-step: 107-45 -- Loss: 0.12296508252620697
train-epoch-step: 107-46 -- Loss: 0.1714753359556198
train-epoch-step: 107-47 -- Loss: 0.1980176568031311
train-epoch-step: 107-48 -- Loss: 0.15801726281642914
train-epoch-step: 107-49 -- Loss: 0.21723556518554688
train-epoch-step: 107-50 -- Loss: 0.1061321571469307
train-epoch-step: 107-51 -- Loss: 0.17120343446731567
train-epoch-step: 107-52 -- Loss: 0.15844455361366272
train-epoch-step: 107-53 -- Loss: 0.20028750598430634
train-epoch-step: 107-54 -- Loss: 0.2807706892490387
train-epoch-step: 107-55 -- Loss: 0.15805427730083466
train-epoch-step: 107-56 -- Loss: 0.17569062113761902
train-epoch-step: 107-57 -- Loss: 0.2315317988395691
train-epoch-step: 107-58 -- Loss: 0.2769694924354553
train-epoch-step: 107-59 -- Loss: 0.23926347494125366
train-epoch-step: 107-60 -- Loss: 0.13089042901992798
train-epoch-step: 107-61 -- Loss: 0.19281116127967834
train-epoch-step: 107-62 -- Loss: 0.17739804089069366
train-epoch-step: 107-63 -- Loss: 0.13274794816970825
train-epoch-step: 107-64 -- Loss: 0.14188829064369202
train-epoch-step: 107-65 -- Loss: 0.1797216683626175
train-epoch-step: 107-66 -- Loss: 0.10635348409414291
train-epoch-step: 107-67 -- Loss: 0.11899752169847488
train-epoch-step: 107-68 -- Loss: 0.2153940349817276
train-epoch-step: 107-69 -- Loss: 0.11666350811719894
train-epoch-step: 107-70 -- Loss: 0.22397111356258392
train-epoch-step: 107-71 -- Loss: 0.24629315733909607
train-epoch-step: 107-72 -- Loss: 0.16851727664470673
train-epoch-step: 107-73 -- Loss: 0.19762521982192993
train-epoch-step: 107-74 -- Loss: 0.09331595152616501
train-epoch-step: 107-75 -- Loss: 0.1218317374587059
train-epoch-step: 107-76 -- Loss: 0.14286504685878754
train-epoch-step: 107-77 -- Loss: 0.2233937382698059
train-epoch-step: 107-78 -- Loss: 0.2532563805580139
train-epoch-step: 107-79 -- Loss: 0.18908102810382843
train-epoch-step: 107-80 -- Loss: 0.24241386353969574
train-epoch-step: 107-81 -- Loss: 0.12309429049491882
train-epoch-step: 107-82 -- Loss: 0.2440038025379181
train-epoch-step: 107-83 -- Loss: 0.1682261824607849
train-epoch-step: 107-84 -- Loss: 0.1806582510471344
train-epoch-step: 107-85 -- Loss: 0.17244265973567963
train-epoch-step: 107-86 -- Loss: 0.11664403975009918
train-epoch-step: 107-87 -- Loss: 0.20421288907527924
train-epoch-step: 107-88 -- Loss: 0.14095847308635712
train-epoch-step: 107-89 -- Loss: 0.1904473453760147
train-epoch-step: 107-90 -- Loss: 0.18364503979682922
train-epoch-step: 107-91 -- Loss: 0.24370712041854858
train-epoch-step: 107-92 -- Loss: 0.14850661158561707
train-epoch-step: 107-93 -- Loss: 0.16960066556930542
train-epoch-step: 107-94 -- Loss: 0.2226254940032959
train-epoch-step: 107-95 -- Loss: 0.19302454590797424
train-epoch-step: 107-96 -- Loss: 0.21156878769397736
train-epoch-step: 107-97 -- Loss: 0.1688677966594696
train-epoch-step: 107-98 -- Loss: 0.15208685398101807
train-epoch-step: 107-99 -- Loss: 0.19281147420406342
train-epoch-step: 107-100 -- Loss: 0.18310195207595825
train-epoch-step: 107-101 -- Loss: 0.26435673236846924
train-epoch-step: 107-102 -- Loss: 0.2107597142457962
train-epoch-step: 107-103 -- Loss: 0.1747267097234726
train-epoch-step: 107-104 -- Loss: 0.142472043633461
train-epoch-step: 107-105 -- Loss: 0.2593092918395996
train-epoch-step: 107-106 -- Loss: 0.17728835344314575
train-epoch-step: 107-107 -- Loss: 0.1805879771709442
train-epoch-step: 107-108 -- Loss: 0.187419593334198
train-epoch-step: 107-109 -- Loss: 0.13783280551433563
train-epoch-step: 107-110 -- Loss: 0.17719025909900665
train-epoch-step: 107-111 -- Loss: 0.18705736100673676
train-epoch-step: 107-112 -- Loss: 0.16554425656795502
train-epoch-step: 107-113 -- Loss: 0.159162238240242
train-epoch-step: 107-114 -- Loss: 0.18445581197738647
train-epoch-step: 107-115 -- Loss: 0.1569831371307373
train-epoch-step: 107-116 -- Loss: 0.13377819955348969
train-epoch-step: 107-117 -- Loss: 0.13072320818901062
train-epoch-step: 107-118 -- Loss: 0.1811160445213318
train-epoch-step: 107-119 -- Loss: 0.1489994078874588
train-epoch-step: 107-120 -- Loss: 0.2408895641565323
train-epoch-step: 107-121 -- Loss: 0.22501039505004883
train-epoch-step: 107-122 -- Loss: 0.21191340684890747
train-epoch-step: 107-123 -- Loss: 0.19577498733997345
train-epoch-step: 107-124 -- Loss: 0.11704369634389877
train-epoch-step: 107-125 -- Loss: 0.14968262612819672
train-epoch-step: 107-126 -- Loss: 0.22482600808143616
train-epoch-step: 107-127 -- Loss: 0.1681407392024994
train-epoch-step: 107-128 -- Loss: 0.1675082892179489
train-epoch-step: 107-129 -- Loss: 0.14196032285690308
train-epoch-step: 107-130 -- Loss: 0.19291788339614868
train-epoch-step: 107-131 -- Loss: 0.13158094882965088
train-epoch-step: 107-132 -- Loss: 0.18293678760528564
train-epoch-step: 107-133 -- Loss: 0.11261382699012756
train-epoch-step: 107-134 -- Loss: 0.18971139192581177
train-epoch-step: 107-135 -- Loss: 0.12884950637817383
train-epoch-step: 107-136 -- Loss: 0.12620286643505096
train-epoch-step: 107-137 -- Loss: 0.250847190618515
train-epoch-step: 107-138 -- Loss: 0.24635478854179382
train-epoch-step: 107-139 -- Loss: 0.13473212718963623
train-epoch-step: 107-140 -- Loss: 0.1968802511692047
train-epoch-step: 107-141 -- Loss: 0.22269245982170105
train-epoch-step: 107-142 -- Loss: 0.19455786049365997
train-epoch-step: 107-143 -- Loss: 0.16432997584342957
train-epoch-step: 107-144 -- Loss: 0.17904946208000183
train-epoch-step: 107-145 -- Loss: 0.13793796300888062
train-epoch-step: 107-146 -- Loss: 0.17165036499500275
train-epoch-step: 107-147 -- Loss: 0.16386738419532776
train-epoch-step: 107-148 -- Loss: 0.1601291447877884
train-epoch-step: 107-149 -- Loss: 0.11630716174840927
train-epoch-step: 107-150 -- Loss: 0.18017809092998505
train-epoch-step: 107-151 -- Loss: 0.18792939186096191
train-epoch-step: 107-152 -- Loss: 0.19203007221221924
train-epoch-step: 107-153 -- Loss: 0.25130122900009155
train-epoch-step: 107-154 -- Loss: 0.13080638647079468
train-epoch-step: 107-155 -- Loss: 0.13220719993114471
train-epoch-step: 107-156 -- Loss: 0.11558175086975098
train-epoch-step: 107-157 -- Loss: 0.16159102320671082
train-epoch-step: 107-158 -- Loss: 0.1604761779308319
train-epoch-step: 107-159 -- Loss: 0.17735743522644043
train-epoch-step: 107-160 -- Loss: 0.20454543828964233
train-epoch-step: 107-161 -- Loss: 0.2007676064968109
train-epoch-step: 107-162 -- Loss: 0.20421172678470612
train-epoch-step: 107-163 -- Loss: 0.17977149784564972
train-epoch-step: 107-164 -- Loss: 0.19045884907245636
train-epoch-step: 107-165 -- Loss: 0.18414026498794556
train-epoch-step: 107-166 -- Loss: 0.12212903052568436
train-epoch-step: 107-167 -- Loss: 0.11976532638072968
train-epoch-step: 107-168 -- Loss: 0.19465704262256622
train-epoch-step: 107-169 -- Loss: 0.1352342963218689
train-epoch-step: 107-170 -- Loss: 0.1909727305173874
train-epoch-step: 107-171 -- Loss: 0.1405162215232849
train-epoch-step: 107-172 -- Loss: 0.2567169666290283
train-epoch-step: 107-173 -- Loss: 0.13101431727409363
train-epoch-step: 107-174 -- Loss: 0.24554461240768433
train-epoch-step: 107-175 -- Loss: 0.18277804553508759
train-epoch-step: 107-176 -- Loss: 0.12442182749509811
train-epoch-step: 107-177 -- Loss: 0.17933358252048492
train-epoch-step: 107-178 -- Loss: 0.17148469388484955
train-epoch-step: 107-179 -- Loss: 0.15584442019462585
train-epoch-step: 107-180 -- Loss: 0.1486586332321167
train-epoch-step: 107-181 -- Loss: 0.1627732813358307
train-epoch-step: 107-182 -- Loss: 0.17954446375370026
train-epoch-step: 107-183 -- Loss: 0.2626696228981018
train-epoch-step: 107-184 -- Loss: 0.13484802842140198
train-epoch-step: 107-185 -- Loss: 0.13582593202590942
train-epoch-step: 107-186 -- Loss: 0.18427550792694092
train-epoch-step: 107-187 -- Loss: 0.20349541306495667
train-epoch-step: 107-188 -- Loss: 0.16724149882793427
train-epoch-step: 107-189 -- Loss: 0.09906045347452164
train-epoch-step: 107-190 -- Loss: 0.18072786927223206
train-epoch-step: 107-191 -- Loss: 0.1570930778980255
train-epoch-step: 107-192 -- Loss: 0.22032642364501953
train-epoch-step: 107-193 -- Loss: 0.20696261525154114
train-epoch-step: 107-194 -- Loss: 0.17792166769504547
train-epoch-step: 107-195 -- Loss: 0.16266880929470062
train-epoch-step: 107-196 -- Loss: 0.15916264057159424
train-epoch-step: 107-197 -- Loss: 0.11940518021583557
train-epoch-step: 107-198 -- Loss: 0.12511901557445526
train-epoch-step: 107-199 -- Loss: 0.14348213374614716
train-epoch-step: 107-200 -- Loss: 0.1193421334028244
train-epoch-step: 107-201 -- Loss: 0.1832166314125061
train-epoch-step: 107-202 -- Loss: 0.1317920684814453
train-epoch-step: 107-203 -- Loss: 0.17087861895561218
train-epoch-step: 107-204 -- Loss: 0.13000406324863434
train-epoch-step: 107-205 -- Loss: 0.18546468019485474
train-epoch-step: 107-206 -- Loss: 0.19051608443260193
train-epoch-step: 107-207 -- Loss: 0.13824725151062012
train-epoch-step: 107-208 -- Loss: 0.1740821897983551
train-epoch-step: 107-209 -- Loss: 0.137728750705719
train-epoch-step: 107-210 -- Loss: 0.1345626562833786
train-epoch-step: 107-211 -- Loss: 0.20583641529083252
train-epoch-step: 107-212 -- Loss: 0.19277119636535645
train-epoch-step: 107-213 -- Loss: 0.1249329000711441
train-epoch-step: 107-214 -- Loss: 0.14255329966545105
train-epoch-step: 107-215 -- Loss: 0.12344217300415039
train-epoch-step: 107-216 -- Loss: 0.2009648233652115
train-epoch-step: 107-217 -- Loss: 0.21208833158016205
train-epoch-step: 107-218 -- Loss: 0.13915252685546875
train-epoch-step: 107-219 -- Loss: 0.2116142362356186
train-epoch-step: 107-220 -- Loss: 0.12488533556461334
train-epoch-step: 107-221 -- Loss: 0.19998720288276672
train-epoch-step: 107-222 -- Loss: 0.11214827746152878
train-epoch-step: 107-223 -- Loss: 0.1745050698518753
train-epoch-step: 107-224 -- Loss: 0.19770926237106323
train-epoch-step: 107-225 -- Loss: 0.26623404026031494
train-epoch-step: 107-226 -- Loss: 0.20835798978805542
train-epoch-step: 107-227 -- Loss: 0.22269786894321442
train-epoch-step: 107-228 -- Loss: 0.17031021416187286
train-epoch-step: 107-229 -- Loss: 0.17504382133483887
train-epoch-step: 107-230 -- Loss: 0.17621703445911407
train-epoch-step: 107-231 -- Loss: 0.14877501130104065
train-epoch-step: 107-232 -- Loss: 0.1875598281621933
train-epoch-step: 107-233 -- Loss: 0.0846947655081749
train-epoch-step: 107-234 -- Loss: 0.17742560803890228
train-epoch-step: 107-235 -- Loss: 0.1440204679965973
train-epoch-step: 107-236 -- Loss: 0.17714282870292664
train-epoch-step: 107-237 -- Loss: 0.2274940311908722
train-epoch-step: 107-238 -- Loss: 0.15695080161094666
train-epoch-step: 107-239 -- Loss: 0.12924520671367645
train-epoch-step: 107-240 -- Loss: 0.21787910163402557
train-epoch-step: 107-241 -- Loss: 0.15448209643363953
train-epoch-step: 107-242 -- Loss: 0.2161177396774292
train-epoch-step: 107-243 -- Loss: 0.23483361303806305
train-epoch-step: 107-244 -- Loss: 0.1990252137184143
train-epoch-step: 107-245 -- Loss: 0.20303723216056824
train-epoch-step: 107-246 -- Loss: 0.21568822860717773
train-epoch-step: 107-247 -- Loss: 0.20528018474578857
train-epoch-step: 107-248 -- Loss: 0.18283911049365997
train-epoch-step: 107-249 -- Loss: 0.1360449343919754
train-epoch-step: 107-250 -- Loss: 0.1966930627822876
train-epoch-step: 107-251 -- Loss: 0.1038803905248642
train-epoch-step: 107-252 -- Loss: 0.20056554675102234
train-epoch-step: 107-253 -- Loss: 0.1324145495891571
train-epoch-step: 107-254 -- Loss: 0.20980682969093323
train-epoch-step: 107-255 -- Loss: 0.14296790957450867
train-epoch-step: 107-256 -- Loss: 0.17497053742408752
train-epoch-step: 107-257 -- Loss: 0.19072264432907104
train-epoch-step: 107-258 -- Loss: 0.14301511645317078
train-epoch-step: 107-259 -- Loss: 0.11038890480995178
train-epoch-step: 107-260 -- Loss: 0.20165105164051056
train-epoch-step: 107-261 -- Loss: 0.17720961570739746
train-epoch-step: 107-262 -- Loss: 0.34845075011253357
train-epoch-step: 107-263 -- Loss: 0.19629254937171936
train-epoch-step: 107-264 -- Loss: 0.1733749806880951
train-epoch-step: 107-265 -- Loss: 0.10964544117450714
train-epoch-step: 107-266 -- Loss: 0.14629203081130981
train-epoch-step: 107-267 -- Loss: 0.12287326902151108
train-epoch-step: 107-268 -- Loss: 0.11566586792469025
train-epoch-step: 107-269 -- Loss: 0.16701525449752808
train-epoch-step: 107-270 -- Loss: 0.1073843389749527
train-epoch-step: 107-271 -- Loss: 0.14592954516410828
train-epoch-step: 107-272 -- Loss: 0.11130914092063904
train-epoch-step: 107-273 -- Loss: 0.12418492138385773
train-epoch-step: 107-274 -- Loss: 0.17797443270683289
train-epoch-step: 107-275 -- Loss: 0.19685372710227966
train-epoch-step: 107-276 -- Loss: 0.1529950201511383
train-epoch-step: 107-277 -- Loss: 0.15336690843105316
train-epoch-step: 107-278 -- Loss: 0.1353898048400879
train-epoch-step: 107-279 -- Loss: 0.13911300897598267
train-epoch-step: 107-280 -- Loss: 0.21063552796840668
train-epoch-step: 107-281 -- Loss: 0.1790076494216919
train-epoch-step: 107-282 -- Loss: 0.14023222029209137
train-epoch-step: 107-283 -- Loss: 0.11427225172519684
train-epoch-step: 107-284 -- Loss: 0.2560895085334778
train-epoch-step: 107-285 -- Loss: 0.20313593745231628
train-epoch-step: 107-286 -- Loss: 0.14814051985740662
train-epoch-step: 107-287 -- Loss: 0.20107954740524292
train-epoch-step: 107-288 -- Loss: 0.09901221096515656
train-epoch-step: 107-289 -- Loss: 0.12448950111865997
train-epoch-step: 107-290 -- Loss: 0.17912493646144867
train-epoch-step: 107-291 -- Loss: 0.11469516158103943
train-epoch-step: 107-292 -- Loss: 0.15923842787742615
train-epoch-step: 107-293 -- Loss: 0.13528157770633698
train-epoch-step: 107-294 -- Loss: 0.16199597716331482
train-epoch-step: 107-295 -- Loss: 0.31719452142715454
train-epoch-step: 107-296 -- Loss: 0.18261396884918213
train-epoch-step: 107-297 -- Loss: 0.17481300234794617
train-epoch-step: 107-298 -- Loss: 0.22083249688148499
train-epoch-step: 107-299 -- Loss: 0.15204694867134094
train-epoch-step: 107-300 -- Loss: 0.17204374074935913
train-epoch-step: 107-301 -- Loss: 0.16749195754528046
train-epoch-step: 107-302 -- Loss: 0.21781161427497864
train-epoch-step: 107-303 -- Loss: 0.19986587762832642
train-epoch-step: 107-304 -- Loss: 0.14558455348014832
train-epoch-step: 107-305 -- Loss: 0.14645123481750488
train-epoch-step: 107-306 -- Loss: 0.21990522742271423
train-epoch-step: 107-307 -- Loss: 0.1659339964389801
train-epoch-step: 107-308 -- Loss: 0.2314559519290924
train-epoch-step: 107-309 -- Loss: 0.15719130635261536
train-epoch-step: 107-310 -- Loss: 0.15966734290122986
train-epoch-step: 107-311 -- Loss: 0.15888184309005737
train-epoch-step: 107-312 -- Loss: 0.19821372628211975
train-epoch-step: 107-313 -- Loss: 0.09836547821760178
train-epoch-step: 107-314 -- Loss: 0.1893683671951294
train-epoch-step: 107-315 -- Loss: 0.1668035387992859
train-epoch-step: 107-316 -- Loss: 0.14600668847560883
train-epoch-step: 107-317 -- Loss: 0.13806389272212982
train-epoch-step: 107-318 -- Loss: 0.16801679134368896
train-epoch-step: 107-319 -- Loss: 0.16337795555591583
train-epoch-step: 107-320 -- Loss: 0.11502077430486679
train-epoch-step: 107-321 -- Loss: 0.1333467662334442
train-epoch-step: 107-322 -- Loss: 0.20964810252189636
train-epoch-step: 107-323 -- Loss: 0.15581926703453064
train-epoch-step: 107-324 -- Loss: 0.2418198436498642
train-epoch-step: 107-325 -- Loss: 0.15551349520683289
train-epoch-step: 107-326 -- Loss: 0.169320210814476
train-epoch-step: 107-327 -- Loss: 0.19762307405471802
train-epoch-step: 107-328 -- Loss: 0.19269347190856934
train-epoch-step: 107-329 -- Loss: 0.33335110545158386
train-epoch-step: 107-330 -- Loss: 0.39239540696144104
train-epoch-step: 107-331 -- Loss: 0.21138878166675568
train-epoch-step: 107-332 -- Loss: 0.09475336968898773
train-epoch-step: 107-333 -- Loss: 0.17354927957057953
train-epoch-step: 107-334 -- Loss: 0.15168094635009766
train-epoch-step: 107-335 -- Loss: 0.16797104477882385
train-epoch-step: 107-336 -- Loss: 0.14623941481113434
train-epoch-step: 107-337 -- Loss: 0.2053806036710739
train-epoch-step: 107-338 -- Loss: 0.15593579411506653
train-epoch-step: 107-339 -- Loss: 0.13930493593215942
train-epoch-step: 107-340 -- Loss: 0.19188357889652252
train-epoch-step: 107-341 -- Loss: 0.13423696160316467
train-epoch-step: 107-342 -- Loss: 0.15765485167503357
train-epoch-step: 107-343 -- Loss: 0.1484178602695465
train-epoch-step: 107-344 -- Loss: 0.16840779781341553
train-epoch-step: 107-345 -- Loss: 0.12000799179077148
train-epoch-step: 107-346 -- Loss: 0.20483967661857605
train-epoch-step: 107-347 -- Loss: 0.1478540599346161
train-epoch-step: 107-348 -- Loss: 0.19756561517715454
train-epoch-step: 107-349 -- Loss: 0.20475147664546967
train-epoch-step: 107-350 -- Loss: 0.24447694420814514
train-epoch-step: 107-351 -- Loss: 0.1910865604877472
train-epoch-step: 107-352 -- Loss: 0.12498246133327484
train-epoch-step: 107-353 -- Loss: 0.18999537825584412
train-epoch-step: 107-354 -- Loss: 0.27009642124176025
train-epoch-step: 107-355 -- Loss: 0.11464256793260574
train-epoch-step: 107-356 -- Loss: 0.11442817002534866
train-epoch-step: 107-357 -- Loss: 0.18026943504810333
train-epoch-step: 107-358 -- Loss: 0.18250036239624023
train-epoch-step: 107-359 -- Loss: 0.1372784972190857
train-epoch-step: 107-360 -- Loss: 0.11636576056480408
train-epoch-step: 107-361 -- Loss: 0.23298999667167664
train-epoch-step: 107-362 -- Loss: 0.16742879152297974
train-epoch-step: 107-363 -- Loss: 0.11870181560516357
train-epoch-step: 107-364 -- Loss: 0.17291861772537231
train-epoch-step: 107-365 -- Loss: 0.1683344841003418
train-epoch-step: 107-366 -- Loss: 0.19542725384235382
train-epoch-step: 107-367 -- Loss: 0.2269303798675537
train-epoch-step: 107-368 -- Loss: 0.19436874985694885
train-epoch-step: 107-369 -- Loss: 0.2693949341773987
train-epoch-step: 107-370 -- Loss: 0.12340667843818665
train-epoch-step: 107-371 -- Loss: 0.11732527613639832
train-epoch-step: 107-372 -- Loss: 0.15118873119354248
train-epoch-step: 107-373 -- Loss: 0.1911604106426239
train-epoch-step: 107-374 -- Loss: 0.15123996138572693
train-epoch-step: 107-375 -- Loss: 0.2656455636024475
train-epoch-step: 107-376 -- Loss: 0.15287764370441437
train-epoch-step: 107-377 -- Loss: 0.21962374448776245
train-epoch-step: 107-378 -- Loss: 0.19545507431030273
train-epoch-step: 107-379 -- Loss: 0.11627086997032166
train-epoch-step: 107-380 -- Loss: 0.09030289202928543
train-epoch-step: 107-381 -- Loss: 0.24295783042907715
train-epoch-step: 107-382 -- Loss: 0.22371116280555725
train-epoch-step: 107-383 -- Loss: 0.17518576979637146
train-epoch-step: 107-384 -- Loss: 0.20894545316696167
train-epoch-step: 107-385 -- Loss: 0.18033209443092346
train-epoch-step: 107-386 -- Loss: 0.17789454758167267
train-epoch-step: 107-387 -- Loss: 0.19905595481395721
train-epoch-step: 107-388 -- Loss: 0.17787067592144012
train-epoch-step: 107-389 -- Loss: 0.1604917347431183
train-epoch-step: 107-390 -- Loss: 0.14182880520820618
train-epoch-step: 107-391 -- Loss: 0.14521314203739166
train-epoch-step: 107-392 -- Loss: 0.17833296954631805
train-epoch-step: 107-393 -- Loss: 0.15178337693214417
train-epoch-step: 107-394 -- Loss: 0.1887769103050232
train-epoch-step: 107-395 -- Loss: 0.14848896861076355
train-epoch-step: 107-396 -- Loss: 0.12411367893218994
train-epoch-step: 107-397 -- Loss: 0.12216144055128098
train-epoch-step: 107-398 -- Loss: 0.1927725225687027
train-epoch-step: 107-399 -- Loss: 0.17202717065811157
train-epoch-step: 107-400 -- Loss: 0.2660468518733978
train-epoch-step: 107-401 -- Loss: 0.11438378691673279
train-epoch-step: 107-402 -- Loss: 0.250083863735199
train-epoch-step: 107-403 -- Loss: 0.15267419815063477
train-epoch-step: 107-404 -- Loss: 0.13682921230793
train-epoch-step: 107-405 -- Loss: 0.13691802322864532
train-epoch-step: 107-406 -- Loss: 0.15759143233299255
train-epoch-step: 107-407 -- Loss: 0.11216948926448822
train-epoch-step: 107-408 -- Loss: 0.15791620314121246
train-epoch-step: 107-409 -- Loss: 0.16487321257591248
train-epoch-step: 107-410 -- Loss: 0.18326015770435333
train-epoch-step: 107-411 -- Loss: 0.18919400870800018
train-epoch-step: 107-412 -- Loss: 0.12456262111663818
train-epoch-step: 107-413 -- Loss: 0.14037281274795532
train-epoch-step: 107-414 -- Loss: 0.12680508196353912
train-epoch-step: 107-415 -- Loss: 0.13556745648384094
train-epoch-step: 107-416 -- Loss: 0.25474193692207336
train-epoch-step: 107-417 -- Loss: 0.18583784997463226
train-epoch-step: 107-418 -- Loss: 0.22002342343330383
train-epoch-step: 107-419 -- Loss: 0.1675756424665451
train-epoch-step: 107-420 -- Loss: 0.15033158659934998
train-epoch-step: 107-421 -- Loss: 0.1701795756816864
train-epoch-step: 107-422 -- Loss: 0.14349542558193207
train-epoch-step: 107-423 -- Loss: 0.16648317873477936
train-epoch-step: 107-424 -- Loss: 0.13293245434761047
train-epoch-step: 107-425 -- Loss: 0.17624972760677338
train-epoch-step: 107-426 -- Loss: 0.1641598492860794
train-epoch-step: 107-427 -- Loss: 0.11712522804737091
train-epoch-step: 107-428 -- Loss: 0.18680904805660248
train-epoch-step: 107-429 -- Loss: 0.17003846168518066
train-epoch-step: 107-430 -- Loss: 0.13761141896247864
train-epoch-step: 107-431 -- Loss: 0.15578457713127136
train-epoch-step: 107-432 -- Loss: 0.23337173461914062
train-epoch-step: 107-433 -- Loss: 0.13612277805805206
train-epoch-step: 107-434 -- Loss: 0.12487819790840149
train-epoch-step: 107-435 -- Loss: 0.15225958824157715
train-epoch-step: 107-436 -- Loss: 0.14705221354961395
train-epoch-step: 107-437 -- Loss: 0.12510235607624054
train-epoch-step: 107-438 -- Loss: 0.16231459379196167
train-epoch-step: 107-439 -- Loss: 0.2541400194168091
train-epoch-step: 107-440 -- Loss: 0.1301390677690506
train-epoch-step: 107-441 -- Loss: 0.19110935926437378
train-epoch-step: 107-442 -- Loss: 0.1682293564081192
train-epoch-step: 107-443 -- Loss: 0.14972233772277832
train-epoch-step: 107-444 -- Loss: 0.1863459199666977
train-epoch-step: 107-445 -- Loss: 0.1709352284669876
train-epoch-step: 107-446 -- Loss: 0.1469726264476776
train-epoch-step: 107-447 -- Loss: 0.18394842743873596
train-epoch-step: 107-448 -- Loss: 0.21606415510177612
train-epoch-step: 107-449 -- Loss: 0.18296566605567932
train-epoch-step: 107-450 -- Loss: 0.1749064028263092
train-epoch-step: 107-451 -- Loss: 0.14263759553432465
train-epoch-step: 107-452 -- Loss: 0.12884825468063354
train-epoch-step: 107-453 -- Loss: 0.08679307252168655
train-epoch-step: 107-454 -- Loss: 0.22370129823684692
train-epoch-step: 107-455 -- Loss: 0.1195831447839737
train-epoch-step: 107-456 -- Loss: 0.11236116290092468
train-epoch-step: 107-457 -- Loss: 0.20365828275680542
train-epoch-step: 107-458 -- Loss: 0.14200884103775024
train-epoch-step: 107-459 -- Loss: 0.21134385466575623
train-epoch-step: 107-460 -- Loss: 0.11835407465696335
train-epoch-step: 107-461 -- Loss: 0.13042081892490387
train-epoch-step: 107-462 -- Loss: 0.15930166840553284
train-epoch-step: 107-463 -- Loss: 0.12996090948581696
train-epoch-step: 107-464 -- Loss: 0.15467022359371185
train-epoch-step: 107-465 -- Loss: 0.29202398657798767
train-epoch-step: 107-466 -- Loss: 0.2006949484348297
train-epoch-step: 107-467 -- Loss: 0.10809437185525894
train-epoch-step: 107-468 -- Loss: 0.15931974351406097
train-epoch-step: 107-469 -- Loss: 0.19925256073474884
train-epoch-step: 107-470 -- Loss: 0.16739927232265472
train-epoch-step: 107-471 -- Loss: 0.151288703083992
train-epoch-step: 107-472 -- Loss: 0.14971566200256348
train-epoch-step: 107-473 -- Loss: 0.1502261608839035
train-epoch-step: 107-474 -- Loss: 0.1216898262500763
train-epoch-step: 107-475 -- Loss: 0.10622913390398026
train-epoch-step: 107-476 -- Loss: 0.19279059767723083
train-epoch-step: 107-477 -- Loss: 0.19229651987552643
train-epoch-step: 107-478 -- Loss: 0.1857444941997528
train-epoch-step: 107-479 -- Loss: 0.1321285218000412
train-epoch-step: 107-480 -- Loss: 0.1792355179786682
train-epoch-step: 107-481 -- Loss: 0.2762720584869385
train-epoch-step: 107-482 -- Loss: 0.24027034640312195
train-epoch-step: 107-483 -- Loss: 0.176780566573143
train-epoch-step: 107-484 -- Loss: 0.20419597625732422
train-epoch-step: 107-485 -- Loss: 0.1257862001657486
train-epoch-step: 107-486 -- Loss: 0.21937483549118042
train-epoch-step: 107-487 -- Loss: 0.22986796498298645
train-epoch-step: 107-488 -- Loss: 0.17832794785499573
train-epoch-step: 107-489 -- Loss: 0.20959599316120148
train-epoch-step: 107-490 -- Loss: 0.13004139065742493
train-epoch-step: 107-491 -- Loss: 0.13206228613853455
train-epoch-step: 107-492 -- Loss: 0.12460040301084518
train-epoch-step: 107-493 -- Loss: 0.1906711906194687
train-epoch-step: 107-494 -- Loss: 0.19310986995697021
train-epoch-step: 107-495 -- Loss: 0.19922232627868652
train-epoch-step: 107-496 -- Loss: 0.14383889734745026
train-epoch-step: 107-497 -- Loss: 0.17715862393379211
train-epoch-step: 107-498 -- Loss: 0.1410072296857834
train-epoch-step: 107-499 -- Loss: 0.15822142362594604
train-epoch-step: 107-500 -- Loss: 0.1520014852285385
train-epoch-step: 107-501 -- Loss: 0.20528630912303925
train-epoch-step: 107-502 -- Loss: 0.16219337284564972
train-epoch-step: 107-503 -- Loss: 0.21172700822353363
train-epoch-step: 107-504 -- Loss: 0.11406095325946808
train-epoch-step: 107-505 -- Loss: 0.16898731887340546
train-epoch-step: 107-506 -- Loss: 0.1100352555513382
train-epoch-step: 107-507 -- Loss: 0.1785927414894104
train-epoch-step: 107-508 -- Loss: 0.1696394383907318
train-epoch-step: 107-509 -- Loss: 0.16666795313358307
train-epoch-step: 107-510 -- Loss: 0.12238804996013641
train-epoch-step: 107-511 -- Loss: 0.20734713971614838
train-epoch-step: 107-512 -- Loss: 0.172639399766922
train-epoch-step: 107-513 -- Loss: 0.1798911988735199
train-epoch-step: 107-514 -- Loss: 0.1495024710893631
train-epoch-step: 107-515 -- Loss: 0.1592320203781128
train-epoch-step: 107-516 -- Loss: 0.17472508549690247
train-epoch-step: 107-517 -- Loss: 0.1660321205854416
train-epoch-step: 107-518 -- Loss: 0.13574428856372833
train-epoch-step: 107-519 -- Loss: 0.12992216646671295
train-epoch-step: 107-520 -- Loss: 0.1805098056793213
train-epoch-step: 107-521 -- Loss: 0.22724449634552002
train-epoch-step: 107-522 -- Loss: 0.16768509149551392
train-epoch-step: 107-523 -- Loss: 0.15521888434886932
train-epoch-step: 107-524 -- Loss: 0.15907007455825806
train-epoch-step: 107-525 -- Loss: 0.18564191460609436
train-epoch-step: 107-526 -- Loss: 0.12840935587882996
train-epoch-step: 107-527 -- Loss: 0.14534138143062592
train-epoch-step: 107-528 -- Loss: 0.1485094428062439
train-epoch-step: 107-529 -- Loss: 0.14992336928844452
train-epoch-step: 107-530 -- Loss: 0.16541579365730286
train-epoch-step: 107-531 -- Loss: 0.18613776564598083
train-epoch-step: 107-532 -- Loss: 0.16593272984027863
train-epoch-step: 107-533 -- Loss: 0.16880173981189728
train-epoch-step: 107-534 -- Loss: 0.12374318391084671
train-epoch-step: 107-535 -- Loss: 0.2580251693725586
train-epoch-step: 107-536 -- Loss: 0.15172825753688812
train-epoch-step: 107-537 -- Loss: 0.13839705288410187
train-epoch-step: 107-538 -- Loss: 0.09937461465597153
train-epoch-step: 107-539 -- Loss: 0.17526283860206604
train-epoch-step: 107-540 -- Loss: 0.1398499757051468
train-epoch-step: 107-541 -- Loss: 0.20500382781028748
train-epoch-step: 107-542 -- Loss: 0.2106875330209732
train-epoch-step: 107-543 -- Loss: 0.1631995439529419
train-epoch-step: 107-544 -- Loss: 0.22239185869693756
train-epoch-step: 107-545 -- Loss: 0.19579952955245972
train-epoch-step: 107-546 -- Loss: 0.20047006011009216
train-epoch-step: 107-547 -- Loss: 0.17716532945632935
train-epoch-step: 107-548 -- Loss: 0.0861915573477745
train-epoch-step: 107-549 -- Loss: 0.1416776031255722
train-epoch-step: 107-550 -- Loss: 0.1956934779882431
train-epoch-step: 107-551 -- Loss: 0.1465405970811844
train-epoch-step: 107-552 -- Loss: 0.11927475780248642
train-epoch-step: 107-553 -- Loss: 0.1782442182302475
train-epoch-step: 107-554 -- Loss: 0.18079696595668793
train-epoch-step: 107-555 -- Loss: 0.20607294142246246
train-epoch-step: 107-556 -- Loss: 0.14212052524089813
train-epoch-step: 107-557 -- Loss: 0.2312217652797699
train-epoch-step: 107-558 -- Loss: 0.21850129961967468
train-epoch-step: 107-559 -- Loss: 0.1309453248977661
train-epoch-step: 107-560 -- Loss: 0.20331911742687225
train-epoch-step: 107-561 -- Loss: 0.1829444169998169
train-epoch-step: 107-562 -- Loss: 0.15518654882907867
train-epoch-step: 107-563 -- Loss: 0.1748170554637909
train-epoch-step: 107-564 -- Loss: 0.09817932546138763
train-epoch-step: 107-565 -- Loss: 0.17866818606853485
train-epoch-step: 107-566 -- Loss: 0.14887899160385132
train-epoch-step: 107-567 -- Loss: 0.20711132884025574
train-epoch-step: 107-568 -- Loss: 0.15607257187366486
train-epoch-step: 107-569 -- Loss: 0.24024508893489838
train-epoch-step: 107-570 -- Loss: 0.1593373715877533
train-epoch-step: 107-571 -- Loss: 0.209011971950531
train-epoch-step: 107-572 -- Loss: 0.23528334498405457
train-epoch-step: 107-573 -- Loss: 0.18995167315006256
train-epoch-step: 107-574 -- Loss: 0.25333407521247864
train-epoch-step: 107-575 -- Loss: 0.3374579846858978
train-epoch-step: 107-576 -- Loss: 0.13804510235786438
train-epoch-step: 107-577 -- Loss: 0.16072498261928558
train-epoch-step: 107-578 -- Loss: 0.2151576727628708
train-epoch-step: 107-579 -- Loss: 0.1744229942560196
train-epoch-step: 107-580 -- Loss: 0.17325414717197418
train-epoch-step: 107-581 -- Loss: 0.13469785451889038
train-epoch-step: 107-582 -- Loss: 0.19993002712726593
train-epoch-step: 107-583 -- Loss: 0.20845547318458557
train-epoch-step: 107-584 -- Loss: 0.15750327706336975
train-epoch-step: 107-585 -- Loss: 0.1914643496274948
train-epoch-step: 107-586 -- Loss: 0.2517980933189392
train-epoch-step: 107-587 -- Loss: 0.15527315437793732
train-epoch-step: 107-588 -- Loss: 0.126586452126503
val-epoch-step: 107-589 -- Loss: 0.20862966775894165
val-epoch-step: 107-590 -- Loss: 0.1576509177684784
val-epoch-step: 107-591 -- Loss: 0.234160378575325
val-epoch-step: 107-592 -- Loss: 0.17380325496196747
val-epoch-step: 107-593 -- Loss: 0.1677861213684082
val-epoch-step: 107-594 -- Loss: 0.2961112856864929
val-epoch-step: 107-595 -- Loss: 0.1759849637746811
val-epoch-step: 107-596 -- Loss: 0.18832498788833618
val-epoch-step: 107-597 -- Loss: 0.16955560445785522
val-epoch-step: 107-598 -- Loss: 0.15172919631004333
val-epoch-step: 107-599 -- Loss: 0.18231236934661865
val-epoch-step: 107-600 -- Loss: 0.16894716024398804
val-epoch-step: 107-601 -- Loss: 0.15807461738586426
val-epoch-step: 107-602 -- Loss: 0.16977360844612122
val-epoch-step: 107-603 -- Loss: 0.22207286953926086
val-epoch-step: 107-604 -- Loss: 0.14259940385818481
val-epoch-step: 107-605 -- Loss: 0.14535124599933624
val-epoch-step: 107-606 -- Loss: 0.33389967679977417
val-epoch-step: 107-607 -- Loss: 0.12814602255821228
val-epoch-step: 107-608 -- Loss: 0.24854962527751923
val-epoch-step: 107-609 -- Loss: 0.17761105298995972
val-epoch-step: 107-610 -- Loss: 0.1742420643568039
val-epoch-step: 107-611 -- Loss: 0.1878298819065094
val-epoch-step: 107-612 -- Loss: 0.34693416953086853
val-epoch-step: 107-613 -- Loss: 0.1803811490535736
val-epoch-step: 107-614 -- Loss: 0.16950882971286774
val-epoch-step: 107-615 -- Loss: 0.16891740262508392
val-epoch-step: 107-616 -- Loss: 0.1626870334148407
val-epoch-step: 107-617 -- Loss: 0.2049819827079773
val-epoch-step: 107-618 -- Loss: 0.1741042584180832
val-epoch-step: 107-619 -- Loss: 0.2084074318408966
val-epoch-step: 107-620 -- Loss: 0.13902594149112701
val-epoch-step: 107-621 -- Loss: 0.1267739087343216
val-epoch-step: 107-622 -- Loss: 0.14329518377780914
val-epoch-step: 107-623 -- Loss: 0.15274053812026978
val-epoch-step: 107-624 -- Loss: 0.13653093576431274
val-epoch-step: 107-625 -- Loss: 0.15448997914791107
val-epoch-step: 107-626 -- Loss: 0.1444455236196518
val-epoch-step: 107-627 -- Loss: 0.21145755052566528
val-epoch-step: 107-628 -- Loss: 0.3473561406135559
val-epoch-step: 107-629 -- Loss: 0.1967160850763321
val-epoch-step: 107-630 -- Loss: 0.34548133611679077
val-epoch-step: 107-631 -- Loss: 0.15529298782348633
val-epoch-step: 107-632 -- Loss: 0.22247622907161713
val-epoch-step: 107-633 -- Loss: 0.15482699871063232
val-epoch-step: 107-634 -- Loss: 0.15364816784858704
val-epoch-step: 107-635 -- Loss: 0.11423778533935547
val-epoch-step: 107-636 -- Loss: 0.1608818769454956
val-epoch-step: 107-637 -- Loss: 0.17788740992546082
val-epoch-step: 107-638 -- Loss: 0.14507989585399628
val-epoch-step: 107-639 -- Loss: 0.29003453254699707
val-epoch-step: 107-640 -- Loss: 0.24967029690742493
val-epoch-step: 107-641 -- Loss: 0.12572284042835236
val-epoch-step: 107-642 -- Loss: 0.17611326277256012
val-epoch-step: 107-643 -- Loss: 0.20359283685684204
val-epoch-step: 107-644 -- Loss: 0.1570182889699936
val-epoch-step: 107-645 -- Loss: 0.21474695205688477
val-epoch-step: 107-646 -- Loss: 0.13570168614387512
val-epoch-step: 107-647 -- Loss: 0.12362442910671234
val-epoch-step: 107-648 -- Loss: 0.15249788761138916
val-epoch-step: 107-649 -- Loss: 0.21316681802272797
val-epoch-step: 107-650 -- Loss: 0.24616672098636627
val-epoch-step: 107-651 -- Loss: 0.14460115134716034
val-epoch-step: 107-652 -- Loss: 0.1521521359682083
val-epoch-step: 107-653 -- Loss: 0.22340121865272522
val-epoch-step: 107-654 -- Loss: 0.1093035489320755
Epoch: 107 -- Train Loss: tensor(0.1388, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1419, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 108-0 -- Loss: 0.2188701033592224
train-epoch-step: 108-1 -- Loss: 0.1378713995218277
train-epoch-step: 108-2 -- Loss: 0.19086353480815887
train-epoch-step: 108-3 -- Loss: 0.1418784260749817
train-epoch-step: 108-4 -- Loss: 0.15291030704975128
train-epoch-step: 108-5 -- Loss: 0.2047838270664215
train-epoch-step: 108-6 -- Loss: 0.21121260523796082
train-epoch-step: 108-7 -- Loss: 0.16505488753318787
train-epoch-step: 108-8 -- Loss: 0.1731143593788147
train-epoch-step: 108-9 -- Loss: 0.23318010568618774
train-epoch-step: 108-10 -- Loss: 0.1850004345178604
train-epoch-step: 108-11 -- Loss: 0.1698586642742157
train-epoch-step: 108-12 -- Loss: 0.14402717351913452
train-epoch-step: 108-13 -- Loss: 0.17020751535892487
train-epoch-step: 108-14 -- Loss: 0.1586942970752716
train-epoch-step: 108-15 -- Loss: 0.1564003974199295
train-epoch-step: 108-16 -- Loss: 0.1622350662946701
train-epoch-step: 108-17 -- Loss: 0.2157568335533142
train-epoch-step: 108-18 -- Loss: 0.18444335460662842
train-epoch-step: 108-19 -- Loss: 0.13136354088783264
train-epoch-step: 108-20 -- Loss: 0.21365214884281158
train-epoch-step: 108-21 -- Loss: 0.24215684831142426
train-epoch-step: 108-22 -- Loss: 0.1364130824804306
train-epoch-step: 108-23 -- Loss: 0.1372363120317459
train-epoch-step: 108-24 -- Loss: 0.12021972984075546
train-epoch-step: 108-25 -- Loss: 0.21029867231845856
train-epoch-step: 108-26 -- Loss: 0.18583667278289795
train-epoch-step: 108-27 -- Loss: 0.21772491931915283
train-epoch-step: 108-28 -- Loss: 0.11942628771066666
train-epoch-step: 108-29 -- Loss: 0.23743608593940735
train-epoch-step: 108-30 -- Loss: 0.10660760849714279
train-epoch-step: 108-31 -- Loss: 0.13282404839992523
train-epoch-step: 108-32 -- Loss: 0.1650688499212265
train-epoch-step: 108-33 -- Loss: 0.267795205116272
train-epoch-step: 108-34 -- Loss: 0.16221734881401062
train-epoch-step: 108-35 -- Loss: 0.23229122161865234
train-epoch-step: 108-36 -- Loss: 0.13788075745105743
train-epoch-step: 108-37 -- Loss: 0.13157977163791656
train-epoch-step: 108-38 -- Loss: 0.1635807901620865
train-epoch-step: 108-39 -- Loss: 0.21932180225849152
train-epoch-step: 108-40 -- Loss: 0.1832909882068634
train-epoch-step: 108-41 -- Loss: 0.21236668527126312
train-epoch-step: 108-42 -- Loss: 0.1401338279247284
train-epoch-step: 108-43 -- Loss: 0.25264060497283936
train-epoch-step: 108-44 -- Loss: 0.12245024740695953
train-epoch-step: 108-45 -- Loss: 0.10818315297365189
train-epoch-step: 108-46 -- Loss: 0.16720716655254364
train-epoch-step: 108-47 -- Loss: 0.1899760216474533
train-epoch-step: 108-48 -- Loss: 0.15021266043186188
train-epoch-step: 108-49 -- Loss: 0.21839073300361633
train-epoch-step: 108-50 -- Loss: 0.10562440752983093
train-epoch-step: 108-51 -- Loss: 0.17542828619480133
train-epoch-step: 108-52 -- Loss: 0.1515192836523056
train-epoch-step: 108-53 -- Loss: 0.20145149528980255
train-epoch-step: 108-54 -- Loss: 0.2840983271598816
train-epoch-step: 108-55 -- Loss: 0.1650618016719818
train-epoch-step: 108-56 -- Loss: 0.1722206175327301
train-epoch-step: 108-57 -- Loss: 0.2261219024658203
train-epoch-step: 108-58 -- Loss: 0.2775590419769287
train-epoch-step: 108-59 -- Loss: 0.23109780251979828
train-epoch-step: 108-60 -- Loss: 0.12394825369119644
train-epoch-step: 108-61 -- Loss: 0.19835788011550903
train-epoch-step: 108-62 -- Loss: 0.17665371298789978
train-epoch-step: 108-63 -- Loss: 0.12905605137348175
train-epoch-step: 108-64 -- Loss: 0.14068418741226196
train-epoch-step: 108-65 -- Loss: 0.17328156530857086
train-epoch-step: 108-66 -- Loss: 0.10483581572771072
train-epoch-step: 108-67 -- Loss: 0.12624160945415497
train-epoch-step: 108-68 -- Loss: 0.2096133828163147
train-epoch-step: 108-69 -- Loss: 0.11767665296792984
train-epoch-step: 108-70 -- Loss: 0.2196493148803711
train-epoch-step: 108-71 -- Loss: 0.2504560947418213
train-epoch-step: 108-72 -- Loss: 0.1662967950105667
train-epoch-step: 108-73 -- Loss: 0.1986539214849472
train-epoch-step: 108-74 -- Loss: 0.0905555784702301
train-epoch-step: 108-75 -- Loss: 0.12121471762657166
train-epoch-step: 108-76 -- Loss: 0.14017629623413086
train-epoch-step: 108-77 -- Loss: 0.2231963872909546
train-epoch-step: 108-78 -- Loss: 0.24954406917095184
train-epoch-step: 108-79 -- Loss: 0.18453682959079742
train-epoch-step: 108-80 -- Loss: 0.24600502848625183
train-epoch-step: 108-81 -- Loss: 0.11871464550495148
train-epoch-step: 108-82 -- Loss: 0.2444518506526947
train-epoch-step: 108-83 -- Loss: 0.16944622993469238
train-epoch-step: 108-84 -- Loss: 0.17911481857299805
train-epoch-step: 108-85 -- Loss: 0.16850125789642334
train-epoch-step: 108-86 -- Loss: 0.11602944135665894
train-epoch-step: 108-87 -- Loss: 0.20682236552238464
train-epoch-step: 108-88 -- Loss: 0.1360892355442047
train-epoch-step: 108-89 -- Loss: 0.1810651421546936
train-epoch-step: 108-90 -- Loss: 0.18378295004367828
train-epoch-step: 108-91 -- Loss: 0.2316601574420929
train-epoch-step: 108-92 -- Loss: 0.14746643602848053
train-epoch-step: 108-93 -- Loss: 0.16933636367321014
train-epoch-step: 108-94 -- Loss: 0.2213175892829895
train-epoch-step: 108-95 -- Loss: 0.1825706660747528
train-epoch-step: 108-96 -- Loss: 0.2073894739151001
train-epoch-step: 108-97 -- Loss: 0.16951662302017212
train-epoch-step: 108-98 -- Loss: 0.1499180942773819
train-epoch-step: 108-99 -- Loss: 0.1807844191789627
train-epoch-step: 108-100 -- Loss: 0.18480154871940613
train-epoch-step: 108-101 -- Loss: 0.25984013080596924
train-epoch-step: 108-102 -- Loss: 0.22034206986427307
train-epoch-step: 108-103 -- Loss: 0.17612920701503754
train-epoch-step: 108-104 -- Loss: 0.14191538095474243
train-epoch-step: 108-105 -- Loss: 0.2560701370239258
train-epoch-step: 108-106 -- Loss: 0.17073620855808258
train-epoch-step: 108-107 -- Loss: 0.18769915401935577
train-epoch-step: 108-108 -- Loss: 0.1820351779460907
train-epoch-step: 108-109 -- Loss: 0.13772329688072205
train-epoch-step: 108-110 -- Loss: 0.1764581799507141
train-epoch-step: 108-111 -- Loss: 0.17901797592639923
train-epoch-step: 108-112 -- Loss: 0.16576707363128662
train-epoch-step: 108-113 -- Loss: 0.15824052691459656
train-epoch-step: 108-114 -- Loss: 0.19218674302101135
train-epoch-step: 108-115 -- Loss: 0.15288285911083221
train-epoch-step: 108-116 -- Loss: 0.1328117549419403
train-epoch-step: 108-117 -- Loss: 0.12269753962755203
train-epoch-step: 108-118 -- Loss: 0.18344062566757202
train-epoch-step: 108-119 -- Loss: 0.14577195048332214
train-epoch-step: 108-120 -- Loss: 0.23992928862571716
train-epoch-step: 108-121 -- Loss: 0.24044488370418549
train-epoch-step: 108-122 -- Loss: 0.21060588955879211
train-epoch-step: 108-123 -- Loss: 0.19162406027317047
train-epoch-step: 108-124 -- Loss: 0.11706506460905075
train-epoch-step: 108-125 -- Loss: 0.14867860078811646
train-epoch-step: 108-126 -- Loss: 0.2161034196615219
train-epoch-step: 108-127 -- Loss: 0.16553980112075806
train-epoch-step: 108-128 -- Loss: 0.16627779603004456
train-epoch-step: 108-129 -- Loss: 0.14018860459327698
train-epoch-step: 108-130 -- Loss: 0.18340419232845306
train-epoch-step: 108-131 -- Loss: 0.13819244503974915
train-epoch-step: 108-132 -- Loss: 0.18372920155525208
train-epoch-step: 108-133 -- Loss: 0.11166682094335556
train-epoch-step: 108-134 -- Loss: 0.18179212510585785
train-epoch-step: 108-135 -- Loss: 0.12637725472450256
train-epoch-step: 108-136 -- Loss: 0.12696729600429535
train-epoch-step: 108-137 -- Loss: 0.2335525006055832
train-epoch-step: 108-138 -- Loss: 0.24709630012512207
train-epoch-step: 108-139 -- Loss: 0.12295803427696228
train-epoch-step: 108-140 -- Loss: 0.2016601264476776
train-epoch-step: 108-141 -- Loss: 0.22100019454956055
train-epoch-step: 108-142 -- Loss: 0.1994035691022873
train-epoch-step: 108-143 -- Loss: 0.17183378338813782
train-epoch-step: 108-144 -- Loss: 0.17743614315986633
train-epoch-step: 108-145 -- Loss: 0.13713721930980682
train-epoch-step: 108-146 -- Loss: 0.16976135969161987
train-epoch-step: 108-147 -- Loss: 0.16407278180122375
train-epoch-step: 108-148 -- Loss: 0.15251608192920685
train-epoch-step: 108-149 -- Loss: 0.11873942613601685
train-epoch-step: 108-150 -- Loss: 0.176358163356781
train-epoch-step: 108-151 -- Loss: 0.18322212994098663
train-epoch-step: 108-152 -- Loss: 0.18235523998737335
train-epoch-step: 108-153 -- Loss: 0.25386419892311096
train-epoch-step: 108-154 -- Loss: 0.12983699142932892
train-epoch-step: 108-155 -- Loss: 0.1346675306558609
train-epoch-step: 108-156 -- Loss: 0.11254800856113434
train-epoch-step: 108-157 -- Loss: 0.16122165322303772
train-epoch-step: 108-158 -- Loss: 0.15903423726558685
train-epoch-step: 108-159 -- Loss: 0.17120321094989777
train-epoch-step: 108-160 -- Loss: 0.21305719017982483
train-epoch-step: 108-161 -- Loss: 0.1945171058177948
train-epoch-step: 108-162 -- Loss: 0.20171326398849487
train-epoch-step: 108-163 -- Loss: 0.18388663232326508
train-epoch-step: 108-164 -- Loss: 0.18911424279212952
train-epoch-step: 108-165 -- Loss: 0.15509764850139618
train-epoch-step: 108-166 -- Loss: 0.11702002584934235
train-epoch-step: 108-167 -- Loss: 0.11764521896839142
train-epoch-step: 108-168 -- Loss: 0.19112804532051086
train-epoch-step: 108-169 -- Loss: 0.13457368314266205
train-epoch-step: 108-170 -- Loss: 0.1916949599981308
train-epoch-step: 108-171 -- Loss: 0.13897770643234253
train-epoch-step: 108-172 -- Loss: 0.2521468997001648
train-epoch-step: 108-173 -- Loss: 0.13104678690433502
train-epoch-step: 108-174 -- Loss: 0.23911051452159882
train-epoch-step: 108-175 -- Loss: 0.18390700221061707
train-epoch-step: 108-176 -- Loss: 0.13296568393707275
train-epoch-step: 108-177 -- Loss: 0.16815185546875
train-epoch-step: 108-178 -- Loss: 0.17260274291038513
train-epoch-step: 108-179 -- Loss: 0.13911280035972595
train-epoch-step: 108-180 -- Loss: 0.14643582701683044
train-epoch-step: 108-181 -- Loss: 0.16491290926933289
train-epoch-step: 108-182 -- Loss: 0.1778588742017746
train-epoch-step: 108-183 -- Loss: 0.2606716752052307
train-epoch-step: 108-184 -- Loss: 0.13165369629859924
train-epoch-step: 108-185 -- Loss: 0.13420194387435913
train-epoch-step: 108-186 -- Loss: 0.17874903976917267
train-epoch-step: 108-187 -- Loss: 0.20006637275218964
train-epoch-step: 108-188 -- Loss: 0.16545365750789642
train-epoch-step: 108-189 -- Loss: 0.10025042295455933
train-epoch-step: 108-190 -- Loss: 0.17469030618667603
train-epoch-step: 108-191 -- Loss: 0.15725700557231903
train-epoch-step: 108-192 -- Loss: 0.22047469019889832
train-epoch-step: 108-193 -- Loss: 0.1982068121433258
train-epoch-step: 108-194 -- Loss: 0.17643797397613525
train-epoch-step: 108-195 -- Loss: 0.160577192902565
train-epoch-step: 108-196 -- Loss: 0.16030511260032654
train-epoch-step: 108-197 -- Loss: 0.12335129082202911
train-epoch-step: 108-198 -- Loss: 0.12280832976102829
train-epoch-step: 108-199 -- Loss: 0.1424056440591812
train-epoch-step: 108-200 -- Loss: 0.12256679683923721
train-epoch-step: 108-201 -- Loss: 0.1805053949356079
train-epoch-step: 108-202 -- Loss: 0.13248173892498016
train-epoch-step: 108-203 -- Loss: 0.1676322966814041
train-epoch-step: 108-204 -- Loss: 0.12869636714458466
train-epoch-step: 108-205 -- Loss: 0.17729614675045013
train-epoch-step: 108-206 -- Loss: 0.19152376055717468
train-epoch-step: 108-207 -- Loss: 0.13219818472862244
train-epoch-step: 108-208 -- Loss: 0.17065966129302979
train-epoch-step: 108-209 -- Loss: 0.14112448692321777
train-epoch-step: 108-210 -- Loss: 0.13183124363422394
train-epoch-step: 108-211 -- Loss: 0.20220258831977844
train-epoch-step: 108-212 -- Loss: 0.18887290358543396
train-epoch-step: 108-213 -- Loss: 0.12493357807397842
train-epoch-step: 108-214 -- Loss: 0.14528802037239075
train-epoch-step: 108-215 -- Loss: 0.12459629774093628
train-epoch-step: 108-216 -- Loss: 0.19443559646606445
train-epoch-step: 108-217 -- Loss: 0.2070111185312271
train-epoch-step: 108-218 -- Loss: 0.13665936887264252
train-epoch-step: 108-219 -- Loss: 0.161970853805542
train-epoch-step: 108-220 -- Loss: 0.12297876924276352
train-epoch-step: 108-221 -- Loss: 0.20417386293411255
train-epoch-step: 108-222 -- Loss: 0.11441733688116074
train-epoch-step: 108-223 -- Loss: 0.1694156378507614
train-epoch-step: 108-224 -- Loss: 0.1845206618309021
train-epoch-step: 108-225 -- Loss: 0.25810205936431885
train-epoch-step: 108-226 -- Loss: 0.20178166031837463
train-epoch-step: 108-227 -- Loss: 0.2129567265510559
train-epoch-step: 108-228 -- Loss: 0.17100530862808228
train-epoch-step: 108-229 -- Loss: 0.16401034593582153
train-epoch-step: 108-230 -- Loss: 0.16244596242904663
train-epoch-step: 108-231 -- Loss: 0.14937356114387512
train-epoch-step: 108-232 -- Loss: 0.1805291622877121
train-epoch-step: 108-233 -- Loss: 0.08193901181221008
train-epoch-step: 108-234 -- Loss: 0.16506148874759674
train-epoch-step: 108-235 -- Loss: 0.1394016146659851
train-epoch-step: 108-236 -- Loss: 0.17308774590492249
train-epoch-step: 108-237 -- Loss: 0.230472594499588
train-epoch-step: 108-238 -- Loss: 0.14887447655200958
train-epoch-step: 108-239 -- Loss: 0.12035378813743591
train-epoch-step: 108-240 -- Loss: 0.2146373689174652
train-epoch-step: 108-241 -- Loss: 0.1503356546163559
train-epoch-step: 108-242 -- Loss: 0.20783743262290955
train-epoch-step: 108-243 -- Loss: 0.2287115901708603
train-epoch-step: 108-244 -- Loss: 0.1999969482421875
train-epoch-step: 108-245 -- Loss: 0.20357689261436462
train-epoch-step: 108-246 -- Loss: 0.20934858918190002
train-epoch-step: 108-247 -- Loss: 0.20359475910663605
train-epoch-step: 108-248 -- Loss: 0.1803385615348816
train-epoch-step: 108-249 -- Loss: 0.13200902938842773
train-epoch-step: 108-250 -- Loss: 0.1885017305612564
train-epoch-step: 108-251 -- Loss: 0.10123427212238312
train-epoch-step: 108-252 -- Loss: 0.18543246388435364
train-epoch-step: 108-253 -- Loss: 0.13082441687583923
train-epoch-step: 108-254 -- Loss: 0.20711615681648254
train-epoch-step: 108-255 -- Loss: 0.13708418607711792
train-epoch-step: 108-256 -- Loss: 0.15447479486465454
train-epoch-step: 108-257 -- Loss: 0.17912566661834717
train-epoch-step: 108-258 -- Loss: 0.13957862555980682
train-epoch-step: 108-259 -- Loss: 0.10935179889202118
train-epoch-step: 108-260 -- Loss: 0.19140075147151947
train-epoch-step: 108-261 -- Loss: 0.16554835438728333
train-epoch-step: 108-262 -- Loss: 0.2730812728404999
train-epoch-step: 108-263 -- Loss: 0.19285504519939423
train-epoch-step: 108-264 -- Loss: 0.17048245668411255
train-epoch-step: 108-265 -- Loss: 0.10240219533443451
train-epoch-step: 108-266 -- Loss: 0.15051037073135376
train-epoch-step: 108-267 -- Loss: 0.12436918914318085
train-epoch-step: 108-268 -- Loss: 0.11255713552236557
train-epoch-step: 108-269 -- Loss: 0.1649562567472458
train-epoch-step: 108-270 -- Loss: 0.1039583683013916
train-epoch-step: 108-271 -- Loss: 0.14025677740573883
train-epoch-step: 108-272 -- Loss: 0.11043943464756012
train-epoch-step: 108-273 -- Loss: 0.1236879825592041
train-epoch-step: 108-274 -- Loss: 0.17615672945976257
train-epoch-step: 108-275 -- Loss: 0.17899297177791595
train-epoch-step: 108-276 -- Loss: 0.1494239866733551
train-epoch-step: 108-277 -- Loss: 0.1468614637851715
train-epoch-step: 108-278 -- Loss: 0.13261111080646515
train-epoch-step: 108-279 -- Loss: 0.13584403693675995
train-epoch-step: 108-280 -- Loss: 0.2068016231060028
train-epoch-step: 108-281 -- Loss: 0.1690545380115509
train-epoch-step: 108-282 -- Loss: 0.13619734346866608
train-epoch-step: 108-283 -- Loss: 0.11266201734542847
train-epoch-step: 108-284 -- Loss: 0.1315733790397644
train-epoch-step: 108-285 -- Loss: 0.18854647874832153
train-epoch-step: 108-286 -- Loss: 0.147883340716362
train-epoch-step: 108-287 -- Loss: 0.19490063190460205
train-epoch-step: 108-288 -- Loss: 0.08949384838342667
train-epoch-step: 108-289 -- Loss: 0.11297698318958282
train-epoch-step: 108-290 -- Loss: 0.17250698804855347
train-epoch-step: 108-291 -- Loss: 0.11378605663776398
train-epoch-step: 108-292 -- Loss: 0.15115691721439362
train-epoch-step: 108-293 -- Loss: 0.1305457353591919
train-epoch-step: 108-294 -- Loss: 0.15276022255420685
train-epoch-step: 108-295 -- Loss: 0.24475577473640442
train-epoch-step: 108-296 -- Loss: 0.14989878237247467
train-epoch-step: 108-297 -- Loss: 0.16346940398216248
train-epoch-step: 108-298 -- Loss: 0.21835742890834808
train-epoch-step: 108-299 -- Loss: 0.13973084092140198
train-epoch-step: 108-300 -- Loss: 0.1542956829071045
train-epoch-step: 108-301 -- Loss: 0.16913743317127228
train-epoch-step: 108-302 -- Loss: 0.20900379121303558
train-epoch-step: 108-303 -- Loss: 0.1958393007516861
train-epoch-step: 108-304 -- Loss: 0.1232849508523941
train-epoch-step: 108-305 -- Loss: 0.13694815337657928
train-epoch-step: 108-306 -- Loss: 0.19957506656646729
train-epoch-step: 108-307 -- Loss: 0.1575993299484253
train-epoch-step: 108-308 -- Loss: 0.20875240862369537
train-epoch-step: 108-309 -- Loss: 0.14712807536125183
train-epoch-step: 108-310 -- Loss: 0.15532232820987701
train-epoch-step: 108-311 -- Loss: 0.15535295009613037
train-epoch-step: 108-312 -- Loss: 0.1946578025817871
train-epoch-step: 108-313 -- Loss: 0.09205152094364166
train-epoch-step: 108-314 -- Loss: 0.18339714407920837
train-epoch-step: 108-315 -- Loss: 0.16620901226997375
train-epoch-step: 108-316 -- Loss: 0.14667576551437378
train-epoch-step: 108-317 -- Loss: 0.13246622681617737
train-epoch-step: 108-318 -- Loss: 0.15097899734973907
train-epoch-step: 108-319 -- Loss: 0.1636543571949005
train-epoch-step: 108-320 -- Loss: 0.11207473278045654
train-epoch-step: 108-321 -- Loss: 0.1276656687259674
train-epoch-step: 108-322 -- Loss: 0.2035503387451172
train-epoch-step: 108-323 -- Loss: 0.15661397576332092
train-epoch-step: 108-324 -- Loss: 0.24419048428535461
train-epoch-step: 108-325 -- Loss: 0.15327630937099457
train-epoch-step: 108-326 -- Loss: 0.16310258209705353
train-epoch-step: 108-327 -- Loss: 0.19742920994758606
train-epoch-step: 108-328 -- Loss: 0.18538188934326172
train-epoch-step: 108-329 -- Loss: 0.32671424746513367
train-epoch-step: 108-330 -- Loss: 0.34648096561431885
train-epoch-step: 108-331 -- Loss: 0.20422078669071198
train-epoch-step: 108-332 -- Loss: 0.09428369253873825
train-epoch-step: 108-333 -- Loss: 0.17658166587352753
train-epoch-step: 108-334 -- Loss: 0.14881522953510284
train-epoch-step: 108-335 -- Loss: 0.16541145741939545
train-epoch-step: 108-336 -- Loss: 0.14136622846126556
train-epoch-step: 108-337 -- Loss: 0.1983591616153717
train-epoch-step: 108-338 -- Loss: 0.15580201148986816
train-epoch-step: 108-339 -- Loss: 0.13835665583610535
train-epoch-step: 108-340 -- Loss: 0.18617984652519226
train-epoch-step: 108-341 -- Loss: 0.13567808270454407
train-epoch-step: 108-342 -- Loss: 0.15483607351779938
train-epoch-step: 108-343 -- Loss: 0.14788374304771423
train-epoch-step: 108-344 -- Loss: 0.16148947179317474
train-epoch-step: 108-345 -- Loss: 0.12214925140142441
train-epoch-step: 108-346 -- Loss: 0.21123909950256348
train-epoch-step: 108-347 -- Loss: 0.14778460562229156
train-epoch-step: 108-348 -- Loss: 0.19982761144638062
train-epoch-step: 108-349 -- Loss: 0.19191616773605347
train-epoch-step: 108-350 -- Loss: 0.2447756826877594
train-epoch-step: 108-351 -- Loss: 0.1833813190460205
train-epoch-step: 108-352 -- Loss: 0.11580027639865875
train-epoch-step: 108-353 -- Loss: 0.1853586733341217
train-epoch-step: 108-354 -- Loss: 0.2665883004665375
train-epoch-step: 108-355 -- Loss: 0.11702074110507965
train-epoch-step: 108-356 -- Loss: 0.11400502175092697
train-epoch-step: 108-357 -- Loss: 0.1804475337266922
train-epoch-step: 108-358 -- Loss: 0.17561458051204681
train-epoch-step: 108-359 -- Loss: 0.13555002212524414
train-epoch-step: 108-360 -- Loss: 0.1187920942902565
train-epoch-step: 108-361 -- Loss: 0.22188538312911987
train-epoch-step: 108-362 -- Loss: 0.1602465808391571
train-epoch-step: 108-363 -- Loss: 0.10333146899938583
train-epoch-step: 108-364 -- Loss: 0.17498354613780975
train-epoch-step: 108-365 -- Loss: 0.17170535027980804
train-epoch-step: 108-366 -- Loss: 0.19067606329917908
train-epoch-step: 108-367 -- Loss: 0.21913060545921326
train-epoch-step: 108-368 -- Loss: 0.20311790704727173
train-epoch-step: 108-369 -- Loss: 0.2739224433898926
train-epoch-step: 108-370 -- Loss: 0.12218475341796875
train-epoch-step: 108-371 -- Loss: 0.11707916855812073
train-epoch-step: 108-372 -- Loss: 0.1425555944442749
train-epoch-step: 108-373 -- Loss: 0.19937178492546082
train-epoch-step: 108-374 -- Loss: 0.14741776883602142
train-epoch-step: 108-375 -- Loss: 0.25692346692085266
train-epoch-step: 108-376 -- Loss: 0.1631447672843933
train-epoch-step: 108-377 -- Loss: 0.2347211241722107
train-epoch-step: 108-378 -- Loss: 0.1924649477005005
train-epoch-step: 108-379 -- Loss: 0.1128002405166626
train-epoch-step: 108-380 -- Loss: 0.08992047607898712
train-epoch-step: 108-381 -- Loss: 0.2397495061159134
train-epoch-step: 108-382 -- Loss: 0.23028317093849182
train-epoch-step: 108-383 -- Loss: 0.17334452271461487
train-epoch-step: 108-384 -- Loss: 0.21186909079551697
train-epoch-step: 108-385 -- Loss: 0.18276959657669067
train-epoch-step: 108-386 -- Loss: 0.17910248041152954
train-epoch-step: 108-387 -- Loss: 0.20091819763183594
train-epoch-step: 108-388 -- Loss: 0.18109771609306335
train-epoch-step: 108-389 -- Loss: 0.16844873130321503
train-epoch-step: 108-390 -- Loss: 0.1483602225780487
train-epoch-step: 108-391 -- Loss: 0.13922405242919922
train-epoch-step: 108-392 -- Loss: 0.17739371955394745
train-epoch-step: 108-393 -- Loss: 0.14823174476623535
train-epoch-step: 108-394 -- Loss: 0.1919100135564804
train-epoch-step: 108-395 -- Loss: 0.1536310911178589
train-epoch-step: 108-396 -- Loss: 0.1204148381948471
train-epoch-step: 108-397 -- Loss: 0.1209975853562355
train-epoch-step: 108-398 -- Loss: 0.19046173989772797
train-epoch-step: 108-399 -- Loss: 0.16837720572948456
train-epoch-step: 108-400 -- Loss: 0.26700663566589355
train-epoch-step: 108-401 -- Loss: 0.11390825361013412
train-epoch-step: 108-402 -- Loss: 0.2489842027425766
train-epoch-step: 108-403 -- Loss: 0.15174609422683716
train-epoch-step: 108-404 -- Loss: 0.13559776544570923
train-epoch-step: 108-405 -- Loss: 0.13897478580474854
train-epoch-step: 108-406 -- Loss: 0.1564786732196808
train-epoch-step: 108-407 -- Loss: 0.10976531356573105
train-epoch-step: 108-408 -- Loss: 0.15752257406711578
train-epoch-step: 108-409 -- Loss: 0.16546157002449036
train-epoch-step: 108-410 -- Loss: 0.1719139963388443
train-epoch-step: 108-411 -- Loss: 0.18962162733078003
train-epoch-step: 108-412 -- Loss: 0.12536531686782837
train-epoch-step: 108-413 -- Loss: 0.13943319022655487
train-epoch-step: 108-414 -- Loss: 0.12692628800868988
train-epoch-step: 108-415 -- Loss: 0.13334831595420837
train-epoch-step: 108-416 -- Loss: 0.2564282715320587
train-epoch-step: 108-417 -- Loss: 0.17965394258499146
train-epoch-step: 108-418 -- Loss: 0.21306012570858002
train-epoch-step: 108-419 -- Loss: 0.1584928333759308
train-epoch-step: 108-420 -- Loss: 0.1483784317970276
train-epoch-step: 108-421 -- Loss: 0.17848268151283264
train-epoch-step: 108-422 -- Loss: 0.14367689192295074
train-epoch-step: 108-423 -- Loss: 0.16224999725818634
train-epoch-step: 108-424 -- Loss: 0.1320667564868927
train-epoch-step: 108-425 -- Loss: 0.1762157380580902
train-epoch-step: 108-426 -- Loss: 0.15943878889083862
train-epoch-step: 108-427 -- Loss: 0.11598888784646988
train-epoch-step: 108-428 -- Loss: 0.1805400252342224
train-epoch-step: 108-429 -- Loss: 0.16964243352413177
train-epoch-step: 108-430 -- Loss: 0.14053045213222504
train-epoch-step: 108-431 -- Loss: 0.1583770513534546
train-epoch-step: 108-432 -- Loss: 0.23536302149295807
train-epoch-step: 108-433 -- Loss: 0.1340007185935974
train-epoch-step: 108-434 -- Loss: 0.12278714776039124
train-epoch-step: 108-435 -- Loss: 0.15072762966156006
train-epoch-step: 108-436 -- Loss: 0.1511840969324112
train-epoch-step: 108-437 -- Loss: 0.13652965426445007
train-epoch-step: 108-438 -- Loss: 0.16616661846637726
train-epoch-step: 108-439 -- Loss: 0.2521047592163086
train-epoch-step: 108-440 -- Loss: 0.1280430257320404
train-epoch-step: 108-441 -- Loss: 0.18446539342403412
train-epoch-step: 108-442 -- Loss: 0.17084170877933502
train-epoch-step: 108-443 -- Loss: 0.14754901826381683
train-epoch-step: 108-444 -- Loss: 0.16990779340267181
train-epoch-step: 108-445 -- Loss: 0.16979050636291504
train-epoch-step: 108-446 -- Loss: 0.14407996833324432
train-epoch-step: 108-447 -- Loss: 0.18398162722587585
train-epoch-step: 108-448 -- Loss: 0.22657611966133118
train-epoch-step: 108-449 -- Loss: 0.18820571899414062
train-epoch-step: 108-450 -- Loss: 0.17500977218151093
train-epoch-step: 108-451 -- Loss: 0.1375640332698822
train-epoch-step: 108-452 -- Loss: 0.1312721222639084
train-epoch-step: 108-453 -- Loss: 0.08693043142557144
train-epoch-step: 108-454 -- Loss: 0.23057794570922852
train-epoch-step: 108-455 -- Loss: 0.11825240403413773
train-epoch-step: 108-456 -- Loss: 0.11319587379693985
train-epoch-step: 108-457 -- Loss: 0.20452459156513214
train-epoch-step: 108-458 -- Loss: 0.14035680890083313
train-epoch-step: 108-459 -- Loss: 0.20546725392341614
train-epoch-step: 108-460 -- Loss: 0.1202266663312912
train-epoch-step: 108-461 -- Loss: 0.1298965960741043
train-epoch-step: 108-462 -- Loss: 0.14529664814472198
train-epoch-step: 108-463 -- Loss: 0.13442733883857727
train-epoch-step: 108-464 -- Loss: 0.15589727461338043
train-epoch-step: 108-465 -- Loss: 0.22646737098693848
train-epoch-step: 108-466 -- Loss: 0.19431182742118835
train-epoch-step: 108-467 -- Loss: 0.10913711786270142
train-epoch-step: 108-468 -- Loss: 0.16102252900600433
train-epoch-step: 108-469 -- Loss: 0.2045890986919403
train-epoch-step: 108-470 -- Loss: 0.16417893767356873
train-epoch-step: 108-471 -- Loss: 0.1543339192867279
train-epoch-step: 108-472 -- Loss: 0.1523492932319641
train-epoch-step: 108-473 -- Loss: 0.15182985365390778
train-epoch-step: 108-474 -- Loss: 0.11644160747528076
train-epoch-step: 108-475 -- Loss: 0.105370432138443
train-epoch-step: 108-476 -- Loss: 0.1918676495552063
train-epoch-step: 108-477 -- Loss: 0.19565638899803162
train-epoch-step: 108-478 -- Loss: 0.1823476254940033
train-epoch-step: 108-479 -- Loss: 0.13280567526817322
train-epoch-step: 108-480 -- Loss: 0.18016397953033447
train-epoch-step: 108-481 -- Loss: 0.283770352602005
train-epoch-step: 108-482 -- Loss: 0.2448062151670456
train-epoch-step: 108-483 -- Loss: 0.1682407259941101
train-epoch-step: 108-484 -- Loss: 0.20963391661643982
train-epoch-step: 108-485 -- Loss: 0.12222452461719513
train-epoch-step: 108-486 -- Loss: 0.2234112173318863
train-epoch-step: 108-487 -- Loss: 0.2245272696018219
train-epoch-step: 108-488 -- Loss: 0.1781613826751709
train-epoch-step: 108-489 -- Loss: 0.21707771718502045
train-epoch-step: 108-490 -- Loss: 0.1324554830789566
train-epoch-step: 108-491 -- Loss: 0.130384162068367
train-epoch-step: 108-492 -- Loss: 0.12211291491985321
train-epoch-step: 108-493 -- Loss: 0.18862828612327576
train-epoch-step: 108-494 -- Loss: 0.19219970703125
train-epoch-step: 108-495 -- Loss: 0.19573965668678284
train-epoch-step: 108-496 -- Loss: 0.14315025508403778
train-epoch-step: 108-497 -- Loss: 0.17312577366828918
train-epoch-step: 108-498 -- Loss: 0.1420033574104309
train-epoch-step: 108-499 -- Loss: 0.15900790691375732
train-epoch-step: 108-500 -- Loss: 0.1488822102546692
train-epoch-step: 108-501 -- Loss: 0.20105688273906708
train-epoch-step: 108-502 -- Loss: 0.14843808114528656
train-epoch-step: 108-503 -- Loss: 0.21016128361225128
train-epoch-step: 108-504 -- Loss: 0.11589740216732025
train-epoch-step: 108-505 -- Loss: 0.1646057814359665
train-epoch-step: 108-506 -- Loss: 0.1094018742442131
train-epoch-step: 108-507 -- Loss: 0.17167191207408905
train-epoch-step: 108-508 -- Loss: 0.16638916730880737
train-epoch-step: 108-509 -- Loss: 0.1654367595911026
train-epoch-step: 108-510 -- Loss: 0.12482907623052597
train-epoch-step: 108-511 -- Loss: 0.21161296963691711
train-epoch-step: 108-512 -- Loss: 0.17449043691158295
train-epoch-step: 108-513 -- Loss: 0.18304280936717987
train-epoch-step: 108-514 -- Loss: 0.1428956687450409
train-epoch-step: 108-515 -- Loss: 0.15007281303405762
train-epoch-step: 108-516 -- Loss: 0.16712543368339539
train-epoch-step: 108-517 -- Loss: 0.1681925356388092
train-epoch-step: 108-518 -- Loss: 0.13413478434085846
train-epoch-step: 108-519 -- Loss: 0.1316075325012207
train-epoch-step: 108-520 -- Loss: 0.1793234944343567
train-epoch-step: 108-521 -- Loss: 0.2222815752029419
train-epoch-step: 108-522 -- Loss: 0.16406556963920593
train-epoch-step: 108-523 -- Loss: 0.151889368891716
train-epoch-step: 108-524 -- Loss: 0.1601376235485077
train-epoch-step: 108-525 -- Loss: 0.18303725123405457
train-epoch-step: 108-526 -- Loss: 0.12448084354400635
train-epoch-step: 108-527 -- Loss: 0.14289213716983795
train-epoch-step: 108-528 -- Loss: 0.1478310376405716
train-epoch-step: 108-529 -- Loss: 0.1441638171672821
train-epoch-step: 108-530 -- Loss: 0.16127409040927887
train-epoch-step: 108-531 -- Loss: 0.18679574131965637
train-epoch-step: 108-532 -- Loss: 0.15997467935085297
train-epoch-step: 108-533 -- Loss: 0.17006973922252655
train-epoch-step: 108-534 -- Loss: 0.1228063553571701
train-epoch-step: 108-535 -- Loss: 0.2443006932735443
train-epoch-step: 108-536 -- Loss: 0.14692719280719757
train-epoch-step: 108-537 -- Loss: 0.1640474796295166
train-epoch-step: 108-538 -- Loss: 0.10289996862411499
train-epoch-step: 108-539 -- Loss: 0.17311370372772217
train-epoch-step: 108-540 -- Loss: 0.1316864788532257
train-epoch-step: 108-541 -- Loss: 0.1997799128293991
train-epoch-step: 108-542 -- Loss: 0.20898526906967163
train-epoch-step: 108-543 -- Loss: 0.15954849123954773
train-epoch-step: 108-544 -- Loss: 0.22968299686908722
train-epoch-step: 108-545 -- Loss: 0.18628734350204468
train-epoch-step: 108-546 -- Loss: 0.1965852677822113
train-epoch-step: 108-547 -- Loss: 0.17956513166427612
train-epoch-step: 108-548 -- Loss: 0.08642223477363586
train-epoch-step: 108-549 -- Loss: 0.14064331352710724
train-epoch-step: 108-550 -- Loss: 0.19056040048599243
train-epoch-step: 108-551 -- Loss: 0.1432989537715912
train-epoch-step: 108-552 -- Loss: 0.12162834405899048
train-epoch-step: 108-553 -- Loss: 0.1806202232837677
train-epoch-step: 108-554 -- Loss: 0.17989711463451385
train-epoch-step: 108-555 -- Loss: 0.19969236850738525
train-epoch-step: 108-556 -- Loss: 0.1379545032978058
train-epoch-step: 108-557 -- Loss: 0.22439879179000854
train-epoch-step: 108-558 -- Loss: 0.2197556048631668
train-epoch-step: 108-559 -- Loss: 0.12973171472549438
train-epoch-step: 108-560 -- Loss: 0.1967886984348297
train-epoch-step: 108-561 -- Loss: 0.17128704488277435
train-epoch-step: 108-562 -- Loss: 0.1522672027349472
train-epoch-step: 108-563 -- Loss: 0.1757020503282547
train-epoch-step: 108-564 -- Loss: 0.09750815480947495
train-epoch-step: 108-565 -- Loss: 0.176837757229805
train-epoch-step: 108-566 -- Loss: 0.14545738697052002
train-epoch-step: 108-567 -- Loss: 0.20400679111480713
train-epoch-step: 108-568 -- Loss: 0.1529127061367035
train-epoch-step: 108-569 -- Loss: 0.235252246260643
train-epoch-step: 108-570 -- Loss: 0.1591632217168808
train-epoch-step: 108-571 -- Loss: 0.20471951365470886
train-epoch-step: 108-572 -- Loss: 0.23012752830982208
train-epoch-step: 108-573 -- Loss: 0.19322222471237183
train-epoch-step: 108-574 -- Loss: 0.2388933002948761
train-epoch-step: 108-575 -- Loss: 0.27933990955352783
train-epoch-step: 108-576 -- Loss: 0.11240507662296295
train-epoch-step: 108-577 -- Loss: 0.1582505851984024
train-epoch-step: 108-578 -- Loss: 0.20606377720832825
train-epoch-step: 108-579 -- Loss: 0.158791646361351
train-epoch-step: 108-580 -- Loss: 0.1670990139245987
train-epoch-step: 108-581 -- Loss: 0.14311029016971588
train-epoch-step: 108-582 -- Loss: 0.19551579654216766
train-epoch-step: 108-583 -- Loss: 0.2108522355556488
train-epoch-step: 108-584 -- Loss: 0.15243762731552124
train-epoch-step: 108-585 -- Loss: 0.1873764544725418
train-epoch-step: 108-586 -- Loss: 0.2420821487903595
train-epoch-step: 108-587 -- Loss: 0.15225060284137726
train-epoch-step: 108-588 -- Loss: 0.1227928102016449
val-epoch-step: 108-589 -- Loss: 0.2050408571958542
val-epoch-step: 108-590 -- Loss: 0.15266184508800507
val-epoch-step: 108-591 -- Loss: 0.24150468409061432
val-epoch-step: 108-592 -- Loss: 0.16518735885620117
val-epoch-step: 108-593 -- Loss: 0.14520324766635895
val-epoch-step: 108-594 -- Loss: 0.3158051073551178
val-epoch-step: 108-595 -- Loss: 0.18062789738178253
val-epoch-step: 108-596 -- Loss: 0.18912650644779205
val-epoch-step: 108-597 -- Loss: 0.1698102504014969
val-epoch-step: 108-598 -- Loss: 0.14153282344341278
val-epoch-step: 108-599 -- Loss: 0.1749197542667389
val-epoch-step: 108-600 -- Loss: 0.16204343736171722
val-epoch-step: 108-601 -- Loss: 0.15495812892913818
val-epoch-step: 108-602 -- Loss: 0.13400083780288696
val-epoch-step: 108-603 -- Loss: 0.1869332194328308
val-epoch-step: 108-604 -- Loss: 0.1400347650051117
val-epoch-step: 108-605 -- Loss: 0.14205576479434967
val-epoch-step: 108-606 -- Loss: 0.25049835443496704
val-epoch-step: 108-607 -- Loss: 0.12131138145923615
val-epoch-step: 108-608 -- Loss: 0.24722321331501007
val-epoch-step: 108-609 -- Loss: 0.17339177429676056
val-epoch-step: 108-610 -- Loss: 0.17486807703971863
val-epoch-step: 108-611 -- Loss: 0.15108129382133484
val-epoch-step: 108-612 -- Loss: 0.4066416621208191
val-epoch-step: 108-613 -- Loss: 0.16757827997207642
val-epoch-step: 108-614 -- Loss: 0.16575706005096436
val-epoch-step: 108-615 -- Loss: 0.16441787779331207
val-epoch-step: 108-616 -- Loss: 0.14772644639015198
val-epoch-step: 108-617 -- Loss: 0.19714000821113586
val-epoch-step: 108-618 -- Loss: 0.23316578567028046
val-epoch-step: 108-619 -- Loss: 0.1997266411781311
val-epoch-step: 108-620 -- Loss: 0.13182011246681213
val-epoch-step: 108-621 -- Loss: 0.11993440240621567
val-epoch-step: 108-622 -- Loss: 0.13739702105522156
val-epoch-step: 108-623 -- Loss: 0.14402243494987488
val-epoch-step: 108-624 -- Loss: 0.13727998733520508
val-epoch-step: 108-625 -- Loss: 0.1549796164035797
val-epoch-step: 108-626 -- Loss: 0.1447131484746933
val-epoch-step: 108-627 -- Loss: 0.17423419654369354
val-epoch-step: 108-628 -- Loss: 0.42258208990097046
val-epoch-step: 108-629 -- Loss: 0.20196671783924103
val-epoch-step: 108-630 -- Loss: 0.3512190878391266
val-epoch-step: 108-631 -- Loss: 0.14664477109909058
val-epoch-step: 108-632 -- Loss: 0.18844862282276154
val-epoch-step: 108-633 -- Loss: 0.15040433406829834
val-epoch-step: 108-634 -- Loss: 0.1573348045349121
val-epoch-step: 108-635 -- Loss: 0.10938102751970291
val-epoch-step: 108-636 -- Loss: 0.16677233576774597
val-epoch-step: 108-637 -- Loss: 0.18510448932647705
val-epoch-step: 108-638 -- Loss: 0.15380272269248962
val-epoch-step: 108-639 -- Loss: 0.2646961212158203
val-epoch-step: 108-640 -- Loss: 0.246206596493721
val-epoch-step: 108-641 -- Loss: 0.1207730770111084
val-epoch-step: 108-642 -- Loss: 0.17563587427139282
val-epoch-step: 108-643 -- Loss: 0.20221588015556335
val-epoch-step: 108-644 -- Loss: 0.15755127370357513
val-epoch-step: 108-645 -- Loss: 0.21305717527866364
val-epoch-step: 108-646 -- Loss: 0.1259012520313263
val-epoch-step: 108-647 -- Loss: 0.12447674572467804
val-epoch-step: 108-648 -- Loss: 0.14912135899066925
val-epoch-step: 108-649 -- Loss: 0.19679352641105652
val-epoch-step: 108-650 -- Loss: 0.24776147305965424
val-epoch-step: 108-651 -- Loss: 0.14427287876605988
val-epoch-step: 108-652 -- Loss: 0.14609143137931824
val-epoch-step: 108-653 -- Loss: 0.20624558627605438
val-epoch-step: 108-654 -- Loss: 0.10843081772327423
Epoch: 108 -- Train Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 109-0 -- Loss: 0.2117554247379303
train-epoch-step: 109-1 -- Loss: 0.13517728447914124
train-epoch-step: 109-2 -- Loss: 0.18994110822677612
train-epoch-step: 109-3 -- Loss: 0.13777564465999603
train-epoch-step: 109-4 -- Loss: 0.14646214246749878
train-epoch-step: 109-5 -- Loss: 0.17063389718532562
train-epoch-step: 109-6 -- Loss: 0.20284497737884521
train-epoch-step: 109-7 -- Loss: 0.16879764199256897
train-epoch-step: 109-8 -- Loss: 0.16999393701553345
train-epoch-step: 109-9 -- Loss: 0.22377526760101318
train-epoch-step: 109-10 -- Loss: 0.1801488995552063
train-epoch-step: 109-11 -- Loss: 0.1677410900592804
train-epoch-step: 109-12 -- Loss: 0.14284178614616394
train-epoch-step: 109-13 -- Loss: 0.17046718299388885
train-epoch-step: 109-14 -- Loss: 0.16077744960784912
train-epoch-step: 109-15 -- Loss: 0.1546785533428192
train-epoch-step: 109-16 -- Loss: 0.1597249060869217
train-epoch-step: 109-17 -- Loss: 0.20877981185913086
train-epoch-step: 109-18 -- Loss: 0.18871617317199707
train-epoch-step: 109-19 -- Loss: 0.12804004549980164
train-epoch-step: 109-20 -- Loss: 0.20303449034690857
train-epoch-step: 109-21 -- Loss: 0.2392016500234604
train-epoch-step: 109-22 -- Loss: 0.13632389903068542
train-epoch-step: 109-23 -- Loss: 0.13580456376075745
train-epoch-step: 109-24 -- Loss: 0.11801058053970337
train-epoch-step: 109-25 -- Loss: 0.20957055687904358
train-epoch-step: 109-26 -- Loss: 0.1818993240594864
train-epoch-step: 109-27 -- Loss: 0.21851015090942383
train-epoch-step: 109-28 -- Loss: 0.11900363117456436
train-epoch-step: 109-29 -- Loss: 0.23293429613113403
train-epoch-step: 109-30 -- Loss: 0.10562379658222198
train-epoch-step: 109-31 -- Loss: 0.12815916538238525
train-epoch-step: 109-32 -- Loss: 0.16666072607040405
train-epoch-step: 109-33 -- Loss: 0.2678894102573395
train-epoch-step: 109-34 -- Loss: 0.16531899571418762
train-epoch-step: 109-35 -- Loss: 0.23574993014335632
train-epoch-step: 109-36 -- Loss: 0.1430051475763321
train-epoch-step: 109-37 -- Loss: 0.13470007479190826
train-epoch-step: 109-38 -- Loss: 0.16391205787658691
train-epoch-step: 109-39 -- Loss: 0.21072207391262054
train-epoch-step: 109-40 -- Loss: 0.1899643987417221
train-epoch-step: 109-41 -- Loss: 0.20724798738956451
train-epoch-step: 109-42 -- Loss: 0.14338715374469757
train-epoch-step: 109-43 -- Loss: 0.24747231602668762
train-epoch-step: 109-44 -- Loss: 0.11898837983608246
train-epoch-step: 109-45 -- Loss: 0.1104377955198288
train-epoch-step: 109-46 -- Loss: 0.16363321244716644
train-epoch-step: 109-47 -- Loss: 0.19342049956321716
train-epoch-step: 109-48 -- Loss: 0.14938996732234955
train-epoch-step: 109-49 -- Loss: 0.2146628051996231
train-epoch-step: 109-50 -- Loss: 0.10539886355400085
train-epoch-step: 109-51 -- Loss: 0.16949181258678436
train-epoch-step: 109-52 -- Loss: 0.1512334644794464
train-epoch-step: 109-53 -- Loss: 0.1968960016965866
train-epoch-step: 109-54 -- Loss: 0.27056241035461426
train-epoch-step: 109-55 -- Loss: 0.1680041253566742
train-epoch-step: 109-56 -- Loss: 0.16796879470348358
train-epoch-step: 109-57 -- Loss: 0.22549009323120117
train-epoch-step: 109-58 -- Loss: 0.27569496631622314
train-epoch-step: 109-59 -- Loss: 0.22502389550209045
train-epoch-step: 109-60 -- Loss: 0.12735562026500702
train-epoch-step: 109-61 -- Loss: 0.2083202600479126
train-epoch-step: 109-62 -- Loss: 0.18007300794124603
train-epoch-step: 109-63 -- Loss: 0.13118699193000793
train-epoch-step: 109-64 -- Loss: 0.14774778485298157
train-epoch-step: 109-65 -- Loss: 0.17140617966651917
train-epoch-step: 109-66 -- Loss: 0.11063544452190399
train-epoch-step: 109-67 -- Loss: 0.12050148844718933
train-epoch-step: 109-68 -- Loss: 0.20461973547935486
train-epoch-step: 109-69 -- Loss: 0.1285979449748993
train-epoch-step: 109-70 -- Loss: 0.21656134724617004
train-epoch-step: 109-71 -- Loss: 0.24965326488018036
train-epoch-step: 109-72 -- Loss: 0.16817402839660645
train-epoch-step: 109-73 -- Loss: 0.2014356404542923
train-epoch-step: 109-74 -- Loss: 0.09172730892896652
train-epoch-step: 109-75 -- Loss: 0.12122510373592377
train-epoch-step: 109-76 -- Loss: 0.13964131474494934
train-epoch-step: 109-77 -- Loss: 0.22032566368579865
train-epoch-step: 109-78 -- Loss: 0.247193843126297
train-epoch-step: 109-79 -- Loss: 0.182411789894104
train-epoch-step: 109-80 -- Loss: 0.2394399344921112
train-epoch-step: 109-81 -- Loss: 0.12960383296012878
train-epoch-step: 109-82 -- Loss: 0.2455964982509613
train-epoch-step: 109-83 -- Loss: 0.16894462704658508
train-epoch-step: 109-84 -- Loss: 0.18180812895298004
train-epoch-step: 109-85 -- Loss: 0.17211925983428955
train-epoch-step: 109-86 -- Loss: 0.11723701655864716
train-epoch-step: 109-87 -- Loss: 0.19849859178066254
train-epoch-step: 109-88 -- Loss: 0.13381820917129517
train-epoch-step: 109-89 -- Loss: 0.17910829186439514
train-epoch-step: 109-90 -- Loss: 0.18462181091308594
train-epoch-step: 109-91 -- Loss: 0.24761199951171875
train-epoch-step: 109-92 -- Loss: 0.15365584194660187
train-epoch-step: 109-93 -- Loss: 0.17086531221866608
train-epoch-step: 109-94 -- Loss: 0.21594566106796265
train-epoch-step: 109-95 -- Loss: 0.18217617273330688
train-epoch-step: 109-96 -- Loss: 0.2095833718776703
train-epoch-step: 109-97 -- Loss: 0.16452698409557343
train-epoch-step: 109-98 -- Loss: 0.1507519781589508
train-epoch-step: 109-99 -- Loss: 0.1787838339805603
train-epoch-step: 109-100 -- Loss: 0.1815728396177292
train-epoch-step: 109-101 -- Loss: 0.2515105903148651
train-epoch-step: 109-102 -- Loss: 0.21107390522956848
train-epoch-step: 109-103 -- Loss: 0.17782104015350342
train-epoch-step: 109-104 -- Loss: 0.1420503705739975
train-epoch-step: 109-105 -- Loss: 0.26231205463409424
train-epoch-step: 109-106 -- Loss: 0.1708555519580841
train-epoch-step: 109-107 -- Loss: 0.1825675219297409
train-epoch-step: 109-108 -- Loss: 0.19419822096824646
train-epoch-step: 109-109 -- Loss: 0.13947832584381104
train-epoch-step: 109-110 -- Loss: 0.17657238245010376
train-epoch-step: 109-111 -- Loss: 0.17259268462657928
train-epoch-step: 109-112 -- Loss: 0.1579654961824417
train-epoch-step: 109-113 -- Loss: 0.15984052419662476
train-epoch-step: 109-114 -- Loss: 0.18675734102725983
train-epoch-step: 109-115 -- Loss: 0.15603841841220856
train-epoch-step: 109-116 -- Loss: 0.13244234025478363
train-epoch-step: 109-117 -- Loss: 0.12784412503242493
train-epoch-step: 109-118 -- Loss: 0.18282611668109894
train-epoch-step: 109-119 -- Loss: 0.14248618483543396
train-epoch-step: 109-120 -- Loss: 0.23629306256771088
train-epoch-step: 109-121 -- Loss: 0.2490052729845047
train-epoch-step: 109-122 -- Loss: 0.2090109884738922
train-epoch-step: 109-123 -- Loss: 0.1900051385164261
train-epoch-step: 109-124 -- Loss: 0.12077979743480682
train-epoch-step: 109-125 -- Loss: 0.1493854820728302
train-epoch-step: 109-126 -- Loss: 0.21810463070869446
train-epoch-step: 109-127 -- Loss: 0.16552993655204773
train-epoch-step: 109-128 -- Loss: 0.1642584204673767
train-epoch-step: 109-129 -- Loss: 0.14218290150165558
train-epoch-step: 109-130 -- Loss: 0.20119024813175201
train-epoch-step: 109-131 -- Loss: 0.13277307152748108
train-epoch-step: 109-132 -- Loss: 0.18288759887218475
train-epoch-step: 109-133 -- Loss: 0.11226684600114822
train-epoch-step: 109-134 -- Loss: 0.18526941537857056
train-epoch-step: 109-135 -- Loss: 0.12866482138633728
train-epoch-step: 109-136 -- Loss: 0.13290318846702576
train-epoch-step: 109-137 -- Loss: 0.23496142029762268
train-epoch-step: 109-138 -- Loss: 0.2454681396484375
train-epoch-step: 109-139 -- Loss: 0.12403850257396698
train-epoch-step: 109-140 -- Loss: 0.20387139916419983
train-epoch-step: 109-141 -- Loss: 0.2250526398420334
train-epoch-step: 109-142 -- Loss: 0.1976391226053238
train-epoch-step: 109-143 -- Loss: 0.18139027059078217
train-epoch-step: 109-144 -- Loss: 0.17468276619911194
train-epoch-step: 109-145 -- Loss: 0.15070980787277222
train-epoch-step: 109-146 -- Loss: 0.17109671235084534
train-epoch-step: 109-147 -- Loss: 0.1672852635383606
train-epoch-step: 109-148 -- Loss: 0.15864121913909912
train-epoch-step: 109-149 -- Loss: 0.1207483783364296
train-epoch-step: 109-150 -- Loss: 0.1772441267967224
train-epoch-step: 109-151 -- Loss: 0.1820131242275238
train-epoch-step: 109-152 -- Loss: 0.23594966530799866
train-epoch-step: 109-153 -- Loss: 0.25816190242767334
train-epoch-step: 109-154 -- Loss: 0.1288764923810959
train-epoch-step: 109-155 -- Loss: 0.1322745829820633
train-epoch-step: 109-156 -- Loss: 0.11496960371732712
train-epoch-step: 109-157 -- Loss: 0.1661095917224884
train-epoch-step: 109-158 -- Loss: 0.16114965081214905
train-epoch-step: 109-159 -- Loss: 0.1851804554462433
train-epoch-step: 109-160 -- Loss: 0.22012200951576233
train-epoch-step: 109-161 -- Loss: 0.20503520965576172
train-epoch-step: 109-162 -- Loss: 0.21489107608795166
train-epoch-step: 109-163 -- Loss: 0.18136203289031982
train-epoch-step: 109-164 -- Loss: 0.19192025065422058
train-epoch-step: 109-165 -- Loss: 0.15634746849536896
train-epoch-step: 109-166 -- Loss: 0.11519883573055267
train-epoch-step: 109-167 -- Loss: 0.1263338029384613
train-epoch-step: 109-168 -- Loss: 0.19650527834892273
train-epoch-step: 109-169 -- Loss: 0.1426217257976532
train-epoch-step: 109-170 -- Loss: 0.1924843192100525
train-epoch-step: 109-171 -- Loss: 0.1418580561876297
train-epoch-step: 109-172 -- Loss: 0.25203365087509155
train-epoch-step: 109-173 -- Loss: 0.13546106219291687
train-epoch-step: 109-174 -- Loss: 0.2389543354511261
train-epoch-step: 109-175 -- Loss: 0.1870570033788681
train-epoch-step: 109-176 -- Loss: 0.14470624923706055
train-epoch-step: 109-177 -- Loss: 0.1709747314453125
train-epoch-step: 109-178 -- Loss: 0.17600291967391968
train-epoch-step: 109-179 -- Loss: 0.1383139193058014
train-epoch-step: 109-180 -- Loss: 0.14569075405597687
train-epoch-step: 109-181 -- Loss: 0.16599318385124207
train-epoch-step: 109-182 -- Loss: 0.18444937467575073
train-epoch-step: 109-183 -- Loss: 0.2685384750366211
train-epoch-step: 109-184 -- Loss: 0.1336749643087387
train-epoch-step: 109-185 -- Loss: 0.13514995574951172
train-epoch-step: 109-186 -- Loss: 0.17852243781089783
train-epoch-step: 109-187 -- Loss: 0.20290182530879974
train-epoch-step: 109-188 -- Loss: 0.16532257199287415
train-epoch-step: 109-189 -- Loss: 0.1018819659948349
train-epoch-step: 109-190 -- Loss: 0.17972859740257263
train-epoch-step: 109-191 -- Loss: 0.16608616709709167
train-epoch-step: 109-192 -- Loss: 0.2220446914434433
train-epoch-step: 109-193 -- Loss: 0.19776651263237
train-epoch-step: 109-194 -- Loss: 0.17506109178066254
train-epoch-step: 109-195 -- Loss: 0.16079990565776825
train-epoch-step: 109-196 -- Loss: 0.16892139613628387
train-epoch-step: 109-197 -- Loss: 0.12164188176393509
train-epoch-step: 109-198 -- Loss: 0.12237656861543655
train-epoch-step: 109-199 -- Loss: 0.14064151048660278
train-epoch-step: 109-200 -- Loss: 0.12390156835317612
train-epoch-step: 109-201 -- Loss: 0.1824282854795456
train-epoch-step: 109-202 -- Loss: 0.13352756202220917
train-epoch-step: 109-203 -- Loss: 0.17363910377025604
train-epoch-step: 109-204 -- Loss: 0.12830056250095367
train-epoch-step: 109-205 -- Loss: 0.17915426194667816
train-epoch-step: 109-206 -- Loss: 0.19638410210609436
train-epoch-step: 109-207 -- Loss: 0.1300453245639801
train-epoch-step: 109-208 -- Loss: 0.17658346891403198
train-epoch-step: 109-209 -- Loss: 0.13906699419021606
train-epoch-step: 109-210 -- Loss: 0.12818880379199982
train-epoch-step: 109-211 -- Loss: 0.20100663602352142
train-epoch-step: 109-212 -- Loss: 0.192572221159935
train-epoch-step: 109-213 -- Loss: 0.1258728951215744
train-epoch-step: 109-214 -- Loss: 0.14348755776882172
train-epoch-step: 109-215 -- Loss: 0.12678608298301697
train-epoch-step: 109-216 -- Loss: 0.1935786008834839
train-epoch-step: 109-217 -- Loss: 0.20306886732578278
train-epoch-step: 109-218 -- Loss: 0.136811301112175
train-epoch-step: 109-219 -- Loss: 0.16302010416984558
train-epoch-step: 109-220 -- Loss: 0.12359090894460678
train-epoch-step: 109-221 -- Loss: 0.20159289240837097
train-epoch-step: 109-222 -- Loss: 0.114100880920887
train-epoch-step: 109-223 -- Loss: 0.16898809373378754
train-epoch-step: 109-224 -- Loss: 0.17948004603385925
train-epoch-step: 109-225 -- Loss: 0.265898734331131
train-epoch-step: 109-226 -- Loss: 0.1989261358976364
train-epoch-step: 109-227 -- Loss: 0.2069329470396042
train-epoch-step: 109-228 -- Loss: 0.17045612633228302
train-epoch-step: 109-229 -- Loss: 0.165568545460701
train-epoch-step: 109-230 -- Loss: 0.1628432273864746
train-epoch-step: 109-231 -- Loss: 0.14785902202129364
train-epoch-step: 109-232 -- Loss: 0.17771349847316742
train-epoch-step: 109-233 -- Loss: 0.08248315006494522
train-epoch-step: 109-234 -- Loss: 0.16690693795681
train-epoch-step: 109-235 -- Loss: 0.13987964391708374
train-epoch-step: 109-236 -- Loss: 0.17797404527664185
train-epoch-step: 109-237 -- Loss: 0.22690828144550323
train-epoch-step: 109-238 -- Loss: 0.15574228763580322
train-epoch-step: 109-239 -- Loss: 0.1219833642244339
train-epoch-step: 109-240 -- Loss: 0.21794220805168152
train-epoch-step: 109-241 -- Loss: 0.15068906545639038
train-epoch-step: 109-242 -- Loss: 0.21526892483234406
train-epoch-step: 109-243 -- Loss: 0.22652199864387512
train-epoch-step: 109-244 -- Loss: 0.20066137611865997
train-epoch-step: 109-245 -- Loss: 0.19707979261875153
train-epoch-step: 109-246 -- Loss: 0.20904287695884705
train-epoch-step: 109-247 -- Loss: 0.2018793225288391
train-epoch-step: 109-248 -- Loss: 0.17969724535942078
train-epoch-step: 109-249 -- Loss: 0.1347162127494812
train-epoch-step: 109-250 -- Loss: 0.19489635527133942
train-epoch-step: 109-251 -- Loss: 0.10534792393445969
train-epoch-step: 109-252 -- Loss: 0.18665722012519836
train-epoch-step: 109-253 -- Loss: 0.13065457344055176
train-epoch-step: 109-254 -- Loss: 0.20688104629516602
train-epoch-step: 109-255 -- Loss: 0.14029332995414734
train-epoch-step: 109-256 -- Loss: 0.13987377285957336
train-epoch-step: 109-257 -- Loss: 0.18169942498207092
train-epoch-step: 109-258 -- Loss: 0.1388821303844452
train-epoch-step: 109-259 -- Loss: 0.10785181820392609
train-epoch-step: 109-260 -- Loss: 0.19788028299808502
train-epoch-step: 109-261 -- Loss: 0.1699790209531784
train-epoch-step: 109-262 -- Loss: 0.2790733575820923
train-epoch-step: 109-263 -- Loss: 0.19342605769634247
train-epoch-step: 109-264 -- Loss: 0.17403817176818848
train-epoch-step: 109-265 -- Loss: 0.1541023552417755
train-epoch-step: 109-266 -- Loss: 0.1628006100654602
train-epoch-step: 109-267 -- Loss: 0.12353390455245972
train-epoch-step: 109-268 -- Loss: 0.11878149211406708
train-epoch-step: 109-269 -- Loss: 0.24323192238807678
train-epoch-step: 109-270 -- Loss: 0.10683959722518921
train-epoch-step: 109-271 -- Loss: 0.14306478202342987
train-epoch-step: 109-272 -- Loss: 0.11388520151376724
train-epoch-step: 109-273 -- Loss: 0.12352069467306137
train-epoch-step: 109-274 -- Loss: 0.1986655592918396
train-epoch-step: 109-275 -- Loss: 0.18969859182834625
train-epoch-step: 109-276 -- Loss: 0.18301409482955933
train-epoch-step: 109-277 -- Loss: 0.1547326296567917
train-epoch-step: 109-278 -- Loss: 0.148121178150177
train-epoch-step: 109-279 -- Loss: 0.13780996203422546
train-epoch-step: 109-280 -- Loss: 0.2179737389087677
train-epoch-step: 109-281 -- Loss: 0.17736634612083435
train-epoch-step: 109-282 -- Loss: 0.15013554692268372
train-epoch-step: 109-283 -- Loss: 0.11600285023450851
train-epoch-step: 109-284 -- Loss: 0.13080236315727234
train-epoch-step: 109-285 -- Loss: 0.1846081018447876
train-epoch-step: 109-286 -- Loss: 0.16001173853874207
train-epoch-step: 109-287 -- Loss: 0.19343136250972748
train-epoch-step: 109-288 -- Loss: 0.09278257191181183
train-epoch-step: 109-289 -- Loss: 0.114967480301857
train-epoch-step: 109-290 -- Loss: 0.184087336063385
train-epoch-step: 109-291 -- Loss: 0.11507879197597504
train-epoch-step: 109-292 -- Loss: 0.156661719083786
train-epoch-step: 109-293 -- Loss: 0.1363694965839386
train-epoch-step: 109-294 -- Loss: 0.15262824296951294
train-epoch-step: 109-295 -- Loss: 0.25377464294433594
train-epoch-step: 109-296 -- Loss: 0.1535291075706482
train-epoch-step: 109-297 -- Loss: 0.1682833880186081
train-epoch-step: 109-298 -- Loss: 0.22673042118549347
train-epoch-step: 109-299 -- Loss: 0.1533004492521286
train-epoch-step: 109-300 -- Loss: 0.1687782108783722
train-epoch-step: 109-301 -- Loss: 0.17543211579322815
train-epoch-step: 109-302 -- Loss: 0.2125614434480667
train-epoch-step: 109-303 -- Loss: 0.1993318647146225
train-epoch-step: 109-304 -- Loss: 0.13035966455936432
train-epoch-step: 109-305 -- Loss: 0.13867828249931335
train-epoch-step: 109-306 -- Loss: 0.22347986698150635
train-epoch-step: 109-307 -- Loss: 0.15945881605148315
train-epoch-step: 109-308 -- Loss: 0.2137359082698822
train-epoch-step: 109-309 -- Loss: 0.1516808569431305
train-epoch-step: 109-310 -- Loss: 0.15253029763698578
train-epoch-step: 109-311 -- Loss: 0.15448346734046936
train-epoch-step: 109-312 -- Loss: 0.19329462945461273
train-epoch-step: 109-313 -- Loss: 0.092379629611969
train-epoch-step: 109-314 -- Loss: 0.1877804696559906
train-epoch-step: 109-315 -- Loss: 0.16287393867969513
train-epoch-step: 109-316 -- Loss: 0.14812517166137695
train-epoch-step: 109-317 -- Loss: 0.13558781147003174
train-epoch-step: 109-318 -- Loss: 0.15762466192245483
train-epoch-step: 109-319 -- Loss: 0.16320830583572388
train-epoch-step: 109-320 -- Loss: 0.11606064438819885
train-epoch-step: 109-321 -- Loss: 0.12852683663368225
train-epoch-step: 109-322 -- Loss: 0.2106902301311493
train-epoch-step: 109-323 -- Loss: 0.16099418699741364
train-epoch-step: 109-324 -- Loss: 0.250336229801178
train-epoch-step: 109-325 -- Loss: 0.15140490233898163
train-epoch-step: 109-326 -- Loss: 0.16878998279571533
train-epoch-step: 109-327 -- Loss: 0.20213478803634644
train-epoch-step: 109-328 -- Loss: 0.18483151495456696
train-epoch-step: 109-329 -- Loss: 0.3378402590751648
train-epoch-step: 109-330 -- Loss: 0.3470386266708374
train-epoch-step: 109-331 -- Loss: 0.20435330271720886
train-epoch-step: 109-332 -- Loss: 0.09451452642679214
train-epoch-step: 109-333 -- Loss: 0.1792038381099701
train-epoch-step: 109-334 -- Loss: 0.15122094750404358
train-epoch-step: 109-335 -- Loss: 0.17247945070266724
train-epoch-step: 109-336 -- Loss: 0.1433478593826294
train-epoch-step: 109-337 -- Loss: 0.19752325117588043
train-epoch-step: 109-338 -- Loss: 0.1555226743221283
train-epoch-step: 109-339 -- Loss: 0.13827551901340485
train-epoch-step: 109-340 -- Loss: 0.1905812919139862
train-epoch-step: 109-341 -- Loss: 0.13548006117343903
train-epoch-step: 109-342 -- Loss: 0.15590707957744598
train-epoch-step: 109-343 -- Loss: 0.14809393882751465
train-epoch-step: 109-344 -- Loss: 0.15922966599464417
train-epoch-step: 109-345 -- Loss: 0.1307751089334488
train-epoch-step: 109-346 -- Loss: 0.2103966325521469
train-epoch-step: 109-347 -- Loss: 0.1472701132297516
train-epoch-step: 109-348 -- Loss: 0.19549793004989624
train-epoch-step: 109-349 -- Loss: 0.19688239693641663
train-epoch-step: 109-350 -- Loss: 0.25582486391067505
train-epoch-step: 109-351 -- Loss: 0.18684889376163483
train-epoch-step: 109-352 -- Loss: 0.12430913001298904
train-epoch-step: 109-353 -- Loss: 0.18511947989463806
train-epoch-step: 109-354 -- Loss: 0.27348554134368896
train-epoch-step: 109-355 -- Loss: 0.11680298298597336
train-epoch-step: 109-356 -- Loss: 0.11574807018041611
train-epoch-step: 109-357 -- Loss: 0.1844293624162674
train-epoch-step: 109-358 -- Loss: 0.17800849676132202
train-epoch-step: 109-359 -- Loss: 0.13711704313755035
train-epoch-step: 109-360 -- Loss: 0.11739686876535416
train-epoch-step: 109-361 -- Loss: 0.22869083285331726
train-epoch-step: 109-362 -- Loss: 0.16567161679267883
train-epoch-step: 109-363 -- Loss: 0.1072799563407898
train-epoch-step: 109-364 -- Loss: 0.17471067607402802
train-epoch-step: 109-365 -- Loss: 0.169520765542984
train-epoch-step: 109-366 -- Loss: 0.1943598836660385
train-epoch-step: 109-367 -- Loss: 0.22113573551177979
train-epoch-step: 109-368 -- Loss: 0.19049417972564697
train-epoch-step: 109-369 -- Loss: 0.27205389738082886
train-epoch-step: 109-370 -- Loss: 0.12015094608068466
train-epoch-step: 109-371 -- Loss: 0.11812923848628998
train-epoch-step: 109-372 -- Loss: 0.1427152156829834
train-epoch-step: 109-373 -- Loss: 0.18065467476844788
train-epoch-step: 109-374 -- Loss: 0.1497090458869934
train-epoch-step: 109-375 -- Loss: 0.25584566593170166
train-epoch-step: 109-376 -- Loss: 0.15062671899795532
train-epoch-step: 109-377 -- Loss: 0.22163498401641846
train-epoch-step: 109-378 -- Loss: 0.19276641309261322
train-epoch-step: 109-379 -- Loss: 0.1125444620847702
train-epoch-step: 109-380 -- Loss: 0.08741716295480728
train-epoch-step: 109-381 -- Loss: 0.23355962336063385
train-epoch-step: 109-382 -- Loss: 0.2221488654613495
train-epoch-step: 109-383 -- Loss: 0.16912315785884857
train-epoch-step: 109-384 -- Loss: 0.20930123329162598
train-epoch-step: 109-385 -- Loss: 0.18067149817943573
train-epoch-step: 109-386 -- Loss: 0.17932705581188202
train-epoch-step: 109-387 -- Loss: 0.19530203938484192
train-epoch-step: 109-388 -- Loss: 0.17494657635688782
train-epoch-step: 109-389 -- Loss: 0.16118760406970978
train-epoch-step: 109-390 -- Loss: 0.14268235862255096
train-epoch-step: 109-391 -- Loss: 0.14340779185295105
train-epoch-step: 109-392 -- Loss: 0.1771378368139267
train-epoch-step: 109-393 -- Loss: 0.1538722813129425
train-epoch-step: 109-394 -- Loss: 0.1859179437160492
train-epoch-step: 109-395 -- Loss: 0.1503288745880127
train-epoch-step: 109-396 -- Loss: 0.12106321007013321
train-epoch-step: 109-397 -- Loss: 0.11918001621961594
train-epoch-step: 109-398 -- Loss: 0.19443269073963165
train-epoch-step: 109-399 -- Loss: 0.16832105815410614
train-epoch-step: 109-400 -- Loss: 0.26673150062561035
train-epoch-step: 109-401 -- Loss: 0.11523688584566116
train-epoch-step: 109-402 -- Loss: 0.24732066690921783
train-epoch-step: 109-403 -- Loss: 0.15306517481803894
train-epoch-step: 109-404 -- Loss: 0.13600754737854004
train-epoch-step: 109-405 -- Loss: 0.1367291510105133
train-epoch-step: 109-406 -- Loss: 0.16205596923828125
train-epoch-step: 109-407 -- Loss: 0.1103937029838562
train-epoch-step: 109-408 -- Loss: 0.15898123383522034
train-epoch-step: 109-409 -- Loss: 0.16307544708251953
train-epoch-step: 109-410 -- Loss: 0.16800419986248016
train-epoch-step: 109-411 -- Loss: 0.20187558233737946
train-epoch-step: 109-412 -- Loss: 0.12529920041561127
train-epoch-step: 109-413 -- Loss: 0.14171791076660156
train-epoch-step: 109-414 -- Loss: 0.12511056661605835
train-epoch-step: 109-415 -- Loss: 0.1298009753227234
train-epoch-step: 109-416 -- Loss: 0.25462770462036133
train-epoch-step: 109-417 -- Loss: 0.18064597249031067
train-epoch-step: 109-418 -- Loss: 0.22354422509670258
train-epoch-step: 109-419 -- Loss: 0.1623803824186325
train-epoch-step: 109-420 -- Loss: 0.14516498148441315
train-epoch-step: 109-421 -- Loss: 0.17100965976715088
train-epoch-step: 109-422 -- Loss: 0.14120498299598694
train-epoch-step: 109-423 -- Loss: 0.16412577033042908
train-epoch-step: 109-424 -- Loss: 0.13413763046264648
train-epoch-step: 109-425 -- Loss: 0.17570531368255615
train-epoch-step: 109-426 -- Loss: 0.15985025465488434
train-epoch-step: 109-427 -- Loss: 0.11303311586380005
train-epoch-step: 109-428 -- Loss: 0.18266132473945618
train-epoch-step: 109-429 -- Loss: 0.16832517087459564
train-epoch-step: 109-430 -- Loss: 0.13869556784629822
train-epoch-step: 109-431 -- Loss: 0.1571730226278305
train-epoch-step: 109-432 -- Loss: 0.2299063801765442
train-epoch-step: 109-433 -- Loss: 0.1346423327922821
train-epoch-step: 109-434 -- Loss: 0.12157049775123596
train-epoch-step: 109-435 -- Loss: 0.15091368556022644
train-epoch-step: 109-436 -- Loss: 0.1510758101940155
train-epoch-step: 109-437 -- Loss: 0.12576554715633392
train-epoch-step: 109-438 -- Loss: 0.15930363535881042
train-epoch-step: 109-439 -- Loss: 0.2505079209804535
train-epoch-step: 109-440 -- Loss: 0.12488444894552231
train-epoch-step: 109-441 -- Loss: 0.18944324553012848
train-epoch-step: 109-442 -- Loss: 0.16894710063934326
train-epoch-step: 109-443 -- Loss: 0.15411445498466492
train-epoch-step: 109-444 -- Loss: 0.1671222448348999
train-epoch-step: 109-445 -- Loss: 0.17170822620391846
train-epoch-step: 109-446 -- Loss: 0.14333045482635498
train-epoch-step: 109-447 -- Loss: 0.1834249347448349
train-epoch-step: 109-448 -- Loss: 0.21617425978183746
train-epoch-step: 109-449 -- Loss: 0.1816481351852417
train-epoch-step: 109-450 -- Loss: 0.17251509428024292
train-epoch-step: 109-451 -- Loss: 0.13488243520259857
train-epoch-step: 109-452 -- Loss: 0.1349426656961441
train-epoch-step: 109-453 -- Loss: 0.08753744512796402
train-epoch-step: 109-454 -- Loss: 0.21916010975837708
train-epoch-step: 109-455 -- Loss: 0.1178598552942276
train-epoch-step: 109-456 -- Loss: 0.1116495430469513
train-epoch-step: 109-457 -- Loss: 0.20326948165893555
train-epoch-step: 109-458 -- Loss: 0.14483383297920227
train-epoch-step: 109-459 -- Loss: 0.20445722341537476
train-epoch-step: 109-460 -- Loss: 0.12021751701831818
train-epoch-step: 109-461 -- Loss: 0.13049191236495972
train-epoch-step: 109-462 -- Loss: 0.14745637774467468
train-epoch-step: 109-463 -- Loss: 0.13004417717456818
train-epoch-step: 109-464 -- Loss: 0.15015709400177002
train-epoch-step: 109-465 -- Loss: 0.22387300431728363
train-epoch-step: 109-466 -- Loss: 0.2021390199661255
train-epoch-step: 109-467 -- Loss: 0.10819637775421143
train-epoch-step: 109-468 -- Loss: 0.1591172218322754
train-epoch-step: 109-469 -- Loss: 0.19378265738487244
train-epoch-step: 109-470 -- Loss: 0.1640760898590088
train-epoch-step: 109-471 -- Loss: 0.15093156695365906
train-epoch-step: 109-472 -- Loss: 0.149947389960289
train-epoch-step: 109-473 -- Loss: 0.1503889113664627
train-epoch-step: 109-474 -- Loss: 0.11795039474964142
train-epoch-step: 109-475 -- Loss: 0.1046881228685379
train-epoch-step: 109-476 -- Loss: 0.19312894344329834
train-epoch-step: 109-477 -- Loss: 0.19104677438735962
train-epoch-step: 109-478 -- Loss: 0.17646919190883636
train-epoch-step: 109-479 -- Loss: 0.1290505826473236
train-epoch-step: 109-480 -- Loss: 0.1843610554933548
train-epoch-step: 109-481 -- Loss: 0.26872527599334717
train-epoch-step: 109-482 -- Loss: 0.24535927176475525
train-epoch-step: 109-483 -- Loss: 0.16960646212100983
train-epoch-step: 109-484 -- Loss: 0.20469588041305542
train-epoch-step: 109-485 -- Loss: 0.12081686407327652
train-epoch-step: 109-486 -- Loss: 0.21518129110336304
train-epoch-step: 109-487 -- Loss: 0.22278648614883423
train-epoch-step: 109-488 -- Loss: 0.17568370699882507
train-epoch-step: 109-489 -- Loss: 0.21397536993026733
train-epoch-step: 109-490 -- Loss: 0.1275266855955124
train-epoch-step: 109-491 -- Loss: 0.1313478946685791
train-epoch-step: 109-492 -- Loss: 0.12751562893390656
train-epoch-step: 109-493 -- Loss: 0.18517610430717468
train-epoch-step: 109-494 -- Loss: 0.2035510241985321
train-epoch-step: 109-495 -- Loss: 0.1885858178138733
train-epoch-step: 109-496 -- Loss: 0.1440049707889557
train-epoch-step: 109-497 -- Loss: 0.1749531328678131
train-epoch-step: 109-498 -- Loss: 0.14366181194782257
train-epoch-step: 109-499 -- Loss: 0.15879234671592712
train-epoch-step: 109-500 -- Loss: 0.1482730656862259
train-epoch-step: 109-501 -- Loss: 0.20353233814239502
train-epoch-step: 109-502 -- Loss: 0.15193288028240204
train-epoch-step: 109-503 -- Loss: 0.2058137208223343
train-epoch-step: 109-504 -- Loss: 0.11538176983594894
train-epoch-step: 109-505 -- Loss: 0.16868340969085693
train-epoch-step: 109-506 -- Loss: 0.11030261218547821
train-epoch-step: 109-507 -- Loss: 0.1742752194404602
train-epoch-step: 109-508 -- Loss: 0.1740739643573761
train-epoch-step: 109-509 -- Loss: 0.16117559373378754
train-epoch-step: 109-510 -- Loss: 0.12400762736797333
train-epoch-step: 109-511 -- Loss: 0.20842371881008148
train-epoch-step: 109-512 -- Loss: 0.17269286513328552
train-epoch-step: 109-513 -- Loss: 0.1758430004119873
train-epoch-step: 109-514 -- Loss: 0.1391560137271881
train-epoch-step: 109-515 -- Loss: 0.14534680545330048
train-epoch-step: 109-516 -- Loss: 0.16181150078773499
train-epoch-step: 109-517 -- Loss: 0.16829931735992432
train-epoch-step: 109-518 -- Loss: 0.13430283963680267
train-epoch-step: 109-519 -- Loss: 0.12766437232494354
train-epoch-step: 109-520 -- Loss: 0.17618466913700104
train-epoch-step: 109-521 -- Loss: 0.21965757012367249
train-epoch-step: 109-522 -- Loss: 0.15873102843761444
train-epoch-step: 109-523 -- Loss: 0.15261997282505035
train-epoch-step: 109-524 -- Loss: 0.16110631823539734
train-epoch-step: 109-525 -- Loss: 0.18912585079669952
train-epoch-step: 109-526 -- Loss: 0.12611855566501617
train-epoch-step: 109-527 -- Loss: 0.1459563672542572
train-epoch-step: 109-528 -- Loss: 0.15628035366535187
train-epoch-step: 109-529 -- Loss: 0.14528536796569824
train-epoch-step: 109-530 -- Loss: 0.16701103746891022
train-epoch-step: 109-531 -- Loss: 0.18545003235340118
train-epoch-step: 109-532 -- Loss: 0.16505953669548035
train-epoch-step: 109-533 -- Loss: 0.16637977957725525
train-epoch-step: 109-534 -- Loss: 0.12497751414775848
train-epoch-step: 109-535 -- Loss: 0.23796941339969635
train-epoch-step: 109-536 -- Loss: 0.15681995451450348
train-epoch-step: 109-537 -- Loss: 0.1419374942779541
train-epoch-step: 109-538 -- Loss: 0.1047847643494606
train-epoch-step: 109-539 -- Loss: 0.18306851387023926
train-epoch-step: 109-540 -- Loss: 0.1380956619977951
train-epoch-step: 109-541 -- Loss: 0.20266863703727722
train-epoch-step: 109-542 -- Loss: 0.21620090305805206
train-epoch-step: 109-543 -- Loss: 0.1599382609128952
train-epoch-step: 109-544 -- Loss: 0.22132974863052368
train-epoch-step: 109-545 -- Loss: 0.18830877542495728
train-epoch-step: 109-546 -- Loss: 0.19534562528133392
train-epoch-step: 109-547 -- Loss: 0.1782899796962738
train-epoch-step: 109-548 -- Loss: 0.08805404603481293
train-epoch-step: 109-549 -- Loss: 0.14203551411628723
train-epoch-step: 109-550 -- Loss: 0.1918553113937378
train-epoch-step: 109-551 -- Loss: 0.1465291827917099
train-epoch-step: 109-552 -- Loss: 0.12869663536548615
train-epoch-step: 109-553 -- Loss: 0.18482165038585663
train-epoch-step: 109-554 -- Loss: 0.1825985312461853
train-epoch-step: 109-555 -- Loss: 0.20576010644435883
train-epoch-step: 109-556 -- Loss: 0.13980811834335327
train-epoch-step: 109-557 -- Loss: 0.22359699010849
train-epoch-step: 109-558 -- Loss: 0.22327440977096558
train-epoch-step: 109-559 -- Loss: 0.1310066133737564
train-epoch-step: 109-560 -- Loss: 0.19854024052619934
train-epoch-step: 109-561 -- Loss: 0.16980230808258057
train-epoch-step: 109-562 -- Loss: 0.15411557257175446
train-epoch-step: 109-563 -- Loss: 0.1758602112531662
train-epoch-step: 109-564 -- Loss: 0.09542250633239746
train-epoch-step: 109-565 -- Loss: 0.1800195276737213
train-epoch-step: 109-566 -- Loss: 0.14339688420295715
train-epoch-step: 109-567 -- Loss: 0.20166705548763275
train-epoch-step: 109-568 -- Loss: 0.15250565111637115
train-epoch-step: 109-569 -- Loss: 0.23619572818279266
train-epoch-step: 109-570 -- Loss: 0.15838144719600677
train-epoch-step: 109-571 -- Loss: 0.19943667948246002
train-epoch-step: 109-572 -- Loss: 0.22896888852119446
train-epoch-step: 109-573 -- Loss: 0.19098502397537231
train-epoch-step: 109-574 -- Loss: 0.23031467199325562
train-epoch-step: 109-575 -- Loss: 0.282563179731369
train-epoch-step: 109-576 -- Loss: 0.11066406220197678
train-epoch-step: 109-577 -- Loss: 0.15755979716777802
train-epoch-step: 109-578 -- Loss: 0.20706817507743835
train-epoch-step: 109-579 -- Loss: 0.160103902220726
train-epoch-step: 109-580 -- Loss: 0.16570642590522766
train-epoch-step: 109-581 -- Loss: 0.14444679021835327
train-epoch-step: 109-582 -- Loss: 0.19416914880275726
train-epoch-step: 109-583 -- Loss: 0.20835810899734497
train-epoch-step: 109-584 -- Loss: 0.15404704213142395
train-epoch-step: 109-585 -- Loss: 0.1852550208568573
train-epoch-step: 109-586 -- Loss: 0.2425192892551422
train-epoch-step: 109-587 -- Loss: 0.1487291157245636
train-epoch-step: 109-588 -- Loss: 0.12243040651082993
val-epoch-step: 109-589 -- Loss: 0.1974075436592102
val-epoch-step: 109-590 -- Loss: 0.1494176983833313
val-epoch-step: 109-591 -- Loss: 0.23385316133499146
val-epoch-step: 109-592 -- Loss: 0.17100059986114502
val-epoch-step: 109-593 -- Loss: 0.13860633969306946
val-epoch-step: 109-594 -- Loss: 0.39325276017189026
val-epoch-step: 109-595 -- Loss: 0.1797836869955063
val-epoch-step: 109-596 -- Loss: 0.25609463453292847
val-epoch-step: 109-597 -- Loss: 0.16424690186977386
val-epoch-step: 109-598 -- Loss: 0.14681236445903778
val-epoch-step: 109-599 -- Loss: 0.1798158437013626
val-epoch-step: 109-600 -- Loss: 0.171510249376297
val-epoch-step: 109-601 -- Loss: 0.1508112996816635
val-epoch-step: 109-602 -- Loss: 0.1323862075805664
val-epoch-step: 109-603 -- Loss: 0.19810518622398376
val-epoch-step: 109-604 -- Loss: 0.1417984664440155
val-epoch-step: 109-605 -- Loss: 0.14337500929832458
val-epoch-step: 109-606 -- Loss: 0.24141044914722443
val-epoch-step: 109-607 -- Loss: 0.11909791082143784
val-epoch-step: 109-608 -- Loss: 0.24644318222999573
val-epoch-step: 109-609 -- Loss: 0.15684229135513306
val-epoch-step: 109-610 -- Loss: 0.17196838557720184
val-epoch-step: 109-611 -- Loss: 0.1654829978942871
val-epoch-step: 109-612 -- Loss: 0.38527143001556396
val-epoch-step: 109-613 -- Loss: 0.16637927293777466
val-epoch-step: 109-614 -- Loss: 0.17426225543022156
val-epoch-step: 109-615 -- Loss: 0.16608235239982605
val-epoch-step: 109-616 -- Loss: 0.13910651206970215
val-epoch-step: 109-617 -- Loss: 0.18729138374328613
val-epoch-step: 109-618 -- Loss: 0.17912644147872925
val-epoch-step: 109-619 -- Loss: 0.21631385385990143
val-epoch-step: 109-620 -- Loss: 0.12818391621112823
val-epoch-step: 109-621 -- Loss: 0.12147152423858643
val-epoch-step: 109-622 -- Loss: 0.14375323057174683
val-epoch-step: 109-623 -- Loss: 0.14467889070510864
val-epoch-step: 109-624 -- Loss: 0.13458311557769775
val-epoch-step: 109-625 -- Loss: 0.1593189835548401
val-epoch-step: 109-626 -- Loss: 0.1448986530303955
val-epoch-step: 109-627 -- Loss: 0.1738806962966919
val-epoch-step: 109-628 -- Loss: 0.5433186292648315
val-epoch-step: 109-629 -- Loss: 0.20742928981781006
val-epoch-step: 109-630 -- Loss: 0.3418370485305786
val-epoch-step: 109-631 -- Loss: 0.13426081836223602
val-epoch-step: 109-632 -- Loss: 0.1896502524614334
val-epoch-step: 109-633 -- Loss: 0.15092387795448303
val-epoch-step: 109-634 -- Loss: 0.15013407170772552
val-epoch-step: 109-635 -- Loss: 0.10661517828702927
val-epoch-step: 109-636 -- Loss: 0.16606633365154266
val-epoch-step: 109-637 -- Loss: 0.1846086084842682
val-epoch-step: 109-638 -- Loss: 0.14251378178596497
val-epoch-step: 109-639 -- Loss: 0.24707593023777008
val-epoch-step: 109-640 -- Loss: 0.2501344382762909
val-epoch-step: 109-641 -- Loss: 0.12153642624616623
val-epoch-step: 109-642 -- Loss: 0.16947129368782043
val-epoch-step: 109-643 -- Loss: 0.21074217557907104
val-epoch-step: 109-644 -- Loss: 0.16304540634155273
val-epoch-step: 109-645 -- Loss: 0.20780766010284424
val-epoch-step: 109-646 -- Loss: 0.13971154391765594
val-epoch-step: 109-647 -- Loss: 0.1269402652978897
val-epoch-step: 109-648 -- Loss: 0.1504300832748413
val-epoch-step: 109-649 -- Loss: 0.19733428955078125
val-epoch-step: 109-650 -- Loss: 0.24571862816810608
val-epoch-step: 109-651 -- Loss: 0.14165785908699036
val-epoch-step: 109-652 -- Loss: 0.1443016529083252
val-epoch-step: 109-653 -- Loss: 0.20830181241035461
val-epoch-step: 109-654 -- Loss: 0.11255575716495514
Epoch: 109 -- Train Loss: tensor(0.1383, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 110-0 -- Loss: 0.2118447721004486
train-epoch-step: 110-1 -- Loss: 0.13763897120952606
train-epoch-step: 110-2 -- Loss: 0.190626323223114
train-epoch-step: 110-3 -- Loss: 0.13865217566490173
train-epoch-step: 110-4 -- Loss: 0.1520940363407135
train-epoch-step: 110-5 -- Loss: 0.17126350104808807
train-epoch-step: 110-6 -- Loss: 0.210796058177948
train-epoch-step: 110-7 -- Loss: 0.1644543707370758
train-epoch-step: 110-8 -- Loss: 0.16784726083278656
train-epoch-step: 110-9 -- Loss: 0.25957661867141724
train-epoch-step: 110-10 -- Loss: 0.18205684423446655
train-epoch-step: 110-11 -- Loss: 0.17245621979236603
train-epoch-step: 110-12 -- Loss: 0.14323531091213226
train-epoch-step: 110-13 -- Loss: 0.18146556615829468
train-epoch-step: 110-14 -- Loss: 0.17190907895565033
train-epoch-step: 110-15 -- Loss: 0.1642938256263733
train-epoch-step: 110-16 -- Loss: 0.1676308959722519
train-epoch-step: 110-17 -- Loss: 0.2150276005268097
train-epoch-step: 110-18 -- Loss: 0.1869916319847107
train-epoch-step: 110-19 -- Loss: 0.12667778134346008
train-epoch-step: 110-20 -- Loss: 0.21244661509990692
train-epoch-step: 110-21 -- Loss: 0.2454490214586258
train-epoch-step: 110-22 -- Loss: 0.13632845878601074
train-epoch-step: 110-23 -- Loss: 0.14013946056365967
train-epoch-step: 110-24 -- Loss: 0.11773839592933655
train-epoch-step: 110-25 -- Loss: 0.20949536561965942
train-epoch-step: 110-26 -- Loss: 0.18476784229278564
train-epoch-step: 110-27 -- Loss: 0.22727054357528687
train-epoch-step: 110-28 -- Loss: 0.11952415108680725
train-epoch-step: 110-29 -- Loss: 0.23870068788528442
train-epoch-step: 110-30 -- Loss: 0.10684357583522797
train-epoch-step: 110-31 -- Loss: 0.1311056762933731
train-epoch-step: 110-32 -- Loss: 0.16777688264846802
train-epoch-step: 110-33 -- Loss: 0.2596409022808075
train-epoch-step: 110-34 -- Loss: 0.17637503147125244
train-epoch-step: 110-35 -- Loss: 0.24326395988464355
train-epoch-step: 110-36 -- Loss: 0.13506560027599335
train-epoch-step: 110-37 -- Loss: 0.13216647505760193
train-epoch-step: 110-38 -- Loss: 0.1704641580581665
train-epoch-step: 110-39 -- Loss: 0.22171379625797272
train-epoch-step: 110-40 -- Loss: 0.20800958573818207
train-epoch-step: 110-41 -- Loss: 0.20761820673942566
train-epoch-step: 110-42 -- Loss: 0.1397372931241989
train-epoch-step: 110-43 -- Loss: 0.2473936378955841
train-epoch-step: 110-44 -- Loss: 0.11947683244943619
train-epoch-step: 110-45 -- Loss: 0.11044993996620178
train-epoch-step: 110-46 -- Loss: 0.16507239639759064
train-epoch-step: 110-47 -- Loss: 0.19070959091186523
train-epoch-step: 110-48 -- Loss: 0.1552574336528778
train-epoch-step: 110-49 -- Loss: 0.22482137382030487
train-epoch-step: 110-50 -- Loss: 0.10819631814956665
train-epoch-step: 110-51 -- Loss: 0.17217011749744415
train-epoch-step: 110-52 -- Loss: 0.1533854901790619
train-epoch-step: 110-53 -- Loss: 0.20087546110153198
train-epoch-step: 110-54 -- Loss: 0.27584171295166016
train-epoch-step: 110-55 -- Loss: 0.15665246546268463
train-epoch-step: 110-56 -- Loss: 0.16804751753807068
train-epoch-step: 110-57 -- Loss: 0.231715589761734
train-epoch-step: 110-58 -- Loss: 0.2792391777038574
train-epoch-step: 110-59 -- Loss: 0.23095649480819702
train-epoch-step: 110-60 -- Loss: 0.12816578149795532
train-epoch-step: 110-61 -- Loss: 0.19441726803779602
train-epoch-step: 110-62 -- Loss: 0.1777648627758026
train-epoch-step: 110-63 -- Loss: 0.1323336660861969
train-epoch-step: 110-64 -- Loss: 0.1400216519832611
train-epoch-step: 110-65 -- Loss: 0.17353659868240356
train-epoch-step: 110-66 -- Loss: 0.10316534340381622
train-epoch-step: 110-67 -- Loss: 0.1211312860250473
train-epoch-step: 110-68 -- Loss: 0.20912453532218933
train-epoch-step: 110-69 -- Loss: 0.11703769862651825
train-epoch-step: 110-70 -- Loss: 0.21633513271808624
train-epoch-step: 110-71 -- Loss: 0.2523798942565918
train-epoch-step: 110-72 -- Loss: 0.16633521020412445
train-epoch-step: 110-73 -- Loss: 0.20092999935150146
train-epoch-step: 110-74 -- Loss: 0.09099680185317993
train-epoch-step: 110-75 -- Loss: 0.123306043446064
train-epoch-step: 110-76 -- Loss: 0.1384088099002838
train-epoch-step: 110-77 -- Loss: 0.22319266200065613
train-epoch-step: 110-78 -- Loss: 0.25944823026657104
train-epoch-step: 110-79 -- Loss: 0.18211334943771362
train-epoch-step: 110-80 -- Loss: 0.24841977655887604
train-epoch-step: 110-81 -- Loss: 0.11733190715312958
train-epoch-step: 110-82 -- Loss: 0.24419447779655457
train-epoch-step: 110-83 -- Loss: 0.17734770476818085
train-epoch-step: 110-84 -- Loss: 0.18060337007045746
train-epoch-step: 110-85 -- Loss: 0.17140765488147736
train-epoch-step: 110-86 -- Loss: 0.11548729240894318
train-epoch-step: 110-87 -- Loss: 0.20862895250320435
train-epoch-step: 110-88 -- Loss: 0.14662250876426697
train-epoch-step: 110-89 -- Loss: 0.1834772676229477
train-epoch-step: 110-90 -- Loss: 0.18117593228816986
train-epoch-step: 110-91 -- Loss: 0.23626857995986938
train-epoch-step: 110-92 -- Loss: 0.19737595319747925
train-epoch-step: 110-93 -- Loss: 0.18538551032543182
train-epoch-step: 110-94 -- Loss: 0.2147403061389923
train-epoch-step: 110-95 -- Loss: 0.17822620272636414
train-epoch-step: 110-96 -- Loss: 0.2134486436843872
train-epoch-step: 110-97 -- Loss: 0.16971455514431
train-epoch-step: 110-98 -- Loss: 0.16071553528308868
train-epoch-step: 110-99 -- Loss: 0.17939044535160065
train-epoch-step: 110-100 -- Loss: 0.18593445420265198
train-epoch-step: 110-101 -- Loss: 0.26571086049079895
train-epoch-step: 110-102 -- Loss: 0.21283946931362152
train-epoch-step: 110-103 -- Loss: 0.1796804666519165
train-epoch-step: 110-104 -- Loss: 0.14625588059425354
train-epoch-step: 110-105 -- Loss: 0.26579615473747253
train-epoch-step: 110-106 -- Loss: 0.17020899057388306
train-epoch-step: 110-107 -- Loss: 0.187987819314003
train-epoch-step: 110-108 -- Loss: 0.19069863855838776
train-epoch-step: 110-109 -- Loss: 0.14153943955898285
train-epoch-step: 110-110 -- Loss: 0.1824512779712677
train-epoch-step: 110-111 -- Loss: 0.17471987009048462
train-epoch-step: 110-112 -- Loss: 0.16720110177993774
train-epoch-step: 110-113 -- Loss: 0.1657925546169281
train-epoch-step: 110-114 -- Loss: 0.19359567761421204
train-epoch-step: 110-115 -- Loss: 0.15251730382442474
train-epoch-step: 110-116 -- Loss: 0.13323311507701874
train-epoch-step: 110-117 -- Loss: 0.12013526260852814
train-epoch-step: 110-118 -- Loss: 0.18680670857429504
train-epoch-step: 110-119 -- Loss: 0.1479480266571045
train-epoch-step: 110-120 -- Loss: 0.24769499897956848
train-epoch-step: 110-121 -- Loss: 0.23374947905540466
train-epoch-step: 110-122 -- Loss: 0.2114347517490387
train-epoch-step: 110-123 -- Loss: 0.19529955089092255
train-epoch-step: 110-124 -- Loss: 0.11927855014801025
train-epoch-step: 110-125 -- Loss: 0.1493423879146576
train-epoch-step: 110-126 -- Loss: 0.22523018717765808
train-epoch-step: 110-127 -- Loss: 0.1670958697795868
train-epoch-step: 110-128 -- Loss: 0.16696681082248688
train-epoch-step: 110-129 -- Loss: 0.13616064190864563
train-epoch-step: 110-130 -- Loss: 0.20078453421592712
train-epoch-step: 110-131 -- Loss: 0.13299724459648132
train-epoch-step: 110-132 -- Loss: 0.18159979581832886
train-epoch-step: 110-133 -- Loss: 0.11237861216068268
train-epoch-step: 110-134 -- Loss: 0.18523326516151428
train-epoch-step: 110-135 -- Loss: 0.12812316417694092
train-epoch-step: 110-136 -- Loss: 0.12331949919462204
train-epoch-step: 110-137 -- Loss: 0.2355467677116394
train-epoch-step: 110-138 -- Loss: 0.2458372861146927
train-epoch-step: 110-139 -- Loss: 0.1292305588722229
train-epoch-step: 110-140 -- Loss: 0.20131966471672058
train-epoch-step: 110-141 -- Loss: 0.22253692150115967
train-epoch-step: 110-142 -- Loss: 0.19577668607234955
train-epoch-step: 110-143 -- Loss: 0.17314861714839935
train-epoch-step: 110-144 -- Loss: 0.17456215620040894
train-epoch-step: 110-145 -- Loss: 0.1355219930410385
train-epoch-step: 110-146 -- Loss: 0.17385992407798767
train-epoch-step: 110-147 -- Loss: 0.16166386008262634
train-epoch-step: 110-148 -- Loss: 0.15431508421897888
train-epoch-step: 110-149 -- Loss: 0.11272324621677399
train-epoch-step: 110-150 -- Loss: 0.17706003785133362
train-epoch-step: 110-151 -- Loss: 0.1791442185640335
train-epoch-step: 110-152 -- Loss: 0.1809505671262741
train-epoch-step: 110-153 -- Loss: 0.26507461071014404
train-epoch-step: 110-154 -- Loss: 0.13198697566986084
train-epoch-step: 110-155 -- Loss: 0.1289486438035965
train-epoch-step: 110-156 -- Loss: 0.11095620691776276
train-epoch-step: 110-157 -- Loss: 0.15655921399593353
train-epoch-step: 110-158 -- Loss: 0.1597280353307724
train-epoch-step: 110-159 -- Loss: 0.17524702847003937
train-epoch-step: 110-160 -- Loss: 0.19719864428043365
train-epoch-step: 110-161 -- Loss: 0.19678635895252228
train-epoch-step: 110-162 -- Loss: 0.20012769103050232
train-epoch-step: 110-163 -- Loss: 0.18013215065002441
train-epoch-step: 110-164 -- Loss: 0.18621708452701569
train-epoch-step: 110-165 -- Loss: 0.15607817471027374
train-epoch-step: 110-166 -- Loss: 0.12126761674880981
train-epoch-step: 110-167 -- Loss: 0.11945892125368118
train-epoch-step: 110-168 -- Loss: 0.19657589495182037
train-epoch-step: 110-169 -- Loss: 0.1352097988128662
train-epoch-step: 110-170 -- Loss: 0.19380730390548706
train-epoch-step: 110-171 -- Loss: 0.13884297013282776
train-epoch-step: 110-172 -- Loss: 0.25029170513153076
train-epoch-step: 110-173 -- Loss: 0.13386772572994232
train-epoch-step: 110-174 -- Loss: 0.23752470314502716
train-epoch-step: 110-175 -- Loss: 0.17952603101730347
train-epoch-step: 110-176 -- Loss: 0.12902489304542542
train-epoch-step: 110-177 -- Loss: 0.1719118058681488
train-epoch-step: 110-178 -- Loss: 0.17294429242610931
train-epoch-step: 110-179 -- Loss: 0.1511937528848648
train-epoch-step: 110-180 -- Loss: 0.14399169385433197
train-epoch-step: 110-181 -- Loss: 0.16542372107505798
train-epoch-step: 110-182 -- Loss: 0.1775205433368683
train-epoch-step: 110-183 -- Loss: 0.26818469166755676
train-epoch-step: 110-184 -- Loss: 0.1342901736497879
train-epoch-step: 110-185 -- Loss: 0.14145295321941376
train-epoch-step: 110-186 -- Loss: 0.1888035386800766
train-epoch-step: 110-187 -- Loss: 0.2074129283428192
train-epoch-step: 110-188 -- Loss: 0.16739097237586975
train-epoch-step: 110-189 -- Loss: 0.10713373124599457
train-epoch-step: 110-190 -- Loss: 0.17779013514518738
train-epoch-step: 110-191 -- Loss: 0.15550100803375244
train-epoch-step: 110-192 -- Loss: 0.22039198875427246
train-epoch-step: 110-193 -- Loss: 0.198966845870018
train-epoch-step: 110-194 -- Loss: 0.17696824669837952
train-epoch-step: 110-195 -- Loss: 0.16285473108291626
train-epoch-step: 110-196 -- Loss: 0.16751238703727722
train-epoch-step: 110-197 -- Loss: 0.12214469164609909
train-epoch-step: 110-198 -- Loss: 0.12269793450832367
train-epoch-step: 110-199 -- Loss: 0.14465729892253876
train-epoch-step: 110-200 -- Loss: 0.12129343301057816
train-epoch-step: 110-201 -- Loss: 0.18558475375175476
train-epoch-step: 110-202 -- Loss: 0.13531792163848877
train-epoch-step: 110-203 -- Loss: 0.17182408273220062
train-epoch-step: 110-204 -- Loss: 0.13140414655208588
train-epoch-step: 110-205 -- Loss: 0.18143552541732788
train-epoch-step: 110-206 -- Loss: 0.19198663532733917
train-epoch-step: 110-207 -- Loss: 0.13052016496658325
train-epoch-step: 110-208 -- Loss: 0.1723414957523346
train-epoch-step: 110-209 -- Loss: 0.13710996508598328
train-epoch-step: 110-210 -- Loss: 0.12872865796089172
train-epoch-step: 110-211 -- Loss: 0.20291583240032196
train-epoch-step: 110-212 -- Loss: 0.1896471381187439
train-epoch-step: 110-213 -- Loss: 0.12481923401355743
train-epoch-step: 110-214 -- Loss: 0.14735844731330872
train-epoch-step: 110-215 -- Loss: 0.12328355014324188
train-epoch-step: 110-216 -- Loss: 0.19360382854938507
train-epoch-step: 110-217 -- Loss: 0.20354095101356506
train-epoch-step: 110-218 -- Loss: 0.1396636664867401
train-epoch-step: 110-219 -- Loss: 0.16142681241035461
train-epoch-step: 110-220 -- Loss: 0.1236211359500885
train-epoch-step: 110-221 -- Loss: 0.1993681639432907
train-epoch-step: 110-222 -- Loss: 0.11577167361974716
train-epoch-step: 110-223 -- Loss: 0.1656644344329834
train-epoch-step: 110-224 -- Loss: 0.19366559386253357
train-epoch-step: 110-225 -- Loss: 0.2590753138065338
train-epoch-step: 110-226 -- Loss: 0.20619094371795654
train-epoch-step: 110-227 -- Loss: 0.21166545152664185
train-epoch-step: 110-228 -- Loss: 0.17341110110282898
train-epoch-step: 110-229 -- Loss: 0.16917362809181213
train-epoch-step: 110-230 -- Loss: 0.1575341522693634
train-epoch-step: 110-231 -- Loss: 0.14924824237823486
train-epoch-step: 110-232 -- Loss: 0.17444275319576263
train-epoch-step: 110-233 -- Loss: 0.08076927810907364
train-epoch-step: 110-234 -- Loss: 0.17110952734947205
train-epoch-step: 110-235 -- Loss: 0.13919538259506226
train-epoch-step: 110-236 -- Loss: 0.1717090904712677
train-epoch-step: 110-237 -- Loss: 0.22452567517757416
train-epoch-step: 110-238 -- Loss: 0.14747416973114014
train-epoch-step: 110-239 -- Loss: 0.12074475735425949
train-epoch-step: 110-240 -- Loss: 0.21708819270133972
train-epoch-step: 110-241 -- Loss: 0.14772653579711914
train-epoch-step: 110-242 -- Loss: 0.21365322172641754
train-epoch-step: 110-243 -- Loss: 0.2265479564666748
train-epoch-step: 110-244 -- Loss: 0.19806614518165588
train-epoch-step: 110-245 -- Loss: 0.2133057862520218
train-epoch-step: 110-246 -- Loss: 0.20959395170211792
train-epoch-step: 110-247 -- Loss: 0.20399008691310883
train-epoch-step: 110-248 -- Loss: 0.17733636498451233
train-epoch-step: 110-249 -- Loss: 0.1320720613002777
train-epoch-step: 110-250 -- Loss: 0.19264636933803558
train-epoch-step: 110-251 -- Loss: 0.10182592272758484
train-epoch-step: 110-252 -- Loss: 0.19227419793605804
train-epoch-step: 110-253 -- Loss: 0.13375744223594666
train-epoch-step: 110-254 -- Loss: 0.20076978206634521
train-epoch-step: 110-255 -- Loss: 0.1408354640007019
train-epoch-step: 110-256 -- Loss: 0.14738976955413818
train-epoch-step: 110-257 -- Loss: 0.18524186313152313
train-epoch-step: 110-258 -- Loss: 0.1406906694173813
train-epoch-step: 110-259 -- Loss: 0.10957025736570358
train-epoch-step: 110-260 -- Loss: 0.1932503879070282
train-epoch-step: 110-261 -- Loss: 0.16681155562400818
train-epoch-step: 110-262 -- Loss: 0.27194222807884216
train-epoch-step: 110-263 -- Loss: 0.1907653957605362
train-epoch-step: 110-264 -- Loss: 0.1679522544145584
train-epoch-step: 110-265 -- Loss: 0.11496089398860931
train-epoch-step: 110-266 -- Loss: 0.15148523449897766
train-epoch-step: 110-267 -- Loss: 0.12466874718666077
train-epoch-step: 110-268 -- Loss: 0.1133517324924469
train-epoch-step: 110-269 -- Loss: 0.166248619556427
train-epoch-step: 110-270 -- Loss: 0.10299264639616013
train-epoch-step: 110-271 -- Loss: 0.142544686794281
train-epoch-step: 110-272 -- Loss: 0.1105593591928482
train-epoch-step: 110-273 -- Loss: 0.12083623558282852
train-epoch-step: 110-274 -- Loss: 0.19264599680900574
train-epoch-step: 110-275 -- Loss: 0.18048244714736938
train-epoch-step: 110-276 -- Loss: 0.1511443853378296
train-epoch-step: 110-277 -- Loss: 0.1488528549671173
train-epoch-step: 110-278 -- Loss: 0.1417090892791748
train-epoch-step: 110-279 -- Loss: 0.13483932614326477
train-epoch-step: 110-280 -- Loss: 0.20644819736480713
train-epoch-step: 110-281 -- Loss: 0.1727779507637024
train-epoch-step: 110-282 -- Loss: 0.1375325620174408
train-epoch-step: 110-283 -- Loss: 0.11245415359735489
train-epoch-step: 110-284 -- Loss: 0.13279029726982117
train-epoch-step: 110-285 -- Loss: 0.18003037571907043
train-epoch-step: 110-286 -- Loss: 0.1463349163532257
train-epoch-step: 110-287 -- Loss: 0.1951138973236084
train-epoch-step: 110-288 -- Loss: 0.10011660307645798
train-epoch-step: 110-289 -- Loss: 0.1136637032032013
train-epoch-step: 110-290 -- Loss: 0.17535041272640228
train-epoch-step: 110-291 -- Loss: 0.11052224040031433
train-epoch-step: 110-292 -- Loss: 0.15147551894187927
train-epoch-step: 110-293 -- Loss: 0.13092659413814545
train-epoch-step: 110-294 -- Loss: 0.15153461694717407
train-epoch-step: 110-295 -- Loss: 0.2595941424369812
train-epoch-step: 110-296 -- Loss: 0.15487635135650635
train-epoch-step: 110-297 -- Loss: 0.16344575583934784
train-epoch-step: 110-298 -- Loss: 0.21968957781791687
train-epoch-step: 110-299 -- Loss: 0.1423877477645874
train-epoch-step: 110-300 -- Loss: 0.1569027304649353
train-epoch-step: 110-301 -- Loss: 0.17234504222869873
train-epoch-step: 110-302 -- Loss: 0.21401607990264893
train-epoch-step: 110-303 -- Loss: 0.19573566317558289
train-epoch-step: 110-304 -- Loss: 0.12229220569133759
train-epoch-step: 110-305 -- Loss: 0.13544054329395294
train-epoch-step: 110-306 -- Loss: 0.20151183009147644
train-epoch-step: 110-307 -- Loss: 0.1610797643661499
train-epoch-step: 110-308 -- Loss: 0.21216905117034912
train-epoch-step: 110-309 -- Loss: 0.14920441806316376
train-epoch-step: 110-310 -- Loss: 0.15995673835277557
train-epoch-step: 110-311 -- Loss: 0.15463590621948242
train-epoch-step: 110-312 -- Loss: 0.19606678187847137
train-epoch-step: 110-313 -- Loss: 0.09285249561071396
train-epoch-step: 110-314 -- Loss: 0.18433097004890442
train-epoch-step: 110-315 -- Loss: 0.15996144711971283
train-epoch-step: 110-316 -- Loss: 0.15005604922771454
train-epoch-step: 110-317 -- Loss: 0.14178383350372314
train-epoch-step: 110-318 -- Loss: 0.14734648168087006
train-epoch-step: 110-319 -- Loss: 0.16815578937530518
train-epoch-step: 110-320 -- Loss: 0.11478814482688904
train-epoch-step: 110-321 -- Loss: 0.13135042786598206
train-epoch-step: 110-322 -- Loss: 0.20116569101810455
train-epoch-step: 110-323 -- Loss: 0.1542477160692215
train-epoch-step: 110-324 -- Loss: 0.2424657791852951
train-epoch-step: 110-325 -- Loss: 0.15198995172977448
train-epoch-step: 110-326 -- Loss: 0.16297174990177155
train-epoch-step: 110-327 -- Loss: 0.19801941514015198
train-epoch-step: 110-328 -- Loss: 0.18931885063648224
train-epoch-step: 110-329 -- Loss: 0.3264968693256378
train-epoch-step: 110-330 -- Loss: 0.3615057170391083
train-epoch-step: 110-331 -- Loss: 0.20897220075130463
train-epoch-step: 110-332 -- Loss: 0.09455060958862305
train-epoch-step: 110-333 -- Loss: 0.17840538918972015
train-epoch-step: 110-334 -- Loss: 0.15026076138019562
train-epoch-step: 110-335 -- Loss: 0.17660090327262878
train-epoch-step: 110-336 -- Loss: 0.1446632742881775
train-epoch-step: 110-337 -- Loss: 0.19654658436775208
train-epoch-step: 110-338 -- Loss: 0.1567661315202713
train-epoch-step: 110-339 -- Loss: 0.1377968043088913
train-epoch-step: 110-340 -- Loss: 0.19074304401874542
train-epoch-step: 110-341 -- Loss: 0.138998880982399
train-epoch-step: 110-342 -- Loss: 0.15770265460014343
train-epoch-step: 110-343 -- Loss: 0.14671260118484497
train-epoch-step: 110-344 -- Loss: 0.16232135891914368
train-epoch-step: 110-345 -- Loss: 0.12045326083898544
train-epoch-step: 110-346 -- Loss: 0.19438409805297852
train-epoch-step: 110-347 -- Loss: 0.1483987420797348
train-epoch-step: 110-348 -- Loss: 0.20109134912490845
train-epoch-step: 110-349 -- Loss: 0.20050852000713348
train-epoch-step: 110-350 -- Loss: 0.2408258020877838
train-epoch-step: 110-351 -- Loss: 0.1867835968732834
train-epoch-step: 110-352 -- Loss: 0.12101636081933975
train-epoch-step: 110-353 -- Loss: 0.20071353018283844
train-epoch-step: 110-354 -- Loss: 0.26880836486816406
train-epoch-step: 110-355 -- Loss: 0.1155654564499855
train-epoch-step: 110-356 -- Loss: 0.1104917973279953
train-epoch-step: 110-357 -- Loss: 0.17805907130241394
train-epoch-step: 110-358 -- Loss: 0.18270637094974518
train-epoch-step: 110-359 -- Loss: 0.13457980751991272
train-epoch-step: 110-360 -- Loss: 0.12052419781684875
train-epoch-step: 110-361 -- Loss: 0.26210498809814453
train-epoch-step: 110-362 -- Loss: 0.16464366018772125
train-epoch-step: 110-363 -- Loss: 0.11042939871549606
train-epoch-step: 110-364 -- Loss: 0.17730489373207092
train-epoch-step: 110-365 -- Loss: 0.16464319825172424
train-epoch-step: 110-366 -- Loss: 0.20320706069469452
train-epoch-step: 110-367 -- Loss: 0.22480809688568115
train-epoch-step: 110-368 -- Loss: 0.18919488787651062
train-epoch-step: 110-369 -- Loss: 0.27048054337501526
train-epoch-step: 110-370 -- Loss: 0.11932146549224854
train-epoch-step: 110-371 -- Loss: 0.1210860013961792
train-epoch-step: 110-372 -- Loss: 0.1481228917837143
train-epoch-step: 110-373 -- Loss: 0.18675503134727478
train-epoch-step: 110-374 -- Loss: 0.14997969567775726
train-epoch-step: 110-375 -- Loss: 0.2602955102920532
train-epoch-step: 110-376 -- Loss: 0.16410192847251892
train-epoch-step: 110-377 -- Loss: 0.24198025465011597
train-epoch-step: 110-378 -- Loss: 0.19273456931114197
train-epoch-step: 110-379 -- Loss: 0.11978672444820404
train-epoch-step: 110-380 -- Loss: 0.09049161523580551
train-epoch-step: 110-381 -- Loss: 0.24374574422836304
train-epoch-step: 110-382 -- Loss: 0.23711645603179932
train-epoch-step: 110-383 -- Loss: 0.18798166513442993
train-epoch-step: 110-384 -- Loss: 0.22390620410442352
train-epoch-step: 110-385 -- Loss: 0.18542757630348206
train-epoch-step: 110-386 -- Loss: 0.1913788914680481
train-epoch-step: 110-387 -- Loss: 0.19944033026695251
train-epoch-step: 110-388 -- Loss: 0.18320932984352112
train-epoch-step: 110-389 -- Loss: 0.16390177607536316
train-epoch-step: 110-390 -- Loss: 0.13940627872943878
train-epoch-step: 110-391 -- Loss: 0.14162911474704742
train-epoch-step: 110-392 -- Loss: 0.17562609910964966
train-epoch-step: 110-393 -- Loss: 0.15082794427871704
train-epoch-step: 110-394 -- Loss: 0.20871208608150482
train-epoch-step: 110-395 -- Loss: 0.15914598107337952
train-epoch-step: 110-396 -- Loss: 0.12457047402858734
train-epoch-step: 110-397 -- Loss: 0.12059169262647629
train-epoch-step: 110-398 -- Loss: 0.19095328450202942
train-epoch-step: 110-399 -- Loss: 0.1699456125497818
train-epoch-step: 110-400 -- Loss: 0.2772914171218872
train-epoch-step: 110-401 -- Loss: 0.114853635430336
train-epoch-step: 110-402 -- Loss: 0.2549532353878021
train-epoch-step: 110-403 -- Loss: 0.1530916392803192
train-epoch-step: 110-404 -- Loss: 0.13587191700935364
train-epoch-step: 110-405 -- Loss: 0.13648031651973724
train-epoch-step: 110-406 -- Loss: 0.16050253808498383
train-epoch-step: 110-407 -- Loss: 0.10799666494131088
train-epoch-step: 110-408 -- Loss: 0.15653088688850403
train-epoch-step: 110-409 -- Loss: 0.16311247646808624
train-epoch-step: 110-410 -- Loss: 0.1687350571155548
train-epoch-step: 110-411 -- Loss: 0.19718630611896515
train-epoch-step: 110-412 -- Loss: 0.12282702326774597
train-epoch-step: 110-413 -- Loss: 0.14385509490966797
train-epoch-step: 110-414 -- Loss: 0.130179300904274
train-epoch-step: 110-415 -- Loss: 0.13587163388729095
train-epoch-step: 110-416 -- Loss: 0.2578464150428772
train-epoch-step: 110-417 -- Loss: 0.18677100539207458
train-epoch-step: 110-418 -- Loss: 0.21520563960075378
train-epoch-step: 110-419 -- Loss: 0.16837231814861298
train-epoch-step: 110-420 -- Loss: 0.14708268642425537
train-epoch-step: 110-421 -- Loss: 0.1780339628458023
train-epoch-step: 110-422 -- Loss: 0.14949172735214233
train-epoch-step: 110-423 -- Loss: 0.16417492926120758
train-epoch-step: 110-424 -- Loss: 0.13296397030353546
train-epoch-step: 110-425 -- Loss: 0.1766786426305771
train-epoch-step: 110-426 -- Loss: 0.1628873497247696
train-epoch-step: 110-427 -- Loss: 0.14431940019130707
train-epoch-step: 110-428 -- Loss: 0.18994444608688354
train-epoch-step: 110-429 -- Loss: 0.16913443803787231
train-epoch-step: 110-430 -- Loss: 0.13539640605449677
train-epoch-step: 110-431 -- Loss: 0.18069776892662048
train-epoch-step: 110-432 -- Loss: 0.23664411902427673
train-epoch-step: 110-433 -- Loss: 0.13308091461658478
train-epoch-step: 110-434 -- Loss: 0.12437347322702408
train-epoch-step: 110-435 -- Loss: 0.15011456608772278
train-epoch-step: 110-436 -- Loss: 0.15834283828735352
train-epoch-step: 110-437 -- Loss: 0.14005473256111145
train-epoch-step: 110-438 -- Loss: 0.1654982566833496
train-epoch-step: 110-439 -- Loss: 0.2634257674217224
train-epoch-step: 110-440 -- Loss: 0.12876395881175995
train-epoch-step: 110-441 -- Loss: 0.19575636088848114
train-epoch-step: 110-442 -- Loss: 0.18164873123168945
train-epoch-step: 110-443 -- Loss: 0.1558276265859604
train-epoch-step: 110-444 -- Loss: 0.16874271631240845
train-epoch-step: 110-445 -- Loss: 0.17818686366081238
train-epoch-step: 110-446 -- Loss: 0.15102359652519226
train-epoch-step: 110-447 -- Loss: 0.1824944168329239
train-epoch-step: 110-448 -- Loss: 0.21922141313552856
train-epoch-step: 110-449 -- Loss: 0.1854000985622406
train-epoch-step: 110-450 -- Loss: 0.17823974788188934
train-epoch-step: 110-451 -- Loss: 0.14303556084632874
train-epoch-step: 110-452 -- Loss: 0.12444442510604858
train-epoch-step: 110-453 -- Loss: 0.09024517238140106
train-epoch-step: 110-454 -- Loss: 0.23039981722831726
train-epoch-step: 110-455 -- Loss: 0.1212918683886528
train-epoch-step: 110-456 -- Loss: 0.12885329127311707
train-epoch-step: 110-457 -- Loss: 0.2135336697101593
train-epoch-step: 110-458 -- Loss: 0.14037980139255524
train-epoch-step: 110-459 -- Loss: 0.20410707592964172
train-epoch-step: 110-460 -- Loss: 0.11941473186016083
train-epoch-step: 110-461 -- Loss: 0.13250277936458588
train-epoch-step: 110-462 -- Loss: 0.1496129184961319
train-epoch-step: 110-463 -- Loss: 0.13352742791175842
train-epoch-step: 110-464 -- Loss: 0.15661731362342834
train-epoch-step: 110-465 -- Loss: 0.22625523805618286
train-epoch-step: 110-466 -- Loss: 0.19819368422031403
train-epoch-step: 110-467 -- Loss: 0.11017386615276337
train-epoch-step: 110-468 -- Loss: 0.15925131738185883
train-epoch-step: 110-469 -- Loss: 0.20272524654865265
train-epoch-step: 110-470 -- Loss: 0.16189859807491302
train-epoch-step: 110-471 -- Loss: 0.15552477538585663
train-epoch-step: 110-472 -- Loss: 0.15099593997001648
train-epoch-step: 110-473 -- Loss: 0.1493566781282425
train-epoch-step: 110-474 -- Loss: 0.11742020398378372
train-epoch-step: 110-475 -- Loss: 0.10638675838708878
train-epoch-step: 110-476 -- Loss: 0.19159457087516785
train-epoch-step: 110-477 -- Loss: 0.18797020614147186
train-epoch-step: 110-478 -- Loss: 0.17961353063583374
train-epoch-step: 110-479 -- Loss: 0.13340266048908234
train-epoch-step: 110-480 -- Loss: 0.18342551589012146
train-epoch-step: 110-481 -- Loss: 0.2697523236274719
train-epoch-step: 110-482 -- Loss: 0.24058638513088226
train-epoch-step: 110-483 -- Loss: 0.17170724272727966
train-epoch-step: 110-484 -- Loss: 0.20408104360103607
train-epoch-step: 110-485 -- Loss: 0.12335892766714096
train-epoch-step: 110-486 -- Loss: 0.2185184359550476
train-epoch-step: 110-487 -- Loss: 0.22635281085968018
train-epoch-step: 110-488 -- Loss: 0.17792516946792603
train-epoch-step: 110-489 -- Loss: 0.21702198684215546
train-epoch-step: 110-490 -- Loss: 0.13184964656829834
train-epoch-step: 110-491 -- Loss: 0.130767360329628
train-epoch-step: 110-492 -- Loss: 0.12034839391708374
train-epoch-step: 110-493 -- Loss: 0.2016097605228424
train-epoch-step: 110-494 -- Loss: 0.1937067210674286
train-epoch-step: 110-495 -- Loss: 0.19440224766731262
train-epoch-step: 110-496 -- Loss: 0.14010471105575562
train-epoch-step: 110-497 -- Loss: 0.18118233978748322
train-epoch-step: 110-498 -- Loss: 0.1420918107032776
train-epoch-step: 110-499 -- Loss: 0.16192574799060822
train-epoch-step: 110-500 -- Loss: 0.1491556614637375
train-epoch-step: 110-501 -- Loss: 0.21014976501464844
train-epoch-step: 110-502 -- Loss: 0.1533198207616806
train-epoch-step: 110-503 -- Loss: 0.208090677857399
train-epoch-step: 110-504 -- Loss: 0.11916401982307434
train-epoch-step: 110-505 -- Loss: 0.16426870226860046
train-epoch-step: 110-506 -- Loss: 0.11562831699848175
train-epoch-step: 110-507 -- Loss: 0.17292757332324982
train-epoch-step: 110-508 -- Loss: 0.17345161736011505
train-epoch-step: 110-509 -- Loss: 0.16738013923168182
train-epoch-step: 110-510 -- Loss: 0.12592455744743347
train-epoch-step: 110-511 -- Loss: 0.2063891887664795
train-epoch-step: 110-512 -- Loss: 0.17086975276470184
train-epoch-step: 110-513 -- Loss: 0.17980723083019257
train-epoch-step: 110-514 -- Loss: 0.13878168165683746
train-epoch-step: 110-515 -- Loss: 0.14901438355445862
train-epoch-step: 110-516 -- Loss: 0.16881999373435974
train-epoch-step: 110-517 -- Loss: 0.16838768124580383
train-epoch-step: 110-518 -- Loss: 0.13457649946212769
train-epoch-step: 110-519 -- Loss: 0.13157424330711365
train-epoch-step: 110-520 -- Loss: 0.17826053500175476
train-epoch-step: 110-521 -- Loss: 0.21375545859336853
train-epoch-step: 110-522 -- Loss: 0.16382019221782684
train-epoch-step: 110-523 -- Loss: 0.1538807451725006
train-epoch-step: 110-524 -- Loss: 0.15827041864395142
train-epoch-step: 110-525 -- Loss: 0.18696659803390503
train-epoch-step: 110-526 -- Loss: 0.12556403875350952
train-epoch-step: 110-527 -- Loss: 0.1481095850467682
train-epoch-step: 110-528 -- Loss: 0.15085966885089874
train-epoch-step: 110-529 -- Loss: 0.14840330183506012
train-epoch-step: 110-530 -- Loss: 0.16611696779727936
train-epoch-step: 110-531 -- Loss: 0.18820396065711975
train-epoch-step: 110-532 -- Loss: 0.1607208102941513
train-epoch-step: 110-533 -- Loss: 0.16920946538448334
train-epoch-step: 110-534 -- Loss: 0.13513867557048798
train-epoch-step: 110-535 -- Loss: 0.24407687783241272
train-epoch-step: 110-536 -- Loss: 0.15533298254013062
train-epoch-step: 110-537 -- Loss: 0.1403294950723648
train-epoch-step: 110-538 -- Loss: 0.10642457753419876
train-epoch-step: 110-539 -- Loss: 0.17683905363082886
train-epoch-step: 110-540 -- Loss: 0.128802090883255
train-epoch-step: 110-541 -- Loss: 0.20107276737689972
train-epoch-step: 110-542 -- Loss: 0.2155156284570694
train-epoch-step: 110-543 -- Loss: 0.16402959823608398
train-epoch-step: 110-544 -- Loss: 0.21981759369373322
train-epoch-step: 110-545 -- Loss: 0.18664352595806122
train-epoch-step: 110-546 -- Loss: 0.20212656259536743
train-epoch-step: 110-547 -- Loss: 0.18080727756023407
train-epoch-step: 110-548 -- Loss: 0.08787557482719421
train-epoch-step: 110-549 -- Loss: 0.14358901977539062
train-epoch-step: 110-550 -- Loss: 0.1913314312696457
train-epoch-step: 110-551 -- Loss: 0.1480618417263031
train-epoch-step: 110-552 -- Loss: 0.11964903771877289
train-epoch-step: 110-553 -- Loss: 0.17628531157970428
train-epoch-step: 110-554 -- Loss: 0.17986467480659485
train-epoch-step: 110-555 -- Loss: 0.20303156971931458
train-epoch-step: 110-556 -- Loss: 0.13648231327533722
train-epoch-step: 110-557 -- Loss: 0.2273852825164795
train-epoch-step: 110-558 -- Loss: 0.2246694564819336
train-epoch-step: 110-559 -- Loss: 0.13219782710075378
train-epoch-step: 110-560 -- Loss: 0.20260858535766602
train-epoch-step: 110-561 -- Loss: 0.1750330626964569
train-epoch-step: 110-562 -- Loss: 0.1589847207069397
train-epoch-step: 110-563 -- Loss: 0.19706222414970398
train-epoch-step: 110-564 -- Loss: 0.09975342452526093
train-epoch-step: 110-565 -- Loss: 0.18474413454532623
train-epoch-step: 110-566 -- Loss: 0.15134258568286896
train-epoch-step: 110-567 -- Loss: 0.20501141250133514
train-epoch-step: 110-568 -- Loss: 0.1545819640159607
train-epoch-step: 110-569 -- Loss: 0.24045786261558533
train-epoch-step: 110-570 -- Loss: 0.1599627286195755
train-epoch-step: 110-571 -- Loss: 0.2026892900466919
train-epoch-step: 110-572 -- Loss: 0.23387140035629272
train-epoch-step: 110-573 -- Loss: 0.1969175934791565
train-epoch-step: 110-574 -- Loss: 0.2304111272096634
train-epoch-step: 110-575 -- Loss: 0.2896044850349426
train-epoch-step: 110-576 -- Loss: 0.11351314932107925
train-epoch-step: 110-577 -- Loss: 0.163074791431427
train-epoch-step: 110-578 -- Loss: 0.21236760914325714
train-epoch-step: 110-579 -- Loss: 0.1610778570175171
train-epoch-step: 110-580 -- Loss: 0.16816188395023346
train-epoch-step: 110-581 -- Loss: 0.1400758922100067
train-epoch-step: 110-582 -- Loss: 0.2032686173915863
train-epoch-step: 110-583 -- Loss: 0.20290738344192505
train-epoch-step: 110-584 -- Loss: 0.16876892745494843
train-epoch-step: 110-585 -- Loss: 0.18859338760375977
train-epoch-step: 110-586 -- Loss: 0.2985570430755615
train-epoch-step: 110-587 -- Loss: 0.17912672460079193
train-epoch-step: 110-588 -- Loss: 0.12386725842952728
val-epoch-step: 110-589 -- Loss: 0.20277948677539825
val-epoch-step: 110-590 -- Loss: 0.15601792931556702
val-epoch-step: 110-591 -- Loss: 0.23951175808906555
val-epoch-step: 110-592 -- Loss: 0.16807830333709717
val-epoch-step: 110-593 -- Loss: 0.1509981006383896
val-epoch-step: 110-594 -- Loss: 0.3959256112575531
val-epoch-step: 110-595 -- Loss: 0.17284341156482697
val-epoch-step: 110-596 -- Loss: 0.26718205213546753
val-epoch-step: 110-597 -- Loss: 0.1672733724117279
val-epoch-step: 110-598 -- Loss: 0.15058685839176178
val-epoch-step: 110-599 -- Loss: 0.18469959497451782
val-epoch-step: 110-600 -- Loss: 0.16337469220161438
val-epoch-step: 110-601 -- Loss: 0.15272819995880127
val-epoch-step: 110-602 -- Loss: 0.13279731571674347
val-epoch-step: 110-603 -- Loss: 0.22528767585754395
val-epoch-step: 110-604 -- Loss: 0.14678406715393066
val-epoch-step: 110-605 -- Loss: 0.1453983187675476
val-epoch-step: 110-606 -- Loss: 0.2478848397731781
val-epoch-step: 110-607 -- Loss: 0.1267206072807312
val-epoch-step: 110-608 -- Loss: 0.24568486213684082
val-epoch-step: 110-609 -- Loss: 0.16016903519630432
val-epoch-step: 110-610 -- Loss: 0.17715062201023102
val-epoch-step: 110-611 -- Loss: 0.1698019653558731
val-epoch-step: 110-612 -- Loss: 0.39389610290527344
val-epoch-step: 110-613 -- Loss: 0.17206509411334991
val-epoch-step: 110-614 -- Loss: 0.18699690699577332
val-epoch-step: 110-615 -- Loss: 0.16854390501976013
val-epoch-step: 110-616 -- Loss: 0.141937717795372
val-epoch-step: 110-617 -- Loss: 0.20911815762519836
val-epoch-step: 110-618 -- Loss: 0.18952760100364685
val-epoch-step: 110-619 -- Loss: 0.20262062549591064
val-epoch-step: 110-620 -- Loss: 0.13411685824394226
val-epoch-step: 110-621 -- Loss: 0.12366737425327301
val-epoch-step: 110-622 -- Loss: 0.1411561220884323
val-epoch-step: 110-623 -- Loss: 0.14660868048667908
val-epoch-step: 110-624 -- Loss: 0.14109277725219727
val-epoch-step: 110-625 -- Loss: 0.15122456848621368
val-epoch-step: 110-626 -- Loss: 0.14481261372566223
val-epoch-step: 110-627 -- Loss: 0.1777949035167694
val-epoch-step: 110-628 -- Loss: 0.5862047672271729
val-epoch-step: 110-629 -- Loss: 0.2853121757507324
val-epoch-step: 110-630 -- Loss: 0.34419548511505127
val-epoch-step: 110-631 -- Loss: 0.1637110561132431
val-epoch-step: 110-632 -- Loss: 0.19603709876537323
val-epoch-step: 110-633 -- Loss: 0.15722058713436127
val-epoch-step: 110-634 -- Loss: 0.14565549790859222
val-epoch-step: 110-635 -- Loss: 0.10977475345134735
val-epoch-step: 110-636 -- Loss: 0.16351142525672913
val-epoch-step: 110-637 -- Loss: 0.177792489528656
val-epoch-step: 110-638 -- Loss: 0.18519580364227295
val-epoch-step: 110-639 -- Loss: 0.25974130630493164
val-epoch-step: 110-640 -- Loss: 0.26134997606277466
val-epoch-step: 110-641 -- Loss: 0.12662769854068756
val-epoch-step: 110-642 -- Loss: 0.2074853777885437
val-epoch-step: 110-643 -- Loss: 0.19995859265327454
val-epoch-step: 110-644 -- Loss: 0.16147682070732117
val-epoch-step: 110-645 -- Loss: 0.21834993362426758
val-epoch-step: 110-646 -- Loss: 0.1362660527229309
val-epoch-step: 110-647 -- Loss: 0.13249672949314117
val-epoch-step: 110-648 -- Loss: 0.15094779431819916
val-epoch-step: 110-649 -- Loss: 0.2018243670463562
val-epoch-step: 110-650 -- Loss: 0.2470797747373581
val-epoch-step: 110-651 -- Loss: 0.1453215628862381
val-epoch-step: 110-652 -- Loss: 0.15003645420074463
val-epoch-step: 110-653 -- Loss: 0.19280469417572021
val-epoch-step: 110-654 -- Loss: 0.110990509390831
Epoch: 110 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 72.8 -- Val Loss: tensor(0.1415, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 72.8
                         Test Loss: 0.0 -- Test Acc: 72.8
train-epoch-step: 111-0 -- Loss: 0.21441979706287384
train-epoch-step: 111-1 -- Loss: 0.143241286277771
train-epoch-step: 111-2 -- Loss: 0.19651754200458527
train-epoch-step: 111-3 -- Loss: 0.1396998018026352
train-epoch-step: 111-4 -- Loss: 0.15687693655490875
train-epoch-step: 111-5 -- Loss: 0.1903260499238968
train-epoch-step: 111-6 -- Loss: 0.22238194942474365
train-epoch-step: 111-7 -- Loss: 0.16617046296596527
train-epoch-step: 111-8 -- Loss: 0.1701696217060089
train-epoch-step: 111-9 -- Loss: 0.23142322897911072
train-epoch-step: 111-10 -- Loss: 0.20123150944709778
train-epoch-step: 111-11 -- Loss: 0.19001507759094238
train-epoch-step: 111-12 -- Loss: 0.15498849749565125
train-epoch-step: 111-13 -- Loss: 0.17548397183418274
train-epoch-step: 111-14 -- Loss: 0.17017391324043274
train-epoch-step: 111-15 -- Loss: 0.17792198061943054
train-epoch-step: 111-16 -- Loss: 0.17148128151893616
train-epoch-step: 111-17 -- Loss: 0.22565296292304993
train-epoch-step: 111-18 -- Loss: 0.23897922039031982
train-epoch-step: 111-19 -- Loss: 0.12616713345050812
train-epoch-step: 111-20 -- Loss: 0.24326445162296295
train-epoch-step: 111-21 -- Loss: 0.24797609448432922
train-epoch-step: 111-22 -- Loss: 0.1382570117712021
train-epoch-step: 111-23 -- Loss: 0.13893753290176392
train-epoch-step: 111-24 -- Loss: 0.12201829254627228
train-epoch-step: 111-25 -- Loss: 0.22137966752052307
train-epoch-step: 111-26 -- Loss: 0.1952323466539383
train-epoch-step: 111-27 -- Loss: 0.2295723706483841
train-epoch-step: 111-28 -- Loss: 0.12483543157577515
train-epoch-step: 111-29 -- Loss: 0.24835743010044098
train-epoch-step: 111-30 -- Loss: 0.10713659226894379
train-epoch-step: 111-31 -- Loss: 0.13505928218364716
train-epoch-step: 111-32 -- Loss: 0.16802197694778442
train-epoch-step: 111-33 -- Loss: 0.2647784352302551
train-epoch-step: 111-34 -- Loss: 0.17349299788475037
train-epoch-step: 111-35 -- Loss: 0.24374234676361084
train-epoch-step: 111-36 -- Loss: 0.14608076214790344
train-epoch-step: 111-37 -- Loss: 0.13635650277137756
train-epoch-step: 111-38 -- Loss: 0.17367582023143768
train-epoch-step: 111-39 -- Loss: 0.2195105254650116
train-epoch-step: 111-40 -- Loss: 0.18711483478546143
train-epoch-step: 111-41 -- Loss: 0.20948056876659393
train-epoch-step: 111-42 -- Loss: 0.14253279566764832
train-epoch-step: 111-43 -- Loss: 0.25231465697288513
train-epoch-step: 111-44 -- Loss: 0.1243949681520462
train-epoch-step: 111-45 -- Loss: 0.11677341163158417
train-epoch-step: 111-46 -- Loss: 0.1686234176158905
train-epoch-step: 111-47 -- Loss: 0.19422301650047302
train-epoch-step: 111-48 -- Loss: 0.15409640967845917
train-epoch-step: 111-49 -- Loss: 0.2240632325410843
train-epoch-step: 111-50 -- Loss: 0.11433665454387665
train-epoch-step: 111-51 -- Loss: 0.1903257966041565
train-epoch-step: 111-52 -- Loss: 0.15130333602428436
train-epoch-step: 111-53 -- Loss: 0.25953757762908936
train-epoch-step: 111-54 -- Loss: 0.28034186363220215
train-epoch-step: 111-55 -- Loss: 0.16779959201812744
train-epoch-step: 111-56 -- Loss: 0.17284271121025085
train-epoch-step: 111-57 -- Loss: 0.2385333776473999
train-epoch-step: 111-58 -- Loss: 0.31087207794189453
train-epoch-step: 111-59 -- Loss: 0.27485135197639465
train-epoch-step: 111-60 -- Loss: 0.13099722564220428
train-epoch-step: 111-61 -- Loss: 0.19682002067565918
train-epoch-step: 111-62 -- Loss: 0.1905292272567749
train-epoch-step: 111-63 -- Loss: 0.15771806240081787
train-epoch-step: 111-64 -- Loss: 0.14846685528755188
train-epoch-step: 111-65 -- Loss: 0.17789916694164276
train-epoch-step: 111-66 -- Loss: 0.11426537483930588
train-epoch-step: 111-67 -- Loss: 0.1240994781255722
train-epoch-step: 111-68 -- Loss: 0.2148699015378952
train-epoch-step: 111-69 -- Loss: 0.126496821641922
train-epoch-step: 111-70 -- Loss: 0.22045773267745972
train-epoch-step: 111-71 -- Loss: 0.26882463693618774
train-epoch-step: 111-72 -- Loss: 0.1700976938009262
train-epoch-step: 111-73 -- Loss: 0.20765888690948486
train-epoch-step: 111-74 -- Loss: 0.09271034598350525
train-epoch-step: 111-75 -- Loss: 0.1255958378314972
train-epoch-step: 111-76 -- Loss: 0.1445469707250595
train-epoch-step: 111-77 -- Loss: 0.22576847672462463
train-epoch-step: 111-78 -- Loss: 0.25478726625442505
train-epoch-step: 111-79 -- Loss: 0.19139757752418518
train-epoch-step: 111-80 -- Loss: 0.24499325454235077
train-epoch-step: 111-81 -- Loss: 0.12078931927680969
train-epoch-step: 111-82 -- Loss: 0.24705266952514648
train-epoch-step: 111-83 -- Loss: 0.17714034020900726
train-epoch-step: 111-84 -- Loss: 0.17914769053459167
train-epoch-step: 111-85 -- Loss: 0.17102348804473877
train-epoch-step: 111-86 -- Loss: 0.11605797708034515
train-epoch-step: 111-87 -- Loss: 0.2033824324607849
train-epoch-step: 111-88 -- Loss: 0.13484308123588562
train-epoch-step: 111-89 -- Loss: 0.18148332834243774
train-epoch-step: 111-90 -- Loss: 0.18873882293701172
train-epoch-step: 111-91 -- Loss: 0.23606136441230774
train-epoch-step: 111-92 -- Loss: 0.1518332064151764
train-epoch-step: 111-93 -- Loss: 0.16742785274982452
train-epoch-step: 111-94 -- Loss: 0.21346740424633026
train-epoch-step: 111-95 -- Loss: 0.1865854561328888
train-epoch-step: 111-96 -- Loss: 0.20806503295898438
train-epoch-step: 111-97 -- Loss: 0.16950911283493042
train-epoch-step: 111-98 -- Loss: 0.15228044986724854
train-epoch-step: 111-99 -- Loss: 0.180250883102417
train-epoch-step: 111-100 -- Loss: 0.1816311776638031
train-epoch-step: 111-101 -- Loss: 0.2827123999595642
train-epoch-step: 111-102 -- Loss: 0.22125139832496643
train-epoch-step: 111-103 -- Loss: 0.17839403450489044
train-epoch-step: 111-104 -- Loss: 0.1438056379556656
train-epoch-step: 111-105 -- Loss: 0.25755876302719116
train-epoch-step: 111-106 -- Loss: 0.17494569718837738
train-epoch-step: 111-107 -- Loss: 0.18261604011058807
train-epoch-step: 111-108 -- Loss: 0.1855943202972412
train-epoch-step: 111-109 -- Loss: 0.14077579975128174
train-epoch-step: 111-110 -- Loss: 0.175085186958313
train-epoch-step: 111-111 -- Loss: 0.17613309621810913
train-epoch-step: 111-112 -- Loss: 0.16542254388332367
train-epoch-step: 111-113 -- Loss: 0.1589791178703308
train-epoch-step: 111-114 -- Loss: 0.19282323122024536
train-epoch-step: 111-115 -- Loss: 0.15810316801071167
train-epoch-step: 111-116 -- Loss: 0.13283061981201172
train-epoch-step: 111-117 -- Loss: 0.12527452409267426
train-epoch-step: 111-118 -- Loss: 0.1854507178068161
train-epoch-step: 111-119 -- Loss: 0.1512773633003235
train-epoch-step: 111-120 -- Loss: 0.23971480131149292
train-epoch-step: 111-121 -- Loss: 0.22787952423095703
train-epoch-step: 111-122 -- Loss: 0.21354928612709045
train-epoch-step: 111-123 -- Loss: 0.1926918625831604
train-epoch-step: 111-124 -- Loss: 0.11908188462257385
train-epoch-step: 111-125 -- Loss: 0.15008923411369324
train-epoch-step: 111-126 -- Loss: 0.22244969010353088
train-epoch-step: 111-127 -- Loss: 0.18411210179328918
train-epoch-step: 111-128 -- Loss: 0.16363729536533356
train-epoch-step: 111-129 -- Loss: 0.1521167755126953
train-epoch-step: 111-130 -- Loss: 0.18600338697433472
train-epoch-step: 111-131 -- Loss: 0.1301814466714859
train-epoch-step: 111-132 -- Loss: 0.18937362730503082
train-epoch-step: 111-133 -- Loss: 0.1167982965707779
train-epoch-step: 111-134 -- Loss: 0.19140321016311646
train-epoch-step: 111-135 -- Loss: 0.12964200973510742
train-epoch-step: 111-136 -- Loss: 0.12446580827236176
train-epoch-step: 111-137 -- Loss: 0.23637238144874573
train-epoch-step: 111-138 -- Loss: 0.25131165981292725
train-epoch-step: 111-139 -- Loss: 0.12598662078380585
train-epoch-step: 111-140 -- Loss: 0.20546773076057434
train-epoch-step: 111-141 -- Loss: 0.22451400756835938
train-epoch-step: 111-142 -- Loss: 0.2019595503807068
train-epoch-step: 111-143 -- Loss: 0.17134226858615875
train-epoch-step: 111-144 -- Loss: 0.17881369590759277
train-epoch-step: 111-145 -- Loss: 0.14549744129180908
train-epoch-step: 111-146 -- Loss: 0.167247474193573
train-epoch-step: 111-147 -- Loss: 0.165339395403862
train-epoch-step: 111-148 -- Loss: 0.16132467985153198
train-epoch-step: 111-149 -- Loss: 0.11294245719909668
train-epoch-step: 111-150 -- Loss: 0.17803281545639038
train-epoch-step: 111-151 -- Loss: 0.18522725999355316
train-epoch-step: 111-152 -- Loss: 0.1817149817943573
train-epoch-step: 111-153 -- Loss: 0.2653217613697052
train-epoch-step: 111-154 -- Loss: 0.13014647364616394
train-epoch-step: 111-155 -- Loss: 0.1365126371383667
train-epoch-step: 111-156 -- Loss: 0.11448574811220169
train-epoch-step: 111-157 -- Loss: 0.17021170258522034
train-epoch-step: 111-158 -- Loss: 0.15806427597999573
train-epoch-step: 111-159 -- Loss: 0.17655347287654877
train-epoch-step: 111-160 -- Loss: 0.20533564686775208
train-epoch-step: 111-161 -- Loss: 0.19844886660575867
train-epoch-step: 111-162 -- Loss: 0.20618079602718353
train-epoch-step: 111-163 -- Loss: 0.1918075680732727
train-epoch-step: 111-164 -- Loss: 0.1881750226020813
train-epoch-step: 111-165 -- Loss: 0.1579512357711792
train-epoch-step: 111-166 -- Loss: 0.11455845832824707
train-epoch-step: 111-167 -- Loss: 0.1258658617734909
train-epoch-step: 111-168 -- Loss: 0.19599443674087524
train-epoch-step: 111-169 -- Loss: 0.13319191336631775
train-epoch-step: 111-170 -- Loss: 0.19935771822929382
train-epoch-step: 111-171 -- Loss: 0.1421070396900177
train-epoch-step: 111-172 -- Loss: 0.2527782917022705
train-epoch-step: 111-173 -- Loss: 0.13344132900238037
train-epoch-step: 111-174 -- Loss: 0.24146099388599396
train-epoch-step: 111-175 -- Loss: 0.18221375346183777
train-epoch-step: 111-176 -- Loss: 0.12910452485084534
train-epoch-step: 111-177 -- Loss: 0.17480182647705078
train-epoch-step: 111-178 -- Loss: 0.17865076661109924
train-epoch-step: 111-179 -- Loss: 0.13842204213142395
train-epoch-step: 111-180 -- Loss: 0.14557960629463196
train-epoch-step: 111-181 -- Loss: 0.16427861154079437
train-epoch-step: 111-182 -- Loss: 0.18017464876174927
train-epoch-step: 111-183 -- Loss: 0.2646537721157074
train-epoch-step: 111-184 -- Loss: 0.133896142244339
train-epoch-step: 111-185 -- Loss: 0.14869652688503265
train-epoch-step: 111-186 -- Loss: 0.18854239583015442
train-epoch-step: 111-187 -- Loss: 0.20318636298179626
train-epoch-step: 111-188 -- Loss: 0.1753087341785431
train-epoch-step: 111-189 -- Loss: 0.10131798684597015
train-epoch-step: 111-190 -- Loss: 0.17687322199344635
train-epoch-step: 111-191 -- Loss: 0.15463751554489136
train-epoch-step: 111-192 -- Loss: 0.2194899171590805
train-epoch-step: 111-193 -- Loss: 0.19832248985767365
train-epoch-step: 111-194 -- Loss: 0.1782795786857605
train-epoch-step: 111-195 -- Loss: 0.1619173139333725
train-epoch-step: 111-196 -- Loss: 0.16600069403648376
train-epoch-step: 111-197 -- Loss: 0.12398489564657211
train-epoch-step: 111-198 -- Loss: 0.12524420022964478
train-epoch-step: 111-199 -- Loss: 0.14393799006938934
train-epoch-step: 111-200 -- Loss: 0.11959831416606903
train-epoch-step: 111-201 -- Loss: 0.18033172190189362
train-epoch-step: 111-202 -- Loss: 0.1328498274087906
train-epoch-step: 111-203 -- Loss: 0.1734238713979721
train-epoch-step: 111-204 -- Loss: 0.12784641981124878
train-epoch-step: 111-205 -- Loss: 0.18380966782569885
train-epoch-step: 111-206 -- Loss: 0.19356346130371094
train-epoch-step: 111-207 -- Loss: 0.12920691072940826
train-epoch-step: 111-208 -- Loss: 0.17211125791072845
train-epoch-step: 111-209 -- Loss: 0.14167557656764984
train-epoch-step: 111-210 -- Loss: 0.12823911011219025
train-epoch-step: 111-211 -- Loss: 0.19981649518013
train-epoch-step: 111-212 -- Loss: 0.19217990338802338
train-epoch-step: 111-213 -- Loss: 0.12550371885299683
train-epoch-step: 111-214 -- Loss: 0.13937346637248993
train-epoch-step: 111-215 -- Loss: 0.12250183522701263
train-epoch-step: 111-216 -- Loss: 0.19576022028923035
train-epoch-step: 111-217 -- Loss: 0.20637445151805878
train-epoch-step: 111-218 -- Loss: 0.13861609995365143
train-epoch-step: 111-219 -- Loss: 0.1620682030916214
train-epoch-step: 111-220 -- Loss: 0.12343411892652512
train-epoch-step: 111-221 -- Loss: 0.20090627670288086
train-epoch-step: 111-222 -- Loss: 0.10927048325538635
train-epoch-step: 111-223 -- Loss: 0.16801312565803528
train-epoch-step: 111-224 -- Loss: 0.1803506463766098
train-epoch-step: 111-225 -- Loss: 0.25527265667915344
train-epoch-step: 111-226 -- Loss: 0.20243677496910095
train-epoch-step: 111-227 -- Loss: 0.21402022242546082
train-epoch-step: 111-228 -- Loss: 0.17042480409145355
train-epoch-step: 111-229 -- Loss: 0.17159545421600342
train-epoch-step: 111-230 -- Loss: 0.15945735573768616
train-epoch-step: 111-231 -- Loss: 0.1508612185716629
train-epoch-step: 111-232 -- Loss: 0.17841972410678864
train-epoch-step: 111-233 -- Loss: 0.08386817574501038
train-epoch-step: 111-234 -- Loss: 0.16650459170341492
train-epoch-step: 111-235 -- Loss: 0.1387157440185547
train-epoch-step: 111-236 -- Loss: 0.17400561273097992
train-epoch-step: 111-237 -- Loss: 0.22485418617725372
train-epoch-step: 111-238 -- Loss: 0.15488970279693604
train-epoch-step: 111-239 -- Loss: 0.12399975955486298
train-epoch-step: 111-240 -- Loss: 0.21730977296829224
train-epoch-step: 111-241 -- Loss: 0.14738504588603973
train-epoch-step: 111-242 -- Loss: 0.21196910738945007
train-epoch-step: 111-243 -- Loss: 0.23417964577674866
train-epoch-step: 111-244 -- Loss: 0.20452359318733215
train-epoch-step: 111-245 -- Loss: 0.20089511573314667
train-epoch-step: 111-246 -- Loss: 0.20970243215560913
train-epoch-step: 111-247 -- Loss: 0.22390183806419373
train-epoch-step: 111-248 -- Loss: 0.18141861259937286
train-epoch-step: 111-249 -- Loss: 0.14757078886032104
train-epoch-step: 111-250 -- Loss: 0.19107916951179504
train-epoch-step: 111-251 -- Loss: 0.10205920040607452
train-epoch-step: 111-252 -- Loss: 0.18432998657226562
train-epoch-step: 111-253 -- Loss: 0.13620805740356445
train-epoch-step: 111-254 -- Loss: 0.20593777298927307
train-epoch-step: 111-255 -- Loss: 0.13737602531909943
train-epoch-step: 111-256 -- Loss: 0.15221631526947021
train-epoch-step: 111-257 -- Loss: 0.18625913560390472
train-epoch-step: 111-258 -- Loss: 0.13742627203464508
train-epoch-step: 111-259 -- Loss: 0.10976945608854294
train-epoch-step: 111-260 -- Loss: 0.19232222437858582
train-epoch-step: 111-261 -- Loss: 0.16706028580665588
train-epoch-step: 111-262 -- Loss: 0.27141615748405457
train-epoch-step: 111-263 -- Loss: 0.19300763309001923
train-epoch-step: 111-264 -- Loss: 0.16931873559951782
train-epoch-step: 111-265 -- Loss: 0.10693595558404922
train-epoch-step: 111-266 -- Loss: 0.14719527959823608
train-epoch-step: 111-267 -- Loss: 0.12499402463436127
train-epoch-step: 111-268 -- Loss: 0.11566752195358276
train-epoch-step: 111-269 -- Loss: 0.16501998901367188
train-epoch-step: 111-270 -- Loss: 0.1066753938794136
train-epoch-step: 111-271 -- Loss: 0.14138013124465942
train-epoch-step: 111-272 -- Loss: 0.11428044736385345
train-epoch-step: 111-273 -- Loss: 0.12168833613395691
train-epoch-step: 111-274 -- Loss: 0.17751334607601166
train-epoch-step: 111-275 -- Loss: 0.18876619637012482
train-epoch-step: 111-276 -- Loss: 0.14825782179832458
train-epoch-step: 111-277 -- Loss: 0.148032546043396
train-epoch-step: 111-278 -- Loss: 0.1404687762260437
train-epoch-step: 111-279 -- Loss: 0.1337575614452362
train-epoch-step: 111-280 -- Loss: 0.20671427249908447
train-epoch-step: 111-281 -- Loss: 0.1707797348499298
train-epoch-step: 111-282 -- Loss: 0.1357015073299408
train-epoch-step: 111-283 -- Loss: 0.1117836982011795
train-epoch-step: 111-284 -- Loss: 0.14166377484798431
train-epoch-step: 111-285 -- Loss: 0.18357689678668976
train-epoch-step: 111-286 -- Loss: 0.14664573967456818
train-epoch-step: 111-287 -- Loss: 0.19238850474357605
train-epoch-step: 111-288 -- Loss: 0.09080145508050919
train-epoch-step: 111-289 -- Loss: 0.11127309501171112
train-epoch-step: 111-290 -- Loss: 0.17440026998519897
train-epoch-step: 111-291 -- Loss: 0.11326596885919571
train-epoch-step: 111-292 -- Loss: 0.14686332643032074
train-epoch-step: 111-293 -- Loss: 0.13179056346416473
train-epoch-step: 111-294 -- Loss: 0.1536174863576889
train-epoch-step: 111-295 -- Loss: 0.250295490026474
train-epoch-step: 111-296 -- Loss: 0.15072235465049744
train-epoch-step: 111-297 -- Loss: 0.16531714797019958
train-epoch-step: 111-298 -- Loss: 0.22095464169979095
train-epoch-step: 111-299 -- Loss: 0.13827656209468842
train-epoch-step: 111-300 -- Loss: 0.1571519821882248
train-epoch-step: 111-301 -- Loss: 0.16325588524341583
train-epoch-step: 111-302 -- Loss: 0.20601260662078857
train-epoch-step: 111-303 -- Loss: 0.19703999161720276
train-epoch-step: 111-304 -- Loss: 0.11753804981708527
train-epoch-step: 111-305 -- Loss: 0.1402532309293747
train-epoch-step: 111-306 -- Loss: 0.2051236778497696
train-epoch-step: 111-307 -- Loss: 0.1568085253238678
train-epoch-step: 111-308 -- Loss: 0.21331486105918884
train-epoch-step: 111-309 -- Loss: 0.14992502331733704
train-epoch-step: 111-310 -- Loss: 0.1531560719013214
train-epoch-step: 111-311 -- Loss: 0.15563462674617767
train-epoch-step: 111-312 -- Loss: 0.19453008472919464
train-epoch-step: 111-313 -- Loss: 0.09238860011100769
train-epoch-step: 111-314 -- Loss: 0.18693146109580994
train-epoch-step: 111-315 -- Loss: 0.159488707780838
train-epoch-step: 111-316 -- Loss: 0.14462117850780487
train-epoch-step: 111-317 -- Loss: 0.13238617777824402
train-epoch-step: 111-318 -- Loss: 0.14922386407852173
train-epoch-step: 111-319 -- Loss: 0.16168704628944397
train-epoch-step: 111-320 -- Loss: 0.11273710429668427
train-epoch-step: 111-321 -- Loss: 0.12895286083221436
train-epoch-step: 111-322 -- Loss: 0.20581980049610138
train-epoch-step: 111-323 -- Loss: 0.15686894953250885
train-epoch-step: 111-324 -- Loss: 0.24677547812461853
train-epoch-step: 111-325 -- Loss: 0.1481160670518875
train-epoch-step: 111-326 -- Loss: 0.16457587480545044
train-epoch-step: 111-327 -- Loss: 0.2042306810617447
train-epoch-step: 111-328 -- Loss: 0.18567219376564026
train-epoch-step: 111-329 -- Loss: 0.3362613916397095
train-epoch-step: 111-330 -- Loss: 0.3447645902633667
train-epoch-step: 111-331 -- Loss: 0.2010270655155182
train-epoch-step: 111-332 -- Loss: 0.09568290412425995
train-epoch-step: 111-333 -- Loss: 0.1732897013425827
train-epoch-step: 111-334 -- Loss: 0.14994922280311584
train-epoch-step: 111-335 -- Loss: 0.1693469136953354
train-epoch-step: 111-336 -- Loss: 0.13812826573848724
train-epoch-step: 111-337 -- Loss: 0.20173832774162292
train-epoch-step: 111-338 -- Loss: 0.157578706741333
train-epoch-step: 111-339 -- Loss: 0.1383470743894577
train-epoch-step: 111-340 -- Loss: 0.19020205736160278
train-epoch-step: 111-341 -- Loss: 0.13585379719734192
train-epoch-step: 111-342 -- Loss: 0.1547962874174118
train-epoch-step: 111-343 -- Loss: 0.14557945728302002
train-epoch-step: 111-344 -- Loss: 0.16408757865428925
train-epoch-step: 111-345 -- Loss: 0.12580633163452148
train-epoch-step: 111-346 -- Loss: 0.21573181450366974
train-epoch-step: 111-347 -- Loss: 0.1514023244380951
train-epoch-step: 111-348 -- Loss: 0.19845548272132874
train-epoch-step: 111-349 -- Loss: 0.19794362783432007
train-epoch-step: 111-350 -- Loss: 0.264518141746521
train-epoch-step: 111-351 -- Loss: 0.19009657204151154
train-epoch-step: 111-352 -- Loss: 0.11938408017158508
train-epoch-step: 111-353 -- Loss: 0.19043000042438507
train-epoch-step: 111-354 -- Loss: 0.27250808477401733
train-epoch-step: 111-355 -- Loss: 0.1148158460855484
train-epoch-step: 111-356 -- Loss: 0.110294871032238
train-epoch-step: 111-357 -- Loss: 0.1836307793855667
train-epoch-step: 111-358 -- Loss: 0.18457099795341492
train-epoch-step: 111-359 -- Loss: 0.135691836476326
train-epoch-step: 111-360 -- Loss: 0.11797010153532028
train-epoch-step: 111-361 -- Loss: 0.2615276873111725
train-epoch-step: 111-362 -- Loss: 0.16286872327327728
train-epoch-step: 111-363 -- Loss: 0.10821080952882767
train-epoch-step: 111-364 -- Loss: 0.17888620495796204
train-epoch-step: 111-365 -- Loss: 0.16324034333229065
train-epoch-step: 111-366 -- Loss: 0.19625583291053772
train-epoch-step: 111-367 -- Loss: 0.22986584901809692
train-epoch-step: 111-368 -- Loss: 0.19308580458164215
train-epoch-step: 111-369 -- Loss: 0.2736239433288574
train-epoch-step: 111-370 -- Loss: 0.12122569233179092
train-epoch-step: 111-371 -- Loss: 0.11848665773868561
train-epoch-step: 111-372 -- Loss: 0.1482824981212616
train-epoch-step: 111-373 -- Loss: 0.1873425841331482
train-epoch-step: 111-374 -- Loss: 0.15293456614017487
train-epoch-step: 111-375 -- Loss: 0.2587932348251343
train-epoch-step: 111-376 -- Loss: 0.1571808010339737
train-epoch-step: 111-377 -- Loss: 0.21334120631217957
train-epoch-step: 111-378 -- Loss: 0.196174755692482
train-epoch-step: 111-379 -- Loss: 0.11488574743270874
train-epoch-step: 111-380 -- Loss: 0.089692123234272
train-epoch-step: 111-381 -- Loss: 0.2342253029346466
train-epoch-step: 111-382 -- Loss: 0.23310327529907227
train-epoch-step: 111-383 -- Loss: 0.16775259375572205
train-epoch-step: 111-384 -- Loss: 0.20305827260017395
train-epoch-step: 111-385 -- Loss: 0.18226711452007294
train-epoch-step: 111-386 -- Loss: 0.18236973881721497
train-epoch-step: 111-387 -- Loss: 0.19630122184753418
train-epoch-step: 111-388 -- Loss: 0.17865294218063354
train-epoch-step: 111-389 -- Loss: 0.15984414517879486
train-epoch-step: 111-390 -- Loss: 0.14241182804107666
train-epoch-step: 111-391 -- Loss: 0.1404280811548233
train-epoch-step: 111-392 -- Loss: 0.1784788817167282
train-epoch-step: 111-393 -- Loss: 0.15094789862632751
train-epoch-step: 111-394 -- Loss: 0.19301815330982208
train-epoch-step: 111-395 -- Loss: 0.14894865453243256
train-epoch-step: 111-396 -- Loss: 0.12354594469070435
train-epoch-step: 111-397 -- Loss: 0.1193438470363617
train-epoch-step: 111-398 -- Loss: 0.19061820209026337
train-epoch-step: 111-399 -- Loss: 0.17698784172534943
train-epoch-step: 111-400 -- Loss: 0.2700892686843872
train-epoch-step: 111-401 -- Loss: 0.11821712553501129
train-epoch-step: 111-402 -- Loss: 0.25221890211105347
train-epoch-step: 111-403 -- Loss: 0.1647329330444336
train-epoch-step: 111-404 -- Loss: 0.13602811098098755
train-epoch-step: 111-405 -- Loss: 0.1402491331100464
train-epoch-step: 111-406 -- Loss: 0.16723676025867462
train-epoch-step: 111-407 -- Loss: 0.11104807257652283
train-epoch-step: 111-408 -- Loss: 0.15785233676433563
train-epoch-step: 111-409 -- Loss: 0.16355572640895844
train-epoch-step: 111-410 -- Loss: 0.1721474826335907
train-epoch-step: 111-411 -- Loss: 0.19036775827407837
train-epoch-step: 111-412 -- Loss: 0.1315290331840515
train-epoch-step: 111-413 -- Loss: 0.1435944139957428
train-epoch-step: 111-414 -- Loss: 0.12797223031520844
train-epoch-step: 111-415 -- Loss: 0.1305975317955017
train-epoch-step: 111-416 -- Loss: 0.2537025511264801
train-epoch-step: 111-417 -- Loss: 0.18663476407527924
train-epoch-step: 111-418 -- Loss: 0.21900098025798798
train-epoch-step: 111-419 -- Loss: 0.16127806901931763
train-epoch-step: 111-420 -- Loss: 0.14753782749176025
train-epoch-step: 111-421 -- Loss: 0.17902275919914246
train-epoch-step: 111-422 -- Loss: 0.14492930471897125
train-epoch-step: 111-423 -- Loss: 0.16894368827342987
train-epoch-step: 111-424 -- Loss: 0.13260573148727417
train-epoch-step: 111-425 -- Loss: 0.17674842476844788
train-epoch-step: 111-426 -- Loss: 0.1570722609758377
train-epoch-step: 111-427 -- Loss: 0.11508101969957352
train-epoch-step: 111-428 -- Loss: 0.18923504650592804
train-epoch-step: 111-429 -- Loss: 0.1682972013950348
train-epoch-step: 111-430 -- Loss: 0.1344330757856369
train-epoch-step: 111-431 -- Loss: 0.15647730231285095
train-epoch-step: 111-432 -- Loss: 0.22968845069408417
train-epoch-step: 111-433 -- Loss: 0.13211046159267426
train-epoch-step: 111-434 -- Loss: 0.11984239518642426
train-epoch-step: 111-435 -- Loss: 0.14816534519195557
train-epoch-step: 111-436 -- Loss: 0.14910699427127838
train-epoch-step: 111-437 -- Loss: 0.12542888522148132
train-epoch-step: 111-438 -- Loss: 0.16267524659633636
train-epoch-step: 111-439 -- Loss: 0.2520996034145355
train-epoch-step: 111-440 -- Loss: 0.12588465213775635
train-epoch-step: 111-441 -- Loss: 0.19204355776309967
train-epoch-step: 111-442 -- Loss: 0.16959743201732635
train-epoch-step: 111-443 -- Loss: 0.15020878612995148
train-epoch-step: 111-444 -- Loss: 0.16758312284946442
train-epoch-step: 111-445 -- Loss: 0.17140306532382965
train-epoch-step: 111-446 -- Loss: 0.15017379820346832
train-epoch-step: 111-447 -- Loss: 0.18279075622558594
train-epoch-step: 111-448 -- Loss: 0.2145979255437851
train-epoch-step: 111-449 -- Loss: 0.18342450261116028
train-epoch-step: 111-450 -- Loss: 0.17423154413700104
train-epoch-step: 111-451 -- Loss: 0.13447557389736176
train-epoch-step: 111-452 -- Loss: 0.12423711270093918
train-epoch-step: 111-453 -- Loss: 0.08515997976064682
train-epoch-step: 111-454 -- Loss: 0.21870917081832886
train-epoch-step: 111-455 -- Loss: 0.11646866053342819
train-epoch-step: 111-456 -- Loss: 0.11371933668851852
train-epoch-step: 111-457 -- Loss: 0.2060076892375946
train-epoch-step: 111-458 -- Loss: 0.14063876867294312
train-epoch-step: 111-459 -- Loss: 0.201633483171463
train-epoch-step: 111-460 -- Loss: 0.1164562776684761
train-epoch-step: 111-461 -- Loss: 0.13086941838264465
train-epoch-step: 111-462 -- Loss: 0.14774903655052185
train-epoch-step: 111-463 -- Loss: 0.12849649786949158
train-epoch-step: 111-464 -- Loss: 0.18567293882369995
train-epoch-step: 111-465 -- Loss: 0.22518576681613922
train-epoch-step: 111-466 -- Loss: 0.1912740021944046
train-epoch-step: 111-467 -- Loss: 0.10903678834438324
train-epoch-step: 111-468 -- Loss: 0.15871375799179077
train-epoch-step: 111-469 -- Loss: 0.19973689317703247
train-epoch-step: 111-470 -- Loss: 0.16246281564235687
train-epoch-step: 111-471 -- Loss: 0.15726464986801147
train-epoch-step: 111-472 -- Loss: 0.1524217426776886
train-epoch-step: 111-473 -- Loss: 0.15083912014961243
train-epoch-step: 111-474 -- Loss: 0.12160904705524445
train-epoch-step: 111-475 -- Loss: 0.10704796016216278
train-epoch-step: 111-476 -- Loss: 0.21051102876663208
train-epoch-step: 111-477 -- Loss: 0.19117578864097595
train-epoch-step: 111-478 -- Loss: 0.1825258582830429
train-epoch-step: 111-479 -- Loss: 0.1363658457994461
train-epoch-step: 111-480 -- Loss: 0.19112449884414673
train-epoch-step: 111-481 -- Loss: 0.2775990962982178
train-epoch-step: 111-482 -- Loss: 0.24536609649658203
train-epoch-step: 111-483 -- Loss: 0.1729062795639038
train-epoch-step: 111-484 -- Loss: 0.20583871006965637
train-epoch-step: 111-485 -- Loss: 0.12382330745458603
train-epoch-step: 111-486 -- Loss: 0.21655994653701782
train-epoch-step: 111-487 -- Loss: 0.2278386652469635
train-epoch-step: 111-488 -- Loss: 0.18384332954883575
train-epoch-step: 111-489 -- Loss: 0.21258392930030823
train-epoch-step: 111-490 -- Loss: 0.13118073344230652
train-epoch-step: 111-491 -- Loss: 0.13273347914218903
train-epoch-step: 111-492 -- Loss: 0.12303240597248077
train-epoch-step: 111-493 -- Loss: 0.209917813539505
train-epoch-step: 111-494 -- Loss: 0.19954589009284973
train-epoch-step: 111-495 -- Loss: 0.19588123261928558
train-epoch-step: 111-496 -- Loss: 0.1450517773628235
train-epoch-step: 111-497 -- Loss: 0.1740339994430542
train-epoch-step: 111-498 -- Loss: 0.15099334716796875
train-epoch-step: 111-499 -- Loss: 0.16177333891391754
train-epoch-step: 111-500 -- Loss: 0.14848466217517853
train-epoch-step: 111-501 -- Loss: 0.20653751492500305
train-epoch-step: 111-502 -- Loss: 0.18202775716781616
train-epoch-step: 111-503 -- Loss: 0.2059527188539505
train-epoch-step: 111-504 -- Loss: 0.12231364846229553
train-epoch-step: 111-505 -- Loss: 0.16820378601551056
train-epoch-step: 111-506 -- Loss: 0.11193376779556274
train-epoch-step: 111-507 -- Loss: 0.17523761093616486
train-epoch-step: 111-508 -- Loss: 0.17811676859855652
train-epoch-step: 111-509 -- Loss: 0.162626713514328
train-epoch-step: 111-510 -- Loss: 0.12614989280700684
train-epoch-step: 111-511 -- Loss: 0.2132454216480255
train-epoch-step: 111-512 -- Loss: 0.17262448370456696
train-epoch-step: 111-513 -- Loss: 0.1865302175283432
train-epoch-step: 111-514 -- Loss: 0.14229930937290192
train-epoch-step: 111-515 -- Loss: 0.158695250749588
train-epoch-step: 111-516 -- Loss: 0.16705003380775452
train-epoch-step: 111-517 -- Loss: 0.16682317852973938
train-epoch-step: 111-518 -- Loss: 0.1392594277858734
train-epoch-step: 111-519 -- Loss: 0.12779393792152405
train-epoch-step: 111-520 -- Loss: 0.18034349381923676
train-epoch-step: 111-521 -- Loss: 0.22338923811912537
train-epoch-step: 111-522 -- Loss: 0.1647602617740631
train-epoch-step: 111-523 -- Loss: 0.15510167181491852
train-epoch-step: 111-524 -- Loss: 0.15752892196178436
train-epoch-step: 111-525 -- Loss: 0.18529564142227173
train-epoch-step: 111-526 -- Loss: 0.12716074287891388
train-epoch-step: 111-527 -- Loss: 0.1457630693912506
train-epoch-step: 111-528 -- Loss: 0.1515982747077942
train-epoch-step: 111-529 -- Loss: 0.16347484290599823
train-epoch-step: 111-530 -- Loss: 0.1643655151128769
train-epoch-step: 111-531 -- Loss: 0.18349434435367584
train-epoch-step: 111-532 -- Loss: 0.16257381439208984
train-epoch-step: 111-533 -- Loss: 0.17079922556877136
train-epoch-step: 111-534 -- Loss: 0.12442823499441147
train-epoch-step: 111-535 -- Loss: 0.23970791697502136
train-epoch-step: 111-536 -- Loss: 0.14998574554920197
train-epoch-step: 111-537 -- Loss: 0.14118289947509766
train-epoch-step: 111-538 -- Loss: 0.10067640244960785
train-epoch-step: 111-539 -- Loss: 0.17655086517333984
train-epoch-step: 111-540 -- Loss: 0.13271686434745789
train-epoch-step: 111-541 -- Loss: 0.20256944000720978
train-epoch-step: 111-542 -- Loss: 0.21456247568130493
train-epoch-step: 111-543 -- Loss: 0.15906864404678345
train-epoch-step: 111-544 -- Loss: 0.21954968571662903
train-epoch-step: 111-545 -- Loss: 0.18694618344306946
train-epoch-step: 111-546 -- Loss: 0.19367322325706482
train-epoch-step: 111-547 -- Loss: 0.17899799346923828
train-epoch-step: 111-548 -- Loss: 0.0857963114976883
train-epoch-step: 111-549 -- Loss: 0.14095371961593628
train-epoch-step: 111-550 -- Loss: 0.19236455857753754
train-epoch-step: 111-551 -- Loss: 0.14231401681900024
train-epoch-step: 111-552 -- Loss: 0.12125392258167267
train-epoch-step: 111-553 -- Loss: 0.17871558666229248
train-epoch-step: 111-554 -- Loss: 0.17559827864170074
train-epoch-step: 111-555 -- Loss: 0.20970138907432556
train-epoch-step: 111-556 -- Loss: 0.14333096146583557
train-epoch-step: 111-557 -- Loss: 0.22494934499263763
train-epoch-step: 111-558 -- Loss: 0.21583345532417297
train-epoch-step: 111-559 -- Loss: 0.1296108365058899
train-epoch-step: 111-560 -- Loss: 0.1984020471572876
train-epoch-step: 111-561 -- Loss: 0.17088624835014343
train-epoch-step: 111-562 -- Loss: 0.15737012028694153
train-epoch-step: 111-563 -- Loss: 0.17693212628364563
train-epoch-step: 111-564 -- Loss: 0.09568168222904205
train-epoch-step: 111-565 -- Loss: 0.18287460505962372
train-epoch-step: 111-566 -- Loss: 0.14081470668315887
train-epoch-step: 111-567 -- Loss: 0.19852307438850403
train-epoch-step: 111-568 -- Loss: 0.15273089706897736
train-epoch-step: 111-569 -- Loss: 0.24215738475322723
train-epoch-step: 111-570 -- Loss: 0.15720991790294647
train-epoch-step: 111-571 -- Loss: 0.2027384638786316
train-epoch-step: 111-572 -- Loss: 0.22791078686714172
train-epoch-step: 111-573 -- Loss: 0.19263464212417603
train-epoch-step: 111-574 -- Loss: 0.23160269856452942
train-epoch-step: 111-575 -- Loss: 0.27794408798217773
train-epoch-step: 111-576 -- Loss: 0.11266008764505386
train-epoch-step: 111-577 -- Loss: 0.163030207157135
train-epoch-step: 111-578 -- Loss: 0.21214841306209564
train-epoch-step: 111-579 -- Loss: 0.16077634692192078
train-epoch-step: 111-580 -- Loss: 0.16546455025672913
train-epoch-step: 111-581 -- Loss: 0.13449019193649292
train-epoch-step: 111-582 -- Loss: 0.20111019909381866
train-epoch-step: 111-583 -- Loss: 0.20549461245536804
train-epoch-step: 111-584 -- Loss: 0.1607894003391266
train-epoch-step: 111-585 -- Loss: 0.1850409209728241
train-epoch-step: 111-586 -- Loss: 0.24533063173294067
train-epoch-step: 111-587 -- Loss: 0.15617774426937103
train-epoch-step: 111-588 -- Loss: 0.12441235035657883
val-epoch-step: 111-589 -- Loss: 0.20835109055042267
val-epoch-step: 111-590 -- Loss: 0.15255063772201538
val-epoch-step: 111-591 -- Loss: 0.2353910207748413
val-epoch-step: 111-592 -- Loss: 0.17152675986289978
val-epoch-step: 111-593 -- Loss: 0.18068565428256989
val-epoch-step: 111-594 -- Loss: 0.3706241548061371
val-epoch-step: 111-595 -- Loss: 0.1647791862487793
val-epoch-step: 111-596 -- Loss: 0.1969924420118332
val-epoch-step: 111-597 -- Loss: 0.17028653621673584
val-epoch-step: 111-598 -- Loss: 0.14244577288627625
val-epoch-step: 111-599 -- Loss: 0.1805172860622406
val-epoch-step: 111-600 -- Loss: 0.1656714677810669
val-epoch-step: 111-601 -- Loss: 0.15185457468032837
val-epoch-step: 111-602 -- Loss: 0.13254883885383606
val-epoch-step: 111-603 -- Loss: 0.201211616396904
val-epoch-step: 111-604 -- Loss: 0.14745363593101501
val-epoch-step: 111-605 -- Loss: 0.1456746608018875
val-epoch-step: 111-606 -- Loss: 0.24493351578712463
val-epoch-step: 111-607 -- Loss: 0.1346229761838913
val-epoch-step: 111-608 -- Loss: 0.24762994050979614
val-epoch-step: 111-609 -- Loss: 0.16328434646129608
val-epoch-step: 111-610 -- Loss: 0.17223897576332092
val-epoch-step: 111-611 -- Loss: 0.1602221131324768
val-epoch-step: 111-612 -- Loss: 0.37005770206451416
val-epoch-step: 111-613 -- Loss: 0.17381799221038818
val-epoch-step: 111-614 -- Loss: 0.16320480406284332
val-epoch-step: 111-615 -- Loss: 0.1677500456571579
val-epoch-step: 111-616 -- Loss: 0.149481400847435
val-epoch-step: 111-617 -- Loss: 0.19722244143486023
val-epoch-step: 111-618 -- Loss: 0.1967204362154007
val-epoch-step: 111-619 -- Loss: 0.19712220132350922
val-epoch-step: 111-620 -- Loss: 0.12967947125434875
val-epoch-step: 111-621 -- Loss: 0.1210821121931076
val-epoch-step: 111-622 -- Loss: 0.13918374478816986
val-epoch-step: 111-623 -- Loss: 0.14643363654613495
val-epoch-step: 111-624 -- Loss: 0.14010299742221832
val-epoch-step: 111-625 -- Loss: 0.15657052397727966
val-epoch-step: 111-626 -- Loss: 0.1476026028394699
val-epoch-step: 111-627 -- Loss: 0.17776590585708618
val-epoch-step: 111-628 -- Loss: 0.6158153414726257
val-epoch-step: 111-629 -- Loss: 0.21628475189208984
val-epoch-step: 111-630 -- Loss: 0.3396008014678955
val-epoch-step: 111-631 -- Loss: 0.13582868874073029
val-epoch-step: 111-632 -- Loss: 0.19722500443458557
val-epoch-step: 111-633 -- Loss: 0.1509038805961609
val-epoch-step: 111-634 -- Loss: 0.1321883499622345
val-epoch-step: 111-635 -- Loss: 0.11021553725004196
val-epoch-step: 111-636 -- Loss: 0.16371604800224304
val-epoch-step: 111-637 -- Loss: 0.17787455022335052
val-epoch-step: 111-638 -- Loss: 0.16005420684814453
val-epoch-step: 111-639 -- Loss: 0.2515924274921417
val-epoch-step: 111-640 -- Loss: 0.24140611290931702
val-epoch-step: 111-641 -- Loss: 0.12984278798103333
val-epoch-step: 111-642 -- Loss: 0.17311209440231323
val-epoch-step: 111-643 -- Loss: 0.20444896817207336
val-epoch-step: 111-644 -- Loss: 0.16043873131275177
val-epoch-step: 111-645 -- Loss: 0.21134409308433533
val-epoch-step: 111-646 -- Loss: 0.12771782279014587
val-epoch-step: 111-647 -- Loss: 0.12223655730485916
val-epoch-step: 111-648 -- Loss: 0.14856600761413574
val-epoch-step: 111-649 -- Loss: 0.20906813442707062
val-epoch-step: 111-650 -- Loss: 0.24077659845352173
val-epoch-step: 111-651 -- Loss: 0.14801360666751862
val-epoch-step: 111-652 -- Loss: 0.14741481840610504
val-epoch-step: 111-653 -- Loss: 0.1921483278274536
val-epoch-step: 111-654 -- Loss: 0.10857820510864258
Epoch: 111 -- Train Loss: tensor(0.1386, device='cuda:0', grad_fn=<DivBackward0>) -- Train Acc: 75.58 -- Val Loss: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>) -- Val Acc: 75.58
                         Test Loss: 0.0 -- Test Acc: 75.58
train-epoch-step: 112-0 -- Loss: 0.2218329906463623
train-epoch-step: 112-1 -- Loss: 0.13746525347232819
train-epoch-step: 112-2 -- Loss: 0.19345024228096008
train-epoch-step: 112-3 -- Loss: 0.14036309719085693
train-epoch-step: 112-4 -- Loss: 0.16251693665981293
train-epoch-step: 112-5 -- Loss: 0.17577840387821198
train-epoch-step: 112-6 -- Loss: 0.2020236849784851
train-epoch-step: 112-7 -- Loss: 0.1601840704679489
train-epoch-step: 112-8 -- Loss: 0.19732865691184998
train-epoch-step: 112-9 -- Loss: 0.21189512312412262
train-epoch-step: 112-10 -- Loss: 0.18245741724967957
train-epoch-step: 112-11 -- Loss: 0.18182110786437988
train-epoch-step: 112-12 -- Loss: 0.14344936609268188
train-epoch-step: 112-13 -- Loss: 0.1714344620704651
train-epoch-step: 112-14 -- Loss: 0.16075783967971802
train-epoch-step: 112-15 -- Loss: 0.15534822642803192
train-epoch-step: 112-16 -- Loss: 0.1692972034215927
train-epoch-step: 112-17 -- Loss: 0.2174474447965622
train-epoch-step: 112-18 -- Loss: 0.18905308842658997
train-epoch-step: 112-19 -- Loss: 0.12812593579292297
train-epoch-step: 112-20 -- Loss: 0.20672200620174408
train-epoch-step: 112-21 -- Loss: 0.23457613587379456
train-epoch-step: 112-22 -- Loss: 0.13700197637081146
train-epoch-step: 112-23 -- Loss: 0.13673731684684753
train-epoch-step: 112-24 -- Loss: 0.11973370611667633
train-epoch-step: 112-25 -- Loss: 0.21294376254081726
train-epoch-step: 112-26 -- Loss: 0.18870732188224792
train-epoch-step: 112-27 -- Loss: 0.21466051042079926
train-epoch-step: 112-28 -- Loss: 0.12004884332418442
train-epoch-step: 112-29 -- Loss: 0.23269233107566833
train-epoch-step: 112-30 -- Loss: 0.10585588961839676
train-epoch-step: 112-31 -- Loss: 0.1266082376241684
train-epoch-step: 112-32 -- Loss: 0.16908226907253265
train-epoch-step: 112-33 -- Loss: 0.2671896517276764
train-epoch-step: 112-34 -- Loss: 0.16811423003673553
train-epoch-step: 112-35 -- Loss: 0.23449724912643433
train-epoch-step: 112-36 -- Loss: 0.13178175687789917
train-epoch-step: 112-37 -- Loss: 0.14107264578342438
train-epoch-step: 112-38 -- Loss: 0.16694557666778564
train-epoch-step: 112-39 -- Loss: 0.20869708061218262
train-epoch-step: 112-40 -- Loss: 0.18554191291332245
train-epoch-step: 112-41 -- Loss: 0.2101081758737564
train-epoch-step: 112-42 -- Loss: 0.14614397287368774
train-epoch-step: 112-43 -- Loss: 0.24898377060890198
train-epoch-step: 112-44 -- Loss: 0.12312149256467819
train-epoch-step: 112-45 -- Loss: 0.10854431986808777
train-epoch-step: 112-46 -- Loss: 0.16470201313495636
train-epoch-step: 112-47 -- Loss: 0.19244524836540222
train-epoch-step: 112-48 -- Loss: 0.15221662819385529
train-epoch-step: 112-49 -- Loss: 0.2179231196641922
train-epoch-step: 112-50 -- Loss: 0.10582321882247925
train-epoch-step: 112-51 -- Loss: 0.1670173555612564
train-epoch-step: 112-52 -- Loss: 0.1523265540599823
train-epoch-step: 112-53 -- Loss: 0.19781748950481415
train-epoch-step: 112-54 -- Loss: 0.2846108078956604
train-epoch-step: 112-55 -- Loss: 0.15911521017551422
train-epoch-step: 112-56 -- Loss: 0.16788454353809357
train-epoch-step: 112-57 -- Loss: 0.22544698417186737
train-epoch-step: 112-58 -- Loss: 0.27453914284706116
train-epoch-step: 112-59 -- Loss: 0.22533634305000305
train-epoch-step: 112-60 -- Loss: 0.12413585186004639
train-epoch-step: 112-61 -- Loss: 0.19406038522720337
train-epoch-step: 112-62 -- Loss: 0.17743147909641266
train-epoch-step: 112-63 -- Loss: 0.12983688712120056
train-epoch-step: 112-64 -- Loss: 0.14147242903709412
train-epoch-step: 112-65 -- Loss: 0.17220035195350647
train-epoch-step: 112-66 -- Loss: 0.10564036667346954
train-epoch-step: 112-67 -- Loss: 0.12001525610685349
train-epoch-step: 112-68 -- Loss: 0.2059641182422638
train-epoch-step: 112-69 -- Loss: 0.11536811292171478
train-epoch-step: 112-70 -- Loss: 0.2120954990386963
train-epoch-step: 112-71 -- Loss: 0.25574740767478943
train-epoch-step: 112-72 -- Loss: 0.1662455052137375
train-epoch-step: 112-73 -- Loss: 0.19834962487220764
train-epoch-step: 112-74 -- Loss: 0.09354884922504425
train-epoch-step: 112-75 -- Loss: 0.12244141101837158
train-epoch-step: 112-76 -- Loss: 0.13923311233520508
train-epoch-step: 112-77 -- Loss: 0.21966445446014404
train-epoch-step: 112-78 -- Loss: 0.2493901401758194
train-epoch-step: 112-79 -- Loss: 0.18797892332077026
train-epoch-step: 112-80 -- Loss: 0.24255043268203735
train-epoch-step: 112-81 -- Loss: 0.1187799796462059
train-epoch-step: 112-82 -- Loss: 0.23741519451141357
train-epoch-step: 112-83 -- Loss: 0.16686823964118958
train-epoch-step: 112-84 -- Loss: 0.180650994181633
train-epoch-step: 112-85 -- Loss: 0.16471615433692932
train-epoch-step: 112-86 -- Loss: 0.11584428697824478
train-epoch-step: 112-87 -- Loss: 0.19655758142471313
train-epoch-step: 112-88 -- Loss: 0.13173893094062805
train-epoch-step: 112-89 -- Loss: 0.17532643675804138
train-epoch-step: 112-90 -- Loss: 0.18482628464698792
train-epoch-step: 112-91 -- Loss: 0.2345638871192932
train-epoch-step: 112-92 -- Loss: 0.14884346723556519
train-epoch-step: 112-93 -- Loss: 0.16793346405029297
train-epoch-step: 112-94 -- Loss: 0.21403361856937408
train-epoch-step: 112-95 -- Loss: 0.17996768653392792
train-epoch-step: 112-96 -- Loss: 0.20698785781860352
train-epoch-step: 112-97 -- Loss: 0.1645537167787552
train-epoch-step: 112-98 -- Loss: 0.14714239537715912
train-epoch-step: 112-99 -- Loss: 0.17136582732200623
train-epoch-step: 112-100 -- Loss: 0.1779419481754303
train-epoch-step: 112-101 -- Loss: 0.25441986322402954
train-epoch-step: 112-102 -- Loss: 0.20365726947784424
train-epoch-step: 112-103 -- Loss: 0.17344553768634796
train-epoch-step: 112-104 -- Loss: 0.14290566742420197
train-epoch-step: 112-105 -- Loss: 0.2551777958869934
train-epoch-step: 112-106 -- Loss: 0.17473025619983673
train-epoch-step: 112-107 -- Loss: 0.18544283509254456
train-epoch-step: 112-108 -- Loss: 0.18173009157180786
train-epoch-step: 112-109 -- Loss: 0.13774928450584412
train-epoch-step: 112-110 -- Loss: 0.1742168813943863
train-epoch-step: 112-111 -- Loss: 0.17571069300174713
train-epoch-step: 112-112 -- Loss: 0.16321347653865814
train-epoch-step: 112-113 -- Loss: 0.15843884646892548
train-epoch-step: 112-114 -- Loss: 0.18912716209888458
train-epoch-step: 112-115 -- Loss: 0.15513060986995697
train-epoch-step: 112-116 -- Loss: 0.13404078781604767
train-epoch-step: 112-117 -- Loss: 0.12113815546035767
train-epoch-step: 112-118 -- Loss: 0.1835106909275055
train-epoch-step: 112-119 -- Loss: 0.14367786049842834
train-epoch-step: 112-120 -- Loss: 0.2365349382162094
train-epoch-step: 112-121 -- Loss: 0.2393208146095276
train-epoch-step: 112-122 -- Loss: 0.2101280838251114
train-epoch-step: 112-123 -- Loss: 0.19223785400390625
train-epoch-step: 112-124 -- Loss: 0.1171596571803093
train-epoch-step: 112-125 -- Loss: 0.14693640172481537
train-epoch-step: 112-126 -- Loss: 0.22385671734809875
train-epoch-step: 112-127 -- Loss: 0.16422347724437714
train-epoch-step: 112-128 -- Loss: 0.16530221700668335
train-epoch-step: 112-129 -- Loss: 0.13590022921562195
train-epoch-step: 112-130 -- Loss: 0.18521128594875336
train-epoch-step: 112-131 -- Loss: 0.12598779797554016
train-epoch-step: 112-132 -- Loss: 0.18137957155704498
train-epoch-step: 112-133 -- Loss: 0.1161351352930069
train-epoch-step: 112-134 -- Loss: 0.18145813047885895
train-epoch-step: 112-135 -- Loss: 0.1269182711839676
train-epoch-step: 112-136 -- Loss: 0.12262416630983353
train-epoch-step: 112-137 -- Loss: 0.2311864197254181
train-epoch-step: 112-138 -- Loss: 0.24612373113632202
train-epoch-step: 112-139 -- Loss: 0.12757545709609985
train-epoch-step: 112-140 -- Loss: 0.19801509380340576
train-epoch-step: 112-141 -- Loss: 0.22285977005958557
train-epoch-step: 112-142 -- Loss: 0.19541822373867035
train-epoch-step: 112-143 -- Loss: 0.1615581065416336
train-epoch-step: 112-144 -- Loss: 0.17171253263950348
train-epoch-step: 112-145 -- Loss: 0.13437096774578094
train-epoch-step: 112-146 -- Loss: 0.17227846384048462
train-epoch-step: 112-147 -- Loss: 0.16423079371452332
train-epoch-step: 112-148 -- Loss: 0.16068978607654572
train-epoch-step: 112-149 -- Loss: 0.11312747001647949
train-epoch-step: 112-150 -- Loss: 0.17600023746490479
train-epoch-step: 112-151 -- Loss: 0.19189731776714325
train-epoch-step: 112-152 -- Loss: 0.18016767501831055
train-epoch-step: 112-153 -- Loss: 0.261574387550354
train-epoch-step: 112-154 -- Loss: 0.12873029708862305
train-epoch-step: 112-155 -- Loss: 0.13162028789520264
train-epoch-step: 112-156 -- Loss: 0.11194667965173721
train-epoch-step: 112-157 -- Loss: 0.15781395137310028
train-epoch-step: 112-158 -- Loss: 0.1576739400625229
train-epoch-step: 112-159 -- Loss: 0.17134560644626617
train-epoch-step: 112-160 -- Loss: 0.19769856333732605
train-epoch-step: 112-161 -- Loss: 0.1966152936220169
train-epoch-step: 112-162 -- Loss: 0.2049972414970398
train-epoch-step: 112-163 -- Loss: 0.18335235118865967
train-epoch-step: 112-164 -- Loss: 0.18778608739376068
train-epoch-step: 112-165 -- Loss: 0.15553627908229828
train-epoch-step: 112-166 -- Loss: 0.11800083518028259
train-epoch-step: 112-167 -- Loss: 0.11671928316354752
train-epoch-step: 112-168 -- Loss: 0.19363422691822052
train-epoch-step: 112-169 -- Loss: 0.1348661482334137
train-epoch-step: 112-170 -- Loss: 0.18949191272258759
train-epoch-step: 112-171 -- Loss: 0.1379072666168213
train-epoch-step: 112-172 -- Loss: 0.2513166069984436
train-epoch-step: 112-173 -- Loss: 0.12414483726024628
train-epoch-step: 112-174 -- Loss: 0.2392541915178299
train-epoch-step: 112-175 -- Loss: 0.18258528411388397
train-epoch-step: 112-176 -- Loss: 0.12648412585258484
train-epoch-step: 112-177 -- Loss: 0.17206323146820068
train-epoch-step: 112-178 -- Loss: 0.17161071300506592
train-epoch-step: 112-179 -- Loss: 0.14393864572048187
train-epoch-step: 112-180 -- Loss: 0.14592024683952332
train-epoch-step: 112-181 -- Loss: 0.16089189052581787
train-epoch-step: 112-182 -- Loss: 0.17306843400001526
train-epoch-step: 112-183 -- Loss: 0.26727673411369324
train-epoch-step: 112-184 -- Loss: 0.13237251341342926
train-epoch-step: 112-185 -- Loss: 0.1352555900812149
train-epoch-step: 112-186 -- Loss: 0.17928527295589447
train-epoch-step: 112-187 -- Loss: 0.19995930790901184
train-epoch-step: 112-188 -- Loss: 0.16409805417060852
train-epoch-step: 112-189 -- Loss: 0.10421524196863174
train-epoch-step: 112-190 -- Loss: 0.17664490640163422
train-epoch-step: 112-191 -- Loss: 0.15142297744750977
train-epoch-step: 112-192 -- Loss: 0.21865926682949066
train-epoch-step: 112-193 -- Loss: 0.1985614150762558
train-epoch-step: 112-194 -- Loss: 0.17463648319244385
train-epoch-step: 112-195 -- Loss: 0.15534013509750366
train-epoch-step: 112-196 -- Loss: 0.16263404488563538
train-epoch-step: 112-197 -- Loss: 0.12558352947235107
train-epoch-step: 112-198 -- Loss: 0.1219056248664856
train-epoch-step: 112-199 -- Loss: 0.1390306055545807
train-epoch-step: 112-200 -- Loss: 0.12130723148584366
train-epoch-step: 112-201 -- Loss: 0.1829310655593872
train-epoch-step: 112-202 -- Loss: 0.13356544077396393
train-epoch-step: 112-203 -- Loss: 0.1704293191432953
train-epoch-step: 112-204 -- Loss: 0.12730859220027924
train-epoch-step: 112-205 -- Loss: 0.17477315664291382
train-epoch-step: 112-206 -- Loss: 0.18996676802635193
train-epoch-step: 112-207 -- Loss: 0.12907305359840393
train-epoch-step: 112-208 -- Loss: 0.17093290388584137
train-epoch-step: 112-209 -- Loss: 0.13529440760612488
train-epoch-step: 112-210 -- Loss: 0.12885448336601257
train-epoch-step: 112-211 -- Loss: 0.19612030684947968
train-epoch-step: 112-212 -- Loss: 0.19247552752494812
train-epoch-step: 112-213 -- Loss: 0.12240637838840485
train-epoch-step: 112-214 -- Loss: 0.14276760816574097
train-epoch-step: 112-215 -- Loss: 0.12135143578052521
train-epoch-step: 112-216 -- Loss: 0.19105243682861328
train-epoch-step: 112-217 -- Loss: 0.20568779110908508
train-epoch-step: 112-218 -- Loss: 0.14367231726646423
train-epoch-step: 112-219 -- Loss: 0.16126836836338043
train-epoch-step: 112-220 -- Loss: 0.12031519412994385
train-epoch-step: 112-221 -- Loss: 0.20044156908988953
train-epoch-step: 112-222 -- Loss: 0.11193887889385223
train-epoch-step: 112-223 -- Loss: 0.16779130697250366
train-epoch-step: 112-224 -- Loss: 0.1807098388671875
train-epoch-step: 112-225 -- Loss: 0.2686856985092163
train-epoch-step: 112-226 -- Loss: 0.20146605372428894
train-epoch-step: 112-227 -- Loss: 0.21723175048828125
train-epoch-step: 112-228 -- Loss: 0.16969269514083862
train-epoch-step: 112-229 -- Loss: 0.1612759530544281
train-epoch-step: 112-230 -- Loss: 0.15932700037956238
train-epoch-step: 112-231 -- Loss: 0.14974930882453918
train-epoch-step: 112-232 -- Loss: 0.17482119798660278
train-epoch-step: 112-233 -- Loss: 0.08097916841506958
train-epoch-step: 112-234 -- Loss: 0.16665038466453552
train-epoch-step: 112-235 -- Loss: 0.13824519515037537
train-epoch-step: 112-236 -- Loss: 0.1730213463306427
train-epoch-step: 112-237 -- Loss: 0.22375339269638062
train-epoch-step: 112-238 -- Loss: 0.1546960026025772
train-epoch-step: 112-239 -- Loss: 0.11818945407867432
train-epoch-step: 112-240 -- Loss: 0.22039422392845154
train-epoch-step: 112-241 -- Loss: 0.14870116114616394
train-epoch-step: 112-242 -- Loss: 0.20968057215213776
train-epoch-step: 112-243 -- Loss: 0.22645796835422516
train-epoch-step: 112-244 -- Loss: 0.20440272986888885
train-epoch-step: 112-245 -- Loss: 0.19953623414039612
train-epoch-step: 112-246 -- Loss: 0.21106818318367004
train-epoch-step: 112-247 -- Loss: 0.19862738251686096
train-epoch-step: 112-248 -- Loss: 0.18438781797885895
train-epoch-step: 112-249 -- Loss: 0.13815878331661224
train-epoch-step: 112-250 -- Loss: 0.18894872069358826
train-epoch-step: 112-251 -- Loss: 0.10433269292116165
train-epoch-step: 112-252 -- Loss: 0.20577487349510193
train-epoch-step: 112-253 -- Loss: 0.13036128878593445
train-epoch-step: 112-254 -- Loss: 0.20643877983093262
train-epoch-step: 112-255 -- Loss: 0.13812020421028137
train-epoch-step: 112-256 -- Loss: 0.16678771376609802
train-epoch-step: 112-257 -- Loss: 0.18193960189819336
train-epoch-step: 112-258 -- Loss: 0.14137175679206848
train-epoch-step: 112-259 -- Loss: 0.11846403777599335
train-epoch-step: 112-260 -- Loss: 0.19321566820144653
train-epoch-step: 112-261 -- Loss: 0.16619549691677094
train-epoch-step: 112-262 -- Loss: 0.29027339816093445
train-epoch-step: 112-263 -- Loss: 0.19343474507331848
train-epoch-step: 112-264 -- Loss: 0.17032533884048462
train-epoch-step: 112-265 -- Loss: 0.13154608011245728